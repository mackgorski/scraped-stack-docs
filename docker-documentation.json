[{
  "url": "https://docs.docker.com/compose/",
  "markdown": "# Docker Compose overview | Docker Docs\n\nDocker Compose is a tool for defining and running multi-container applications. It is the key to unlocking a streamlined and efficient development and deployment experience.\n\nCompose simplifies the control of your entire application stack, making it easy to manage services, networks, and volumes in a single, comprehensible YAML configuration file. Then, with a single command, you create and start all the services from your configuration file.\n\nCompose works in all environments; production, staging, development, testing, as well as CI workflows. It also has commands for managing the whole lifecycle of your application:\n\n*   Start, stop, and rebuild services\n*   View the status of running services\n*   Stream the log output of running services\n*   Run a one-off command on a service",
  "title": "Docker Compose overview | Docker Docs\n",
  "description": "Learn how to use Docker Compose to define and run multi-container applications with this detailed introduction to the tool.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/",
  "markdown": "# Overview of Docker Build | Docker Docs\n\nDocker Build is one of Docker Engine's most used features. Whenever you are creating an image you are using Docker Build. Build is a key part of your software development life cycle allowing you to package and bundle your code and ship it anywhere.\n\nDocker Build is more than a command for building images, and it's not only about packaging your code. It's a whole ecosystem of tools and features that support not only common workflow tasks but also provides support for more complex and advanced scenarios.",
  "title": "Overview of Docker Build | Docker Docs\n",
  "description": "Get an overview of Docker Build to package and bundle your code and ship it anywhere",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/",
  "markdown": "# Docker Engine overview | Docker Docs\n\nDocker Engine is an open source containerization technology for building and containerizing your applications. Docker Engine acts as a client-server application with:\n\n*   A server with a long-running daemon process [`dockerd`](https://docs.docker.com/reference/cli/dockerd).\n*   APIs which specify interfaces that programs can use to talk to and instruct the Docker daemon.\n*   A command line interface (CLI) client [`docker`](https://docs.docker.com/reference/cli/docker/).\n\nThe CLI uses [Docker APIs](https://docs.docker.com/engine/api/) to control or interact with the Docker daemon through scripting or direct CLI commands. Many other Docker applications use the underlying API and CLI. The daemon creates and manages Docker objects, such as images, containers, networks, and volumes.\n\nFor more details, see [Docker Architecture](https://docs.docker.com/guides/docker-overview/#docker-architecture).\n\nThe Docker Engine is licensed under the Apache License, Version 2.0. See [LICENSE](https://github.com/moby/moby/blob/master/LICENSE) for the full license text.\n\nHowever, for commercial use of Docker Engine obtained via Docker Desktop within larger enterprises (exceeding 250 employees OR with annual revenue surpassing $10 million USD), a [paid subscription](https://www.docker.com/pricing/) is required.",
  "title": "Docker Engine overview | Docker Docs\n",
  "description": "Find a comprehensive overview of Docker Engine, including how to install, storage details, networking, and more",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/",
  "markdown": "# How services work | Docker Docs\n\nTo deploy an application image when Docker Engine is in Swarm mode, you create a service. Frequently a service is the image for a microservice within the context of some larger application. Examples of services might include an HTTP server, a database, or any other type of executable program that you wish to run in a distributed environment.\n\nWhen you create a service, you specify which container image to use and which commands to execute inside running containers. You also define options for the service including:\n\n*   The port where the swarm makes the service available outside the swarm\n*   An overlay network for the service to connect to other services in the swarm\n*   CPU and memory limits and reservations\n*   A rolling update policy\n*   The number of replicas of the image to run in the swarm\n\nWhen you deploy the service to the swarm, the swarm manager accepts your service definition as the desired state for the service. Then it schedules the service on nodes in the swarm as one or more replica tasks. The tasks run independently of each other on nodes in the swarm.\n\nFor example, imagine you want to load balance between three instances of an HTTP listener. The diagram below shows an HTTP listener service with three replicas. Each of the three instances of the listener is a task in the swarm.\n\n![ HTTP listener service with three replicas](https://docs.docker.com/engine/swarm/images/services-diagram.webp)\n\nA container is an isolated process. In the Swarm mode model, each task invokes exactly one container. A task is analogous to a â€œslotâ€ where the scheduler places a container. Once the container is live, the scheduler recognizes that the task is in a running state. If the container fails health checks or terminates, the task terminates.\n\nA task is the atomic unit of scheduling within a swarm. When you declare a desired service state by creating or updating a service, the orchestrator realizes the desired state by scheduling tasks. For instance, you define a service that instructs the orchestrator to keep three instances of an HTTP listener running at all times. The orchestrator responds by creating three tasks. Each task is a slot that the scheduler fills by spawning a container. The container is the instantiation of the task. If an HTTP listener task subsequently fails its health check or crashes, the orchestrator creates a new replica task that spawns a new container.\n\nA task is a one-directional mechanism. It progresses monotonically through a series of states: assigned, prepared, running, etc. If the task fails, the orchestrator removes the task and its container and then creates a new task to replace it according to the desired state specified by the service.\n\nThe underlying logic of Docker's Swarm mode is a general purpose scheduler and orchestrator. The service and task abstractions themselves are unaware of the containers they implement. Hypothetically, you could implement other types of tasks such as virtual machine tasks or non-containerized process tasks. The scheduler and orchestrator are agnostic about the type of the task. However, the current version of Docker only supports container tasks.\n\nThe diagram below shows how Swarm mode accepts service create requests and schedules tasks to worker nodes.\n\n![Services flow](https://docs.docker.com/engine/swarm/images/service-lifecycle.webp)\n\n### [Pending services](#pending-services)\n\nA service may be configured in such a way that no node currently in the swarm can run its tasks. In this case, the service remains in state `pending`. Here are a few examples of when a service might remain in state `pending`.\n\n> **Tip** If your only intention is to prevent a service from being deployed, scale the service to 0 instead of trying to configure it in such a way that it remains in `pending`.\n\n*   If all nodes are paused or drained, and you create a service, it is pending until a node becomes available. In reality, the first node to become available gets all of the tasks, so this is not a good thing to do in a production environment.\n    \n*   You can reserve a specific amount of memory for a service. If no node in the swarm has the required amount of memory, the service remains in a pending state until a node is available which can run its tasks. If you specify a very large value, such as 500 GB, the task stays pending forever, unless you really have a node which can satisfy it.\n    \n*   You can impose placement constraints on the service, and the constraints may not be able to be honored at a given time.\n    \n\nThis behavior illustrates that the requirements and configuration of your tasks are not tightly tied to the current state of the swarm. As the administrator of a swarm, you declare the desired state of your swarm, and the manager works with the nodes in the swarm to create that state. You do not need to micro-manage the tasks on the swarm.\n\nThere are two types of service deployments, replicated and global.\n\nFor a replicated service, you specify the number of identical tasks you want to run. For example, you decide to deploy an HTTP service with three replicas, each serving the same content.\n\nA global service is a service that runs one task on every node. There is no pre-specified number of tasks. Each time you add a node to the swarm, the orchestrator creates a task and the scheduler assigns the task to the new node. Good candidates for global services are monitoring agents, anti-virus scanners or other types of containers that you want to run on every node in the swarm.\n\nThe diagram below shows a three-service replica in gray and a global service in black.\n\n![Global vs replicated services](https://docs.docker.com/engine/swarm/images/replicated-vs-global.webp)\n\n*   Read about how Swarm mode [nodes](https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/) work.\n*   Learn how [PKI](https://docs.docker.com/engine/swarm/how-swarm-mode-works/pki/) works in Swarm mode.",
  "title": "How services work | Docker Docs\n",
  "description": "How swarm mode services work",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/install/",
  "markdown": "# Install Docker Engine | Docker Docs\n\nThis section describes how to install Docker Engine on Linux, also known as Docker CE. Docker Engine is also available for Windows, macOS, and Linux, through Docker Desktop. For instructions on how to install Docker Desktop, see:\n\n*   [Docker Desktop for Linux](https://docs.docker.com/desktop/install/linux-install/)\n*   [Docker Desktop for Mac (macOS)](https://docs.docker.com/desktop/install/mac-install/)\n*   [Docker Desktop for Windows](https://docs.docker.com/desktop/install/windows-install/)\n\n| Platform | x86\\_64 / amd64 | arm64 / aarch64 | arm (32-bit) | ppc64le | s390x |\n| --- | --- | --- | --- | --- | --- |\n| [CentOS](https://docs.docker.com/engine/install/centos/) | âœ…   | âœ…   |     | âœ…   |     |\n| [Debian](https://docs.docker.com/engine/install/debian/) | âœ…   | âœ…   | âœ…   | âœ…   |     |\n| [Fedora](https://docs.docker.com/engine/install/fedora/) | âœ…   | âœ…   |     | âœ…   |     |\n| [Raspberry Pi OS (32-bit)](https://docs.docker.com/engine/install/raspberry-pi-os/) |     |     | âœ…   |     |     |\n| [RHEL](https://docs.docker.com/engine/install/rhel/) | ðŸš§  | ðŸš§  |     |     | âœ…   |\n| [SLES](https://docs.docker.com/engine/install/sles/) |     |     |     |     | âœ…   |\n| [Ubuntu](https://docs.docker.com/engine/install/ubuntu/) | âœ…   | âœ…   | âœ…   | âœ…   | âœ…   |\n| [Binaries](https://docs.docker.com/engine/install/binaries/) | âœ…   | âœ…   | âœ…   |     |     |\n\nðŸš§ = Experimental\n\n### [Other Linux distros](#other-linux-distros)\n\n> **Note**\n> \n> While the following instructions may work, Docker doesn't test or verify installation on distro derivatives.\n\n*   If you use Debian derivatives such as \"BunsenLabs Linux\", \"Kali Linux\" or \"LMDE\" (Debian-based Mint) should follow the installation instructions for [Debian](https://docs.docker.com/engine/install/debian/), substitute the version of your distro for the corresponding Debian release. Refer to the documentation of your distro to find which Debian release corresponds with your derivative version.\n*   Likewise, if you use Ubuntu derivatives such as \"Kubuntu\", \"Lubuntu\" or \"Xubuntu\" you should follow the installation instructions for [Ubuntu](https://docs.docker.com/engine/install/ubuntu/), substituting the version of your distro for the corresponding Ubuntu release. Refer to the documentation of your distro to find which Ubuntu release corresponds with your derivative version.\n*   Some Linux distros provide a package of Docker Engine through their package repositories. These packages are built and maintained by the Linux distro's package maintainers and may have differences in configuration or are built from modified source code. Docker isn't involved in releasing these packages and you should report any bugs or issues involving these packages to your Linux distro's issue tracker.\n\nDocker provides [binaries](https://docs.docker.com/engine/install/binaries/) for manual installation of Docker Engine. These binaries are statically linked and you can use them on any Linux distro.\n\nDocker Engine has two types of update channels, **stable** and **test**:\n\n*   The **stable** channel gives you the latest versions released for general availability.\n*   The **test** channel gives you pre-release versions that are ready for testing before general availability.\n\nUse the test channel with caution. Pre-release versions include experimental and early-access features that are subject to breaking changes.\n\nDocker Engine is an open source project, supported by the Moby project maintainers and community members. Docker doesn't provide support for Docker Engine. Docker provides support for Docker products, including Docker Desktop, which uses Docker Engine as one of its components.\n\nFor information about the open source project, refer to the [Moby project website](https://mobyproject.org/).\n\n### [Upgrade path](#upgrade-path)\n\nPatch releases are always backward compatible with its major and minor version.\n\n### [Licensing](#licensing)\n\nDocker Engine is licensed under the Apache License, Version 2.0. See [LICENSE](https://github.com/moby/moby/blob/master/LICENSE) for the full license text.\n\nIf you discover a security issue, we request that you bring it to our attention immediately.\n\nDO NOT file a public issue. Instead, submit your report privately to security@docker.com.\n\nSecurity reports are greatly appreciated, and Docker will publicly thank you for it.\n\nAfter setting up Docker, you can learn the basics with [Getting started with Docker](https://docs.docker.com/guides/getting-started/).",
  "title": "Install Docker Engine | Docker Docs\n",
  "description": "Learn how to choose the best method for you to install Docker Engine. This client-server application is available on Linux, Mac, Windows, and as a static binary.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/how-swarm-mode-works/pki/",
  "markdown": "# Manage swarm security with public key infrastructure (PKI)\n\nThe Swarm mode public key infrastructure (PKI) system built into Docker makes it simple to securely deploy a container orchestration system. The nodes in a swarm use mutual Transport Layer Security (TLS) to authenticate, authorize, and encrypt the communications with other nodes in the swarm.\n\nWhen you create a swarm by running `docker swarm init`, Docker designates itself as a manager node. By default, the manager node generates a new root Certificate Authority (CA) along with a key pair, which are used to secure communications with other nodes that join the swarm. If you prefer, you can specify your own externally-generated root CA, using the `--external-ca` flag of the [docker swarm init](https://docs.docker.com/reference/cli/docker/swarm/init/) command.\n\nThe manager node also generates two tokens to use when you join additional nodes to the swarm: one worker token and one manager token. Each token includes the digest of the root CA's certificate and a randomly generated secret. When a node joins the swarm, the joining node uses the digest to validate the root CA certificate from the remote manager. The remote manager uses the secret to ensure the joining node is an approved node.\n\nEach time a new node joins the swarm, the manager issues a certificate to the node. The certificate contains a randomly generated node ID to identify the node under the certificate common name (CN) and the role under the organizational unit (OU). The node ID serves as the cryptographically secure node identity for the lifetime of the node in the current swarm.\n\nThe diagram below illustrates how manager nodes and worker nodes encrypt communications using a minimum of TLS 1.2.\n\n![TLS diagram](https://docs.docker.com/engine/swarm/images/tls.webp?w=600)\n\nThe example below shows the information from a certificate from a worker node:\n\nBy default, each node in the swarm renews its certificate every three months. You can configure this interval by running the `docker swarm update --cert-expiry <TIME PERIOD>` command. The minimum rotation value is 1 hour. Refer to the [docker swarm update](https://docs.docker.com/reference/cli/docker/swarm/update/) CLI reference for details.\n\n> **Note**\n> \n> Mirantis Kubernetes Engine (MKE), formerly known as Docker UCP, provides an external certificate manager service for the swarm. If you run swarm on MKE, you shouldn't rotate the CA certificates manually. Instead, contact Mirantis support if you need to rotate a certificate.\n\nIn the event that a cluster CA key or a manager node is compromised, you can rotate the swarm root CA so that none of the nodes trust certificates signed by the old root CA anymore.\n\nRun `docker swarm ca --rotate` to generate a new CA certificate and key. If you prefer, you can pass the `--ca-cert` and `--external-ca` flags to specify the root certificate and to use a root CA external to the swarm. Alternately, you can pass the `--ca-cert` and `--ca-key` flags to specify the exact certificate and key you would like the swarm to use.\n\nWhen you issue the `docker swarm ca --rotate` command, the following things happen in sequence:\n\n1.  Docker generates a cross-signed certificate. This means that a version of the new root CA certificate is signed with the old root CA certificate. This cross-signed certificate is used as an intermediate certificate for all new node certificates. This ensures that nodes that still trust the old root CA can still validate a certificate signed by the new CA.\n    \n2.  Docker also tells all nodes to immediately renew their TLS certificates. This process may take several minutes, depending on the number of nodes in the swarm.\n    \n3.  After every node in the swarm has a new TLS certificate signed by the new CA, Docker forgets about the old CA certificate and key material, and tells all the nodes to trust the new CA certificate only.\n    \n    This also causes a change in the swarm's join tokens. The previous join tokens are no longer valid.\n    \n\nFrom this point on, all new node certificates issued are signed with the new root CA, and do not contain any intermediates.\n\n*   Read about how [nodes](https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/) work.\n*   Learn how Swarm mode [services](https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/) work.",
  "title": "Manage swarm security with public key infrastructure (PKI) | Docker Docs\n",
  "description": "How PKI works in swarm mode",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/how-swarm-mode-works/swarm-task-states/",
  "markdown": "# Swarm task states | Docker Docs\n\nDocker lets you create services, which can start tasks. A service is a description of a desired state, and a task does the work. Work is scheduled on swarm nodes in this sequence:\n\n1.  Create a service by using `docker service create`.\n2.  The request goes to a Docker manager node.\n3.  The Docker manager node schedules the service to run on particular nodes.\n4.  Each service can start multiple tasks.\n5.  Each task has a life cycle, with states like `NEW`, `PENDING`, and `COMPLETE`.\n\nTasks are execution units that run once to completion. When a task stops, it isn't executed again, but a new task may take its place.\n\nTasks advance through a number of states until they complete or fail. Tasks are initialized in the `NEW` state. The task progresses forward through a number of states, and its state doesn't go backward. For example, a task never goes from `COMPLETE` to `RUNNING`.\n\nTasks go through the states in the following order:\n\n| Task state | Description |\n| --- | --- |\n| `NEW` | The task was initialized. |\n| `PENDING` | Resources for the task were allocated. |\n| `ASSIGNED` | Docker assigned the task to nodes. |\n| `ACCEPTED` | The task was accepted by a worker node. If a worker node rejects the task, the state changes to `REJECTED`. |\n| `READY` | The worker node is ready to start the task |\n| `PREPARING` | Docker is preparing the task. |\n| `STARTING` | Docker is starting the task. |\n| `RUNNING` | The task is executing. |\n| `COMPLETE` | The task exited without an error code. |\n| `FAILED` | The task exited with an error code. |\n| `SHUTDOWN` | Docker requested the task to shut down. |\n| `REJECTED` | The worker node rejected the task. |\n| `ORPHANED` | The node was down for too long. |\n| `REMOVE` | The task is not terminal but the associated service was removed or scaled down. |\n\nRun `docker service ps <service-name>` to get the state of a task. The `CURRENT STATE` field shows the task's state and how long it's been there.\n\n*   [Learn about swarm tasks](https://github.com/docker/swarmkit/blob/master/design/task_model.md)",
  "title": "Swarm task states | Docker Docs\n",
  "description": "Learn about tasks that are scheduled on your swarm.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/install/centos/",
  "markdown": "# Install Docker Engine on CentOS\n\nTo get started with Docker Engine on CentOS, make sure you [meet the prerequisites](#prerequisites), and then follow the [installation steps](#installation-methods).\n\n### [OS requirements](#os-requirements)\n\nTo install Docker Engine, you need a maintained version of one of the following CentOS versions:\n\n*   CentOS 9 (stream)\n\nThe `centos-extras` repository must be enabled. This repository is enabled by default. If you have disabled it, you need to re-enable it.\n\n### [Uninstall old versions](#uninstall-old-versions)\n\nOlder versions of Docker went by `docker` or `docker-engine`. Uninstall any such older versions before attempting to install a new version, along with associated dependencies.\n\n`yum` might report that you have none of these packages installed.\n\nImages, containers, volumes, and networks stored in `/var/lib/docker/` aren't automatically removed when you uninstall Docker.\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n*   You can [set up Docker's repositories](#install-using-the-repository) and install from them, for ease of installation and upgrade tasks. This is the recommended approach.\n    \n*   You can download the RPM package, [install it manually](#install-from-a-package), and manage upgrades completely manually. This is useful in situations such as installing Docker on air-gapped systems with no access to the internet.\n    \n*   In testing and development environments, you can use automated [convenience scripts](#install-using-the-convenience-script) to install Docker.\n    \n\n### [Install using the rpm repository](#install-using-the-repository)\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\n#### [Set up the repository](#set-up-the-repository)\n\nInstall the `yum-utils` package (which provides the `yum-config-manager` utility) and set up the repository.\n\n#### [Install Docker Engine](#install-docker-engine)\n\n1.  Install Docker Engine, containerd, and Docker Compose:\n    \n    * * *\n    \n    To install the latest version, run:\n    \n    If prompted to accept the GPG key, verify that the fingerprint matches `060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35`, and if so, accept it.\n    \n    This command installs Docker, but it doesn't start Docker. It also creates a `docker` group, however, it doesn't add any users to the group by default.\n    \n    To install a specific version, start by listing the available versions in the repository:\n    \n    The list returned depends on which repositories are enabled, and is specific to your version of CentOS (indicated by the `.el9` suffix in this example).\n    \n    Install a specific version by its fully qualified package name, which is the package name (`docker-ce`) plus the version string (2nd column), separated by a hyphen (`-`). For example, `docker-ce-3:27.0.3-1.el9`.\n    \n    Replace `<VERSION_STRING>` with the desired version and then run the following command to install:\n    \n    This command installs Docker, but it doesn't start Docker. It also creates a `docker` group, however, it doesn't add any users to the group by default.\n    \n    * * *\n    \n2.  Start Docker.\n    \n3.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why youâ€™re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine)\n\nTo upgrade Docker Engine, follow the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### [Install from a package](#install-from-a-package)\n\nIf you can't use Docker's `rpm` repository to install Docker Engine, you can download the `.rpm` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [https://download.docker.com/linux/centos/](https://download.docker.com/linux/centos/) and choose your version of CentOS. Then browse to `x86_64/stable/Packages/` and download the `.rpm` file for the Docker version you want to install.\n    \n2.  Install Docker Engine, changing the following path to the path where you downloaded the Docker package.\n    \n    Docker is installed but not started. The `docker` group is created, but no users are added to the group.\n    \n3.  Start Docker.\n    \n4.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why youâ€™re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine-1)\n\nTo upgrade Docker Engine, download the newer package files and repeat the [installation procedure](#install-from-a-package), using `yum -y upgrade` instead of `yum -y install`, and point to the new files.\n\n### [Install using the convenience script](#install-using-the-convenience-script)\n\nDocker provides a convenience script at [https://get.docker.com/](https://get.docker.com/) to install Docker into development environments non-interactively. The convenience script isn't recommended for production environments, but it's useful for creating a provisioning script tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and you can find it in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n*   The script requires `root` or `sudo` privileges to run.\n*   The script attempts to detect your Linux distribution and version and configure your package management system for you.\n*   The script doesn't allow you to customize most installation parameters.\n*   The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n*   By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test upgrades in a test environment before deploying to your production systems.\n*   The script isn't designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, resulting in outdated versions.\n\n> **Tip: preview script steps before running**\n> \n> You can run the script with the `--dry-run` option to learn what steps the script will run when invoked:\n\nThis example downloads the script from [https://get.docker.com/](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\nYou have now successfully installed and started Docker Engine. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users can't run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n> \n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user). You can also install Docker without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](https://docs.docker.com/engine/security/rootless/).\n\n#### [Install pre-releases](#install-pre-releases)\n\nDocker also provides a convenience script at [https://test.docker.com/](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equal to the script at `get.docker.com`, but configures your package manager to use the test channel of the Docker package repository. The test channel includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they're released as stable.\n\nTo install the latest version of Docker on Linux from the test channel, run:\n\n#### [Upgrade Docker after using the convenience script](#upgrade-docker-after-using-the-convenience-script)\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There's no advantage to re-running the convenience script. Re-running it can cause issues if it attempts to re-install repositories which already exist on the host machine.\n\n1.  Uninstall the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n2.  Images, containers, volumes, or custom configuration files on your host aren't automatically removed. To delete all images, containers, and volumes:\n    \n\nYou have to delete any edited configuration files manually.\n\n*   Continue to [Post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/).",
  "title": "Install Docker Engine on CentOS | Docker Docs\n",
  "description": "Learn how to install Docker Engine on CentOS. These instructions cover the different installation methods, how to uninstall, and next steps.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/swarm-mode/",
  "markdown": "# Run Docker Engine in swarm mode\n\nWhen you first install and start working with Docker Engine, Swarm mode is disabled by default. When you enable Swarm mode, you work with the concept of services managed through the `docker service` command.\n\nThere are two ways to run the engine in Swarm mode:\n\n*   Create a new swarm, covered in this article.\n*   [Join an existing swarm](https://docs.docker.com/engine/swarm/join-nodes/).\n\nWhen you run the engine in Swarm mode on your local machine, you can create and test services based upon images you've created or other available images. In your production environment, Swarm mode provides a fault-tolerant platform with cluster management features to keep your services running and available.\n\nThese instructions assume you have installed the Docker Engine on a machine to serve as a manager node in your swarm.\n\nIf you haven't already, read through the [Swarm mode key concepts](https://docs.docker.com/engine/swarm/key-concepts/) and try the [Swarm mode tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/).\n\nWhen you run the command to create a swarm, Docker Engine starts running in Swarm mode.\n\nRun [`docker swarm init`](https://docs.docker.com/reference/cli/docker/swarm/init/) to create a single-node swarm on the current node. The engine sets up the swarm as follows:\n\n*   Switches the current node into Swarm mode.\n*   Creates a swarm named `default`.\n*   Designates the current node as a leader manager node for the swarm.\n*   Names the node with the machine hostname.\n*   Configures the manager to listen on an active network interface on port \\`2377\\`\\`.\n*   Sets the current node to `Active` availability, meaning it can receive tasks from the scheduler.\n*   Starts an internal distributed data store for Engines participating in the swarm to maintain a consistent view of the swarm and all services running on it.\n*   By default, generates a self-signed root CA for the swarm.\n*   By default, generates tokens for worker and manager nodes to join the swarm.\n*   Creates an overlay network named `ingress` for publishing service ports external to the swarm.\n*   Creates an overlay default IP addresses and subnet mask for your networks\n\nThe output for `docker swarm init` provides the connection command to use when you join new worker nodes to the swarm:\n\n### [Configuring default address pools](#configuring-default-address-pools)\n\nBy default Swarm mode uses a default address pool `10.0.0.0/8` for global scope (overlay) networks. Every network that does not have a subnet specified will have a subnet sequentially allocated from this pool. In some circumstances it may be desirable to use a different default IP address pool for networks.\n\nFor example, if the default `10.0.0.0/8` range conflicts with already allocated address space in your network, then it is desirable to ensure that networks use a different range without requiring swarm users to specify each subnet with the `--subnet` command.\n\nTo configure custom default address pools, you must define pools at swarm initialization using the `--default-addr-pool` command line option. This command line option uses CIDR notation for defining the subnet mask. To create the custom address pool for Swarm, you must define at least one default address pool, and an optional default address pool subnet mask. For example, for the `10.0.0.0/27`, use the value `27`.\n\nDocker allocates subnet addresses from the address ranges specified by the `--default-addr-pool` option. For example, a command line option `--default-addr-pool 10.10.0.0/16` indicates that Docker will allocate subnets from that `/16` address range. If `--default-addr-pool-mask-len` were unspecified or set explicitly to 24, this would result in 256 `/24` networks of the form `10.10.X.0/24`.\n\nThe subnet range comes from the `--default-addr-pool`, (such as `10.10.0.0/16`). The size of 16 there represents the number of networks one can create within that `default-addr-pool` range. The `--default-addr-pool` option may occur multiple times with each option providing additional addresses for docker to use for overlay subnets.\n\nThe format of the command is:\n\nThe command to create a default IP address pool with a /16 (class B) for the `10.20.0.0` network looks like this:\n\nThe command to create a default IP address pool with a `/16` (class B) for the `10.20.0.0` and `10.30.0.0` networks, and to create a subnet mask of `/26` for each network looks like this:\n\nIn this example, `docker network create -d overlay net1` will result in `10.20.0.0/26` as the allocated subnet for `net1`, and `docker network create -d overlay net2` will result in `10.20.0.64/26` as the allocated subnet for `net2`. This continues until all the subnets are exhausted.\n\nRefer to the following pages for more information:\n\n*   [Swarm networking](https://docs.docker.com/engine/swarm/networking/) for more information about the default address pool usage\n*   `docker swarm init` [CLI reference](https://docs.docker.com/reference/cli/docker/swarm/init/) for more detail on the `--default-addr-pool` flag.\n\n### [Configure the advertise address](#configure-the-advertise-address)\n\nManager nodes use an advertise address to allow other nodes in the swarm access to the Swarmkit API and overlay networking. The other nodes on the swarm must be able to access the manager node on its advertise address.\n\nIf you don't specify an advertise address, Docker checks if the system has a single IP address. If so, Docker uses the IP address with the listening port `2377` by default. If the system has multiple IP addresses, you must specify the correct `--advertise-addr` to enable inter-manager communication and overlay networking:\n\nYou must also specify the `--advertise-addr` if the address where other nodes reach the first manager node is not the same address the manager sees as its own. For instance, in a cloud setup that spans different regions, hosts have both internal addresses for access within the region and external addresses that you use for access from outside that region. In this case, specify the external address with `--advertise-addr` so that the node can propagate that information to other nodes that subsequently connect to it.\n\nRefer to the `docker swarm init` [CLI reference](https://docs.docker.com/reference/cli/docker/swarm/init/) for more detail on the advertise address.\n\n### [View the join command or update a swarm join token](#view-the-join-command-or-update-a-swarm-join-token)\n\nNodes require a secret token to join the swarm. The token for worker nodes is different from the token for manager nodes. Nodes only use the join-token at the moment they join the swarm. Rotating the join token after a node has already joined a swarm does not affect the node's swarm membership. Token rotation ensures an old token cannot be used by any new nodes attempting to join the swarm.\n\nTo retrieve the join command including the join token for worker nodes, run:\n\nTo view the join command and token for manager nodes, run:\n\nPass the `--quiet` flag to print only the token:\n\nBe careful with the join tokens because they are the secrets necessary to join the swarm. In particular, checking a secret into version control is a bad practice because it would allow anyone with access to the application source code to add new nodes to the swarm. Manager tokens are especially sensitive because they allow a new manager node to join and gain control over the whole swarm.\n\nWe recommend that you rotate the join tokens in the following circumstances:\n\n*   If a token was checked-in by accident into a version control system, group chat or accidentally printed to your logs.\n*   If you suspect a node has been compromised.\n*   If you wish to guarantee that no new nodes can join the swarm.\n\nAdditionally, it is a best practice to implement a regular rotation schedule for any secret including swarm join tokens. We recommend that you rotate your tokens at least every 6 months.\n\nRun `swarm join-token --rotate` to invalidate the old token and generate a new token. Specify whether you want to rotate the token for `worker` or `manager` nodes:\n\n*   [Join nodes to a swarm](https://docs.docker.com/engine/swarm/join-nodes/)\n*   `swarm init` [command line reference](https://docs.docker.com/reference/cli/docker/swarm/init/)\n*   [Swarm mode tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/)",
  "title": "Run Docker Engine in swarm mode | Docker Docs\n",
  "description": "Run Docker Engine in swarm mode",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/install/debian/",
  "markdown": "# Install Docker Engine on Debian\n\nTo get started with Docker Engine on Debian, make sure you [meet the prerequisites](#prerequisites), and then follow the [installation steps](#installation-methods).\n\n### [Firewall limitations](#firewall-limitations)\n\n> **Warning**\n> \n> Before you install Docker, make sure you consider the following security implications and firewall incompatibilities.\n\n*   If you use ufw or firewalld to manage firewall settings, be aware that when you expose container ports using Docker, these ports bypass your firewall rules. For more information, refer to [Docker and ufw](https://docs.docker.com/network/packet-filtering-firewalls/#docker-and-ufw).\n*   Docker is only compatible with `iptables-nft` and `iptables-legacy`. Firewall rules created with `nft` are not supported on a system with Docker installed. Make sure that any firewall rulesets you use are created with `iptables` or `iptables6`, and that you add them to the `DOCKER-USER` chain, see [Packet filtering and firewalls](https://docs.docker.com/network/packet-filtering-firewalls/).\n\n### [OS requirements](#os-requirements)\n\nTo install Docker Engine, you need the 64-bit version of one of these Debian versions:\n\n*   Debian Bookworm 12 (stable)\n*   Debian Bullseye 11 (oldstable)\n\nDocker Engine for Debian is compatible with x86\\_64 (or amd64), armhf, arm64, and ppc64le (ppc64el) architectures.\n\n### [Uninstall old versions](#uninstall-old-versions)\n\nBefore you can install Docker Engine, you need to uninstall any conflicting packages.\n\nDistro maintainers provide unofficial distributions of Docker packages in their repositories. You must uninstall these packages before you can install the official version of Docker Engine.\n\nThe unofficial packages to uninstall are:\n\n*   `docker.io`\n*   `docker-compose`\n*   `docker-doc`\n*   `podman-docker`\n\nMoreover, Docker Engine depends on `containerd` and `runc`. Docker Engine bundles these dependencies as one bundle: `containerd.io`. If you have installed the `containerd` or `runc` previously, uninstall them to avoid conflicts with the versions bundled with Docker Engine.\n\nRun the following command to uninstall all conflicting packages:\n\n`apt-get` might report that you have none of these packages installed.\n\nImages, containers, volumes, and networks stored in `/var/lib/docker/` aren't automatically removed when you uninstall Docker. If you want to start with a clean installation, and prefer to clean up any existing data, read the [uninstall Docker Engine](#uninstall-docker-engine) section.\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n*   Docker Engine comes bundled with [Docker Desktop for Linux](https://docs.docker.com/desktop/install/linux-install/). This is the easiest and quickest way to get started.\n    \n*   Set up and install Docker Engine from [Docker's `apt` repository](#install-using-the-repository).\n    \n*   [Install it manually](#install-from-a-package) and manage upgrades manually.\n    \n*   Use a [convenience script](#install-using-the-convenience-script). Only recommended for testing and development environments.\n    \n\n### [Install using the `apt` repository](#install-using-the-repository)\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker `apt` repository. Afterward, you can install and update Docker from the repository.\n\n1.  Set up Docker's `apt` repository.\n    \n    > **Note**\n    > \n    > If you use a derivative distro, such as Kali Linux, you may need to substitute the part of this command that's expected to print the version codename:\n    > \n    > Replace this part with the codename of the corresponding Debian release, such as `bookworm`.\n    \n2.  Install the Docker packages.\n    \n    * * *\n    \n    To install the latest version, run:\n    \n    To install a specific version of Docker Engine, start by listing the available versions in the repository:\n    \n    Select the desired version and install:\n    \n    * * *\n    \n3.  Verify that the installation is successful by running the `hello-world` image:\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why youâ€™re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine)\n\nTo upgrade Docker Engine, follow step 2 of the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### [Install from a package](#install-from-a-package)\n\nIf you can't use Docker's `apt` repository to install Docker Engine, you can download the `deb` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [`https://download.docker.com/linux/debian/dists/`](https://download.docker.com/linux/debian/dists/).\n    \n2.  Select your Debian version in the list.\n    \n3.  Go to `pool/stable/` and select the applicable architecture (`amd64`, `armhf`, `arm64`, or `s390x`).\n    \n4.  Download the following `deb` files for the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n    *   `containerd.io_<version>_<arch>.deb`\n    *   `docker-ce_<version>_<arch>.deb`\n    *   `docker-ce-cli_<version>_<arch>.deb`\n    *   `docker-buildx-plugin_<version>_<arch>.deb`\n    *   `docker-compose-plugin_<version>_<arch>.deb`\n5.  Install the `.deb` packages. Update the paths in the following example to where you downloaded the Docker packages.\n    \n    The Docker daemon starts automatically.\n    \n6.  Verify that the Docker Engine installation is successful by running the `hello-world` image:\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why youâ€™re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine-1)\n\nTo upgrade Docker Engine, download the newer package files and repeat the [installation procedure](#install-from-a-package), pointing to the new files.\n\n### [Install using the convenience script](#install-using-the-convenience-script)\n\nDocker provides a convenience script at [https://get.docker.com/](https://get.docker.com/) to install Docker into development environments non-interactively. The convenience script isn't recommended for production environments, but it's useful for creating a provisioning script tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and you can find it in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n*   The script requires `root` or `sudo` privileges to run.\n*   The script attempts to detect your Linux distribution and version and configure your package management system for you.\n*   The script doesn't allow you to customize most installation parameters.\n*   The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n*   By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test upgrades in a test environment before deploying to your production systems.\n*   The script isn't designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, resulting in outdated versions.\n\n> **Tip: preview script steps before running**\n> \n> You can run the script with the `--dry-run` option to learn what steps the script will run when invoked:\n\nThis example downloads the script from [https://get.docker.com/](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\nYou have now successfully installed and started Docker Engine. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users can't run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n> \n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user). You can also install Docker without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](https://docs.docker.com/engine/security/rootless/).\n\n#### [Install pre-releases](#install-pre-releases)\n\nDocker also provides a convenience script at [https://test.docker.com/](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equal to the script at `get.docker.com`, but configures your package manager to use the test channel of the Docker package repository. The test channel includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they're released as stable.\n\nTo install the latest version of Docker on Linux from the test channel, run:\n\n#### [Upgrade Docker after using the convenience script](#upgrade-docker-after-using-the-convenience-script)\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There's no advantage to re-running the convenience script. Re-running it can cause issues if it attempts to re-install repositories which already exist on the host machine.\n\n1.  Uninstall the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n2.  Images, containers, volumes, or custom configuration files on your host aren't automatically removed. To delete all images, containers, and volumes:\n    \n\nYou have to delete any edited configuration files manually.\n\n*   Continue to [Post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/).",
  "title": "Install Docker Engine on Debian | Docker Docs\n",
  "description": "Learn how to install Docker Engine on Debian. These instructions cover the different installation methods, how to uninstall, and next steps.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/join-nodes/",
  "markdown": "# Join nodes to a swarm\n\nWhen you first create a swarm, you place a single Docker Engine into Swarm mode. To take full advantage of Swarm mode you can add nodes to the swarm:\n\n*   Adding worker nodes increases capacity. When you deploy a service to a swarm, the engine schedules tasks on available nodes whether they are worker nodes or manager nodes. When you add workers to your swarm, you increase the scale of the swarm to handle tasks without affecting the manager raft consensus.\n*   Manager nodes increase fault-tolerance. Manager nodes perform the orchestration and cluster management functions for the swarm. Among manager nodes, a single leader node conducts orchestration tasks. If a leader node goes down, the remaining manager nodes elect a new leader and resume orchestration and maintenance of the swarm state. By default, manager nodes also run tasks.\n\nDocker Engine joins the swarm depending on the **join-token** you provide to the `docker swarm join` command. The node only uses the token at join time. If you subsequently rotate the token, it doesn't affect existing swarm nodes. Refer to [Run Docker Engine in swarm mode](https://docs.docker.com/engine/swarm/swarm-mode/#view-the-join-command-or-update-a-swarm-join-token).\n\nTo retrieve the join command including the join token for worker nodes, run the following command on a manager node:\n\nRun the command from the output on the worker to join the swarm:\n\nThe `docker swarm join` command does the following:\n\n*   Switches Docker Engine on the current node into Swarm mode.\n*   Requests a TLS certificate from the manager.\n*   Names the node with the machine hostname.\n*   Joins the current node to the swarm at the manager listen address based upon the swarm token.\n*   Sets the current node to `Active` availability, meaning it can receive tasks from the scheduler.\n*   Extends the `ingress` overlay network to the current node.\n\nWhen you run `docker swarm join` and pass the manager token, Docker Engine switches into Swarm mode the same as for workers. Manager nodes also participate in the raft consensus. The new nodes should be `Reachable`, but the existing manager remains the swarm `Leader`.\n\nDocker recommends three or five manager nodes per cluster to implement high availability. Because Swarm-mode manager nodes share data using Raft, there must be an odd number of managers. The swarm can continue to function after as long as a quorum of more than half of the manager nodes are available.\n\nFor more detail about swarm managers and administering a swarm, see [Administer and maintain a swarm of Docker Engines](https://docs.docker.com/engine/swarm/admin_guide/).\n\nTo retrieve the join command including the join token for manager nodes, run the following command on a manager node:\n\nRun the command from the output on the new manager node to join it to the swarm:\n\n*   `swarm join` [command line reference](https://docs.docker.com/reference/cli/docker/swarm/join/)\n*   [Swarm mode tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/)",
  "title": "Join nodes to a swarm | Docker Docs\n",
  "description": "Add worker and manager nodes to a swarm",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/install/rhel/",
  "markdown": "# Install Docker Engine on RHEL\n\n> **Experimental**\n> \n> Support for Docker Engine on RHEL x86\\_64 and aarch64 is experimental.\n\n> **Docker Desktop for Linux** is also available for RHEL.\n> \n> To get access, join the [Early Access Program](https://www.docker.com/docker-desktop-preview-program/).\n\nTo get started with Docker Engine on RHEL, make sure you [meet the prerequisites](#prerequisites), and then follow the [installation steps](#installation-methods).\n\n### [OS requirements](#os-requirements)\n\nTo install Docker Engine, you need a maintained version of one of the following RHEL versions:\n\n*   RHEL 8\n*   RHEL 9\n\n### [Uninstall old versions](#uninstall-old-versions)\n\nOlder versions of Docker went by `docker` or `docker-engine`. Uninstall any such older versions before attempting to install a new version, along with associated dependencies. Also uninstall `Podman` and the associated dependencies if installed already:\n\n`yum` might report that you have none of these packages installed.\n\nImages, containers, volumes, and networks stored in `/var/lib/docker/` aren't automatically removed when you uninstall Docker.\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n*   You can [set up Docker's repositories](#install-using-the-repository) and install from them, for ease of installation and upgrade tasks. This is the recommended approach.\n    \n*   You can download the RPM package, [install it manually](#install-from-a-package), and manage upgrades completely manually. This is useful in situations such as installing Docker on air-gapped systems with no access to the internet.\n    \n*   In testing and development environments, you can use automated [convenience scripts](#install-using-the-convenience-script) to install Docker.\n    \n\n### [Install using the rpm repository](#install-using-the-repository)\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\n#### [Set up the repository](#set-up-the-repository)\n\nInstall the `yum-utils` package (which provides the `yum-config-manager` utility) and set up the repository.\n\n#### [Install Docker Engine](#install-docker-engine)\n\n1.  Install Docker Engine, containerd, and Docker Compose:\n    \n    * * *\n    \n    To install the latest version, run:\n    \n    If prompted to accept the GPG key, verify that the fingerprint matches `060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35`, and if so, accept it.\n    \n    This command installs Docker, but it doesn't start Docker. It also creates a `docker` group, however, it doesn't add any users to the group by default.\n    \n    To install a specific version, start by listing the available versions in the repository:\n    \n    The list returned depends on which repositories are enabled, and is specific to your version of RHEL (indicated by the `.el9` suffix in this example).\n    \n    Install a specific version by its fully qualified package name, which is the package name (`docker-ce`) plus the version string (2nd column), separated by a hyphen (`-`). For example, `docker-ce-3:27.0.3-1.el9`.\n    \n    Replace `<VERSION_STRING>` with the desired version and then run the following command to install:\n    \n    This command installs Docker, but it doesn't start Docker. It also creates a `docker` group, however, it doesn't add any users to the group by default.\n    \n    * * *\n    \n2.  Start Docker.\n    \n3.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why youâ€™re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine)\n\nTo upgrade Docker Engine, follow the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### [Install from a package](#install-from-a-package)\n\nIf you can't use Docker's `rpm` repository to install Docker Engine, you can download the `.rpm` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [https://download.docker.com/linux/rhel/](https://download.docker.com/linux/rhel/).\n    \n2.  Select your RHEL version in the list.\n    \n3.  Select the applicable architecture (`x86_64`, `aarch64`, or `s390x`), and then go to `stable/Packages/`.\n    \n4.  Download the following `deb` files for the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n    *   `containerd.io_<version>_<arch>.deb`\n    *   `docker-ce_<version>_<arch>.deb`\n    *   `docker-ce-cli_<version>_<arch>.deb`\n    *   `docker-buildx-plugin_<version>_<arch>.deb`\n    *   `docker-compose-plugin_<version>_<arch>.deb`\n5.  Install Docker Engine, changing the following path to the path where you downloaded the packages.\n    \n    Docker is installed but not started. The `docker` group is created, but no users are added to the group.\n    \n6.  Start Docker.\n    \n7.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why youâ€™re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine-1)\n\nTo upgrade Docker Engine, download the newer package files and repeat the [installation procedure](#install-from-a-package), using `yum -y upgrade` instead of `yum -y install`, and point to the new files.\n\n### [Install using the convenience script](#install-using-the-convenience-script)\n\nDocker provides a convenience script at [https://get.docker.com/](https://get.docker.com/) to install Docker into development environments non-interactively. The convenience script isn't recommended for production environments, but it's useful for creating a provisioning script tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and you can find it in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n*   The script requires `root` or `sudo` privileges to run.\n*   The script attempts to detect your Linux distribution and version and configure your package management system for you.\n*   The script doesn't allow you to customize most installation parameters.\n*   The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n*   By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test upgrades in a test environment before deploying to your production systems.\n*   The script isn't designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, resulting in outdated versions.\n\n> **Tip: preview script steps before running**\n> \n> You can run the script with the `--dry-run` option to learn what steps the script will run when invoked:\n\nThis example downloads the script from [https://get.docker.com/](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\nYou have now successfully installed and started Docker Engine. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users can't run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n> \n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user). You can also install Docker without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](https://docs.docker.com/engine/security/rootless/).\n\n#### [Install pre-releases](#install-pre-releases)\n\nDocker also provides a convenience script at [https://test.docker.com/](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equal to the script at `get.docker.com`, but configures your package manager to use the test channel of the Docker package repository. The test channel includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they're released as stable.\n\nTo install the latest version of Docker on Linux from the test channel, run:\n\n#### [Upgrade Docker after using the convenience script](#upgrade-docker-after-using-the-convenience-script)\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There's no advantage to re-running the convenience script. Re-running it can cause issues if it attempts to re-install repositories which already exist on the host machine.\n\n1.  Uninstall the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n2.  Images, containers, volumes, or custom configuration files on your host aren't automatically removed. To delete all images, containers, and volumes:\n    \n\nYou have to delete any edited configuration files manually.\n\n*   Continue to [Post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/).",
  "title": "Install Docker Engine on RHEL | Docker Docs\n",
  "description": "Learn how to install Docker Engine on RHEL. These instructions cover the different installation methods, how to uninstall, and next steps.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/install/fedora/",
  "markdown": "# Install Docker Engine on Fedora\n\nTo get started with Docker Engine on Fedora, make sure you [meet the prerequisites](#prerequisites), and then follow the [installation steps](#installation-methods).\n\n### [OS requirements](#os-requirements)\n\nTo install Docker Engine, you need a maintained version of one of the following Fedora versions:\n\n*   Fedora 39\n*   Fedora 40\n\n### [Uninstall old versions](#uninstall-old-versions)\n\nOlder versions of Docker went by `docker` or `docker-engine`. Uninstall any such older versions before attempting to install a new version, along with associated dependencies.\n\n`dnf` might report that you have none of these packages installed.\n\nImages, containers, volumes, and networks stored in `/var/lib/docker/` aren't automatically removed when you uninstall Docker.\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n*   You can [set up Docker's repositories](#install-using-the-repository) and install from them, for ease of installation and upgrade tasks. This is the recommended approach.\n    \n*   You can download the RPM package, [install it manually](#install-from-a-package), and manage upgrades completely manually. This is useful in situations such as installing Docker on air-gapped systems with no access to the internet.\n    \n*   In testing and development environments, you can use automated [convenience scripts](#install-using-the-convenience-script) to install Docker.\n    \n\n### [Install using the rpm repository](#install-using-the-repository)\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\n#### [Set up the repository](#set-up-the-repository)\n\nInstall the `dnf-plugins-core` package (which provides the commands to manage your DNF repositories) and set up the repository.\n\n#### [Install Docker Engine](#install-docker-engine)\n\n1.  Install Docker Engine, containerd, and Docker Compose:\n    \n    * * *\n    \n    To install the latest version, run:\n    \n    If prompted to accept the GPG key, verify that the fingerprint matches `060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35`, and if so, accept it.\n    \n    This command installs Docker, but it doesn't start Docker. It also creates a `docker` group, however, it doesn't add any users to the group by default.\n    \n    To install a specific version, start by listing the available versions in the repository:\n    \n    The list returned depends on which repositories are enabled, and is specific to your version of Fedora (indicated by the `.fc40` suffix in this example).\n    \n    Install a specific version by its fully qualified package name, which is the package name (`docker-ce`) plus the version string (2nd column), separated by a hyphen (`-`). For example, `docker-ce-3:27.0.3-1.fc40`.\n    \n    Replace `<VERSION_STRING>` with the desired version and then run the following command to install:\n    \n    This command installs Docker, but it doesn't start Docker. It also creates a `docker` group, however, it doesn't add any users to the group by default.\n    \n    * * *\n    \n2.  Start Docker.\n    \n3.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why youâ€™re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine)\n\nTo upgrade Docker Engine, follow the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### [Install from a package](#install-from-a-package)\n\nIf you can't use Docker's `rpm` repository to install Docker Engine, you can download the `.rpm` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [https://download.docker.com/linux/fedora/](https://download.docker.com/linux/fedora/) and choose your version of Fedora. Then browse to `x86_64/stable/Packages/` and download the `.rpm` file for the Docker version you want to install.\n    \n2.  Install Docker Engine, changing the following path to the path where you downloaded the Docker package.\n    \n    Docker is installed but not started. The `docker` group is created, but no users are added to the group.\n    \n3.  Start Docker.\n    \n4.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why youâ€™re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine-1)\n\nTo upgrade Docker Engine, download the newer package files and repeat the [installation procedure](#install-from-a-package), using `dnf -y upgrade` instead of `dnf -y install`, and point to the new files.\n\n### [Install using the convenience script](#install-using-the-convenience-script)\n\nDocker provides a convenience script at [https://get.docker.com/](https://get.docker.com/) to install Docker into development environments non-interactively. The convenience script isn't recommended for production environments, but it's useful for creating a provisioning script tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and you can find it in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n*   The script requires `root` or `sudo` privileges to run.\n*   The script attempts to detect your Linux distribution and version and configure your package management system for you.\n*   The script doesn't allow you to customize most installation parameters.\n*   The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n*   By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test upgrades in a test environment before deploying to your production systems.\n*   The script isn't designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, resulting in outdated versions.\n\n> **Tip: preview script steps before running**\n> \n> You can run the script with the `--dry-run` option to learn what steps the script will run when invoked:\n\nThis example downloads the script from [https://get.docker.com/](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\nYou have now successfully installed and started Docker Engine. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users can't run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n> \n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user). You can also install Docker without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](https://docs.docker.com/engine/security/rootless/).\n\n#### [Install pre-releases](#install-pre-releases)\n\nDocker also provides a convenience script at [https://test.docker.com/](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equal to the script at `get.docker.com`, but configures your package manager to use the test channel of the Docker package repository. The test channel includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they're released as stable.\n\nTo install the latest version of Docker on Linux from the test channel, run:\n\n#### [Upgrade Docker after using the convenience script](#upgrade-docker-after-using-the-convenience-script)\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There's no advantage to re-running the convenience script. Re-running it can cause issues if it attempts to re-install repositories which already exist on the host machine.\n\n1.  Uninstall the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n2.  Images, containers, volumes, or custom configuration files on your host aren't automatically removed. To delete all images, containers, and volumes:\n    \n\nYou have to delete any edited configuration files manually.\n\n*   Continue to [Post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/).",
  "title": "Install Docker Engine on Fedora | Docker Docs\n",
  "description": "Learn how to install Docker Engine on Fedora. These instructions cover the different installation methods, how to uninstall, and next steps.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/manage-nodes/",
  "markdown": "# Manage nodes in a swarm\n\nAs part of the swarm management lifecycle, you may need to:\n\n*   [List nodes in the swarm](#list-nodes)\n*   [Inspect an individual node](#inspect-an-individual-node)\n*   [Update a node](#update-a-node)\n*   [Leave the swarm](#leave-the-swarm)\n\nTo view a list of nodes in the swarm run `docker node ls` from a manager node:\n\nThe `AVAILABILITY` column shows whether or not the scheduler can assign tasks to the node:\n\n*   `Active` means that the scheduler can assign tasks to the node.\n*   `Pause` means the scheduler doesn't assign new tasks to the node, but existing tasks remain running.\n*   `Drain` means the scheduler doesn't assign new tasks to the node. The scheduler shuts down any existing tasks and schedules them on an available node.\n\nThe `MANAGER STATUS` column shows node participation in the Raft consensus:\n\n*   No value indicates a worker node that does not participate in swarm management.\n*   `Leader` means the node is the primary manager node that makes all swarm management and orchestration decisions for the swarm.\n*   `Reachable` means the node is a manager node participating in the Raft consensus quorum. If the leader node becomes unavailable, the node is eligible for election as the new leader.\n*   `Unavailable` means the node is a manager that can't communicate with other managers. If a manager node becomes unavailable, you should either join a new manager node to the swarm or promote a worker node to be a manager.\n\nFor more information on swarm administration refer to the [Swarm administration guide](https://docs.docker.com/engine/swarm/admin_guide/).\n\nYou can run `docker node inspect <NODE-ID>` on a manager node to view the details for an individual node. The output defaults to JSON format, but you can pass the `--pretty` flag to print the results in human-readable format. For example:\n\nYou can modify node attributes to:\n\n*   [Change node availability](#change-node-availability)\n*   [Add or remove label metadata](#add-or-remove-label-metadata)\n*   [Change a node role](#promote-or-demote-a-node)\n\n### [Change node availability](#change-node-availability)\n\nChanging node availability lets you:\n\n*   Drain a manager node so that it only performs swarm management tasks and is unavailable for task assignment.\n*   Drain a node so you can take it down for maintenance.\n*   Pause a node so it can't receive new tasks.\n*   Restore unavailable or paused nodes availability status.\n\nFor example, to change a manager node to `Drain` availability:\n\nSee [list nodes](#list-nodes) for descriptions of the different availability options.\n\n### [Add or remove label metadata](#add-or-remove-label-metadata)\n\nNode labels provide a flexible method of node organization. You can also use node labels in service constraints. Apply constraints when you create a service to limit the nodes where the scheduler assigns tasks for the service.\n\nRun `docker node update --label-add` on a manager node to add label metadata to a node. The `--label-add` flag supports either a `<key>` or a `<key>=<value>` pair.\n\nPass the `--label-add` flag once for each node label you want to add:\n\nThe labels you set for nodes using docker node update apply only to the node entity within the swarm. Do not confuse them with the docker daemon labels for [dockerd](https://docs.docker.com/config/labels-custom-metadata/).\n\nTherefore, node labels can be used to limit critical tasks to nodes that meet certain requirements. For example, schedule only on machines where special workloads should be run, such as machines that meet [PCI-SS compliance](https://www.pcisecuritystandards.org/).\n\nA compromised worker could not compromise these special workloads because it cannot change node labels.\n\nEngine labels, however, are still useful because some features that do not affect secure orchestration of containers might be better off set in a decentralized manner. For instance, an engine could have a label to indicate that it has a certain type of disk device, which may not be relevant to security directly. These labels are more easily \"trusted\" by the swarm orchestrator.\n\nRefer to the `docker service create` [CLI reference](https://docs.docker.com/reference/cli/docker/service/create/) for more information about service constraints.\n\n### [Promote or demote a node](#promote-or-demote-a-node)\n\nYou can promote a worker node to the manager role. This is useful when a manager node becomes unavailable or if you want to take a manager offline for maintenance. Similarly, you can demote a manager node to the worker role.\n\n> **Note**\n> \n> Regardless of your reason to promote or demote a node, you must always maintain a quorum of manager nodes in the swarm. For more information refer to the [Swarm administration guide](https://docs.docker.com/engine/swarm/admin_guide/).\n\nTo promote a node or set of nodes, run `docker node promote` from a manager node:\n\nTo demote a node or set of nodes, run `docker node demote` from a manager node:\n\n`docker node promote` and `docker node demote` are convenience commands for `docker node update --role manager` and `docker node update --role worker` respectively.\n\nIf your swarm service relies on one or more [plugins](https://docs.docker.com/engine/extend/plugin_api/), these plugins need to be available on every node where the service could potentially be deployed. You can manually install the plugin on each node or script the installation. You can also deploy the plugin in a similar way as a global service using the Docker API, by specifying a `PluginSpec` instead of a `ContainerSpec`.\n\n> **Note**\n> \n> There is currently no way to deploy a plugin to a swarm using the Docker CLI or Docker Compose. In addition, it is not possible to install plugins from a private repository.\n\nThe [`PluginSpec`](https://docs.docker.com/engine/extend/plugin_api/#json-specification) is defined by the plugin developer. To add the plugin to all Docker nodes, use the [`service/create`](https://docs.docker.com/engine/api/v1.31/#operation/ServiceCreate) API, passing the `PluginSpec` JSON defined in the `TaskTemplate`.\n\nRun the `docker swarm leave` command on a node to remove it from the swarm.\n\nFor example to leave the swarm on a worker node:\n\nWhen a node leaves the swarm, Docker Engine stops running in Swarm mode. The orchestrator no longer schedules tasks to the node.\n\nIf the node is a manager node, you receive a warning about maintaining the quorum. To override the warning, pass the `--force` flag. If the last manager node leaves the swarm, the swarm becomes unavailable requiring you to take disaster recovery measures.\n\nFor information about maintaining a quorum and disaster recovery, refer to the [Swarm administration guide](https://docs.docker.com/engine/swarm/admin_guide/).\n\nAfter a node leaves the swarm, you can run `docker node rm` on a manager node to remove the node from the node list.\n\nFor instance:\n\n*   [Swarm administration guide](https://docs.docker.com/engine/swarm/admin_guide/)\n*   [Docker Engine command line reference](https://docs.docker.com/reference/cli/docker/)\n*   [Swarm mode tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/)",
  "title": "Manage nodes in a swarm | Docker Docs\n",
  "description": "Manage existing nodes in a swarm",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/security/protect-access/",
  "markdown": "# Protect the Docker daemon socket\n\nBy default, Docker runs through a non-networked UNIX socket. It can also optionally communicate using SSH or a TLS (HTTPS) socket.\n\n> **Note**\n> \n> The given `USERNAME` must have permissions to access the docker socket on the remote machine. Refer to [manage Docker as a non-root user](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user) to learn how to give a non-root user access to the docker socket.\n\nThe following example creates a [`docker context`](https://docs.docker.com/engine/context/working-with-contexts/) to connect with a remote `dockerd` daemon on `host1.example.com` using SSH, and as the `docker-user` user on the remote machine:\n\nAfter creating the context, use `docker context use` to switch the `docker` CLI to use it, and to connect to the remote engine:\n\nUse the `default` context to switch back to the default (local) daemon:\n\nAlternatively, use the `DOCKER_HOST` environment variable to temporarily switch the `docker` CLI to connect to the remote host using SSH. This does not require creating a context, and can be useful to create an ad-hoc connection with a different engine:\n\n### [SSH Tips](#ssh-tips)\n\nFor the best user experience with SSH, configure `~/.ssh/config` as follows to allow reusing a SSH connection for multiple invocations of the `docker` CLI:\n\nIf you need Docker to be reachable through HTTP rather than SSH in a safe manner, you can enable TLS (HTTPS) by specifying the `tlsverify` flag and pointing Docker's `tlscacert` flag to a trusted CA certificate.\n\nIn the daemon mode, it only allows connections from clients authenticated by a certificate signed by that CA. In the client mode, it only connects to servers with a certificate signed by that CA.\n\n> **Important**\n> \n> Using TLS and managing a CA is an advanced topic. Familiarize yourself with OpenSSL, x509, and TLS before using it in production.\n\n### [Create a CA, server and client keys with OpenSSL](#create-a-ca-server-and-client-keys-with-openssl)\n\n> **Note**\n> \n> Replace all instances of `$HOST` in the following example with the DNS name of your Docker daemon's host.\n\nFirst, on the Docker daemon's host machine, generate CA private and public keys:\n\nNow that you have a CA, you can create a server key and certificate signing request (CSR). Make sure that \"Common Name\" matches the hostname you use to connect to Docker:\n\n> **Note**\n> \n> Replace all instances of `$HOST` in the following example with the DNS name of your Docker daemon's host.\n\nNext, we're going to sign the public key with our CA:\n\nSince TLS connections can be made through IP address as well as DNS name, the IP addresses need to be specified when creating the certificate. For example, to allow connections using `10.10.10.20` and `127.0.0.1`:\n\nSet the Docker daemon key's extended usage attributes to be used only for server authentication:\n\nNow, generate the signed certificate:\n\n[Authorization plugins](https://docs.docker.com/engine/extend/plugins_authorization/) offer more fine-grained control to supplement authentication from mutual TLS. In addition to other information described in the above document, authorization plugins running on a Docker daemon receive the certificate information for connecting Docker clients.\n\nFor client authentication, create a client key and certificate signing request:\n\n> **Note**\n> \n> For simplicity of the next couple of steps, you may perform this step on the Docker daemon's host machine as well.\n\nTo make the key suitable for client authentication, create a new extensions config file:\n\nNow, generate the signed certificate:\n\nAfter generating `cert.pem` and `server-cert.pem` you can safely remove the two certificate signing requests and extensions config files:\n\nWith a default `umask` of 022, your secret keys are _world-readable_ and writable for you and your group.\n\nTo protect your keys from accidental damage, remove their write permissions. To make them only readable by you, change file modes as follows:\n\nCertificates can be world-readable, but you might want to remove write access to prevent accidental damage:\n\nNow you can make the Docker daemon only accept connections from clients providing a certificate trusted by your CA:\n\nTo connect to Docker and validate its certificate, provide your client keys, certificates and trusted CA:\n\n> **Tip**\n> \n> This step should be run on your Docker client machine. As such, you need to copy your CA certificate, your server certificate, and your client certificate to that machine.\n\n> **Note**\n> \n> Replace all instances of `$HOST` in the following example with the DNS name of your Docker daemon's host.\n\n> **Note**\n> \n> Docker over TLS should run on TCP port 2376.\n\n> **Warning**\n> \n> As shown in the example above, you don't need to run the `docker` client with `sudo` or the `docker` group when you use certificate authentication. That means anyone with the keys can give any instructions to your Docker daemon, giving them root access to the machine hosting the daemon. Guard these keys as you would a root password!\n\n### [Secure by default](#secure-by-default)\n\nIf you want to secure your Docker client connections by default, you can move the files to the `.docker` directory in your home directory --- and set the `DOCKER_HOST` and `DOCKER_TLS_VERIFY` variables as well (instead of passing `-H=tcp://$HOST:2376` and `--tlsverify` on every call).\n\nDocker now connects securely by default:\n\n```\n$ docker ps\n```\n\n### [Other modes](#other-modes)\n\nIf you don't want to have complete two-way authentication, you can run Docker in various other modes by mixing the flags.\n\n#### [Daemon modes](#daemon-modes)\n\n*   `tlsverify`, `tlscacert`, `tlscert`, `tlskey` set: Authenticate clients\n*   `tls`, `tlscert`, `tlskey`: Do not authenticate clients\n\n#### [Client modes](#client-modes)\n\n*   `tls`: Authenticate server based on public/default CA pool\n*   `tlsverify`, `tlscacert`: Authenticate server based on given CA\n*   `tls`, `tlscert`, `tlskey`: Authenticate with client certificate, do not authenticate server based on given CA\n*   `tlsverify`, `tlscacert`, `tlscert`, `tlskey`: Authenticate with client certificate and authenticate server based on given CA\n\nIf found, the client sends its client certificate, so you just need to drop your keys into `~/.docker/{ca,cert,key}.pem`. Alternatively, if you want to store your keys in another location, you can specify that location using the environment variable `DOCKER_CERT_PATH`.\n\n#### [Connecting to the secure Docker port using `curl`](#connecting-to-the-secure-docker-port-using-curl)\n\nTo use `curl` to make test API requests, you need to use three extra command line flags:\n\n*   [Using certificates for repository client verification](https://docs.docker.com/engine/security/certificates/)\n*   [Use trusted images](https://docs.docker.com/engine/security/trust/)",
  "title": "Protect the Docker daemon socket | Docker Docs\n",
  "description": "How to setup and run Docker with SSH or HTTPS",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/services/",
  "markdown": "# Deploy services to a swarm\n\nSwarm services use a declarative model, which means that you define the desired state of the service, and rely upon Docker to maintain this state. The state includes information such as (but not limited to):\n\n*   The image name and tag the service containers should run\n*   How many containers participate in the service\n*   Whether any ports are exposed to clients outside the swarm\n*   Whether the service should start automatically when Docker starts\n*   The specific behavior that happens when the service is restarted (such as whether a rolling restart is used)\n*   Characteristics of the nodes where the service can run (such as resource constraints and placement preferences)\n\nFor an overview of Swarm mode, see [Swarm mode key concepts](https://docs.docker.com/engine/swarm/key-concepts/). For an overview of how services work, see [How services work](https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/).\n\nTo create a single-replica service with no extra configuration, you only need to supply the image name. This command starts an Nginx service with a randomly-generated name and no published ports. This is a naive example, since you can't interact with the Nginx service.\n\nThe service is scheduled on an available node. To confirm that the service was created and started successfully, use the `docker service ls` command:\n\nCreated services do not always run right away. A service can be in a pending state if its image is unavailable, if no node meets the requirements you configure for the service, or for other reasons. See [Pending services](https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/#pending-services) for more information.\n\nTo provide a name for your service, use the `--name` flag:\n\nJust like with standalone containers, you can specify a command that the service's containers should run, by adding it after the image name. This example starts a service called `helloworld` which uses an `alpine` image and runs the command `ping docker.com`:\n\nYou can also specify an image tag for the service to use. This example modifies the previous one to use the `alpine:3.6` tag:\n\nFor more details about image tag resolution, see [Specify the image version the service should use](#specify-the-image-version-a-service-should-use).\n\n### [gMSA for Swarm](#gmsa-for-swarm)\n\n> **Note**\n> \n> This example only works for a Windows container.\n\nSwarm now allows using a Docker config as a gMSA credential spec - a requirement for Active Directory-authenticated applications. This reduces the burden of distributing credential specs to the nodes they're used on.\n\nThe following example assumes a gMSA and its credential spec (called credspec.json) already exists, and that the nodes being deployed to are correctly configured for the gMSA.\n\nTo use a config as a credential spec, first create the Docker config containing the credential spec:\n\nNow, you should have a Docker config named credspec, and you can create a service using this credential spec. To do so, use the --credential-spec flag with the config name, like this:\n\nYour service uses the gMSA credential spec when it starts, but unlike a typical Docker config (used by passing the --config flag), the credential spec is not mounted into the container.\n\n### [Create a service using an image on a private registry](#create-a-service-using-an-image-on-a-private-registry)\n\nIf your image is available on a private registry which requires login, use the `--with-registry-auth` flag with `docker service create`, after logging in. If your image is stored on `registry.example.com`, which is a private registry, use a command like the following:\n\nThis passes the login token from your local client to the swarm nodes where the service is deployed, using the encrypted WAL logs. With this information, the nodes are able to log into the registry and pull the image.\n\n### [Provide credential specs for managed service accounts](#provide-credential-specs-for-managed-service-accounts)\n\nIn Enterprise Edition 3.0, security is improved through the centralized distribution and management of Group Managed Service Account(gMSA) credentials using Docker config functionality. Swarm now allows using a Docker config as a gMSA credential spec, which reduces the burden of distributing credential specs to the nodes on which they are used.\n\n> **Note**\n> \n> This option is only applicable to services using Windows containers.\n\nCredential spec files are applied at runtime, eliminating the need for host-based credential spec files or registry entries - no gMSA credentials are written to disk on worker nodes. You can make credential specs available to Docker Engine running swarm kit worker nodes before a container starts. When deploying a service using a gMSA-based config, the credential spec is passed directly to the runtime of containers in that service.\n\nThe `--credential-spec` must be in one of the following formats:\n\n*   `file://<filename>`: The referenced file must be present in the `CredentialSpecs` subdirectory in the docker data directory, which defaults to `C:\\ProgramData\\Docker\\` on Windows. For example, specifying `file://spec.json` loads `C:\\ProgramData\\Docker\\CredentialSpecs\\spec.json`.\n*   `registry://<value-name>`: The credential spec is read from the Windows registry on the daemonâ€™s host.\n*   `config://<config-name>`: The config name is automatically converted to the config ID in the CLI. The credential spec contained in the specified `config` is used.\n\nThe following simple example retrieves the gMSA name and JSON contents from your Active Directory (AD) instance:\n\nMake sure that the nodes to which you are deploying are correctly configured for the gMSA.\n\nTo use a config as a credential spec, create a Docker config in a credential spec file named `credpspec.json`. You can specify any name for the name of the `config`.\n\nNow you can create a service using this credential spec. Specify the `--credential-spec` flag with the config name:\n\nYour service uses the gMSA credential spec when it starts, but unlike a typical Docker config (used by passing the --config flag), the credential spec is not mounted into the container.\n\nYou can change almost everything about an existing service using the `docker service update` command. When you update a service, Docker stops its containers and restarts them with the new configuration.\n\nSince Nginx is a web service, it works much better if you publish port 80 to clients outside the swarm. You can specify this when you create the service, using the `-p` or `--publish` flag. When updating an existing service, the flag is `--publish-add`. There is also a `--publish-rm` flag to remove a port that was previously published.\n\nAssuming that the `my_web` service from the previous section still exists, use the following command to update it to publish port 80.\n\nTo verify that it worked, use `docker service ls`:\n\nFor more information on how publishing ports works, see [publish ports](#publish-ports).\n\nYou can update almost every configuration detail about an existing service, including the image name and tag it runs. See [Update a service's image after creation](#update-a-services-image-after-creation).\n\nTo remove a service, use the `docker service remove` command. You can remove a service by its ID or name, as shown in the output of the `docker service ls` command. The following command removes the `my_web` service.\n\nThe following sections provide details about service configuration. This topic does not cover every flag or scenario. In almost every instance where you can define a configuration at service creation, you can also update an existing service's configuration in a similar way.\n\nSee the command-line references for [`docker service create`](https://docs.docker.com/reference/cli/docker/service/create/) and [`docker service update`](https://docs.docker.com/reference/cli/docker/service/update/), or run one of those commands with the `--help` flag.\n\n### [Configure the runtime environment](#configure-the-runtime-environment)\n\nYou can configure the following options for the runtime environment in the container:\n\n*   Environment variables using the `--env` flag\n*   The working directory inside the container using the `--workdir` flag\n*   The username or UID using the `--user` flag\n\nThe following service's containers have an environment variable `$MYVAR` set to `myvalue`, run from the `/tmp/` directory, and run as the `my_user` user.\n\n### [Update the command an existing service runs](#update-the-command-an-existing-service-runs)\n\nTo update the command an existing service runs, you can use the `--args` flag. The following example updates an existing service called `helloworld` so that it runs the command `ping docker.com` instead of whatever command it was running before:\n\n### [Specify the image version a service should use](#specify-the-image-version-a-service-should-use)\n\nWhen you create a service without specifying any details about the version of the image to use, the service uses the version tagged with the `latest` tag. You can force the service to use a specific version of the image in a few different ways, depending on your desired outcome.\n\nAn image version can be expressed in several different ways:\n\n*   If you specify a tag, the manager (or the Docker client, if you use [content trust](https://docs.docker.com/engine/security/trust/)) resolves that tag to a digest. When the request to create a container task is received on a worker node, the worker node only sees the digest, not the tag.\n    \n    Some tags represent discrete releases, such as `ubuntu:16.04`. Tags like this almost always resolve to a stable digest over time. It is recommended that you use this kind of tag when possible.\n    \n    Other types of tags, such as `latest` or `nightly`, may resolve to a new digest often, depending on how often an image's author updates the tag. It is not recommended to run services using a tag which is updated frequently, to prevent different service replica tasks from using different image versions.\n    \n*   If you don't specify a version at all, by convention the image's `latest` tag is resolved to a digest. Workers use the image at this digest when creating the service task.\n    \n    Thus, the following two commands are equivalent:\n    \n*   If you specify a digest directly, that exact version of the image is always used when creating service tasks.\n    \n\nWhen you create a service, the image's tag is resolved to the specific digest the tag points to **at the time of service creation**. Worker nodes for that service use that specific digest forever unless the service is explicitly updated. This feature is particularly important if you do use often-changing tags such as `latest`, because it ensures that all service tasks use the same version of the image.\n\n> **Note**\\>\n> \n> If [content trust](https://docs.docker.com/engine/security/trust/) is enabled, the client actually resolves the image's tag to a digest before contacting the swarm manager, to verify that the image is signed. Thus, if you use content trust, the swarm manager receives the request pre-resolved. In this case, if the client cannot resolve the image to a digest, the request fails.\n\nIf the manager can't resolve the tag to a digest, each worker node is responsible for resolving the tag to a digest, and different nodes may use different versions of the image. If this happens, a warning like the following is logged, substituting the placeholders for real information.\n\nTo see an image's current digest, issue the command `docker inspect <IMAGE>:<TAG>` and look for the `RepoDigests` line. The following is the current digest for `ubuntu:latest` at the time this content was written. The output is truncated for clarity.\n\nAfter you create a service, its image is never updated unless you explicitly run `docker service update` with the `--image` flag as described below. Other update operations such as scaling the service, adding or removing networks or volumes, renaming the service, or any other type of update operation do not update the service's image.\n\n### [Update a service's image after creation](#update-a-services-image-after-creation)\n\nEach tag represents a digest, similar to a Git hash. Some tags, such as `latest`, are updated often to point to a new digest. Others, such as `ubuntu:16.04`, represent a released software version and are not expected to update to point to a new digest often if at all. When you create a service, it is constrained to create tasks using a specific digest of an image until you update the service using `service update` with the `--image` flag.\n\nWhen you run `service update` with the `--image` flag, the swarm manager queries Docker Hub or your private Docker registry for the digest the tag currently points to and updates the service tasks to use that digest.\n\n> **Note**\n> \n> If you use [content trust](https://docs.docker.com/engine/security/trust/), the Docker client resolves image and the swarm manager receives the image and digest, rather than a tag.\n\nUsually, the manager can resolve the tag to a new digest and the service updates, redeploying each task to use the new image. If the manager can't resolve the tag or some other problem occurs, the next two sections outline what to expect.\n\n#### [If the manager resolves the tag](#if-the-manager-resolves-the-tag)\n\nIf the swarm manager can resolve the image tag to a digest, it instructs the worker nodes to redeploy the tasks and use the image at that digest.\n\n*   If a worker has cached the image at that digest, it uses it.\n    \n*   If not, it attempts to pull the image from Docker Hub or the private registry.\n    \n    *   If it succeeds, the task is deployed using the new image.\n        \n    *   If the worker fails to pull the image, the service fails to deploy on that worker node. Docker tries again to deploy the task, possibly on a different worker node.\n        \n\n#### [If the manager cannot resolve the tag](#if-the-manager-cannot-resolve-the-tag)\n\nIf the swarm manager cannot resolve the image to a digest, all is not lost:\n\n*   The manager instructs the worker nodes to redeploy the tasks using the image at that tag.\n    \n*   If the worker has a locally cached image that resolves to that tag, it uses that image.\n    \n*   If the worker does not have a locally cached image that resolves to the tag, the worker tries to connect to Docker Hub or the private registry to pull the image at that tag.\n    \n    *   If this succeeds, the worker uses that image.\n        \n    *   If this fails, the task fails to deploy and the manager tries again to deploy the task, possibly on a different worker node.\n        \n\n### [Publish ports](#publish-ports)\n\nWhen you create a swarm service, you can publish that service's ports to hosts outside the swarm in two ways:\n\n*   [You can rely on the routing mesh](#publish-a-services-ports-using-the-routing-mesh). When you publish a service port, the swarm makes the service accessible at the target port on every node, regardless of whether there is a task for the service running on that node or not. This is less complex and is the right choice for many types of services.\n    \n*   [You can publish a service task's port directly on the swarm node](#publish-a-services-ports-directly-on-the-swarm-node) where that service is running. This bypasses the routing mesh and provides the maximum flexibility, including the ability for you to develop your own routing framework. However, you are responsible for keeping track of where each task is running and routing requests to the tasks, and load-balancing across the nodes.\n    \n\nKeep reading for more information and use cases for each of these methods.\n\n#### [Publish a service's ports using the routing mesh](#publish-a-services-ports-using-the-routing-mesh)\n\nTo publish a service's ports externally to the swarm, use the `--publish <PUBLISHED-PORT>:<SERVICE-PORT>` flag. The swarm makes the service accessible at the published port on every swarm node. If an external host connects to that port on any swarm node, the routing mesh routes it to a task. The external host does not need to know the IP addresses or internally-used ports of the service tasks to interact with the service. When a user or process connects to a service, any worker node running a service task may respond. For more details about swarm service networking, see [Manage swarm service networks](https://docs.docker.com/engine/swarm/networking/).\n\n##### [Example: Run a three-task Nginx service on 10-node swarm](#example-run-a-three-task-nginx-service-on-10-node-swarm)\n\nImagine that you have a 10-node swarm, and you deploy an Nginx service running three tasks on a 10-node swarm:\n\nThree tasks run on up to three nodes. You don't need to know which nodes are running the tasks; connecting to port 8080 on any of the 10 nodes connects you to one of the three `nginx` tasks. You can test this using `curl`. The following example assumes that `localhost` is one of the swarm nodes. If this is not the case, or `localhost` does not resolve to an IP address on your host, substitute the host's IP address or resolvable host name.\n\nThe HTML output is truncated:\n\nSubsequent connections may be routed to the same swarm node or a different one.\n\n#### [Publish a service's ports directly on the swarm node](#publish-a-services-ports-directly-on-the-swarm-node)\n\nUsing the routing mesh may not be the right choice for your application if you need to make routing decisions based on application state or you need total control of the process for routing requests to your service's tasks. To publish a service's port directly on the node where it is running, use the `mode=host` option to the `--publish` flag.\n\n> **Note**\n> \n> If you publish a service's ports directly on the swarm node using `mode=host` and also set `published=<PORT>` this creates an implicit limitation that you can only run one task for that service on a given swarm node. You can work around this by specifying `published` without a port definition, which causes Docker to assign a random port for each task.\n> \n> In addition, if you use `mode=host` and you do not use the `--mode=global` flag on `docker service create`, it is difficult to know which nodes are running the service to route work to them.\n\n##### [Example: Run an `nginx` web server service on every swarm node](#example-run-an-nginx-web-server-service-on-every-swarm-node)\n\n[nginx](https://hub.docker.com/_/nginx/) is an open source reverse proxy, load balancer, HTTP cache, and a web server. If you run nginx as a service using the routing mesh, connecting to the nginx port on any swarm node shows you the web page for (effectively) a random swarm node running the service.\n\nThe following example runs nginx as a service on each node in your swarm and exposes nginx port locally on each swarm node.\n\nYou can reach the nginx server on port 8080 of every swarm node. If you add a node to the swarm, a nginx task is started on it. You cannot start another service or container on any swarm node which binds to port 8080.\n\n> **Note**\n> \n> This is a purely illustrative example. Creating an application-layer routing framework for a multi-tiered service is complex and out of scope for this topic.\n\n### [Connect the service to an overlay network](#connect-the-service-to-an-overlay-network)\n\nYou can use overlay networks to connect one or more services within the swarm.\n\nFirst, create overlay network on a manager node using the `docker network create` command with the `--driver overlay` flag.\n\nAfter you create an overlay network in swarm mode, all manager nodes have access to the network.\n\nYou can create a new service and pass the `--network` flag to attach the service to the overlay network:\n\nThe swarm extends `my-network` to each node running the service.\n\nYou can also connect an existing service to an overlay network using the `--network-add` flag.\n\nTo disconnect a running service from a network, use the `--network-rm` flag.\n\nFor more information on overlay networking and service discovery, refer to [Attach services to an overlay network](https://docs.docker.com/engine/swarm/networking/) and [Docker swarm mode overlay network security model](https://docs.docker.com/network/drivers/overlay/).\n\n### [Grant a service access to secrets](#grant-a-service-access-to-secrets)\n\nTo create a service with access to Docker-managed secrets, use the `--secret` flag. For more information, see [Manage sensitive strings (secrets) for Docker services](https://docs.docker.com/engine/swarm/secrets/)\n\n### [Customize a service's isolation mode](#customize-a-services-isolation-mode)\n\n> **Important**\n> \n> This setting applies to Windows hosts only and is ignored for Linux hosts.\n\nDocker allows you to specify a swarm service's isolation mode. The isolation mode can be one of the following:\n\n*   `default`: Use the default isolation mode configured for the Docker host, as configured by the `-exec-opt` flag or `exec-opts` array in `daemon.json`. If the daemon does not specify an isolation technology, `process` is the default for Windows Server, and `hyperv` is the default (and only) choice for Windows 10.\n    \n*   `process`: Run the service tasks as a separate process on the host.\n    \n    > **Note**\n    > \n    > `process` isolation mode is only supported on Windows Server. Windows 10 only supports `hyperv` isolation mode.\n    \n*   `hyperv`: Run the service tasks as isolated `hyperv` tasks. This increases overhead but provides more isolation.\n    \n\nYou can specify the isolation mode when creating or updating a new service using the `--isolation` flag.\n\n### [Control service placement](#control-service-placement)\n\nSwarm services provide a few different ways for you to control scale and placement of services on different nodes.\n\n*   You can specify whether the service needs to run a specific number of replicas or should run globally on every worker node. See [Replicated or global services](#replicated-or-global-services).\n    \n*   You can configure the service's [CPU or memory requirements](#reserve-memory-or-cpus-for-a-service), and the service only runs on nodes which can meet those requirements.\n    \n*   [Placement constraints](#placement-constraints) let you configure the service to run only on nodes with specific (arbitrary) metadata set, and cause the deployment to fail if appropriate nodes do not exist. For instance, you can specify that your service should only run on nodes where an arbitrary label `pci_compliant` is set to `true`.\n    \n*   [Placement preferences](#placement-preferences) let you apply an arbitrary label with a range of values to each node, and spread your service's tasks across those nodes using an algorithm. Currently, the only supported algorithm is `spread`, which tries to place them evenly. For instance, if you label each node with a label `rack` which has a value from 1-10, then specify a placement preference keyed on `rack`, then service tasks are placed as evenly as possible across all nodes with the label `rack`, after taking other placement constraints, placement preferences, and other node-specific limitations into account.\n    \n    Unlike constraints, placement preferences are best-effort, and a service does not fail to deploy if no nodes can satisfy the preference. If you specify a placement preference for a service, nodes that match that preference are ranked higher when the swarm managers decide which nodes should run the service tasks. Other factors, such as high availability of the service, also factor into which nodes are scheduled to run service tasks. For example, if you have N nodes with the rack label (and then some others), and your service is configured to run N+1 replicas, the +1 is scheduled on a node that doesn't already have the service on it if there is one, regardless of whether that node has the `rack` label or not.\n    \n\n#### [Replicated or global services](#replicated-or-global-services)\n\nSwarm mode has two types of services: replicated and global. For replicated services, you specify the number of replica tasks for the swarm manager to schedule onto available nodes. For global services, the scheduler places one task on each available node that meets the service's [placement constraints](#placement-constraints) and [resource requirements](#reserve-memory-or-cpus-for-a-service).\n\nYou control the type of service using the `--mode` flag. If you don't specify a mode, the service defaults to `replicated`. For replicated services, you specify the number of replica tasks you want to start using the `--replicas` flag. For example, to start a replicated nginx service with 3 replica tasks:\n\nTo start a global service on each available node, pass `--mode global` to `docker service create`. Every time a new node becomes available, the scheduler places a task for the global service on the new node. For example to start a service that runs alpine on every node in the swarm:\n\nService constraints let you set criteria for a node to meet before the scheduler deploys a service to the node. You can apply constraints to the service based upon node attributes and metadata or engine metadata. For more information on constraints, refer to the `docker service create` [CLI reference](https://docs.docker.com/reference/cli/docker/service/create/).\n\n#### [Reserve memory or CPUs for a service](#reserve-memory-or-cpus-for-a-service)\n\nTo reserve a given amount of memory or number of CPUs for a service, use the `--reserve-memory` or `--reserve-cpu` flags. If no available nodes can satisfy the requirement (for instance, if you request 4 CPUs and no node in the swarm has 4 CPUs), the service remains in a pending state until an appropriate node is available to run its tasks.\n\n##### [Out Of Memory Exceptions (OOME)](#out-of-memory-exceptions-oome)\n\nIf your service attempts to use more memory than the swarm node has available, you may experience an Out Of Memory Exception (OOME) and a container, or the Docker daemon, might be killed by the kernel OOM killer. To prevent this from happening, ensure that your application runs on hosts with adequate memory and see [Understand the risks of running out of memory](https://docs.docker.com/config/containers/resource_constraints/#understand-the-risks-of-running-out-of-memory).\n\nSwarm services allow you to use resource constraints, placement preferences, and labels to ensure that your service is deployed to the appropriate swarm nodes.\n\n#### [Placement constraints](#placement-constraints)\n\nUse placement constraints to control the nodes a service can be assigned to. In the following example, the service only runs on nodes with the [label](https://docs.docker.com/engine/swarm/manage-nodes/#add-or-remove-label-metadata) `region` set to `east`. If no appropriately-labelled nodes are available, tasks will wait in `Pending` until they become available. The `--constraint` flag uses an equality operator (`==` or `!=`). For replicated services, it is possible that all services run on the same node, or each node only runs one replica, or that some nodes don't run any replicas. For global services, the service runs on every node that meets the placement constraint and any [resource requirements](#reserve-memory-or-cpus-for-a-service).\n\nYou can also use the `constraint` service-level key in a `compose.yml` file.\n\nIf you specify multiple placement constraints, the service only deploys onto nodes where they are all met. The following example limits the service to run on all nodes where `region` is set to `east` and `type` is not set to `devel`:\n\nYou can also use placement constraints in conjunction with placement preferences and CPU/memory constraints. Be careful not to use settings that are not possible to fulfill.\n\nFor more information on constraints, refer to the `docker service create` [CLI reference](https://docs.docker.com/reference/cli/docker/service/create/).\n\n#### [Placement preferences](#placement-preferences)\n\nWhile [placement constraints](#placement-constraints) limit the nodes a service can run on, _placement preferences_ try to place tasks on appropriate nodes in an algorithmic way (currently, only spread evenly). For instance, if you assign each node a `rack` label, you can set a placement preference to spread the service evenly across nodes with the `rack` label, by value. This way, if you lose a rack, the service is still running on nodes on other racks.\n\nPlacement preferences are not strictly enforced. If no node has the label you specify in your preference, the service is deployed as though the preference were not set.\n\n> **Note**\n> \n> Placement preferences are ignored for global services.\n\nThe following example sets a preference to spread the deployment across nodes based on the value of the `datacenter` label. If some nodes have `datacenter=us-east` and others have `datacenter=us-west`, the service is deployed as evenly as possible across the two sets of nodes.\n\n> **Note**\n> \n> Nodes which are missing the label used to spread still receive task assignments. As a group, these nodes receive tasks in equal proportion to any of the other groups identified by a specific label value. In a sense, a missing label is the same as having the label with a null value attached to it. If the service should only run on nodes with the label being used for the spread preference, the preference should be combined with a constraint.\n\nYou can specify multiple placement preferences, and they are processed in the order they are encountered. The following example sets up a service with multiple placement preferences. Tasks are spread first over the various datacenters, and then over racks (as indicated by the respective labels):\n\nYou can also use placement preferences in conjunction with placement constraints or CPU/memory constraints. Be careful not to use settings that are not possible to fulfill.\n\nThis diagram illustrates how placement preferences work:\n\n![How placement preferences work](https://docs.docker.com/engine/swarm/images/placement_prefs.png)\n\nWhen updating a service with `docker service update`, `--placement-pref-add` appends a new placement preference after all existing placement preferences. `--placement-pref-rm` removes an existing placement preference that matches the argument.\n\n### [Configure a service's update behavior](#configure-a-services-update-behavior)\n\nWhen you create a service, you can specify a rolling update behavior for how the swarm should apply changes to the service when you run `docker service update`. You can also specify these flags as part of the update, as arguments to `docker service update`.\n\nThe `--update-delay` flag configures the time delay between updates to a service task or sets of tasks. You can describe the time `T` as a combination of the number of seconds `Ts`, minutes `Tm`, or hours `Th`. So `10m30s` indicates a 10 minute 30 second delay.\n\nBy default the scheduler updates 1 task at a time. You can pass the `--update-parallelism` flag to configure the maximum number of service tasks that the scheduler updates simultaneously.\n\nWhen an update to an individual task returns a state of `RUNNING`, the scheduler continues the update by continuing to another task until all tasks are updated. If at any time during an update a task returns `FAILED`, the scheduler pauses the update. You can control the behavior using the `--update-failure-action` flag for `docker service create` or `docker service update`.\n\nIn the example service below, the scheduler applies updates to a maximum of 2 replicas at a time. When an updated task returns either `RUNNING` or `FAILED`, the scheduler waits 10 seconds before stopping the next task to update:\n\nThe `--update-max-failure-ratio` flag controls what fraction of tasks can fail during an update before the update as a whole is considered to have failed. For example, with `--update-max-failure-ratio 0.1 --update-failure-action pause`, after 10% of the tasks being updated fail, the update is paused.\n\nAn individual task update is considered to have failed if the task doesn't start up, or if it stops running within the monitoring period specified with the `--update-monitor` flag. The default value for `--update-monitor` is 30 seconds, which means that a task failing in the first 30 seconds after it's started counts towards the service update failure threshold, and a failure after that is not counted.\n\n### [Roll back to the previous version of a service](#roll-back-to-the-previous-version-of-a-service)\n\nIn case the updated version of a service doesn't function as expected, it's possible to manually roll back to the previous version of the service using `docker service update`'s `--rollback` flag. This reverts the service to the configuration that was in place before the most recent `docker service update` command.\n\nOther options can be combined with `--rollback`; for example, `--update-delay 0s`, to execute the rollback without a delay between tasks:\n\nYou can configure a service to roll back automatically if a service update fails to deploy. See [Automatically roll back if an update fails](#automatically-roll-back-if-an-update-fails).\n\nManual rollback is handled at the server side, which allows manually-initiated rollbacks to respect the new rollback parameters. Note that `--rollback` cannot be used in conjunction with other flags to `docker service update`.\n\n### [Automatically roll back if an update fails](#automatically-roll-back-if-an-update-fails)\n\nYou can configure a service in such a way that if an update to the service causes redeployment to fail, the service can automatically roll back to the previous configuration. This helps protect service availability. You can set one or more of the following flags at service creation or update. If you do not set a value, the default is used.\n\n| Flag | Default | Description |\n| --- | --- | --- |\n| `--rollback-delay` | `0s` | Amount of time to wait after rolling back a task before rolling back the next one. A value of `0` means to roll back the second task immediately after the first rolled-back task deploys. |\n| `--rollback-failure-action` | `pause` | When a task fails to roll back, whether to `pause` or `continue` trying to roll back other tasks. |\n| `--rollback-max-failure-ratio` | `0` | The failure rate to tolerate during a rollback, specified as a floating-point number between 0 and 1. For instance, given 5 tasks, a failure ratio of `.2` would tolerate one task failing to roll back. A value of `0` means no failure are tolerated, while a value of `1` means any number of failure are tolerated. |\n| `--rollback-monitor` | `5s` | Duration after each task rollback to monitor for failure. If a task stops before this time period has elapsed, the rollback is considered to have failed. |\n| `--rollback-parallelism` | `1` | The maximum number of tasks to roll back in parallel. By default, one task is rolled back at a time. A value of `0` causes all tasks to be rolled back in parallel. |\n\nThe following example configures a `redis` service to roll back automatically if a `docker service update` fails to deploy. Two tasks can be rolled back in parallel. Tasks are monitored for 20 seconds after rollback to be sure they do not exit, and a maximum failure ratio of 20% is tolerated. Default values are used for `--rollback-delay` and `--rollback-failure-action`.\n\n### [Give a service access to volumes or bind mounts](#give-a-service-access-to-volumes-or-bind-mounts)\n\nFor best performance and portability, you should avoid writing important data directly into a container's writable layer. You should instead use data volumes or bind mounts. This principle also applies to services.\n\nYou can create two types of mounts for services in a swarm, `volume` mounts or `bind` mounts. Regardless of which type of mount you use, configure it using the `--mount` flag when you create a service, or the `--mount-add` or `--mount-rm` flag when updating an existing service. The default is a data volume if you don't specify a type.\n\n#### [Data volumes](#data-volumes)\n\nData volumes are storage that exist independently of a container. The lifecycle of data volumes under swarm services is similar to that under containers. Volumes outlive tasks and services, so their removal must be managed separately. Volumes can be created before deploying a service, or if they don't exist on a particular host when a task is scheduled there, they are created automatically according to the volume specification on the service.\n\nTo use existing data volumes with a service use the `--mount` flag:\n\nIf a volume with the name `<VOLUME-NAME>` doesn't exist when a task is scheduled to a particular host, then one is created. The default volume driver is `local`. To use a different volume driver with this create-on-demand pattern, specify the driver and its options with the `--mount` flag:\n\nFor more information on how to create data volumes and the use of volume drivers, see [Use volumes](https://docs.docker.com/storage/volumes/).\n\n#### [Bind mounts](#bind-mounts)\n\nBind mounts are file system paths from the host where the scheduler deploys the container for the task. Docker mounts the path into the container. The file system path must exist before the swarm initializes the container for the task.\n\nThe following examples show bind mount syntax:\n\n*   To mount a read-write bind:\n    \n*   To mount a read-only bind:\n    \n\n> **Important**\n> \n> Bind mounts can be useful but they can also cause problems. In most cases, it is recommended that you architect your application such that mounting paths from the host is unnecessary. The main risks include the following:\n> \n> *   If you bind mount a host path into your serviceâ€™s containers, the path must exist on every swarm node. The Docker swarm mode scheduler can schedule containers on any machine that meets resource availability requirements and satisfies all constraints and placement preferences you specify.\n>     \n> *   The Docker swarm mode scheduler may reschedule your running service containers at any time if they become unhealthy or unreachable.\n>     \n> *   Host bind mounts are non-portable. When you use bind mounts, there is no guarantee that your application runs the same way in development as it does in production.\n>     \n\n### [Create services using templates](#create-services-using-templates)\n\nYou can use templates for some flags of `service create`, using the syntax provided by the Go's [text/template](https://golang.org/pkg/text/template/) package.\n\nThe following flags are supported:\n\n*   `--hostname`\n*   `--mount`\n*   `--env`\n\nValid placeholders for the Go template are:\n\n| Placeholder | Description |\n| --- | --- |\n| `.Service.ID` | Service ID |\n| `.Service.Name` | Service name |\n| `.Service.Labels` | Service labels |\n| `.Node.ID` | Node ID |\n| `.Node.Hostname` | Node hostname |\n| `.Task.Name` | Task name |\n| `.Task.Slot` | Task slot |\n\n#### [Template example](#template-example)\n\nThis example sets the template of the created containers based on the service's name and the ID of the node where the container is running:\n\nTo see the result of using the template, use the `docker service ps` and `docker inspect` commands.\n\n*   [Swarm administration guide](https://docs.docker.com/engine/swarm/admin_guide/)\n*   [Docker Engine command line reference](https://docs.docker.com/reference/cli/docker/)\n*   [Swarm mode tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/)",
  "title": "Deploy services to a swarm | Docker Docs\n",
  "description": "Deploy services to a swarm",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/security/certificates/",
  "markdown": "# Verify repository client with certificates\n\nIn [Running Docker with HTTPS](https://docs.docker.com/engine/security/protect-access/), you learned that, by default, Docker runs via a non-networked Unix socket and TLS must be enabled in order to have the Docker client and the daemon communicate securely over HTTPS. TLS ensures authenticity of the registry endpoint and that traffic to/from registry is encrypted.\n\nThis article demonstrates how to ensure the traffic between the Docker registry server and the Docker daemon (a client of the registry server) is encrypted and properly authenticated using certificate-based client-server authentication.\n\nWe show you how to install a Certificate Authority (CA) root certificate for the registry and how to set the client TLS certificate for verification.\n\nA custom certificate is configured by creating a directory under `/etc/docker/certs.d` using the same name as the registry's hostname, such as `localhost`. All `*.crt` files are added to this directory as CA roots.\n\n> **Note**\n> \n> On Linux any root certificates authorities are merged with the system defaults, including the host's root CA set. If you are running Docker on Windows Server, or Docker Desktop for Windows with Windows containers, the system default certificates are only used when no custom root certificates are configured.\n\nThe presence of one or more `<filename>.key/cert` pairs indicates to Docker that there are custom certificates required for access to the desired repository.\n\n> **Note**\n> \n> If multiple certificates exist, each is tried in alphabetical order. If there is a 4xx-level or 5xx-level authentication error, Docker continues to try with the next certificate.\n\nThe following illustrates a configuration with custom certificates:\n\nThe preceding example is operating-system specific and is for illustrative purposes only. You should consult your operating system documentation for creating an os-provided bundled certificate chain.\n\nUse OpenSSL's `genrsa` and `req` commands to first generate an RSA key and then use the key to create the certificate.\n\n> **Note**\n> \n> These TLS commands only generate a working set of certificates on Linux. The version of OpenSSL in macOS is incompatible with the type of certificate Docker requires.\n\nThe Docker daemon interprets `.crt` files as CA certificates and `.cert` files as client certificates. If a CA certificate is accidentally given the extension `.cert` instead of the correct `.crt` extension, the Docker daemon logs the following error message:\n\nIf the Docker registry is accessed without a port number, do not add the port to the directory name. The following shows the configuration for a registry on default port 443 which is accessed with `docker login my-https.registry.example.com`:\n\n*   [Use trusted images](https://docs.docker.com/engine/security/trust/)\n*   [Protect the Docker daemon socket](https://docs.docker.com/engine/security/protect-access/)",
  "title": "Verify repository client with certificates | Docker Docs\n",
  "description": "How to set up and use certificates with a registry to verify access",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/install/ubuntu/",
  "markdown": "# Install Docker Engine on Ubuntu\n\nTo get started with Docker Engine on Ubuntu, make sure you [meet the prerequisites](#prerequisites), and then follow the [installation steps](#installation-methods).\n\n### [Firewall limitations](#firewall-limitations)\n\n> **Warning**\n> \n> Before you install Docker, make sure you consider the following security implications and firewall incompatibilities.\n\n*   If you use ufw or firewalld to manage firewall settings, be aware that when you expose container ports using Docker, these ports bypass your firewall rules. For more information, refer to [Docker and ufw](https://docs.docker.com/network/packet-filtering-firewalls/#docker-and-ufw).\n*   Docker is only compatible with `iptables-nft` and `iptables-legacy`. Firewall rules created with `nft` are not supported on a system with Docker installed. Make sure that any firewall rulesets you use are created with `iptables` or `iptables6`, and that you add them to the `DOCKER-USER` chain, see [Packet filtering and firewalls](https://docs.docker.com/network/packet-filtering-firewalls/).\n\n### [OS requirements](#os-requirements)\n\nTo install Docker Engine, you need the 64-bit version of one of these Ubuntu versions:\n\n*   Ubuntu Noble 24.04 (LTS)\n*   Ubuntu Mantic 23.10 (EOL: [July 12, 2024](https://wiki.ubuntu.com/Releases))\n*   Ubuntu Jammy 22.04 (LTS)\n*   Ubuntu Focal 20.04 (LTS)\n\nDocker Engine for Ubuntu is compatible with x86\\_64 (or amd64), armhf, arm64, s390x, and ppc64le (ppc64el) architectures.\n\n### [Uninstall old versions](#uninstall-old-versions)\n\nBefore you can install Docker Engine, you need to uninstall any conflicting packages.\n\nDistro maintainers provide unofficial distributions of Docker packages in APT. You must uninstall these packages before you can install the official version of Docker Engine.\n\nThe unofficial packages to uninstall are:\n\n*   `docker.io`\n*   `docker-compose`\n*   `docker-compose-v2`\n*   `docker-doc`\n*   `podman-docker`\n\nMoreover, Docker Engine depends on `containerd` and `runc`. Docker Engine bundles these dependencies as one bundle: `containerd.io`. If you have installed the `containerd` or `runc` previously, uninstall them to avoid conflicts with the versions bundled with Docker Engine.\n\nRun the following command to uninstall all conflicting packages:\n\n`apt-get` might report that you have none of these packages installed.\n\nImages, containers, volumes, and networks stored in `/var/lib/docker/` aren't automatically removed when you uninstall Docker. If you want to start with a clean installation, and prefer to clean up any existing data, read the [uninstall Docker Engine](#uninstall-docker-engine) section.\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n*   Docker Engine comes bundled with [Docker Desktop for Linux](https://docs.docker.com/desktop/install/linux-install/). This is the easiest and quickest way to get started.\n    \n*   Set up and install Docker Engine from [Docker's `apt` repository](#install-using-the-repository).\n    \n*   [Install it manually](#install-from-a-package) and manage upgrades manually.\n    \n*   Use a [convenience script](#install-using-the-convenience-script). Only recommended for testing and development environments.\n    \n\n### [Install using the `apt` repository](#install-using-the-repository)\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\n1.  Set up Docker's `apt` repository.\n    \n    > **Note**\n    > \n    > If you use an Ubuntu derivative distro, such as Linux Mint, you may need to use `UBUNTU_CODENAME` instead of `VERSION_CODENAME`.\n    \n2.  Install the Docker packages.\n    \n    * * *\n    \n    To install the latest version, run:\n    \n    To install a specific version of Docker Engine, start by listing the available versions in the repository:\n    \n    Select the desired version and install:\n    \n    * * *\n    \n3.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why youâ€™re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine)\n\nTo upgrade Docker Engine, follow step 2 of the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### [Install from a package](#install-from-a-package)\n\nIf you can't use Docker's `apt` repository to install Docker Engine, you can download the `deb` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [`https://download.docker.com/linux/ubuntu/dists/`](https://download.docker.com/linux/ubuntu/dists/).\n    \n2.  Select your Ubuntu version in the list.\n    \n3.  Go to `pool/stable/` and select the applicable architecture (`amd64`, `armhf`, `arm64`, or `s390x`).\n    \n4.  Download the following `deb` files for the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n    *   `containerd.io_<version>_<arch>.deb`\n    *   `docker-ce_<version>_<arch>.deb`\n    *   `docker-ce-cli_<version>_<arch>.deb`\n    *   `docker-buildx-plugin_<version>_<arch>.deb`\n    *   `docker-compose-plugin_<version>_<arch>.deb`\n5.  Install the `.deb` packages. Update the paths in the following example to where you downloaded the Docker packages.\n    \n    The Docker daemon starts automatically.\n    \n6.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why youâ€™re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine-1)\n\nTo upgrade Docker Engine, download the newer package files and repeat the [installation procedure](#install-from-a-package), pointing to the new files.\n\n### [Install using the convenience script](#install-using-the-convenience-script)\n\nDocker provides a convenience script at [https://get.docker.com/](https://get.docker.com/) to install Docker into development environments non-interactively. The convenience script isn't recommended for production environments, but it's useful for creating a provisioning script tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and you can find it in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n*   The script requires `root` or `sudo` privileges to run.\n*   The script attempts to detect your Linux distribution and version and configure your package management system for you.\n*   The script doesn't allow you to customize most installation parameters.\n*   The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n*   By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test upgrades in a test environment before deploying to your production systems.\n*   The script isn't designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, resulting in outdated versions.\n\n> **Tip: preview script steps before running**\n> \n> You can run the script with the `--dry-run` option to learn what steps the script will run when invoked:\n\nThis example downloads the script from [https://get.docker.com/](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\nYou have now successfully installed and started Docker Engine. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users can't run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n> \n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user). You can also install Docker without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](https://docs.docker.com/engine/security/rootless/).\n\n#### [Install pre-releases](#install-pre-releases)\n\nDocker also provides a convenience script at [https://test.docker.com/](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equal to the script at `get.docker.com`, but configures your package manager to use the test channel of the Docker package repository. The test channel includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they're released as stable.\n\nTo install the latest version of Docker on Linux from the test channel, run:\n\n#### [Upgrade Docker after using the convenience script](#upgrade-docker-after-using-the-convenience-script)\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There's no advantage to re-running the convenience script. Re-running it can cause issues if it attempts to re-install repositories which already exist on the host machine.\n\n1.  Uninstall the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n2.  Images, containers, volumes, or custom configuration files on your host aren't automatically removed. To delete all images, containers, and volumes:\n    \n\nYou have to delete any edited configuration files manually.\n\n*   Continue to [Post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/).",
  "title": "Install Docker Engine on Ubuntu | Docker Docs\n",
  "description": "Jumpstart your client-side server applications with Docker Engine on Ubuntu. This guide details prerequisites and multiple methods to install Docker Engine on Ubuntu.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/stack-deploy/",
  "markdown": "# Deploy a stack to a swarm\n\nWhen running Docker Engine in swarm mode, you can use `docker stack deploy` to deploy a complete application stack to the swarm. The `deploy` command accepts a stack description in the form of a [Compose file](https://docs.docker.com/compose/compose-file/legacy-versions/).\n\n> **Note**\n> \n> The `docker stack deploy` command uses the legacy [Compose file version 3](https://docs.docker.com/compose/compose-file/compose-file-v3/) format, used by Compose V1. The latest format, defined by the [Compose specification](https://docs.docker.com/compose/compose-file/) isn't compatible with the `docker stack deploy` command.\n> \n> For more information about the evolution of Compose, see [History of Compose](https://docs.docker.com/compose/history/).\n\nTo run through this tutorial, you need:\n\n1.  A Docker Engine running in [Swarm mode](https://docs.docker.com/engine/swarm/swarm-mode/). If you're not familiar with Swarm mode, you might want to read [Swarm mode key concepts](https://docs.docker.com/engine/swarm/key-concepts/) and [How services work](https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/).\n    \n    > **Note**\n    > \n    > If you're trying things out on a local development environment, you can put your engine into Swarm mode with `docker swarm init`.\n    > \n    > If you've already got a multi-node swarm running, keep in mind that all `docker stack` and `docker service` commands must be run from a manager node.\n    \n2.  A current version of [Docker Compose](https://docs.docker.com/compose/install/).\n    \n\nBecause a swarm consists of multiple Docker Engines, a registry is required to distribute images to all of them. You can use the [Docker Hub](https://hub.docker.com/) or maintain your own. Here's how to create a throwaway registry, which you can discard afterward.\n\n1.  Start the registry as a service on your swarm:\n    \n2.  Check its status with `docker service ls`:\n    \n    Once it reads `1/1` under `REPLICAS`, it's running. If it reads `0/1`, it's probably still pulling the image.\n    \n3.  Check that it's working with `curl`:\n    \n\nThe app used in this guide is based on the hit counter app in the [Get started with Docker Compose](https://docs.docker.com/compose/gettingstarted/) guide. It consists of a Python app which maintains a counter in a Redis instance and increments the counter whenever you visit it.\n\n1.  Create a directory for the project:\n    \n2.  Create a file called `app.py` in the project directory and paste this in:\n    \n3.  Create a file called `requirements.txt` and paste these two lines in:\n    \n4.  Create a file called `Dockerfile` and paste this in:\n    \n5.  Create a file called `compose.yml` and paste this in:\n    \n    The image for the web app is built using the Dockerfile defined above. It's also tagged with `127.0.0.1:5000` - the address of the registry created earlier. This is important when distributing the app to the swarm.\n    \n\n1.  Start the app with `docker compose up`. This builds the web app image, pulls the Redis image if you don't already have it, and creates two containers.\n    \n    You see a warning about the Engine being in swarm mode. This is because Compose doesn't take advantage of swarm mode, and deploys everything to a single node. You can safely ignore this.\n    \n2.  Check that the app is running with `docker compose ps`:\n    \n    You can test the app with `curl`:\n    \n3.  Bring the app down:\n    \n\nTo distribute the web app's image across the swarm, it needs to be pushed to the registry you set up earlier. With Compose, this is very simple:\n\nThe stack is now ready to be deployed.\n\n1.  Create the stack with `docker stack deploy`:\n    \n    The last argument is a name for the stack. Each network, volume and service name is prefixed with the stack name.\n    \n2.  Check that it's running with `docker stack services stackdemo`:\n    \n    Once it's running, you should see `1/1` under `REPLICAS` for both services. This might take some time if you have a multi-node swarm, as images need to be pulled.\n    \n    As before, you can test the app with `curl`:\n    \n    With Docker's built-in routing mesh, you can access any node in the swarm on port `8000` and get routed to the app:\n    \n3.  Bring the stack down with `docker stack rm`:\n    \n4.  Bring the registry down with `docker service rm`:\n    \n5.  If you're just testing things out on a local machine and want to bring your Docker Engine out of Swarm mode, use `docker swarm leave`:",
  "title": "Deploy a stack to a swarm | Docker Docs\n",
  "description": "How to deploy a stack to a swarm",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/security/trust/",
  "markdown": "# Content trust in Docker | Docker Docs\n\nWhen transferring data among networked systems, trust is a central concern. In particular, when communicating over an untrusted medium such as the internet, it is critical to ensure the integrity and the publisher of all the data a system operates on. You use Docker Engine to push and pull images (data) to a public or private registry. Content trust gives you the ability to verify both the integrity and the publisher of all the data received from a registry over any channel.\n\n## [About Docker Content Trust (DCT)](#about-docker-content-trust-dct)\n\nDocker Content Trust (DCT) provides the ability to use digital signatures for data sent to and received from remote Docker registries. These signatures allow client-side or runtime verification of the integrity and publisher of specific image tags.\n\nThrough DCT, image publishers can sign their images and image consumers can ensure that the images they pull are signed. Publishers could be individuals or organizations manually signing their content or automated software supply chains signing content as part of their release process.\n\n### [Image tags and DCT](#image-tags-and-dct)\n\nAn individual image record has the following identifier:\n\nA particular image `REPOSITORY` can have multiple tags. For example, `latest` and `3.1.2` are both tags on the `mongo` image. An image publisher can build an image and tag combination many times changing the image with each build.\n\nDCT is associated with the `TAG` portion of an image. Each image repository has a set of keys that image publishers use to sign an image tag. Image publishers have discretion on which tags they sign.\n\nAn image repository can contain an image with one tag that is signed and another tag that is not. For example, consider [the Mongo image repository](https://hub.docker.com/r/library/mongo/tags/). The `latest` tag could be unsigned while the `3.1.6` tag could be signed. It is the responsibility of the image publisher to decide if an image tag is signed or not. In this representation, some image tags are signed, others are not:\n\n![Signed tags](https://docs.docker.com/engine/security/trust/images/tag_signing.png)\n\nPublishers can choose to sign a specific tag or not. As a result, the content of an unsigned tag and that of a signed tag with the same name may not match. For example, a publisher can push a tagged image `someimage:latest` and sign it. Later, the same publisher can push an unsigned `someimage:latest` image. This second push replaces the last unsigned tag `latest` but does not affect the signed `latest` version. The ability to choose which tags they can sign, allows publishers to iterate over the unsigned version of an image before officially signing it.\n\nImage consumers can enable DCT to ensure that images they use were signed. If a consumer enables DCT, they can only pull, run, or build with trusted images. Enabling DCT is a bit like applying a \"filter\" to your registry. Consumers \"see\" only signed image tags and the less desirable, unsigned image tags are \"invisible\" to them.\n\n![Trust view](https://docs.docker.com/engine/security/trust/images/trust_view.png)\n\nTo the consumer who has not enabled DCT, nothing about how they work with Docker images changes. Every image is visible regardless of whether it is signed or not.\n\n### [Docker Content Trust Keys](#docker-content-trust-keys)\n\nTrust for an image tag is managed through the use of signing keys. A key set is created when an operation using DCT is first invoked. A key set consists of the following classes of keys:\n\n*   An offline key that is the root of DCT for an image tag\n*   Repository or tagging keys that sign tags\n*   Server-managed keys such as the timestamp key, which provides freshness security guarantees for your repository\n\nThe following image depicts the various signing keys and their relationships:\n\n![Content Trust components](https://docs.docker.com/engine/security/trust/images/trust_components.png)\n\n> **Warning**\n> \n> The root key once lost is not recoverable. If you lose any other key, send an email to Docker Hub Support. This loss also requires manual intervention from every consumer that used a signed tag from this repository prior to the loss.\n\nYou should back up the root key somewhere safe. Given that it is only required to create new repositories, it is a good idea to store it offline in hardware. For details on securing, and backing up your keys, make sure you read how to [manage keys for DCT](https://docs.docker.com/engine/security/trust/trust_key_mng/).\n\n## [Signing images with Docker Content Trust](#signing-images-with-docker-content-trust)\n\nWithin the Docker CLI we can sign and push a container image with the `$ docker trust` command syntax. This is built on top of the Notary feature set. For more information, see the [Notary GitHub repository](https://github.com/theupdateframework/notary).\n\nA prerequisite for signing an image is a Docker Registry with a Notary server attached (Such as the Docker Hub ). Instructions for standing up a self-hosted environment can be found [here](https://docs.docker.com/engine/security/trust/deploying_notary/).\n\nTo sign a Docker Image you will need a delegation key pair. These keys can be generated locally using `$ docker trust key generate` or generated by a certificate authority.\n\nFirst we will add the delegation private key to the local Docker trust repository. (By default this is stored in `~/.docker/trust/`). If you are generating delegation keys with `$ docker trust key generate`, the private key is automatically added to the local trust store. If you are importing a separate key, you will need to use the `$ docker trust key load` command.\n\nOr if you have an existing key:\n\nNext we will need to add the delegation public key to the Notary server; this is specific to a particular image repository in Notary known as a Global Unique Name (GUN). If this is the first time you are adding a delegation to that repository, this command will also initiate the repository, using a local Notary canonical root key. To understand more about initiating a repository, and the role of delegations, head to [delegations for content trust](https://docs.docker.com/engine/security/trust/trust_delegation/).\n\nFinally, we will use the delegation private key to sign a particular tag and push it up to the registry.\n\nAlternatively, once the keys have been imported an image can be pushed with the `$ docker push` command, by exporting the DCT environmental variable.\n\nRemote trust data for a tag or a repository can be viewed by the `$ docker trust inspect` command:\n\nRemote Trust data for a tag can be removed by the `$ docker trust revoke` command:\n\n## [Client enforcement with Docker Content Trust](#client-enforcement-with-docker-content-trust)\n\nContent trust is disabled by default in the Docker Client. To enable it, set the `DOCKER_CONTENT_TRUST` environment variable to `1`. This prevents users from working with tagged images unless they contain a signature.\n\nWhen DCT is enabled in the Docker client, `docker` CLI commands that operate on tagged images must either have content signatures or explicit content hashes. The commands that operate with DCT are:\n\n*   `push`\n*   `build`\n*   `create`\n*   `pull`\n*   `run`\n\nFor example, with DCT enabled a `docker pull someimage:latest` only succeeds if `someimage:latest` is signed. However, an operation with an explicit content hash always succeeds as long as the hash exists:\n\n*   [Delegations for content trust](https://docs.docker.com/engine/security/trust/trust_delegation/)\n*   [Automation with content trust](https://docs.docker.com/engine/security/trust/trust_automation/)\n*   [Manage keys for content trust](https://docs.docker.com/engine/security/trust/trust_key_mng/)\n*   [Play in a content trust sandbox](https://docs.docker.com/engine/security/trust/trust_sandbox/)",
  "title": "Content trust in Docker | Docker Docs\n",
  "description": "Enabling content trust in Docker",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/install/sles/",
  "markdown": "# Install Docker Engine on SLES (s390x)\n\n> **Note**\n> \n> The installation instructions on this page refer to packages for SLES on the **s390x** architecture (IBM Z). Other architectures, including x86\\_64, aren't supported for SLES.\n\nTo get started with Docker Engine on SLES, make sure you [meet the prerequisites](#prerequisites), and then follow the [installation steps](#installation-methods).\n\n### [OS requirements](#os-requirements)\n\nTo install Docker Engine, you need a maintained version of one of the following SLES versions:\n\n*   SLES 15-SP4 on s390x (IBM Z)\n*   SLES 15-SP5 on s390x (IBM Z)\n\nYou must enable the [`SCC SUSE`](https://scc.suse.com/packages?name=SUSE%20Linux%20Enterprise%20Server&version=15.5&arch=s390x) repositories.\n\nYou must add the [OpenSUSE `SELinux` repository](https://download.opensuse.org/repositories/security:/SELinux/). This repository is not added by default. Run the following commands to add it:\n\n### [Uninstall old versions](#uninstall-old-versions)\n\nOlder versions of Docker went by `docker` or `docker-engine`. Uninstall any such older versions before attempting to install a new version, along with associated dependencies.\n\n`zypper` might report that you have none of these packages installed.\n\nImages, containers, volumes, and networks stored in `/var/lib/docker/` aren't automatically removed when you uninstall Docker.\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n*   You can [set up Docker's repositories](#install-using-the-repository) and install from them, for ease of installation and upgrade tasks. This is the recommended approach.\n    \n*   You can download the RPM package, [install it manually](#install-from-a-package), and manage upgrades completely manually. This is useful in situations such as installing Docker on air-gapped systems with no access to the internet.\n    \n*   In testing and development environments, you can use automated [convenience scripts](#install-using-the-convenience-script) to install Docker.\n    \n\n### [Install using the rpm repository](#install-using-the-repository)\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\n#### [Set up the repository](#set-up-the-repository)\n\nSet up the repository.\n\n#### [Install Docker Engine](#install-docker-engine)\n\n1.  Install Docker Engine, containerd, and Docker Compose:\n    \n    * * *\n    \n    To install the latest version, run:\n    \n    If prompted to accept the GPG key, verify that the fingerprint matches `060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35`, and if so, accept it.\n    \n    This command installs Docker, but it doesn't start Docker. It also creates a `docker` group, however, it doesn't add any users to the group by default.\n    \n    To install a specific version, start by listing the available versions in the repository:\n    \n    The list returned depends on which repositories are enabled, and is specific to your version of SLES.\n    \n    Install a specific version by its fully qualified package name, which is the package name (`docker-ce`) plus the version string (2nd column), separated by a hyphen (`-`). For example, `docker-ce-3:25.0.0`.\n    \n    Replace `<VERSION_STRING>` with the desired version and then run the following command to install:\n    \n    This command installs Docker, but it doesn't start Docker. It also creates a `docker` group, however, it doesn't add any users to the group by default.\n    \n    * * *\n    \n2.  Start Docker.\n    \n3.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why youâ€™re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine)\n\nTo upgrade Docker Engine, follow the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### [Install from a package](#install-from-a-package)\n\nIf you can't use Docker's `rpm` repository to install Docker Engine, you can download the `.rpm` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [https://download.docker.com/linux/sles/](https://download.docker.com/linux/sles/) and choose your version of SLES. Then browse to `s390x/stable/Packages/` and download the `.rpm` file for the Docker version you want to install.\n    \n2.  Install Docker Engine, changing the following path to the path where you downloaded the Docker package.\n    \n    Docker is installed but not started. The `docker` group is created, but no users are added to the group.\n    \n3.  Start Docker.\n    \n4.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why youâ€™re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine-1)\n\nTo upgrade Docker Engine, download the newer package files and repeat the [installation procedure](#install-from-a-package), using `zypper -y upgrade` instead of `zypper -y install`, and point to the new files.\n\n### [Install using the convenience script](#install-using-the-convenience-script)\n\nDocker provides a convenience script at [https://get.docker.com/](https://get.docker.com/) to install Docker into development environments non-interactively. The convenience script isn't recommended for production environments, but it's useful for creating a provisioning script tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and you can find it in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n*   The script requires `root` or `sudo` privileges to run.\n*   The script attempts to detect your Linux distribution and version and configure your package management system for you.\n*   The script doesn't allow you to customize most installation parameters.\n*   The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n*   By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test upgrades in a test environment before deploying to your production systems.\n*   The script isn't designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, resulting in outdated versions.\n\n> **Tip: preview script steps before running**\n> \n> You can run the script with the `--dry-run` option to learn what steps the script will run when invoked:\n\nThis example downloads the script from [https://get.docker.com/](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\nYou have now successfully installed and started Docker Engine. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users can't run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n> \n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user). You can also install Docker without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](https://docs.docker.com/engine/security/rootless/).\n\n#### [Install pre-releases](#install-pre-releases)\n\nDocker also provides a convenience script at [https://test.docker.com/](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equal to the script at `get.docker.com`, but configures your package manager to use the test channel of the Docker package repository. The test channel includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they're released as stable.\n\nTo install the latest version of Docker on Linux from the test channel, run:\n\n#### [Upgrade Docker after using the convenience script](#upgrade-docker-after-using-the-convenience-script)\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There's no advantage to re-running the convenience script. Re-running it can cause issues if it attempts to re-install repositories which already exist on the host machine.\n\n1.  Uninstall the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n2.  Images, containers, volumes, or custom configuration files on your host aren't automatically removed. To delete all images, containers, and volumes:\n    \n\nYou have to delete any edited configuration files manually.\n\n*   Continue to [Post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/).",
  "title": "Install Docker Engine on SLES (s390x) | Docker Docs\n",
  "description": "Learn how to install Docker Engine on SLES. These instructions cover the different installation methods, how to uninstall, and next steps.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/security/trust/trust_automation/",
  "markdown": "# Automation with content trust | Docker Docs\n\nIt is very common for Docker Content Trust to be built into existing automation systems. To allow tools to wrap Docker and push trusted content, there are environment variables that can be passed through to the client.\n\nThis guide follows the steps as described in [Signing images with Docker Content Trust](https://docs.docker.com/engine/security/trust/#signing-images-with-docker-content-trust). Make sure you understand and follow the prerequisites.\n\nWhen working directly with the Notary client, it uses its [own set of environment variables](https://github.com/theupdateframework/notary/blob/master/docs/reference/client-config.md#environment-variables-optional).\n\nTo automate importing a delegation private key to the local Docker trust store, we need to pass a passphrase for the new key. This passphrase will be required everytime that delegation signs a tag.\n\nIf you initialize a repository at the same time as adding a delegation public key, then you will need to use the local Notary Canonical Root Key's passphrase to create the repositories trust data. If the repository has already been initiated then you only need the repositories passphrase.\n\nFinally when signing an image, we will need to export the passphrase of the signing key. This was created when the key was loaded into the local Docker trust store with `$ docker trust key load`.\n\n## [Build with content trust](#build-with-content-trust)\n\nYou can also build with content trust. Before running the `docker build` command, you should set the environment variable `DOCKER_CONTENT_TRUST` either manually or in a scripted fashion. Consider the simple Dockerfile below.\n\nThe `FROM` tag is pulling a signed image. You cannot build an image that has a `FROM` that is not either present locally or signed. Given that content trust data exists for the tag `latest`, the following build should succeed:\n\nIf content trust is enabled, building from a Dockerfile that relies on tag without trust data, causes the build command to fail:\n\n*   [Delegations for content trust](https://docs.docker.com/engine/security/trust/trust_delegation/)\n*   [Content trust in Docker](https://docs.docker.com/engine/security/trust/)\n*   [Manage keys for content trust](https://docs.docker.com/engine/security/trust/trust_key_mng/)\n*   [Play in a content trust sandbox](https://docs.docker.com/engine/security/trust/trust_sandbox/)",
  "title": "Automation with content trust | Docker Docs\n",
  "description": "Automating content push pulls with trust",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/install/raspberry-pi-os/",
  "markdown": "# Install Docker Engine on Raspberry Pi OS (32-bit)\n\nTo get started with Docker Engine on Raspberry Pi OS, make sure you [meet the prerequisites](#prerequisites), and then follow the [installation steps](#installation-methods).\n\n> **Important**\n> \n> This installation instruction refers to the 32-bit (armhf) version of Raspberry Pi OS. If you're using the 64-bit (arm64) version, follow the instructions for [Debian](https://docs.docker.com/engine/install/debian/).\n\n### [Firewall limitations](#firewall-limitations)\n\n> **Warning**\n> \n> Before you install Docker, make sure you consider the following security implications and firewall incompatibilities.\n\n*   If you use ufw or firewalld to manage firewall settings, be aware that when you expose container ports using Docker, these ports bypass your firewall rules. For more information, refer to [Docker and ufw](https://docs.docker.com/network/packet-filtering-firewalls/#docker-and-ufw).\n*   Docker is only compatible with `iptables-nft` and `iptables-legacy`. Firewall rules created with `nft` are not supported on a system with Docker installed. Make sure that any firewall rulesets you use are created with `iptables` or `iptables6`, and that you add them to the `DOCKER-USER` chain, see [Packet filtering and firewalls](https://docs.docker.com/network/packet-filtering-firewalls/).\n\n### [OS requirements](#os-requirements)\n\nTo install Docker Engine, you need one of the following OS versions:\n\n*   32-bit Raspberry Pi OS Bookworm 12 (stable)\n*   32-bit Raspberry Pi OS Bullseye 11 (oldstable)\n\n### [Uninstall old versions](#uninstall-old-versions)\n\nBefore you can install Docker Engine, you need to uninstall any conflicting packages.\n\nDistro maintainers provide an unofficial distributions of Docker packages in APT. You must uninstall these packages before you can install the official version of Docker Engine.\n\nThe unofficial packages to uninstall are:\n\n*   `docker.io`\n*   `docker-compose`\n*   `docker-doc`\n*   `podman-docker`\n\nMoreover, Docker Engine depends on `containerd` and `runc`. Docker Engine bundles these dependencies as one bundle: `containerd.io`. If you have installed the `containerd` or `runc` previously, uninstall them to avoid conflicts with the versions bundled with Docker Engine.\n\nRun the following command to uninstall all conflicting packages:\n\n`apt-get` might report that you have none of these packages installed.\n\nImages, containers, volumes, and networks stored in `/var/lib/docker/` aren't automatically removed when you uninstall Docker. If you want to start with a clean installation, and prefer to clean up any existing data, read the [uninstall Docker Engine](#uninstall-docker-engine) section.\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n*   Docker Engine comes bundled with [Docker Desktop for Linux](https://docs.docker.com/desktop/install/linux-install/). This is the easiest and quickest way to get started.\n    \n*   Set up and install Docker Engine from [Docker's `apt` repository](#install-using-the-repository).\n    \n*   [Install it manually](#install-from-a-package) and manage upgrades manually.\n    \n*   Use a [convenience script](#install-using-the-convenience-script). Only recommended for testing and development environments.\n    \n\n### [Install using the `apt` repository](#install-using-the-repository)\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker `apt` repository. Afterward, you can install and update Docker from the repository.\n\n1.  Set up Docker's `apt` repository.\n    \n2.  Install the Docker packages.\n    \n    * * *\n    \n    To install the latest version, run:\n    \n    To install a specific version of Docker Engine, start by listing the available versions in the repository:\n    \n    Select the desired version and install:\n    \n    * * *\n    \n3.  Verify that the installation is successful by running the `hello-world` image:\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why youâ€™re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine)\n\nTo upgrade Docker Engine, follow step 2 of the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### [Install from a package](#install-from-a-package)\n\nIf you can't use Docker's `apt` repository to install Docker Engine, you can download the `deb` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [`https://download.docker.com/linux/raspbian/dists/`](https://download.docker.com/linux/raspbian/dists/).\n    \n2.  Select your Raspberry Pi OS version in the list.\n    \n3.  Go to `pool/stable/` and select the applicable architecture (`amd64`, `armhf`, `arm64`, or `s390x`).\n    \n4.  Download the following `deb` files for the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n    *   `containerd.io_<version>_<arch>.deb`\n    *   `docker-ce_<version>_<arch>.deb`\n    *   `docker-ce-cli_<version>_<arch>.deb`\n    *   `docker-buildx-plugin_<version>_<arch>.deb`\n    *   `docker-compose-plugin_<version>_<arch>.deb`\n5.  Install the `.deb` packages. Update the paths in the following example to where you downloaded the Docker packages.\n    \n    The Docker daemon starts automatically.\n    \n6.  Verify that the Docker Engine installation is successful by running the `hello-world` image:\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why youâ€™re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine-1)\n\nTo upgrade Docker Engine, download the newer package files and repeat the [installation procedure](#install-from-a-package), pointing to the new files.\n\n### [Install using the convenience script](#install-using-the-convenience-script)\n\nDocker provides a convenience script at [https://get.docker.com/](https://get.docker.com/) to install Docker into development environments non-interactively. The convenience script isn't recommended for production environments, but it's useful for creating a provisioning script tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and you can find it in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n*   The script requires `root` or `sudo` privileges to run.\n*   The script attempts to detect your Linux distribution and version and configure your package management system for you.\n*   The script doesn't allow you to customize most installation parameters.\n*   The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n*   By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test upgrades in a test environment before deploying to your production systems.\n*   The script isn't designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, resulting in outdated versions.\n\n> **Tip: preview script steps before running**\n> \n> You can run the script with the `--dry-run` option to learn what steps the script will run when invoked:\n\nThis example downloads the script from [https://get.docker.com/](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\nYou have now successfully installed and started Docker Engine. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users can't run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n> \n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user). You can also install Docker without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](https://docs.docker.com/engine/security/rootless/).\n\n#### [Install pre-releases](#install-pre-releases)\n\nDocker also provides a convenience script at [https://test.docker.com/](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equal to the script at `get.docker.com`, but configures your package manager to use the test channel of the Docker package repository. The test channel includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they're released as stable.\n\nTo install the latest version of Docker on Linux from the test channel, run:\n\n#### [Upgrade Docker after using the convenience script](#upgrade-docker-after-using-the-convenience-script)\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There's no advantage to re-running the convenience script. Re-running it can cause issues if it attempts to re-install repositories which already exist on the host machine.\n\n1.  Uninstall the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n2.  Images, containers, volumes, or custom configuration files on your host aren't automatically removed. To delete all images, containers, and volumes:\n    \n\nYou have to delete any edited configuration files manually.\n\n*   Continue to [Post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/).",
  "title": "Install Docker Engine on Raspberry Pi OS (32-bit) | Docker Docs\n",
  "description": "Learn how to install Docker Engine on a 32-bit Raspberry Pi OS system. These instructions cover the different installation methods, how to uninstall, and next steps.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/configs/",
  "markdown": "# Store configuration data using Docker Configs\n\nDocker swarm service configs allow you to store non-sensitive information, such as configuration files, outside a service's image or running containers. This allows you to keep your images as generic as possible, without the need to bind-mount configuration files into the containers or use environment variables.\n\nConfigs operate in a similar way to [secrets](https://docs.docker.com/engine/swarm/secrets/), except that they are not encrypted at rest and are mounted directly into the container's filesystem without the use of RAM disks. Configs can be added or removed from a service at any time, and services can share a config. You can even use configs in conjunction with environment variables or labels, for maximum flexibility. Config values can be generic strings or binary content (up to 500 kb in size).\n\n> **Note**\n> \n> Docker configs are only available to swarm services, not to standalone containers. To use this feature, consider adapting your container to run as a service with a scale of 1.\n\nConfigs are supported on both Linux and Windows services.\n\n### [Windows support](#windows-support)\n\nDocker includes support for configs on Windows containers, but there are differences in the implementations, which are called out in the examples below. Keep the following notable differences in mind:\n\n*   Config files with custom targets are not directly bind-mounted into Windows containers, since Windows does not support non-directory file bind-mounts. Instead, configs for a container are all mounted in `C:\\ProgramData\\Docker\\internal\\configs` (an implementation detail which should not be relied upon by applications) within the container. Symbolic links are used to point from there to the desired target of the config within the container. The default target is `C:\\ProgramData\\Docker\\configs`.\n    \n*   When creating a service which uses Windows containers, the options to specify UID, GID, and mode are not supported for configs. Configs are currently only accessible by administrators and users with `system` access within the container.\n    \n*   On Windows, create or update a service using `--credential-spec` with the `config://<config-name>` format. This passes the gMSA credentials file directly to nodes before a container starts. No gMSA credentials are written to disk on worker nodes. For more information, refer to [Deploy services to a swarm](https://docs.docker.com/engine/swarm/services/#gmsa-for-swarm).\n    \n\nWhen you add a config to the swarm, Docker sends the config to the swarm manager over a mutual TLS connection. The config is stored in the Raft log, which is encrypted. The entire Raft log is replicated across the other managers, ensuring the same high availability guarantees for configs as for the rest of the swarm management data.\n\nWhen you grant a newly-created or running service access to a config, the config is mounted as a file in the container. The location of the mount point within the container defaults to `/<config-name>` in Linux containers. In Windows containers, configs are all mounted into `C:\\ProgramData\\Docker\\configs` and symbolic links are created to the desired location, which defaults to `C:\\<config-name>`.\n\nYou can set the ownership (`uid` and `gid`) for the config, using either the numerical ID or the name of the user or group. You can also specify the file permissions (`mode`). These settings are ignored for Windows containers.\n\n*   If not set, the config is owned by the user running the container command (often `root`) and that user's default group (also often `root`).\n*   If not set, the config has world-readable permissions (mode `0444`), unless a `umask` is set within the container, in which case the mode is impacted by that `umask` value.\n\nYou can update a service to grant it access to additional configs or revoke its access to a given config at any time.\n\nA node only has access to configs if the node is a swarm manager or if it is running service tasks which have been granted access to the config. When a container task stops running, the configs shared to it are unmounted from the in-memory filesystem for that container and flushed from the node's memory.\n\nIf a node loses connectivity to the swarm while it is running a task container with access to a config, the task container still has access to its configs, but cannot receive updates until the node reconnects to the swarm.\n\nYou can add or inspect an individual config at any time, or list all configs. You cannot remove a config that a running service is using. See [Rotate a config](https://docs.docker.com/engine/swarm/configs/#example-rotate-a-config) for a way to remove a config without disrupting running services.\n\nTo update or roll back configs more easily, consider adding a version number or date to the config name. This is made easier by the ability to control the mount point of the config within a given container.\n\nTo update a stack, make changes to your Compose file, then re-run `docker stack deploy -c <new-compose-file> <stack-name>`. If you use a new config in that file, your services start using them. Keep in mind that configurations are immutable, so you can't change the file for an existing service. Instead, you create a new config to use a different file\n\nYou can run `docker stack rm` to stop the app and take down the stack. This removes any config that was created by `docker stack deploy` with the same stack name. This removes _all_ configs, including those not referenced by services and those remaining after a `docker service update --config-rm`.\n\nUse these links to read about specific commands, or continue to the [example about using configs with a service](#advanced-example-use-configs-with-a-nginx-service).\n\n*   [`docker config create`](https://docs.docker.com/reference/cli/docker/config/create/)\n*   [`docker config inspect`](https://docs.docker.com/reference/cli/docker/config/inspect/)\n*   [`docker config ls`](https://docs.docker.com/reference/cli/docker/config/ls/)\n*   [`docker config rm`](https://docs.docker.com/reference/cli/docker/config/rm/)\n\nThis section includes graduated examples which illustrate how to use Docker configs.\n\n> **Note**\n> \n> These examples use a single-engine swarm and unscaled services for simplicity. The examples use Linux containers, but Windows containers also support configs.\n\n### [Defining and using configs in compose files](#defining-and-using-configs-in-compose-files)\n\nThe `docker stack` command supports defining configs in a Compose file. However, the `configs` key is not supported for `docker compose`. See [the Compose file reference](https://docs.docker.com/compose/compose-file/legacy-versions/) for details.\n\n### [Simple example: Get started with configs](#simple-example-get-started-with-configs)\n\nThis simple example shows how configs work in just a few commands. For a real-world example, continue to [Advanced example: Use configs with a Nginx service](#advanced-example-use-configs-with-a-nginx-service).\n\n1.  Add a config to Docker. The `docker config create` command reads standard input because the last argument, which represents the file to read the config from, is set to `-`.\n    \n2.  Create a `redis` service and grant it access to the config. By default, the container can access the config at `/my-config`, but you can customize the file name on the container using the `target` option.\n    \n3.  Verify that the task is running without issues using `docker service ps`. If everything is working, the output looks similar to this:\n    \n4.  Get the ID of the `redis` service task container using `docker ps`, so that you can use `docker container exec` to connect to the container and read the contents of the config data file, which defaults to being readable by all and has the same name as the name of the config. The first command below illustrates how to find the container ID, and the second and third commands use shell completion to do this automatically.\n    \n5.  Try removing the config. The removal fails because the `redis` service is running and has access to the config.\n    \n6.  Remove access to the config from the running `redis` service by updating the service.\n    \n7.  Repeat steps 3 and 4 again, verifying that the service no longer has access to the config. The container ID is different, because the `service update` command redeploys the service.\n    \n8.  Stop and remove the service, and remove the config from Docker.\n    \n\n### [Simple example: Use configs in a Windows service](#simple-example-use-configs-in-a-windows-service)\n\nThis is a very simple example which shows how to use configs with a Microsoft IIS service running on Docker for Windows running Windows containers on Microsoft Windows 10. It is a naive example that stores the webpage in a config.\n\nThis example assumes that you have PowerShell installed.\n\n1.  Save the following into a new file `index.html`.\n    \n2.  If you have not already done so, initialize or join the swarm.\n    \n3.  Save the `index.html` file as a swarm config named `homepage`.\n    \n4.  Create an IIS service and grant it access to the `homepage` config.\n    \n5.  Access the IIS service at `http://localhost:8000/`. It should serve the HTML content from the first step.\n    \n6.  Remove the service and the config.\n    \n\n### [Example: Use a templated config](#example-use-a-templated-config)\n\nTo create a configuration in which the content will be generated using a template engine, use the `--template-driver` parameter and specify the engine name as its argument. The template will be rendered when container is created.\n\n1.  Save the following into a new file `index.html.tmpl`.\n    \n2.  Save the `index.html.tmpl` file as a swarm config named `homepage`. Provide parameter `--template-driver` and specify `golang` as template engine.\n    \n3.  Create a service that runs Nginx and has access to the environment variable HELLO and to the config.\n    \n4.  Verify that the service is operational: you can reach the Nginx server, and that the correct output is being served.\n    \n\n### [Advanced example: Use configs with a Nginx service](#advanced-example-use-configs-with-a-nginx-service)\n\nThis example is divided into two parts. [The first part](#generate-the-site-certificate) is all about generating the site certificate and does not directly involve Docker configs at all, but it sets up [the second part](#configure-the-nginx-container), where you store and use the site certificate as a series of secrets and the Nginx configuration as a config. The example shows how to set options on the config, such as the target location within the container and the file permissions (`mode`).\n\n#### [Generate the site certificate](#generate-the-site-certificate)\n\nGenerate a root CA and TLS certificate and key for your site. For production sites, you may want to use a service such as `Letâ€™s Encrypt` to generate the TLS certificate and key, but this example uses command-line tools. This step is a little complicated, but is only a set-up step so that you have something to store as a Docker secret. If you want to skip these sub-steps, you can [use Let's Encrypt](https://letsencrypt.org/getting-started/) to generate the site key and certificate, name the files `site.key` and `site.crt`, and skip to [Configure the Nginx container](#configure-the-nginx-container).\n\n1.  Generate a root key.\n    \n2.  Generate a CSR using the root key.\n    \n3.  Configure the root CA. Edit a new file called `root-ca.cnf` and paste the following contents into it. This constrains the root CA to only sign leaf certificates and not intermediate CAs.\n    \n4.  Sign the certificate.\n    \n5.  Generate the site key.\n    \n6.  Generate the site certificate and sign it with the site key.\n    \n7.  Configure the site certificate. Edit a new file called `site.cnf` and paste the following contents into it. This constrains the site certificate so that it can only be used to authenticate a server and can't be used to sign certificates.\n    \n8.  Sign the site certificate.\n    \n9.  The `site.csr` and `site.cnf` files are not needed by the Nginx service, but you need them if you want to generate a new site certificate. Protect the `root-ca.key` file.\n    \n\n#### [Configure the Nginx container](#configure-the-nginx-container)\n\n1.  Produce a very basic Nginx configuration that serves static files over HTTPS. The TLS certificate and key are stored as Docker secrets so that they can be rotated easily.\n    \n    In the current directory, create a new file called `site.conf` with the following contents:\n    \n2.  Create two secrets, representing the key and the certificate. You can store any file as a secret as long as it is smaller than 500 KB. This allows you to decouple the key and certificate from the services that use them. In these examples, the secret name and the file name are the same.\n    \n3.  Save the `site.conf` file in a Docker config. The first parameter is the name of the config, and the second parameter is the file to read it from.\n    \n    List the configs:\n    \n4.  Create a service that runs Nginx and has access to the two secrets and the config. Set the mode to `0440` so that the file is only readable by its owner and that owner's group, not the world.\n    \n    Within the running containers, the following three files now exist:\n    \n    *   `/run/secrets/site.key`\n    *   `/run/secrets/site.crt`\n    *   `/etc/nginx/conf.d/site.conf`\n5.  Verify that the Nginx service is running.\n    \n6.  Verify that the service is operational: you can reach the Nginx server, and that the correct TLS certificate is being used.\n    \n7.  Unless you are going to continue to the next example, clean up after running this example by removing the `nginx` service and the stored secrets and config.\n    \n\nYou have now configured a Nginx service with its configuration decoupled from its image. You could run multiple sites with exactly the same image but separate configurations, without the need to build a custom image at all.\n\n### [Example: Rotate a config](#example-rotate-a-config)\n\nTo rotate a config, you first save a new config with a different name than the one that is currently in use. You then redeploy the service, removing the old config and adding the new config at the same mount point within the container. This example builds upon the previous one by rotating the `site.conf` configuration file.\n\n1.  Edit the `site.conf` file locally. Add `index.php` to the `index` line, and save the file.\n    \n2.  Create a new Docker config using the new `site.conf`, called `site-v2.conf`.\n    \n3.  Update the `nginx` service to use the new config instead of the old one.\n    \n4.  Verify that the `nginx` service is fully re-deployed, using `docker service ps nginx`. When it is, you can remove the old `site.conf` config.\n    \n5.  To clean up, you can remove the `nginx` service, as well as the secrets and configs.\n    \n\nYou have now updated your `nginx` service's configuration without the need to rebuild its image.",
  "title": "Store configuration data using Docker Configs | Docker Docs\n",
  "description": "How to store configuration data separate from the runtime",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/security/trust/trust_delegation/",
  "markdown": "# Delegations for content trust | Docker Docs\n\nDelegations in Docker Content Trust (DCT) allow you to control who can and cannot sign an image tag. A delegation will have a pair of private and public delegation keys. A delegation could contain multiple pairs of keys and contributors in order to a) allow multiple users to be part of a delegation, and b) to support key rotation.\n\nThe most important delegation within Docker Content Trust is `targets/releases`. This is seen as the canonical source of a trusted image tag, and without a contributor's key being under this delegation, they will be unable to sign a tag.\n\nFortunately when using the `$ docker trust` commands, we will automatically initialize a repository, manage the repository keys, and add a collaborator's key to the `targets/releases` delegation via `docker trust signer add`.\n\nBy default, the `$ docker trust` commands expect the notary server URL to be the same as the registry URL specified in the image tag (following a similar logic to `$ docker push`). When using Docker Hub or DTR, the notary server URL is the same as the registry URL. However, for self-hosted environments or 3rd party registries, you will need to specify an alternative URL for the notary server. This is done with:\n\nIf you do not export this variable in self-hosted environments, you may see errors such as:\n\nIf you have enabled authentication for your notary server, or are using DTR, you will need to log in before you can push data to the notary server.\n\nIf you do not log in, you will see:\n\nSome of the more advanced features of DCT require the Notary CLI. To install and configure the Notary CLI:\n\n1.  Download the [client](https://github.com/theupdateframework/notary/releases) and ensure that it is available on your path.\n    \n2.  Create a configuration file at `~/.notary/config.json` with the following content:\n    \n\nThe newly created configuration file contains information about the location of your local Docker trust data and the notary server URL.\n\nFor more detailed information about how to use notary outside of the Docker Content Trust use cases, refer to the Notary CLI documentation [here](https://github.com/theupdateframework/notary/blob/master/docs/command_reference.md)\n\nA prerequisite to adding your first contributor is a pair of delegation keys. These keys can either be generated locally using `$ docker trust`, generated by a certificate authority.\n\n### [Using Docker Trust to generate keys](#using-docker-trust-to-generate-keys)\n\nDocker trust has a built-in generator for a delegation key pair, `$ docker trust generate <name>`. Running this command will automatically load the delegation private key in to the local Docker trust store.\n\n### [Manually generating keys](#manually-generating-keys)\n\nIf you need to manually generate a private key (either RSA or ECDSA) and a x509 certificate containing the public key, you can use local tools like openssl or cfssl along with a local or company-wide Certificate Authority.\n\nHere is an example of how to generate a 2048-bit RSA portion key (all RSA keys must be at least 2048 bits):\n\nThey should keep `delegation.key` private because it is used to sign tags.\n\nThen they need to generate an x509 certificate containing the public key, which is what you need from them. Here is the command to generate a CSR (certificate signing request):\n\nThen they can send it to whichever CA you trust to sign certificates, or they can self-sign the certificate (in this example, creating a certificate that is valid for 1 year):\n\nThen they need to give you `delegation.crt`, whether it is self-signed or signed by a CA.\n\nFinally you will need to add the private key into your local Docker trust store.\n\n### [Viewing local delegation keys](#viewing-local-delegation-keys)\n\nTo list the keys that have been imported in to the local Docker trust store we can use the Notary CLI.\n\nWhen the first delegation is added to the Notary Server using `$ docker trust`, we automatically initiate trust data for the repository. This includes creating the notary target and snapshots keys, and rotating the snapshot key to be managed by the notary server. More information on these keys can be found [here](https://docs.docker.com/engine/security/trust/trust_key_mng/)\n\nWhen initiating a repository, you will need the key and the passphrase of a local Notary Canonical Root Key. If you have not initiated a repository before, and therefore don't have a Notary root key, `$ docker trust` will create one for you.\n\n> **Important**\n> \n> Be sure to protect and back up your [Notary Canonical Root Key](https://docs.docker.com/engine/security/trust/trust_key_mng/).\n\n### [Initiating the repository](#initiating-the-repository)\n\nTo upload the first key to a delegation, at the same time initiating a repository, you can use the `$ docker trust signer add` command. This will add the contributor's public key to the `targets/releases` delegation, and create a second `targets/<name>` delegation.\n\nFor DCT the name of the second delegation, in the below example `jeff`, is there to help you keep track of the owner of the keys. In more advanced use cases of Notary additional delegations are used for hierarchy.\n\nYou can see which keys have been pushed to the Notary server for each repository with the `$ docker trust inspect` command.\n\nYou could also use the Notary CLI to list delegations and keys. Here you can clearly see the keys were attached to `targets/releases` and `targets/jeff`.\n\n### [Adding additional signers](#adding-additional-signers)\n\nDocker Trust allows you to configure multiple delegations per repository, allowing you to manage the lifecycle of delegations. When adding additional delegations with `$ docker trust` the collaborators key is once again added to the `targets/release` role.\n\n> Note you will need the passphrase for the repository key; this would have been configured when you first initiated the repository.\n\nCheck to prove that there are now 2 delegations (Signer).\n\n### [Adding keys to an existing delegation](#adding-keys-to-an-existing-delegation)\n\nTo support things like key rotation and expiring / retiring keys you can publish multiple contributor keys per delegation. The only prerequisite here is to make sure you use the same the delegation name, in this case `jeff`. Docker trust will automatically handle adding this new key to `targets/releases`.\n\n> **Note**\n> \n> You will need the passphrase for the repository key; this would have been configured when you first initiated the repository.\n\nCheck to prove that the delegation (Signer) now contains multiple Key IDs.\n\n### [Removing a delegation](#removing-a-delegation)\n\nIf you need to remove a delegation, including the contributor keys that are attached to the `targets/releases` role, you can use the `$ docker trust signer remove` command.\n\n> **Note**\n> \n> Tags that were signed by the removed delegation will need to be resigned by an active delegation\n\n#### [Troubleshooting](#troubleshooting)\n\n1.  If you see an error that there are no usable keys in `targets/releases`, you will need to add additional delegations using `docker trust signer add` before resigning images.\n    \n2.  If you have added additional delegations already and are seeing an error message that there are no valid signatures in `targest/releases`, you will need to resign the `targets/releases` delegation file with the Notary CLI.\n    \n    Resigning the delegation file is done with the `$ notary witness` command\n    \n    More information on the `$ notary witness` command can be found [here](https://github.com/theupdateframework/notary/blob/master/docs/advanced_usage.md#recovering-a-delegation)\n    \n\n### [Removing a contributor's key from a delegation](#removing-a-contributors-key-from-a-delegation)\n\nAs part of rotating keys for a delegation, you may want to remove an individual key but retain the delegation. This can be done with the Notary CLI.\n\nRemember you will have to remove the key from both the `targets/releases` role and the role specific to that signer `targets/<name>`.\n\n1.  We will need to grab the Key ID from the Notary Server\n    \n2.  Remove from the `targets/releases` delegation\n    \n3.  Remove from the `targets/<name>` delegation\n    \n4.  Check the remaining delegation list\n    \n\n### [Removing a local delegation private key](#removing-a-local-delegation-private-key)\n\nAs part of rotating delegation keys, you may need to remove a local delegation key from the local Docker trust store. This is done with the Notary CLI, using the `$ notary key remove` command.\n\n1.  We will need to get the Key ID from the local Docker Trust store\n    \n2.  Remove the key from the local Docker Trust store\n    \n\nYou can remove all trust data from a repository, including repository, target, snapshot and all delegations keys using the Notary CLI.\n\nThis is often required by a container registry before a particular repository can be deleted.\n\n*   [Content trust in Docker](https://docs.docker.com/engine/security/trust/)\n*   [Manage keys for content trust](https://docs.docker.com/engine/security/trust/trust_key_mng/)\n*   [Automation with content trust](https://docs.docker.com/engine/security/trust/trust_automation/)\n*   [Play in a content trust sandbox](https://docs.docker.com/engine/security/trust/trust_sandbox/)",
  "title": "Delegations for content trust | Docker Docs\n",
  "description": "Delegations for content trust",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/swarm_manager_locking/",
  "markdown": "# Lock your swarm to protect its encryption key\n\nThe Raft logs used by swarm managers are encrypted on disk by default. This at-rest encryption protects your service's configuration and data from attackers who gain access to the encrypted Raft logs. One of the reasons this feature was introduced was in support of the [Docker secrets](https://docs.docker.com/engine/swarm/secrets/) feature.\n\nWhen Docker restarts, both the TLS key used to encrypt communication among swarm nodes and the key used to encrypt and decrypt Raft logs on disk are loaded into each manager node's memory. Docker has the ability to protect the mutual TLS encryption key and the key used to encrypt and decrypt Raft logs at rest, by allowing you to take ownership of these keys and to require manual unlocking of your managers. This feature is called autolock.\n\nWhen Docker restarts, you must [unlock the swarm](#unlock-a-swarm) first, using a key encryption key generated by Docker when the swarm was locked. You can rotate this key encryption key at any time.\n\n> **Note**\n> \n> You don't need to unlock the swarm when a new node joins the swarm, because the key is propagated to it over mutual TLS.\n\nWhen you initialize a new swarm, you can use the `--autolock` flag to enable autolocking of swarm manager nodes when Docker restarts.\n\nStore the key in a safe place, such as in a password manager.\n\nWhen Docker restarts, you need to [unlock the swarm](#unlock-a-swarm). A locked swarm causes an error like the following when you try to start or restart a service:\n\nTo enable autolock on an existing swarm, set the `autolock` flag to `true`.\n\nTo disable autolock, set `--autolock` to `false`. The mutual TLS key and the encryption key used to read and write Raft logs are stored unencrypted on disk. There is a trade-off between the risk of storing the encryption key unencrypted at rest and the convenience of restarting a swarm without needing to unlock each manager.\n\nKeep the unlock key around for a short time after disabling autolocking, in case a manager goes down while it is still configured to lock using the old key.\n\nTo unlock a locked swarm, use `docker swarm unlock`.\n\nEnter the encryption key that was generated and shown in the command output when you locked the swarm or rotated the key, and the swarm unlocks.\n\nConsider a situation where your swarm is running as expected, then a manager node becomes unavailable. You troubleshoot the problem and bring the physical node back online, but you need to unlock the manager by providing the unlock key to read the encrypted credentials and Raft logs.\n\nIf the key has not been rotated since the node left the swarm, and you have a quorum of functional manager nodes in the swarm, you can view the current unlock key using `docker swarm unlock-key` without any arguments.\n\nIf the key was rotated after the swarm node became unavailable and you do not have a record of the previous key, you may need to force the manager to leave the swarm and join it back to the swarm as a new manager.\n\nYou should rotate the locked swarm's unlock key on a regular schedule.\n\n> **Warning**\n> \n> When you rotate the unlock key, keep a record of the old key around for a few minutes, so that if a manager goes down before it gets the new key, it may still be unlocked with the old one.",
  "title": "Lock your swarm to protect its encryption key | Docker Docs\n",
  "description": "Automatically lock Swarm managers to protect encryption keys",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/install/binaries/",
  "markdown": "# Install Docker Engine from binaries\n\n> **Important**\n> \n> This page contains information on how to install Docker using binaries. These instructions are mostly suitable for testing purposes. We do not recommend installing Docker using binaries in production environments as they don't have automatic security updates. The Linux binaries described on this page are statically linked, which means that vulnerabilities in build-time dependencies are not automatically patched by security updates of your Linux distribution.\n> \n> Updating binaries is also slightly more involved when compared to Docker packages installed using a package manager or through Docker Desktop, as it requires (manually) updating the installed version whenever there is a new release of Docker.\n> \n> Also, static binaries may not include all functionalities provided by the dynamic packages.\n> \n> On Windows and Mac, we recommend that you install [Docker Desktop](https://docs.docker.com/desktop/) instead. For Linux, we recommend that you follow the instructions specific for your distribution.\n\nIf you want to try Docker or use it in a testing environment, but you're not on a supported platform, you can try installing from static binaries. If possible, you should use packages built for your operating system, and use your operating system's package management system to manage Docker installation and upgrades.\n\nStatic binaries for the Docker daemon binary are only available for Linux (as `dockerd`) and Windows (as `dockerd.exe`). Static binaries for the Docker client are available for Linux, Windows, and macOS (as `docker`).\n\nThis topic discusses binary installation for Linux, Windows, and macOS:\n\n*   [Install daemon and client binaries on Linux](#install-daemon-and-client-binaries-on-linux)\n*   [Install client binaries on macOS](#install-client-binaries-on-macos)\n*   [Install server and client binaries on Windows](#install-server-and-client-binaries-on-windows)\n\n### [Prerequisites](#prerequisites)\n\nBefore attempting to install Docker from binaries, be sure your host machine meets the prerequisites:\n\n*   A 64-bit installation\n*   Version 3.10 or higher of the Linux kernel. The latest version of the kernel available for your platform is recommended.\n*   `iptables` version 1.4 or higher\n*   `git` version 1.7 or higher\n*   A `ps` executable, usually provided by `procps` or a similar package.\n*   [XZ Utils](https://tukaani.org/xz/) 4.9 or higher\n*   A [properly mounted](https://github.com/tianon/cgroupfs-mount/blob/master/cgroupfs-mount) `cgroupfs` hierarchy; a single, all-encompassing `cgroup` mount point is not sufficient. See Github issues [#2683](https://github.com/moby/moby/issues/2683), [#3485](https://github.com/moby/moby/issues/3485), [#4568](https://github.com/moby/moby/issues/4568)).\n\n#### [Secure your environment as much as possible](#secure-your-environment-as-much-as-possible)\n\n##### [OS considerations](#os-considerations)\n\nEnable SELinux or AppArmor if possible.\n\nIt is recommended to use AppArmor or SELinux if your Linux distribution supports either of the two. This helps improve security and blocks certain types of exploits. Review the documentation for your Linux distribution for instructions for enabling and configuring AppArmor or SELinux.\n\n> **Security warning**\n> \n> If either of the security mechanisms is enabled, do not disable it as a work-around to make Docker or its containers run. Instead, configure it correctly to fix any problems.\n\n##### [Docker daemon considerations](#docker-daemon-considerations)\n\n*   Enable `seccomp` security profiles if possible. See [Enabling `seccomp` for Docker](https://docs.docker.com/engine/security/seccomp/).\n    \n*   Enable user namespaces if possible. See the [Daemon user namespace options](https://docs.docker.com/reference/cli/dockerd/#daemon-user-namespace-options).\n    \n\n### [Install static binaries](#install-static-binaries)\n\n1.  Download the static binary archive. Go to [https://download.docker.com/linux/static/stable/](https://download.docker.com/linux/static/stable/), choose your hardware platform, and download the `.tgz` file relating to the version of Docker Engine you want to install.\n    \n2.  Extract the archive using the `tar` utility. The `dockerd` and `docker` binaries are extracted.\n    \n3.  **Optional**: Move the binaries to a directory on your executable path, such as `/usr/bin/`. If you skip this step, you must provide the path to the executable when you invoke `docker` or `dockerd` commands.\n    \n4.  Start the Docker daemon:\n    \n    If you need to start the daemon with additional options, modify the above command accordingly or create and edit the file `/etc/docker/daemon.json` to add the custom configuration options.\n    \n5.  Verify that Docker is installed correctly by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why youâ€™re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n> **Note**\n> \n> The following instructions are mostly suitable for testing purposes. The macOS binary includes the Docker client only. It does not include the `dockerd` daemon which is required to run containers. Therefore, we recommend that you install [Docker Desktop](https://docs.docker.com/desktop/) instead.\n\nThe binaries for Mac also do not contain:\n\n*   A runtime environment. You must set up a functional engine either in a Virtual Machine, or on a remote Linux machine.\n*   Docker components such as `buildx` and `docker compose`.\n\nTo install client binaries, perform the following steps:\n\n1.  Download the static binary archive. Go to [https://download.docker.com/mac/static/stable/](https://download.docker.com/mac/static/stable/) and select `x86_64` (for Mac on Intel chip) or `aarch64` (for Mac on Apple silicon), and then download the `.tgz` file relating to the version of Docker Engine you want to install.\n    \n2.  Extract the archive using the `tar` utility. The `docker` binary is extracted.\n    \n3.  Clear the extended attributes to allow it run.\n    \n    Now, when you run the following command, you can see the Docker CLI usage instructions:\n    \n4.  **Optional**: Move the binary to a directory on your executable path, such as `/usr/local/bin/`. If you skip this step, you must provide the path to the executable when you invoke `docker` or `dockerd` commands.\n    \n5.  Verify that Docker is installed correctly by running the `hello-world` image. The value of `<hostname>` is a hostname or IP address running the Docker daemon and accessible to the client.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n    \n\n> **Note**\n> \n> The following section describes how to install the Docker daemon on Windows Server which allows you to run Windows containers only. When you install the Docker daemon on Windows Server, the daemon doesn't contain Docker components such as `buildx` and `compose`. If you're running Windows 10 or 11, we recommend that you install [Docker Desktop](https://docs.docker.com/desktop/) instead.\n\nBinary packages on Windows include both `dockerd.exe` and `docker.exe`. On Windows, these binaries only provide the ability to run native Windows containers (not Linux containers).\n\nTo install server and client binaries, perform the following steps:\n\n1.  Download the static binary archive. Go to [https://download.docker.com/win/static/stable/x86\\_64](https://download.docker.com/win/static/stable/x86_64) and select the latest version from the list.\n    \n2.  Run the following PowerShell commands to install and extract the archive to your program files:\n    \n3.  Register the service and start the Docker Engine:\n    \n4.  Verify that Docker is installed correctly by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n    \n\nTo upgrade your manual installation of Docker Engine, first stop any `dockerd` or `dockerd.exe` processes running locally, then follow the regular installation steps to install the new version on top of the existing version.\n\n*   Continue to [Post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/).",
  "title": "Install Docker Engine from binaries | Docker Docs\n",
  "description": "Learn how to install Docker as a binary. These instructions are most suitable for testing purposes.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/secrets/",
  "markdown": "# Manage sensitive data with Docker secrets\n\nIn terms of Docker Swarm services, a _secret_ is a blob of data, such as a password, SSH private key, SSL certificate, or another piece of data that should not be transmitted over a network or stored unencrypted in a Dockerfile or in your application's source code. You can use Docker _secrets_ to centrally manage this data and securely transmit it to only those containers that need access to it. Secrets are encrypted during transit and at rest in a Docker swarm. A given secret is only accessible to those services which have been granted explicit access to it, and only while those service tasks are running.\n\nYou can use secrets to manage any sensitive data which a container needs at runtime but you don't want to store in the image or in source control, such as:\n\n*   Usernames and passwords\n*   TLS certificates and keys\n*   SSH keys\n*   Other important data such as the name of a database or internal server\n*   Generic strings or binary content (up to 500 kb in size)\n\n> **Note**\n> \n> Docker secrets are only available to swarm services, not to standalone containers. To use this feature, consider adapting your container to run as a service. Stateful containers can typically run with a scale of 1 without changing the container code.\n\nAnother use case for using secrets is to provide a layer of abstraction between the container and a set of credentials. Consider a scenario where you have separate development, test, and production environments for your application. Each of these environments can have different credentials, stored in the development, test, and production swarms with the same secret name. Your containers only need to know the name of the secret to function in all three environments.\n\nYou can also use secrets to manage non-sensitive data, such as configuration files. However, Docker supports the use of [configs](https://docs.docker.com/engine/swarm/configs/) for storing non-sensitive data. Configs are mounted into the container's filesystem directly, without the use of a RAM disk.\n\n### [Windows support](#windows-support)\n\nDocker includes support for secrets on Windows containers. Where there are differences in the implementations, they are called out in the examples below. Keep the following notable differences in mind:\n\n*   Microsoft Windows has no built-in driver for managing RAM disks, so within running Windows containers, secrets are persisted in clear text to the container's root disk. However, the secrets are explicitly removed when a container stops. In addition, Windows does not support persisting a running container as an image using `docker commit` or similar commands.\n    \n*   On Windows, we recommend enabling [BitLocker](https://technet.microsoft.com/en-us/library/cc732774%28v=ws.11%29.aspx) on the volume containing the Docker root directory on the host machine to ensure that secrets for running containers are encrypted at rest.\n    \n*   Secret files with custom targets are not directly bind-mounted into Windows containers, since Windows does not support non-directory file bind-mounts. Instead, secrets for a container are all mounted in `C:\\ProgramData\\Docker\\internal\\secrets` (an implementation detail which should not be relied upon by applications) within the container. Symbolic links are used to point from there to the desired target of the secret within the container. The default target is `C:\\ProgramData\\Docker\\secrets`.\n    \n*   When creating a service which uses Windows containers, the options to specify UID, GID, and mode are not supported for secrets. Secrets are currently only accessible by administrators and users with `system` access within the container.\n    \n\nWhen you add a secret to the swarm, Docker sends the secret to the swarm manager over a mutual TLS connection. The secret is stored in the Raft log, which is encrypted. The entire Raft log is replicated across the other managers, ensuring the same high availability guarantees for secrets as for the rest of the swarm management data.\n\nWhen you grant a newly-created or running service access to a secret, the decrypted secret is mounted into the container in an in-memory filesystem. The location of the mount point within the container defaults to `/run/secrets/<secret_name>` in Linux containers, or `C:\\ProgramData\\Docker\\secrets` in Windows containers. You can also specify a custom location.\n\nYou can update a service to grant it access to additional secrets or revoke its access to a given secret at any time.\n\nA node only has access to (encrypted) secrets if the node is a swarm manager or if it is running service tasks which have been granted access to the secret. When a container task stops running, the decrypted secrets shared to it are unmounted from the in-memory filesystem for that container and flushed from the node's memory.\n\nIf a node loses connectivity to the swarm while it is running a task container with access to a secret, the task container still has access to its secrets, but cannot receive updates until the node reconnects to the swarm.\n\nYou can add or inspect an individual secret at any time, or list all secrets. You cannot remove a secret that a running service is using. See [Rotate a secret](https://docs.docker.com/engine/swarm/secrets/#example-rotate-a-secret) for a way to remove a secret without disrupting running services.\n\nTo update or roll back secrets more easily, consider adding a version number or date to the secret name. This is made easier by the ability to control the mount point of the secret within a given container.\n\nUse these links to read about specific commands, or continue to the [example about using secrets with a service](https://docs.docker.com/engine/swarm/secrets/#simple-example-get-started-with-secrets).\n\n*   [`docker secret create`](https://docs.docker.com/reference/cli/docker/secret/create/)\n*   [`docker secret inspect`](https://docs.docker.com/reference/cli/docker/secret/inspect/)\n*   [`docker secret ls`](https://docs.docker.com/reference/cli/docker/secret/ls/)\n*   [`docker secret rm`](https://docs.docker.com/reference/cli/docker/secret/rm/)\n*   [`--secret`](https://docs.docker.com/reference/cli/docker/service/create/#secret) flag for `docker service create`\n*   [`--secret-add` and `--secret-rm`](https://docs.docker.com/reference/cli/docker/service/update/#secret-add) flags for `docker service update`\n\nThis section includes three graduated examples which illustrate how to use Docker secrets. The images used in these examples have been updated to make it easier to use Docker secrets. To find out how to modify your own images in a similar way, see [Build support for Docker Secrets into your images](#build-support-for-docker-secrets-into-your-images).\n\n> **Note**\n> \n> These examples use a single-Engine swarm and unscaled services for simplicity. The examples use Linux containers, but Windows containers also support secrets. See [Windows support](#windows-support).\n\n### [Defining and using secrets in compose files](#defining-and-using-secrets-in-compose-files)\n\nBoth the `docker-compose` and `docker stack` commands support defining secrets in a compose file. See [the Compose file reference](https://docs.docker.com/compose/compose-file/legacy-versions/) for details.\n\n### [Simple example: Get started with secrets](#simple-example-get-started-with-secrets)\n\nThis simple example shows how secrets work in just a few commands. For a real-world example, continue to [Intermediate example: Use secrets with a Nginx service](#intermediate-example-use-secrets-with-a-nginx-service).\n\n1.  Add a secret to Docker. The `docker secret create` command reads standard input because the last argument, which represents the file to read the secret from, is set to `-`.\n    \n2.  Create a `redis` service and grant it access to the secret. By default, the container can access the secret at `/run/secrets/<secret_name>`, but you can customize the file name on the container using the `target` option.\n    \n3.  Verify that the task is running without issues using `docker service ps`. If everything is working, the output looks similar to this:\n    \n    If there were an error, and the task were failing and repeatedly restarting, you would see something like this:\n    \n4.  Get the ID of the `redis` service task container using `docker ps` , so that you can use `docker container exec` to connect to the container and read the contents of the secret data file, which defaults to being readable by all and has the same name as the name of the secret. The first command below illustrates how to find the container ID, and the second and third commands use shell completion to do this automatically.\n    \n5.  Verify that the secret is not available if you commit the container.\n    \n6.  Try removing the secret. The removal fails because the `redis` service is running and has access to the secret.\n    \n7.  Remove access to the secret from the running `redis` service by updating the service.\n    \n8.  Repeat steps 3 and 4 again, verifying that the service no longer has access to the secret. The container ID is different, because the `service update` command redeploys the service.\n    \n9.  Stop and remove the service, and remove the secret from Docker.\n    \n\n### [Simple example: Use secrets in a Windows service](#simple-example-use-secrets-in-a-windows-service)\n\nThis is a very simple example which shows how to use secrets with a Microsoft IIS service running on Docker for Windows running Windows containers on Microsoft Windows 10. It is a naive example that stores the webpage in a secret.\n\nThis example assumes that you have PowerShell installed.\n\n1.  Save the following into a new file `index.html`.\n    \n2.  If you have not already done so, initialize or join the swarm.\n    \n3.  Save the `index.html` file as a swarm secret named `homepage`.\n    \n4.  Create an IIS service and grant it access to the `homepage` secret.\n    \n    > **Note**\n    > \n    > There is technically no reason to use secrets for this example; [configs](https://docs.docker.com/engine/swarm/configs/) are a better fit. This example is for illustration only.\n    \n5.  Access the IIS service at `http://localhost:8000/`. It should serve the HTML content from the first step.\n    \n6.  Remove the service and the secret.\n    \n\n### [Intermediate example: Use secrets with a Nginx service](#intermediate-example-use-secrets-with-a-nginx-service)\n\nThis example is divided into two parts. [The first part](#generate-the-site-certificate) is all about generating the site certificate and does not directly involve Docker secrets at all, but it sets up [the second part](#configure-the-nginx-container), where you store and use the site certificate and Nginx configuration as secrets.\n\n#### [Generate the site certificate](#generate-the-site-certificate)\n\nGenerate a root CA and TLS certificate and key for your site. For production sites, you may want to use a service such as `Letâ€™s Encrypt` to generate the TLS certificate and key, but this example uses command-line tools. This step is a little complicated, but is only a set-up step so that you have something to store as a Docker secret. If you want to skip these sub-steps, you can [use Let's Encrypt](https://letsencrypt.org/getting-started/) to generate the site key and certificate, name the files `site.key` and `site.crt`, and skip to [Configure the Nginx container](#configure-the-nginx-container).\n\n1.  Generate a root key.\n    \n2.  Generate a CSR using the root key.\n    \n3.  Configure the root CA. Edit a new file called `root-ca.cnf` and paste the following contents into it. This constrains the root CA to signing leaf certificates and not intermediate CAs.\n    \n4.  Sign the certificate.\n    \n5.  Generate the site key.\n    \n6.  Generate the site certificate and sign it with the site key.\n    \n7.  Configure the site certificate. Edit a new file called `site.cnf` and paste the following contents into it. This constrains the site certificate so that it can only be used to authenticate a server and can't be used to sign certificates.\n    \n8.  Sign the site certificate.\n    \n9.  The `site.csr` and `site.cnf` files are not needed by the Nginx service, but you need them if you want to generate a new site certificate. Protect the `root-ca.key` file.\n    \n\n#### [Configure the Nginx container](#configure-the-nginx-container)\n\n1.  Produce a very basic Nginx configuration that serves static files over HTTPS. The TLS certificate and key are stored as Docker secrets so that they can be rotated easily.\n    \n    In the current directory, create a new file called `site.conf` with the following contents:\n    \n2.  Create three secrets, representing the key, the certificate, and the `site.conf`. You can store any file as a secret as long as it is smaller than 500 KB. This allows you to decouple the key, certificate, and configuration from the services that use them. In each of these commands, the last argument represents the path to the file to read the secret from on the host machine's filesystem. In these examples, the secret name and the file name are the same.\n    \n3.  Create a service that runs Nginx and has access to the three secrets. The last part of the `docker service create` command creates a symbolic link from the location of the `site.conf` secret to `/etc/nginx.conf.d/`, where Nginx looks for extra configuration files. This step happens before Nginx actually starts, so you don't need to rebuild your image if you change the Nginx configuration.\n    \n    > **Note**\n    > \n    > Normally you would create a Dockerfile which copies the `site.conf` into place, build the image, and run a container using your custom image. This example does not require a custom image. It puts the `site.conf` into place and runs the container all in one step.\n    \n    Secrets are located within the `/run/secrets/` directory in the container by default, which may require extra steps in the container to make the secret available in a different path. The example below creates a symbolic link to the true location of the `site.conf` file so that Nginx can read it:\n    \n    Instead of creating symlinks, secrets allow you to specify a custom location using the `target` option. The example below illustrates how the `site.conf` secret is made available at `/etc/nginx/conf.d/site.conf` inside the container without the use of symbolic links:\n    \n    The `site.key` and `site.crt` secrets use the short-hand syntax, without a custom `target` location set. The short syntax mounts the secrets in \\`/run/secrets/ with the same name as the secret. Within the running containers, the following three files now exist:\n    \n    *   `/run/secrets/site.key`\n    *   `/run/secrets/site.crt`\n    *   `/etc/nginx/conf.d/site.conf`\n4.  Verify that the Nginx service is running.\n    \n5.  Verify that the service is operational: you can reach the Nginx server, and that the correct TLS certificate is being used.\n    \n6.  To clean up after running this example, remove the `nginx` service and the stored secrets.\n    \n\n### [Advanced example: Use secrets with a WordPress service](#advanced-example-use-secrets-with-a-wordpress-service)\n\nIn this example, you create a single-node MySQL service with a custom root password, add the credentials as secrets, and create a single-node WordPress service which uses these credentials to connect to MySQL. The [next example](#example-rotate-a-secret) builds on this one and shows you how to rotate the MySQL password and update the services so that the WordPress service can still connect to MySQL.\n\nThis example illustrates some techniques to use Docker secrets to avoid saving sensitive credentials within your image or passing them directly on the command line.\n\n> **Note**\n> \n> This example uses a single-Engine swarm for simplicity, and uses a single-node MySQL service because a single MySQL server instance cannot be scaled by simply using a replicated service, and setting up a MySQL cluster is beyond the scope of this example.\n> \n> Also, changing a MySQL root passphrase isnâ€™t as simple as changing a file on disk. You must use a query or a `mysqladmin` command to change the password in MySQL.\n\n1.  Generate a random alphanumeric password for MySQL and store it as a Docker secret with the name `mysql_password` using the `docker secret create` command. To make the password shorter or longer, adjust the last argument of the `openssl` command. This is just one way to create a relatively random password. You can use another command to generate the password if you choose.\n    \n    > **Note**\n    > \n    > After you create a secret, you cannot update it. You can only remove and re-create it, and you cannot remove a secret that a service is using. However, you can grant or revoke a running service's access to secrets using `docker service update`. If you need the ability to update a secret, consider adding a version component to the secret name, so that you can later add a new version, update the service to use it, then remove the old version.\n    \n    The last argument is set to `-`, which indicates that the input is read from standard input.\n    \n    The value returned is not the password, but the ID of the secret. In the remainder of this tutorial, the ID output is omitted.\n    \n    Generate a second secret for the MySQL `root` user. This secret isn't shared with the WordPress service created later. It's only needed to bootstrap the `mysql` service.\n    \n    List the secrets managed by Docker using `docker secret ls`:\n    \n    The secrets are stored in the encrypted Raft logs for the swarm.\n    \n2.  Create a user-defined overlay network which is used for communication between the MySQL and WordPress services. There is no need to expose the MySQL service to any external host or container.\n    \n3.  Create the MySQL service. The MySQL service has the following characteristics:\n    \n    *   Because the scale is set to `1`, only a single MySQL task runs. Load-balancing MySQL is left as an exercise to the reader and involves more than just scaling the service.\n        \n    *   Only reachable by other containers on the `mysql_private` network.\n        \n    *   Uses the volume `mydata` to store the MySQL data, so that it persists across restarts to the `mysql` service.\n        \n    *   The secrets are each mounted in a `tmpfs` filesystem at `/run/secrets/mysql_password` and `/run/secrets/mysql_root_password`. They are never exposed as environment variables, nor can they be committed to an image if the `docker commit` command is run. The `mysql_password` secret is the one used by the non-privileged WordPress container to connect to MySQL.\n        \n    *   Sets the environment variables `MYSQL_PASSWORD_FILE` and `MYSQL_ROOT_PASSWORD_FILE` to point to the files `/run/secrets/mysql_password` and `/run/secrets/mysql_root_password`. The `mysql` image reads the password strings from those files when initializing the system database for the first time. Afterward, the passwords are stored in the MySQL system database itself.\n        \n    *   Sets environment variables `MYSQL_USER` and `MYSQL_DATABASE`. A new database called `wordpress` is created when the container starts, and the `wordpress` user has full permissions for this database only. This user cannot create or drop databases or change the MySQL configuration.\n        \n4.  Verify that the `mysql` container is running using the `docker service ls` command.\n    \n5.  Now that MySQL is set up, create a WordPress service that connects to the MySQL service. The WordPress service has the following characteristics:\n    \n    *   Because the scale is set to `1`, only a single WordPress task runs. Load-balancing WordPress is left as an exercise to the reader, because of limitations with storing WordPress session data on the container filesystem.\n    *   Exposes WordPress on port 30000 of the host machine, so that you can access it from external hosts. You can expose port 80 instead if you do not have a web server running on port 80 of the host machine.\n    *   Connects to the `mysql_private` network so it can communicate with the `mysql` container, and also publishes port 80 to port 30000 on all swarm nodes.\n    *   Has access to the `mysql_password` secret, but specifies a different target file name within the container. The WordPress container uses the mount point `/run/secrets/wp_db_password`.\n    *   Sets the environment variable `WORDPRESS_DB_PASSWORD_FILE` to the file path where the secret is mounted. The WordPress service reads the MySQL password string from that file and add it to the `wp-config.php` configuration file.\n    *   Connects to the MySQL container using the username `wordpress` and the password in `/run/secrets/wp_db_password` and creates the `wordpress` database if it does not yet exist.\n    *   Stores its data, such as themes and plugins, in a volume called `wpdata` so these files persist when the service restarts.\n6.  Verify the service is running using `docker service ls` and `docker service ps` commands.\n    \n    At this point, you could actually revoke the WordPress service's access to the `mysql_password` secret, because WordPress has copied the secret to its configuration file `wp-config.php`. Don't do that for now, because we use it later to facilitate rotating the MySQL password.\n    \n7.  Access `http://localhost:30000/` from any swarm node and set up WordPress using the web-based wizard. All of these settings are stored in the MySQL `wordpress` database. WordPress automatically generates a password for your WordPress user, which is completely different from the password WordPress uses to access MySQL. Store this password securely, such as in a password manager. You need it to log into WordPress after [rotating the secret](#example-rotate-a-secret).\n    \n    Go ahead and write a blog post or two and install a WordPress plugin or theme to verify that WordPress is fully operational and its state is saved across service restarts.\n    \n8.  Do not clean up any services or secrets if you intend to proceed to the next example, which demonstrates how to rotate the MySQL root password.\n    \n\n### [Example: Rotate a secret](#example-rotate-a-secret)\n\nThis example builds upon the previous one. In this scenario, you create a new secret with a new MySQL password, update the `mysql` and `wordpress` services to use it, then remove the old secret.\n\n> **Note**\n> \n> Changing the password on a MySQL database involves running extra queries or commands, as opposed to just changing a single environment variable or a file, since the image only sets the MySQL password if the database doesnâ€™t already exist, and MySQL stores the password within a MySQL database by default. Rotating passwords or other secrets may involve additional steps outside of Docker.\n\n1.  Create the new password and store it as a secret named `mysql_password_v2`.\n    \n2.  Update the MySQL service to give it access to both the old and new secrets. Remember that you cannot update or rename a secret, but you can revoke a secret and grant access to it using a new target filename.\n    \n    Updating a service causes it to restart, and when the MySQL service restarts the second time, it has access to the old secret under `/run/secrets/old_mysql_password` and the new secret under `/run/secrets/mysql_password`.\n    \n    Even though the MySQL service has access to both the old and new secrets now, the MySQL password for the WordPress user has not yet been changed.\n    \n    > **Note**\n    > \n    > This example does not rotate the MySQL `root` password.\n    \n3.  Now, change the MySQL password for the `wordpress` user using the `mysqladmin` CLI. This command reads the old and new password from the files in `/run/secrets` but does not expose them on the command line or save them in the shell history.\n    \n    Do this quickly and move on to the next step, because WordPress loses the ability to connect to MySQL.\n    \n    First, find the ID of the `mysql` container task.\n    \n    Substitute the ID in the command below, or use the second variant which uses shell expansion to do it all in a single step.\n    \n    Or:\n    \n4.  Update the `wordpress` service to use the new password, keeping the target path at `/run/secrets/wp_db_password`. This triggers a rolling restart of the WordPress service and the new secret is used.\n    \n5.  Verify that WordPress works by browsing to http://localhost:30000/ on any swarm node again. Use the WordPress username and password from when you ran through the WordPress wizard in the previous task.\n    \n    Verify that the blog post you wrote still exists, and if you changed any configuration values, verify that they are still changed.\n    \n6.  Revoke access to the old secret from the MySQL service and remove the old secret from Docker.\n    \n7.  Run the following commands to remove the WordPress service, the MySQL container, the `mydata` and `wpdata` volumes, and the Docker secrets:\n    \n\nIf you develop a container that can be deployed as a service and requires sensitive data, such as a credential, as an environment variable, consider adapting your image to take advantage of Docker secrets. One way to do this is to ensure that each parameter you pass to the image when creating the container can also be read from a file.\n\nMany of the Docker Official Images in the [Docker library](https://github.com/docker-library/), such as the [wordpress](https://github.com/docker-library/wordpress/) image used in the above examples, have been updated in this way.\n\nWhen you start a WordPress container, you provide it with the parameters it needs by setting them as environment variables. The WordPress image has been updated so that the environment variables which contain important data for WordPress, such as `WORDPRESS_DB_PASSWORD`, also have variants which can read their values from a file (`WORDPRESS_DB_PASSWORD_FILE`). This strategy ensures that backward compatibility is preserved, while allowing your container to read the information from a Docker-managed secret instead of being passed directly.\n\n> **Note**\n> \n> Docker secrets do not set environment variables directly. This was a conscious decision, because environment variables can unintentionally be leaked between containers (for instance, if you use `--link`).\n\nThis example creates a simple WordPress site using two secrets in a Compose file.\n\nThe top-level element `secrets` defines two secrets `db_password` and `db_root_password`.\n\nWhen deploying, Docker creates these two secrets and populates them with the content from the file specified in the Compose file.\n\nThe `db` service uses both secrets, and `wordpress` is using one.\n\nWhen you deploy, Docker mounts a file under `/run/secrets/<secret_name>` in the services. These files are never persisted on disk, but are managed in memory.\n\nEach service uses environment variables to specify where the service should look for that secret data.\n\nMore information on short and long syntax for secrets can be found in the [Compose Specification](https://docs.docker.com/compose/compose-file/09-secrets/).",
  "title": "Manage sensitive data with Docker secrets | Docker Docs\n",
  "description": "How to securely store, retrieve, and use sensitive data with Docker services",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/install/linux-postinstall/",
  "markdown": "# Linux post-installation steps for Docker Engine\n\nThese optional post-installation procedures describe how to configure your Linux host machine to work better with Docker.\n\nThe Docker daemon binds to a Unix socket, not a TCP port. By default it's the `root` user that owns the Unix socket, and other users can only access it using `sudo`. The Docker daemon always runs as the `root` user.\n\nIf you don't want to preface the `docker` command with `sudo`, create a Unix group called `docker` and add users to it. When the Docker daemon starts, it creates a Unix socket accessible by members of the `docker` group. On some Linux distributions, the system automatically creates this group when installing Docker Engine using a package manager. In that case, there is no need for you to manually create the group.\n\n> **Warning**\n> \n> The `docker` group grants root-level privileges to the user. For details on how this impacts security in your system, see [Docker Daemon Attack Surface](https://docs.docker.com/engine/security/#docker-daemon-attack-surface).\n\n> **Note**\n> \n> To run Docker without root privileges, see [Run the Docker daemon as a non-root user (Rootless mode)](https://docs.docker.com/engine/security/rootless/).\n\nTo create the `docker` group and add your user:\n\n1.  Create the `docker` group.\n    \n2.  Add your user to the `docker` group.\n    \n3.  Log out and log back in so that your group membership is re-evaluated.\n    \n    > If you're running Linux in a virtual machine, it may be necessary to restart the virtual machine for changes to take effect.\n    \n    You can also run the following command to activate the changes to groups:\n    \n4.  Verify that you can run `docker` commands without `sudo`.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n    \n    If you initially ran Docker CLI commands using `sudo` before adding your user to the `docker` group, you may see the following error:\n    \n    This error indicates that the permission settings for the `~/.docker/` directory are incorrect, due to having used the `sudo` command earlier.\n    \n    To fix this problem, either remove the `~/.docker/` directory (it's recreated automatically, but any custom settings are lost), or change its ownership and permissions using the following commands:\n    \n\nMany modern Linux distributions use [systemd](https://systemd.io/) to manage which services start when the system boots. On Debian and Ubuntu, the Docker service starts on boot by default. To automatically start Docker and containerd on boot for other Linux distributions using systemd, run the following commands:\n\nTo stop this behavior, use `disable` instead.\n\nYou can use systemd unit files to configure the Docker service on startup, for example to add an HTTP proxy, set a different directory or partition for the Docker runtime files, or other customizations. For an example, see [Configure the daemon to use a proxy](https://docs.docker.com/config/daemon/proxy/#systemd-unit-file).\n\nDocker provides [logging drivers](https://docs.docker.com/config/containers/logging/) for collecting and viewing log data from all containers running on a host. The default logging driver, `json-file`, writes log data to JSON-formatted files on the host filesystem. Over time, these log files expand in size, leading to potential exhaustion of disk resources.\n\nTo avoid issues with overusing disk for log data, consider one of the following options:\n\n*   Configure the `json-file` logging driver to turn on [log rotation](https://docs.docker.com/config/containers/logging/json-file/).\n*   Use an [alternative logging driver](https://docs.docker.com/config/containers/logging/configure/#configure-the-default-logging-driver) such as the [\"local\" logging driver](https://docs.docker.com/config/containers/logging/local/) that performs log rotation by default.\n*   Use a logging driver that sends logs to a remote logging aggregator.\n\n*   Take a look at the [Docker workshop](https://docs.docker.com/guides/workshop/) to learn how to build an image and run it as a containerized application.",
  "title": "Linux post-installation steps for Docker Engine | Docker Docs\n",
  "description": "Find the recommended Docker Engine post-installation steps for Linux users, including how to run Docker as a non-root user and more.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/security/trust/deploying_notary/",
  "markdown": "# Deploy Notary Server with Compose\n\nThe easiest way to deploy Notary Server is by using Docker Compose. To follow the procedure on this page, you must have already [installed Docker Compose](https://docs.docker.com/compose/install/).\n\n1.  Clone the Notary repository.\n    \n2.  Build and start Notary Server with the sample certificates.\n    \n    For more detailed documentation about how to deploy Notary Server, see the [instructions to run a Notary service](https://github.com/theupdateframework/notary/blob/master/docs/running_a_service.md) as well as [the Notary repository](https://github.com/theupdateframework/notary) for more information.\n    \n3.  Make sure that your Docker or Notary client trusts Notary Server's certificate before you try to interact with the Notary server.\n    \n\nSee the instructions for [Docker](https://docs.docker.com/engine/reference/commandline/cli/#notary) or for [Notary](https://github.com/docker/notary#using-notary) depending on which one you are using.\n\nCheck back here for instructions after Notary Server has an official stable release. To get a head start on deploying Notary in production, see [the Notary repository](https://github.com/theupdateframework/notary).",
  "title": "Deploy Notary Server with Compose | Docker Docs\n",
  "description": "Deploying Notary",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/networking/",
  "markdown": "# Manage swarm service networks | Docker Docs\n\nThis page describes networking for swarm services.\n\nA Docker swarm generates two different kinds of traffic:\n\n*   Control and management plane traffic: This includes swarm management messages, such as requests to join or leave the swarm. This traffic is always encrypted.\n    \n*   Application data plane traffic: This includes container traffic and traffic to and from external clients.\n    \n\nThe following three network concepts are important to swarm services:\n\n*   Overlay networks manage communications among the Docker daemons participating in the swarm. You can create overlay networks, in the same way as user-defined networks for standalone containers. You can attach a service to one or more existing overlay networks as well, to enable service-to-service communication. Overlay networks are Docker networks that use the `overlay` network driver.\n    \n*   The ingress network is a special overlay network that facilitates load balancing among a service's nodes. When any swarm node receives a request on a published port, it hands that request off to a module called `IPVS`. `IPVS` keeps track of all the IP addresses participating in that service, selects one of them, and routes the request to it, over the `ingress` network.\n    \n    The `ingress` network is created automatically when you initialize or join a swarm. Most users do not need to customize its configuration, but Docker allows you to do so.\n    \n*   The docker\\_gwbridge is a bridge network that connects the overlay networks (including the `ingress` network) to an individual Docker daemon's physical network. By default, each container a service is running is connected to its local Docker daemon host's `docker_gwbridge` network.\n    \n    The `docker_gwbridge` network is created automatically when you initialize or join a swarm. Most users do not need to customize its configuration, but Docker allows you to do so.\n    \n\n> **Tip**\n> \n> See also [Networking overview](https://docs.docker.com/network/) for more details about Swarm networking in general.\n\nDocker daemons participating in a swarm need the ability to communicate with each other over the following ports:\n\n*   Port `7946` TCP/UDP for container network discovery.\n*   Port `4789` UDP (configurable) for the overlay network (including ingress) data path.\n\nWhen setting up networking in a Swarm, special care should be taken. Consult the [tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/#open-protocols-and-ports-between-the-hosts) for an overview.\n\nWhen you initialize a swarm or join a Docker host to an existing swarm, two new networks are created on that Docker host:\n\n*   An overlay network called `ingress`, which handles the control and data traffic related to swarm services. When you create a swarm service and do not connect it to a user-defined overlay network, it connects to the `ingress` network by default.\n*   A bridge network called `docker_gwbridge`, which connects the individual Docker daemon to the other daemons participating in the swarm.\n\n### [Create an overlay network](#create-an-overlay-network)\n\nTo create an overlay network, specify the `overlay` driver when using the `docker network create` command:\n\nThe above command doesn't specify any custom options, so Docker assigns a subnet and uses default options. You can see information about the network using `docker network inspect`.\n\nWhen no containers are connected to the overlay network, its configuration is not very exciting:\n\nIn the above output, notice that the driver is `overlay` and that the scope is `swarm`, rather than `local`, `host`, or `global` scopes you might see in other types of Docker networks. This scope indicates that only hosts which are participating in the swarm can access this network.\n\nThe network's subnet and gateway are dynamically configured when a service connects to the network for the first time. The following example shows the same network as above, but with three containers of a `redis` service connected to it.\n\n### [Customize an overlay network](#customize-an-overlay-network)\n\nThere may be situations where you don't want to use the default configuration for an overlay network. For a full list of configurable options, run the command `docker network create --help`. The following are some of the most common options to change.\n\n#### [Configure the subnet and gateway](#configure-the-subnet-and-gateway)\n\nBy default, the network's subnet and gateway are configured automatically when the first service is connected to the network. You can configure these when creating a network using the `--subnet` and `--gateway` flags. The following example extends the previous one by configuring the subnet and gateway.\n\n##### [Using custom default address pools](#using-custom-default-address-pools)\n\nTo customize subnet allocation for your Swarm networks, you can [optionally configure them](https://docs.docker.com/engine/swarm/swarm-mode/) during `swarm init`.\n\nFor example, the following command is used when initializing Swarm:\n\nWhenever a user creates a network, but does not use the `--subnet` command line option, the subnet for this network will be allocated sequentially from the next available subnet from the pool. If the specified network is already allocated, that network will not be used for Swarm.\n\nMultiple pools can be configured if discontiguous address space is required. However, allocation from specific pools is not supported. Network subnets will be allocated sequentially from the IP pool space and subnets will be reused as they are deallocated from networks that are deleted.\n\nThe default mask length can be configured and is the same for all networks. It is set to `/24` by default. To change the default subnet mask length, use the `--default-addr-pool-mask-length` command line option.\n\n> **Note**\n> \n> Default address pools can only be configured on `swarm init` and cannot be altered after cluster creation.\n\n##### [Overlay network size limitations](#overlay-network-size-limitations)\n\nDocker recommends creating overlay networks with `/24` blocks. The `/24` overlay network blocks limit the network to 256 IP addresses.\n\nThis recommendation addresses [limitations with swarm mode](https://github.com/moby/moby/issues/30820). If you need more than 256 IP addresses, do not increase the IP block size. You can either use `dnsrr` endpoint mode with an external load balancer, or use multiple smaller overlay networks. See [Configure service discovery](#configure-service-discovery) for more information about different endpoint modes.\n\n#### [Configure encryption of application data](#encryption)\n\nManagement and control plane data related to a swarm is always encrypted. For more details about the encryption mechanisms, see the [Docker swarm mode overlay network security model](https://docs.docker.com/network/drivers/overlay/).\n\nApplication data among swarm nodes is not encrypted by default. To encrypt this traffic on a given overlay network, use the `--opt encrypted` flag on `docker network create`. This enables IPSEC encryption at the level of the vxlan. This encryption imposes a non-negligible performance penalty, so you should test this option before using it in production.\n\n> **Note**\n> \n> You must [customize the automatically created ingress](#customize-ingress) to enable encryption. By default, all ingress traffic is unencrypted, as encryption is a network-level option.\n\nTo attach a service to an existing overlay network, pass the `--network` flag to `docker service create`, or the `--network-add` flag to `docker service update`.\n\nService containers connected to an overlay network can communicate with each other across it.\n\nTo see which networks a service is connected to, use `docker service ls` to find the name of the service, then `docker service ps <service-name>` to list the networks. Alternately, to see which services' containers are connected to a network, use `docker network inspect <network-name>`. You can run these commands from any swarm node which is joined to the swarm and is in a `running` state.\n\n### [Configure service discovery](#configure-service-discovery)\n\nService discovery is the mechanism Docker uses to route a request from your service's external clients to an individual swarm node, without the client needing to know how many nodes are participating in the service or their IP addresses or ports. You don't need to publish ports which are used between services on the same network. For instance, if you have a [WordPress service that stores its data in a MySQL service](https://training.play-with-docker.com/swarm-service-discovery/), and they are connected to the same overlay network, you do not need to publish the MySQL port to the client, only the WordPress HTTP port.\n\nService discovery can work in two different ways: internal connection-based load-balancing at Layers 3 and 4 using the embedded DNS and a virtual IP (VIP), or external and customized request-based load-balancing at Layer 7 using DNS round robin (DNSRR). You can configure this per service.\n\n*   By default, when you attach a service to a network and that service publishes one or more ports, Docker assigns the service a virtual IP (VIP), which is the \"front end\" for clients to reach the service. Docker keeps a list of all worker nodes in the service, and routes requests between the client and one of the nodes. Each request from the client might be routed to a different node.\n    \n*   If you configure a service to use DNS round-robin (DNSRR) service discovery, there is not a single virtual IP. Instead, Docker sets up DNS entries for the service such that a DNS query for the service name returns a list of IP addresses, and the client connects directly to one of these.\n    \n    DNS round-robin is useful in cases where you want to use your own load balancer, such as HAProxy. To configure a service to use DNSRR, use the flag `--endpoint-mode dnsrr` when creating a new service or updating an existing one.\n    \n\nMost users never need to configure the `ingress` network, but Docker allows you to do so. This can be useful if the automatically-chosen subnet conflicts with one that already exists on your network, or you need to customize other low-level network settings such as the MTU, or if you want to [enable encryption](#encryption).\n\nCustomizing the `ingress` network involves removing and recreating it. This is usually done before you create any services in the swarm. If you have existing services which publish ports, those services need to be removed before you can remove the `ingress` network.\n\nDuring the time that no `ingress` network exists, existing services which do not publish ports continue to function but are not load-balanced. This affects services which publish ports, such as a WordPress service which publishes port 80.\n\n1.  Inspect the `ingress` network using `docker network inspect ingress`, and remove any services whose containers are connected to it. These are services that publish ports, such as a WordPress service which publishes port 80. If all such services are not stopped, the next step fails.\n    \n2.  Remove the existing `ingress` network:\n    \n3.  Create a new overlay network using the `--ingress` flag, along with the custom options you want to set. This example sets the MTU to 1200, sets the subnet to `10.11.0.0/16`, and sets the gateway to `10.11.0.2`.\n    \n    > **Note**\n    > \n    > You can name your `ingress` network something other than `ingress`, but you can only have one. An attempt to create a second one fails.\n    \n4.  Restart the services that you stopped in the first step.\n    \n\nThe `docker_gwbridge` is a virtual bridge that connects the overlay networks (including the `ingress` network) to an individual Docker daemon's physical network. Docker creates it automatically when you initialize a swarm or join a Docker host to a swarm, but it is not a Docker device. It exists in the kernel of the Docker host. If you need to customize its settings, you must do so before joining the Docker host to the swarm, or after temporarily removing the host from the swarm.\n\nYou need to have the `brctl` application installed on your operating system in order to delete an existing bridge. The package name is `bridge-utils`.\n\n1.  Stop Docker.\n    \n2.  Use the `brctl show docker_gwbridge` command to check whether a bridge device exists called `docker_gwbridge`. If so, remove it using `brctl delbr docker_gwbridge`.\n    \n3.  Start Docker. Do not join or initialize the swarm.\n    \n4.  Create or re-create the `docker_gwbridge` bridge with your custom settings. This example uses the subnet `10.11.0.0/16`. For a full list of customizable options, see [Bridge driver options](https://docs.docker.com/reference/cli/docker/network/create/#bridge-driver-options).\n    \n5.  Initialize or join the swarm.\n    \n\nBy default, all swarm traffic is sent over the same interface, including control and management traffic for maintaining the swarm itself and data traffic to and from the service containers.\n\nYou can separate this traffic by passing the `--data-path-addr` flag when initializing or joining the swarm. If there are multiple interfaces, `--advertise-addr` must be specified explicitly, and `--data-path-addr` defaults to `--advertise-addr` if not specified. Traffic about joining, leaving, and managing the swarm is sent over the `--advertise-addr` interface, and traffic among a service's containers is sent over the `--data-path-addr` interface. These flags can take an IP address or a network device name, such as `eth0`.\n\nThis example initializes a swarm with a separate `--data-path-addr`. It assumes that your Docker host has two different network interfaces: 10.0.0.1 should be used for control and management traffic and 192.168.0.1 should be used for traffic relating to services.\n\nThis example joins the swarm managed by host `192.168.99.100:2377` and sets the `--advertise-addr` flag to `eth0` and the `--data-path-addr` flag to `eth1`.\n\nSwarm services connected to the same overlay network effectively expose all ports to each other. For a port to be accessible outside of the service, that port must be _published_ using the `-p` or `--publish` flag on `docker service create` or `docker service update`. Both the legacy colon-separated syntax and the newer comma-separated value syntax are supported. The longer syntax is preferred because it is somewhat self-documenting.\n\n| Flag value | Description |\n| --- | --- |\n| \\-p 8080:80 or  <br>\\-p published=8080,target=80 | Map TCP port 80 on the service to port 8080 on the routing mesh. |\n| \\-p 8080:80/udp or  <br>\\-p published=8080,target=80,protocol=udp | Map UDP port 80 on the service to port 8080 on the routing mesh. |\n| \\-p 8080:80/tcp -p 8080:80/udp or  <br>\\-p published=8080,target=80,protocol=tcp -p published=8080,target=80,protocol=udp | Map TCP port 80 on the service to TCP port 8080 on the routing mesh, and map UDP port 80 on the service to UDP port 8080 on the routing mesh. |\n\n*   [Deploy services to a swarm](https://docs.docker.com/engine/swarm/services/)\n*   [Swarm administration guide](https://docs.docker.com/engine/swarm/admin_guide/)\n*   [Swarm mode tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/)\n*   [Networking overview](https://docs.docker.com/network/)\n*   [Docker CLI reference](https://docs.docker.com/reference/cli/docker/)",
  "title": "Manage swarm service networks | Docker Docs\n",
  "description": "Use swarm mode overlay networking features",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/reference/run/",
  "markdown": "# Running containers | Docker Docs\n\nDocker runs processes in isolated containers. A container is a process which runs on a host. The host may be local or remote. When you execute `docker run`, the container process that runs is isolated in that it has its own file system, its own networking, and its own isolated process tree separate from the host.\n\nThis page details how to use the `docker run` command to run containers.\n\nA `docker run` command takes the following form:\n\nThe `docker run` command must specify an [image reference](#image-references) to create the container from.\n\n### [Image references](#image-references)\n\nThe image reference is the name and version of the image. You can use the image reference to create or run a container based on an image.\n\n*   `docker run IMAGE[:TAG][@DIGEST]`\n*   `docker create IMAGE[:TAG][@DIGEST]`\n\nAn image tag is the image version, which defaults to `latest` when omitted. Use the tag to run a container from specific version of an image. For example, to run version `23.10` of the `ubuntu` image: `docker run ubuntu:23.10`.\n\n#### [Image digests](#image-digests)\n\nImages using the v2 or later image format have a content-addressable identifier called a digest. As long as the input used to generate the image is unchanged, the digest value is predictable.\n\nThe following example runs a container from the `alpine` image with the `sha256:9cacb71397b640eca97488cf08582ae4e4068513101088e9f96c9814bfda95e0` digest:\n\n### [Options](#options)\n\n`[OPTIONS]` let you configure options for the container. For example, you can give the container a name (`--name`), or run it as a background process (`-d`). You can also set options to control things like resource constraints and networking.\n\n### [Commands and arguments](#commands-and-arguments)\n\nYou can use the `[COMMAND]` and `[ARG...]` positional arguments to specify commands and arguments for the container to run when it starts up. For example, you can specify `sh` as the `[COMMAND]`, combined with the `-i` and `-t` flags, to start an interactive shell in the container (if the image you select has an `sh` executable on `PATH`).\n\n> **Note**\n> \n> Depending on your Docker system configuration, you may be required to preface the `docker run` command with `sudo`. To avoid having to use `sudo` with the `docker` command, your system administrator can create a Unix group called `docker` and add users to it. For more information about this configuration, refer to the Docker installation documentation for your operating system.\n\nWhen you start a container, the container runs in the foreground by default. If you want to run the container in the background instead, you can use the `--detach` (or `-d`) flag. This starts the container without occupying your terminal window.\n\nWhile the container runs in the background, you can interact with the container using other CLI commands. For example, `docker logs` lets you view the logs for the container, and `docker attach` brings it to the foreground.\n\nFor more information about `docker run` flags related to foreground and background modes, see:\n\n*   [`docker run --detach`](https://docs.docker.com/reference/cli/docker/container/run/#detach): run container in background\n*   [`docker run --attach`](https://docs.docker.com/reference/cli/docker/container/run/#attach): attach to `stdin`, `stdout`, and `stderr`\n*   [`docker run --tty`](https://docs.docker.com/reference/cli/docker/container/run/#tty): allocate a pseudo-tty\n*   [`docker run --interactive`](https://docs.docker.com/reference/cli/docker/container/run/#interactive): keep `stdin` open even if not attached\n\nFor more information about re-attaching to a background container, see [`docker attach`](https://docs.docker.com/reference/cli/docker/container/attach/).\n\nYou can identify a container in three ways:\n\n| Identifier type | Example value |\n| --- | --- |\n| UUID long identifier | `f78375b1c487e03c9438c729345e54db9d20cfa2ac1fc3494b6eb60872e74778` |\n| UUID short identifier | `f78375b1c487` |\n| Name | `evil_ptolemy` |\n\nThe UUID identifier is a random ID assigned to the container by the daemon.\n\nThe daemon generates a random string name for containers automatically. You can also defined a custom name using [the `--name` flag](https://docs.docker.com/reference/cli/docker/container/run/#name). Defining a `name` can be a handy way to add meaning to a container. If you specify a `name`, you can use it when referring to the container in a user-defined network. This works for both background and foreground Docker containers.\n\nA container identifier is not the same thing as an image reference. The image reference specifies which image to use when you run a container. You can't run `docker exec nginx:alpine sh` to open a shell in a container based on the `nginx:alpine` image, because `docker exec` expects a container identifier (name or ID), not an image.\n\nWhile the image used by a container is not an identifier for the container, you find out the IDs of containers using an image by using the `--filter` flag. For example, the following `docker ps` command gets the IDs of all running containers based on the `nginx:alpine` image:\n\nFor more information about using filters, see [Filtering](https://docs.docker.com/config/filter/).\n\nContainers have networking enabled by default, and they can make outgoing connections. If you're running multiple containers that need to communicate with each other, you can create a custom network and attach the containers to the network.\n\nWhen multiple containers are attached to the same custom network, they can communicate with each other using the container names as a DNS hostname. The following example creates a custom network named `my-net`, and runs two containers that attach to the network.\n\nFor more information about container networking, see [Networking overview](https://docs.docker.com/network/)\n\nBy default, the data in a container is stored in an ephemeral, writable container layer. Removing the container also removes its data. If you want to use persistent data with containers, you can use filesystem mounts to store the data persistently on the host system. Filesystem mounts can also let you share data between containers and the host.\n\nDocker supports two main categories of mounts:\n\n*   Volume mounts\n*   Bind mounts\n\nVolume mounts are great for persistently storing data for containers, and for sharing data between containers. Bind mounts, on the other hand, are for sharing data between a container and the host.\n\nYou can add a filesystem mount to a container using the `--mount` flag for the `docker run` command.\n\nThe following sections show basic examples of how to create volumes and bind mounts. For more in-depth examples and descriptions, refer to the section of the [storage section](https://docs.docker.com/storage/) in the documentation.\n\n### [Volume mounts](#volume-mounts)\n\nTo create a volume mount:\n\nThe `--mount` flag takes two parameters in this case: `source` and `target`. The value for the `source` parameter is the name of the volume. The value of `target` is the mount location of the volume inside the container. Once you've created the volume, any data you write to the volume is persisted, even if you stop or remove the container:\n\nThe `target` must always be an absolute path, such as `/src/docs`. An absolute path starts with a `/` (forward slash). Volume names must start with an alphanumeric character, followed by `a-z0-9`, `_` (underscore), `.` (period) or `-` (hyphen).\n\n### [Bind mounts](#bind-mounts)\n\nTo create a bind mount:\n\nIn this case, the `--mount` flag takes three parameters. A type (`bind`), and two paths. The `source` path is a the location on the host that you want to bind mount into the container. The `target` path is the mount destination inside the container.\n\nBind mounts are read-write by default, meaning that you can both read and write files to and from the mounted location from the container. Changes that you make, such as adding or editing files, are reflected on the host filesystem:\n\nThe exit code from `docker run` gives information about why the container failed to run or why it exited. The following sections describe the meanings of different container exit codes values.\n\n### [125](#125)\n\nExit code `125` indicates that the error is with Docker daemon itself.\n\n### [126](#126)\n\nExit code `126` indicates that the specified contained command can't be invoked. The container command in the following example is: `/etc; echo $?`.\n\n### [127](#127)\n\nExit code `127` indicates that the contained command can't be found.\n\n### [Other exit codes](#other-exit-codes)\n\nAny exit code other than `125`, `126`, and `127` represent the exit code of the provided container command.\n\nThe operator can also adjust the performance parameters of the container:\n\n| Option | Description |\n| --- | --- |\n| `-m`, `--memory=\"\"` | Memory limit (format: `<number>[<unit>]`). Number is a positive integer. Unit can be one of `b`, `k`, `m`, or `g`. Minimum is 6M. |\n| `--memory-swap=\"\"` | Total memory limit (memory + swap, format: `<number>[<unit>]`). Number is a positive integer. Unit can be one of `b`, `k`, `m`, or `g`. |\n| `--memory-reservation=\"\"` | Memory soft limit (format: `<number>[<unit>]`). Number is a positive integer. Unit can be one of `b`, `k`, `m`, or `g`. |\n| `--kernel-memory=\"\"` | Kernel memory limit (format: `<number>[<unit>]`). Number is a positive integer. Unit can be one of `b`, `k`, `m`, or `g`. Minimum is 4M. |\n| `-c`, `--cpu-shares=0` | CPU shares (relative weight) |\n| `--cpus=0.000` | Number of CPUs. Number is a fractional number. 0.000 means no limit. |\n| `--cpu-period=0` | Limit the CPU CFS (Completely Fair Scheduler) period |\n| `--cpuset-cpus=\"\"` | CPUs in which to allow execution (0-3, 0,1) |\n| `--cpuset-mems=\"\"` | Memory nodes (MEMs) in which to allow execution (0-3, 0,1). Only effective on NUMA systems. |\n| `--cpu-quota=0` | Limit the CPU CFS (Completely Fair Scheduler) quota |\n| `--cpu-rt-period=0` | Limit the CPU real-time period. In microseconds. Requires parent cgroups be set and cannot be higher than parent. Also check rtprio ulimits. |\n| `--cpu-rt-runtime=0` | Limit the CPU real-time runtime. In microseconds. Requires parent cgroups be set and cannot be higher than parent. Also check rtprio ulimits. |\n| `--blkio-weight=0` | Block IO weight (relative weight) accepts a weight value between 10 and 1000. |\n| `--blkio-weight-device=\"\"` | Block IO weight (relative device weight, format: `DEVICE_NAME:WEIGHT`) |\n| `--device-read-bps=\"\"` | Limit read rate from a device (format: `<device-path>:<number>[<unit>]`). Number is a positive integer. Unit can be one of `kb`, `mb`, or `gb`. |\n| `--device-write-bps=\"\"` | Limit write rate to a device (format: `<device-path>:<number>[<unit>]`). Number is a positive integer. Unit can be one of `kb`, `mb`, or `gb`. |\n| `--device-read-iops=\"\"` | Limit read rate (IO per second) from a device (format: `<device-path>:<number>`). Number is a positive integer. |\n| `--device-write-iops=\"\"` | Limit write rate (IO per second) to a device (format: `<device-path>:<number>`). Number is a positive integer. |\n| `--oom-kill-disable=false` | Whether to disable OOM Killer for the container or not. |\n| `--oom-score-adj=0` | Tune container's OOM preferences (-1000 to 1000) |\n| `--memory-swappiness=\"\"` | Tune a container's memory swappiness behavior. Accepts an integer between 0 and 100. |\n| `--shm-size=\"\"` | Size of `/dev/shm`. The format is `<number><unit>`. `number` must be greater than `0`. Unit is optional and can be `b` (bytes), `k` (kilobytes), `m` (megabytes), or `g` (gigabytes). If you omit the unit, the system uses bytes. If you omit the size entirely, the system uses `64m`. |\n\n### [User memory constraints](#user-memory-constraints)\n\nWe have four ways to set user memory usage:\n\n| Option | Result |\n| --- | --- |\n| **memory=inf, memory-swap=inf** (default) | There is no memory limit for the container. The container can use as much memory as needed. |\n| **memory=L<inf, memory-swap=inf** | (specify memory and set memory-swap as `-1`) The container is not allowed to use more than L bytes of memory, but can use as much swap as is needed (if the host supports swap memory). |\n| **memory=L<inf, memory-swap=2\\*L** | (specify memory without memory-swap) The container is not allowed to use more than L bytes of memory, swap _plus_ memory usage is double of that. |\n| **memory=L<inf, memory-swap=S<inf, L<=S** | (specify both memory and memory-swap) The container is not allowed to use more than L bytes of memory, swap _plus_ memory usage is limited by S. |\n\nExamples:\n\nWe set nothing about memory, this means the processes in the container can use as much memory and swap memory as they need.\n\nWe set memory limit and disabled swap memory limit, this means the processes in the container can use 300M memory and as much swap memory as they need (if the host supports swap memory).\n\nWe set memory limit only, this means the processes in the container can use 300M memory and 300M swap memory, by default, the total virtual memory size (--memory-swap) will be set as double of memory, in this case, memory + swap would be 2\\*300M, so processes can use 300M swap memory as well.\n\nWe set both memory and swap memory, so the processes in the container can use 300M memory and 700M swap memory.\n\nMemory reservation is a kind of memory soft limit that allows for greater sharing of memory. Under normal circumstances, containers can use as much of the memory as needed and are constrained only by the hard limits set with the `-m`/`--memory` option. When memory reservation is set, Docker detects memory contention or low memory and forces containers to restrict their consumption to a reservation limit.\n\nAlways set the memory reservation value below the hard limit, otherwise the hard limit takes precedence. A reservation of 0 is the same as setting no reservation. By default (without reservation set), memory reservation is the same as the hard memory limit.\n\nMemory reservation is a soft-limit feature and does not guarantee the limit won't be exceeded. Instead, the feature attempts to ensure that, when memory is heavily contended for, memory is allocated based on the reservation hints/setup.\n\nThe following example limits the memory (`-m`) to 500M and sets the memory reservation to 200M.\n\nUnder this configuration, when the container consumes memory more than 200M and less than 500M, the next system memory reclaim attempts to shrink container memory below 200M.\n\nThe following example set memory reservation to 1G without a hard memory limit.\n\nThe container can use as much memory as it needs. The memory reservation setting ensures the container doesn't consume too much memory for long time, because every memory reclaim shrinks the container's consumption to the reservation.\n\nBy default, kernel kills processes in a container if an out-of-memory (OOM) error occurs. To change this behaviour, use the `--oom-kill-disable` option. Only disable the OOM killer on containers where you have also set the `-m/--memory` option. If the `-m` flag is not set, this can result in the host running out of memory and require killing the host's system processes to free memory.\n\nThe following example limits the memory to 100M and disables the OOM killer for this container:\n\nThe following example, illustrates a dangerous way to use the flag:\n\nThe container has unlimited memory which can cause the host to run out memory and require killing system processes to free memory. The `--oom-score-adj` parameter can be changed to select the priority of which containers will be killed when the system is out of memory, with negative scores making them less likely to be killed, and positive scores more likely.\n\n### [Kernel memory constraints](#kernel-memory-constraints)\n\nKernel memory is fundamentally different than user memory as kernel memory can't be swapped out. The inability to swap makes it possible for the container to block system services by consuming too much kernel memory. Kernel memory includesï¼š\n\n*   stack pages\n*   slab pages\n*   sockets memory pressure\n*   tcp memory pressure\n\nYou can setup kernel memory limit to constrain these kinds of memory. For example, every process consumes some stack pages. By limiting kernel memory, you can prevent new processes from being created when the kernel memory usage is too high.\n\nKernel memory is never completely independent of user memory. Instead, you limit kernel memory in the context of the user memory limit. Assume \"U\" is the user memory limit and \"K\" the kernel limit. There are three possible ways to set limits:\n\n| Option | Result |\n| --- | --- |\n| **U != 0, K = inf** (default) | This is the standard memory limitation mechanism already present before using kernel memory. Kernel memory is completely ignored. |\n| **U != 0, K < U** | Kernel memory is a subset of the user memory. This setup is useful in deployments where the total amount of memory per-cgroup is overcommitted. Overcommitting kernel memory limits is definitely not recommended, since the box can still run out of non-reclaimable memory. In this case, you can configure K so that the sum of all groups is never greater than the total memory. Then, freely set U at the expense of the system's service quality. |\n| **U != 0, K > U** | Since kernel memory charges are also fed to the user counter and reclamation is triggered for the container for both kinds of memory. This configuration gives the admin a unified view of memory. It is also useful for people who just want to track kernel memory usage. |\n\nExamples:\n\nWe set memory and kernel memory, so the processes in the container can use 500M memory in total, in this 500M memory, it can be 50M kernel memory tops.\n\nWe set kernel memory without **\\-m**, so the processes in the container can use as much memory as they want, but they can only use 50M kernel memory.\n\n### [Swappiness constraint](#swappiness-constraint)\n\nBy default, a container's kernel can swap out a percentage of anonymous pages. To set this percentage for a container, specify a `--memory-swappiness` value between 0 and 100. A value of 0 turns off anonymous page swapping. A value of 100 sets all anonymous pages as swappable. By default, if you are not using `--memory-swappiness`, memory swappiness value will be inherited from the parent.\n\nFor example, you can set:\n\nSetting the `--memory-swappiness` option is helpful when you want to retain the container's working set and to avoid swapping performance penalties.\n\nBy default, all containers get the same proportion of CPU cycles. This proportion can be modified by changing the container's CPU share weighting relative to the weighting of all other running containers.\n\nTo modify the proportion from the default of 1024, use the `-c` or `--cpu-shares` flag to set the weighting to 2 or higher. If 0 is set, the system will ignore the value and use the default of 1024.\n\nThe proportion will only apply when CPU-intensive processes are running. When tasks in one container are idle, other containers can use the left-over CPU time. The actual amount of CPU time will vary depending on the number of containers running on the system.\n\nFor example, consider three containers, one has a cpu-share of 1024 and two others have a cpu-share setting of 512. When processes in all three containers attempt to use 100% of CPU, the first container would receive 50% of the total CPU time. If you add a fourth container with a cpu-share of 1024, the first container only gets 33% of the CPU. The remaining containers receive 16.5%, 16.5% and 33% of the CPU.\n\nOn a multi-core system, the shares of CPU time are distributed over all CPU cores. Even if a container is limited to less than 100% of CPU time, it can use 100% of each individual CPU core.\n\nFor example, consider a system with more than three cores. If you start one container `{C0}` with `-c=512` running one process, and another container `{C1}` with `-c=1024` running two processes, this can result in the following division of CPU shares:\n\n```\nPID    container\tCPU\tCPU share\n100    {C0}\t\t0\t100% of CPU0\n101    {C1}\t\t1\t100% of CPU1\n102    {C1}\t\t2\t100% of CPU2\n```\n\n### [CPU period constraint](#cpu-period-constraint)\n\nThe default CPU CFS (Completely Fair Scheduler) period is 100ms. We can use `--cpu-period` to set the period of CPUs to limit the container's CPU usage. And usually `--cpu-period` should work with `--cpu-quota`.\n\nExamples:\n\nIf there is 1 CPU, this means the container can get 50% CPU worth of run-time every 50ms.\n\nIn addition to use `--cpu-period` and `--cpu-quota` for setting CPU period constraints, it is possible to specify `--cpus` with a float number to achieve the same purpose. For example, if there is 1 CPU, then `--cpus=0.5` will achieve the same result as setting `--cpu-period=50000` and `--cpu-quota=25000` (50% CPU).\n\nThe default value for `--cpus` is `0.000`, which means there is no limit.\n\nFor more information, see the [CFS documentation on bandwidth limiting](https://www.kernel.org/doc/Documentation/scheduler/sched-bwc.txt).\n\n### [Cpuset constraint](#cpuset-constraint)\n\nWe can set cpus in which to allow execution for containers.\n\nExamples:\n\nThis means processes in container can be executed on cpu 1 and cpu 3.\n\nThis means processes in container can be executed on cpu 0, cpu 1 and cpu 2.\n\nWe can set mems in which to allow execution for containers. Only effective on NUMA systems.\n\nExamples:\n\nThis example restricts the processes in the container to only use memory from memory nodes 1 and 3.\n\nThis example restricts the processes in the container to only use memory from memory nodes 0, 1 and 2.\n\n### [CPU quota constraint](#cpu-quota-constraint)\n\nThe `--cpu-quota` flag limits the container's CPU usage. The default 0 value allows the container to take 100% of a CPU resource (1 CPU). The CFS (Completely Fair Scheduler) handles resource allocation for executing processes and is default Linux Scheduler used by the kernel. Set this value to 50000 to limit the container to 50% of a CPU resource. For multiple CPUs, adjust the `--cpu-quota` as necessary. For more information, see the [CFS documentation on bandwidth limiting](https://www.kernel.org/doc/Documentation/scheduler/sched-bwc.txt).\n\n### [Block IO bandwidth (Blkio) constraint](#block-io-bandwidth-blkio-constraint)\n\nBy default, all containers get the same proportion of block IO bandwidth (blkio). This proportion is 500. To modify this proportion, change the container's blkio weight relative to the weighting of all other running containers using the `--blkio-weight` flag.\n\n> **Note:**\n> \n> The blkio weight setting is only available for direct IO. Buffered IO is not currently supported.\n\nThe `--blkio-weight` flag can set the weighting to a value between 10 to 1000. For example, the commands below create two containers with different blkio weight:\n\nIf you do block IO in the two containers at the same time, by, for example:\n\nYou'll find that the proportion of time is the same as the proportion of blkio weights of the two containers.\n\nThe `--blkio-weight-device=\"DEVICE_NAME:WEIGHT\"` flag sets a specific device weight. The `DEVICE_NAME:WEIGHT` is a string containing a colon-separated device name and weight. For example, to set `/dev/sda` device weight to `200`:\n\nIf you specify both the `--blkio-weight` and `--blkio-weight-device`, Docker uses the `--blkio-weight` as the default weight and uses `--blkio-weight-device` to override this default with a new value on a specific device. The following example uses a default weight of `300` and overrides this default on `/dev/sda` setting that weight to `200`:\n\nThe `--device-read-bps` flag limits the read rate (bytes per second) from a device. For example, this command creates a container and limits the read rate to `1mb` per second from `/dev/sda`:\n\nThe `--device-write-bps` flag limits the write rate (bytes per second) to a device. For example, this command creates a container and limits the write rate to `1mb` per second for `/dev/sda`:\n\nBoth flags take limits in the `<device-path>:<limit>[unit]` format. Both read and write rates must be a positive integer. You can specify the rate in `kb` (kilobytes), `mb` (megabytes), or `gb` (gigabytes).\n\nThe `--device-read-iops` flag limits read rate (IO per second) from a device. For example, this command creates a container and limits the read rate to `1000` IO per second from `/dev/sda`:\n\nThe `--device-write-iops` flag limits write rate (IO per second) to a device. For example, this command creates a container and limits the write rate to `1000` IO per second to `/dev/sda`:\n\nBoth flags take limits in the `<device-path>:<limit>` format. Both read and write rates must be a positive integer.\n\nBy default, the docker container process runs with the supplementary groups looked up for the specified user. If one wants to add more to that list of groups, then one can use this flag:\n\n| Option | Description |\n| --- | --- |\n| `--cap-add` | Add Linux capabilities |\n| `--cap-drop` | Drop Linux capabilities |\n| `--privileged` | Give extended privileges to this container |\n| `--device=[]` | Allows you to run devices inside the container without the `--privileged` flag. |\n\nBy default, Docker containers are \"unprivileged\" and cannot, for example, run a Docker daemon inside a Docker container. This is because by default a container is not allowed to access any devices, but a \"privileged\" container is given access to all devices (see the documentation on [cgroups devices](https://www.kernel.org/doc/Documentation/cgroup-v1/devices.txt)).\n\nThe `--privileged` flag gives all capabilities to the container. When the operator executes `docker run --privileged`, Docker enables access to all devices on the host, and reconfigures AppArmor or SELinux to allow the container nearly all the same access to the host as processes running outside containers on the host. Use this flag with caution. For more information about the `--privileged` flag, see the [`docker run` reference](https://docs.docker.com/reference/cli/docker/container/run/#privileged).\n\nIf you want to limit access to a specific device or devices you can use the `--device` flag. It allows you to specify one or more devices that will be accessible within the container.\n\nBy default, the container will be able to `read`, `write`, and `mknod` these devices. This can be overridden using a third `:rwm` set of options to each `--device` flag:\n\nIn addition to `--privileged`, the operator can have fine grain control over the capabilities using `--cap-add` and `--cap-drop`. By default, Docker has a default list of capabilities that are kept. The following table lists the Linux capability options which are allowed by default and can be dropped.\n\n| Capability Key | Capability Description |\n| --- | --- |\n| AUDIT\\_WRITE | Write records to kernel auditing log. |\n| CHOWN | Make arbitrary changes to file UIDs and GIDs (see chown(2)). |\n| DAC\\_OVERRIDE | Bypass file read, write, and execute permission checks. |\n| FOWNER | Bypass permission checks on operations that normally require the file system UID of the process to match the UID of the file. |\n| FSETID | Don't clear set-user-ID and set-group-ID permission bits when a file is modified. |\n| KILL | Bypass permission checks for sending signals. |\n| MKNOD | Create special files using mknod(2). |\n| NET\\_BIND\\_SERVICE | Bind a socket to internet domain privileged ports (port numbers less than 1024). |\n| NET\\_RAW | Use RAW and PACKET sockets. |\n| SETFCAP | Set file capabilities. |\n| SETGID | Make arbitrary manipulations of process GIDs and supplementary GID list. |\n| SETPCAP | Modify process capabilities. |\n| SETUID | Make arbitrary manipulations of process UIDs. |\n| SYS\\_CHROOT | Use chroot(2), change root directory. |\n\nThe next table shows the capabilities which are not granted by default and may be added.\n\n| Capability Key | Capability Description |\n| --- | --- |\n| AUDIT\\_CONTROL | Enable and disable kernel auditing; change auditing filter rules; retrieve auditing status and filtering rules. |\n| AUDIT\\_READ | Allow reading the audit log via multicast netlink socket. |\n| BLOCK\\_SUSPEND | Allow preventing system suspends. |\n| BPF | Allow creating BPF maps, loading BPF Type Format (BTF) data, retrieve JITed code of BPF programs, and more. |\n| CHECKPOINT\\_RESTORE | Allow checkpoint/restore related operations. Introduced in kernel 5.9. |\n| DAC\\_READ\\_SEARCH | Bypass file read permission checks and directory read and execute permission checks. |\n| IPC\\_LOCK | Lock memory (mlock(2), mlockall(2), mmap(2), shmctl(2)). |\n| IPC\\_OWNER | Bypass permission checks for operations on System V IPC objects. |\n| LEASE | Establish leases on arbitrary files (see fcntl(2)). |\n| LINUX\\_IMMUTABLE | Set the FS\\_APPEND\\_FL and FS\\_IMMUTABLE\\_FL i-node flags. |\n| MAC\\_ADMIN | Allow MAC configuration or state changes. Implemented for the Smack LSM. |\n| MAC\\_OVERRIDE | Override Mandatory Access Control (MAC). Implemented for the Smack Linux Security Module (LSM). |\n| NET\\_ADMIN | Perform various network-related operations. |\n| NET\\_BROADCAST | Make socket broadcasts, and listen to multicasts. |\n| PERFMON | Allow system performance and observability privileged operations using perf\\_events, i915\\_perf and other kernel subsystems |\n| SYS\\_ADMIN | Perform a range of system administration operations. |\n| SYS\\_BOOT | Use reboot(2) and kexec\\_load(2), reboot and load a new kernel for later execution. |\n| SYS\\_MODULE | Load and unload kernel modules. |\n| SYS\\_NICE | Raise process nice value (nice(2), setpriority(2)) and change the nice value for arbitrary processes. |\n| SYS\\_PACCT | Use acct(2), switch process accounting on or off. |\n| SYS\\_PTRACE | Trace arbitrary processes using ptrace(2). |\n| SYS\\_RAWIO | Perform I/O port operations (iopl(2) and ioperm(2)). |\n| SYS\\_RESOURCE | Override resource Limits. |\n| SYS\\_TIME | Set system clock (settimeofday(2), stime(2), adjtimex(2)); set real-time (hardware) clock. |\n| SYS\\_TTY\\_CONFIG | Use vhangup(2); employ various privileged ioctl(2) operations on virtual terminals. |\n| SYSLOG | Perform privileged syslog(2) operations. |\n| WAKE\\_ALARM | Trigger something that will wake up the system. |\n\nFurther reference information is available on the [capabilities(7) - Linux man page](https://man7.org/linux/man-pages/man7/capabilities.7.html), and in the [Linux kernel source code](https://github.com/torvalds/linux/blob/124ea650d3072b005457faed69909221c2905a1f/include/uapi/linux/capability.h).\n\nBoth flags support the value `ALL`, so to allow a container to use all capabilities except for `MKNOD`:\n\nThe `--cap-add` and `--cap-drop` flags accept capabilities to be specified with a `CAP_` prefix. The following examples are therefore equivalent:\n\nFor interacting with the network stack, instead of using `--privileged` they should use `--cap-add=NET_ADMIN` to modify the network interfaces.\n\nTo mount a FUSE based filesystem, you need to combine both `--cap-add` and `--device`:\n\nThe default seccomp profile will adjust to the selected capabilities, in order to allow use of facilities allowed by the capabilities, so you should not have to adjust this.\n\nWhen you build an image from a [Dockerfile](https://docs.docker.com/reference/dockerfile/), or when committing it, you can set a number of default parameters that take effect when the image starts up as a container. When you run an image, you can override those defaults using flags for the `docker run` command.\n\n*   [Default entrypoint](#default-entrypoint)\n*   [Default command and options](#default-command-and-options)\n*   [Expose ports](#exposed-ports)\n*   [Environment variables](#environment-variables)\n*   [Healthcheck](#healthchecks)\n*   [User](#user)\n*   [Working directory](#working-directory)\n\n### [Default command and options](#default-command-and-options)\n\nThe command syntax for `docker run` supports optionally specifying commands and arguments to the container's entrypoint, represented as `[COMMAND]` and `[ARG...]` in the following synopsis example:\n\nThis command is optional because whoever created the `IMAGE` may have already provided a default `COMMAND`, using the Dockerfile `CMD` instruction. When you run a container, you can override that `CMD` instruction just by specifying a new `COMMAND`.\n\nIf the image also specifies an `ENTRYPOINT` then the `CMD` or `COMMAND` get appended as arguments to the `ENTRYPOINT`.\n\n### [Default entrypoint](#default-entrypoint)\n\nThe entrypoint refers to the default executable that's invoked when you run a container. A container's entrypoint is defined using the Dockerfile `ENTRYPOINT` instruction. It's similar to specifying a default command because it specifies, but the difference is that you need to pass an explicit flag to override the entrypoint, whereas you can override default commands with positional arguments. The defines a container's default behavior, with the idea that when you set an entrypoint you can run the container _as if it were that binary_, complete with default options, and you can pass in more options as commands. But there are cases where you may want to run something else inside the container. This is when overriding the default entrypoint at runtime comes in handy, using the `--entrypoint` flag for the `docker run` command.\n\nThe `--entrypoint` flag expects a string value, representing the name or path of the binary that you want to invoke when the container starts. The following example shows you how to run a Bash shell in a container that has been set up to automatically run some other binary (like `/usr/bin/redis-server`):\n\nThe following examples show how to pass additional parameters to the custom entrypoint, using the positional command arguments:\n\nYou can reset a containers entrypoint by passing an empty string, for example:\n\n> **Note**\n> \n> Passing `--entrypoint` clears out any default command set on the image. That is, any `CMD` instruction in the Dockerfile used to build it.\n\n### [Exposed ports](#exposed-ports)\n\nBy default, when you run a container, none of the container's ports are exposed to the host. This means you won't be able to access any ports that the container might be listening on. To make a container's ports accessible from the host, you need to publish the ports.\n\nYou can start the container with the `-P` or `-p` flags to expose its ports:\n\n*   The `-P` (or `--publish-all`) flag publishes all the exposed ports to the host. Docker binds each exposed port to a random port on the host.\n    \n    The `-P` flag only publishes port numbers that are explicitly flagged as exposed, either using the Dockerfile `EXPOSE` instruction or the `--expose` flag for the `docker run` command.\n    \n*   The `-p` (or `--publish`) flag lets you explicitly map a single port or range of ports in the container to the host.\n    \n\nThe port number inside the container (where the service listens) doesn't need to match the port number published on the outside of the container (where clients connect). For example, inside the container an HTTP service might be listening on port 80. At runtime, the port might be bound to 42800 on the host. To find the mapping between the host ports and the exposed ports, use the `docker port` command.\n\n### [Environment variables](#environment-variables)\n\nDocker automatically sets some environment variables when creating a Linux container. Docker doesn't set any environment variables when creating a Windows container.\n\nThe following environment variables are set for Linux containers:\n\n| Variable | Value |\n| --- | --- |\n| `HOME` | Set based on the value of `USER` |\n| `HOSTNAME` | The hostname associated with the container |\n| `PATH` | Includes popular directories, such as `/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin` |\n| `TERM` | `xterm` if the container is allocated a pseudo-TTY |\n\nAdditionally, you can set any environment variable in the container by using one or more `-e` flags. You can even override the variables mentioned above, or variables defined using a Dockerfile `ENV` instruction when building the image.\n\nIf the you name an environment variable without specifying a value, the current value of the named variable on the host is propagated into the container's environment:\n\n### [Healthchecks](#healthchecks)\n\nThe following flags for the `docker run` command let you control the parameters for container healthchecks:\n\n| Option | Description |\n| --- | --- |\n| `--health-cmd` | Command to run to check health |\n| `--health-interval` | Time between running the check |\n| `--health-retries` | Consecutive failures needed to report unhealthy |\n| `--health-timeout` | Maximum time to allow one check to run |\n| `--health-start-period` | Start period for the container to initialize before starting health-retries countdown |\n| `--health-start-interval` | Time between running the check during the start period |\n| `--no-healthcheck` | Disable any container-specified `HEALTHCHECK` |\n\nExample:\n\nThe health status is also displayed in the `docker ps` output.\n\n### [User](#user)\n\nThe default user within a container is `root` (uid = 0). You can set a default user to run the first process with the Dockerfile `USER` instruction. When starting a container, you can override the `USER` instruction by passing the `-u` option.\n\nThe followings examples are all valid:\n\n> **Note**\n> \n> If you pass a numeric user ID, it must be in the range of 0-2147483647. If you pass a username, the user must exist in the container.\n\n### [Working directory](#working-directory)\n\nThe default working directory for running binaries within a container is the root directory (`/`). The default working directory of an image is set using the Dockerfile `WORKDIR` command. You can override the default working directory for an image using the `-w` (or `--workdir`) flag for the `docker run` command:\n\nIf the directory doesn't already exist in the container, it's created.",
  "title": "Running containers | Docker Docs\n",
  "description": "Running and configuring containers with the Docker CLI",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/security/trust/trust_key_mng/",
  "markdown": "# Manage keys for content trust\n\nTrust for an image tag is managed through the use of keys. Docker's content trust makes use of five different types of keys:\n\n| Key | Description |\n| --- | --- |\n| root key | Root of content trust for an image tag. When content trust is enabled, you create the root key once. Also known as the offline key, because it should be kept offline. |\n| targets | This key allows you to sign image tags, to manage delegations including delegated keys or permitted delegation paths. Also known as the repository key, since this key determines what tags can be signed into an image repository. |\n| snapshot | This key signs the current collection of image tags, preventing mix and match attacks. |\n| timestamp | This key allows Docker image repositories to have freshness security guarantees without requiring periodic content refreshes on the client's side. |\n| delegation | Delegation keys are optional tagging keys and allow you to delegate signing image tags to other publishers without having to share your targets key. |\n\nWhen doing a `docker push` with Content Trust enabled for the first time, the root, targets, snapshot, and timestamp keys are generated automatically for the image repository:\n\n*   The root and targets key are generated and stored locally client-side.\n    \n*   The timestamp and snapshot keys are safely generated and stored in a signing server that is deployed alongside the Docker registry. These keys are generated in a backend service that isn't directly exposed to the internet and are encrypted at rest. Use the Notary CLI to [manage your snapshot key locally](https://github.com/theupdateframework/notary/blob/master/docs/advanced_usage.md#rotate-keys).\n    \n\nDelegation keys are optional, and not generated as part of the normal `docker` workflow. They need to be [manually generated and added to the repository](https://docs.docker.com/engine/security/trust/trust_delegation/#creating-delegation-keys).\n\nThe passphrases you chose for both the root key and your repository key should be randomly generated and stored in a password manager. Having the repository key allows users to sign image tags on a repository. Passphrases are used to encrypt your keys at rest and ensure that a lost laptop or an unintended backup doesn't put the private key material at risk.\n\nAll the Docker trust keys are stored encrypted using the passphrase you provide on creation. Even so, you should still take care of the location where you back them up. Good practice is to create two encrypted USB keys.\n\n> **Warning**\n> \n> It is very important that you back up your keys to a safe, secure location. The loss of the repository key is recoverable, but the loss of the root key is not.\n\nThe Docker client stores the keys in the `~/.docker/trust/private` directory. Before backing them up, you should `tar` them into an archive:\n\nDocker Content Trust can store and sign with root keys from a Yubikey 4. The Yubikey is prioritized over keys stored in the filesystem. When you initialize a new repository with content trust, Docker Engine looks for a root key locally. If a key is not found and the Yubikey 4 exists, Docker Engine creates a root key in the Yubikey 4. Consult the [Notary documentation](https://github.com/theupdateframework/notary/blob/master/docs/advanced_usage.md#use-a-yubikey) for more details.\n\nPrior to Docker Engine 1.11, this feature was only in the experimental branch.\n\n> **Warning**\n> \n> If a publisher loses keys it means losing the ability to sign images for the repositories in question. If you lose a key, send an email to Docker Hub Support. As a reminder, the loss of a root key is not recoverable.\n\nThis loss also requires manual intervention from every consumer that used a signed tag from this repository prior to the loss.  \nImage consumers get the following error for content previously downloaded from the affected repo(s):\n\nTo correct this, they need to download a new image tag that is signed with the new key.\n\n*   [Content trust in Docker](https://docs.docker.com/engine/security/trust/)\n*   [Automation with content trust](https://docs.docker.com/engine/security/trust/trust_automation/)\n*   [Delegations for content trust](https://docs.docker.com/engine/security/trust/trust_delegation/)\n*   [Play in a content trust sandbox](https://docs.docker.com/engine/security/trust/trust_sandbox/)",
  "title": "Manage keys for content trust | Docker Docs\n",
  "description": "Manage keys for content trust",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/security/trust/trust_sandbox/",
  "markdown": "# Play in a content trust sandbox\n\nThis page explains how to set up and use a sandbox for experimenting with trust. The sandbox allows you to configure and try trust operations locally without impacting your production images.\n\nBefore working through this sandbox, you should have read through the [trust overview](https://docs.docker.com/engine/security/trust/).\n\nThese instructions assume you are running in Linux or macOS. You can run this sandbox on a local machine or on a virtual machine. You need to have privileges to run docker commands on your local machine or in the VM.\n\nThis sandbox requires you to install two Docker tools: Docker Engine >= 1.10.0 and Docker Compose >= 1.6.0. To install the Docker Engine, choose from the [list of supported platforms](https://docs.docker.com/engine/install/). To install Docker Compose, see the [detailed instructions here](https://docs.docker.com/compose/install/).\n\nIf you are just using trust out-of-the-box you only need your Docker Engine client and access to the Docker Hub. The sandbox mimics a production trust environment, and sets up these additional components.\n\n| Container | Description |\n| --- | --- |\n| trustsandbox | A container with the latest version of Docker Engine and with some preconfigured certificates. This is your sandbox where you can use the `docker` client to test trust operations. |\n| Registry server | A local registry service. |\n| Notary server | The service that does all the heavy-lifting of managing trust |\n\nThis means you run your own content trust (Notary) server and registry. If you work exclusively with the Docker Hub, you would not need these components. They are built into the Docker Hub for you. For the sandbox, however, you build your own entire, mock production environment.\n\nWithin the `trustsandbox` container, you interact with your local registry rather than the Docker Hub. This means your everyday image repositories are not used. They are protected while you play.\n\nWhen you play in the sandbox, you also create root and repository keys. The sandbox is configured to store all the keys and files inside the `trustsandbox` container. Since the keys you create in the sandbox are for play only, destroying the container destroys them as well.\n\nBy using a docker-in-docker image for the `trustsandbox` container, you also don't pollute your real Docker daemon cache with any images you push and pull. The images are stored in an anonymous volume attached to this container, and can be destroyed after you destroy the container.\n\nIn this section, you use Docker Compose to specify how to set up and link together the `trustsandbox` container, the Notary server, and the Registry server.\n\n1.  Create a new `trustsandbox` directory and change into it.\n    \n    ```\n     $ mkdir trustsandbox\n     $ cd trustsandbox\n    ```\n    \n2.  Create a file called `compose.yml` with your favorite editor. For example, using vim:\n    \n    ```\n     $ touch compose.yml\n     $ vim compose.yml\n    ```\n    \n3.  Add the following to the new file.\n    \n    ```\n     version: \"2\"\n     services:\n       notaryserver:\n         image: dockersecurity/notary_autobuilds:server-v0.5.1\n         volumes:\n           - notarycerts:/var/lib/notary/fixtures\n         networks:\n           - sandbox\n         environment:\n           - NOTARY_SERVER_STORAGE_TYPE=memory\n           - NOTARY_SERVER_TRUST_SERVICE_TYPE=local\n       sandboxregistry:\n         image: registry:2.4.1\n         networks:\n           - sandbox\n         container_name: sandboxregistry\n       trustsandbox:\n         image: docker:dind\n         networks:\n           - sandbox\n         volumes:\n           - notarycerts:/notarycerts\n         privileged: true\n         container_name: trustsandbox\n         entrypoint: \"\"\n         command: |-\n             sh -c '\n                 cp /notarycerts/root-ca.crt /usr/local/share/ca-certificates/root-ca.crt &&\n                 update-ca-certificates &&\n                 dockerd-entrypoint.sh --insecure-registry sandboxregistry:5000'\n     volumes:\n       notarycerts:\n         external: false\n     networks:\n       sandbox:\n         external: false\n    ```\n    \n4.  Save and close the file.\n    \n5.  Run the containers on your local system.\n    \n    ```\n     $ docker compose up -d\n    ```\n    \n    The first time you run this, the docker-in-docker, Notary server, and registry images are downloaded from Docker Hub.\n    \n\nNow that everything is setup, you can go into your `trustsandbox` container and start testing Docker content trust. From your host machine, obtain a shell in the `trustsandbox` container.\n\n```\n$ docker container exec -it trustsandbox sh\n/ #\n```\n\n### [Test some trust operations](#test-some-trust-operations)\n\nNow, pull some images from within the `trustsandbox` container.\n\n1.  Download a `docker` image to test with.\n    \n    ```\n     / # docker pull docker/trusttest\n     docker pull docker/trusttest\n     Using default tag: latest\n     latest: Pulling from docker/trusttest\n    \n     b3dbab3810fc: Pull complete\n     a9539b34a6ab: Pull complete\n     Digest: sha256:d149ab53f8718e987c3a3024bb8aa0e2caadf6c0328f1d9d850b2a2a67f2819a\n     Status: Downloaded newer image for docker/trusttest:latest\n    ```\n    \n2.  Tag it to be pushed to our sandbox registry:\n    \n    ```\n     / # docker tag docker/trusttest sandboxregistry:5000/test/trusttest:latest\n    ```\n    \n3.  Enable content trust.\n    \n    ```\n     / # export DOCKER_CONTENT_TRUST=1\n    ```\n    \n4.  Identify the trust server.\n    \n    ```\n     / # export DOCKER_CONTENT_TRUST_SERVER=https://notaryserver:4443\n    ```\n    \n    This step is only necessary because the sandbox is using its own server. Normally, if you are using the Docker Public Hub this step isn't necessary.\n    \n5.  Pull the test image.\n    \n    ```\n     / # docker pull sandboxregistry:5000/test/trusttest\n     Using default tag: latest\n     Error: remote trust data does not exist for sandboxregistry:5000/test/trusttest: notaryserver:4443 does not have trust data for sandboxregistry:5000/test/trusttest\n    ```\n    \n    You see an error, because this content doesn't exist on the `notaryserver` yet.\n    \n6.  Push and sign the trusted image.\n    \n    ```\n     / # docker push sandboxregistry:5000/test/trusttest:latest\n     The push refers to a repository [sandboxregistry:5000/test/trusttest]\n     5f70bf18a086: Pushed\n     c22f7bc058a9: Pushed\n     latest: digest: sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926 size: 734\n     Signing and pushing trust metadata\n     You are about to create a new root signing key passphrase. This passphrase\n     will be used to protect the most sensitive key in your signing system. Please\n     choose a long, complex passphrase and be careful to keep the password and the\n     key file itself secure and backed up. It is highly recommended that you use a\n     password manager to generate the passphrase and keep it safe. There will be no\n     way to recover this key. You can find the key in your config directory.\n     Enter passphrase for new root key with ID 27ec255:\n     Repeat passphrase for new root key with ID 27ec255:\n     Enter passphrase for new repository key with ID 58233f9 (sandboxregistry:5000/test/trusttest):\n     Repeat passphrase for new repository key with ID 58233f9 (sandboxregistry:5000/test/trusttest):\n     Finished initializing \"sandboxregistry:5000/test/trusttest\"\n     Successfully signed \"sandboxregistry:5000/test/trusttest\":latest\n    ```\n    \n    Because you are pushing this repository for the first time, Docker creates new root and repository keys and asks you for passphrases with which to encrypt them. If you push again after this, it only asks you for repository passphrase so it can decrypt the key and sign again.\n    \n7.  Try pulling the image you just pushed:\n    \n    ```\n     / # docker pull sandboxregistry:5000/test/trusttest\n     Using default tag: latest\n     Pull (1 of 1): sandboxregistry:5000/test/trusttest:latest@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926\n     sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926: Pulling from test/trusttest\n     Digest: sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926\n     Status: Downloaded newer image for sandboxregistry:5000/test/trusttest@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926\n     Tagging sandboxregistry:5000/test/trusttest@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926 as sandboxregistry:5000/test/trusttest:latest\n    ```\n    \n\n### [Test with malicious images](#test-with-malicious-images)\n\nWhat happens when data is corrupted and you try to pull it when trust is enabled? In this section, you go into the `sandboxregistry` and tamper with some data. Then, you try and pull it.\n\n1.  Leave the `trustsandbox` shell and container running.\n    \n2.  Open a new interactive terminal from your host, and obtain a shell into the `sandboxregistry` container.\n    \n    ```\n    $ docker container exec -it sandboxregistry bash\n    root@65084fc6f047:/#\n    ```\n    \n3.  List the layers for the `test/trusttest` image you pushed:\n    \n4.  Change into the registry storage for one of those layers (this is in a different directory):\n    \n    ```\n    root@65084fc6f047:/# cd /var/lib/registry/docker/registry/v2/blobs/sha256/aa/aac0c133338db2b18ff054943cee3267fe50c75cdee969aed88b1992539ed042\n    ```\n    \n5.  Add malicious data to one of the `trusttest` layers:\n    \n    ```\n    root@65084fc6f047:/# echo \"Malicious data\" > data\n    ```\n    \n6.  Go back to your `trustsandbox` terminal.\n    \n7.  List the `trusttest` image.\n    \n    ```\n    / # docker image ls | grep trusttest\n    REPOSITORY                            TAG                 IMAGE ID            CREATED             SIZE\n    docker/trusttest                      latest              cc7629d1331a        11 months ago       5.025 MB\n    sandboxregistry:5000/test/trusttest   latest              cc7629d1331a        11 months ago       5.025 MB\n    sandboxregistry:5000/test/trusttest   <none>              cc7629d1331a        11 months ago       5.025 MB\n    ```\n    \n8.  Remove the `trusttest:latest` image from our local cache.\n    \n    ```\n    / # docker image rm -f cc7629d1331a\n    Untagged: docker/trusttest:latest\n    Untagged: sandboxregistry:5000/test/trusttest:latest\n    Untagged: sandboxregistry:5000/test/trusttest@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926\n    Deleted: sha256:cc7629d1331a7362b5e5126beb5bf15ca0bf67eb41eab994c719a45de53255cd\n    Deleted: sha256:2a1f6535dc6816ffadcdbe20590045e6cbf048d63fd4cc753a684c9bc01abeea\n    Deleted: sha256:c22f7bc058a9a8ffeb32989b5d3338787e73855bf224af7aa162823da015d44c\n    ```\n    \n    Docker does not re-download images that it already has cached, but we want Docker to attempt to download the tampered image from the registry and reject it because it is invalid.\n    \n9.  Pull the image again. This downloads the image from the registry, because we don't have it cached.\n    \n    ```\n    / # docker pull sandboxregistry:5000/test/trusttest\n    Using default tag: latest\n    Pull (1 of 1): sandboxregistry:5000/test/trusttest:latest@sha256:35d5bc26fd358da8320c137784fe590d8fcf9417263ef261653e8e1c7f15672e\n    sha256:35d5bc26fd358da8320c137784fe590d8fcf9417263ef261653e8e1c7f15672e: Pulling from test/trusttest\n    \n    aac0c133338d: Retrying in 5 seconds\n    a3ed95caeb02: Download complete\n    error pulling image configuration: unexpected EOF\n    ```\n    \n    The pull did not complete because the trust system couldn't verify the image.\n    \n\nNow, you have a full Docker content trust sandbox on your local system, feel free to play with it and see how it behaves. If you find any security issues with Docker, feel free to send us an email at security@docker.com.\n\nWhen you are done, and want to clean up all the services you've started and any anonymous volumes that have been created, just run the following command in the directory where you've created your Docker Compose file:\n\n```\n    $ docker compose down -v\n```",
  "title": "Play in a content trust sandbox | Docker Docs\n",
  "description": "Play in a trust sandbox",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/admin_guide/",
  "markdown": "# Administer and maintain a swarm of Docker Engines\n\nWhen you run a swarm of Docker Engines, manager nodes are the key components for managing the swarm and storing the swarm state. It is important to understand some key features of manager nodes to properly deploy and maintain the swarm.\n\nRefer to [How nodes work](https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/) for a brief overview of Docker Swarm mode and the difference between manager and worker nodes.\n\nSwarm manager nodes use the [Raft Consensus Algorithm](https://docs.docker.com/engine/swarm/raft/) to manage the swarm state. You only need to understand some general concepts of Raft in order to manage a swarm.\n\nThere is no limit on the number of manager nodes. The decision about how many manager nodes to implement is a trade-off between performance and fault-tolerance. Adding manager nodes to a swarm makes the swarm more fault-tolerant. However, additional manager nodes reduce write performance because more nodes must acknowledge proposals to update the swarm state. This means more network round-trip traffic.\n\nRaft requires a majority of managers, also called the quorum, to agree on proposed updates to the swarm, such as node additions or removals. Membership operations are subject to the same constraints as state replication.\n\n### [Maintain the quorum of managers](#maintain-the-quorum-of-managers)\n\nIf the swarm loses the quorum of managers, the swarm cannot perform management tasks. If your swarm has multiple managers, always have more than two. To maintain quorum, a majority of managers must be available. An odd number of managers is recommended, because the next even number does not make the quorum easier to keep. For instance, whether you have 3 or 4 managers, you can still only lose 1 manager and maintain the quorum. If you have 5 or 6 managers, you can still only lose two.\n\nEven if a swarm loses the quorum of managers, swarm tasks on existing worker nodes continue to run. However, swarm nodes cannot be added, updated, or removed, and new or existing tasks cannot be started, stopped, moved, or updated.\n\nSee [Recovering from losing the quorum](#recover-from-losing-the-quorum) for troubleshooting steps if you do lose the quorum of managers.\n\nWhen initiating a swarm, you must specify the `--advertise-addr` flag to advertise your address to other manager nodes in the swarm. For more information, see [Run Docker Engine in swarm mode](https://docs.docker.com/engine/swarm/swarm-mode/#configure-the-advertise-address). Because manager nodes are meant to be a stable component of the infrastructure, you should use a _fixed IP address_ for the advertise address to prevent the swarm from becoming unstable on machine reboot.\n\nIf the whole swarm restarts and every manager node subsequently gets a new IP address, there is no way for any node to contact an existing manager. Therefore the swarm is hung while nodes try to contact one another at their old IP addresses.\n\nDynamic IP addresses are OK for worker nodes.\n\nYou should maintain an odd number of managers in the swarm to support manager node failures. Having an odd number of managers ensures that during a network partition, there is a higher chance that the quorum remains available to process requests if the network is partitioned into two sets. Keeping the quorum is not guaranteed if you encounter more than two network partitions.\n\n| Swarm Size | Majority | Fault Tolerance |\n| --- | --- | --- |\n| 1   | 1   | 0   |\n| 2   | 2   | 0   |\n| **3** | 2   | **1** |\n| 4   | 3   | 1   |\n| **5** | 3   | **2** |\n| 6   | 4   | 2   |\n| **7** | 4   | **3** |\n| 8   | 5   | 3   |\n| **9** | 5   | **4** |\n\nFor example, in a swarm with _5 nodes_, if you lose _3 nodes_, you don't have a quorum. Therefore you can't add or remove nodes until you recover one of the unavailable manager nodes or recover the swarm with disaster recovery commands. See [Recover from disaster](#recover-from-disaster).\n\nWhile it is possible to scale a swarm down to a single manager node, it is impossible to demote the last manager node. This ensures you maintain access to the swarm and that the swarm can still process requests. Scaling down to a single manager is an unsafe operation and is not recommended. If the last node leaves the swarm unexpectedly during the demote operation, the swarm becomes unavailable until you reboot the node or restart with `--force-new-cluster`.\n\nYou manage swarm membership with the `docker swarm` and `docker node` subsystems. Refer to [Add nodes to a swarm](https://docs.docker.com/engine/swarm/join-nodes/) for more information on how to add worker nodes and promote a worker node to be a manager.\n\n### [Distribute manager nodes](#distribute-manager-nodes)\n\nIn addition to maintaining an odd number of manager nodes, pay attention to datacenter topology when placing managers. For optimal fault-tolerance, distribute manager nodes across a minimum of 3 availability-zones to support failures of an entire set of machines or common maintenance scenarios. If you suffer a failure in any of those zones, the swarm should maintain the quorum of manager nodes available to process requests and rebalance workloads.\n\n| Swarm manager nodes | Repartition (on 3 Availability zones) |\n| --- | --- |\n| 3   | 1-1-1 |\n| 5   | 2-2-1 |\n| 7   | 3-2-2 |\n| 9   | 3-3-3 |\n\n### [Run manager-only nodes](#run-manager-only-nodes)\n\nBy default manager nodes also act as a worker nodes. This means the scheduler can assign tasks to a manager node. For small and non-critical swarms assigning tasks to managers is relatively low-risk as long as you schedule services using resource constraints for cpu and memory.\n\nHowever, because manager nodes use the Raft consensus algorithm to replicate data in a consistent way, they are sensitive to resource starvation. You should isolate managers in your swarm from processes that might block swarm operations like swarm heartbeat or leader elections.\n\nTo avoid interference with manager node operation, you can drain manager nodes to make them unavailable as worker nodes:\n\nWhen you drain a node, the scheduler reassigns any tasks running on the node to other available worker nodes in the swarm. It also prevents the scheduler from assigning tasks to the node.\n\n[Add nodes to the swarm](https://docs.docker.com/engine/swarm/join-nodes/) to balance your swarm's load. Replicated service tasks are distributed across the swarm as evenly as possible over time, as long as the worker nodes are matched to the requirements of the services. When limiting a service to run on only specific types of nodes, such as nodes with a specific number of CPUs or amount of memory, remember that worker nodes that do not meet these requirements cannot run these tasks.\n\nYou can monitor the health of manager nodes by querying the docker `nodes` API in JSON format through the `/nodes` HTTP endpoint. Refer to the [nodes API documentation](https://docs.docker.com/engine/api/v1.25/#tag/Node) for more information.\n\nFrom the command line, run `docker node inspect <id-node>` to query the nodes. For instance, to query the reachability of the node as a manager:\n\nTo query the status of the node as a worker that accept tasks:\n\nFrom those commands, we can see that `manager1` is both at the status `reachable` as a manager and `ready` as a worker.\n\nAn `unreachable` health status means that this particular manager node is unreachable from other manager nodes. In this case you need to take action to restore the unreachable manager:\n\n*   Restart the daemon and see if the manager comes back as reachable.\n*   Reboot the machine.\n*   If neither restarting nor rebooting works, you should add another manager node or promote a worker to be a manager node. You also need to cleanly remove the failed node entry from the manager set with `docker node demote <NODE>` and `docker node rm <id-node>`.\n\nAlternatively you can also get an overview of the swarm health from a manager node with `docker node ls`:\n\nYou should never restart a manager node by copying the `raft` directory from another node. The data directory is unique to a node ID. A node can only use a node ID once to join the swarm. The node ID space should be globally unique.\n\nTo cleanly re-join a manager node to a cluster:\n\n1.  Demote the node to a worker using `docker node demote <NODE>`.\n2.  Remove the node from the swarm using `docker node rm <NODE>`.\n3.  Re-join the node to the swarm with a fresh state using `docker swarm join`.\n\nFor more information on joining a manager node to a swarm, refer to [Join nodes to a swarm](https://docs.docker.com/engine/swarm/join-nodes/).\n\nIn most cases, you should shut down a node before removing it from a swarm with the `docker node rm` command. If a node becomes unreachable, unresponsive, or compromised you can forcefully remove the node without shutting it down by passing the `--force` flag. For instance, if `node9` becomes compromised:\n\nBefore you forcefully remove a manager node, you must first demote it to the worker role. Make sure that you always have an odd number of manager nodes if you demote or remove a manager.\n\nDocker manager nodes store the swarm state and manager logs in the `/var/lib/docker/swarm/` directory. This data includes the keys used to encrypt the Raft logs. Without these keys, you cannot restore the swarm.\n\nYou can back up the swarm using any manager. Use the following procedure.\n\n1.  If the swarm has auto-lock enabled, you need the unlock key to restore the swarm from backup. Retrieve the unlock key if necessary and store it in a safe location. If you are unsure, read [Lock your swarm to protect its encryption key](https://docs.docker.com/engine/swarm/swarm_manager_locking/).\n    \n2.  Stop Docker on the manager before backing up the data, so that no data is being changed during the backup. It is possible to take a backup while the manager is running (a \"hot\" backup), but this is not recommended and your results are less predictable when restoring. While the manager is down, other nodes continue generating swarm data that is not part of this backup.\n    \n    > **Note**\n    > \n    > Be sure to maintain the quorum of swarm managers. During the time that a manager is shut down, your swarm is more vulnerable to losing the quorum if further nodes are lost. The number of managers you run is a trade-off. If you regularly take down managers to do backups, consider running a five manager swarm, so that you can lose an additional manager while the backup is running, without disrupting your services.\n    \n3.  Back up the entire `/var/lib/docker/swarm` directory.\n    \n4.  Restart the manager.\n    \n\nTo restore, see [Restore from a backup](#restore-from-a-backup).\n\n### [Restore from a backup](#restore-from-a-backup)\n\nAfter backing up the swarm as described in [Back up the swarm](#back-up-the-swarm), use the following procedure to restore the data to a new swarm.\n\n1.  Shut down Docker on the target host machine for the restored swarm.\n    \n2.  Remove the contents of the `/var/lib/docker/swarm` directory on the new swarm.\n    \n3.  Restore the `/var/lib/docker/swarm` directory with the contents of the backup.\n    \n    > **Note**\n    > \n    > The new node uses the same encryption key for on-disk storage as the old one. It is not possible to change the on-disk storage encryption keys at this time.\n    > \n    > In the case of a swarm with auto-lock enabled, the unlock key is also the same as on the old swarm, and the unlock key is needed to restore the swarm.\n    \n4.  Start Docker on the new node. Unlock the swarm if necessary. Re-initialize the swarm using the following command, so that this node does not attempt to connect to nodes that were part of the old swarm, and presumably no longer exist.\n    \n5.  Verify that the state of the swarm is as expected. This may include application-specific tests or simply checking the output of `docker service ls` to be sure that all expected services are present.\n    \n6.  If you use auto-lock, [rotate the unlock key](https://docs.docker.com/engine/swarm/swarm_manager_locking/#rotate-the-unlock-key).\n    \n7.  Add manager and worker nodes to bring your new swarm up to operating capacity.\n    \n8.  Reinstate your previous backup regimen on the new swarm.\n    \n\n### [Recover from losing the quorum](#recover-from-losing-the-quorum)\n\nSwarm is resilient to failures and can recover from any number of temporary node failures (machine reboots or crash with restart) or other transient errors. However, a swarm cannot automatically recover if it loses a quorum. Tasks on existing worker nodes continue to run, but administrative tasks are not possible, including scaling or updating services and joining or removing nodes from the swarm. The best way to recover is to bring the missing manager nodes back online. If that is not possible, continue reading for some options for recovering your swarm.\n\nIn a swarm of `N` managers, a quorum (a majority) of manager nodes must always be available. For example, in a swarm with five managers, a minimum of three must be operational and in communication with each other. In other words, the swarm can tolerate up to `(N-1)/2` permanent failures beyond which requests involving swarm management cannot be processed. These types of failures include data corruption or hardware failures.\n\nIf you lose the quorum of managers, you cannot administer the swarm. If you have lost the quorum and you attempt to perform any management operation on the swarm, an error occurs:\n\nThe best way to recover from losing the quorum is to bring the failed nodes back online. If you can't do that, the only way to recover from this state is to use the `--force-new-cluster` action from a manager node. This removes all managers except the manager the command was run from. The quorum is achieved because there is now only one manager. Promote nodes to be managers until you have the desired number of managers.\n\nFrom the node to recover, run:\n\nWhen you run the `docker swarm init` command with the `--force-new-cluster` flag, the Docker Engine where you run the command becomes the manager node of a single-node swarm which is capable of managing and running services. The manager has all the previous information about services and tasks, worker nodes are still part of the swarm, and services are still running. You need to add or re-add manager nodes to achieve your previous task distribution and ensure that you have enough managers to maintain high availability and prevent losing the quorum.\n\nGenerally, you do not need to force the swarm to rebalance its tasks. When you add a new node to a swarm, or a node reconnects to the swarm after a period of unavailability, the swarm does not automatically give a workload to the idle node. This is a design decision. If the swarm periodically shifted tasks to different nodes for the sake of balance, the clients using those tasks would be disrupted. The goal is to avoid disrupting running services for the sake of balance across the swarm. When new tasks start, or when a node with running tasks becomes unavailable, those tasks are given to less busy nodes. The goal is eventual balance, with minimal disruption to the end user.\n\nYou can use the `--force` or `-f` flag with the `docker service update` command to force the service to redistribute its tasks across the available worker nodes. This causes the service tasks to restart. Client applications may be disrupted. If you have configured it, your service uses a [rolling update](https://docs.docker.com/engine/swarm/swarm-tutorial/rolling-update/).\n\nIf you use an earlier version and you want to achieve an even balance of load across workers and don't mind disrupting running tasks, you can force your swarm to re-balance by temporarily scaling the service upward. Use `docker service inspect --pretty <servicename>` to see the configured scale of a service. When you use `docker service scale`, the nodes with the lowest number of tasks are targeted to receive the new workloads. There may be multiple under-loaded nodes in your swarm. You may need to scale the service up by modest increments a few times to achieve the balance you want across all the nodes.\n\nWhen the load is balanced to your satisfaction, you can scale the service back down to the original scale. You can use `docker service ps` to assess the current balance of your service across nodes.\n\nSee also [`docker service scale`](https://docs.docker.com/reference/cli/docker/service/scale/) and [`docker service ps`](https://docs.docker.com/reference/cli/docker/service/ps/).",
  "title": "Administer and maintain a swarm of Docker Engines | Docker Docs\n",
  "description": "Manager administration guide",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/security/antivirus/",
  "markdown": "# Antivirus software and Docker | Docker Docs\n\nWhen antivirus software scans files used by Docker, these files may be locked in a way that causes Docker commands to hang.\n\nOne way to reduce these problems is to add the Docker data directory (`/var/lib/docker` on Linux, `%ProgramData%\\docker` on Windows Server, or `$HOME/Library/Containers/com.docker.docker/` on Mac) to the antivirus's exclusion list. However, this comes with the trade-off that viruses or malware in Docker images, writable layers of containers, or volumes are not detected. If you do choose to exclude Docker's data directory from background virus scanning, you may want to schedule a recurring task that stops Docker, scans the data directory, and restarts Docker.",
  "title": "Antivirus software and Docker | Docker Docs\n",
  "description": "General guidelines for using antivirus software with Docker",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/building/base-images/",
  "markdown": "# Base images | Docker Docs\n\nAll Dockerfiles start from a base image. A base is the image that your image extends. It refers to the contents of the `FROM` instruction in the Dockerfile.\n\nFor most cases, you don't need to create your own base image. Docker Hub contains a vast library of Docker images that are suitable for use as a base image in your build. [Docker Official Images](https://docs.docker.com/trusted-content/official-images/) are specifically designed as a set of hardened, battle-tested images that supports a wide variety of platforms, languages, and frameworks. There are also [Docker Verified Publisher](https://hub.docker.com/search?q=&image_filter=store) images, created by trusted publishing partners, verified by Docker.\n\nIf you need to completely control the contents of your image, you can create your own base image from a Linux distribution of your choosing, or use the special `FROM scratch` base:\n\nThe `scratch` image is typically used to create minimal images containing only just what an application needs. See [Create a minimal base image using scratch](#create-a-minimal-base-image-using-scratch).\n\nTo create a distribution base image, you can use a root filesystem, packaged as a `tar` file, and import it to Docker with `docker import`. The process for creating your own base image depends on the Linux distribution you want to package. See [Create a full image using tar](#create-a-full-image-using-tar).\n\nThe reserved, minimal `scratch` image serves as a starting point for building containers. Using the `scratch` image signals to the build process that you want the next command in the `Dockerfile` to be the first filesystem layer in your image.\n\nWhile `scratch` appears in Docker's [repository on Docker Hub](https://hub.docker.com/_/scratch), you can't pull it, run it, or tag any image with the name `scratch`. Instead, you can refer to it in your `Dockerfile`. For example, to create a minimal container using `scratch`:\n\nAssuming an executable binary named `hello` exists at the root of the [build context](https://docs.docker.com/build/building/context/). You can build this Docker image using the following `docker build` command:\n\nTo run your new image, use the `docker run` command:\n\nThis example image can only successfully execute as long as the `hello` binary doesn't have any runtime dependencies. Computer programs tend to depend on certain other programs or resources to exist in the runtime environment. For example:\n\n*   Programming language runtimes\n*   Dynamically linked C libraries\n*   CA certificates\n\nWhen building a base image, or any image, this is an important aspect to consider. And this is why creating a base image using `FROM scratch` can be difficult, for anything other than small, simple programs. On the other hand, it's also important to include only the things you need in your image, to reduce the image size and attack surface.\n\nIn general, start with a working machine that is running the distribution you'd like to package as a base image, though that is not required for some tools like Debian's [Debootstrap](https://wiki.debian.org/Debootstrap), which you can also use to build Ubuntu images.\n\nFor example, to create an Ubuntu base image:\n\nThere are more example scripts for creating base images in [the Moby GitHub repository](https://github.com/moby/moby/blob/master/contrib).\n\nFor more information about building images and writing Dockerfiles, see:\n\n*   [Dockerfile reference](https://docs.docker.com/reference/dockerfile/)\n*   [Dockerfile best practices](https://docs.docker.com/build/building/best-practices/)\n*   [Docker Official Images](https://docs.docker.com/trusted-content/official-images/)",
  "title": "Base images | Docker Docs\n",
  "description": "Learn about base images and how they're created",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/reference/commandline/cli/",
  "markdown": "# Use the Docker command line\n\nThe base command for the Docker CLI is `docker`. For information about the available flags and subcommands, refer to the [CLI reference](https://docs.docker.com/reference/cli/docker/)\n\nDepending on your Docker system configuration, you may be required to preface each `docker` command with `sudo`. To avoid having to use `sudo` with the `docker` command, your system administrator can create a Unix group called `docker` and add users to it.\n\nFor more information about installing Docker or `sudo` configuration, refer to the [installation](https://docs.docker.com/install/) instructions for your operating system.\n\nThe following list of environment variables are supported by the `docker` command line:\n\n| Variable | Description |\n| --- | --- |\n| `DOCKER_API_VERSION` | Override the negotiated API version to use for debugging (e.g. `1.19`) |\n| `DOCKER_CERT_PATH` | Location of your authentication keys. This variable is used both by the `docker` CLI and the [`dockerd` daemon](https://docs.docker.com/reference/cli/dockerd/) |\n| `DOCKER_CONFIG` | The location of your client configuration files. |\n| `DOCKER_CONTENT_TRUST_SERVER` | The URL of the Notary server to use. Defaults to the same URL as the registry. |\n| `DOCKER_CONTENT_TRUST` | When set Docker uses notary to sign and verify images. Equates to `--disable-content-trust=false` for build, create, pull, push, run. |\n| `DOCKER_CONTEXT` | Name of the `docker context` to use (overrides `DOCKER_HOST` env var and default context set with `docker context use`) |\n| `DOCKER_DEFAULT_PLATFORM` | Default platform for commands that take the `--platform` flag. |\n| `DOCKER_HIDE_LEGACY_COMMANDS` | When set, Docker hides \"legacy\" top-level commands (such as `docker rm`, and `docker pull`) in `docker help` output, and only `Management commands` per object-type (e.g., `docker container`) are printed. This may become the default in a future release. |\n| `DOCKER_HOST` | Daemon socket to connect to. |\n| `DOCKER_TLS` | Enable TLS for connections made by the `docker` CLI (equivalent of the `--tls` command-line option). Set to a non-empty value to enable TLS. Note that TLS is enabled automatically if any of the other TLS options are set. |\n| `DOCKER_TLS_VERIFY` | When set Docker uses TLS and verifies the remote. This variable is used both by the `docker` CLI and the [`dockerd` daemon](https://docs.docker.com/reference/cli/dockerd/) |\n| `BUILDKIT_PROGRESS` | Set type of progress output (`auto`, `plain`, `tty`, `rawjson`) when [building](https://docs.docker.com/reference/cli/docker/image/build/) with [BuildKit backend](https://docs.docker.com/build/buildkit/). Use plain to show container output (default `auto`). |\n\nBecause Docker is developed using Go, you can also use any environment variables used by the Go runtime. In particular, you may find these useful:\n\n| Variable | Description |\n| --- | --- |\n| `HTTP_PROXY` | Proxy URL for HTTP requests unless overridden by NoProxy. |\n| `HTTPS_PROXY` | Proxy URL for HTTPS requests unless overridden by NoProxy. |\n| `NO_PROXY` | Comma-separated values specifying hosts that should be excluded from proxying. |\n\nSee the [Go specification](https://pkg.go.dev/golang.org/x/net/http/httpproxy#Config) for details on these variables.\n\nBy default, the Docker command line stores its configuration files in a directory called `.docker` within your `$HOME` directory.\n\nDocker manages most of the files in the configuration directory and you shouldn't modify them. However, you can modify the `config.json` file to control certain aspects of how the `docker` command behaves.\n\nYou can modify the `docker` command behavior using environment variables or command-line options. You can also use options within `config.json` to modify some of the same behavior. If an environment variable and the `--config` flag are set, the flag takes precedent over the environment variable. Command line options override environment variables and environment variables override properties you specify in a `config.json` file.\n\n### [Change the `.docker` directory](#change-the-docker-directory)\n\nTo specify a different directory, use the `DOCKER_CONFIG` environment variable or the `--config` command line option. If both are specified, then the `--config` option overrides the `DOCKER_CONFIG` environment variable. The example below overrides the `docker ps` command using a `config.json` file located in the `~/testconfigs/` directory.\n\nThis flag only applies to whatever command is being ran. For persistent configuration, you can set the `DOCKER_CONFIG` environment variable in your shell (e.g. `~/.profile` or `~/.bashrc`). The example below sets the new directory to be `HOME/newdir/.docker`.\n\nUse the Docker CLI configuration to customize settings for the `docker` CLI. The configuration file uses JSON formatting, and properties:\n\nBy default, configuration file is stored in `~/.docker/config.json`. Refer to the [change the `.docker` directory](#change-the-docker-directory) section to use a different location.\n\n> **Warning**\n> \n> The configuration file and other files inside the `~/.docker` configuration directory may contain sensitive information, such as authentication information for proxies or, depending on your credential store, credentials for your image registries. Review your configuration file's content before sharing with others, and prevent committing the file to version control.\n\n### [Customize the default output format for commands](#customize-the-default-output-format-for-commands)\n\nThese fields lets you customize the default output format for some commands if no `--format` flag is provided.\n\n| Property | Description |\n| --- | --- |\n| `configFormat` | Custom default format for `docker config ls` output. See [`docker config ls`](https://docs.docker.com/reference/cli/docker/config/ls/#format) for a list of supported formatting directives. |\n| `imagesFormat` | Custom default format for `docker images` / `docker image ls` output. See [`docker images`](https://docs.docker.com/reference/cli/docker/image/ls/#format) for a list of supported formatting directives. |\n| `networksFormat` | Custom default format for `docker network ls` output. See [`docker network ls`](https://docs.docker.com/reference/cli/docker/network/ls/#format) for a list of supported formatting directives. |\n| `nodesFormat` | Custom default format for `docker node ls` output. See [`docker node ls`](https://docs.docker.com/reference/cli/docker/node/ls/#format) for a list of supported formatting directives. |\n| `pluginsFormat` | Custom default format for `docker plugin ls` output. See [`docker plugin ls`](https://docs.docker.com/reference/cli/docker/plugin/ls/#format) for a list of supported formatting directives. |\n| `psFormat` | Custom default format for `docker ps` / `docker container ps` output. See [`docker ps`](https://docs.docker.com/reference/cli/docker/container/ls/#format) for a list of supported formatting directives. |\n| `secretFormat` | Custom default format for `docker secret ls` output. See [`docker secret ls`](https://docs.docker.com/reference/cli/docker/secret/ls/#format) for a list of supported formatting directives. |\n| `serviceInspectFormat` | Custom default format for `docker service inspect` output. See [`docker service inspect`](https://docs.docker.com/reference/cli/docker/service/inspect/#format) for a list of supported formatting directives. |\n| `servicesFormat` | Custom default format for `docker service ls` output. See [`docker service ls`](https://docs.docker.com/reference/cli/docker/service/ls/#format) for a list of supported formatting directives. |\n| `statsFormat` | Custom default format for `docker stats` output. See [`docker stats`](https://docs.docker.com/reference/cli/docker/container/stats/#format) for a list of supported formatting directives. |\n| `tasksFormat` | Custom default format for `docker stack ps` output. See [`docker stack ps`](https://docs.docker.com/reference/cli/docker/stack/ps/#format) for a list of supported formatting directives. |\n| `volumesFormat` | Custom default format for `docker volume ls` output. See [`docker volume ls`](https://docs.docker.com/reference/cli/docker/volume/ls/#format) for a list of supported formatting directives. |\n\nThe property `HttpHeaders` specifies a set of headers to include in all messages sent from the Docker client to the daemon. Docker doesn't try to interpret or understand these headers; it simply puts them into the messages. Docker does not allow these headers to change any headers it sets for itself.\n\n### [Credential store options](#credential-store-options)\n\nThe property `credsStore` specifies an external binary to serve as the default credential store. When this property is set, `docker login` will attempt to store credentials in the binary specified by `docker-credential-<value>` which is visible on `$PATH`. If this property isn't set, credentials are stored in the `auths` property of the CLI configuration file. For more information, see the [**Credential stores** section in the `docker login` documentation](https://docs.docker.com/reference/cli/docker/login/#credential-stores)\n\nThe property `credHelpers` specifies a set of credential helpers to use preferentially over `credsStore` or `auths` when storing and retrieving credentials for specific registries. If this property is set, the binary `docker-credential-<value>` will be used when storing or retrieving credentials for a specific registry. For more information, see the [**Credential helpers** section in the `docker login` documentation](https://docs.docker.com/reference/cli/docker/login/#credential-helpers)\n\n### [Automatic proxy configuration for containers](#automatic-proxy-configuration-for-containers)\n\nThe property `proxies` specifies proxy environment variables to be automatically set on containers, and set as `--build-arg` on containers used during `docker build`. A `\"default\"` set of proxies can be configured, and will be used for any Docker daemon that the client connects to, or a configuration per host (Docker daemon), for example, `https://docker-daemon1.example.com`. The following properties can be set for each environment:\n\n| Property | Description |\n| --- | --- |\n| `httpProxy` | Default value of `HTTP_PROXY` and `http_proxy` for containers, and as `--build-arg` on `docker build` |\n| `httpsProxy` | Default value of `HTTPS_PROXY` and `https_proxy` for containers, and as `--build-arg` on `docker build` |\n| `ftpProxy` | Default value of `FTP_PROXY` and `ftp_proxy` for containers, and as `--build-arg` on `docker build` |\n| `noProxy` | Default value of `NO_PROXY` and `no_proxy` for containers, and as `--build-arg` on `docker build` |\n| `allProxy` | Default value of `ALL_PROXY` and `all_proxy` for containers, and as `--build-arg` on `docker build` |\n\nThese settings are used to configure proxy settings for containers only, and not used as proxy settings for the `docker` CLI or the `dockerd` daemon. Refer to the [environment variables](#environment-variables) and [HTTP/HTTPS proxy](https://docs.docker.com/config/daemon/systemd/#httphttps-proxy) sections for configuring proxy settings for the cli and daemon.\n\n> **Warning**\n> \n> Proxy settings may contain sensitive information (for example, if the proxy requires authentication). Environment variables are stored as plain text in the container's configuration, and as such can be inspected through the remote API or committed to an image when using `docker commit`.\n\n### [Default key-sequence to detach from containers](#default-key-sequence-to-detach-from-containers)\n\nOnce attached to a container, users detach from it and leave it running using the using `CTRL-p CTRL-q` key sequence. This detach key sequence is customizable using the `detachKeys` property. Specify a `<sequence>` value for the property. The format of the `<sequence>` is a comma-separated list of either a letter \\[a-Z\\], or the `ctrl-` combined with any of the following:\n\n*   `a-z` (a single lowercase alpha character )\n*   `@` (at sign)\n*   `[` (left bracket)\n*   `\\\\` (two backward slashes)\n*   `_` (underscore)\n*   `^` (caret)\n\nYour customization applies to all containers started in with your Docker client. Users can override your custom or the default key sequence on a per-container basis. To do this, the user specifies the `--detach-keys` flag with the `docker attach`, `docker exec`, `docker run` or `docker start` command.\n\n### [CLI plugin options](#cli-plugin-options)\n\nThe property `plugins` contains settings specific to CLI plugins. The key is the plugin name, while the value is a further map of options, which are specific to that plugin.\n\n### [Sample configuration file](#sample-configuration-file)\n\nFollowing is a sample `config.json` file to illustrate the format used for various fields:\n\n### [Experimental features](#experimental-features)\n\nExperimental features provide early access to future product functionality. These features are intended for testing and feedback, and they may change between releases without warning or can be removed from a future release.\n\nStarting with Docker 20.10, experimental CLI features are enabled by default, and require no configuration to enable them.\n\n### [Notary](#notary)\n\nIf using your own notary server and a self-signed certificate or an internal Certificate Authority, you need to place the certificate at `tls/<registry_url>/ca.crt` in your Docker config directory.\n\nAlternatively you can trust the certificate globally by adding it to your system's list of root Certificate Authorities.\n\n### [](#a-namehosta-specify-daemon-host--h---host)Specify daemon host (-H, --host)\n\nYou can use the `-H`, `--host` flag to specify a socket to use when you invoke a `docker` command. You can use the following protocols:\n\n| Scheme | Description | Example |\n| --- | --- | --- |\n| `unix://[<path>]` | Unix socket (Linux only) | `unix:///var/run/docker.sock` |\n| `tcp://[<IP or host>[:port]]` | TCP connection | `tcp://174.17.0.1:2376` |\n| `ssh://[username@]<IP or host>[:port]` | SSH connection | `ssh://user@192.168.64.5` |\n| `npipe://[<name>]` | Named pipe (Windows only) | `npipe:////./pipe/docker_engine` |\n\nIf you don't specify the `-H` flag, and you're not using a custom [context](https://docs.docker.com/engine/context/working-with-contexts), commands use the following default sockets:\n\n*   `unix:///var/run/docker.sock` on macOS and Linux\n*   `npipe:////./pipe/docker_engine` on Windows\n\nTo achieve a similar effect without having to specify the `-H` flag for every command, you could also [create a context](https://docs.docker.com/reference/cli/docker/context/create/), or alternatively, use the [`DOCKER_HOST` environment variable](#environment-variables).\n\nFor more information about the `-H` flag, see [Daemon socket option](https://docs.docker.com/reference/cli/dockerd/#daemon-socket-option).\n\n#### [Using TCP sockets](#using-tcp-sockets)\n\nThe following example shows how to invoke `docker ps` over TCP, to a remote daemon with IP address `174.17.0.1`, listening on port `2376`:\n\n> **Note**\n> \n> By convention, the Docker daemon uses port `2376` for secure TLS connections, and port `2375` for insecure, non-TLS connections.\n\n#### [Using SSH sockets](#using-ssh-sockets)\n\nWhen you use SSH invoke a command on a remote daemon, the request gets forwarded to the `/var/run/docker.sock` Unix socket on the SSH host.\n\nYou can optionally specify the location of the socket by appending a path component to the end of the SSH address.\n\n### [Display help text](#display-help-text)\n\nTo list the help on any command just execute the command, followed by the `--help` option.\n\n### [Option types](#option-types)\n\nSingle character command line options can be combined, so rather than typing `docker run -i -t --name test busybox sh`, you can write `docker run -it --name test busybox sh`.\n\n#### [Boolean](#boolean)\n\nBoolean options take the form `-d=false`. The value you see in the help text is the default value which is set if you do **not** specify that flag. If you specify a Boolean flag without a value, this will set the flag to `true`, irrespective of the default value.\n\nFor example, running `docker run -d` will set the value to `true`, so your container **will** run in \"detached\" mode, in the background.\n\nOptions which default to `true` (e.g., `docker build --rm=true`) can only be set to the non-default value by explicitly setting them to `false`:\n\n#### [Multi](#multi)\n\nYou can specify options like `-a=[]` multiple times in a single command line, for example in these commands:\n\nSometimes, multiple options can call for a more complex value string as for `-v`:\n\n> **Note**\n> \n> Do not use the `-t` and `-a stderr` options together due to limitations in the `pty` implementation. All `stderr` in `pty` mode simply goes to `stdout`.\n\n#### [Strings and Integers](#strings-and-integers)\n\nOptions like `--name=\"\"` expect a string, and they can only be specified once. Options like `-c=0` expect an integer, and they can only be specified once.",
  "title": "Use the Docker command line | Docker Docs\n",
  "description": "Docker's CLI command description and usage",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/context/working-with-contexts/",
  "markdown": "# Docker contexts | Docker Docs\n\nThis guide shows how you can use contexts to manage Docker daemons from a single client.\n\nEach context contains all information required to manage resources on the daemon. The `docker context` command makes it easy to configure these contexts and switch between them.\n\nAs an example, a single Docker client might be configured with two contexts:\n\n*   A default context running locally\n*   A remote, shared context\n\nOnce these contexts are configured, you can use the `docker context use <context-name>` command to switch between them.\n\nTo follow the examples in this guide, you'll need:\n\n*   A Docker client that supports the top-level `context` command\n\nRun `docker context` to verify that your Docker client supports contexts.\n\n## [The anatomy of a context](#the-anatomy-of-a-context)\n\nA context is a combination of several properties. These include:\n\n*   Name and description\n*   Endpoint configuration\n*   TLS info\n\nTo list available contexts, use the `docker context ls` command.\n\nThis shows a single context called \"default\". It's configured to talk to a daemon through the local `/var/run/docker.sock` Unix socket.\n\nThe asterisk in the `NAME` column indicates that this is the active context. This means all `docker` commands run against this context, unless overridden with environment variables such as `DOCKER_HOST` and `DOCKER_CONTEXT`, or on the command-line with the `--context` and `--host` flags.\n\nDig a bit deeper with `docker context inspect`. The following example shows how to inspect the context called `default`.\n\n### [Create a new context](#create-a-new-context)\n\nYou can create new contexts with the `docker context create` command.\n\nThe following example creates a new context called `docker-test` and specifies the host endpoint of the context to TCP socket `tcp://docker:2375`.\n\nThe new context is stored in a `meta.json` file below `~/.docker/contexts/`. Each new context you create gets its own `meta.json` stored in a dedicated sub-directory of `~/.docker/contexts/`.\n\nYou can view the new context with `docker context ls` and `docker context inspect <context-name>`.\n\nThe current context is indicated with an asterisk (\"\\*\").\n\n## [Use a different context](#use-a-different-context)\n\nYou can use `docker context use` to switch between contexts.\n\nThe following command will switch the `docker` CLI to use the `docker-test` context.\n\nVerify the operation by listing all contexts and ensuring the asterisk (\"\\*\") is against the `docker-test` context.\n\n`docker` commands will now target endpoints defined in the `docker-test` context.\n\nYou can also set the current context using the `DOCKER_CONTEXT` environment variable. The environment variable overrides the context set with `docker context use`.\n\nUse the appropriate command below to set the context to `docker-test` using an environment variable.\n\nRun `docker context ls` to verify that the `docker-test` context is now the active context.\n\nYou can also use the global `--context` flag to override the context. The following command uses a context called `production`.\n\n## [Exporting and importing Docker contexts](#exporting-and-importing-docker-contexts)\n\nYou can use the `docker context export` and `docker context import` commands to export and import contexts on different hosts.\n\nThe `docker context export` command exports an existing context to a file. The file can be imported on any host that has the `docker` client installed.\n\n### [Exporting and importing a context](#exporting-and-importing-a-context)\n\nThe following example exports an existing context called `docker-test`. It will be written to a file called `docker-test.dockercontext`.\n\nCheck the contents of the export file.\n\nImport this file on another host using `docker context import` to create context with the same configuration.\n\nYou can verify that the context was imported with `docker context ls`.\n\nThe format of the import command is `docker context import <context-name> <context-file>`.\n\n## [Updating a context](#updating-a-context)\n\nYou can use `docker context update` to update fields in an existing context.\n\nThe following example updates the description field in the existing `docker-test` context.",
  "title": "Docker contexts | Docker Docs\n",
  "description": "Learn about managing multiple daemons from a single client with contexts",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/raft/",
  "markdown": "# Raft consensus in swarm mode\n\nWhen Docker Engine runs in Swarm mode, manager nodes implement the [Raft Consensus Algorithm](http://thesecretlivesofdata.com/raft/) to manage the global cluster state.\n\nThe reason why Swarm mode is using a consensus algorithm is to make sure that all the manager nodes that are in charge of managing and scheduling tasks in the cluster are storing the same consistent state.\n\nHaving the same consistent state across the cluster means that in case of a failure, any Manager node can pick up the tasks and restore the services to a stable state. For example, if the Leader Manager which is responsible for scheduling tasks in the cluster dies unexpectedly, any other Manager can pick up the task of scheduling and re-balance tasks to match the desired state.\n\nSystems using consensus algorithms to replicate logs in a distributed systems do require special care. They ensure that the cluster state stays consistent in the presence of failures by requiring a majority of nodes to agree on values.\n\nRaft tolerates up to `(N-1)/2` failures and requires a majority or quorum of `(N/2)+1` members to agree on values proposed to the cluster. This means that in a cluster of 5 Managers running Raft, if 3 nodes are unavailable, the system cannot process any more requests to schedule additional tasks. The existing tasks keep running but the scheduler cannot rebalance tasks to cope with failures if the manager set is not healthy.\n\nThe implementation of the consensus algorithm in Swarm mode means it features the properties inherent to distributed systems:\n\n*   Agreement on values in a fault tolerant system. (Refer to [FLP impossibility theorem](https://www.the-paper-trail.org/post/2008-08-13-a-brief-tour-of-flp-impossibility/) and the [Raft Consensus Algorithm paper](https://www.usenix.org/system/files/conference/atc14/atc14-paper-ongaro.pdf))\n*   Mutual exclusion through the leader election process\n*   Cluster membership management\n*   Globally consistent object sequencing and CAS (compare-and-swap) primitives",
  "title": "Raft consensus in swarm mode | Docker Docs\n",
  "description": "Raft consensus algorithm in swarm mode",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/alternative-runtimes/",
  "markdown": "# Alternative container runtimes | Docker Docs\n\nDocker Engine uses containerd for managing the container lifecycle, which includes creating, starting, and stopping containers. By default, containerd uses runc as its container runtime.\n\nYou can use any runtime that implements the containerd [shim API](https://github.com/containerd/containerd/blob/main/core/runtime/v2/README.md). Such runtimes ship with a containerd shim, and you can use them without any additional configuration. See [Use containerd shims](#use-containerd-shims).\n\nExamples of runtimes that implement their own containerd shims include:\n\n*   [Wasmtime](https://wasmtime.dev/)\n*   [gVisor](https://github.com/google/gvisor)\n*   [Kata Containers](https://katacontainers.io/)\n\nYou can also use runtimes designed as drop-in replacements for runc. Such runtimes depend on the runc containerd shim for invoking the runtime binary. You must manually register such runtimes in the daemon configuration.\n\n[youki](https://github.com/containers/youki) is one example of a runtime that can function as a runc drop-in replacement. Refer to the [youki example](#youki) explaining the setup.\n\ncontainerd shims let you use alternative runtimes without having to change the configuration of the Docker daemon. To use a containerd shim, install the shim binary on `PATH` on the system where the Docker daemon is running.\n\nTo use a shim with `docker run`, specify the fully qualified name of the runtime as the value to the `--runtime` flag:\n\n### [Use a containerd shim without installing on PATH](#use-a-containerd-shim-without-installing-on-path)\n\nYou can use a shim without installing it on `PATH`, in which case you need to register the shim in the daemon configuration as follows:\n\nTo use the shim, specify the name that you assigned to it:\n\n### [Configure shims](#configure-shims)\n\nIf you need to pass additional configuration for a containerd shim, you can use the `runtimes` option in the daemon configuration file.\n\n1.  Edit the daemon configuration file by adding a `runtimes` entry for the shim you want to configure.\n    \n    *   Specify the fully qualified name for the runtime in `runtimeType` key\n    *   Add your runtime configuration under the `options` key\n2.  Reload the daemon's configuration.\n    \n3.  Use the customized runtime using the `--runtime` flag for `docker run`.\n    \n\nFor more information about the configuration options for containerd shims, see [Configure containerd shims](https://docs.docker.com/reference/cli/dockerd/#configure-containerd-shims).\n\nThe following examples show you how to set up and use alternative container runtimes with Docker Engine.\n\n*   [youki](#youki)\n*   [Wasmtime](#wasmtime)\n\n### [youki](#youki)\n\nyouki is a container runtime written in Rust. youki claims to be faster and use less memory than runc, making it a good choice for resource-constrained environments.\n\nyouki functions as a drop-in replacement for runc, meaning it relies on the runc shim to invoke the runtime binary. When you register runtimes acting as runc replacements, you configure the path to the runtime executable, and optionally a set of runtime arguments. For more information, see [Configure runc drop-in replacements](https://docs.docker.com/reference/cli/dockerd/#configure-runc-drop-in-replacements).\n\nTo add youki as a container runtime:\n\n1.  Install youki and its dependencies.\n    \n    For instructions, refer to the [official setup guide](https://containers.github.io/youki/user/basic_setup.html).\n    \n2.  Register youki as a runtime for Docker by editing the Docker daemon configuration file, located at `/etc/docker/daemon.json` by default.\n    \n    The `path` key should specify the path to wherever you installed youki.\n    \n3.  Reload the daemon's configuration.\n    \n\nNow you can run containers that use youki as a runtime.\n\n### [Wasmtime](#wasmtime)\n\nWasmtime is a [Bytecode Alliance](https://bytecodealliance.org/) project, and a Wasm runtime that lets you run Wasm containers. Running Wasm containers with Docker provides two layers of security. You get all the benefits from container isolation, plus the added sandboxing provided by the Wasm runtime environment.\n\nTo add Wasmtime as a container runtime, follow these steps:\n\n1.  Turn on the [containerd image store](https://docs.docker.com/storage/containerd/) feature in the daemon configuration file.\n    \n    > **Note**\n    > \n    > This is an experimental feature.\n    \n2.  Restart the Docker daemon.\n    \n3.  Install the Wasmtime containerd shim on `PATH`.\n    \n    The following command Dockerfile builds the Wasmtime binary from source and exports it to `./containerd-shim-wasmtime-v1`.\n    \n    Put the binary in a directory on `PATH`.\n    \n\nNow you can run containers that use Wasmtime as a runtime.\n\n*   To learn more about the configuration options for container runtimes, see [Configure container runtimes](https://docs.docker.com/reference/cli/dockerd/#configure-container-runtimes).\n*   You can configure which runtime that the daemon should use as its default. Refer to [Configure the default container runtime](https://docs.docker.com/reference/cli/dockerd/#configure-the-default-container-runtime).",
  "title": "Alternative container runtimes | Docker Docs\n",
  "description": "Docker Engine uses runc as the default container runtime, but you can specify alternative runtimes using the CLI or by configuring the daemon ",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/security/apparmor/",
  "markdown": "# AppArmor security profiles for Docker\n\nAppArmor (Application Armor) is a Linux security module that protects an operating system and its applications from security threats. To use it, a system administrator associates an AppArmor security profile with each program. Docker expects to find an AppArmor policy loaded and enforced.\n\nDocker automatically generates and loads a default profile for containers named `docker-default`. The Docker binary generates this profile in `tmpfs` and then loads it into the kernel.\n\n> **Note**\n> \n> This profile is used on containers, not on the Docker daemon.\n\nA profile for the Docker Engine daemon exists but it is not currently installed with the `deb` packages. If you are interested in the source for the daemon profile, it is located in [contrib/apparmor](https://github.com/moby/moby/tree/master/contrib/apparmor) in the Docker Engine source repository.\n\nThe `docker-default` profile is the default for running containers. It is moderately protective while providing wide application compatibility. The profile is generated from the following [template](https://github.com/moby/moby/blob/master/profiles/apparmor/template.go).\n\nWhen you run a container, it uses the `docker-default` policy unless you override it with the `security-opt` option. For example, the following explicitly specifies the default policy:\n\nTo load a new profile into AppArmor for use with containers:\n\nThen, run the custom profile with `--security-opt`:\n\nTo unload a profile from AppArmor:\n\n### [Resources for writing profiles](#resources-for-writing-profiles)\n\nThe syntax for file globbing in AppArmor is a bit different than some other globbing implementations. It is highly suggested you take a look at some of the below resources with regard to AppArmor profile syntax.\n\n*   [Quick Profile Language](https://gitlab.com/apparmor/apparmor/wikis/QuickProfileLanguage)\n*   [Globbing Syntax](https://gitlab.com/apparmor/apparmor/wikis/AppArmor_Core_Policy_Reference#AppArmor_globbing_syntax)\n\nIn this example, you create a custom AppArmor profile for Nginx. Below is the custom profile.\n\n1.  Save the custom profile to disk in the `/etc/apparmor.d/containers/docker-nginx` file.\n    \n    The file path in this example is not a requirement. In production, you could use another.\n    \n2.  Load the profile.\n    \n3.  Run a container with the profile.\n    \n    To run nginx in detached mode:\n    \n4.  Exec into the running container.\n    \n5.  Try some operations to test the profile.\n    \n\nYou just deployed a container secured with a custom apparmor profile.\n\nYou can use `dmesg` to debug problems and `aa-status` check the loaded profiles.\n\n### [Use dmesg](#use-dmesg)\n\nHere are some helpful tips for debugging any problems you might be facing with regard to AppArmor.\n\nAppArmor sends quite verbose messaging to `dmesg`. Usually an AppArmor line looks like the following:\n\nIn the above example, you can see `profile=/usr/bin/docker`. This means the user has the `docker-engine` (Docker Engine daemon) profile loaded.\n\nLook at another log line:\n\nThis time the profile is `docker-default`, which is run on containers by default unless in `privileged` mode. This line shows that apparmor has denied `ptrace` in the container. This is exactly as expected.\n\n### [Use aa-status](#use-aa-status)\n\nIf you need to check which profiles are loaded, you can use `aa-status`. The output looks like:\n\nThe above output shows that the `docker-default` profile running on various container PIDs is in `enforce` mode. This means AppArmor is actively blocking and auditing in `dmesg` anything outside the bounds of the `docker-default` profile.\n\nThe output above also shows the `/usr/bin/docker` (Docker Engine daemon) profile is running in `complain` mode. This means AppArmor only logs to `dmesg` activity outside the bounds of the profile. (Except in the case of Ubuntu Trusty, where some interesting behaviors are enforced.)\n\nAdvanced users and package managers can find a profile for `/usr/bin/docker` (Docker Engine daemon) underneath [contrib/apparmor](https://github.com/moby/moby/tree/master/contrib/apparmor) in the Docker Engine source repository.\n\nThe `docker-default` profile for containers lives in [profiles/apparmor](https://github.com/moby/moby/tree/master/profiles/apparmor).",
  "title": "AppArmor security profiles for Docker | Docker Docs\n",
  "description": "Enabling AppArmor in Docker",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/deprecated/",
  "markdown": "# Deprecated Engine Features | Docker Docs\n\nThis page provides an overview of features that are deprecated in Engine. Changes in packaging, and supported (Linux) distributions are not included. To learn about end of support for Linux distributions, refer to the [release notes](https://docs.docker.com/engine/release-notes/).\n\nAs changes are made to Docker there may be times when existing features need to be removed or replaced with newer features. Before an existing feature is removed it is labeled as \"deprecated\" within the documentation and remains in Docker for at least one stable release unless specified explicitly otherwise. After that time it may be removed.\n\nUsers are expected to take note of the list of deprecated features each release and plan their migration away from those features, and (if applicable) towards the replacement features as soon as possible.\n\nThe table below provides an overview of the current status of deprecated features:\n\n*   **Deprecated**: the feature is marked \"deprecated\" and should no longer be used. The feature may be removed, disabled, or change behavior in a future release. The _\"Deprecated\"_ column contains the release in which the feature was marked deprecated, whereas the _\"Remove\"_ column contains a tentative release in which the feature is to be removed. If no release is included in the _\"Remove\"_ column, the release is yet to be decided on.\n*   **Removed**: the feature was removed, disabled, or hidden. Refer to the linked section for details. Some features are \"soft\" deprecated, which means that they remain functional for backward compatibility, and to allow users to migrate to alternatives. In such cases, a warning may be printed, and users should not rely on this feature.\n\n| Status | Feature | Deprecated | Remove |\n| --- | --- | --- | --- |\n| Deprecated | [Non-standard fields in image inspect](#non-standard-fields-in-image-inspect) | v27.0 | v28.0 |\n| Deprecated | [API CORS headers](#api-cors-headers) | v27.0 | v28.0 |\n| Deprecated | [Graphdriver plugins (experimental)](#graphdriver-plugins-experimental) | v27.0 | v28.0 |\n| Deprecated | [Unauthenticated TCP connections](#unauthenticated-tcp-connections) | v26.0 | v28.0 |\n| Deprecated | [`Container` and `ContainerConfig` fields in Image inspect](#container-and-containerconfig-fields-in-image-inspect) | v25.0 | v26.0 |\n| Deprecated | [Deprecate legacy API versions](#deprecate-legacy-api-versions) | v25.0 | v26.0 |\n| Removed | [Container short ID in network Aliases field](#container-short-id-in-network-aliases-field) | v25.0 | v26.0 |\n| Deprecated | [IsAutomated field, and \"is-automated\" filter on docker search](#isautomated-field-and-is-automated-filter-on-docker-search) | v25.0 | v26.0 |\n| Removed | [logentries logging driver](#logentries-logging-driver) | v24.0 | v25.0 |\n| Removed | [OOM-score adjust for the daemon](#oom-score-adjust-for-the-daemon) | v24.0 | v25.0 |\n| Removed | [Buildkit build information](#buildkit-build-information) | v23.0 | v24.0 |\n| Deprecated | [Legacy builder for Linux images](#legacy-builder-for-linux-images) | v23.0 | \\-  |\n| Deprecated | [Legacy builder fallback](#legacy-builder-fallback) | v23.0 | \\-  |\n| Removed | [Btrfs storage driver on CentOS 7 and RHEL 7](#btrfs-storage-driver-on-centos-7-and-rhel-7) | v20.10 | v23.0 |\n| Removed | [Support for encrypted TLS private keys](#support-for-encrypted-tls-private-keys) | v20.10 | v23.0 |\n| Removed | [Kubernetes stack and context support](#kubernetes-stack-and-context-support) | v20.10 | v23.0 |\n| Deprecated | [Pulling images from non-compliant image registries](#pulling-images-from-non-compliant-image-registries) | v20.10 | \\-  |\n| Removed | [Linux containers on Windows (LCOW)](#linux-containers-on-windows-lcow-experimental) | v20.10 | v23.0 |\n| Deprecated | [BLKIO weight options with cgroups v1](#blkio-weight-options-with-cgroups-v1) | v20.10 | \\-  |\n| Removed | [Kernel memory limit](#kernel-memory-limit) | v20.10 | v23.0 |\n| Removed | [Classic Swarm and overlay networks using external key/value stores](#classic-swarm-and-overlay-networks-using-cluster-store) | v20.10 | v23.0 |\n| Removed | [Support for the legacy `~/.dockercfg` configuration file for authentication](#support-for-legacy-dockercfg-configuration-files) | v20.10 | v23.0 |\n| Deprecated | [CLI plugins support](#cli-plugins-support) | v20.10 | \\-  |\n| Deprecated | [Dockerfile legacy `ENV name value` syntax](#dockerfile-legacy-env-name-value-syntax) | v20.10 | \\-  |\n| Removed | [`docker build --stream` flag (experimental)](#docker-build---stream-flag-experimental) | v20.10 | v20.10 |\n| Deprecated | [`fluentd-async-connect` log opt](#fluentd-async-connect-log-opt) | v20.10 | \\-  |\n| Removed | [Configuration options for experimental CLI features](#configuration-options-for-experimental-cli-features) | v19.03 | v23.0 |\n| Deprecated | [Pushing and pulling with image manifest v2 schema 1](#pushing-and-pulling-with-image-manifest-v2-schema-1) | v19.03 | v27.0 |\n| Removed | [`docker engine` subcommands](#docker-engine-subcommands) | v19.03 | v20.10 |\n| Removed | [Top-level `docker deploy` subcommand (experimental)](#top-level-docker-deploy-subcommand-experimental) | v19.03 | v20.10 |\n| Removed | [`docker stack deploy` using \"dab\" files (experimental)](#docker-stack-deploy-using-dab-files-experimental) | v19.03 | v20.10 |\n| Removed | [Support for the `overlay2.override_kernel_check` storage option](#support-for-the-overlay2override_kernel_check-storage-option) | v19.03 | v24.0 |\n| Removed | [AuFS storage driver](#aufs-storage-driver) | v19.03 | v24.0 |\n| Removed | [Legacy \"overlay\" storage driver](#legacy-overlay-storage-driver) | v18.09 | v24.0 |\n| Removed | [Device mapper storage driver](#device-mapper-storage-driver) | v18.09 | v25.0 |\n| Removed | [Use of reserved namespaces in engine labels](#use-of-reserved-namespaces-in-engine-labels) | v18.06 | v20.10 |\n| Removed | [`--disable-legacy-registry` override daemon option](#--disable-legacy-registry-override-daemon-option) | v17.12 | v19.03 |\n| Removed | [Interacting with V1 registries](#interacting-with-v1-registries) | v17.06 | v17.12 |\n| Removed | [Asynchronous `service create` and `service update` as default](#asynchronous-service-create-and-service-update-as-default) | v17.05 | v17.10 |\n| Removed | [`-g` and `--graph` flags on `dockerd`](#-g-and---graph-flags-on-dockerd) | v17.05 | v23.0 |\n| Deprecated | [Top-level network properties in NetworkSettings](#top-level-network-properties-in-networksettings) | v1.13 | v17.12 |\n| Removed | [`filter` param for `/images/json` endpoint](#filter-param-for-imagesjson-endpoint) | v1.13 | v20.10 |\n| Removed | [`repository:shortid` image references](#repositoryshortid-image-references) | v1.13 | v17.12 |\n| Removed | [`docker daemon` subcommand](#docker-daemon-subcommand) | v1.13 | v17.12 |\n| Removed | [Duplicate keys with conflicting values in engine labels](#duplicate-keys-with-conflicting-values-in-engine-labels) | v1.13 | v17.12 |\n| Deprecated | [`MAINTAINER` in Dockerfile](#maintainer-in-dockerfile) | v1.13 | \\-  |\n| Deprecated | [API calls without a version](#api-calls-without-a-version) | v1.13 | v17.12 |\n| Removed | [Backing filesystem without `d_type` support for overlay/overlay2](#backing-filesystem-without-d_type-support-for-overlayoverlay2) | v1.13 | v17.12 |\n| Removed | [`--automated` and `--stars` flags on `docker search`](#--automated-and---stars-flags-on-docker-search) | v1.12 | v20.10 |\n| Deprecated | [`-h` shorthand for `--help`](#-h-shorthand-for---help) | v1.12 | v17.09 |\n| Removed | [`-e` and `--email` flags on `docker login`](#-e-and---email-flags-on-docker-login) | v1.11 | v17.06 |\n| Deprecated | [Separator (`:`) of `--security-opt` flag on `docker run`](#separator--of---security-opt-flag-on-docker-run) | v1.11 | v17.06 |\n| Deprecated | [Ambiguous event fields in API](#ambiguous-event-fields-in-api) | v1.10 | \\-  |\n| Removed | [`-f` flag on `docker tag`](#-f-flag-on-docker-tag) | v1.10 | v1.12 |\n| Removed | [HostConfig at API container start](#hostconfig-at-api-container-start) | v1.10 | v1.12 |\n| Removed | [`--before` and `--since` flags on `docker ps`](#--before-and---since-flags-on-docker-ps) | v1.10 | v1.12 |\n| Removed | [Driver-specific log tags](#driver-specific-log-tags) | v1.9 | v1.12 |\n| Removed | [Docker Content Trust `ENV` passphrase variables name change](#docker-content-trust-env-passphrase-variables-name-change) | v1.9 | v1.12 |\n| Removed | [`/containers/(id or name)/copy` endpoint](#containersid-or-namecopy-endpoint) | v1.8 | v1.12 |\n| Removed | [LXC built-in exec driver](#lxc-built-in-exec-driver) | v1.8 | v1.10 |\n| Removed | [Old Command Line Options](#old-command-line-options) | v1.8 | v1.10 |\n| Removed | [`--api-enable-cors` flag on `dockerd`](#--api-enable-cors-flag-on-dockerd) | v1.6 | v17.09 |\n| Removed | [`--run` flag on `docker commit`](#--run-flag-on-docker-commit) | v0.10 | v1.13 |\n| Removed | [Three arguments form in `docker import`](#three-arguments-form-in-docker-import) | v0.6.7 | v1.12 |\n\n### [Non-standard fields in image inspect](#non-standard-fields-in-image-inspect)\n\n**Deprecated in Release: v27.0** **Target For Removal In Release: v28.0**\n\nThe `Config` field returned shown in `docker image inspect` (and as returned by the `GET /images/{name}/json` API endpoint) returns additional fields that are not part of the image's configuration and not part of the [Docker Image Spec](https://github.com/moby/docker-image-spec/blob/v1.3.1/specs-go/v1/image.go#L19-L32) and \\[OCI Image Specification\\].\n\nThese fields are never set (and always return the default value for the type), but are not omitted in the response when left empty. As these fields were not intended to be part of the image configuration response, they are deprecated, and will be removed from the API in thee next release.\n\nThe following fields are currently included in the API response, but are not part of the underlying image's Config, and deprecated:\n\n*   `Hostname`\n*   `Domainname`\n*   `AttachStdin`\n*   `AttachStdout`\n*   `AttachStderr`\n*   `Tty`\n*   `OpenStdin`\n*   `StdinOnce`\n*   `Image`\n*   `NetworkDisabled` (already omitted unless set)\n*   `MacAddress` (already omitted unless set)\n*   `StopTimeout` (already omitted unless set)\n\n### [Graphdriver plugins (experimental)](#graphdriver-plugins-experimental)\n\n**Deprecated in Release: v27.0** **Disabled by default in Release: v27.0** **Target For Removal In Release: v28.0**\n\n[Graphdriver plugins](https://github.com/docker/cli/blob/v26.1.4/docs/extend/plugins_graphdriver.md) are an experimental feature that allow extending the Docker Engine with custom storage drivers for storing images and containers. This feature was not maintained since its inception, and will no longer be supported in upcoming releases.\n\nSupport for graphdriver plugins is disabled by default in v27.0, and will be removed v28.0. An `DOCKERD_DEPRECATED_GRAPHDRIVER_PLUGINS` environment variable is provided in v27.0 to re-enable the feature. This environment variable must be set to a non-empty value in the daemon's environment.\n\nThe `DOCKERD_DEPRECATED_GRAPHDRIVER_PLUGINS` environment variable, along with support for graphdriver plugins, will be removed in v28.0. Users of this feature are recommended to instead configure the Docker Engine to use the [containerd image store](https://docs.docker.com/storage/containerd/) and a custom [snapshotter](https://github.com/containerd/containerd/tree/v1.7.18/docs/snapshotters)\n\n**Deprecated in Release: v27.0** **Target For Removal In Release: v28.0**\n\nThe `api-cors-header` configuration option for the Docker daemon is insecure, and is therefore deprecated and scheduled for removal. Incorrectly setting this option could leave a window of opportunity for unauthenticated cross-origin requests to be accepted by the daemon.\n\nStarting in Docker Engine v27.0, this flag can still be set, but it has no effect unless the environment variable `DOCKERD_DEPRECATED_CORS_HEADER` is also set to a non-empty value.\n\nThis flag will be removed altogether in v28.0.\n\nThis is a breaking change for authorization plugins and other programs that depend on this option for accessing the Docker API from a browser. If you need to access the API through a browser, use a reverse proxy.\n\n### [Unauthenticated TCP connections](#unauthenticated-tcp-connections)\n\n**Deprecated in Release: v26.0** **Target For Removal In Release: v28.0**\n\nConfiguring the Docker daemon to listen on a TCP address will require mandatory TLS verification. This change aims to ensure secure communication by preventing unauthorized access to the Docker daemon over potentially insecure networks. This mandatory TLS requirement applies to all TCP addresses except `tcp://localhost`.\n\nIn version 27.0 and later, specifying `--tls=false` or `--tlsverify=false` CLI flags causes the daemon to fail to start if it's also configured to accept remote connections over TCP. This also applies to the equivalent configuration options in `daemon.json`.\n\nTo facilitate remote access to the Docker daemon over TCP, you'll need to implement TLS verification. This secures the connection by encrypting data in transit and providing a mechanism for mutual authentication.\n\nFor environments remote daemon access isn't required, we recommend binding the Docker daemon to a Unix socket. For daemon's where remote access is required and where TLS encryption is not feasible, you may want to consider using SSH as an alternative solution.\n\nFor further information, assistance, and step-by-step instructions on configuring TLS (or SSH) for the Docker daemon, refer to [Protect the Docker daemon socket](https://docs.docker.com/engine/security/protect-access/).\n\n### [`Container` and `ContainerConfig` fields in Image inspect](#container-and-containerconfig-fields-in-image-inspect)\n\n**Deprecated in Release: v25.0** **Target For Removal In Release: v26.0**\n\nThe `Container` and `ContainerConfig` fields returned by `docker inspect` are mostly an implementation detail of the classic (non-BuildKit) image builder. These fields are not portable and are empty when using the BuildKit-based builder (enabled by default since v23.0). These fields are deprecated in v25.0 and will be omitted starting from v26.0. If image configuration of an image is needed, you can obtain it from the `Config` field.\n\n### [Deprecate legacy API versions](#deprecate-legacy-api-versions)\n\n**Deprecated in Release: v25.0** **Target For Removal In Release: v26.0**\n\nThe Docker daemon provides a versioned API for backward compatibility with old clients. Docker clients can perform API-version negotiation to select the most recent API version supported by the daemon (downgrading to and older version of the API when necessary). API version negotiation was introduced in Docker v1.12.0 (API 1.24), and clients before that used a fixed API version.\n\nDocker Engine versions through v25.0 provide support for all [API versions](https://docs.docker.com/engine/api/#api-version-matrix) included in stable releases for a given platform. For Docker daemons on Linux, the earliest supported API version is 1.12 (corresponding with Docker Engine v1.0.0), whereas for Docker daemons on Windows, the earliest supported API version is 1.24 (corresponding with Docker Engine v1.12.0).\n\nSupport for legacy API versions (providing old API versions on current versions of the Docker Engine) is primarily intended to provide compatibility with recent, but still supported versions of the client, which is a common scenario (the Docker daemon may be updated to the latest release, but not all clients may be up-to-date or vice versa). Support for API versions before that (API versions provided by EOL versions of the Docker Daemon) is provided on a \"best effort\" basis.\n\nUse of old API versions is very rare, and support for legacy API versions involves significant complexity (Docker 1.0.0 having been released 10 years ago). Because of this, we'll start deprecating support for legacy API versions.\n\nDocker Engine v25.0 by default disables API version older than 1.24 (aligning the minimum supported API version between Linux and Windows daemons). When connecting with a client that uses an API version version older than 1.24, the daemon returns an error. The following example configures the docker CLI to use API version 1.23, which produces an error:\n\nAn environment variable (`DOCKER_MIN_API_VERSION`) is introduced that allows re-enabling older API versions in the daemon. This environment variable must be set in the daemon's environment (for example, through a [systemd override file](https://docs.docker.com/config/daemon/systemd/)), and the specified API version must be supported by the daemon (`1.12` or higher on Linux, or `1.24` or higher on Windows).\n\nSupport for API versions lower than `1.24` will be permanently removed in Docker Engine v26, and the minimum supported API version will be incrementally raised in releases following that.\n\nWe do not recommend depending on the `DOCKER_MIN_API_VERSION` environment variable other than for exceptional cases where it's not possible to update old clients, and those clients must be supported.\n\n### [Container short ID in network Aliases field](#container-short-id-in-network-aliases-field)\n\n**Deprecated in Release: v25.0** **Removed In Release: v26.0**\n\nThe `Aliases` field returned by `docker inspect` contains the container short ID once the container is started. This behavior is deprecated in v25.0 but kept until the next release, v26.0. Starting with that version, the `Aliases` field will only contain the aliases set through the `docker container create` and `docker run` flag `--network-alias`.\n\nA new field `DNSNames` containing the container name (if one was specified), the hostname, the network aliases, as well as the container short ID, has been introduced in v25.0 and should be used instead of the `Aliases` field.\n\n### [IsAutomated field, and \"is-automated\" filter on docker search](#isautomated-field-and-is-automated-filter-on-docker-search)\n\n**Deprecated in Release: v25.0** **Target For Removal In Release: v26.0**\n\nThe \"is\\_automated\" field has been deprecated by Docker Hub's search API. Consequently, the `IsAutomated` field in image search will always be set to `false` in future, and searching for \"is-automated=true\" will yield no results.\n\nThe `AUTOMATED` column has been removed from the default `docker search` and `docker image search` output in v25.0, and the corresponding `IsAutomated` templating option will be removed in v26.0.\n\n### [Logentries logging driver](#logentries-logging-driver)\n\n**Deprecated in Release: v24.0** **Removed in Release: v25.0**\n\nThe logentries service SaaS was shut down on November 15, 2022, rendering this logging driver non-functional. Users should no longer use this logging driver, and the driver has been removed in Docker 25.0. Existing containers using this logging-driver are migrated to use the \"local\" logging driver after upgrading.\n\n### [OOM-score adjust for the daemon](#oom-score-adjust-for-the-daemon)\n\n**Deprecated in Release: v24.0** **Removed in Release: v25.0**\n\nThe `oom-score-adjust` option was added to prevent the daemon from being OOM-killed before other processes. This option was mostly added as a convenience, as running the daemon as a systemd unit was not yet common.\n\nHaving the daemon set its own limits is not best-practice, and something better handled by the process-manager starting the daemon.\n\nDocker v20.10 and newer no longer adjust the daemon's OOM score by default, instead setting the OOM-score to the systemd unit (OOMScoreAdjust) that's shipped with the packages.\n\nUsers currently depending on this feature are recommended to adjust the daemon's OOM score using systemd or through other means, when starting the daemon.\n\n### [Buildkit build information](#buildkit-build-information)\n\n**Deprecated in Release: v23.0** **Removed in Release: v24.0**\n\n[Build information](https://github.com/moby/buildkit/blob/v0.11/docs/buildinfo.md) structures have been introduced in [BuildKit v0.10.0](https://github.com/moby/buildkit/releases/tag/v0.10.0) and are generated with build metadata that allows you to see all the sources (images, git repositories) that were used by the build with their exact versions and also the configuration that was passed to the build. This information is also embedded into the image configuration if one is generated.\n\n### [Legacy builder for Linux images](#legacy-builder-for-linux-images)\n\n**Deprecated in Release: v23.0**\n\nDocker v23.0 now uses BuildKit by default to build Linux images, and uses the [Buildx](https://docs.docker.com/buildx/working-with-buildx/) CLI component for `docker build`. With this change, `docker build` now exposes all advanced features that BuildKit provides and which were previously only available through the `docker buildx` subcommands.\n\nThe Buildx component is installed automatically when installing the `docker` CLI using our `.deb` or `.rpm` packages, and statically linked binaries are provided both on `download.docker.com`, and through the [`docker/buildx-bin` image](https://hub.docker.com/r/docker/buildx-bin) on Docker Hub. Refer the [Buildx section](http://docs.docker.com/go/buildx/) for detailed instructions on installing the Buildx component.\n\nThis release marks the beginning of the deprecation cycle of the classic (\"legacy\") builder for Linux images. No active development will happen on the classic builder (except for bugfixes). BuildKit development started five Years ago, left the \"experimental\" phase since Docker 18.09, and is already the default builder for [Docker Desktop](https://docs.docker.com/desktop/previous-versions/3.x-mac/#docker-desktop-320). While we're comfortable that BuildKit is stable for general use, there may be some changes in behavior. If you encounter issues with BuildKit, we encourage you to report issues in the [BuildKit issue tracker on GitHub](https://github.com/moby/buildkit/){:target=\"_blank\" rel=\"noopener\" class=\"_\"}\n\n> Classic builder for building Windows images\n> \n> BuildKit does not (yet) provide support for building Windows images, and `docker build` continues to use the classic builder to build native Windows images on Windows daemons.\n\n### [Legacy builder fallback](#legacy-builder-fallback)\n\n**Deprecated in Release: v23.0**\n\n[Docker v23.0 now uses BuildKit by default to build Linux images](#legacy-builder-for-linux-images), which requires the Buildx component to build images with BuildKit. There may be situations where the Buildx component is not available, and BuildKit cannot be used.\n\nTo provide a smooth transition to BuildKit as the default builder, Docker v23.0 has an automatic fallback for some situations, or produces an error to assist users to resolve the problem.\n\nIn situations where the user did not explicitly opt-in to use BuildKit (i.e., `DOCKER_BUILDKIT=1` is not set), the CLI automatically falls back to the classic builder, but prints a deprecation warning:\n\nThis situation may occur if the `docker` CLI is installed using the static binaries, and the Buildx component is not installed or not installed correctly. This fallback will be removed in a future release, therefore we recommend to [install the Buildx component](https://docs.docker.com/go/buildx/) and use BuildKit for your builds, or opt-out of using BuildKit with `DOCKER_BUILDKIT=0`.\n\nIf you opted-in to use BuildKit (`DOCKER_BUILDKIT=1`), but the Buildx component is missing, an error is printed instead, and the `docker build` command fails:\n\nWe recommend to [install the Buildx component](https://docs.docker.com/go/buildx/) to continue using BuildKit for your builds, but alternatively, users can either unset the `DOCKER_BUILDKIT` environment variable to fall back to the legacy builder, or opt-out of using BuildKit with `DOCKER_BUILDKIT=0`.\n\nBe aware that the [classic builder is deprecated](#legacy-builder-for-linux-images) so both the automatic fallback and opting-out of using BuildKit will no longer be possible in a future release.\n\n### [Btrfs storage driver on CentOS 7 and RHEL 7](#btrfs-storage-driver-on-centos-7-and-rhel-7)\n\n**Removed in Release: v23.0**\n\nThe `btrfs` storage driver on CentOS and RHEL was provided as a technology preview by CentOS and RHEL, but has been deprecated since the [Red Hat Enterprise Linux 7.4 release](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/storage_administration_guide/ch-btrfs), and removed in CentOS 8 and RHEL 8. Users of the `btrfs` storage driver on CentOS are recommended to migrate to a different storage driver, such as `overlay2`, which is now the default storage driver. Docker 23.0 continues to provide the `btrfs` storage driver to allow users to migrate to an alternative driver. The next release of Docker will no longer provide this driver.\n\n### [Support for encrypted TLS private keys](#support-for-encrypted-tls-private-keys)\n\n**Deprecated in Release: v20.10**\n\n**Removed in Release: v23.0**\n\nUse of encrypted TLS private keys has been deprecated, and has been removed. Golang has deprecated support for legacy PEM encryption (as specified in [RFC 1423](https://datatracker.ietf.org/doc/html/rfc1423)), as it is insecure by design (see [https://go-review.googlesource.com/c/go/+/264159](https://go-review.googlesource.com/c/go/+/264159)).\n\nThis feature allowed using an encrypted private key with a supplied password, but did not provide additional security as the encryption is known to be broken, and the key is sitting next to the password in the filesystem. Users are recommended to decrypt the private key, and store it un-encrypted to continue using it.\n\n### [Kubernetes stack and context support](#kubernetes-stack-and-context-support)\n\n**Deprecated in Release: v20.10** **Removed in Release: v23.0**\n\nFollowing the deprecation of [Compose on Kubernetes](https://github.com/docker/compose-on-kubernetes), support for Kubernetes in the `stack` and `context` commands has been removed from the cli, and options related to this functionality are now either ignored, or may produce an error.\n\nThe following command-line flags are removed from the `docker context` subcommands:\n\n*   `--default-stack-orchestrator` - swarm is now the only (and default) orchestrator for stacks.\n*   `--kubernetes` - the kubernetes endpoint can no longer be stored in `docker context`.\n*   `--kubeconfig` - exporting a context as a kubeconfig file is no longer supported.\n\nThe output produced by the `docker context inspect` subcommand no longer contains information about `StackOrchestrator` and `Kubernetes` endpoints for new contexts.\n\nThe following command-line flags are removed from the `docker stack` subcommands:\n\n*   `--kubeconfig` - using a kubeconfig file as context is no longer supported.\n*   `--namespace` - configuring the kubernetes namespace for stacks is no longer supported.\n*   `--orchestrator` - swarm is now the only (and default) orchestrator for stacks.\n\nThe `DOCKER_STACK_ORCHESTRATOR`, `DOCKER_ORCHESTRATOR`, and `KUBECONFIG` environment variables, as well as the `stackOrchestrator` option in the `~/.docker/config.json` cli configuration file are no longer used, and ignored.\n\n### [Pulling images from non-compliant image registries](#pulling-images-from-non-compliant-image-registries)\n\n**Deprecated in Release: v20.10**\n\nDocker Engine v20.10 and up includes optimizations to verify if images in the local image cache need updating before pulling, preventing the Docker Engine from making unnecessary API requests. These optimizations require the container image registry to conform to the [Open Container Initiative Distribution Specification](https://github.com/opencontainers/distribution-spec).\n\nWhile most registries conform to the specification, we encountered some registries to be non-compliant, resulting in `docker pull` to fail.\n\nAs a temporary solution, Docker Engine v20.10 includes a fallback mechanism to allow `docker pull` to be functional when using a non-compliant registry. A warning message is printed in this situation:\n\n```\nWARNING Failed to pull manifest by the resolved digest. This registry does not\n        appear to conform to the distribution registry specification; falling back to\n        pull by tag. This fallback is DEPRECATED, and will be removed in a future\n        release.\n```\n\nThe fallback is added to allow users to either migrate their images to a compliant registry, or for these registries to become compliant.\n\nNote that this fallback only addresses failures on `docker pull`. Other commands, such as `docker stack deploy`, or pulling images with `containerd` will continue to fail.\n\nGiven that other functionality is still broken with these registries, we consider this fallback a _temporary_ solution, and will remove the fallback in an upcoming major release.\n\n### [Linux containers on Windows (LCOW) (experimental)](#linux-containers-on-windows-lcow-experimental)\n\n**Deprecated in Release: v20.10** **Removed in Release: v23.0**\n\nThe experimental feature to run Linux containers on Windows (LCOW) was introduced as a technical preview in Docker 17.09. While many enhancements were made after its introduction, the feature never reached completeness, and development has now stopped in favor of running docker natively on Linux in WSL2.\n\nDevelopers who want to run Linux workloads on a Windows host are encouraged to use [Docker Desktop with WSL2](https://docs.docker.com/docker-for-windows/wsl/) instead.\n\n### [BLKIO weight options with cgroups v1](#blkio-weight-options-with-cgroups-v1)\n\n**Deprecated in Release: v20.10**\n\nSpecifying blkio weight (`docker run --blkio-weight` and `docker run --blkio-weight-device`) is now marked as deprecated when using cgroups v1 because the corresponding features were [removed in Linux kernel v5.0 and up](https://github.com/torvalds/linux/commit/f382fb0bcef4c37dc049e9f6963e3baf204d815c). When using cgroups v2, the `--blkio-weight` options are implemented using [\\`io.weight](https://github.com/torvalds/linux/blob/v5.0/Documentation/admin-guide/cgroup-v2.rst#io).\n\n### [Kernel memory limit](#kernel-memory-limit)\n\n**Deprecated in Release: v20.10** **Removed in Release: v23.0**\n\nSpecifying kernel memory limit (`docker run --kernel-memory`) is no longer supported because the [Linux kernel deprecated `kmem.limit_in_bytes` in v5.4](https://github.com/torvalds/linux/commit/0158115f702b0ba208ab0b5adf44cae99b3ebcc7). The OCI runtime specification now marks this option (as well as `--kernel-memory-tcp`) as [\"NOT RECOMMENDED\"](https://github.com/opencontainers/runtime-spec/pull/1093), and OCI runtimes such as `runc` no longer support this option.\n\nDocker API v1.42 and up now ignores this option when set. Older versions of the API continue to accept the option, but depending on the OCI runtime used, may take no effect.\n\n> **Note**\n> \n> While not deprecated (yet) in Docker, the OCI runtime specification also deprecated the `memory.kmem.tcp.limit_in_bytes` option. When using `runc` as runtime, this option takes no effect. The linux kernel did not explicitly deprecate this feature, and there is a tracking ticket in the `runc` issue tracker to determine if this option should be reinstated or if this was an oversight of the Linux kernel maintainers (see [opencontainers/runc#3174](https://github.com/opencontainers/runc/issues/3174)).\n> \n> The `memory.kmem.tcp.limit_in_bytes` option is only supported with cgroups v1, and not available on installations running with cgroups v2. This option is only supported by the API, and not exposed on the `docker` command-line.\n\n### [Classic Swarm and overlay networks using cluster store](#classic-swarm-and-overlay-networks-using-cluster-store)\n\n**Deprecated in Release: v20.10** **Removed in Release: v23.0**\n\nStandalone (\"classic\") Swarm has been deprecated, and with that the use of overlay networks using an external key/value store. The corresponding`--cluster-advertise`, `--cluster-store`, and `--cluster-store-opt` daemon options have been removed.\n\n### [Support for legacy `~/.dockercfg` configuration files](#support-for-legacy-dockercfg-configuration-files)\n\n**Deprecated in Release: v20.10** **Removed in Release: v23.0**\n\nThe docker CLI up until v1.7.0 used the `~/.dockercfg` file to store credentials after authenticating to a registry (`docker login`). Docker v1.7.0 replaced this file with a new CLI configuration file, located in `~/.docker/config.json`. When implementing the new configuration file, the old file (and file-format) was kept as a fall-back, to assist existing users with migrating to the new file.\n\nGiven that the old file format encourages insecure storage of credentials (credentials are stored unencrypted), and that no version of the CLI since Docker v1.7.0 has created this file, support for this file, and its format has been removed.\n\n### [Configuration options for experimental CLI features](#configuration-options-for-experimental-cli-features)\n\n**Deprecated in Release: v19.03**\n\n**Removed in Release: v23.0**\n\nThe `DOCKER_CLI_EXPERIMENTAL` environment variable and the corresponding `experimental` field in the CLI configuration file are deprecated. Experimental features are enabled by default, and these configuration options are no longer functional.\n\nStarting with v23.0, the Docker CLI no longer prints `Experimental` for the client in the output of `docker version`, and the field has been removed from the JSON format.\n\n### [CLI plugins support](#cli-plugins-support)\n\n**Deprecated in Release: v20.10**\n\nCLI Plugin API is now marked as deprecated.\n\n### [Dockerfile legacy `ENV name value` syntax](#dockerfile-legacy-env-name-value-syntax)\n\n**Deprecated in Release: v20.10**\n\nThe Dockerfile `ENV` instruction allows values to be set using either `ENV name=value` or `ENV name value`. The latter (`ENV name value`) form can be ambiguous, for example, the following defines a single env-variable (`ONE`) with value `\"TWO= THREE=world\"`, but may have intended to be setting three env-vars:\n\nThis format also does not allow setting multiple environment-variables in a single `ENV` line in the Dockerfile.\n\nUse of the `ENV name value` syntax is discouraged, and may be removed in a future release. Users are encouraged to update their Dockerfiles to use the `ENV name=value` syntax, for example:\n\n### [`docker build --stream` flag (experimental)](#docker-build---stream-flag-experimental)\n\n**Deprecated in Release: v20.10** **Removed in Release: v20.10**\n\nDocker v17.07 introduced an experimental `--stream` flag on `docker build` which allowed the build-context to be incrementally sent to the daemon, instead of unconditionally sending the whole build-context.\n\nThis functionality has been reimplemented as part of BuildKit, which uses streaming by default and the `--stream` option will be ignored when using the classic builder, printing a deprecation warning instead.\n\nUsers that want to use this feature are encouraged to enable BuildKit by setting the `DOCKER_BUILDKIT=1` environment variable or through the daemon or CLI configuration files.\n\n### [`fluentd-async-connect` log opt](#fluentd-async-connect-log-opt)\n\n**Deprecated in Release: v20.10**\n\nThe `--log-opt fluentd-async-connect` option for the fluentd logging driver is [deprecated in favor of `--log-opt fluentd-async`](https://github.com/moby/moby/pull/39086). A deprecation message is logged in the daemon logs if the old option is used:\n\nUsers are encouraged to use the `fluentd-async` option going forward, as support for the old option will be removed in a future release.\n\n### [Pushing and pulling with image manifest v2 schema 1](#pushing-and-pulling-with-image-manifest-v2-schema-1)\n\n**Deprecated in Release: v19.03**\n\n**Disabled by default in Release: v26.0**\n\n**Target For Removal In Release: v27.0**\n\nThe image manifest [v2 schema 1](https://distribution.github.io/distribution/spec/deprecated-schema-v1/) and \"Docker Image v1\" formats were deprecated in favor of the [v2 schema 2](https://distribution.github.io/distribution/spec/manifest-v2-2/) and [OCI image spec](https://github.com/opencontainers/image-spec/tree/v1.1.0) formats.\n\nThese legacy formats should no longer be used, and users are recommended to update images to use current formats, or to upgrade to more current images. Starting with Docker v26.0, pulling these images is disabled by default, and produces an error when attempting to pull the image:\n\nAn environment variable (`DOCKER_ENABLE_DEPRECATED_PULL_SCHEMA_1_IMAGE`) is added in Docker v26.0 that allows re-enabling support for these image formats in the daemon. This environment variable must be set to a non-empty value in the daemon's environment (for example, through a [systemd override file](https://docs.docker.com/config/daemon/systemd/)). Support for the `DOCKER_ENABLE_DEPRECATED_PULL_SCHEMA_1_IMAGE` environment variable will be removed in Docker v27.0 after which this functionality is removed permanently.\n\n### [`docker engine` subcommands](#docker-engine-subcommands)\n\n**Deprecated in Release: v19.03**\n\n**Removed in Release: v20.10**\n\nThe `docker engine activate`, `docker engine check`, and `docker engine update` provided an alternative installation method to upgrade Docker Community engines to Docker Enterprise, using an image-based distribution of the Docker Engine.\n\nThis feature was only available on Linux, and only when executed on a local node. Given the limitations of this feature, and the feature not getting widely adopted, the `docker engine` subcommands will be removed, in favor of installation through standard package managers.\n\n### [Top-level `docker deploy` subcommand (experimental)](#top-level-docker-deploy-subcommand-experimental)\n\n**Deprecated in Release: v19.03**\n\n**Removed in Release: v20.10**\n\nThe top-level `docker deploy` command (using the \"Docker Application Bundle\" (.dab) file format was introduced as an experimental feature in Docker 1.13 / 17.03, but superseded by support for Docker Compose files using the `docker stack deploy` subcommand.\n\n### [`docker stack deploy` using \"dab\" files (experimental)](#docker-stack-deploy-using-dab-files-experimental)\n\n**Deprecated in Release: v19.03**\n\n**Removed in Release: v20.10**\n\nWith no development being done on this feature, and no active use of the file format, support for the DAB file format and the top-level docker deploy command (hidden by default in 19.03), will be removed, in favour of `docker stack deploy` using compose files.\n\n### [Support for the `overlay2.override_kernel_check` storage option](#support-for-the-overlay2override_kernel_check-storage-option)\n\n**Deprecated in Release: v19.03** **Removed in Release: v24.0**\n\nThis daemon configuration option disabled the Linux kernel version check used to detect if the kernel supported OverlayFS with multiple lower dirs, which is required for the overlay2 storage driver. Starting with Docker v19.03.7, the detection was improved to no longer depend on the kernel _version_, so this option was no longer used.\n\n### [AuFS storage driver](#aufs-storage-driver)\n\n**Deprecated in Release: v19.03** **Removed in Release: v24.0**\n\nThe `aufs` storage driver is deprecated in favor of `overlay2`, and has been removed in a Docker Engine v24.0. Users of the `aufs` storage driver must migrate to a different storage driver, such as `overlay2`, before upgrading to Docker Engine v24.0.\n\nThe `aufs` storage driver facilitated running Docker on distros that have no support for OverlayFS, such as Ubuntu 14.04 LTS, which originally shipped with a 3.14 kernel.\n\nNow that Ubuntu 14.04 is no longer a supported distro for Docker, and `overlay2` is available to all supported distros (as they are either on kernel 4.x, or have support for multiple lowerdirs backported), there is no reason to continue maintenance of the `aufs` storage driver.\n\n### [Legacy overlay storage driver](#legacy-overlay-storage-driver)\n\n**Deprecated in Release: v18.09** **Removed in Release: v24.0**\n\nThe `overlay` storage driver is deprecated in favor of the `overlay2` storage driver, which has all the benefits of `overlay`, without its limitations (excessive inode consumption). The legacy `overlay` storage driver has been removed in Docker Engine v24.0. Users of the `overlay` storage driver should migrate to the `overlay2` storage driver before upgrading to Docker Engine v24.0.\n\nThe legacy `overlay` storage driver allowed using overlayFS-backed filesystems on pre 4.x kernels. Now that all supported distributions are able to run `overlay2` (as they are either on kernel 4.x, or have support for multiple lowerdirs backported), there is no reason to keep maintaining the `overlay` storage driver.\n\n### [Device mapper storage driver](#device-mapper-storage-driver)\n\n**Deprecated in Release: v18.09** **Disabled by default in Release: v23.0** **Removed in Release: v25.0**\n\nThe `devicemapper` storage driver is deprecated in favor of `overlay2`, and has been removed in Docker Engine v25.0. Users of the `devicemapper` storage driver must migrate to a different storage driver, such as `overlay2`, before upgrading to Docker Engine v25.0.\n\nThe `devicemapper` storage driver facilitates running Docker on older (3.x) kernels that have no support for other storage drivers (such as overlay2, or btrfs).\n\nNow that support for `overlay2` is added to all supported distros (as they are either on kernel 4.x, or have support for multiple lowerdirs backported), there is no reason to continue maintenance of the `devicemapper` storage driver.\n\n### [Use of reserved namespaces in engine labels](#use-of-reserved-namespaces-in-engine-labels)\n\n**Deprecated in Release: v18.06**\n\n**Removed In Release: v20.10**\n\nThe namespaces `com.docker.*`, `io.docker.*`, and `org.dockerproject.*` in engine labels were always documented to be reserved, but there was never any enforcement.\n\nUsage of these namespaces will now cause a warning in the engine logs to discourage their use, and will error instead in v20.10 and above.\n\n### [`--disable-legacy-registry` override daemon option](#--disable-legacy-registry-override-daemon-option)\n\n**Disabled In Release: v17.12**\n\n**Removed In Release: v19.03**\n\nThe `--disable-legacy-registry` flag was disabled in Docker 17.12 and will print an error when used. For this error to be printed, the flag itself is still present, but hidden. The flag has been removed in Docker 19.03.\n\n### [Interacting with V1 registries](#interacting-with-v1-registries)\n\n**Disabled By Default In Release: v17.06**\n\n**Removed In Release: v17.12**\n\nVersion 1.8.3 added a flag (`--disable-legacy-registry=false`) which prevents the docker daemon from `pull`, `push`, and `login` operations against v1 registries. Though enabled by default, this signals the intent to deprecate the v1 protocol.\n\nSupport for the v1 protocol to the public registry was removed in 1.13. Any mirror configurations using v1 should be updated to use a [v2 registry mirror](https://docs.docker.com/registry/recipes/mirror/).\n\nStarting with Docker 17.12, support for V1 registries has been removed, and the `--disable-legacy-registry` flag can no longer be used, and `dockerd` will fail to start when set.\n\n### [Asynchronous `service create` and `service update` as default](#asynchronous-service-create-and-service-update-as-default)\n\n**Deprecated In Release: v17.05**\n\n**Disabled by default in release: [v17.10](https://github.com/docker/docker-ce/releases/tag/v17.10.0-ce)**\n\nDocker 17.05 added an optional `--detach=false` option to make the `docker service create` and `docker service update` work synchronously. This option will be enabled by default in Docker 17.10, at which point the `--detach` flag can be used to use the previous (asynchronous) behavior.\n\nThe default for this option will also be changed accordingly for `docker service rollback` and `docker service scale` in Docker 17.10.\n\n### [`-g` and `--graph` flags on `dockerd`](#-g-and---graph-flags-on-dockerd)\n\n**Deprecated In Release: v17.05**\n\n**Removed In Release: v23.0**\n\nThe `-g` or `--graph` flag for the `dockerd` or `docker daemon` command was used to indicate the directory in which to store persistent data and resource configuration and has been replaced with the more descriptive `--data-root` flag. These flags were deprecated and hidden in v17.05, and removed in v23.0.\n\n### [Top-level network properties in NetworkSettings](#top-level-network-properties-in-networksettings)\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Target For Removal In Release: v17.12**\n\nWhen inspecting a container, `NetworkSettings` contains top-level information about the default (\"bridge\") network;\n\n`EndpointID`, `Gateway`, `GlobalIPv6Address`, `GlobalIPv6PrefixLen`, `IPAddress`, `IPPrefixLen`, `IPv6Gateway`, and `MacAddress`.\n\nThese properties are deprecated in favor of per-network properties in `NetworkSettings.Networks`. These properties were already \"deprecated\" in docker 1.9, but kept around for backward compatibility.\n\nRefer to [#17538](https://github.com/docker/docker/pull/17538) for further information.\n\n### [`filter` param for `/images/json` endpoint](#filter-param-for-imagesjson-endpoint)\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Removed In Release: v20.10**\n\nThe `filter` param to filter the list of image by reference (name or name:tag) is now implemented as a regular filter, named `reference`.\n\n### [`repository:shortid` image references](#repositoryshortid-image-references)\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Removed In Release: v17.12**\n\nThe `repository:shortid` syntax for referencing images is very little used, collides with tag references, and can be confused with digest references.\n\nSupport for the `repository:shortid` notation to reference images was removed in Docker 17.12.\n\n### [`docker daemon` subcommand](#docker-daemon-subcommand)\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Removed In Release: v17.12**\n\nThe daemon is moved to a separate binary (`dockerd`), and should be used instead.\n\n### [Duplicate keys with conflicting values in engine labels](#duplicate-keys-with-conflicting-values-in-engine-labels)\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Removed In Release: v17.12**\n\nWhen setting duplicate keys with conflicting values, an error will be produced, and the daemon will fail to start.\n\n### [`MAINTAINER` in Dockerfile](#maintainer-in-dockerfile)\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n`MAINTAINER` was an early very limited form of `LABEL` which should be used instead.\n\n### [API calls without a version](#api-calls-without-a-version)\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Target For Removal In Release: v17.12**\n\nAPI versions should be supplied to all API calls to ensure compatibility with future Engine versions. Instead of just requesting, for example, the URL `/containers/json`, you must now request `/v1.25/containers/json`.\n\n### [Backing filesystem without `d_type` support for overlay/overlay2](#backing-filesystem-without-d_type-support-for-overlayoverlay2)\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Removed In Release: v17.12**\n\nThe overlay and overlay2 storage driver does not work as expected if the backing filesystem does not support `d_type`. For example, XFS does not support `d_type` if it is formatted with the `ftype=0` option.\n\nSupport for these setups has been removed, and Docker v23.0 and up now fails to start when attempting to use the `overlay2` or `overlay` storage driver on a backing filesystem without `d_type` support.\n\nRefer to [#27358](https://github.com/docker/docker/issues/27358) for details.\n\n### [`--automated` and `--stars` flags on `docker search`](#--automated-and---stars-flags-on-docker-search)\n\n**Deprecated in Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\n**Removed In Release: v20.10**\n\nThe `docker search --automated` and `docker search --stars` options are deprecated. Use `docker search --filter=is-automated=<true|false>` and `docker search --filter=stars=...` instead.\n\n### [`-h` shorthand for `--help`](#-h-shorthand-for---help)\n\n**Deprecated In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\n**Target For Removal In Release: v17.09**\n\nThe shorthand (`-h`) is less common than `--help` on Linux and cannot be used on all subcommands (due to it conflicting with, e.g. `-h` / `--hostname` on `docker create`). For this reason, the `-h` shorthand was not printed in the \"usage\" output of subcommands, nor documented, and is now marked \"deprecated\".\n\n### [`-e` and `--email` flags on `docker login`](#-e-and---email-flags-on-docker-login)\n\n**Deprecated In Release: [v1.11.0](https://github.com/docker/docker/releases/tag/v1.11.0)**\n\n**Removed In Release: [v17.06](https://github.com/docker/docker-ce/releases/tag/v17.06.0-ce)**\n\nThe docker login command is removing the ability to automatically register for an account with the target registry if the given username doesn't exist. Due to this change, the email flag is no longer required, and will be deprecated.\n\n### [Separator (`:`) of `--security-opt` flag on `docker run`](#separator--of---security-opt-flag-on-docker-run)\n\n**Deprecated In Release: [v1.11.0](https://github.com/docker/docker/releases/tag/v1.11.0)**\n\n**Target For Removal In Release: v17.06**\n\nThe flag `--security-opt` doesn't use the colon separator (`:`) anymore to divide keys and values, it uses the equal symbol (`=`) for consistency with other similar flags, like `--storage-opt`.\n\n### [Ambiguous event fields in API](#ambiguous-event-fields-in-api)\n\n**Deprecated In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\nThe fields `ID`, `Status` and `From` in the events API have been deprecated in favor of a more rich structure. See the events API documentation for the new format.\n\n### [`-f` flag on `docker tag`](#-f-flag-on-docker-tag)\n\n**Deprecated In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nTo make tagging consistent across the various `docker` commands, the `-f` flag on the `docker tag` command is deprecated. It is no longer necessary to specify `-f` to move a tag from one image to another. Nor will `docker` generate an error if the `-f` flag is missing and the specified tag is already in use.\n\n### [HostConfig at API container start](#hostconfig-at-api-container-start)\n\n**Deprecated In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nPassing an `HostConfig` to `POST /containers/{name}/start` is deprecated in favor of defining it at container creation (`POST /containers/create`).\n\n### [`--before` and `--since` flags on `docker ps`](#--before-and---since-flags-on-docker-ps)\n\n**Deprecated In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nThe `docker ps --before` and `docker ps --since` options are deprecated. Use `docker ps --filter=before=...` and `docker ps --filter=since=...` instead.\n\n### [Driver-specific log tags](#driver-specific-log-tags)\n\n**Deprecated In Release: [v1.9.0](https://github.com/docker/docker/releases/tag/v1.9.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nLog tags are now generated in a standard way across different logging drivers. Because of which, the driver specific log tag options `syslog-tag`, `gelf-tag` and `fluentd-tag` have been deprecated in favor of the generic `tag` option.\n\n### [Docker Content Trust ENV passphrase variables name change](#docker-content-trust-env-passphrase-variables-name-change)\n\n**Deprecated In Release: [v1.9.0](https://github.com/docker/docker/releases/tag/v1.9.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nSince 1.9, Docker Content Trust Offline key has been renamed to Root key and the Tagging key has been renamed to Repository key. Due to this renaming, we're also changing the corresponding environment variables\n\n*   DOCKER\\_CONTENT\\_TRUST\\_OFFLINE\\_PASSPHRASE is now named DOCKER\\_CONTENT\\_TRUST\\_ROOT\\_PASSPHRASE\n*   DOCKER\\_CONTENT\\_TRUST\\_TAGGING\\_PASSPHRASE is now named DOCKER\\_CONTENT\\_TRUST\\_REPOSITORY\\_PASSPHRASE\n\n### [`/containers/(id or name)/copy` endpoint](#containersid-or-namecopy-endpoint)\n\n**Deprecated In Release: [v1.8.0](https://github.com/docker/docker/releases/tag/v1.8.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nThe endpoint `/containers/(id or name)/copy` is deprecated in favor of `/containers/(id or name)/archive`.\n\n### [LXC built-in exec driver](#lxc-built-in-exec-driver)\n\n**Deprecated In Release: [v1.8.0](https://github.com/docker/docker/releases/tag/v1.8.0)**\n\n**Removed In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\nThe built-in LXC execution driver, the lxc-conf flag, and API fields have been removed.\n\n### [Old Command Line Options](#old-command-line-options)\n\n**Deprecated In Release: [v1.8.0](https://github.com/docker/docker/releases/tag/v1.8.0)**\n\n**Removed In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\nThe flags `-d` and `--daemon` are deprecated in favor of the `daemon` subcommand:\n\n```\ndocker daemon -H ...\n```\n\nThe following single-dash (`-opt`) variant of certain command line options are deprecated and replaced with double-dash options (`--opt`):\n\n```\ndocker attach -nostdin\ndocker attach -sig-proxy\ndocker build -no-cache\ndocker build -rm\ndocker commit -author\ndocker commit -run\ndocker events -since\ndocker history -notrunc\ndocker images -notrunc\ndocker inspect -format\ndocker ps -beforeId\ndocker ps -notrunc\ndocker ps -sinceId\ndocker rm -link\ndocker run -cidfile\ndocker run -dns\ndocker run -entrypoint\ndocker run -expose\ndocker run -link\ndocker run -lxc-conf\ndocker run -n\ndocker run -privileged\ndocker run -volumes-from\ndocker search -notrunc\ndocker search -stars\ndocker search -t\ndocker search -trusted\ndocker tag -force\n```\n\nThe following double-dash options are deprecated and have no replacement:\n\n```\ndocker run --cpuset\ndocker run --networking\ndocker ps --since-id\ndocker ps --before-id\ndocker search --trusted\n```\n\n**Deprecated In Release: [v1.5.0](https://github.com/docker/docker/releases/tag/v1.5.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nThe single-dash (`-help`) was removed, in favor of the double-dash `--help`\n\n```\ndocker -help\ndocker [COMMAND] -help\n```\n\n### [`--api-enable-cors` flag on dockerd](#--api-enable-cors-flag-on-dockerd)\n\n**Deprecated In Release: [v1.6.0](https://github.com/docker/docker/releases/tag/v1.6.0)**\n\n**Removed In Release: [v17.09](https://github.com/docker/docker-ce/releases/tag/v17.09.0-ce)**\n\nThe flag `--api-enable-cors` is deprecated since v1.6.0. Use the flag `--api-cors-header` instead.\n\n### [`--run` flag on docker commit](#--run-flag-on-docker-commit)\n\n**Deprecated In Release: [v0.10.0](https://github.com/docker/docker/releases/tag/v0.10.0)**\n\n**Removed In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\nThe flag `--run` of the docker commit (and its short version `-run`) were deprecated in favor of the `--changes` flag that allows to pass `Dockerfile` commands.\n\n### [Three arguments form in `docker import`](#three-arguments-form-in-docker-import)\n\n**Deprecated In Release: [v0.6.7](https://github.com/docker/docker/releases/tag/v0.6.7)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nThe `docker import` command format `file|URL|- [REPOSITORY [TAG]]` is deprecated since November 2013. It's no more supported.",
  "title": "Deprecated Engine Features | Docker Docs\n",
  "description": "Deprecated Features.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/checks/",
  "markdown": "# Checking your build configuration | Docker Docs\n\nIntroduced in Buildx version 0.15.0\n\nBuild checks are a feature introduced in Dockerfile 1.8. It lets you validate your build configuration and conduct a series of checks prior to executing your build. Think of it as an advanced form of linting for your Dockerfile and build options, or a dry-run mode for builds.\n\nYou can find the list of checks available, and a description of each, in the [Build checks reference](https://docs.docker.com/reference/build-checks/).\n\nTypically, when you run a build, Docker executes the build steps in your Dockerfile and build options as specified. With build checks, rather than executing the build steps, Docker checks the Dockerfile and options you provide and reports any issues it detects.\n\nBuild checks are useful for:\n\n*   Validating your Dockerfile and build options before running a build.\n*   Ensuring that your Dockerfile and build options are up-to-date with the latest best practices.\n*   Identifying potential issues or anti-patterns in your Dockerfile and build options.\n\nBuild checks are supported in Buildx version 0.15.0 and later. Invoking a build runs the checks by default, and displays any violations in the build output. For example, the following command both builds the image and runs the checks:\n\nIn this example, the build ran successfully, but a [JSONArgsRecommended](https://docs.docker.com/reference/build-checks/json-args-recommended/) warning was reported, because `CMD` instructions should use JSON array syntax.\n\n### [More verbose output](#more-verbose-output)\n\nCheck warnings for a regular `docker build` display a concise message containing the rule name, the message, and the line number of where in the Dockerfile the issue originated. If you want to see more detailed information about the checks, you can use the `--debug` flag. For example:\n\nWith the `--debug` flag, the output includes a link to the documentation for the check, and a snippet of the Dockerfile where the issue was found.\n\nTo run build checks without actually building, you can use the `docker build` command as you typically would, but with the addition of the `--check` flag. Here's an example:\n\nInstead of executing the build steps, this command only runs the checks and reports any issues it finds. If there are any issues, they will be reported in the output. For example:\n\nThis output with `--check` shows the [verbose message](#more-verbose-output) for the check.\n\nUnlike a regular build, if any violations are reported when using the `--check` flag, the command exits with a non-zero status code.\n\nCheck violations for builds are reported as warnings, with exit code 0, by default. You can configure Docker to fail the build when violations are reported, using a `check=error=true` directive in your Dockerfile. This will cause the build to error out when after the build checks are run, before the actual build gets executed.\n\nWithout the `# check=error=true` directive, this build would complete with an exit code of 0. However, with the directive, build check violation results in non-zero exit code:\n\nYou can also set the error directive on the CLI by passing the `BUILDKIT_DOCKERFILE_CHECK` build argument:\n\nBy default, all checks are run when you build an image. If you want to skip specific checks, you can use the `check=skip` directive in your Dockerfile. The `skip` parameter takes a CSV string of the check IDs you want to skip. For example:\n\nBuilding this Dockerfile results in no check violations.\n\nYou can also skip checks by passing the `BUILDKIT_DOCKERFILE_CHECK` build argument with a CSV string of check IDs you want to skip. For example:\n\nTo both skip specific checks and error on check violations, pass both the `skip` and `error` parameters separated by a semi-colon (`;`) to the `check` directive in your Dockerfile or in a build argument. For example:",
  "title": "Checking your build configuration | Docker Docs\n",
  "description": "Learn how to use build checks to validate your build configuration.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/27.0/",
  "markdown": "# Docker Engine 27.0 release notes\n\nThis page describes the latest changes, additions, known issues, and fixes for Docker Engine version 27.0.\n\nFor more information about:\n\n*   Deprecated and removed features, see [Deprecated Engine Features](https://docs.docker.com/engine/deprecated/).\n*   Changes to the Engine API, see [Engine API version history](https://docs.docker.com/engine/api/version-history/).\n\n_2024-07-01_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 27.0.3 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A27.0.3)\n*   [moby/moby, 27.0.3 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A27.0.3)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v27.0.3/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v27.0.3/docs/api/version-history.md).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements)\n\n*   Fix a regression that incorrectly reported a port mapping from a host IPv6 address to an IPv4-only container as an error. [moby/moby#48090](https://github.com/moby/moby/pull/48090)\n*   Fix a regression that caused duplicate subnet allocations when creating networks. [moby/moby#48089](https://github.com/moby/moby/pull/48089)\n*   Fix a regression resulting in `fail to register layer: failed to Lchown` errors when trying to pull an image with rootless enabled on a system that supports native overlay with user-namespaces. [moby/moby#48086](https://github.com/moby/moby/pull/48086)\n\n_2024-06-27_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 27.0.2 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A27.0.2)\n*   [moby/moby, 27.0.2 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A27.0.2)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v27.0.2/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v27.0.2/docs/api/version-history.md).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-1)\n\n*   Fix a regression that caused port numbers to be ignored when parsing a Docker registry URL. [docker/cli#5197](https://github.com/docker/cli/pull/5197), [docker/cli#5198](https://github.com/docker/cli/pull/5198)\n\n### [Removed](#removed)\n\n*   api/types: deprecate `ContainerJSONBase.Node` field and `ContainerNode` type. These definitions were used by the standalone (\"classic\") Swarm API, but never implemented in the Docker Engine itself. [moby/moby#48055](https://github.com/moby/moby/pull/48055)\n\n_2024-06-24_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 27.0.0 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A27.0.0)\n*   [moby/moby, 27.0.0 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A27.0.0)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v27.0.1/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v27.0.1/docs/api/version-history.md).\n\n### [New](#new)\n\n*   containerd image store: Add `--platform` flag to `docker image push` and improve the default behavior when not all platforms of the multi-platform image are available locally. [docker/cli#4984](https://github.com/docker/cli/pull/4984), [moby/moby#47679](https://github.com/moby/moby/pull/47679)\n*   Add support to `docker stack deploy` for `driver_opts` in a service's networks. [docker/cli#5125](https://github.com/docker/cli/pull/5125)\n*   Consider additional `/usr/local/libexec` and `/usr/libexec` paths when looking up the userland proxy binaries by a name with a `docker-` prefix. [moby/moby#47804](https://github.com/moby/moby/pull/47804)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-2)\n\n*   `*client.Client` instances are now always safe for concurrent use by multiple goroutines. Previously, this could lead to data races when the `WithAPIVersionNegotiation()` option is used. [moby/moby#47961](https://github.com/moby/moby/pull/47961)\n*   Fix a bug causing the Docker CLI to leak Unix sockets in `$TMPDIR` in some cases. [docker/cli#5146](https://github.com/docker/cli/pull/5146)\n*   Don't ignore a custom seccomp profile when used in conjunction with `--privileged`. [moby/moby#47500](https://github.com/moby/moby/pull/47500)\n*   rootless: overlay2: support native overlay diff when using rootless-mode with Linux kernel version 5.11 and later. [moby/moby#47605](https://github.com/moby/moby/pull/47605)\n*   Fix the `StartInterval` default value of healthcheck to reflect the documented value of 5s. [moby/moby#47799](https://github.com/moby/moby/pull/47799)\n*   Fix `docker save` and `docker load` not ending on the daemon side when the operation was cancelled by the user, for example with Ctrl+C. [moby/moby#47629](https://github.com/moby/moby/pull/47629)\n*   The `StartedAt` property of containers is now recorded before container startup, guaranteeing that the `StartedAt` is always before `FinishedAt`. [moby/moby#47003](https://github.com/moby/moby/pull/47003)\n*   The internal DNS resolver used by Windows containers on Windows now forwards requests to external DNS servers by default. This enables `nslookup` to resolve external hostnames. This behaviour can be disabled via `daemon.json`, using `\"features\": { \"windows-dns-proxy\": false }`. The configuration option will be removed in a future release. [moby/moby#47826](https://github.com/moby/moby/pull/47826)\n*   Print a warning when the CLI does not have permissions to read the configuration file. [docker/cli#5077](https://github.com/docker/cli/pull/5077)\n*   Fix a goroutine and file-descriptor leak on container attach. [moby/moby#45052](https://github.com/moby/moby/pull/45052)\n*   Clear the networking state of all stopped or dead containers during daemon start-up. [moby/moby#47984](https://github.com/moby/moby/pull/47984)\n*   Write volume options JSON atomically to avoid \"invalid JSON\" errors after system crash. [moby/moby#48034](https://github.com/moby/moby/pull/48034)\n*   Allow multiple macvlan networks with the same parent. [moby/moby#47318](https://github.com/moby/moby/pull/47318)\n*   Allow BuildKit to be used on Windows daemons that advertise it. [docker/cli#5178](https://github.com/docker/cli/pull/5178)\n\n### [Networking](#networking)\n\n*   Allow sysctls to be set per-interface during container creation and network connection. [moby/moby#47686](https://github.com/moby/moby/pull/47686)\n    *   In a future release, this will be the only way to set per-interface sysctl options. For example, on the command line in a `docker run` command,`--network mynet --sysctl net.ipv4.conf.eth0.log_martians=1` will be rejected. Instead, you must use `--network name=mynet,driver-opt=com.docker.network.endpoint.sysctls=net.ipv4.conf.IFNAME.log_martians=1`.\n\n#### [IPv6](#ipv6)\n\n*   `ip6tables` is no longer experimental. You may remove the `experimental` configuration option and continue to use IPv6, if it is not required by any other features.\n*   `ip6tables` is now enabled for Linux bridge networks by default. [moby/moby#47747](https://github.com/moby/moby/pull/47747)\n    *   This makes IPv4 and IPv6 behaviors consistent with each other, and reduces the risk that IPv6-enabled containers are inadvertently exposed to the network.\n    *   There is no impact if you are running Docker Engine with `ip6tables` enabled (new default).\n    *   If you are using an IPv6-enabled bridge network without `ip6tables`, this is likely a breaking change. Only published container ports (`-p` or `--publish`) are accessible from outside the Docker bridge network, and outgoing connections masquerade as the host.\n    *   To restore the behavior of earlier releases, no `ip6tables` at all, set `\"ip6tables\": false` in `daemon.json`, or use the CLI option `--ip6tables=false`. Alternatively, leave `ip6tables` enabled, publish ports, and enable direct routing.\n    *   With `ip6tables` enabled, if `ip6tables` is not functional on your host, Docker Engine will start but it will not be possible to create an IPv6-enabled network.\n\n#### [IPv6 network configuration improvements](#ipv6-network-configuration-improvements)\n\n*   A Unique Local Address (ULA) base prefix is automatically added to `default-address-pools` if this parameter wasn't manually configured, or if it contains no IPv6 prefixes. [moby/moby#47853](https://github.com/moby/moby/pull/47853)\n    *   Prior to this release, to create an IPv6-enabled network it was necessary to use the `--subnet` option to specify an IPv6 subnet, or add IPv6 ranges to `default-address-pools` in `daemon.json`.\n    *   Starting in this release, when a bridge network is created with `--ipv6` and no IPv6 subnet is defined by those options, an IPv6 Unique Local Address (ULA) base prefix is used.\n    *   The ULA prefix is derived from the Engine host ID such that it's unique across hosts and over time.\n*   IPv6 address pools of any size can now be added to `default-address-pools`. [moby/moby#47768](https://github.com/moby/moby/pull/47768)\n*   IPv6 can now be enabled by default on all custom bridge networks using `\"default-network-opts\": { \"bridge\": {\"com.docker.network.enable_ipv6\": \"true\"}}` in `daemon.json`, or `dockerd --default-network-opt=bridge=com.docker.network.enable_ipv6=true`on the comand line. [moby/moby#47867](https://github.com/moby/moby/pull/47867)\n*   Direct routing for IPv6 networks, with `ip6tables` enabled. [moby/moby#47871](https://github.com/moby/moby/pull/47871)\n    *   Added bridge driver option `com.docker.network.bridge.gateway_mode_ipv6=<nat|routed>`.\n    *   The default behavior, `nat`, is unchanged from previous releases running with `ip6tables` enabled. NAT and masquerading rules are set up for each published container port.\n    *   When set to `routed`, no NAT or masquerading rules are configured for published ports. This enables direct IPv6 access to the container, if the host's network can route packets for the container's address to the host. Published ports will be opened in the container's firewall.\n    *   When a port mapping only applies to `routed` mode, only addresses `0.0.0.0` or `::` are allowed and a host port must not be given.\n    *   Note that published container ports, in `nat` or `routed` mode, are accessible from any remote address if routing is set up in the network, unless the Docker host's firewall has additional restrictions. For example: `docker network create --ipv6 -o com.docker.network.bridge.gateway_mode_ipv6=routed mynet`.\n    *   The option `com.docker.network.bridge.gateway_mode_ipv4=<nat|routed>` is also available, with the same behavior but for IPv4.\n*   If firewalld is running on the host, Docker creates policy `docker-forwarding` to allow forwarding from any zone to the `docker` zone. This makes it possible to configure a bridge network with a routable IPv6 address, and no NAT or masquerading. [moby/moby#47745](https://github.com/moby/moby/pull/47745)\n*   When a port is published with no host port specified, or a host port range is given, the same port will be allocated for IPv4 and IPv6. [moby/moby#47871](https://github.com/moby/moby/pull/47871)\n    *   For example `-p 80` will result in the same ephemeral port being allocated for `0.0.0.0` and `::`, and `-p 8080-8083:80` will pick the same port from the range for both address families.\n    *   Similarly, ports published to specific addresses will be allocated the same port. For example, `-p 127.0.0.1::80 -p '[::1]::80'`.\n    *   If no port is available on all required addresses, container creation will fail.\n*   Environment variable `DOCKER_ALLOW_IPV6_ON_IPV4_INTERFACE`, introduced in release 26.1.1, no longer has any effect. [moby/moby#47963](https://github.com/moby/moby/pull/47963)\n    *   If IPv6 could not be disabled on an interface because of a read-only `/proc/sys/net`, the environment variable allowed the container to start anyway.\n    *   In this release, if IPv4 cannot be disabled for an interface, IPv6 can be explicitly enabled for the network simply by using `--ipv6` when creating it. Other workarounds are to configure the OS to disable IPv6 by default on new interfaces, mount `/proc/sys/net` read-write, or use a kernel with no IPv6 support.\n*   For IPv6-enabled bridge networks, do not attempt to replace the bridge's kernel-assigned link local address with `fe80::1`. [moby/moby#47787](https://github.com/moby/moby/pull/47787)\n\n### [Removed](#removed-1)\n\n*   Deprecate experimental GraphDriver plugins. [moby/moby#48050](https://github.com/moby/moby/pull/48050), [docker/cli#5172](https://github.com/docker/cli/pull/5172)\n*   pkg/archive: deprecate `NewTempArchive` and `TempArchive`. These types were only used in tests and will be removed in the next release. [moby/moby#48002](https://github.com/moby/moby/pull/48002)\n*   pkg/archive: deprecate `CanonicalTarNameForPath` [moby/moby#48001](https://github.com/moby/moby/pull/48001)\n*   Deprecate pkg/dmesg. This package was no longer used, and will be removed in the next release. [moby/moby#47999](https://github.com/moby/moby/pull/47999)\n*   Deprecate `pkg/stringid.ValidateID` and `pkg/stringid.IsShortID` [moby/moby#47995](https://github.com/moby/moby/pull/47995)\n*   runconfig: deprecate `SetDefaultNetModeIfBlank` and move `ContainerConfigWrapper` to `api/types/container` [moby/moby#48007](https://github.com/moby/moby/pull/48007)\n*   runconfig: deprecate `DefaultDaemonNetworkMode` and move to `daemon/network` [moby/moby#48008](https://github.com/moby/moby/pull/48008)\n*   runconfig: deprecate `opts.ConvertKVStringsToMap`. This utility is no longer used, and will be removed in the next release. [moby/moby#48016](https://github.com/moby/moby/pull/48016)\n*   runconfig: deprecate `IsPreDefinedNetwork`. [moby/moby#48011](https://github.com/moby/moby/pull/48011)\n\n### [API](#api)\n\n*   containerd image store: `POST /images/{name}/push` now supports a `platform` parameter (JSON encoded OCI Platform type) that allows selecting a specific platform-manifest from the multi-platform image. This is experimental and may change in future API versions. [moby/moby#47679](https://github.com/moby/moby/pull/47679)\n*   `POST /services/create` and `POST /services/{id}/update` now support `OomScoreAdj`. [moby/moby#47950](https://github.com/moby/moby/pull/47950)\n*   `ContainerList` api returns container annotations. [moby/moby#47866](https://github.com/moby/moby/pull/47866)\n*   `POST /containers/create` and `POST /services/create` now take `Options` as part of `HostConfig.Mounts.TmpfsOptions` allowing to set options for tmpfs mounts. [moby/moby#46809](https://github.com/moby/moby/pull/46809)\n*   The `Healthcheck.StartInterval` property is now correctly ignored when updating a Swarm service using API versions less than v1.44. [moby/moby#47991](https://github.com/moby/moby/pull/47991)\n*   `GET /events` now supports image `create` event that is emitted when a new image is built regardless if it was tagged or not. [moby/moby#47929](https://github.com/moby/moby/pull/47929)\n*   `GET /info` now includes a `Containerd` field containing information about the location of the containerd API socket and containerd namespaces used by the daemon to run containers and plugins. [moby/moby#47239](https://github.com/moby/moby/pull/47239)\n*   Deprecate non-standard (config) fields in image inspect output. The `Config` field returned by this endpoint (used for `docker image inspect`) returned additional fields that are not part of the image's configuration and not part of the [Docker Image Spec](https://github.com/moby/docker-image-spec/blob/v1.3.1/specs-go/v1/image.go#L19-L32) and the [OCI Image Spec](https://github.com/opencontainers/image-spec/blob/v1.1.0/specs-go/v1/config.go#L24-L62). These fields are never set (and always return the default value for the type), but are not omitted in the response when left empty. As these fields were not intended to be part of the image configuration response, they are deprecated, and will be removed in the future API versions.\n*   Deprecate the daemon flag `--api-cors-header` and the corresponding `daemon.json` configuration option. These will be removed in the next major release. [moby/moby#45313](https://github.com/moby/moby/pull/45313)\n\nThe following deprecated fields are currently included in the API response, but are not part of the underlying image's `Config`: [moby/moby#47941](https://github.com/moby/moby/pull/47941)\n\n*   `Hostname`\n*   `Domainname`\n*   `AttachStdin`\n*   `AttachStdout`\n*   `AttachStderr`\n*   `Tty`\n*   `OpenStdin`\n*   `StdinOnce`\n*   `Image`\n*   `NetworkDisabled` (already omitted unless set)\n*   `MacAddress` (already omitted unless set)\n*   `StopTimeout` (already omitted unless set)\n\n### [Go SDK changes](#go-sdk-changes)\n\n*   Client API callback for the following functions now require a context parameter. [moby/moby#47536](https://github.com/moby/moby/pull/47536)\n    *   `client.RequestPrivilegeFunc`\n    *   `client.ImageSearchOptions.AcceptPermissionsFunc`\n    *   `image.ImportOptions.PrivilegeFunc`\n*   Remove deprecated aliases for Image types. [moby/moby#47900](https://github.com/moby/moby/pull/47900)\n    *   `ImageImportOptions`\n    *   `ImageCreateOptions`\n    *   `ImagePullOptions`\n    *   `ImagePushOptions`\n    *   `ImageListOptions`\n    *   `ImageRemoveOptions`\n*   Introduce `Ulimit` type alias for `github.com/docker/go-units.Ulimit`. The `Ulimit` type as used in the API is defined in a Go module that will transition to a new location in future. A type alias is added to reduce the friction that comes with moving the type to a new location. The alias makes sure that existing code continues to work, but its definition may change in future. Users are recommended to use this alias instead of the `units.Ulimit` directly. [moby/moby#48023](https://github.com/moby/moby/pull/48023)\n\nMove and rename types, changing their import paths and exported names. [moby/moby#47936](https://github.com/moby/moby/pull/47936), [moby/moby#47873](https://github.com/moby/moby/pull/47873), [moby/moby#47887](https://github.com/moby/moby/pull/47887), [moby/moby#47882](https://github.com/moby/moby/pull/47882), [moby/moby#47921](https://github.com/moby/moby/pull/47921), [moby/moby#48040](https://github.com/moby/moby/pull/48040)\n\n*   Move the following types to `api/types/container`:\n    *   `BlkioStatEntry`\n    *   `BlkioStats`\n    *   `CPUStats`\n    *   `CPUUsage`\n    *   `ContainerExecInspect`\n    *   `ContainerPathStat`\n    *   `ContainerStats`\n    *   `ContainersPruneReport`\n    *   `CopyToContainerOptions`\n    *   `ExecConfig`\n    *   `ExecStartCheck`\n    *   `MemoryStats`\n    *   `NetworkStats`\n    *   `PidsStats`\n    *   `StatsJSON`\n    *   `Stats`\n    *   `StorageStats`\n    *   `ThrottlingData`\n*   Move the following types to `api/types/image`:\n    *   `ImagesPruneReport`\n    *   `ImageImportSource`\n    *   `ImageLoadResponse`\n*   Move the `ExecStartOptions` type to `api/types/backend`.\n*   Move the `VolumesPruneReport` type to `api/types/volume`.\n*   Move the `EventsOptions` type to `api/types/events`.\n*   Move the `ImageSearchOptions` type to `api/types/registry`.\n*   Drop `Network` prefix and move the following types to `api/types/network`:\n    *   `NetworkCreateResponse`\n    *   `NetworkConnect`\n    *   `NetworkDisconnect`\n    *   `NetworkInspectOptions`\n    *   `EndpointResource`\n    *   `NetworkListOptions`\n    *   `NetworkCreateOptions`\n    *   `NetworkCreateRequest`\n    *   `NetworksPruneReport`\n*   Move `NetworkResource` to `api/types/network`.\n\n### [Packaging updates](#packaging-updates)\n\n*   Update Buildx to [v0.15.1](https://github.com/docker/buildx/releases/tag/v0.15.1). [docker/docker-ce-packaging#1029](https://github.com/docker/docker-ce-packaging/pull/1029)\n*   Update BuildKit to [v0.14.1](https://github.com/moby/buildkit/releases/tag/v0.14.1). [moby/moby#48028](https://github.com/moby/moby/pull/48028)\n*   Update runc to [v1.1.13](https://github.com/opencontainers/runc/releases/tag/v1.1.13) [moby/moby#47976](https://github.com/moby/moby/pull/47976)\n*   Update Compose to [v2.28.1](https://github.com/docker/compose/releases/tag/v2.28.1). [moby/docker-ce-packaging#1032](https://github.com/docker/docker-ce-packaging/pull/1032)\n\nThere's no 27.0.0 release due to a mistake during the pre-release of 27.0.0-rc.1 on GitHub which resulted in the v27.0.0 tag being created. Unfortunately the tag was already picked up by the [Go Module Mirror](https://sum.golang.org/) so it's not possible to cleanly change the v27.0.0. To workaround this, the 27.0.1 will be the first release of the 27.0.",
  "title": "Docker Engine 27.0 release notes | Docker Docs\n",
  "description": "Learn about the new features, bug fixes, and breaking changes for Docker Engine",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/builders/",
  "markdown": "# Builders | Docker Docs\n\nA builder is a BuildKit daemon that you can use to run your builds. BuildKit is the build engine that solves the build steps in a Dockerfile to produce a container image or other artifacts.\n\nYou can create and manage builders, inspect them, and even connect to builders running remotely. You interact with builders using the Docker CLI.\n\nDocker Engine automatically creates a builder that becomes the default backend for your builds. This builder uses the BuildKit library bundled with the daemon. This builder requires no configuration.\n\nThe default builder is directly bound to the Docker daemon and its [context](https://docs.docker.com/engine/context/working-with-contexts/). If you change the Docker context, your `default` builder refers to the new Docker context.\n\nBuildx implements a concept of [build drivers](https://docs.docker.com/build/drivers/) to refer to different builder configurations. The default builder created by the daemon uses the [`docker` driver](https://docs.docker.com/build/drivers/docker/).\n\nBuildx supports the following build drivers:\n\n*   `docker`: uses the BuildKit library bundled into the Docker daemon.\n*   `docker-container`: creates a dedicated BuildKit container using Docker.\n*   `kubernetes`: creates BuildKit pods in a Kubernetes cluster.\n*   `remote`: connects directly to a manually managed BuildKit daemon.\n\nSelected builder refers to the builder that's used by default when you run build commands.\n\nWhen you run a build, or interact with builders in some way using the CLI, you can use the optional `--builder` flag, or the `BUILDX_BUILDER` [environment variable](https://docs.docker.com/build/building/variables/#buildx_builder), to specify a builder by name. If you don't specify a builder, the selected builder is used.\n\nUse the `docker buildx ls` command to see the available builder instances. The asterisk (`*`) next to a builder name indicates the selected builder.\n\n### [Select a different builder](#select-a-different-builder)\n\nTo switch between builders, use the `docker buildx use <name>` command.\n\nAfter running this command, the builder you specify is automatically selected when you invoke builds.\n\n*   For information about how to interact with and manage builders, see [Manage builders](https://docs.docker.com/build/builders/manage/)\n*   To learn about different types of builders, see [Build drivers](https://docs.docker.com/build/drivers/)",
  "title": "Builders | Docker Docs\n",
  "description": "Learn about builders and how to manage them",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/security/userns-remap/",
  "markdown": "# Isolate containers with a user namespace\n\nLinux namespaces provide isolation for running processes, limiting their access to system resources without the running process being aware of the limitations. For more information on Linux namespaces, see [Linux namespaces](https://www.linux.com/news/understanding-and-securing-linux-namespaces).\n\nThe best way to prevent privilege-escalation attacks from within a container is to configure your container's applications to run as unprivileged users. For containers whose processes must run as the `root` user within the container, you can re-map this user to a less-privileged user on the Docker host. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself.\n\nThe remapping itself is handled by two files: `/etc/subuid` and `/etc/subgid`. Each file works the same, but one is concerned with the user ID range, and the other with the group ID range. Consider the following entry in `/etc/subuid`:\n\nThis means that `testuser` is assigned a subordinate user ID range of `231072` and the next 65536 integers in sequence. UID `231072` is mapped within the namespace (within the container, in this case) as UID `0` (`root`). UID `231073` is mapped as UID `1`, and so forth. If a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, which does not even map to a real user. This means the process has no privileges on the host system at all.\n\n> **Note**\n> \n> It is possible to assign multiple subordinate ranges for a given user or group by adding multiple non-overlapping mappings for the same user or group in the `/etc/subuid` or `/etc/subgid` file. In this case, Docker uses only the first five mappings, in accordance with the kernel's limitation of only five entries in `/proc/self/uid_map` and `/proc/self/gid_map`.\n\nWhen you configure Docker to use the `userns-remap` feature, you can optionally specify an existing user and/or group, or you can specify `default`. If you specify `default`, a user and group `dockremap` is created and used for this purpose.\n\n> **Warning**\n> \n> Some distributions do not automatically add the new group to the `/etc/subuid` and `/etc/subgid` files. If that's the case, you are may have to manually edit these files and assign non-overlapping ranges. This step is covered in [Prerequisites](#prerequisites).\n\nIt is very important that the ranges do not overlap, so that a process cannot gain access in a different namespace. On most Linux distributions, system utilities manage the ranges for you when you add or remove users.\n\nThis re-mapping is transparent to the container, but introduces some configuration complexity in situations where the container needs access to resources on the Docker host, such as bind mounts into areas of the filesystem that the system user cannot write to. From a security standpoint, it is best to avoid these situations.\n\n1.  The subordinate UID and GID ranges must be associated with an existing user, even though the association is an implementation detail. The user owns the namespaced storage directories under `/var/lib/docker/`. If you don't want to use an existing user, Docker can create one for you and use that. If you want to use an existing username or user ID, it must already exist. Typically, this means that the relevant entries need to be in `/etc/passwd` and `/etc/group`, but if you are using a different authentication back-end, this requirement may translate differently.\n    \n    To verify this, use the `id` command:\n    \n2.  The way the namespace remapping is handled on the host is using two files, `/etc/subuid` and `/etc/subgid`. These files are typically managed automatically when you add or remove users or groups, but on some distributions, you may need to manage these files manually.\n    \n    Each file contains three fields: the username or ID of the user, followed by a beginning UID or GID (which is treated as UID or GID 0 within the namespace) and a maximum number of UIDs or GIDs available to the user. For instance, given the following entry:\n    \n    This means that user-namespaced processes started by `testuser` are owned by host UID `231072` (which looks like UID `0` inside the namespace) through 296607 (231072 + 65536 - 1). These ranges should not overlap, to ensure that namespaced processes cannot access each other's namespaces.\n    \n    After adding your user, check `/etc/subuid` and `/etc/subgid` to see if your user has an entry in each. If not, you need to add it, being careful to avoid overlap.\n    \n    If you want to use the `dockremap` user automatically created by Docker, check for the `dockremap` entry in these files after configuring and restarting Docker.\n    \n3.  If there are any locations on the Docker host where the unprivileged user needs to write, adjust the permissions of those locations accordingly. This is also true if you want to use the `dockremap` user automatically created by Docker, but you can't modify the permissions until after configuring and restarting Docker.\n    \n4.  Enabling `userns-remap` effectively masks existing image and container layers, as well as other Docker objects within `/var/lib/docker/`. This is because Docker needs to adjust the ownership of these resources and actually stores them in a subdirectory within `/var/lib/docker/`. It is best to enable this feature on a new Docker installation rather than an existing one.\n    \n    Along the same lines, if you disable `userns-remap` you can't access any of the resources created while it was enabled.\n    \n5.  Check the [limitations](#user-namespace-known-limitations) on user namespaces to be sure your use case is possible.\n    \n\nYou can start `dockerd` with the `--userns-remap` flag or follow this procedure to configure the daemon using the `daemon.json` configuration file. The `daemon.json` method is recommended. If you use the flag, use the following command as a model:\n\n1.  Edit `/etc/docker/daemon.json`. Assuming the file was previously empty, the following entry enables `userns-remap` using user and group called `testuser`. You can address the user and group by ID or name. You only need to specify the group name or ID if it is different from the user name or ID. If you provide both the user and group name or ID, separate them by a colon (`:`) character. The following formats all work for the value, assuming the UID and GID of `testuser` are `1001`:\n    \n    *   `testuser`\n    *   `testuser:testuser`\n    *   `1001`\n    *   `1001:1001`\n    *   `testuser:1001`\n    *   `1001:testuser`\n    \n    > **Note**\n    > \n    > To use the `dockremap` user and have Docker create it for you, set the value to `default` rather than `testuser`.\n    \n    Save the file and restart Docker.\n    \n2.  If you are using the `dockremap` user, verify that Docker created it using the `id` command.\n    \n    Verify that the entry has been added to `/etc/subuid` and `/etc/subgid`:\n    \n    If these entries are not present, edit the files as the `root` user and assign a starting UID and GID that is the highest-assigned one plus the offset (in this case, `65536`). Be careful not to allow any overlap in the ranges.\n    \n3.  Verify that previous images are not available using the `docker image ls` command. The output should be empty.\n    \n4.  Start a container from the `hello-world` image.\n    \n5.  Verify that a namespaced directory exists within `/var/lib/docker/` named with the UID and GID of the namespaced user, owned by that UID and GID, and not group-or-world-readable. Some of the subdirectories are still owned by `root` and have different permissions.\n    \n    Your directory listing may have some differences, especially if you use a different container storage driver than `aufs`.\n    \n    The directories which are owned by the remapped user are used instead of the same directories directly beneath `/var/lib/docker/` and the unused versions (such as `/var/lib/docker/tmp/` in the example here) can be removed. Docker does not use them while `userns-remap` is enabled.\n    \n\nIf you enable user namespaces on the daemon, all containers are started with user namespaces enabled by default. In some situations, such as privileged containers, you may need to disable user namespaces for a specific container. See [user namespace known limitations](#user-namespace-known-limitations) for some of these limitations.\n\nTo disable user namespaces for a specific container, add the `--userns=host` flag to the `docker container create`, `docker container run`, or `docker container exec` command.\n\nThere is a side effect when using this flag: user remapping will not be enabled for that container but, because the read-only (image) layers are shared between containers, ownership of the containers filesystem will still be remapped.\n\nWhat this means is that the whole container filesystem will belong to the user specified in the `--userns-remap` daemon config (`231072` in the example above). This can lead to unexpected behavior of programs inside the container. For instance `sudo` (which checks that its binaries belong to user `0`) or binaries with a `setuid` flag.\n\nThe following standard Docker features are incompatible with running a Docker daemon with user namespaces enabled:\n\n*   Sharing PID or NET namespaces with the host (`--pid=host` or `--network=host`).\n*   External (volume or storage) drivers which are unaware or incapable of using daemon user mappings.\n*   Using the `--privileged` mode flag on `docker run` without also specifying `--userns=host`.\n\nUser namespaces are an advanced feature and require coordination with other capabilities. For example, if volumes are mounted from the host, file ownership must be pre-arranged need read or write access to the volume contents.\n\nWhile the root user inside a user-namespaced container process has many of the expected privileges of the superuser within the container, the Linux kernel imposes restrictions based on internal knowledge that this is a user-namespaced process. One notable restriction is the inability to use the `mknod` command. Permission is denied for device creation within the container when run by the `root` user.",
  "title": "Isolate containers with a user namespace | Docker Docs\n",
  "description": "Isolate containers within a user namespace",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/extend/",
  "markdown": "# Docker Engine managed plugin system\n\n*   [Installing and using a plugin](https://docs.docker.com/engine/extend/#installing-and-using-a-plugin)\n*   [Developing a plugin](https://docs.docker.com/engine/extend/#developing-a-plugin)\n*   [Debugging plugins](https://docs.docker.com/engine/extend/#debugging-plugins)\n\nDocker Engine's plugin system lets you install, start, stop, and remove plugins using Docker Engine.\n\nFor information about legacy (non-managed) plugins, refer to [Understand legacy Docker Engine plugins](https://docs.docker.com/engine/extend/legacy_plugins/).\n\n> **Note**\n> \n> Docker Engine managed plugins are currently not supported on Windows daemons.\n\nPlugins are distributed as Docker images and can be hosted on Docker Hub or on a private registry.\n\nTo install a plugin, use the `docker plugin install` command, which pulls the plugin from Docker Hub or your private registry, prompts you to grant permissions or capabilities if necessary, and enables the plugin.\n\nTo check the status of installed plugins, use the `docker plugin ls` command. Plugins that start successfully are listed as enabled in the output.\n\nAfter a plugin is installed, you can use it as an option for another Docker operation, such as creating a volume.\n\nIn the following example, you install the `sshfs` plugin, verify that it is enabled, and use it to create a volume.\n\n> **Note**\n> \n> This example is intended for instructional purposes only. Once the volume is created, your SSH password to the remote host is exposed as plaintext when inspecting the volume. Delete the volume as soon as you are done with the example.\n\n1.  Install the `sshfs` plugin.\n    \n    The plugin requests 2 privileges:\n    \n    *   It needs access to the `host` network.\n    *   It needs the `CAP_SYS_ADMIN` capability, which allows the plugin to run the `mount` command.\n2.  Check that the plugin is enabled in the output of `docker plugin ls`.\n    \n3.  Create a volume using the plugin. This example mounts the `/remote` directory on host `1.2.3.4` into a volume named `sshvolume`.\n    \n    This volume can now be mounted into containers.\n    \n4.  Verify that the volume was created successfully.\n    \n5.  Start a container that uses the volume `sshvolume`.\n    \n6.  Remove the volume `sshvolume`\n    \n\nTo disable a plugin, use the `docker plugin disable` command. To completely remove it, use the `docker plugin remove` command. For other available commands and options, see the [command line reference](https://docs.docker.com/engine/reference/commandline/cli/).\n\n#### [The rootfs directory](#the-rootfs-directory)\n\nThe `rootfs` directory represents the root filesystem of the plugin. In this example, it was created from a Dockerfile:\n\n> **Note**\n> \n> The `/run/docker/plugins` directory is mandatory inside of the plugin's filesystem for Docker to communicate with the plugin.\n\n#### [The config.json file](#the-configjson-file)\n\nThe `config.json` file describes the plugin. See the [plugins config reference](https://docs.docker.com/engine/extend/config/).\n\nConsider the following `config.json` file.\n\nThis plugin is a volume driver. It requires a `host` network and the `CAP_SYS_ADMIN` capability. It depends upon the `/docker-volume-sshfs` entrypoint and uses the `/run/docker/plugins/sshfs.sock` socket to communicate with Docker Engine. This plugin has no runtime parameters.\n\n#### [Creating the plugin](#creating-the-plugin)\n\nA new plugin can be created by running `docker plugin create <plugin-name> ./path/to/plugin/data` where the plugin data contains a plugin configuration file `config.json` and a root filesystem in subdirectory `rootfs`.\n\nAfter that the plugin `<plugin-name>` will show up in `docker plugin ls`. Plugins can be pushed to remote registries with `docker plugin push <plugin-name>`.\n\nStdout of a plugin is redirected to dockerd logs. Such entries have a `plugin=<ID>` suffix. Here are a few examples of commands for pluginID `f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62` and their corresponding log entries in the docker daemon logs.\n\n#### [Using runc to obtain logfiles and shell into the plugin.](#using-runc-to-obtain-logfiles-and-shell-into-the-plugin)\n\nUse `runc`, the default docker container runtime, for debugging plugins by collecting plugin logs redirected to a file.\n\nIf the plugin has a built-in shell, then exec into the plugin can be done as follows:\n\n#### [Using curl to debug plugin socket issues.](#using-curl-to-debug-plugin-socket-issues)\n\nTo verify if the plugin API socket that the docker daemon communicates with is responsive, use curl. In this example, we will make API calls from the docker host to volume and network plugins using curl 7.47.0 to ensure that the plugin is listening on the said socket. For a well functioning plugin, these basic requests should work. Note that plugin sockets are available on the host under `/var/run/docker/plugins/<pluginID>`\n\nWhen using curl 7.5 and above, the URL should be of the form `http://hostname/APICall`, where `hostname` is the valid hostname where the plugin is installed and `APICall` is the call to the plugin API.\n\nFor example, `http://localhost/VolumeDriver.List`",
  "title": "Docker Engine managed plugin system | Docker Docs\n",
  "description": "Develop and use a plugin with the managed plugin system",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/security/seccomp/",
  "markdown": "# Seccomp security profiles for Docker\n\n`acct`Accounting syscall which could let containers disable their own resource limits or process accounting. Also gated by `CAP_SYS_PACCT`.`add_key`Prevent containers from using the kernel keyring, which is not namespaced.`bpf`Deny loading potentially persistent bpf programs into kernel, already gated by `CAP_SYS_ADMIN`.`clock_adjtime`Time/date is not namespaced. Also gated by `CAP_SYS_TIME`.`clock_settime`Time/date is not namespaced. Also gated by `CAP_SYS_TIME`.`clone`Deny cloning new namespaces. Also gated by `CAP_SYS_ADMIN` for CLONE\\_\\* flags, except `CLONE_NEWUSER`.`create_module`Deny manipulation and functions on kernel modules. Obsolete. Also gated by `CAP_SYS_MODULE`.`delete_module`Deny manipulation and functions on kernel modules. Also gated by `CAP_SYS_MODULE`.`finit_module`Deny manipulation and functions on kernel modules. Also gated by `CAP_SYS_MODULE`.`get_kernel_syms`Deny retrieval of exported kernel and module symbols. Obsolete.`get_mempolicy`Syscall that modifies kernel memory and NUMA settings. Already gated by `CAP_SYS_NICE`.`init_module`Deny manipulation and functions on kernel modules. Also gated by `CAP_SYS_MODULE`.`ioperm`Prevent containers from modifying kernel I/O privilege levels. Already gated by `CAP_SYS_RAWIO`.`iopl`Prevent containers from modifying kernel I/O privilege levels. Already gated by `CAP_SYS_RAWIO`.`kcmp`Restrict process inspection capabilities, already blocked by dropping `CAP_SYS_PTRACE`.`kexec_file_load`Sister syscall of `kexec_load` that does the same thing, slightly different arguments. Also gated by `CAP_SYS_BOOT`.`kexec_load`Deny loading a new kernel for later execution. Also gated by `CAP_SYS_BOOT`.`keyctl`Prevent containers from using the kernel keyring, which is not namespaced.`lookup_dcookie`Tracing/profiling syscall, which could leak a lot of information on the host. Also gated by `CAP_SYS_ADMIN`.`mbind`Syscall that modifies kernel memory and NUMA settings. Already gated by `CAP_SYS_NICE`.`mount`Deny mounting, already gated by `CAP_SYS_ADMIN`.`move_pages`Syscall that modifies kernel memory and NUMA settings.`nfsservctl`Deny interaction with the kernel nfs daemon. Obsolete since Linux 3.1.`open_by_handle_at`Cause of an old container breakout. Also gated by `CAP_DAC_READ_SEARCH`.`perf_event_open`Tracing/profiling syscall, which could leak a lot of information on the host.`personality`Prevent container from enabling BSD emulation. Not inherently dangerous, but poorly tested, potential for a lot of kernel vulns.`pivot_root`Deny `pivot_root`, should be privileged operation.`process_vm_readv`Restrict process inspection capabilities, already blocked by dropping `CAP_SYS_PTRACE`.`process_vm_writev`Restrict process inspection capabilities, already blocked by dropping `CAP_SYS_PTRACE`.`ptrace`Tracing/profiling syscall. Blocked in Linux kernel versions before 4.8 to avoid seccomp bypass. Tracing/profiling arbitrary processes is already blocked by dropping `CAP_SYS_PTRACE`, because it could leak a lot of information on the host.`query_module`Deny manipulation and functions on kernel modules. Obsolete.`quotactl`Quota syscall which could let containers disable their own resource limits or process accounting. Also gated by `CAP_SYS_ADMIN`.`reboot`Don't let containers reboot the host. Also gated by `CAP_SYS_BOOT`.`request_key`Prevent containers from using the kernel keyring, which is not namespaced.`set_mempolicy`Syscall that modifies kernel memory and NUMA settings. Already gated by `CAP_SYS_NICE`.`setns`Deny associating a thread with a namespace. Also gated by `CAP_SYS_ADMIN`.`settimeofday`Time/date is not namespaced. Also gated by `CAP_SYS_TIME`.`stime`Time/date is not namespaced. Also gated by `CAP_SYS_TIME`.`swapon`Deny start/stop swapping to file/device. Also gated by `CAP_SYS_ADMIN`.`swapoff`Deny start/stop swapping to file/device. Also gated by `CAP_SYS_ADMIN`.`sysfs`Obsolete syscall.`_sysctl`Obsolete, replaced by /proc/sys.`umount`Should be a privileged operation. Also gated by `CAP_SYS_ADMIN`.`umount2`Should be a privileged operation. Also gated by `CAP_SYS_ADMIN`.`unshare`Deny cloning new namespaces for processes. Also gated by `CAP_SYS_ADMIN`, with the exception of `unshare --user`.`uselib`Older syscall related to shared libraries, unused for a long time.`userfaultfd`Userspace page fault handling, largely needed for process migration.`ustat`Obsolete syscall.`vm86`In kernel x86 real mode virtual machine. Also gated by `CAP_SYS_ADMIN`.`vm86old`In kernel x86 real mode virtual machine. Also gated by `CAP_SYS_ADMIN`.",
  "title": "Seccomp security profiles for Docker | Docker Docs\n",
  "description": "Enabling seccomp in Docker",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/builders/manage/",
  "markdown": "# Manage builders | Docker Docs\n\nYou can create, inspect, and manage builders using `docker buildx` commands, or [using Docker Desktop](#manage-builders-with-docker-desktop).\n\nThe default builder uses the [`docker` driver](https://docs.docker.com/build/drivers/docker/). You can't manually create new `docker` builders, but you can create builders that use other drivers, such as the [`docker-container` driver](https://docs.docker.com/build/drivers/docker-container/), which runs the BuildKit daemon in a container.\n\nUse the [`docker buildx create`](https://docs.docker.com/reference/cli/docker/buildx/create/) command to create a builder.\n\nBuildx uses the `docker-container` driver by default if you omit the `--driver` flag. For more information about available drivers, see [Build drivers](https://docs.docker.com/build/drivers/).\n\nUse `docker buildx ls` to see builder instances available on your system, and the drivers they're using.\n\nThe asterisk (`*`) next to the builder name indicates the [selected builder](https://docs.docker.com/build/builders/#selected-builder).\n\nTo inspect a builder with the CLI, use `docker buildx inspect <name>`. You can only inspect a builder if the builder is active. You can add the `--bootstrap` flag to the command to start the builder.\n\nIf you want to see how much disk space a builder is using, use the `docker buildx du` command. By default, this command shows the total disk usage for all available builders. To see usage for a specific builder, use the `--builder` flag.\n\nUse the [`docker buildx remove`](https://docs.docker.com/reference/cli/docker/buildx/create/) command to remove a builder.\n\nIf you remove your currently selected builder, the default `docker` builder is automatically selected. You can't remove the default builder.\n\nLocal build cache for the builder is also removed.\n\n### [Removing remote builders](#removing-remote-builders)\n\nRemoving a remote builder doesn't affect the remote build cache. It also doesn't stop the remote BuildKit daemon. It only removes your connection to the builder.\n\nIf you have turned on the [Docker Desktop Builds view](https://docs.docker.com/desktop/use-desktop/builds/), you can inspect builders in Docker Desktop settings. See:\n\n*   [Change settings, Windows](https://docs.docker.com/desktop/settings/windows/#builders)\n*   [Change settings, Mac](https://docs.docker.com/desktop/settings/mac/#builders)\n*   [Change settings, Linux](https://docs.docker.com/desktop/settings/linux/#builders)",
  "title": "Manage builders | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/extend/plugins_authorization/",
  "markdown": "# Access authorization plugin | Docker Docs\n\nThis document describes the Docker Engine plugins available in Docker Engine. To view information on plugins managed by Docker Engine, refer to [Docker Engine plugin system](https://docs.docker.com/engine/extend/).\n\nDocker's out-of-the-box authorization model is all or nothing. Any user with permission to access the Docker daemon can run any Docker client command. The same is true for callers using Docker's Engine API to contact the daemon. If you require greater access control, you can create authorization plugins and add them to your Docker daemon configuration. Using an authorization plugin, a Docker administrator can configure granular access policies for managing access to the Docker daemon.\n\nAnyone with the appropriate skills can develop an authorization plugin. These skills, at their most basic, are knowledge of Docker, understanding of REST, and sound programming knowledge. This document describes the architecture, state, and methods information available to an authorization plugin developer.\n\nDocker's [plugin infrastructure](https://docs.docker.com/engine/extend/plugin_api/) enables extending Docker by loading, removing and communicating with third-party components using a generic API. The access authorization subsystem was built using this mechanism.\n\nUsing this subsystem, you don't need to rebuild the Docker daemon to add an authorization plugin. You can add a plugin to an installed Docker daemon. You do need to restart the Docker daemon to add a new plugin.\n\nAn authorization plugin approves or denies requests to the Docker daemon based on both the current authentication context and the command context. The authentication context contains all user details and the authentication method. The command context contains all the relevant request data.\n\nAuthorization plugins must follow the rules described in [Docker Plugin API](https://docs.docker.com/engine/extend/plugin_api/). Each plugin must reside within directories described under the [Plugin discovery](https://docs.docker.com/engine/extend/plugin_api/#plugin-discovery) section.\n\n> **Note**\n> \n> The abbreviations `AuthZ` and `AuthN` mean authorization and authentication respectively.\n\nIf TLS is enabled in the [Docker daemon](https://docs.docker.com/engine/security/https/), the default user authorization flow extracts the user details from the certificate subject name. That is, the `User` field is set to the client certificate subject common name, and the `AuthenticationMethod` field is set to `TLS`.\n\nYou are responsible for registering your plugin as part of the Docker daemon startup. You can install multiple plugins and chain them together. This chain can be ordered. Each request to the daemon passes in order through the chain. Only when all the plugins grant access to the resource, is the access granted.\n\nWhen an HTTP request is made to the Docker daemon through the CLI or via the Engine API, the authentication subsystem passes the request to the installed authentication plugin(s). The request contains the user (caller) and command context. The plugin is responsible for deciding whether to allow or deny the request.\n\nThe sequence diagrams below depict an allow and deny authorization flow:\n\n![Authorization Allow flow](https://docs.docker.com/engine/extend/images/authz_allow.png)\n\n![Authorization Deny flow](https://docs.docker.com/engine/extend/images/authz_deny.png)\n\nEach request sent to the plugin includes the authenticated user, the HTTP headers, and the request/response body. Only the user name and the authentication method used are passed to the plugin. Most importantly, no user credentials or tokens are passed. Finally, not all request/response bodies are sent to the authorization plugin. Only those request/response bodies where the `Content-Type` is either `text/*` or `application/json` are sent.\n\nFor commands that can potentially hijack the HTTP connection (`HTTP Upgrade`), such as `exec`, the authorization plugin is only called for the initial HTTP requests. Once the plugin approves the command, authorization is not applied to the rest of the flow. Specifically, the streaming data is not passed to the authorization plugins. For commands that return chunked HTTP response, such as `logs` and `events`, only the HTTP request is sent to the authorization plugins.\n\nDuring request/response processing, some authorization flows might need to do additional queries to the Docker daemon. To complete such flows, plugins can call the daemon API similar to a regular user. To enable these additional queries, the plugin must provide the means for an administrator to configure proper authentication and security policies.\n\nTo enable and configure the authorization plugin, the plugin developer must support the Docker client interactions detailed in this section.\n\n### [Setting up Docker daemon](#setting-up-docker-daemon)\n\nEnable the authorization plugin with a dedicated command line flag in the `--authorization-plugin=PLUGIN_ID` format. The flag supplies a `PLUGIN_ID` value. This value can be the pluginâ€™s socket or a path to a specification file. Authorization plugins can be loaded without restarting the daemon. Refer to the [`dockerd` documentation](https://docs.docker.com/reference/cli/dockerd/#configuration-reload-behavior) for more information.\n\nDocker's authorization subsystem supports multiple `--authorization-plugin` parameters.\n\n### [Calling authorized command (allow)](#calling-authorized-command-allow)\n\n### [Calling unauthorized command (deny)](#calling-unauthorized-command-deny)\n\n### [Error from plugins](#error-from-plugins)\n\nIn addition to Docker's standard plugin registration method, each plugin should implement the following two methods:\n\n*   `/AuthZPlugin.AuthZReq` This authorize request method is called before the Docker daemon processes the client request.\n    \n*   `/AuthZPlugin.AuthZRes` This authorize response method is called before the response is returned from Docker daemon to the client.\n    \n\n#### [/AuthZPlugin.AuthZReq](#authzpluginauthzreq)\n\nRequest\n\nResponse\n\n#### [/AuthZPlugin.AuthZRes](#authzpluginauthzres)\n\nRequest:\n\nResponse:\n\n### [Request authorization](#request-authorization)\n\nEach plugin must support two request authorization messages formats, one from the daemon to the plugin and then from the plugin to the daemon. The tables below detail the content expected in each message.\n\n#### [Daemon -> Plugin](#daemon---plugin)\n\n| Name | Type | Description |\n| --- | --- | --- |\n| User | string | The user identification |\n| Authentication method | string | The authentication method used |\n| Request method | enum | The HTTP method (GET/DELETE/POST) |\n| Request URI | string | The HTTP request URI including API version (e.g., v.1.17/containers/json) |\n| Request headers | map\\[string\\]string | Request headers as key value pairs (without the authorization header) |\n| Request body | \\[\\]byte | Raw request body |\n\n#### [Plugin -> Daemon](#plugin---daemon)\n\n| Name | Type | Description |\n| --- | --- | --- |\n| Allow | bool | Boolean value indicating whether the request is allowed or denied |\n| Msg | string | Authorization message (will be returned to the client in case the access is denied) |\n| Err | string | Error message (will be returned to the client in case the plugin encounter an error. The string value supplied may appear in logs, so should not include confidential information) |\n\n### [Response authorization](#response-authorization)\n\nThe plugin must support two authorization messages formats, one from the daemon to the plugin and then from the plugin to the daemon. The tables below detail the content expected in each message.\n\n#### [Daemon -> Plugin](#daemon---plugin-1)\n\n| Name | Type | Description |\n| --- | --- | --- |\n| User | string | The user identification |\n| Authentication method | string | The authentication method used |\n| Request method | string | The HTTP method (GET/DELETE/POST) |\n| Request URI | string | The HTTP request URI including API version (e.g., v.1.17/containers/json) |\n| Request headers | map\\[string\\]string | Request headers as key value pairs (without the authorization header) |\n| Request body | \\[\\]byte | Raw request body |\n| Response status code | int | Status code from the Docker daemon |\n| Response headers | map\\[string\\]string | Response headers as key value pairs |\n| Response body | \\[\\]byte | Raw Docker daemon response body |\n\n#### [Plugin -> Daemon](#plugin---daemon-1)\n\n| Name | Type | Description |\n| --- | --- | --- |\n| Allow | bool | Boolean value indicating whether the response is allowed or denied |\n| Msg | string | Authorization message (will be returned to the client in case the access is denied) |\n| Err | string | Error message (will be returned to the client in case the plugin encounter an error. The string value supplied may appear in logs, so should not include confidential information) |",
  "title": "Access authorization plugin | Docker Docs\n",
  "description": "How to create authorization plugins to manage access control to your Docker daemon.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/",
  "markdown": "# Swarm mode overview | Docker Docs\n\n> **Note**\n> \n> Swarm mode is an advanced feature for managing a cluster of Docker daemons.\n> \n> Use Swarm mode if you intend to use Swarm as a production runtime environment.\n> \n> If you're not planning on deploying with Swarm, use [Docker Compose](https://docs.docker.com/compose/) instead. If you're developing for a Kubernetes deployment, consider using the [integrated Kubernetes feature](https://docs.docker.com/desktop/kubernetes/) in Docker Desktop.\n\nCurrent versions of Docker include Swarm mode for natively managing a cluster of Docker Engines called a swarm. Use the Docker CLI to create a swarm, deploy application services to a swarm, and manage swarm behavior.\n\nDocker Swarm mode is built into the Docker Engine. Do not confuse Docker Swarm mode with [Docker Classic Swarm](https://github.com/docker/classicswarm) which is no longer actively developed.\n\n### [Cluster management integrated with Docker Engine](#cluster-management-integrated-with-docker-engine)\n\nUse the Docker Engine CLI to create a swarm of Docker Engines where you can deploy application services. You don't need additional orchestration software to create or manage a swarm.\n\n### [Decentralized design](#decentralized-design)\n\nInstead of handling differentiation between node roles at deployment time, the Docker Engine handles any specialization at runtime. You can deploy both kinds of nodes, managers and workers, using the Docker Engine. This means you can build an entire swarm from a single disk image.\n\n### [Declarative service model](#declarative-service-model)\n\nDocker Engine uses a declarative approach to let you define the desired state of the various services in your application stack. For example, you might describe an application comprised of a web front end service with message queueing services and a database backend.\n\n### [Scaling](#scaling)\n\nFor each service, you can declare the number of tasks you want to run. When you scale up or down, the swarm manager automatically adapts by adding or removing tasks to maintain the desired state.\n\n### [Desired state reconciliation](#desired-state-reconciliation)\n\nThe swarm manager node constantly monitors the cluster state and reconciles any differences between the actual state and your expressed desired state. For example, if you set up a service to run 10 replicas of a container, and a worker machine hosting two of those replicas crashes, the manager creates two new replicas to replace the replicas that crashed. The swarm manager assigns the new replicas to workers that are running and available.\n\n### [Multi-host networking](#multi-host-networking)\n\nYou can specify an overlay network for your services. The swarm manager automatically assigns addresses to the containers on the overlay network when it initializes or updates the application.\n\n### [Service discovery](#service-discovery)\n\nSwarm manager nodes assign each service in the swarm a unique DNS name and load balance running containers. You can query every container running in the swarm through a DNS server embedded in the swarm.\n\n### [Load balancing](#load-balancing)\n\nYou can expose the ports for services to an external load balancer. Internally, the swarm lets you specify how to distribute service containers between nodes.\n\n### [Secure by default](#secure-by-default)\n\nEach node in the swarm enforces TLS mutual authentication and encryption to secure communications between itself and all other nodes. You have the option to use self-signed root certificates or certificates from a custom root CA.\n\n### [Rolling updates](#rolling-updates)\n\nAt rollout time you can apply service updates to nodes incrementally. The swarm manager lets you control the delay between service deployment to different sets of nodes. If anything goes wrong, you can roll back to a previous version of the service.\n\n*   Learn Swarm mode [key concepts](https://docs.docker.com/engine/swarm/key-concepts/).\n*   Get started with the [Swarm mode tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/).\n*   Explore Swarm mode CLI commands\n    *   [swarm init](https://docs.docker.com/reference/cli/docker/swarm/init/)\n    *   [swarm join](https://docs.docker.com/reference/cli/docker/swarm/join/)\n    *   [service create](https://docs.docker.com/reference/cli/docker/service/create/)\n    *   [service inspect](https://docs.docker.com/reference/cli/docker/service/inspect/)\n    *   [service ls](https://docs.docker.com/reference/cli/docker/service/ls/)\n    *   [service rm](https://docs.docker.com/reference/cli/docker/service/rm/)\n    *   [service scale](https://docs.docker.com/reference/cli/docker/service/scale/)\n    *   [service ps](https://docs.docker.com/reference/cli/docker/service/ps/)\n    *   [service update](https://docs.docker.com/reference/cli/docker/service/update/)",
  "title": "Swarm mode overview | Docker Docs\n",
  "description": "Docker Engine Swarm mode overview",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/drivers/",
  "markdown": "# Build drivers | Docker Docs\n\nBuild drivers are configurations for how and where the BuildKit backend runs. Driver settings are customizable and allows fine-grained control of the builder. Buildx supports the following drivers:\n\n*   `docker`: uses the BuildKit library bundled into the Docker daemon.\n*   `docker-container`: creates a dedicated BuildKit container using Docker.\n*   `kubernetes`: creates BuildKit pods in a Kubernetes cluster.\n*   `remote`: connects directly to a manually managed BuildKit daemon.\n\nDifferent drivers support different use cases. The default `docker` driver prioritizes simplicity and ease of use. It has limited support for advanced features like caching and output formats, and isn't configurable. Other drivers provide more flexibility and are better at handling advanced scenarios.\n\nThe following table outlines some differences between drivers.\n\n| Feature | `docker` | `docker-container` | `kubernetes` | `remote` |\n| --- | --- | --- | --- | --- |\n| **Automatically load image** | âœ…   |     |     |     |\n| **Cache export** | âœ“\\* | âœ…   | âœ…   | âœ…   |\n| **Tarball output** |     | âœ…   | âœ…   | âœ…   |\n| **Multi-arch images** |     | âœ…   | âœ…   | âœ…   |\n| **BuildKit configuration** |     | âœ…   | âœ…   | Managed externally |\n\n\\* _The `docker` driver doesn't support all cache export options. See [Cache storage backends](https://docs.docker.com/build/cache/backends/) for more information._\n\nUnlike when using the default `docker` driver, images built using other drivers aren't automatically loaded into the local image store. If you don't specify an output, the build result is exported to the build cache only.\n\nTo build an image using a non-default driver and load it to the image store, use the `--load` flag with the build command:\n\nWith this option, the image is available in the image store after the build finishes:\n\n### [Load by default](#load-by-default)\n\nIntroduced in Buildx version 0.14.0\n\nYou can configure the custom build drivers to behave in a similar way to the default `docker` driver, and load images to the local image store by default. To do so, set the `default-load` driver option when creating the builder:\n\nNote that, just like with the `docker` driver, if you specify a different output format with `--output`, the result will not be loaded to the image store unless you also explicitly specify `--output type=docker` or use the `--load` flag.\n\nRead about each driver:\n\n*   [Docker driver](https://docs.docker.com/build/drivers/docker/)\n*   [Docker container driver](https://docs.docker.com/build/drivers/docker-container/)\n*   [Kubernetes driver](https://docs.docker.com/build/drivers/kubernetes/)\n*   [Remote driver](https://docs.docker.com/build/drivers/remote/)",
  "title": "Build drivers | Docker Docs\n",
  "description": "Build drivers are configurations for how and where the BuildKit backend runs.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/drivers/docker/",
  "markdown": "# Docker driver | Docker Docs\n\nThe Buildx Docker driver is the default driver. It uses the BuildKit server components built directly into the Docker engine. The Docker driver requires no configuration.\n\nUnlike the other drivers, builders using the Docker driver can't be manually created. They're only created automatically from the Docker context.\n\nImages built with the Docker driver are automatically loaded to the local image store.\n\nIt's not possible to configure which BuildKit version to use, or to pass any additional BuildKit parameters to a builder using the Docker driver. The BuildKit version and parameters are preset by the Docker engine internally.\n\nIf you need additional configuration and flexibility, consider using the [Docker container driver](https://docs.docker.com/build/drivers/docker-container/).\n\nFor more information on the Docker driver, see the [buildx reference](https://docs.docker.com/reference/cli/docker/buildx/create/#driver).",
  "title": "Docker driver | Docker Docs\n",
  "description": "The Docker driver is the default driver. It uses the BuildKit bundled with the Docker Engine. ",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/key-concepts/",
  "markdown": "# Swarm mode key concepts | Docker Docs\n\nThis topic introduces some of the concepts unique to the cluster management and orchestration features of Docker Engine 1.12.\n\nThe cluster management and orchestration features embedded in Docker Engine are built using [swarmkit](https://github.com/docker/swarmkit/). Swarmkit is a separate project which implements Docker's orchestration layer and is used directly within Docker.\n\nA swarm consists of multiple Docker hosts which run in Swarm mode and act as managers, to manage membership and delegation, and workers, which run [swarm services](#services-and-tasks). A given Docker host can be a manager, a worker, or perform both roles. When you create a service, you define its optimal state - number of replicas, network and storage resources available to it, ports the service exposes to the outside world, and more. Docker works to maintain that desired state. For instance, if a worker node becomes unavailable, Docker schedules that node's tasks on other nodes. A task is a running container which is part of a swarm service and is managed by a swarm manager, as opposed to a standalone container.\n\nOne of the key advantages of swarm services over standalone containers is that you can modify a service's configuration, including the networks and volumes it is connected to, without the need to manually restart the service. Docker will update the configuration, stop the service tasks with out of date configuration, and create new ones matching the desired configuration.\n\nWhen Docker is running in Swarm mode, you can still run standalone containers on any of the Docker hosts participating in the swarm, as well as swarm services. A key difference between standalone containers and swarm services is that only swarm managers can manage a swarm, while standalone containers can be started on any daemon. Docker daemons can participate in a swarm as managers, workers, or both.\n\nIn the same way that you can use [Docker Compose](https://docs.docker.com/compose/) to define and run containers, you can define and run [Swarm service](https://docs.docker.com/engine/swarm/services/) stacks.\n\nKeep reading for details about concepts related to Docker swarm services, including nodes, services, tasks, and load balancing.\n\nA node is an instance of the Docker engine participating in the swarm. You can also think of this as a Docker node. You can run one or more nodes on a single physical computer or cloud server, but production swarm deployments typically include Docker nodes distributed across multiple physical and cloud machines.\n\nTo deploy your application to a swarm, you submit a service definition to a manager node\\*. The manager node dispatches units of work called [tasks](#services-and-tasks) to worker nodes.\n\nManager nodes also perform the orchestration and cluster management functions required to maintain the desired state of the swarm. Manager nodes elect a single leader to conduct orchestration tasks.\n\nWorker nodes receive and execute tasks dispatched from manager nodes. By default manager nodes also run services as worker nodes, but you can configure them to run manager tasks exclusively and be manager-only nodes. An agent runs on each worker node and reports on the tasks assigned to it. The worker node notifies the manager node of the current state of its assigned tasks so that the manager can maintain the desired state of each worker.\n\nA service is the definition of the tasks to execute on the manager or worker nodes. It is the central structure of the swarm system and the primary root of user interaction with the swarm.\n\nWhen you create a service, you specify which container image to use and which commands to execute inside running containers.\n\nIn the replicated services model, the swarm manager distributes a specific number of replica tasks among the nodes based upon the scale you set in the desired state.\n\nFor global services, the swarm runs one task for the service on every available node in the cluster.\n\nA task carries a Docker container and the commands to run inside the container. It is the atomic scheduling unit of swarm. Manager nodes assign tasks to worker nodes according to the number of replicas set in the service scale. Once a task is assigned to a node, it cannot move to another node. It can only run on the assigned node or fail.\n\nThe swarm manager uses ingress load balancing to expose the services you want to make available externally to the swarm. The swarm manager can automatically assign the service a published port or you can configure a published port for the service. You can specify any unused port. If you do not specify a port, the swarm manager assigns the service a port in the 30000-32767 range.\n\nExternal components, such as cloud load balancers, can access the service on the published port of any node in the cluster whether or not the node is currently running the task for the service. All nodes in the swarm route ingress connections to a running task instance.\n\nSwarm mode has an internal DNS component that automatically assigns each service in the swarm a DNS entry. The swarm manager uses internal load balancing to distribute requests among services within the cluster based upon the DNS name of the service.\n\n*   Read the [Swarm mode overview](https://docs.docker.com/engine/swarm/).\n*   Get started with the [Swarm mode tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/).",
  "title": "Swarm mode key concepts | Docker Docs\n",
  "description": "Introducing key concepts for Docker Engine swarm mode",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/26.0/",
  "markdown": "# Docker Engine 26.0 release notes\n\nThis page describes the latest changes, additions, known issues, and fixes for Docker Engine version 26.0.\n\nFor more information about:\n\n*   Deprecated and removed features, see [Deprecated Engine Features](https://docs.docker.com/engine/deprecated/).\n*   Changes to the Engine API, see [Engine API version history](https://docs.docker.com/engine/api/version-history/).\n\n_2024-04-18_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 26.0.2 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A26.0.2)\n*   [moby/moby, 26.0.2 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A26.0.2)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v26.0.2/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v26.0.2/docs/api/version-history.md).\n\n### [Security](#security)\n\nThis release contains a security fix for [CVE-2024-32473](https://github.com/moby/moby/security/advisories/GHSA-x84c-p2g9-rqv9), an unexpected configuration of IPv6 on IPv4-only interfaces.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements)\n\n*   [CVE-2024-32473](https://github.com/moby/moby/security/advisories/GHSA-x84c-p2g9-rqv9): Ensure IPv6 is disabled on interfaces only allocated an IPv4 address by the engine. [moby#GHSA-x84c-p2g9-rqv9](https://github.com/moby/moby/security/advisories/GHSA-x84c-p2g9-rqv9)\n    \n\n_2024-04-11_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 26.0.1 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A26.0.1)\n*   [moby/moby, 26.0.1 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A26.0.1)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v26.0.1/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v26.0.1/docs/api/version-history.md).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-1)\n\n*   Fix a regression that meant network interface specific `--sysctl` options prevented container startup. [moby/moby#47646](https://github.com/moby/moby/pull/47646)\n*   Remove erroneous `platform` from image `config` OCI descriptor in `docker save` output. [moby/moby#47694](https://github.com/moby/moby/pull/47694)\n*   containerd image store: OCI archives produced by `docker save` will now have a non-empty `mediaType` field in `index.json` [moby/moby#47701](https://github.com/moby/moby/pull/47701)\n*   Fix a regression that prevented the internal resolver from forwarding requests from IPvlan L3 networks to external resolvers. [moby/moby#47705](https://github.com/moby/moby/pull/47705)\n*   Prevent the use of external resolvers in IPvlan and Macvlan networks created with no parent interface specified. [moby/moby#47705](https://github.com/moby/moby/pull/47705)\n\n### [Packaging updates](#packaging-updates)\n\n*   Update Go runtime to 1.21.9 [moby/moby#47671](https://github.com/moby/moby/pull/47671), [docker/cli#4987](https://github.com/docker/cli/pull/4987)\n*   Update Compose to [v1.26.1](https://github.com/docker/compose/releases/tag/v2.26.1) , [docker/docker-ce-packaging#1009](https://github.com/docker/docker-ce-packaging/pull/1009)\n*   Update containerd to [v1.7.15](https://github.com/containerd/containerd/releases/tag/v1.7.15) (static binaries only) [moby/moby#47692](https://github.com/moby/moby/pull/47692)\n\n_2024-03-20_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 26.0.0 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A26.0.0)\n*   [moby/moby, 26.0.0 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A26.0.0)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v26.0.0/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v26.0.0/docs/api/version-history.md).\n\n### [Security](#security-1)\n\nThis release contains a security fix for [CVE-2024-29018](https://github.com/moby/moby/security/advisories/GHSA-mq39-4gv4-mvpx), a potential data exfiltration from 'internal' networks via authoritative DNS servers.\n\n### [New](#new)\n\n*   Add `Subpath` field to the `VolumeOptions` making it possible to mount a subpath of a volume. [moby/moby#45687](https://github.com/moby/moby/pull/45687)\n*   Add `volume-subpath` support to the mount flag (`--mount type=volume,...,volume-subpath=<subpath>`). [docker/cli#4331](https://github.com/docker/cli/pull/4331)\n*   Accept `=` separators and `[ipv6]` in compose files for `docker stack deploy`. [docker/cli#4860](https://github.com/docker/cli/pull/4860)\n*   rootless: Add support for enabling host loopback by setting the `DOCKERD_ROOTLESS_ROOTLESSKIT_DISABLE_HOST_LOOPBACK` environment variable to `false` (defaults to `true`). This lets containers connect to the host by using IP address `10.0.2.2`. [moby/moby#47352](https://github.com/moby/moby/pull/47352)\n*   containerd image store: `docker image ls` no longer creates duplicates entries for multi-platform images. [moby/moby#45967](https://github.com/moby/moby/pull/45967)\n*   containerd image store: Send Prometheus metrics. [moby/moby#47555](https://github.com/moby/moby/pull/47555)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-2)\n\n*   [CVE-2024-29018](https://github.com/moby/moby/security/advisories/GHSA-mq39-4gv4-mvpx): Do not forward requests to external DNS servers for a container that is only connected to an 'internal' network. Previously, requests were forwarded if the host's DNS server was running on a loopback address, like systemd's 127.0.0.53. [moby/moby#47589](https://github.com/moby/moby/pull/47589)\n    \n*   Ensure that a generated MAC address is not restored when a container is restarted, but a configured MAC address is preserved. [moby/moby#47233](https://github.com/moby/moby/pull/47233)\n    \n    > **Warning**\n    > \n    > Containers created using Docker Engine 25.0.0 may have duplicate MAC addresses, they must be re-created. Containers created using version 25.0.0 or 25.0.1 with user-defined MAC addresses will get generated MAC addresses when they are started using 25.0.2. They must also be re-created.\n    \n*   Always attempt to enable IPv6 on a container's loopback interface, and only include IPv6 in `/etc/hosts` if successful. [moby/moby#47062](https://github.com/moby/moby/pull/47062)\n    \n    > **Note**\n    > \n    > By default, IPv6 will remain enabled on a container's loopback interface when the container is not connected to an IPv6-enabled network. For example, containers that are only connected to an IPv4-only network now have the `::1` address on their loopback interface.\n    > \n    > To disable IPv6 in a container, use option `--sysctl net.ipv6.conf.all.disable_ipv6=1` in the `create` or `run` command, or the equivalent `sysctls` option in the service configuration section of a Compose file.\n    > \n    > If IPv6 is not available in a container because it has been explicitly disabled for the container, or the host's networking stack does not have IPv6 enabled (or for any other reason) the container's `/etc/hosts` file will not include IPv6 entries.\n    \n*   Fix `ADD` Dockerfile instruction failing with `lsetxattr <file>: operation not supported` when unpacking archive with xattrs onto a filesystem that doesn't support them. [moby/moby#47175](https://github.com/moby/moby/pull/47175)\n    \n*   Fix `docker container start` failing when used with `--checkpoint`. [moby/moby#47456](https://github.com/moby/moby/pull/47456)\n    \n*   Restore IP connectivity between the host and containers on an internal bridge network. [moby/moby#47356](https://github.com/moby/moby/pull/47356)\n    \n*   Do not enforce new validation rules for existing swarm networks. [moby/moby#47361](https://github.com/moby/moby/pull/47361)\n    \n*   Restore DNS names for containers in the default \"nat\" network on Windows. [moby/moby#47375](https://github.com/moby/moby/pull/47375)\n    \n*   Print hint when invoking `docker image ls` with ambiguous argument. [docker/cli#4849](https://github.com/docker/cli/pull/4849)\n    \n*   Cleanup `@docker_cli_[UUID]` files on OpenBSD. [docker/cli#4862](https://github.com/docker/cli/pull/4862)\n    \n*   Add explicit [deprecation notice](https://github.com/docker/cli/blob/v26.0.0/docs/deprecated.md#unauthenticated-tcp-connections) message when using remote TCP connections without TLS. [docker/cli#4928](https://github.com/docker/cli/pull/4928), [moby/moby#47556](https://github.com/moby/moby/pull/47556)\n    \n*   Use IPv6 nameservers from the host's `resolv.conf` as upstream resolvers for Docker Engine's internal DNS, rather than listing them in the container's `resolv.conf`. [moby/moby#47512](https://github.com/moby/moby/pull/47512)\n    \n*   containerd image store: Isolate images with different containerd namespaces when `--userns-remap` option is used. [moby/moby#46786](https://github.com/moby/moby/pull/46786)\n    \n*   containerd image store: Fix image pull not emitting `Pulling fs layer` status. [moby/moby#47432](https://github.com/moby/moby/pull/47432)\n    \n\n### [API](#api)\n\n*   To preserve backwards compatibility, read-only mounts are not recursive by default when using older clients (API version < v1.44). [moby/moby#47391](https://github.com/moby/moby/pull/47391)\n*   `GET /images/{id}/json` omits the `Created` field (previously it was `0001-01-01T00:00:00Z`) if the `Created` field is missing from the image config. [moby/moby#47451](https://github.com/moby/moby/pull/47451)\n*   Populate a missing `Created` field in `GET /images/{id}/json` with `0001-01-01T00:00:00Z` for API version <= 1.43. [moby/moby#47387](https://github.com/moby/moby/pull/47387)\n*   The `is_automated` field in the `POST /images/search` endpoint results is always `false` now. Consequently, searching for `is-automated=true` will yield no results, while `is-automated=false` will be a no-op. [moby/moby#47465](https://github.com/moby/moby/pull/47465)\n*   Remove `Container` and `ContainerConfig` fields from the `GET /images/{name}/json` response. [moby/moby#47430](https://github.com/moby/moby/pull/47430)\n\n### [Packaging updates](#packaging-updates-1)\n\n*   Update BuildKit to [v0.13.1](https://github.com/moby/buildkit/releases/tag/v0.13.1). [moby/moby#47582](https://github.com/moby/moby/pull/47582)\n*   Update Buildx to [v0.13.1](https://github.com/docker/buildx/releases/tag/v0.13.1). [docker/docker-ce-packaging#1000](https://github.com/docker/docker-ce-packaging/pull/1000)\n*   Update Compose to [v2.25.0](https://github.com/docker/compose/releases/tag/v2.25.0). [docker/docker-ce-packaging#1002](https://github.com/docker/docker-ce-packaging/pull/1002)\n*   Update Go runtime to [1.21.8](https://go.dev/doc/devel/release#go1.21.8). [moby/moby#47502](https://github.com/moby/moby/pull/47502)\n*   Update RootlessKit to [v2.0.2](https://github.com/rootless-containers/rootlesskit/releases/tag/v2.0.2). [moby/moby#47508](https://github.com/moby/moby/pull/47504)\n*   Update containerd to v1.7.13 (static binaries only) [moby/moby#47278](https://github.com/moby/moby/pull/47278)\n*   Update runc binary to v1.1.12 [moby/moby#47268](https://github.com/moby/moby/pull/47268)\n*   Update OTel to v0.46.1 / v1.21.0 [moby/moby#47245](https://github.com/moby/moby/pull/47245)\n\n### [Removed](#removed)\n\n*   Remove `Container` and `ContainerConfig` fields from the `GET /images/{name}/json` response. [moby/moby#47430](https://github.com/moby/moby/pull/47430)\n    \n*   Deprecate the ability to accept remote TCP connections without TLS. [Deprecation notice](https://github.com/docker/cli/tree/v26.0.0/deprecation.md#unauthenticated-tcp-connections) [docker/cli#4928](https://github.com/docker/cli/pull/4928) [moby/moby#47556](https://github.com/moby/moby/pull/47556).\n    \n*   Remove deprecated API versions (API < v1.24) [moby/moby#47155](https://github.com/moby/moby/pull/47155)\n    \n*   Disable pulling of deprecated image formats by default. These image formats are deprecated, and support will be removed in a future version. [moby/moby#47459](https://github.com/moby/moby/pull/47459)\n    \n*   image: remove deprecated IDFromDigest [moby/moby#47198](https://github.com/moby/moby/pull/47198)\n    \n*   Remove the deprecated `github.com/docker/docker/pkg/loopback` package. [moby/moby#47128](https://github.com/moby/moby/pull/47128)\n    \n*   pkg/system: remove deprecated `ErrNotSupportedOperatingSystem`, `IsOSSupported` [moby/moby#47129](https://github.com/moby/moby/pull/47129)\n    \n*   pkg/homedir: remove deprecated Key() and GetShortcutString() [moby/moby#47130](https://github.com/moby/moby/pull/47130)\n    \n*   pkg/containerfs: remove deprecated ResolveScopedPath [moby/moby#47131](https://github.com/moby/moby/pull/47131)\n    \n*   The daemon flag `--oom-score-adjust` was deprecated in v24.0 and is now removed. [moby/moby#46113](https://github.com/moby/moby/pull/46113)\n    \n*   Remove deprecated aliases from the api/types package. These types were deprecated in v25.0.0, which provided temporary aliases. [moby/moby#47148](https://github.com/moby/moby/pull/47148) These aliases are now removed: `types.Info`, `types.Commit`, `types.PluginsInfo`, `types.NetworkAddressPool`, `types.Runtime`, `types.SecurityOpt`, `types.KeyValue`, `types.DecodeSecurityOptions`, `types.CheckpointCreateOptions`, `types.CheckpointListOptions`, `types.CheckpointDeleteOptions`, `types.Checkpoint`, `types.ImageDeleteResponseItem`, `types.ImageSummary`, `types.ImageMetadata`, `types.ServiceUpdateResponse`, `types.ServiceCreateResponse`, `types.ResizeOptions`, `types.ContainerAttachOptions`, `types.ContainerCommitOptions`, `types.ContainerRemoveOptions`, `types.ContainerStartOptions`, `types.ContainerListOptions`, `types.ContainerLogsOptions`\n    \n*   cli/command/container: remove deprecated `NewStartOptions()` [docker/cli#4811](https://github.com/docker/cli/pull/4811)\n    \n*   cli/command: remove deprecated `DockerCliOption`, `InitializeOpt` [docker/cli#4810](https://github.com/docker/cli/pull/4810)",
  "title": "Docker Engine 26.0 release notes | Docker Docs\n",
  "description": "Learn about the new features, bug fixes, and breaking changes for Docker Engine",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/extend/legacy_plugins/",
  "markdown": "# Use Docker Engine plugins | Docker Docs\n\nThis document describes the Docker Engine plugins generally available in Docker Engine. To view information on plugins managed by Docker, refer to [Docker Engine plugin system](https://docs.docker.com/engine/extend/).\n\nYou can extend the capabilities of the Docker Engine by loading third-party plugins. This page explains the types of plugins and provides links to several volume and network plugins for Docker.\n\nPlugins extend Docker's functionality. They come in specific types. For example, a [volume plugin](https://docs.docker.com/engine/extend/plugins_volume/) might enable Docker volumes to persist across multiple Docker hosts and a [network plugin](https://docs.docker.com/engine/extend/plugins_network/) might provide network plumbing.\n\nCurrently Docker supports authorization, volume and network driver plugins. In the future it will support additional plugin types.\n\nFollow the instructions in the plugin's documentation.\n\nThe sections below provide an overview of available third-party plugins.\n\n### [Network plugins](#network-plugins)\n\n| Plugin | Description |\n| --- | --- |\n| [Contiv Networking](https://github.com/contiv/netplugin) | An open source network plugin to provide infrastructure and security policies for a multi-tenant micro services deployment, while providing an integration to physical network for non-container workload. Contiv Networking implements the remote driver and IPAM APIs available in Docker 1.9 onwards. |\n| [Kuryr Network Plugin](https://github.com/openstack/kuryr) | A network plugin is developed as part of the OpenStack Kuryr project and implements the Docker networking (libnetwork) remote driver API by utilizing Neutron, the OpenStack networking service. It includes an IPAM driver as well. |\n| [KatharÃ¡ Network Plugin](https://github.com/KatharaFramework/NetworkPlugin) | Docker Network Plugin used by KatharÃ¡, an open source container-based network emulation system for showing interactive demos/lessons, testing production networks in a sandbox environment, or developing new network protocols. |\n\n### [Volume plugins](#volume-plugins)\n\n| Plugin | Description |\n| --- | --- |\n| [Azure File Storage plugin](https://github.com/Azure/azurefile-dockervolumedriver) | Lets you mount Microsoft [Azure File Storage](https://azure.microsoft.com/blog/azure-file-storage-now-generally-available/) shares to Docker containers as volumes using the SMB 3.0 protocol. [Learn more](https://azure.microsoft.com/blog/persistent-docker-volumes-with-azure-file-storage/). |\n| [BeeGFS Volume Plugin](https://github.com/RedCoolBeans/docker-volume-beegfs) | An open source volume plugin to create persistent volumes in a BeeGFS parallel file system. |\n| [Blockbridge plugin](https://github.com/blockbridge/blockbridge-docker-volume) | A volume plugin that provides access to an extensible set of container-based persistent storage options. It supports single and multi-host Docker environments with features that include tenant isolation, automated provisioning, encryption, secure deletion, snapshots and QoS. |\n| [Contiv Volume Plugin](https://github.com/contiv/volplugin) | An open source volume plugin that provides multi-tenant, persistent, distributed storage with intent based consumption. It has support for Ceph and NFS. |\n| [Convoy plugin](https://github.com/rancher/convoy) | A volume plugin for a variety of storage back-ends including device mapper and NFS. It's a simple standalone executable written in Go and provides the framework to support vendor-specific extensions such as snapshots, backups and restore. |\n| [DigitalOcean Block Storage plugin](https://github.com/omallo/docker-volume-plugin-dostorage) | Integrates DigitalOcean's [block storage solution](https://www.digitalocean.com/products/storage/) into the Docker ecosystem by automatically attaching a given block storage volume to a DigitalOcean droplet and making the contents of the volume available to Docker containers running on that droplet. |\n| [DRBD plugin](https://www.drbd.org/en/supported-projects/docker) | A volume plugin that provides highly available storage replicated by [DRBD](https://www.drbd.org/). Data written to the docker volume is replicated in a cluster of DRBD nodes. |\n| [Flocker plugin](https://github.com/ScatterHQ/flocker) | A volume plugin that provides multi-host portable volumes for Docker, enabling you to run databases and other stateful containers and move them around across a cluster of machines. |\n| [Fuxi Volume Plugin](https://github.com/openstack/fuxi) | A volume plugin that is developed as part of the OpenStack Kuryr project and implements the Docker volume plugin API by utilizing Cinder, the OpenStack block storage service. |\n| [gce-docker plugin](https://github.com/mcuadros/gce-docker) | A volume plugin able to attach, format and mount Google Compute [persistent-disks](https://cloud.google.com/compute/docs/disks/persistent-disks). |\n| [GlusterFS plugin](https://github.com/calavera/docker-volume-glusterfs) | A volume plugin that provides multi-host volumes management for Docker using GlusterFS. |\n| [Horcrux Volume Plugin](https://github.com/muthu-r/horcrux) | A volume plugin that allows on-demand, version controlled access to your data. Horcrux is an open-source plugin, written in Go, and supports SCP, [Minio](https://www.minio.io/) and Amazon S3. |\n| [HPE 3Par Volume Plugin](https://github.com/hpe-storage/python-hpedockerplugin/) | A volume plugin that supports HPE 3Par and StoreVirtual iSCSI storage arrays. |\n| [Infinit volume plugin](https://infinit.sh/documentation/docker/volume-plugin) | A volume plugin that makes it easy to mount and manage Infinit volumes using Docker. |\n| [IPFS Volume Plugin](https://github.com/vdemeester/docker-volume-ipfs) | An open source volume plugin that allows using an [ipfs](https://ipfs.io/) filesystem as a volume. |\n| [Keywhiz plugin](https://github.com/calavera/docker-volume-keywhiz) | A plugin that provides credentials and secret management using Keywhiz as a central repository. |\n| [Linode Volume Plugin](https://github.com/linode/docker-volume-linode) | A plugin that adds the ability to manage Linode Block Storage as Docker Volumes from within a Linode. |\n| [Local Persist Plugin](https://github.com/CWSpear/local-persist) | A volume plugin that extends the default `local` driver's functionality by allowing you specify a mountpoint anywhere on the host, which enables the files to _always persist_, even if the volume is removed via `docker volume rm`. |\n| [NetApp Plugin](https://github.com/NetApp/netappdvp) (nDVP) | A volume plugin that provides direct integration with the Docker ecosystem for the NetApp storage portfolio. The nDVP package supports the provisioning and management of storage resources from the storage platform to Docker hosts, with a robust framework for adding additional platforms in the future. |\n| [Netshare plugin](https://github.com/ContainX/docker-volume-netshare) | A volume plugin that provides volume management for NFS 3/4, AWS EFS and CIFS file systems. |\n| [Nimble Storage Volume Plugin](https://scod.hpedev.io/docker_volume_plugins/hpe_nimble_storage/index.html) | A volume plug-in that integrates with Nimble Storage Unified Flash Fabric arrays. The plug-in abstracts array volume capabilities to the Docker administrator to allow self-provisioning of secure multi-tenant volumes and clones. |\n| [OpenStorage Plugin](https://github.com/libopenstorage/openstorage) | A cluster-aware volume plugin that provides volume management for file and block storage solutions. It implements a vendor neutral specification for implementing extensions such as CoS, encryption, and snapshots. It has example drivers based on FUSE, NFS, NBD and EBS to name a few. |\n| [Portworx Volume Plugin](https://github.com/portworx/px-dev) | A volume plugin that turns any server into a scale-out converged compute/storage node, providing container granular storage and highly available volumes across any node, using a shared-nothing storage backend that works with any docker scheduler. |\n| [Quobyte Volume Plugin](https://github.com/quobyte/docker-volume) | A volume plugin that connects Docker to [Quobyte](https://www.quobyte.com/containers)'s data center file system, a general-purpose scalable and fault-tolerant storage platform. |\n| [REX-Ray plugin](https://github.com/emccode/rexray) | A volume plugin which is written in Go and provides advanced storage functionality for many platforms including VirtualBox, EC2, Google Compute Engine, OpenStack, and EMC. |\n| [Virtuozzo Storage and Ploop plugin](https://github.com/virtuozzo/docker-volume-ploop) | A volume plugin with support for Virtuozzo Storage distributed cloud file system as well as ploop devices. |\n| [VMware vSphere Storage Plugin](https://github.com/vmware/docker-volume-vsphere) | Docker Volume Driver for vSphere enables customers to address persistent storage requirements for Docker containers in vSphere environments. |\n\n| Plugin | Description |\n| --- | --- |\n| [Casbin AuthZ Plugin](https://github.com/casbin/casbin-authz-plugin) | An authorization plugin based on [Casbin](https://github.com/casbin/casbin), which supports access control models like ACL, RBAC, ABAC. The access control model can be customized. The policy can be persisted into file or DB. |\n| [HBM plugin](https://github.com/kassisol/hbm) | An authorization plugin that prevents from executing commands with certains parameters. |\n| [Twistlock AuthZ Broker](https://github.com/twistlock/authz) | A basic extendable authorization plugin that runs directly on the host or inside a container. This plugin allows you to define user policies that it evaluates during authorization. Basic authorization is provided if Docker daemon is started with the --tlsverify flag (username is extracted from the certificate common name). |\n\nIf you are having problems with Docker after loading a plugin, ask the authors of the plugin for help. The Docker team may not be able to assist you.\n\nIf you are interested in writing a plugin for Docker, or seeing how they work under the hood, see the [Docker plugins reference](https://docs.docker.com/engine/extend/plugin_api/).",
  "title": "Use Docker Engine plugins | Docker Docs\n",
  "description": "How to add additional functionality to Docker with plugins extensions",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/26.1/",
  "markdown": "# Docker Engine 26.1 release notes\n\nThis page describes the latest changes, additions, known issues, and fixes for Docker Engine version 26.1.\n\nFor more information about:\n\n*   Deprecated and removed features, see [Deprecated Engine Features](https://docs.docker.com/engine/deprecated/).\n*   Changes to the Engine API, see [Engine API version history](https://docs.docker.com/engine/api/version-history/).\n\n_2024-06-05_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 26.1.4 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A26.1.4)\n*   [moby/moby, 26.1.4 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A26.1.4)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v26.1.4/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v26.1.4/docs/api/version-history.md).\n\n### [Security](#security)\n\nThis release updates the Go runtime to 1.21.11 which contains security fixes for:\n\n*   [CVE-2024-24789](https://github.com/golang/go/issues/66869)\n*   [CVE-2024-24790](https://github.com/golang/go/issues/67680)\n*   A symlink time of check to time of use race condition during directory removal reported by [Addison Crump](https://github.com/addisoncrump).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements)\n\n*   Fixed an issue where promoting a node immediately after another node was demoted could cause the promotion to fail. [moby/moby#47870](https://github.com/moby/moby/pull/47870)\n*   Prevent the daemon log from being spammed with `superfluous response.WriteHeader call ...` messages. [moby/moby#47843](https://github.com/moby/moby/pull/47843)\n*   Don't show empty hints when plugins return an empty hook message. [docker/cli#5083](https://github.com/docker/cli/pull/5083)\n*   Fix a compatibility issue with Visual Studio Container Tools. [docker/cli#5095](https://github.com/docker/cli/pull/5095)\n\n### [Packaging updates](#packaging-updates)\n\n*   Update containerd (static binaries only) to [v1.7.17](https://github.com/containerd/containerd/releases/tag/v1.7.17). [moby/moby#47841](https://github.com/moby/moby/pull/47841)\n*   [CVE-2024-24789](https://github.com/golang/go/issues/66869), [CVE-2024-24790](https://github.com/golang/go/issues/67680): Update Go runtime to 1.21.11. [moby/moby#47904](https://github.com/moby/moby/pull/47904)\n*   Update Compose to [v2.27.1](https://github.com/docker/compose/releases/tag/v2.27.1). [docker/docker-ce-packages#1022](https://github.com/docker/docker-ce-packaging/pull/1022)\n*   Update Buildx to [v0.14.1](https://github.com/docker/buildx/releases/tag/v0.14.1). [docker/docker-ce-packages#1021](https://github.com/docker/docker-ce-packaging/pull/1021)\n\n_2024-05-16_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 26.1.3 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A26.1.3)\n*   [moby/moby, 26.1.3 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A26.1.3)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v26.1.3/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v26.1.3/docs/api/version-history.md).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-1)\n\n*   Fix a regression that prevented the use of DNS servers within a `--internal` network. [moby/moby#47832](https://github.com/moby/moby/pull/47832)\n*   When the internal DNS server's own address is supplied as an external server address, ignore it to avoid unproductive recursion. [moby/moby#47833](https://github.com/moby/moby/pull/47833)\n\n### [Packaging updates](#packaging-updates-1)\n\n*   Allow runc to kill containers when confined to the runc profile in AppArmor version 4.0.0 and later. [moby/moby#47829](https://github.com/moby/moby/pull/47829)\n\n_2024-05-08_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 26.1.2 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A26.1.2)\n*   [moby/moby, 26.1.2 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A26.1.2)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v26.1.2/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v26.1.2/docs/api/version-history.md).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-2)\n\n*   Fix an issue where the CLI process would sometimes hang when a container failed to start. [docker/cli#5062](https://github.com/docker/cli/pull/5062)\n\n### [Packaging updates](#packaging-updates-2)\n\n*   Update Go runtime to 1.21.10. [moby/moby#47806](https://github.com/moby/moby/pull/47806)\n\n_2024-04-30_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 26.1.1 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A26.1.1)\n*   [moby/moby, 26.1.1 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A26.1.1)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v26.1.1/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v26.1.1/docs/api/version-history.md).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-3)\n\n*   Fix `docker run -d` printing an `context canceled` spurious error when OpenTelemetry is configured. [docker/cli#5044](https://github.com/docker/cli/pull/5044)\n*   Experimental environment variable `DOCKER_BRIDGE_PRESERVE_KERNEL_LL=1` will prevent the daemon from removing the kernel-assigned link local address on a Linux bridge. [moby/moby#47775](https://github.com/moby/moby/pull/47775)\n*   Resolve an issue preventing container creation on hosts with a read-only `/proc/sys/net` filesystem. If IPv6 cannot be disabled on an interface due to this, either disable IPv6 by default on the host or ensure `/proc/sys/net` is read-write. To bypass the error, set the environment variable `DOCKER_ALLOW_IPV6_ON_IPV4_INTERFACE=1` before starting the Docker daemon. [moby/moby#47769](https://github.com/moby/moby/pull/47769)\n\n> **Note**\n> \n> The `DOCKER_ALLOW_IPV6_ON_IPV4_INTERFACE` is added as a temporary fix and will be phased out in a future major release, when the IPv6 enablement process has been improved.\n\n### [Packaging updates](#packaging-updates-3)\n\n*   Update BuildKit to [v0.13.2](https://github.com/moby/buildkit/releases/tag/v0.13.2). [moby/moby#47762](https://github.com/moby/moby/pull/47762)\n*   Update Compose to [v2.27.0](https://github.com/docker/compose/releases/tag/v2.27.0). [docker/docker-ce-packages#1017](https://github.com/docker/docker-ce-packaging/pull/1017)\n\n_2024-04-22_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 26.1.0 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A26.1.0)\n*   [moby/moby, 26.1.0 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A26.1.0)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v26.1.0/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v26.1.0/docs/api/version-history.md).\n\n### [New](#new)\n\n*   Added configurable OpenTelemetry utilities and basic instrumentation to commands. For more information, see [OpenTelemetry for the Docker CLI](https://docs.docker.com/config/otel). [docker/cli#4889](https://github.com/docker/cli/pull/4889)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-4)\n\n*   Native Windows containers are configured with an internal DNS server for container name resolution, and external DNS servers for other lookups. Not all resolvers, including `nslookup`, fall back to the external resolvers when they get a `SERVFAIL` answer from the internal server. So, the internal DNS server can now be configured to forward requests to the external resolvers, by setting a `feature` option in the `daemon.json` file:\n    \n    [moby/moby#47584](https://github.com/moby/moby/pull/47584)\n    \n    > **Note**\n    > \n    > *   This will be the new default behavior in Docker Engine 27.0.\n    > *   The `windows-dns-proxy` feature flag will be removed in a future release.\n    \n*   Swarm: Fix `Subpath` not being passed to the container config. [moby/moby#47711](https://github.com/moby/moby/pull/47711)\n    \n*   Classic builder: Fix cache miss on `WORKDIR <directory>/` build step (directory with a trailing slash). [moby/moby#47723](https://github.com/moby/moby/pull/47723)\n    \n*   containerd image store: Fix `docker images` failing when any image in the store has unexpected target. [moby/moby#47738](https://github.com/moby/moby/pull/47738)",
  "title": "Docker Engine 26.1 release notes | Docker Docs\n",
  "description": "Learn about the new features, bug fixes, and breaking changes for Docker Engine",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/extend/plugins_network/",
  "markdown": "# Docker network driver plugins | Docker Docs\n\nThis document describes Docker Engine network driver plugins generally available in Docker Engine. To view information on plugins managed by Docker Engine, refer to [Docker Engine plugin system](https://docs.docker.com/engine/extend/).\n\nDocker Engine network plugins enable Engine deployments to be extended to support a wide range of networking technologies, such as VXLAN, IPVLAN, MACVLAN or something completely different. Network driver plugins are supported via the LibNetwork project. Each plugin is implemented as a \"remote driver\" for LibNetwork, which shares plugin infrastructure with Engine. Effectively, network driver plugins are activated in the same way as other plugins, and use the same kind of protocol.\n\n[Legacy plugins](https://docs.docker.com/engine/extend/legacy_plugins/) do not work in Swarm mode. However, plugins written using the [v2 plugin system](https://docs.docker.com/engine/extend/) do work in Swarm mode, as long as they are installed on each Swarm worker node.\n\nThe means of installing and running a network driver plugin depend on the particular plugin. So, be sure to install your plugin according to the instructions obtained from the plugin developer.\n\nOnce running however, network driver plugins are used just like the built-in network drivers: by being mentioned as a driver in network-oriented Docker commands. For example,\n\nSome network driver plugins are listed in [plugins](https://docs.docker.com/engine/extend/legacy_plugins/)\n\nThe `mynet` network is now owned by `weave`, so subsequent commands referring to that network will be sent to the plugin,\n\nNetwork plugins are written by third parties, and are published by those third parties, either on [Docker Hub](https://hub.docker.com/search?q=&type=plugin) or on the third party's site.\n\nNetwork plugins implement the [Docker plugin API](https://docs.docker.com/engine/extend/plugin_api/) and the network plugin protocol\n\nThe network driver protocol, in addition to the plugin activation call, is documented as part of libnetwork: [https://github.com/moby/moby/blob/master/libnetwork/docs/remote.md](https://github.com/moby/moby/blob/master/libnetwork/docs/remote.md).\n\nTo interact with the Docker maintainers and other interested users, see the IRC channel `#docker-network`.\n\n*   [Docker networks feature overview](https://docs.docker.com/engine/userguide/networking/)\n*   The [LibNetwork](https://github.com/docker/libnetwork) project",
  "title": "Docker network driver plugins | Docker Docs\n",
  "description": "Network driver plugins.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/",
  "markdown": "# Getting started with Swarm mode\n\nThis tutorial introduces you to the features of Docker Engine Swarm mode. You may want to familiarize yourself with the [key concepts](https://docs.docker.com/engine/swarm/key-concepts/) before you begin.\n\nThe tutorial guides you through:\n\n*   Initializing a cluster of Docker Engines in swarm mode\n*   Adding nodes to the swarm\n*   Deploying application services to the swarm\n*   Managing the swarm once you have everything running\n\nThis tutorial uses Docker Engine CLI commands entered on the command line of a terminal window.\n\nIf you are brand new to Docker, see [About Docker Engine](https://docs.docker.com/engine/).\n\nTo run this tutorial, you need:\n\n*   [Three Linux hosts which can communicate over a network, with Docker installed](#three-networked-host-machines)\n*   [The IP address of the manager machine](#the-ip-address-of-the-manager-machine)\n*   [Open ports between the hosts](#open-protocols-and-ports-between-the-hosts)\n\n### [Three networked host machines](#three-networked-host-machines)\n\nThis tutorial requires three Linux hosts which have Docker installed and can communicate over a network. These can be physical machines, virtual machines, Amazon EC2 instances, or hosted in some other way. Check out [Deploy to Swarm](https://docs.docker.com/guides/deployment-orchestration/swarm-deploy/#prerequisites) for one possible set-up for the hosts.\n\nOne of these machines is a manager (called `manager1`) and two of them are workers (`worker1` and `worker2`).\n\n> **Note**\n> \n> You can follow many of the tutorial steps to test single-node swarm as well, in which case you need only one host. Multi-node commands do not work, but you can initialize a swarm, create services, and scale them.\n\n#### [Install Docker Engine on Linux machines](#install-docker-engine-on-linux-machines)\n\nIf you are using Linux based physical computers or cloud-provided computers as hosts, simply follow the [Linux install instructions](https://docs.docker.com/engine/install/) for your platform. Spin up the three machines, and you are ready. You can test both single-node and multi-node swarm scenarios on Linux machines.\n\n### [The IP address of the manager machine](#the-ip-address-of-the-manager-machine)\n\nThe IP address must be assigned to a network interface available to the host operating system. All nodes in the swarm need to connect to the manager at the IP address.\n\nBecause other nodes contact the manager node on its IP address, you should use a fixed IP address.\n\nYou can run `ifconfig` on Linux or macOS to see a list of the available network interfaces.\n\nThe tutorial uses `manager1` : `192.168.99.100`.\n\n### [Open protocols and ports between the hosts](#open-protocols-and-ports-between-the-hosts)\n\nThe following ports must be available. On some systems, these ports are open by default.\n\n*   Port `2377` TCP for communication with and between manager nodes\n*   Port `7946` TCP/UDP for overlay network node discovery\n*   Port `4789` UDP (configurable) for overlay network traffic\n\nIf you plan on creating an overlay network with encryption (`--opt encrypted`), you also need to ensure IP protocol 50 (IPSec ESP) traffic is allowed.\n\nPort `4789` is the default value for the Swarm data path port, also known as the VXLAN port. It is important to prevent any untrusted traffic from reaching this port, as VXLAN does not provide authentication. This port should only be opened to a trusted network, and never at a perimeter firewall.\n\nIf the network which Swarm traffic traverses is not fully trusted, it is strongly suggested that encrypted overlay networks be used. If encrypted overlay networks are in exclusive use, some additional hardening is suggested:\n\n*   [Customize the default ingress network](https://docs.docker.com/engine/swarm/networking/) to use encryption\n*   Only accept encrypted packets on the Data Path Port:\n\nNext, you'll create a swarm.",
  "title": "Getting started with Swarm mode | Docker Docs\n",
  "description": "Getting Started tutorial for Docker Engine Swarm mode",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/25.0/",
  "markdown": "# Docker Engine 25.0 release notes\n\nThis page describes the latest changes, additions, known issues, and fixes for Docker Engine version 25.0.\n\nFor more information about:\n\n*   Deprecated and removed features, see [Deprecated Engine Features](https://docs.docker.com/engine/deprecated/).\n*   Changes to the Engine API, see [Engine API version history](https://docs.docker.com/engine/api/version-history/).\n\n_2024-03-19_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 25.0.5 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A25.0.5)\n*   [moby/moby, 25.0.5 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A25.0.5)\n\n### [Security](#security)\n\nThis release contains a security fix for [CVE-2024-29018](https://github.com/moby/moby/security/advisories/GHSA-mq39-4gv4-mvpx), a potential data exfiltration from 'internal' networks via authoritative DNS servers.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements)\n\n*   [CVE-2024-29018](https://github.com/moby/moby/security/advisories/GHSA-mq39-4gv4-mvpx): Do not forward requests to external DNS servers for a container that is only connected to an 'internal' network. Previously, requests were forwarded if the host's DNS server was running on a loopback address, like systemd's 127.0.0.53. [moby/moby#47589](https://github.com/moby/moby/pull/47589)\n    \n*   plugin: fix mounting /etc/hosts when running in UserNS. [moby/moby#47588](https://github.com/moby/moby/pull/47588)\n    \n*   rootless: fix `open /etc/docker/plugins: permission denied`. [moby/moby#47587](https://github.com/moby/moby/pull/47587)\n    \n*   Fix multiple parallel `docker build` runs leaking disk space. [moby/moby#47527](https://github.com/moby/moby/pull/47527)\n    \n\n_2024-03-07_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 25.0.4 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A25.0.4)\n*   [moby/moby, 25.0.4 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A25.0.4)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-1)\n\n*   Restore DNS names for containers in the default \"nat\" network on Windows. [moby/moby#47490](https://github.com/moby/moby/pull/47490)\n*   Fix `docker start` failing when used with `--checkpoint` [moby/moby#47466](https://github.com/moby/moby/pull/47466)\n*   Don't enforce new validation rules for existing swarm networks [moby/moby#47482](https://github.com/moby/moby/pull/47482)\n*   Restore IP connectivity between the host and containers on an internal bridge network. [moby/moby#47481](https://github.com/moby/moby/pull/47481)\n*   Fix a regression introduced in v25.0 that prevented the classic builder from adding tar archive with `xattrs` created on a non-Linux OS [moby/moby#47483](https://github.com/moby/moby/pull/47483)\n*   containerd image store: Fix image pull not emitting `Pulling fs layer status` [moby/moby#47484](https://github.com/moby/moby/pull/47484)\n*   API: To preserve backwards compatibility, make read-only mounts non-recursive by default when using older clients (API versions < v1.44). [moby/moby#47393](https://github.com/moby/moby/pull/47393)\n*   API: `GET /images/{id}/json` omits the `Created` field (previously it was `0001-01-01T00:00:00Z`) if the `Created` field was missing from the image config. [moby/moby#47451](https://github.com/moby/moby/pull/47451)\n*   API: Populate a missing `Created` field in `GET /images/{id}/json` with `0001-01-01T00:00:00Z` for API versions <= 1.43. [moby/moby#47387](https://github.com/moby/moby/pull/47387)\n*   API: Fix a regression that caused API socket connection failures to report an API version negotiation failure instead. [moby/moby#47470](https://github.com/moby/moby/pull/47470)\n*   API: Preserve supplied endpoint configuration in a container-create API request, when a container-wide MAC address is specified, but `NetworkMode` name or id is not the same as the name or id used in `NetworkSettings.Networks`. [moby/moby#47510](https://github.com/moby/moby/pull/47510)\n\n### [Packaging updates](#packaging-updates)\n\n*   Upgrade Go runtime to 1.21.8. [moby/moby#47503](https://github.com/moby/moby/pull/47503)\n*   Upgrade RootlessKit to v2.0.2. [moby/moby#47508](https://github.com/moby/moby/pull/47508)\n*   Upgrade Compose to v2.24.7. [docker/docker-ce-packaging#998](https://github.com/moby/moby/pull/998)\n*   Upgrade Buildx to v0.13.0. [docker/docker-ce-packaging#997](https://github.com/moby/moby/pull/997)\n\n_2024-02-06_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 25.0.3 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A25.0.3)\n*   [moby/moby, 25.0.3 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A25.0.3)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-2)\n\n*   containerd image store: Fix a bug where `docker image history` would fail if a manifest wasn't found in the content store. [moby/moby#47348](https://github.com/moby/moby/pull/47348)\n    \n*   Ensure that a generated MAC address is not restored when a container is restarted, but a configured MAC address is preserved. [moby/moby#47304](https://github.com/moby/moby/pull/47304)\n    \n    > **Note**\n    > \n    > *   Containers created with Docker Engine version 25.0.0 may have duplicate MAC addresses. They must be re-created.\n    > *   Containers with user-defined MAC addresses created with Docker Engine versions 25.0.0 or 25.0.1 receive new MAC addresses when started using Docker Engine version 25.0.2. They must also be re-created.\n    \n*   Fix `docker save <image>@<digest>` producing an OCI archive with index without manifests. [moby/moby#47294](https://github.com/moby/moby/pull/47294)\n    \n*   Fix a bug preventing bridge networks from being created with an MTU higher than 1500 on RHEL and CentOS 7. [moby/moby#47308](https://github.com/moby/moby/issues/47308), [moby/moby#47311](https://github.com/moby/moby/pull/47311)\n    \n*   Fix a bug where containers are unable to communicate over an `internal` network. [moby/moby#47303](https://github.com/moby/moby/pull/47303)\n    \n*   Fix a bug where the value of the `ipv6` daemon option was ignored. [moby/moby#47310](https://github.com/moby/moby/pull/47310)\n    \n*   Fix a bug where trying to install a pulling using a digest revision would cause a panic. [moby/moby#47323](https://github.com/moby/moby/pull/47323)\n    \n*   Fix a potential race condition in the managed containerd supervisor. [moby/moby#47313](https://github.com/moby/moby/pull/47313)\n    \n*   Fix an issue with the `journald` log driver preventing container logs from being followed correctly with systemd version 255. [moby/moby47243](https://github.com/moby/moby/pull/47243)\n    \n*   seccomp: Update the builtin seccomp profile to include syscalls added in kernel v5.17 - v6.7 to align the profile with the profile used by containerd. [moby/moby#47341](https://github.com/moby/moby/pull/47341)\n    \n*   Windows: Fix cache not being used when building images based on Windows versions older than the host's version. [moby/moby#47307](https://github.com/moby/moby/pull/47307), [moby/moby#47337](https://github.com/moby/moby/pull/47337)\n    \n\n### [Packaging updates](#packaging-updates-1)\n\n*   Removed support for Ubuntu Lunar (23.04). [docker/ce-packaging#986](https://github.com/docker/docker-ce-packaging/pull/986)\n\n_2024-01-31_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 25.0.2 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A25.0.2)\n*   [moby/moby, 25.0.2 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A25.0.2)\n\n### [Security](#security-1)\n\nThis release contains security fixes for the following CVEs affecting Docker Engine and its components.\n\n| CVE | Component | Fix version | Severity |\n| --- | --- | --- | --- |\n| [CVE-2024-21626](https://scout.docker.com/v/CVE-2024-21626) | runc | 1.1.12 | High, CVSS 8.6 |\n| [CVE-2024-23651](https://scout.docker.com/v/CVE-2024-23651) | BuildKit | 1.12.5 | High, CVSS 8.7 |\n| [CVE-2024-23652](https://scout.docker.com/v/CVE-2024-23652) | BuildKit | 1.12.5 | High, CVSS 8.7 |\n| [CVE-2024-23653](https://scout.docker.com/v/CVE-2024-23653) | BuildKit | 1.12.5 | High, CVSS 7.7 |\n| [CVE-2024-23650](https://scout.docker.com/v/CVE-2024-23650) | BuildKit | 1.12.5 | Medium, CVSS 5.5 |\n| [CVE-2024-24557](https://scout.docker.com/v/CVE-2024-24557) | Docker Engine | 25.0.2 | Medium, CVSS 6.9 |\n\nThe potential impacts of the above vulnerabilities include:\n\n*   Unauthorized access to the host filesystem\n*   Compromising the integrity of the build cache\n*   In the case of CVE-2024-21626, a scenario that could lead to full container escape\n\nFor more information about the security issues addressed in this release, refer to the [blog post](https://www.docker.com/blog/docker-security-advisory-multiple-vulnerabilities-in-runc-buildkit-and-moby/). For details about each vulnerability, see the relevant security advisory:\n\n*   [CVE-2024-21626](https://github.com/opencontainers/runc/security/advisories/GHSA-xr7r-f8xq-vfvv)\n*   [CVE-2024-23651](https://github.com/moby/buildkit/security/advisories/GHSA-m3r6-h7wv-7xxv)\n*   [CVE-2024-23652](https://github.com/moby/buildkit/security/advisories/GHSA-4v98-7qmw-rqr8)\n*   [CVE-2024-23653](https://github.com/moby/buildkit/security/advisories/GHSA-wr6v-9f75-vh2g)\n*   [CVE-2024-23650](https://github.com/moby/buildkit/security/advisories/GHSA-9p26-698r-w4hx)\n*   [CVE-2024-24557](https://github.com/moby/moby/security/advisories/GHSA-xw73-rw38-6vjc)\n\n### [Packaging updates](#packaging-updates-2)\n\n*   Upgrade containerd to [v1.6.28](https://github.com/containerd/containerd/releases/tag/v1.6.28).\n*   Upgrade containerd to v1.7.13 (static binaries only). [moby/moby#47280](https://github.com/moby/moby/pull/47280)\n*   Upgrade runc to v1.1.12. [moby/moby#47269](https://github.com/moby/moby/pull/47269)\n*   Upgrade Compose to v2.24.5. [docker/docker-ce-packaging#985](https://github.com/docker/docker-ce-packaging/pull/985)\n*   Upgrade BuildKit to v0.12.5. [moby/moby#47273](https://github.com/moby/moby/pull/47273)\n\n_2024-01-23_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 25.0.1 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A25.0.1)\n*   [moby/moby, 25.0.1 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A25.0.1)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-3)\n\n*   API: Fix incorrect HTTP status code for containers with an invalid network configuration created before upgrading to Docker Engine v25.0. [moby/moby#47159](https://github.com/moby/moby/pull/47159)\n*   Ensure that a MAC address based on a container's IP address is re-generated when the container is stopped and restarted, in case the generated IP/MAC addresses have been reused. [moby/moby#47171](https://github.com/moby/moby/pull/47171)\n*   Fix `host-gateway-ip` not working during build when not set through configuration. [moby/moby#47192](https://github.com/moby/moby/pull/47192)\n*   Fix a bug that prevented a container from being renamed twice. [moby/moby#47196](https://github.com/moby/moby/pull/47196)\n*   Fix an issue causing containers to have their short ID added to their network alias when inspecting them. [moby/moby#47182](https://github.com/moby/moby/pull/47182)\n*   Fix an issue in detecting whether a remote build context is a Git repository. [moby/moby#47136](https://github.com/moby/moby/pull/47136)\n*   Fix an issue with layers order in OCI manifests. [moby/moby#47150](https://github.com/moby/moby/issues/47150)\n*   Fix volume mount error when passing an `addr` or `ip` mount option. [moby/moby#47185](https://github.com/moby/moby/pull/47185)\n*   Improve error message related to extended attributes that can't be set due to improperly namespaced attribute names. [moby/moby#47178](https://github.com/moby/moby/pull/47178)\n*   Swarm: Fixed `start_interval` not being passed to the container config. [moby/moby#47163](https://github.com/moby/moby/pull/47163)\n\n### [Packaging updates](#packaging-updates-3)\n\n*   Upgrade Compose to `2.24.2`. [docker/docker-ce-packaging#981](https://github.com/docker/docker-ce-packaging/pull/981)\n\n_2024-01-19_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 25.0.0 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A25.0.0)\n*   [moby/moby, 25.0.0 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A25.0.0)\n\n> **Note**\n> \n> In earlier versions of Docker Engine, recursive mounts (submounts) would always be mounted as writable, even when specifying a read-only mount. This behavior has changed in v25.0.0, for hosts running on kernel version 5.12 or later. Now, read-only bind mounts are **recursively read-only** by default.\n> \n> To get the same behavior as earlier releases, you can specify the `bind-recursive` option for the `--mount` flag.\n> \n> This option isn't supported with the `-v` or `--volume` flag. For more information, see [Recursive mounts](https://docs.docker.com/storage/bind-mounts/#recursive-mounts).\n\n### [New](#new)\n\n*   The daemon now uses systemd's default `LimitNOFILE`. In earlier versions of Docker Engine, this limit was set to `infinity`. This would cause issues with recent versions of systemd, where the hard limit was increased, causing programs that adjusted their behaviors based on ulimits to consume a high amount of memory. [moby/moby#45534](https://github.com/moby/moby/pull/45534)\n    \n    The new setting makes containers behave the same way as programs running on the host, but may cause programs that make incorrect assumptions based on the soft limit to misbehave. To get the previous behavior, you can set `LimitNOFILE=1048576`.\n    \n    This change currently only affects build containers created with `docker build` when using BuildKit with the `docker` driver. Future versions of containerd will also use this limit, which will cause this behavior to affect all containers, not only build containers.\n    \n    If you're experiencing issues with the higher ulimit in systemd v240 or later, consider adding a system `drop-in` or `override` file to configure the ulimit settings for your setup. The [Flatcar Container Linux documentation](https://www.flatcar.org/docs/latest/setup/systemd/drop-in-units/) has a great article covering this topic in detail.\n    \n*   Add OpenTelemetry tracing. [moby/moby#45652](https://github.com/moby/moby/pull/45652), [moby/moby#45579](https://github.com/moby/moby/pull/45579)\n    \n*   Add support for CDI devices under Linux. [moby/moby#45134](https://github.com/moby/moby/pull/45134), [docker/cli#4510](https://github.com/docker/cli/pull/4510), [moby/moby#46004](https://github.com/moby/moby/pull/46004)\n    \n*   Add an additional interval to be used by healthchecks during the container start period. [moby/moby#40894](https://github.com/moby/moby/pull/40894), [docker/cli#4405](https://github.com/docker/cli/pull/4405), [moby/moby#45965](https://github.com/moby/moby/pull/45965)\n    \n*   Add a `--log-format` flag to `dockerd` to control the logging format: text (default) or JSON. [moby/moby#45737](https://github.com/moby/moby/pull/45737)\n    \n*   Add support for recursive read-only mounts. [moby/moby#45278](https://github.com/moby/moby/pull/45278), [moby/moby#46037](https://github.com/moby/moby/pull/46037)\n    \n*   Add support for filtering images based on timestamp with `docker image ls --filter=until=<timestamp>`. [moby/moby#46577](https://github.com/moby/moby/pull/46577)\n    \n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-4)\n\n*   API: Fix error message for invalid policies at `ValidateRestartPolicy`. [moby/moby#46352](https://github.com/moby/moby/pull/46352)\n*   API: Update `/info` endpoint to use singleflight. [moby/moby#45847](https://github.com/moby/moby/pull/45847)\n*   Add an error message for when specifying a Dockerfile filename with `-f`, and also using `stdin`. [docker/cli#4346](https://github.com/docker/cli/pull/4346)\n*   Add support for `mac-address` and `link-local-ip` fields in `--network` long format. [docker/cli#4419](https://github.com/docker/cli/pull/4419)\n*   Add support for specifying multiple `--network` flags with `docker container create` and `docker run`. [moby/moby#45906](https://github.com/moby/moby/pull/45906)\n*   Automatically enable IPv6 on a network when an IPv6 subnet is specified. [moby/moby#46455](https://github.com/moby/moby/pull/46455)\n*   Add support for overlay networks over IPv6 transport. [moby/moby#46790](https://github.com/moby/moby/pull/46790)\n*   Configuration reloading is now more robust: if there's an error during the configuration reload process, no configuration changes are applied. [moby/moby#43980](https://github.com/moby/moby/pull/43980)\n*   Live restore: Containers with auto remove (`docker run --rm`) are no longer forcibly removed on engine restart. [moby/moby#46857](https://github.com/moby/moby/pull/46857)\n*   Live restore: containers that are live-restored will now be given another health-check start period when the daemon restarts. [moby/moby#47051](https://github.com/moby/moby/pull/47051)\n*   Container health status is flushed to disk less frequently, reducing wear on flash storage. [moby/moby#47044](https://github.com/moby/moby/pull/47044)\n*   Ensure network names are unique. [moby/moby#46251](https://github.com/moby/moby/pull/46251)\n*   Ensure that overlay2 layer metadata is correct. [moby/moby#46471](https://github.com/moby/moby/pull/46471)\n*   Fix `Downloading` progress message on image pull. [moby/moby#46515](https://github.com/moby/moby/pull/46515)\n*   Fix `NetworkConnect` and `ContainerCreate` with improved data validation, and return all validation errors at once. [moby/moby#46183](https://github.com/moby/moby/pull/46183)\n*   Fix `com.docker.network.host_ipv4` option when IPv6 and ip6tables are enabled. [moby/moby#46446](https://github.com/moby/moby/pull/46446)\n*   Fix daemon's `cleanupContainer` if containerd is stopped. [moby/moby#46213](https://github.com/moby/moby/pull/46213)\n*   Fix returning incorrect HTTP status codes for libnetwork errors. [moby/moby#46146](https://github.com/moby/moby/pull/46146)\n*   Fix various issues with images/json API filters and image list. [moby/moby#46034](https://github.com/moby/moby/pull/46034)\n*   CIFS volumes now resolves FQDN correctly. [moby/moby#46863](https://github.com/moby/moby/pull/46863)\n*   Improve validation of the `userland-proxy-path` daemon configuration option. Validation now happens during daemon startup, instead of producing an error when starting a container with port-mapping. [moby/moby#47000](https://github.com/moby/moby/pull/47000)\n*   Set the MAC address of container's interface when network mode is a short network ID. [moby/moby#46406](https://github.com/moby/moby/pull/46406)\n*   Sort unconsumed build arguments before display in build output. [moby/moby#45917](https://github.com/moby/moby/pull/45917)\n*   The `docker image save` tarball output is now OCI compliant. [moby/moby#44598](https://github.com/moby/moby/pull/44598)\n*   The daemon no longer appends `ACCEPT` rules to the end of the `INPUT` iptables chain for encrypted overlay networks. Depending on firewall configuration, a rule may be needed to permit incoming encrypted overlay network traffic. [moby/moby#45280](https://github.com/moby/moby/pull/45280)\n*   Unpacking layers with extended attributes onto an incompatible filesystem will now fail instead of silently discarding extended attributes. [moby/moby#45464](https://github.com/moby/moby/pull/45464)\n*   Update daemon MTU option to BridgeConfig and display warning on Windows. [moby/moby#45887](https://github.com/moby/moby/pull/45887)\n*   Validate IPAM config when creating a network. Automatically fix networks created prior to this release where `--ip-range` is larger than `--subnet`. [moby/moby#45759](https://github.com/moby/moby/pull/45759)\n*   Containers connected only to internal networks will now have no default route set, making the `connect` syscall fail-fast. [moby/moby#46603](https://github.com/moby/moby/pull/46603)\n*   containerd image store: Add image events for `push`, `pull`, and `save`. [moby/moby#46405](https://github.com/moby/moby/pull/46405)\n*   containerd image store: Add support for pulling legacy schema1 images. [moby/moby#46513](https://github.com/moby/moby/pull/46513)\n*   containerd image store: Add support for pushing all tags. [moby/moby#46485](https://github.com/moby/moby/pull/46485)\n*   containerd image store: Add support for registry token. [moby/moby#46475](https://github.com/moby/moby/pull/46475)\n*   containerd image store: Add support for showing the number of containers that use an image. [moby/moby#46511](https://github.com/moby/moby/pull/46511)\n*   containerd image store: Fix a bug related to the `ONBUILD`, `MAINTAINER`, and `HEALTHCHECK` Dockerfile instructions. [moby/moby#46313](https://github.com/moby/moby/pull/46313)\n*   containerd image store: Fix `Pulling from` progress message. [moby/moby#46494](https://github.com/moby/moby/pull/46494)\n*   containerd image store: Add support for referencing images via the truncated ID with `sha256:` prefix. [moby/moby#46435](https://github.com/moby/moby/pull/46435)\n*   containerd image store: Fix `docker images` showing intermediate layers by default. [moby/moby#46423](https://github.com/moby/moby/pull/46423)\n*   containerd image store: Fix checking if the specified platform exists when getting an image. [moby/moby#46495](https://github.com/moby/moby/pull/46495)\n*   containerd image store: Fix errors when multiple `ADD` or `COPY` instructions were used with the classic builder. [moby/moby#46383](https://github.com/moby/moby/pull/46383)\n*   containerd image store: Fix stack overflow errors when importing an image. [moby/moby#46418](https://github.com/moby/moby/pull/46418)\n*   containerd image store: Improve `docker pull` progress output. [moby/moby#46412](https://github.com/moby/moby/pull/46412)\n*   containerd image store: Print the tag, digest, and size after pushing an image. [moby/moby#46384](https://github.com/moby/moby/pull/46384)\n*   containerd image store: Remove panic from `UpdateConfig`. [moby/moby#46433](https://github.com/moby/moby/pull/46433)\n*   containerd image store: Return an error when an image tag resembles a digest. [moby/moby#46492](https://github.com/moby/moby/pull/46492)\n*   containerd image store: `docker image ls` now shows the correct image creation time and date. [moby/moby#46719](https://github.com/moby/moby/pull/46719)\n*   containerd image store: Fix an issue handling user namespace settings. [moby/moby#46375](https://github.com/moby/moby/pull/46375)\n*   containerd image store: Add support for pulling all tags (`docker pull -a`). [moby/moby#46618](https://github.com/moby/moby/pull/46618)\n*   containerd image store: Use the domain name in the image reference as the default registry authentication domain. [moby/moby#46779](https://github.com/moby/moby/pull/46779)\n\n### [Packaging updates](#packaging-updates-4)\n\n*   Upgrade API to v1.44. [moby/moby#45468](https://github.com/moby/moby/pull/45468)\n*   Upgrade Compose to `2.24.1`. [docker/docker-ce-packaging#980](https://github.com/docker/docker-ce-packaging/pull/980)\n*   Upgrade containerd to v1.7.12 (static binaries only). [moby/moby#47070](https://github.com/moby/moby/pull/47070)\n*   Upgrade Go runtime to [1.21.6](https://go.dev/doc/devel/release#go1.21.minor). [moby/moby#47053](https://github.com/moby/moby/pull/47053)\n*   Upgrade runc to v1.1.11. [moby/moby#47007](https://github.com/moby/moby/pull/47007)\n*   Upgrade BuildKit to v0.12.4. [moby/moby#46882](https://github.com/moby/moby/pull/46882)\n*   Upgrade Buildx to v0.12.1. [docker/docker-ce-packaging#979](https://github.com/docker/docker-ce-packaging/pull/979)\n\n### [Removed](#removed)\n\n*   API: Remove VirtualSize field for the `GET /images/json` and `GET /images/{id}/json` endpoints. [moby/moby#45469](https://github.com/moby/moby/pull/45469)\n*   Remove deprecated `devicemapper` storage driver. [moby/moby#43637](https://github.com/moby/moby/pull/43637)\n*   Remove deprecated orchestrator options. [docker/cli#4366](https://github.com/docker/cli/pull/4366)\n*   Remove support for Debian Upstart init system. [moby/moby#45548](https://github.com/moby/moby/pull/45548), [moby/moby#45551](https://github.com/moby/moby/pull/45551)\n*   Remove the `--oom-score-adjust` daemon option. [moby/moby#45484](https://github.com/moby/moby/pull/45484)\n*   Remove warning for deprecated `~/.dockercfg` file. [docker/cli#4281](https://github.com/docker/cli/pull/4281)\n*   Remove `logentries` logging driver. [moby/moby#46925](https://github.com/moby/moby/pull/46925)\n\n### [Deprecated](#deprecated)\n\n*   Deprecate API versions older than 1.24. [Deprecation notice](https://docs.docker.com/engine/deprecated/#deprecate-legacy-api-versions)\n*   Deprecate `IsAutomated` field and `is-automated` filter for `docker search`. [Deprecation notice](https://docs.docker.com/engine/deprecated/#isautomated-field-and-is-automated-filter-on-docker-search)\n*   API: Deprecate `Container` and `ContainerConfig` properties for `/images/{id}/json` (`docker image inspect`). [moby/moby#46939](https://github.com/moby/moby/pull/46939)\n\n### [Known limitations](#known-limitations)\n\n#### [Extended attributes for tar files](#extended-attributes-for-tar-files)\n\nIn this release, the code that handles `tar` archives was changed to be more strict and to produce an error when failing to write extended attributes (`xattr`). The `tar` implementation for macOS generates additional extended attributes by default when creating tar files. These attribute prefixes aren't valid Linux `xattr` namespace prefixes, which causes an error when Docker attempts to process these files. For example, if you try to use a tar file with an `ADD` Dockerfile instruction, you might see an error message similar to the following:\n\nError messages related to extended attribute validation were improved to include more context in [v25.0.1](#2501), but the limitation in Docker being unable to process the files remains. Tar files created with the macOS `tar` using default arguments will produce an error when the tar file is used with Docker.\n\nAs a workaround, if you need to use tar files with Docker generated on macOS, you can either:\n\n*   Use the `--no-xattr` flag for the macOS `tar` command to strip **all** the extended attributes. If you want to preserve extended attributes, this isn't a recommended option.\n    \n*   Install and use `gnu-tar` to create the tarballs on macOS instead of the default `tar` implementation. To install `gnu-tar` using Homebrew:\n    \n    After installing, add the `gnu-tar` binary to your `PATH`, for example by updating your `.zshrc` file:",
  "title": "Docker Engine 25.0 release notes | Docker Docs\n",
  "description": "Learn about the new features, bug fixes, and breaking changes for Docker Engine",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/drivers/docker-container/",
  "markdown": "# Docker container build driver | Docker Docs\n\nThe Docker container driver allows creation of a managed and customizable BuildKit environment in a dedicated Docker container.\n\nUsing the Docker container driver has a couple of advantages over the default Docker driver. For example:\n\n*   Specify custom BuildKit versions to use.\n*   Build multi-arch images, see [QEMU](#qemu)\n*   Advanced options for [cache import and export](https://docs.docker.com/build/cache/backends/)\n\nRun the following command to create a new builder, named `container`, that uses the Docker container driver:\n\nThe following table describes the available driver-specific options that you can pass to `--driver-opt`:\n\n| Parameter | Type | Default | Description |\n| --- | --- | --- | --- |\n| `image` | String |     | Sets the BuildKit image to use for the container. |\n| `memory` | String |     | Sets the amount of memory the container can use. |\n| `memory-swap` | String |     | Sets the memory swap limit for the container. |\n| `cpu-quota` | String |     | Imposes a CPU CFS quota on the container. |\n| `cpu-period` | String |     | Sets the CPU CFS scheduler period for the container. |\n| `cpu-shares` | String |     | Configures CPU shares (relative weight) of the container. |\n| `cpuset-cpus` | String |     | Limits the set of CPU cores the container can use. |\n| `cpuset-mems` | String |     | Limits the set of CPU memory nodes the container can use. |\n| `default-load` | Boolean | `false` | Automatically load images to the Docker Engine image store. |\n| `network` | String |     | Sets the network mode for the container. |\n| `cgroup-parent` | String | `/docker/buildx` | Sets the cgroup parent of the container if Docker is using the \"cgroupfs\" driver. |\n| `restart-policy` | String | `unless-stopped` | Sets the container's [restart policy](https://docs.docker.com/config/containers/start-containers-automatically/#use-a-restart-policy). |\n| `env.<key>` | String |     | Sets the environment variable `key` to the specified `value` in the container. |\n\nBefore you configure the resource limits for the container, read about [configuring runtime resource constraints for containers](https://docs.docker.com/config/containers/resource_constraints/).\n\nWhen you run a build, Buildx pulls the specified `image` (by default, [`moby/buildkit`](https://hub.docker.com/r/moby/buildkit)). When the container has started, Buildx submits the build submitted to the containerized build server.\n\nThe `docker-container` driver supports cache persistence, as it stores all the BuildKit state and related cache into a dedicated Docker volume.\n\nTo persist the `docker-container` driver's cache, even after recreating the driver using `docker buildx rm` and `docker buildx create`, you can destroy the builder using the `--keep-state` flag:\n\nFor example, to create a builder named `container` and then remove it while persisting state:\n\nThe `docker-container` driver supports using [QEMU](https://www.qemu.org/) (user mode) to build non-native platforms. Use the `--platform` flag to specify which architectures that you want to build for.\n\nFor example, to build a Linux image for `amd64` and `arm64`:\n\n> **Note**\n> \n> Emulation with QEMU can be much slower than native builds, especially for compute-heavy tasks like compilation and compression or decompression.\n\nYou can customize the network that the builder container uses. This is useful if you need to use a specific network for your builds.\n\nFor example, let's [create a network](https://docs.docker.com/reference/cli/docker/network/create/) named `foonet`:\n\nNow create a [`docker-container` builder](https://docs.docker.com/reference/cli/docker/buildx/create/) that will use this network:\n\nBoot and [inspect `mybuilder`](https://docs.docker.com/reference/cli/docker/buildx/inspect/):\n\n[Inspect the builder container](https://docs.docker.com/reference/cli/docker/inspect/) and see what network is being used:\n\nFor more information on the Docker container driver, see the [buildx reference](https://docs.docker.com/reference/cli/docker/buildx/create/#driver).",
  "title": "Docker container build driver | Docker Docs\n",
  "description": "The Docker container driver runs BuildKit in a container image.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/24.0/",
  "markdown": "# Docker Engine 24.0 release notes\n\nThis page describes the latest changes, additions, known issues, and fixes for Docker Engine version 24.0.\n\nFor more information about:\n\n*   Deprecated and removed features, see [Deprecated Engine Features](https://docs.docker.com/engine/deprecated/).\n*   Changes to the Engine API, see [Engine API version history](https://docs.docker.com/engine/api/version-history/).\n\n_2024-01-31_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.9 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.9)\n*   [moby/moby, 24.0.9 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.9)\n\nThis release contains security fixes for the following CVEs affecting Docker Engine and its components.\n\n| CVE | Component | Fix version | Severity |\n| --- | --- | --- | --- |\n| [CVE-2024-21626](https://scout.docker.com/v/CVE-2024-21626) | runc | 1.1.12 | High, CVSS 8.6 |\n| [CVE-2024-24557](https://scout.docker.com/v/CVE-2024-24557) | Docker Engine | 24.0.9 | Medium, CVSS 6.9 |\n\n> **Important**\n> \n> Note that this release of Docker Engine doesn't include fixes for the following known vulnerabilities in BuildKit:\n> \n> *   [CVE-2024-23651](https://scout.docker.com/v/CVE-2024-23651)\n> *   [CVE-2024-23652](https://scout.docker.com/v/CVE-2024-23652)\n> *   [CVE-2024-23653](https://scout.docker.com/v/CVE-2024-23653)\n> *   [CVE-2024-23650](https://scout.docker.com/v/CVE-2024-23650)\n> \n> To address these vulnerabilities, upgrade to [Docker Engine v25.0.2](https://docs.docker.com/engine/release-notes/25.0/#2502).\n\nFor more information about the security issues addressed in this release, and the unaddressed vulnerabilities in BuildKit, refer to the [blog post](https://www.docker.com/blog/docker-security-advisory-multiple-vulnerabilities-in-runc-buildkit-and-moby/).\n\nFor details about each vulnerability, see the relevant security advisory:\n\n*   [CVE-2024-21626](https://github.com/opencontainers/runc/security/advisories/GHSA-xr7r-f8xq-vfvv)\n*   [CVE-2024-24557](https://github.com/moby/moby/security/advisories/GHSA-xw73-rw38-6vjc)\n\n### [Packaging updates](#packaging-updates)\n\n*   Upgrade runc to [v1.1.12](https://github.com/opencontainers/runc/releases/tag/v1.1.12). [moby/moby#47269](https://github.com/moby/moby/pull/47269)\n*   Upgrade containerd to [v1.7.13](https://github.com/containerd/containerd/releases/tag/v1.7.13) (static binaries only). [moby/moby#47280](https://github.com/moby/moby/pull/47280)\n\n_2024-01-25_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.8 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.8)\n*   [moby/moby, 24.0.8 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.8)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements)\n\n*   Live restore: Containers with auto remove (`docker run --rm`) are no longer forcibly removed on engine restart. [moby/moby#46857](https://github.com/moby/moby/pull/46869)\n\n### [Packaging updates](#packaging-updates-1)\n\n*   Upgrade Go to `go1.20.13`. [moby/moby#47054](https://github.com/moby/moby/pull/47054), [docker/cli#4826](https://github.com/docker/cli/pull/4826), [docker/docker-ce-packaging#975](https://github.com/docker/docker-ce-packaging/pull/975)\n*   Upgrade containerd (static binaries only) to [v1.7.12](https://github.com/containerd/containerd/releases/tag/v1.7.12) [moby/moby#47096](https://github.com/moby/moby/pull/47096)\n*   Upgrade runc to v1.1.11. [moby/moby#47010](https://github.com/moby/moby/pull/47010)\n\n_2023-10-27_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.7 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.7)\n*   [moby/moby, 24.0.7 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.7)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-1)\n\n*   Write overlay2 layer metadata atomically. [moby/moby#46703](https://github.com/moby/moby/pull/46703)\n*   Fix \"Rootful-in-Rootless\" Docker-in-Docker on systemd version 250 and later. [moby/moby#46626](https://github.com/moby/moby/pull/46626)\n*   Fix `dockerd-rootless-setuptools.sh` when username contains a backslash. [moby/moby#46407](https://github.com/moby/moby/pull/46407)\n*   Fix a bug that would prevent network sandboxes to be fully deleted when stopping containers with no network attachments and when `dockerd --bridge=none` is used. [moby/moby#46702](https://github.com/moby/moby/pull/46702)\n*   Fix a bug where cancelling an API request could interrupt container restart. [moby/moby#46697](https://github.com/moby/moby/pull/46697)\n*   Fix an issue where containers would fail to start when providing `--ip-range` with a range larger than the subnet. [docker/for-mac#6870](https://github.com/docker/for-mac/issues/6870)\n*   Fix data corruption with zstd output. [moby/moby#46709](https://github.com/moby/moby/pull/46709)\n*   Fix the conditions under which the container's MAC address is applied. [moby/moby#46478](https://github.com/moby/moby/pull/46478)\n*   Improve the performance of the stats collector. [moby/moby#46448](https://github.com/moby/moby/pull/46448)\n*   Fix an issue with source policy rules ending up in the wrong order. [moby/moby#46441](https://github.com/moby/moby/pull/46441)\n\n### [Packaging updates](#packaging-updates-2)\n\n*   Add support for Fedora 39 and Ubuntu 23.10. [docker/docker-ce-packaging#940](https://github.com/docker/docker-ce-packaging/pull/940), [docker/docker-ce-packaging#955](https://github.com/docker/docker-ce-packaging/pull/955)\n*   Fix `docker.socket` not getting disabled when uninstalling the `docker-ce` RPM package. [docker/docker-ce-packaging#852](https://github.com/docker/docker-ce-packaging/pull/852)\n*   Upgrade Go to `go1.20.10`. [docker/docker-ce-packaging#951](https://github.com/docker/docker-ce-packaging/pull/951)\n*   Upgrade containerd to `v1.7.6` (static binaries only). [moby/moby#46103](https://github.com/moby/moby/pull/46103)\n*   Upgrade the `containerd.io` package to [`v1.6.24`](https://github.com/containerd/containerd/releases/tag/v1.6.24).\n\n### [Security](#security-1)\n\n*   Deny containers access to `/sys/devices/virtual/powercap` by default. This change hardens against [CVE-2020-8694](https://scout.docker.com/v/CVE-2020-8694), [CVE-2020-8695](https://scout.docker.com/v/CVE-2020-8695), and [CVE-2020-12912](https://scout.docker.com/v/CVE-2020-12912), and an attack known as [the PLATYPUS attack](https://platypusattack.com/).\n    \n    For more details, see [advisory](https://github.com/moby/moby/security/advisories/GHSA-jq35-85cj-fj4p), [commit](https://github.com/moby/moby/commit/c9ccbfad11a60e703e91b6cca4f48927828c7e35).\n    \n\n_2023-09-05_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.6 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.6)\n*   [moby/moby, 24.0.6 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.6)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-2)\n\n*   containerd storage backend: Fix `docker ps` failing when a container image is no longer present in the content store. [moby/moby#46095](https://github.com/moby/moby/pull/46095)\n*   containerd storage backend: Fix `docker ps -s -a` and `docker container prune` failing when a container image config is no longer present in the content store. [moby/moby#46097](https://github.com/moby/moby/pull/46097)\n*   containerd storage backend: Fix `docker inspect` failing when a container image config is no longer (or was never) present in the content store. [moby/moby#46244](https://github.com/moby/moby/pull/46244)\n*   containerd storage backend: Fix diff and export with the `overlayfs` snapshotter by using reference-counted rootfs mounts. [moby/moby#46266](https://github.com/moby/moby/pull/46266)\n*   containerd storage backend: Fix a misleading error message when the image platforms available locally do not match the desired platform. [moby/moby#46300](https://github.com/moby/moby/pull/46300)\n*   containerd storage backend: Fix the `FROM scratch` Dockerfile instruction with the classic builder. [moby/moby#46302](https://github.com/moby/moby/pull/46302)\n*   containerd storage backend: Fix `mismatched image rootfs and manifest layers` errors with the classic builder. [moby/moby#46310](https://github.com/moby/moby/pull/46310)\n*   Warn when pulling Docker Image Format v1, and Docker Image manifest version 2, schema 1 images from all registries. [moby/moby#46290](https://github.com/moby/moby/pull/46290)\n*   Fix live-restore of volumes with custom volume options. [moby/moby#46366](https://github.com/moby/moby/pull/46366)\n*   Fix incorrectly dropping capabilities bits when running a container as a non-root user (note: this change was already effectively present due to a regression). [moby/moby#46221](https://github.com/moby/moby/pull/46221)\n*   Fix network isolation iptables rules preventing IPv6 Neighbor Solicitation packets from being exchanged between containers. [moby/moby#46214](https://github.com/moby/moby/pull/46214)\n*   Fix `dockerd.exe --register-service` not working when the binary is in the current directory on Windows. [moby/moby#46215](https://github.com/moby/moby/pull/46215)\n*   Add a hint suggesting the use of a PAT to `docker login` against Docker Hub. [docker/cli#4500](https://github.com/docker/cli/pull/4500)\n*   Improve shell startup time for users of Bash completion for the CLI. [docker/cli#4517](https://github.com/docker/cli/pull/4517)\n*   Improve the speed of some commands by skipping `GET /_ping` when possible. [docker/cli#4508](https://github.com/docker/cli/pull/4508)\n*   Fix credential scopes when using a PAT to `docker manifest inspect` an image on Docker Hub. [docker/cli#4512](https://github.com/docker/cli/pull/4512)\n*   Fix `docker events` not supporting `--format=json`. [docker/cli#4544](https://github.com/docker/cli/pull/4544)\n\n### [Packaging updates](#packaging-updates-3)\n\n*   Upgrade Go to `go1.20.7`. [moby/moby#46140](https://github.com/moby/moby/pull/46140), [docker/cli#4476](https://github.com/docker/cli/pull/4476), [docker/docker-ce-packaging#932](https://github.com/docker/docker-ce-packaging/pull/932)\n*   Upgrade containerd to `v1.7.3` (static binaries only). [moby/moby#46103](https://github.com/moby/moby/pull/46103)\n*   Upgrade Compose to `v2.21.0`. [docker/docker-ce-packaging#936](https://github.com/docker/docker-ce-packaging/pull/936)\n\n_2023-07-24_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.5 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.5)\n*   [moby/moby, 24.0.5 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.5)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-3)\n\n*   The Go client now avoids using UNIX socket paths in the HTTP `Host:` header, in order to be compatible with changes introduced in `go1.20.6`. [moby/moby#45962](https://github.com/moby/moby/pull/45962), [moby/moby#45990](https://github.com/moby/moby/pull/45990)\n*   containerd storage backend: Fix `Variant` not being included in `docker image inspect` and `GET /images/{name}/json`. [moby/moby#46025](https://github.com/moby/moby/pull/46025)\n*   containerd storage backend: Prevent potential garbage collection of content during image export. [moby/moby#46021](https://github.com/moby/moby/pull/46021)\n*   containerd storage backend: Prevent duplicate digest entries in `RepoDigests`. [moby/moby#46014](https://github.com/moby/moby/pull/46014)\n*   containerd storage backend: Fix operations taking place against the incorrect tag when working with an image referenced by tag and digest. [moby/moby#46013](https://github.com/moby/moby/pull/46013)\n*   containerd storage backend: Fix a panic caused by `EXPOSE` when building containers with the legacy builder. [moby/moby#45921](https://github.com/moby/moby/pull/45921)\n*   Fix a regression causing unintuitive errors to be returned when attempting to create an `overlay` network on a non-Swarm node. [moby/moby#45974](https://github.com/moby/moby/pull/45974)\n*   Properly report errors parsing volume specifications from the command line. [docker/cli#4423](https://github.com/docker/cli/pull/4423)\n*   Fix a panic caused when `auths: null` is found in the CLI config file. [docker/cli#4450](https://github.com/docker/cli/pull/4450)\n\n### [Packaging updates](#packaging-updates-4)\n\n*   Use init scripts as provided by in moby/moby `contrib/init`. [docker/docker-ce-packaging#914](https://github.com/docker/docker-ce-packaging/pull/914), [docker/docker-ce-packaging#926](https://github.com/docker/docker-ce-packaging/pull/926)\n*   Drop Upstart from `contrib/init`. [moby/moby#46044](https://github.com/moby/moby/pull/46044)\n*   Upgrade Go to `go1.20.6`. [docker/cli#4428](https://github.com/docker/cli/pull/4428), [moby/moby#45970](https://github.com/moby/moby/pull/45970), [docker/docker-ce-packaging#921](https://github.com/docker/docker-ce-packaging/pull/921)\n*   Upgrade Compose to `v2.20.2`. [docker/docker-ce-packaging#924](https://github.com/docker/docker-ce-packaging/pull/924)\n*   Upgrade buildx to `v0.11.2`. [docker/docker-ce-packaging#922](https://github.com/docker/docker-ce-packaging/pull/922)\n\n_2023-07-07_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.4 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.4)\n*   [moby/moby, 24.0.4 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.4)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-4)\n\n*   Fix a regression introduced during 24.0.3 that causes a panic during live-restore of containers with bind mounts. [moby/moby#45903](https://github.com/moby/moby/pull/45903)\n\n_2023-07-06_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.3 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.3)\n*   [moby/moby, 24.0.3 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.3)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-5)\n\n*   containerd image store: Fix an issue where multi-platform images that did not include a manifest for the default platform could not be interacted with. [moby/moby#45849](https://github.com/moby/moby/pull/45849)\n*   containerd image store: Fix specious attempts to cache `FROM scratch` in container builds. [moby/moby#45822](https://github.com/moby/moby/pull/45822)\n*   containerd image store: Fix `docker cp` with snapshotters that cannot mount the same content multiple times. [moby/moby#45780](https://github.com/moby/moby/pull/45780), [moby/moby#45786](https://github.com/moby/moby/pull/45786)\n*   containerd image store: Fix builds with `type=image` not being correctly unpacked/stored. [moby/moby#45692](https://github.com/moby/moby/pull/45692)\n*   containerd image store: Fix incorrectly attempting to unpack pseudo-images (including attestations) in `docker load`. [moby/moby#45688](https://github.com/moby/moby/pull/45688)\n*   containerd image store: Correctly set the user agent, and include additional information like the snapshotter when interacting with registries. [moby/moby#45671](https://github.com/moby/moby/pull/45671), [moby/moby#45684](https://github.com/moby/moby/pull/45684)\n*   containerd image store: Fix a failure to unpack already-pulled content after switching between snapshotters. [moby/moby#45678](https://github.com/moby/moby/pull/45678)\n*   containerd image store: Fix images that have been re-tagged or with all tags removed being pruned while still in use. [moby/moby#45857](https://github.com/moby/moby/pull/45857)\n*   Fix a Swarm CSI issue where the Topology field was not propagated into NodeCSIInfo. [moby/moby#45810](https://github.com/moby/moby/pull/45810)\n*   Fix failures to add new Swarm managers caused by a very large raft log. [moby/moby#45703](https://github.com/moby/moby/pull/45703), [moby/swarmkit#3122](https://github.com/moby/swarmkit/pull/3122), [moby/swarmkit#3128](https://github.com/moby/swarmkit/pull/3128)\n*   `name_to_handle_at(2)` is now always allowed in the default seccomp profile. [moby/moby#45833](https://github.com/moby/moby/pull/45833)\n*   Fix an issue that prevented encrypted Swarm overlay networks from working on ports other than the default (4789). [moby/moby#45637](https://github.com/moby/moby/pull/45637)\n*   Fix a failure to restore mount reference-counts during live-restore. [moby/moby#45824](https://github.com/moby/moby/pull/45824)\n*   Fix various networking-related failures during live-restore. [moby/moby#45658](https://github.com/moby/moby/pull/45658), [moby/moby#45659](https://github.com/moby/moby/pull/45659)\n*   Fix running containers restoring with a zero (successful) exit status when the daemon is unexpectedly terminated. [moby/moby#45801](https://github.com/moby/moby/pull/45801)\n*   Fix a potential panic while executing healthcheck probes. [moby/moby#45798](https://github.com/moby/moby/pull/45798)\n*   Fix a panic caused by a race condition in container exec start. [moby/moby#45794](https://github.com/moby/moby/pull/45794)\n*   Fix an exception caused by attaching a terminal to an exec with a non-existent command. [moby/moby#45643](https://github.com/moby/moby/pull/45643)\n*   Fix `host-gateway` with BuildKit by passing the IP as a label (also requires [docker/buildx#1894](https://github.com/docker/buildx/pull/1894)). [moby/moby#45790](https://github.com/moby/moby/pull/45790)\n*   Fix an issue where `POST /containers/{id}/stop` would forcefully terminate the container when the request was canceled, instead of waiting until the specified timeout for a 'graceful' stop. [moby/moby#45774](https://github.com/moby/moby/pull/45774)\n*   Fix an issue where `docker cp -a` from the root (`/`) directory would fail. [moby/moby#45748](https://github.com/moby/moby/pull/45748)\n*   Improve compatibility with non-runc container runtimes by more correctly setting resource constraint parameters in the OCI config. [moby/moby#45746](https://github.com/moby/moby/pull/45746)\n*   Fix an issue caused by overlapping subuid/subgid ranges in certain configurations (e.g. LDAP) in rootless mode. [moby/moby#45747](https://github.com/moby/moby/pull/45747), [rootless-containers/rootlesskit#369](https://github.com/rootless-containers/rootlesskit/pull/369)\n*   Greatly reduce CPU and memory usage while populating the Debug section of `GET /info`. [moby/moby#45856](https://github.com/moby/moby/pull/45856)\n*   Fix an issue where debug information was not correctly printed during `docker info` when only the client is in debug mode. [docker/cli#4393](https://github.com/docker/cli/pull/4393)\n*   Fix issues related to hung connections when connecting to hosts over a SSH connection. [docker/cli#4395](https://github.com/docker/cli/pull/4395)\n\n### [Packaging updates](#packaging-updates-5)\n\n*   Upgrade Go to `go1.20.5`. [moby/moby#45745](https://github.com/moby/moby/pull/45745), [docker/cli#4351](https://github.com/docker/cli/pull/4351), [docker/docker-ce-packaging#904](https://github.com/docker/docker-ce-packaging/pull/904)\n*   Upgrade Compose to `v2.19.1`. [docker/docker-ce-packaging#916](https://github.com/docker/docker-ce-packaging/pull/916)\n*   Upgrade buildx to `v0.11.1`. [docker/docker-ce-packaging#918](https://github.com/docker/docker-ce-packaging/pull/918)\n\n_2023-05-26_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.2 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.2)\n*   [moby/moby, 24.0.2 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.2)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-6)\n\n*   Fix a panic during build when referencing locally tagged images. [moby/buildkit#3899](https://github.com/moby/buildkit/pull/3899), [moby/moby#45582](https://github.com/moby/moby/pull/45582)\n*   Fix builds potentially failing with `exit code: 4294967295` when performing many concurrent build stages. [moby/moby#45620](https://github.com/moby/moby/pull/45620)\n*   Fix DNS resolution on Windows ignoring `etc/hosts` (`%WINDIR%\\System32\\Drivers\\etc\\hosts`), including resolution of `localhost`. [moby/moby#45562](https://github.com/moby/moby/pull/45562)\n*   Apply a workaround for a containerd bug that causes concurrent `docker exec` commands to take significantly longer than expected. [moby/moby#45625](https://github.com/moby/moby/pull/45625)\n*   containerd image store: Fix an issue where the image `Created` field would contain an incorrect value. [moby/moby#45623](https://github.com/moby/moby/pull/45623)\n*   containerd image store: Adjust the output of image pull progress so that the output has the same format regardless of whether the containerd image store is enabled. [moby/moby#45602](https://github.com/moby/moby/pull/45602)\n*   containerd image store: Switching between the default and containerd image store now requires a daemon restart. [moby/moby#45616](https://github.com/moby/moby/pull/45616)\n\n### [Packaging updates](#packaging-updates-6)\n\n*   Upgrade Buildx to `v0.10.5`. [docker/docker-ce-packaging#900](https://github.com/docker/docker-ce-packaging/pull/900)\n\n_2023-05-19_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.1 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.1)\n*   [moby/moby, 24.0.1 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.1)\n\n### [Removed](#removed)\n\n*   Remove CLI completions for storage drivers removed in the 24.0 major release. [docker/cli#4302](https://github.com/docker/cli/pull/4302)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-7)\n\n*   Fix an issue where DNS query NXDOMAIN replies from external servers were forwarded to the client as SERVFAIL. [moby/moby#45573](https://github.com/moby/moby/pull/45573)\n*   Fix an issue where `docker pull --platform` would report `No such image` regarding another tag pointing to the same image. [moby/moby#45562](https://github.com/moby/moby/pull/45562)\n*   Fix an issue where insecure registry configuration would be forgotten during config reload. [moby/moby#45571](https://github.com/moby/moby/pull/45571)\n*   containerd image store: Fix an issue where images which have no layers would not be listed in `docker images -a` [moby/moby#45588](https://github.com/moby/moby/pull/45588)\n*   API: Fix an issue where `GET /images/{id}/json` would return `null` instead of empty `RepoTags` and `RepoDigests`. [moby/moby#45564](https://github.com/moby/moby/pull/45564)\n*   API: Fix an issue where `POST /commit` did not accept an empty request body. [moby/moby#45568](https://github.com/moby/moby/pull/45568)\n\n### [Packaging updates](#packaging-updates-7)\n\n*   Upgrade Compose to `v2.18.1`. [docker/docker-ce-packaging#896](https://github.com/docker/docker-ce-packaging/pull/896)\n\n_2023-05-16_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.0 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.0)\n*   [moby/moby, 24.0.0 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.0)\n\n### [New](#new)\n\n*   Introduce experimental support for containerd as the content store (replacing the existing storage drivers). [moby/moby#43735](https://github.com/moby/moby/pull/43735), [other moby/moby pull requests](https://github.com/moby/moby/pulls?q=is%3Apr+is%3Amerged+milestone%3A24.0.0+-label%3Aprocess%2Fcherry-picked+label%3Acontainerd-integration+)\n*   The `--host` CLI flag now supports a path component in a `ssh://` host address, allowing use of an alternate socket path without configuration on the remote host. [docker/cli#4073](https://github.com/docker/cli/pull/4073)\n*   The `docker info` CLI command now reports a version and platform field. [docker/cli#4180](https://github.com/docker/cli/pull/4180)\n*   Introduce the daemon flag `--default-network-opt` to configure options for newly created networks. [moby/moby#43197](https://github.com/moby/moby/pull/43197)\n*   Restrict access to `AF_VSOCK` in the `socket(2)` family of syscalls in the default seccomp profile. [moby/moby#44562](https://github.com/moby/moby/pull/44562)\n*   Introduce support for setting OCI runtime annotations on containers. [docker/cli#45025](https://github.com/docker/cli/pull/4156), [moby/moby#45025](https://github.com/moby/moby/pull/45025)\n*   Alternative runtimes can now be configured in `daemon.json`, enabling runtime names to be aliased and options to be passed. [moby/moby#45032](https://github.com/moby/moby/pull/45032)\n*   The `docker-init` binary will now be discovered in FHS-compliant libexec directories, in addition to the `PATH`. [moby/moby#45198](https://github.com/moby/moby/pull/45198)\n*   API: Surface the daemon-level `--no-new-privileges` in `GET /info`. [moby/moby#45320](https://github.com/moby/moby/pull/45320)\n\n### [Removed](#removed-1)\n\n*   `docker info` no longer reports `IndexServiceAddress`. [docker/cli#4204](https://github.com/docker/cli/pull/4204)\n*   libnetwork: Remove fallback code for obsolete kernel versions. [moby/moby#44684](https://github.com/moby/moby/pull/44684), [moby/moby#44802](https://github.com/moby/moby/pull/44802)\n*   libnetwork: Remove unused code related to classic Swarm. [moby/moby#44965](https://github.com/moby/moby/pull/44965)\n*   libnetwork: Remove usage of the `xt_u32` kernel module from encrypted Swarm overlay networks. [moby/moby#45281](https://github.com/moby/moby/pull/45281)\n*   Remove support for BuildKit's deprecated `buildinfo` in favor of standard provenance attestations. [moby/moby#45097](https://github.com/moby/moby/pull/45097)\n*   Remove the deprecated AUFS and legacy `overlay` storage drivers. [moby/moby#45342](https://github.com/moby/moby/pull/45342), [moby/moby#45359](https://github.com/moby/moby/pull/45359)\n*   Remove the deprecated `overlay2.override_kernel_check` storage driver option. [moby/moby#45368](https://github.com/moby/moby/pull/45368)\n*   Remove workarounds for obsolete versions of `apparmor_parser` from the AppArmor profiles. [moby/moby#45500](https://github.com/moby/moby/pull/45500)\n*   API: `GET /images/json` no longer represents empty RepoTags and RepoDigests as`<none>:<none>`/`<none>@<none>`. Empty arrays are returned instead on API >= 1.43. [moby/moby#45068](https://github.com/moby/moby/pull/45068)\n\n### [Deprecated](#deprecated)\n\n*   Deprecate the `--oom-score-adjust` daemon option. [moby/moby#45315](https://github.com/moby/moby/pull/45315)\n*   API: Deprecate the `VirtualSize` field in `GET /images/json` and `GET /images/{id}/json`. [moby/moby#45346](https://github.com/moby/moby/pull/45346)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-8)\n\n*   The `docker stack` command no longer validates the `build` section of Compose files. [docker/cli#4214](https://github.com/docker/cli/pull/4214)\n*   Fix lingering healthcheck processes after the timeout is reached. [moby/moby#43739](https://github.com/moby/moby/pull/43739)\n*   Reduce the overhead of container startup when using the `overlay2` storage driver. [moby/moby#44285](https://github.com/moby/moby/pull/44285)\n*   API: Handle multiple `before=` and `since=` filters in `GET /images`. [moby/moby#44503](https://github.com/moby/moby/pull/44503)\n*   Fix numerous bugs in the embedded DNS resolver implementation used by user-defined networks. [moby/moby#44664](https://github.com/moby/moby/pull/44664)\n*   Add `execDuration` field to the map of event attributes. [moby/moby#45494](https://github.com/moby/moby/pull/45494)\n*   Swarm-level networks can now be created with the Windows `internal`, `l2bridge`, and `nat` drivers. [moby/swarmkit#3121](https://github.com/moby/swarmkit/pull/3121), [moby/moby#45291](https://github.com/moby/moby/pull/45291)\n\n### [Packaging updates](#packaging-updates-8)\n\n*   Update Go to `1.20.4`. [docker/cli#4253](https://github.com/docker/cli/pull/4253), [moby/moby#45456](https://github.com/moby/moby/pull/45456), [docker/docker-ce-packaging#888](https://github.com/docker/docker-ce-packaging/pull/888)\n*   Update `containerd` to [`v1.7.1`](https://github.com/containerd/containerd/releases/tag/v1.7.1). [moby/moby#45537](https://github.com/moby/moby/pull/45537)\n*   Update `buildkit` to [`v0.11.6`](https://github.com/moby/buildkit/releases/v0.11.6). [moby/moby#45367](https://github.com/moby/moby/pull/45367)",
  "title": "Docker Engine 24.0 release notes | Docker Docs\n",
  "description": "Learn about the new features, bug fixes, and breaking changes for Docker Engine",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/extend/plugins_logging/",
  "markdown": "# Docker log driver plugins | Docker Docs\n\nThis document describes logging driver plugins for Docker.\n\nLogging drivers enables users to forward container logs to another service for processing. Docker includes several logging drivers as built-ins, however can never hope to support all use-cases with built-in drivers. Plugins allow Docker to support a wide range of logging services without requiring to embed client libraries for these services in the main Docker codebase. See the [plugin documentation](https://docs.docker.com/engine/extend/legacy_plugins/) for more information.\n\nThe main interface for logging plugins uses the same JSON+HTTP RPC protocol used by other plugin types. See the [example](https://github.com/cpuguy83/docker-log-driver-test) plugin for a reference implementation of a logging plugin. The example wraps the built-in `jsonfilelog` log driver.\n\nLogging plugins must register as a `LogDriver` during plugin activation. Once activated users can specify the plugin as a log driver.\n\nThere are two HTTP endpoints that logging plugins must implement:\n\n### [`/LogDriver.StartLogging`](#logdriverstartlogging)\n\nSignals to the plugin that a container is starting that the plugin should start receiving logs for.\n\nLogs will be streamed over the defined file in the request. On Linux this file is a FIFO. Logging plugins are not currently supported on Windows.\n\nRequest:\n\n`File` is the path to the log stream that needs to be consumed. Each call to `StartLogging` should provide a different file path, even if it's a container that the plugin has already received logs for prior. The file is created by Docker with a randomly generated name.\n\n`Info` is details about the container that's being logged. This is fairly free-form, but is defined by the following struct definition:\n\n`ContainerID` will always be supplied with this struct, but other fields may be empty or missing.\n\nResponse:\n\nIf an error occurred during this request, add an error message to the `Err` field in the response. If no error then you can either send an empty response (`{}`) or an empty value for the `Err` field.\n\nThe driver should at this point be consuming log messages from the passed in file. If messages are unconsumed, it may cause the container to block while trying to write to its stdio streams.\n\nLog stream messages are encoded as protocol buffers. The protobuf definitions are in the [moby repository](https://github.com/moby/moby/blob/master/api/types/plugins/logdriver/entry.proto).\n\nSince protocol buffers are not self-delimited you must decode them from the stream using the following stream format:\n\nWhere `size` is a 4-byte big endian binary encoded uint32. `size` in this case defines the size of the next message. `message` is the actual log entry.\n\nA reference golang implementation of a stream encoder/decoder can be found [here](https://github.com/docker/docker/blob/master/api/types/plugins/logdriver/io.go)\n\n### [`/LogDriver.StopLogging`](#logdriverstoplogging)\n\nSignals to the plugin to stop collecting logs from the defined file. Once a response is received, the file will be removed by Docker. You must make sure to collect all logs on the stream before responding to this request or risk losing log data.\n\nRequests on this endpoint does not mean that the container has been removed only that it has stopped.\n\nRequest:\n\nResponse:\n\nIf an error occurred during this request, add an error message to the `Err` field in the response. If no error then you can either send an empty response (`{}`) or an empty value for the `Err` field.\n\nLogging plugins can implement two extra logging endpoints:\n\n### [`/LogDriver.Capabilities`](#logdrivercapabilities)\n\nDefines the capabilities of the log driver. You must implement this endpoint for Docker to be able to take advantage of any of the defined capabilities.\n\nRequest:\n\nResponse:\n\nSupported capabilities:\n\n*   `ReadLogs` - this tells Docker that the plugin is capable of reading back logs to clients. Plugins that report that they support `ReadLogs` must implement the `/LogDriver.ReadLogs` endpoint\n\n### [`/LogDriver.ReadLogs`](#logdriverreadlogs)\n\nReads back logs to the client. This is used when `docker logs <container>` is called.\n\nIn order for Docker to use this endpoint, the plugin must specify as much when `/LogDriver.Capabilities` is called.\n\nRequest:\n\n`ReadConfig` is the list of options for reading, it is defined with the following golang struct:\n\n*   `Since` defines the oldest log that should be sent.\n*   `Tail` defines the number of lines to read (e.g. like the command `tail -n 10`)\n*   `Follow` signals that the client wants to stay attached to receive new log messages as they come in once the existing logs have been read.\n\n`Info` is the same type defined in `/LogDriver.StartLogging`. It should be used to determine what set of logs to read.\n\nResponse:\n\nThe response should be the encoded log message using the same format as the messages that the plugin consumed from Docker.",
  "title": "Docker log driver plugins | Docker Docs\n",
  "description": "Log driver plugins.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/",
  "markdown": "# Create a swarm | Docker Docs\n\nAfter you complete the [tutorial setup](https://docs.docker.com/engine/swarm/swarm-tutorial/) steps, you're ready to create a swarm. Make sure the Docker Engine daemon is started on the host machines.\n\n1.  Open a terminal and ssh into the machine where you want to run your manager node. This tutorial uses a machine named `manager1`.\n    \n2.  Run the following command to create a new swarm:\n    \n    In the tutorial, the following command creates a swarm on the `manager1` machine:\n    \n    The `--advertise-addr` flag configures the manager node to publish its address as `192.168.99.100`. The other nodes in the swarm must be able to access the manager at the IP address.\n    \n    The output includes the commands to join new nodes to the swarm. Nodes will join as managers or workers depending on the value for the `--token` flag.\n    \n3.  Run `docker info` to view the current state of the swarm:\n    \n4.  Run the `docker node ls` command to view information about nodes:\n    \n    The `*` next to the node ID indicates that you're currently connected on this node.\n    \n    Docker Engine Swarm mode automatically names the node with the machine host name. The tutorial covers other columns in later steps.\n    \n\nNext, you'll add two more nodes to the cluster.",
  "title": "Create a swarm | Docker Docs\n",
  "description": "Initialize the swarm",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/23.0/",
  "markdown": "# Docker Engine 23.0 release notes\n\n> **Note**\n> \n> From Docker Engine version 23.0.0, Buildx is distributed in a separate package: `docker-buildx-plugin`. In earlier versions, Buildx was included in the `docker-ce-cli` package. When you upgrade to this version of Docker Engine, make sure you update all packages. For example, on Ubuntu:\n> \n> Refer to the [Docker Engine installation instructions](https://docs.docker.com/engine/install/) for your operating system for more details on upgrading Docker Engine.\n\nThis page describes the latest changes, additions, known issues, and fixes for Docker Engine version 23.0.\n\nFor more information about:\n\n*   Deprecated and removed features, see [Deprecated Engine Features](https://docs.docker.com/engine/deprecated/).\n*   Changes to the Engine API, see [Engine API version history](https://docs.docker.com/engine/api/version-history/).\n\nStarting with the 23.0.0 release, Docker Engine moves away from using CalVer versioning, and starts using the [SemVer versioning format](https://semver.org/). Changing the version format is a stepping-stone towards Go module compatibility, but the repository doesn't yet use Go modules, and still requires using a \"+incompatible\" version. Work continues towards Go module compatibility in a future release.\n\n_2023-05-08_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 23.0.6 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A23.0.6)\n*   [moby/moby, 23.0.6 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A23.0.6)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements)\n\n*   Fix vfs storage driver not working on NFS. [moby/moby#45465](https://github.com/moby/moby/pull/45465)\n\n### [Packaging Updates](#packaging-updates)\n\n*   Upgrade Go to `1.19.9`. [docker/docker-ce-packaging#889](https://github.com/docker/docker-ce-packaging/pull/889), [docker/cli#4254](https://github.com/docker/cli/pull/4254), [moby/moby#45455](https://github.com/moby/moby/pull/45455)\n*   Upgrade `containerd` to [v1.6.21](https://github.com/containerd/containerd/releases/tag/v1.6.21)\n*   Upgrade `runc` to [v1.1.7](https://github.com/opencontainers/runc/releases/tag/v1.1.7)\n\n_2023-04-26_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 23.0.5 milestone](https://github.com/docker/cli/milestone/79?closed=1)\n*   [moby/moby, 23.0.5 milestone](https://github.com/moby/moby/milestone/118?closed=1)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-1)\n\n*   Add the `--all` / `-a` option when pruning volumes. [docker/cli#4229](https://github.com/docker/cli/pull/4229)\n*   Add `--format=json` for `docker info`. [docker/cli#4320](https://github.com/docker/cli/pull/4230)\n*   Fix log loss with the AWSLogs log driver. [moby/moby#45350](https://github.com/moby/moby/pull/45350)\n*   Fix a regression introduced in v23.0.4 where dockerd would refuse to start if the fixed-cidr config parameter is provided but not bip. [moby/moby#45403](https://github.com/moby/moby/pull/45403)\n*   Fix a panic in libnetwork during daemon start [moby/moby#45376](https://github.com/moby/moby/pull/45376)\n*   Fix \"tag\" event not being sent when an image is built with `buildx`. [moby/moby#45410](https://github.com/moby/moby/pull/45410)\n\n### [Packaging Updates](#packaging-updates-1)\n\n*   Upgrade Compose to `2.17.3`. [docker/docker-ce-packaging#883](https://github.com/docker/docker-ce-packaging/pull/883)\n\n_2023-04-17_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 23.0.4 milestone](https://github.com/docker/cli/milestone/77?closed=1)\n*   [moby/moby, 23.0.4 milestone](https://github.com/moby/moby/milestone/117?closed=1)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-2)\n\n*   Fix a performance regression in Docker CLI 23.0.0 [docker/cli#4141](https://github.com/docker/cli/pull/4141).\n*   Fix progress indicator on `docker cp` not functioning as intended [docker/cli#4157](https://github.com/docker/cli/pull/4157).\n*   Fix shell completion for `docker compose --file` [docker/cli#4177](https://github.com/docker/cli/pull/4177).\n*   Fix an error caused by incorrect handling of \"default-address-pools\" in `daemon.json` [moby/moby#45246](https://github.com/moby/moby/pull/45246).\n\n### [Packaging Updates](#packaging-updates-2)\n\n*   Fix missing packages for CentOS 9 Stream.\n*   Upgrade Go to `1.19.8`. [docker/docker-ce-packaging#878](https://github.com/docker/docker-ce-packaging/pull/878), [docker/cli#4164](https://github.com/docker/cli/pull/4164), [moby/moby#45277](https://github.com/moby/moby/pull/45277), which contains fixes for [CVE-2023-24537](https://github.com/advisories/GHSA-fp86-2355-v99r), [CVE-2023-24538](https://github.com/advisories/GHSA-v4m2-x4rp-hv22), [CVE-2023-24534](https://github.com/advisories/GHSA-8v5j-pwr7-w5f8), and [CVE-2023-24536](https://github.com/advisories/GHSA-9f7g-gqwh-jpf5)\n\n_2023-04-04_\n\n> **Note**\n> \n> Due to an issue with CentOS 9 Stream's package repositories, packages for CentOS 9 are currently unavailable. Packages for CentOS 9 may be added later, or as part of the next (23.0.4) patch release.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-3)\n\n*   Fixed a number of issues that can cause Swarm encrypted overlay networks to fail to uphold their guarantees, addressing [CVE-2023-28841](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-28841), [CVE-2023-28840](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-28840), and [CVE-2023-28842](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-28842).\n    *   A lack of kernel support for encrypted overlay networks now reports as an error.\n    *   Encrypted overlay networks are eagerly set up, rather than waiting for multiple nodes to attach.\n    *   Encrypted overlay networks are now usable on Red Hat Enterprise Linux 9 through the use of the `xt_bpf` kernel module.\n    *   Users of Swarm overlay networks should review [GHSA-vwm3-crmr-xfxw](https://github.com/moby/moby/security/advisories/GHSA-vwm3-crmr-xfxw) to ensure that unintentional exposure has not occurred.\n\n### [Packaging Updates](#packaging-updates-3)\n\n*   Upgrade `containerd` to [v1.6.20](https://github.com/containerd/containerd/releases/tag/v1.6.20).\n*   Upgrade `runc` to [v1.1.5](https://github.com/opencontainers/runc/releases/tag/v1.1.5).\n\n_2023-03-28_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 23.0.2 milestone](https://github.com/docker/cli/milestone/75?closed=1)\n*   [moby/moby, 23.0.2 milestone](https://github.com/moby/moby/milestone/114?closed=1)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-4)\n\n*   Fully resolve missing checks for `apparmor_parser` when an AppArmor enabled kernel is detected. [containerd/containerd#8087](https://github.com/containerd/containerd/pull/8087), [moby/moby#45043](https://github.com/moby/moby/pull/45043)\n*   Ensure that credentials are redacted from Git URLs when generating BuildKit buildinfo. Fixes [CVE-2023-26054](https://github.com/moby/buildkit/security/advisories/GHSA-gc89-7gcr-jxqc). [moby/moby#45110](https://github.com/moby/moby/pull/45110)\n*   Fix anonymous volumes created by a `VOLUME` line in a Dockerfile being excluded from volume prune. [moby/moby#45159](https://github.com/moby/moby/pull/45159)\n*   Fix a failure to properly propagate errors during removal of volumes on a Swarm node. [moby/moby#45155](https://github.com/moby/moby/pull/45155)\n*   Temporarily work around a bug in BuildKit `COPY --link` by disabling mergeop/diffop optimization. [moby/moby#45112](https://github.com/moby/moby/pull/45112)\n*   Properly clean up child tasks when a parent Swarm job is removed. [moby/swarmkit#3112](https://github.com/moby/swarmkit/pull/3112), [moby/moby#45107](https://github.com/moby/moby/pull/45107)\n*   Fix Swarm service creation logic so that both a GenericResource and a non-default network can be used together. [moby/swarmkit#3082](https://github.com/moby/swarmkit/pull/3082), [moby/moby#45107](https://github.com/moby/moby/pull/45107)\n*   Fix Swarm CSI support requiring the CSI plugin to offer staging endpoints in order to publish a volume. [moby/swarmkit#3116](https://github.com/moby/swarmkit/pull/3116), [moby/moby#45107](https://github.com/moby/moby/pull/45107)\n*   Fix a panic caused by log buffering in some configurations. [containerd/fifo#47](https://github.com/containerd/fifo/pull/47), [moby/moby#45051](https://github.com/moby/moby/pull/45051)\n*   Log errors in the REST to Swarm gRPC API translation layer at the debug level to reduce redundancy and noise. [moby/moby#45016](https://github.com/moby/moby/pull/45016)\n*   Fix a DNS resolution issue affecting containers created with `--dns-opt` or `--dns-search` when `systemd-resolved` is used outside the container. [moby/moby#45000](https://github.com/moby/moby/pull/45000)\n*   Fix a panic when logging errors in handling DNS queries originating from inside a container. [moby/moby#44980](https://github.com/moby/moby/pull/44980)\n*   Improve the speed of `docker ps` by allowing users to opt out of size calculations with `--size=false`. [docker/cli#4107](https://github.com/docker/cli/pull/4107)\n*   Extend support for Bash completion to all plugins. [docker/cli#4092](https://github.com/docker/cli/pull/4092)\n*   Fix `docker stack deploy` failing on Windows when special environment variables set by `cmd.exe` are present. [docker/cli#4083](https://github.com/docker/cli/pull/4083)\n*   Add forward compatibility for future API versions by considering empty image tags to be the same as `<none>`. [docker/cli#4065](https://github.com/docker/cli/pull/4065)\n*   Atomically write context files to greatly reduce the probability of corruption, and improve the error message for a corrupt context. [docker/cli#4063](https://github.com/docker/cli/pull/4063)\n\n### [Packaging](#packaging)\n\n*   Upgrade Go to `1.19.7`. [docker/docker-ce-packaging#857](https://github.com/docker/docker-ce-packaging/pull/857), [docker/cli#4086](https://github.com/docker/cli/pull/4086), [moby/moby#45137](https://github.com/moby/moby/pull/45137)\n*   Upgrade `containerd` to `v1.6.19`. [moby/moby#45084](https://github.com/moby/moby/pull/45084), [moby/moby#45099](https://github.com/moby/moby/pull/45099)\n*   Upgrade Buildx to `v0.10.4`. [docker/docker-ce-packaging#855](https://github.com/docker/docker-ce-packaging/pull/855)\n*   Upgrade Compose to `v2.17.2`. [docker/docker-ce-packaging#867](https://github.com/docker/docker-ce-packaging/pull/867)\n\n_2023-02-09_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 23.0.1 milestone](https://github.com/docker/cli/milestone/73?closed=1)\n*   [moby/moby, 23.0.1 milestone](https://github.com/moby/moby/milestone/113?closed=1)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-5)\n\n*   Fix containers not starting if the kernel has AppArmor enabled, but `apparmor_parser` is not available. [moby/moby#44942](https://github.com/moby/moby/pull/44942)\n*   Fix BuildKit-enabled builds with inline caching causing the daemon to crash. [moby/moby#44944](https://github.com/moby/moby/pull/44944)\n*   Fix BuildKit improperly loading cached layers created by previous versions. [moby/moby#44959](https://github.com/moby/moby/pull/44959)\n*   Fix an issue where `ipvlan` networks created prior to upgrading would prevent the daemon from starting. [moby/moby#44937](https://github.com/moby/moby/pull/44937)\n*   Fix the `overlay2` storage driver failing early in `metacopy` testing when initialized on an unsupported backing filesystem. [moby/moby#44922](https://github.com/moby/moby/pull/44922)\n*   Fix `exec` exit events being misinterpreted as container exits under some runtimes, such as Kata Containers. [moby/moby#44892](https://github.com/moby/moby/pull/44892)\n*   Improve the error message returned by the CLI when receiving a truncated JSON response caused by the API hanging up mid-request. [docker/cli#4004](https://github.com/docker/cli/pull/4004)\n*   Fix an incorrect CLI exit code when attempting to execute a directory with a `runc` compiled using Go 1.20. [docker/cli#4004](https://github.com/docker/cli/pull/4004)\n*   Fix mishandling the size argument to `--device-write-bps` as a path. [docker/cli#4004](https://github.com/docker/cli/pull/4004)\n\n### [Packaging](#packaging-1)\n\n*   Add `/etc/docker` to RPM and DEB packaging. [docker/docker-ce-packaging#842](https://github.com/docker/docker-ce-packaging/pull/842)\n    *   Not all use cases will benefit; if you depend on this, you should explicitly `mkdir -p /etc/docker`.\n*   Upgrade Compose to `v2.16.0`. [docker/docker-ce-packaging#844](https://github.com/docker/docker-ce-packaging/pull/844)\n\n_2023-02-01_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 23.0.0 milestone](https://github.com/docker/cli/milestone/51?closed=1)\n*   [moby/moby, 23.0.0 milestone](https://github.com/moby/moby/milestone/91?closed=1)\n\n### [New](#new)\n\n*   Set Buildx and BuildKit as the default builder on Linux. [moby/moby#43992](https://github.com/moby/moby/pull/43992)\n    *   Alias `docker build` to `docker buildx build`. [docker/cli#3314](https://github.com/docker/cli/pull/3314)\n    *   The legacy builder can still be used by explicitly setting `DOCKER_BUILDKIT=0`.\n    *   There are differences in how BuildKit and the legacy builder handle multi-stage builds. For more information, see [Multi-stage builds](https://docs.docker.com/build/building/multi-stage/#differences-between-legacy-builder-and-buildkit).\n*   Add support for pulling `zstd` compressed layers. [moby/moby#41759](https://github.com/moby/moby/pull/41759), [moby/moby#42862](https://github.com/moby/moby/pull/42862)\n*   Add support for alternate OCI runtimes on Linux, compatible with the containerd runtime v2 API. [moby/moby#43887](https://github.com/moby/moby/pull/43887), [moby/moby#43993](https://github.com/moby/moby/pull/43993)\n*   Add support for the containerd `runhcs` shim on Windows (off by default). [moby/moby#42089](https://github.com/moby/moby/pull/42089)\n*   Add `dockerd --validate` to check the daemon JSON config and exit. [moby/moby#42393](https://github.com/moby/moby/pull/42393)\n*   Add the ability to configure the daemon's HTTP proxy via flags or JSON config. [moby/moby#42835](https://github.com/moby/moby/pull/42835)\n*   Add support for RFC 3021 point-to-point networks (IPv4 /31s) and single hosts (IPv4 /32s). For networks with two or fewer addresses, IPAM won't reserve a network and broadcast address. [moby/moby#42626](https://github.com/moby/moby/pull/42626)\n*   Add support for setting `ipvlan_flag` and using the `l3s` `ipvlan_mode` in the `ipvlan` network driver. [moby/moby#42542](https://github.com/moby/moby/pull/42542)\n*   Add support for displaying the value of the `metacopy` option for the `overlay2` storage driver. [moby/moby#43557](https://github.com/moby/moby/pull/43557)\n*   Add support for describing Windows devices using the syntax `IDType://ID`. [moby/moby#43368](https://github.com/moby/moby/pull/43368)\n*   Add `RootlessKit`, `slirp4netns`, and `VPNKit` version reporting. [moby/moby#42330](https://github.com/moby/moby/pull/42330)\n*   Add experimental support for SwarmKit cluster volumes (CSI). [moby/moby#41982](https://github.com/moby/moby/pull/41982)\n    *   CLI: Add cluster volume (CSI) options to `docker volume`. [docker/cli#3606](https://github.com/docker/cli/pull/3606)\n    *   CLI: Add cluster volume (CSI) support to `docker stack`. [docker/cli#3662](https://github.com/docker/cli/pull/3662)\n*   Add support for SwarmKit jobs in `docker stack deploy`. [docker/cli#2907](https://github.com/docker/cli/pull/2907)\n*   Add the `docker stack config` command to output the merged and interpolated config files as utilized by `stack deploy`. [docker/cli#3544](https://github.com/docker/cli/pull/3544)\n*   Add a new `docker context show` command that prints the name of the current context. [docker/cli#3567](https://github.com/docker/cli/pull/3567)\n*   Add the `--format=json` shorthand variant of `--format=\"{{ json . }}\"` to all commands supporting the `--format` flag. [docker/cli#2936](https://github.com/docker/cli/pull/2936)\n*   Add a `--quiet` option to `docker create` and `docker run` commands to suppress output when pulling an image. [docker/cli#3377](https://github.com/docker/cli/pull/3377)\n*   Add a `--force` option to `docker network rm` subcommand. Causes CLI to return a 0 exit code even if the network doesn't exist. Has no effect on the server-side procedure for removing a network. [docker/cli#3547](https://github.com/docker/cli/pull/3547)\n*   Add a `--signal` option to `docker stop` and `docker restart`. [docker/cli#3614](https://github.com/docker/cli/pull/3614)\n*   Add a `-v/--version` flag to `docker-proxy`. [moby/moby#44703](https://github.com/moby/moby/pull/44703)\n*   Plugins are now discovered in well-known user-level paths when the daemon is running in rootless mode. [moby/moby#44778](https://github.com/moby/moby/pull/44778)\n*   The daemon now handles common alternate JSON encodings in the JSON configuration file gracefully, and reports useful errors. [moby/moby#44777](https://github.com/moby/moby/pull/44777), [moby/moby#44832](https://github.com/moby/moby/pull/44832)\n    *   UTF-8 with a byte order mark is accepted.\n    *   UTF-16 with a byte order mark is accepted.\n    *   Invalid UTF-8 is reported early and with a comprehensible error message.\n*   Allow use of `STOPSIGNAL` via `docker commit`. [moby/moby#43369](https://github.com/moby/moby/pull/43369)\n*   Add a new option to the `awslogs` log driver to allow skipping log stream creation in CloudWatch. [moby/moby#42132](https://github.com/moby/moby/pull/42132)\n*   Add a new option to the `awslogs` log driver to specify the log format that's sent to CloudWatch. [moby/moby#42838](https://github.com/moby/moby/pull/42838)\n*   Add a new option to the `fluentd` log driver to set the reconnection interval. [moby/moby#43100](https://github.com/moby/moby/pull/43100)\n*   Add new options-setters to the Go API client: `WithTLSClientConfigFromEnv()`, `WithHostFromEnv()`, and `WithVersionFromEnv()`. [moby/moby#42224](https://github.com/moby/moby/pull/42224)\n*   Add generation of shell command completion through a `docker completion` subcommand. [docker/cli#3429](https://github.com/docker/cli/pull/3429)\n*   API: Add a `Swarm` header to `GET /_ping` and `HEAD /_ping`, allowing single-request detection of Swarm support. [moby/moby#42064](https://github.com/moby/moby/pull/42064)\n*   API: Add a `signal` parameter to `POST /containers/{id}/stop` and `POST /containers/{id}/restart` to set the signal used. [moby/moby#43206](https://github.com/moby/moby/pull/43206)\n*   API: Add a `CreateMountPoint` parameter to `POST /containers/create`. [moby/moby#43484](https://github.com/moby/moby/pull/43484)\n*   API: Add a `shared-size` parameter to `GET /images/json` to enable shared-size computation of images. [moby/moby#42531](https://github.com/moby/moby/pull/42531)\n*   API: Add a `type` parameter to `GET /system/df`, to control what object types to are considered when computing disk usage. [moby/moby#42559](https://github.com/moby/moby/pull/42559)\n*   systemd: Use a systemd-managed containerd instead of a daemon-managed containerd. [moby/moby#42373](https://github.com/moby/moby/pull/42373)\n*   systemd: Start `docker.service` after `time-set.target`. [moby/moby#43107](https://github.com/moby/moby/pull/43107)\n\n### [Removed](#removed)\n\n*   Remove support for reading configuration from `~/.dockercfg`. [docker/cli#2504](https://github.com/docker/cli/pull/2504)\n    *   This location has been deprecated since 1.7.0.\n    *   [Deprecation notice](https://docs.docker.com/engine/deprecated/#support-for-legacy-dockercfg-configuration-files)\n*   Remove the `-g` and `--graph` daemon options in favor of `--data-root`. [docker/cli#3739](https://github.com/docker/cli/pull/3739)\n    *   These options have been hidden and deprecated since 17.05.\n    *   [Deprecation notice](https://docs.docker.com/engine/deprecated/#-g-and---graph-flags-on-dockerd)\n*   Remove client-side sorting of results, in favor of the order in which the search API returns. [docker/cli#3470](https://github.com/docker/cli/pull/3470)\n*   Remove warnings related to deprecated storage drivers from the CLI. Warnings are now handled by the daemon instead. [docker/cli#3542](https://github.com/docker/cli/pull/3542)\n*   Remove `Experimental` client field from `docker version`. [docker/cli#3543](https://github.com/docker/cli/pull/3543)\n    *   [Deprecation notice](https://docs.docker.com/engine/deprecated/#configuration-options-for-experimental-cli-features)\n*   Require explicit opt-in to use deprecated storage drivers, and don't automatically select them when upgrading. [moby/moby#43378](https://github.com/moby/moby/pull/43378)\n*   Remove deprecated support for `overlay` and `overlay2` storage drivers on backing filesystems without `d_type` support. [moby/moby#43472](https://github.com/moby/moby/pull/43472)\n    *   [Deprecation notice](https://docs.docker.com/engine/deprecated/#backing-filesystem-without-d_type-support-for-overlayoverlay2)\n*   Remove the deprecated `overrideKernelCheck` option from the `overlay2` storage driver. [moby/moby#44279](https://github.com/moby/moby/pull/44279) [Deprecation notice](https://docs.docker.com/engine/deprecated/#support-for-the-overlay2override_kernel_check-storage-option)\n*   Remove support for the deprecated `io.containerd.runtime.v1.linux` OCI runtime. [moby/moby#43695](https://github.com/moby/moby/pull/43695)\n*   Remove LCOW (Linux Containers on Windows). [moby/moby#42451](https://github.com/moby/moby/pull/42451), [moby/moby#42499](https://github.com/moby/moby/pull/42499), [moby/moby#42506](https://github.com/moby/moby/pull/42506), [moby/moby#42511](https://github.com/moby/moby/pull/42511), [moby/moby#42520](https://github.com/moby/moby/pull/42520), [moby/moby#42683](https://github.com/moby/moby/pull/42683), [moby/moby#42684](https://github.com/moby/moby/pull/42684), [moby/moby#42685](https://github.com/moby/moby/pull/42685), [moby/moby#43187](https://github.com/moby/moby/pull/43187)\n    *   LCOW was introduced as a technical preview in 17.09 and deprecated in 20.10.\n    *   [Deprecation notice](https://docs.docker.com/engine/deprecated/#linux-containers-on-windows-lcow-experimental)\n*   Remove daemon options related to legacy overlay networks used with standalone Swarm.\n    *   Remove `--cluster-xx` options from `dockerd`. [moby/moby#40383](https://github.com/moby/moby/issues/40383)\n    *   Remove `host-discovery` and overlay networks with external k/v stores. [moby/moby#42247](https://github.com/moby/moby/pull/42247)\n    *   [Deprecation notice](https://docs.docker.com/engine/deprecated/#classic-swarm-and-overlay-networks-using-cluster-store)\n*   Remove a deprecated `arm` platform fallback. `--platform linux/arm/vY` will now return a error when `arm/vY` isn't available instead of pulling the wrong image. [moby/moby#44414](https://github.com/moby/moby/pull/44414)\n*   Remove the deprecated `SetCustomHTTPHeaders()`, `CustomHTTPHeaders()` options-setters from the Go client API. [moby/moby#42694](https://github.com/moby/moby/pull/42694)\n*   Remove the deprecated `WithDialer()` option-setter from the Go client API. [moby/moby#44022](https://github.com/moby/moby/pull/44022)\n    *   Use `WithDialContext()` instead.\n*   Remove the daemon implementation of `opts.QuotedString`. The implementation has moved to the CLI. [moby/moby#43250](https://github.com/moby/moby/pull/43250)\n*   Remove separate daemon ID from trust-key in the daemon, and disable generating the trust-key. [moby/moby#43555](https://github.com/moby/moby/pull/43555)\n*   API: Remove the deprecated `KernelMemory` option from `POST /containers/create` on API version >= 1.42. [moby/moby#43214](https://github.com/moby/moby/pull/43214)\n    *   [Deprecation notice](https://docs.docker.com/engine/deprecated/#kernel-memory-limit)\n\n### [Deprecated](#deprecated)\n\n*   Require Windows Server RS5 / LTSC 2019 (build 17763) as the minimum to run the daemon. [moby/moby#43254](https://github.com/moby/moby/pull/43254)\n*   Deprecate `BuilderSize` on API version >= 1.42. [moby/moby#42608](https://github.com/moby/moby/pull/42608)\n*   Deprecate `BuildCache.Parent` in favor of the newly introduced `BuildCache.Parents` on API version >= 1.42. [moby/moby#43908](https://github.com/moby/moby/pull/43908)\n*   Deprecate `pkg/urlutil`, moving the implementation to `builder/remotecontext/urlutil`. [moby/moby#43477](https://github.com/moby/moby/pull/43477)\n\n### [Upgrades](#upgrades)\n\n*   Upgrade Go to `1.19.5`. [docker/cli#3958](https://github.com/docker/cli/pull/3958), [moby/moby#44794](https://github.com/moby/moby/pull/44794)\n*   Upgrade `rootlesskit` to `v0.14.4`. [moby/moby#42708](https://github.com/moby/moby/pull/42708)\n*   Upgrade `buildkit` to `v0.10.6`. [moby/moby#43239](https://github.com/moby/moby/pull/43239)\n*   Upgrade `buildx` to `v0.10.2`. [docker/docker-ce-packaging#840](https://github.com/docker/docker-ce-packaging/pull/840)\n*   Upgrade `swarmkit` to `v2.0.0-20230119195359-904c221ac281`. [moby/moby#44858](https://github.com/moby/moby/pull/44858)\n*   Upgrade `containerd` to `v1.6.16`. [moby/moby#44766](https://github.com/moby/moby/pull/44766), [moby/moby#44769](https://github.com/moby/moby/pull/44769), [moby/moby#44881](https://github.com/moby/moby/pull/44881)\n*   Upgrade `runc` to `v1.1.4`. [moby/moby#44039](https://github.com/moby/moby/pull/44039)\n*   Upgrade `hcsshim` `v0.9.6`. [moby/moby#44658](https://github.com/moby/moby/pull/44658)\n*   The `btrfs` storage driver now depends on Linux kernel headers (>= 4.12) instead of headers from btrfs-progs. [moby/moby#44776](https://github.com/moby/moby/pull/44776)\n\n### [Security](#security)\n\n*   Change permissions on container `hostconfig.json` files to `0600` (was `0644`). [moby/moby#41620](https://github.com/moby/moby/pull/41620)\n*   Fix `--seccomp-profile` not accepting `unconfined` and renamed the default seccomp profile to `builtin`. [moby/moby#42481](https://github.com/moby/moby/pull/42481)\n*   Always build with seccomp support, and remove the `seccomp` build tag. [moby/moby#42501](https://github.com/moby/moby/pull/42501)\n*   Add seccomp support on `riscv64`. [moby/moby#43553](https://github.com/moby/moby/pull/43553)\n*   Add support for setting flags passed to `seccomp(2)` in seccomp profiles. [moby/moby#42648](https://github.com/moby/moby/pull/42648)\n*   Refactor seccomp types to reuse runtime-spec, and add support for `ErrnoRet`. [moby/moby#42005](https://github.com/moby/moby/pull/42005)\n*   Add support for `DefaultErrnoRet` in `seccomp` profiles. [moby/moby#42604](https://github.com/moby/moby/pull/42604)\n*   Add an explicit `DefaultErrnoRet` field to the default seccomp profile, with no behavior change. [moby/moby#42649](https://github.com/moby/moby/pull/42649)\n*   Block `socket` with `AF_VSOCK` in the default seccomp profile. [moby/moby#44563](https://github.com/moby/moby/pull/44563)\n*   Re-enable `process_vm_readv` and `process_vm_writev` in the default seccomp profile. [moby/moby#42083](https://github.com/moby/moby/pull/42083)\n*   Add syscalls related to PKU to the default seccomp profile. [moby/moby#43812](https://github.com/moby/moby/pull/43812)\n*   Allow `clock_settime64` with `CAP_SYS_TIME`. [moby/moby#43775](https://github.com/moby/moby/pull/43775)\n*   Allow `bpf` with `CAP_BPF` and `perf_event_open` with `CAP_PERFMON`. [moby/moby#43988](https://github.com/moby/moby/pull/43988)\n*   Explicitly set the `clone3` syscall to return `ENOSYS` in the default seccomp profile, in order to ensure `glibc` will correctly fallback to using `clone`. [moby/moby#42681](https://github.com/moby/moby/pull/42681)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-6)\n\n*   Promote `overlay2` to be the default storage driver (`btrfs` and `zfs` are now opt-in). [moby/moby#42661](https://github.com/moby/moby/pull/42661)\n*   Add a loading spinner to the `docker cp` command. [docker/cli#2708](https://github.com/docker/cli/pull/2708)\n*   Deprecate the `ElectAuthServer` function, and made it return the default registry without calling the `GET /info` API endpoint. [docker/cli#2819](https://github.com/docker/cli/pull/2819)\n*   Progress bars are no longer reversed when rolling back Swarm services. [docker/cli#2940](https://github.com/docker/cli/pull/2940)\n*   Use `net.JoinHostPort()` to fix formatting with IPv6 addresses. [docker/cli#2972](https://github.com/docker/cli/pull/2972)\n*   CLI error messages are now printed to `stderr`. [docker/cli#3044](https://github.com/docker/cli/pull/3044)\n*   Improve performance of `docker info` if a custom `--format` is used that only uses local information. With this change, the CLI only uses the daemon API if it detects that information from the daemon is needed. [docker/cli#3179](https://github.com/docker/cli/pull/3179)\n*   Remove the default value from the `--stop-signal` flag, as it may not reflect the actual default used by the daemon. [docker/cli#3245](https://github.com/docker/cli/pull/3245)\n*   Add Compose schema `3.10` to `docker stack`; allow omitting the `version` field (resulting in `latest`). [docker/cli#3257](https://github.com/docker/cli/pull/3257)\n*   Compose version `3` is now equivalent to `3.x` (latest) in `docker stack`. [docker/cli#3445](https://github.com/docker/cli/pull/3445)\n*   Fix `<Ctrl-c>` hanging on Windows to exit after running a container in non-interactive mode. [docker/cli#3302](https://github.com/docker/cli/pull/3302)\n*   Add relative source paths to the `run` command in the `-v`/`--volume` and `-m`/`--mount` flags. [docker/cli#3469](https://github.com/docker/cli/pull/3469)\n*   `docker exec -t` now sets the console size for the executed process immediately when it's created. [docker/cli#3627](https://github.com/docker/cli/pull/3627)\n*   Update the pretty-print format of `docker info` to provide more details on installed plugins. [docker/cli#3645](https://github.com/docker/cli/pull/3645)\n*   Print warning messages for the `docker context list` and `docker context use` commands when the context is overridden by the environment. [docker/cli#3668](https://github.com/docker/cli/pull/3668)\n*   Add a custom `aliases` annotation that can be used to print all available aliases for a command. [docker/cli#3694](https://github.com/docker/cli/pull/3694)\n*   The CLI no longer creates or updates the CLI configuration file when running `docker context use` and selecting the current context. [docker/cli#3721](https://github.com/docker/cli/pull/3721)\n*   Non-existing contexts are now ignored when running `docker context rm --force`. [docker/cli#3791](https://github.com/docker/cli/pull/3791)\n*   Add the ability to override integers to `0` in Compose files. [docker/cli#3812](https://github.com/docker/cli/pull/3812)\n*   SIGINT (`<Ctrl-c>`) now passes through to running containers instead of causing the CLI to exit. [docker/cli#3849](https://github.com/docker/cli/pull/3849)\n*   Improve `docker port CONTAINER` UX by sorting ports before printing. [docker/cli#3892](https://github.com/docker/cli/pull/3892)\n*   API: `GET /containers/{id}/logs` and `POST /containers/{id}/attach` now report which raw-stream format is in use using the `Content-type` response header on API version >= 1.42. [moby/moby#39812](https://github.com/moby/moby/pull/39812)\n*   Set default sandbox size for Windows layers to 127GB, and ensure that the `--storage-opts` flag applies to all storage on Windows. [moby/moby#41636](https://github.com/moby/moby/pull/41636)\n*   Remove the plugin section from the containerd configuration file (`/var/run/docker/containerd/containerd.toml`). [moby/moby#41675](https://github.com/moby/moby/pull/41675)\n*   Reject `null` manifests during tar import. [moby/moby#41842](https://github.com/moby/moby/pull/41842)\n*   Add shim config for custom runtimes for plugins. [moby/moby#41854](https://github.com/moby/moby/pull/41854)\n*   Container health checks now resume when the daemon is restarted. [moby/moby#41935](https://github.com/moby/moby/pull/41935)\n*   Quota is no longer disabled on cleanup of the `btrfs` driver. [moby/moby#42273](https://github.com/moby/moby/pull/42273)\n*   Host devices that are accessible can now be mounted in `--privileged` rootless containers. [moby/moby#42638](https://github.com/moby/moby/pull/42638)\n*   Fix incorrect handling of `**/foo` recursive wildcard directory patterns in `.dockerignore`. [moby/moby#42676](https://github.com/moby/moby/pull/42676)\n*   Extend `docker import --platform` to allow marking an imported image as a foreign architecture. [moby/moby#43103](https://github.com/moby/moby/pull/43103)\n*   Validation of CPU real-time options is now performed when the daemon starts instead of performing validations for each individual container, allowing startup to fail early. [moby/moby#43131](https://github.com/moby/moby/pull/43131)\n*   Freeze the `namesgenerator` package against new additions. Users will have to be satisfied with the existing 25359 adjective-name combinations. [moby/moby#43210](https://github.com/moby/moby/pull/43210)\n*   API: `containers/{id}/attach/ws` only to streams according by `stdin`, `stdout` and `stderr` parameters on API version >= 1.42. [moby/moby#43322](https://github.com/moby/moby/pull/43322)\n*   Fix UDP traffic in containers not working after the container is restarted under sustained traffic. [moby/moby#43409](https://github.com/moby/moby/pull/43409)\n*   Add support for pulling images with custom amd64 micro-architecture feature levels as supported by the latest versions of Go, GCC, LLVM, and other compiler tools. [moby/moby#43434](https://github.com/moby/moby/pull/43434)\n*   Improve validation of invalid JSON requests in the API. [moby/moby#43463](https://github.com/moby/moby/pull/43463)\n*   Mitigate the impact of slow `exec` starts on health checks. Check timeout now only applies to the duration that the health check command is running. The time it takes to start the command no longer counts against the timeout. [moby/moby#43480](https://github.com/moby/moby/pull/43480)\n*   Console `tty` size is set immediately on creation. [moby/moby#43593](https://github.com/moby/moby/pull/43593), [moby/moby#43622](https://github.com/moby/moby/pull/43622)\n*   Fix `overlay2` mounts not being cleaned up after failed container starts, or daemon shutdown. [moby/moby#43659](https://github.com/moby/moby/pull/43659)\n*   Match manifest list resolution with `containerd`. [moby/moby#43675](https://github.com/moby/moby/pull/43675)\n*   Skip use of `firewalld` for networking when the daemon is running in rootless mode. [moby/moby#43813](https://github.com/moby/moby/pull/43813)\n*   Custom NAT networks are now re-created after daemon restart if missing on Windows. [moby/moby#43858](https://github.com/moby/moby/pull/43858)\n*   Fix terminating the container health-check process when it times out. [moby/moby#43994](https://github.com/moby/moby/pull/43994)\n*   Fix `live-restore` with restart policies and volume refs. [moby/moby#44237](https://github.com/moby/moby/pull/44237)\n*   API: Only anonymous volumes now pruned by default on API version >= v1.42. Pass the filter `all=true` to prune named volumes in addition to anonymous. [moby/moby#44259](https://github.com/moby/moby/pull/44259)\n*   API: Support concurrent calls on the `GET /system/df` endpoint. [moby/moby#42715](https://github.com/moby/moby/pull/42715)\n*   Improve the reliability of the daemon dumping the stack and exits with code 2 when sent a SIGQUIT. [moby/moby#44831](https://github.com/moby/moby/pull/44831)\n*   Improve the reliability of `docker logs -f` on Windows, and prevent newlines from being dropped in the `local` log driver. [moby/moby#43294](https://github.com/moby/moby/pull/43294)\n*   Fix a rare deadlock in the daemon caused by buffering of container logs. [moby/moby#44856](https://github.com/moby/moby/pull/44856)\n*   Improve error handling in misc filesystem operations so that the daemon can start on a overlayfs backing filesystem. [moby/moby#44834](https://github.com/moby/moby/pull/44834)\n*   Fix an issue where `--ipc=host` wasn't handled correctly when the daemon is running in rootless mode. [moby/moby#44863](https://github.com/moby/moby/pull/44863)\n*   Fix a long-standing set of issues where stale conntrack entries caused incorrect routing of UDP traffic for containers. [moby/moby#44752](https://github.com/moby/moby/pull/44752)\n*   Fix half-registered containers being listed in the API, as well as a nil pointer de-reference and panic caused by using a partially registered container in API calls. [moby/moby#44633](https://github.com/moby/moby/pull/44633)\n*   Fix a failure to create the `DOCKER-USER` ip6tables chain. [moby/moby#44845](https://github.com/moby/moby/pull/44845)\n*   Fix a failure to clean up iptables rules when the `ip6tables` command isn't available. [moby/moby#44727](https://github.com/moby/moby/pull/44727)\n*   Fix an issue where some iptables NAT rules weren't cleaned up after enabling the userland proxy. [moby/moby#44811](https://github.com/moby/moby/pull/44811)\n*   Fix a potentially leaked process in rare situations where cleaning up a failed attempt to start a container was mishandled. [moby/moby#44400](https://github.com/moby/moby/pull/44400)\n*   Fix the `CreatedAt` time of a volume reflecting initialization and not creation. [moby/moby#44725](https://github.com/moby/moby/pull/44725)\n*   Fix an issue where the CLI incorrectly reported an incompatible server instead of an unreachable server in some commands. [docker/cli#3901](https://github.com/docker/cli/pull/3901), [docker/cli#3904](https://github.com/docker/cli/pull/3904)\n*   Fix broken completion of volumes in Zsh. [docker/cli#2998](https://github.com/docker/cli/pull/2998)\n*   Improve output of `docker context` when an invalid context is present. [docker/cli#3847](https://github.com/docker/cli/pull/3847)\n*   Remove ANSI decoration of CLI help annotations when the output isn't a TTY, and added a newline for readability. [docker/cli#3973](https://github.com/docker/cli/pull/3973)\n*   Add `docker container remove` as an alias for `docker container rm`. [docker/cli#3986](https://github.com/docker/cli/pull/3986)\n\n### [Known issues](#known-issues)\n\n#### [apparmor\\_parser (](#apparmor_parser-tracking-issuehttpsgithubcommobymobyissues44900) [tracking issue](https://github.com/moby/moby/issues/44900))\n\nSome Debian users have reported issues with containers failing to start after upgrading to the 23.0 branch. The error message indicates that the issue is due to a missing `apparmor_parser` binary:\n\nThe workaround to this issue is to install the `apparmor` package manually:\n\n#### [BuildKit inline cache (](#buildkit-inline-cache-tracking-issuehttpsgithubcommobymobyissues44918) [tracking issue](https://github.com/moby/moby/issues/44918))\n\nAttempting to build an image with BuildKit's inline cache feature (e.g. `docker build --build-arg BUILDKIT_INLINE_CACHE=1 .`, `docker buildx build --cache-to type=inline .`) will result in the daemon unexpectedly exiting:\n\nThe daemon will restart if configured to do so (e.g. via systemd) after such a crash. The only available mitigation in this release is to avoid performing builds with the inline cache feature enabled.\n\n#### [BuildKit with warm cache (](#buildkit-with-warm-cache-tracking-issuehttpsgithubcommobymobyissues44943) [tracking issue](https://github.com/moby/moby/issues/44943))\n\nIf an image was built with BuildKit on a previous version of the daemon, and is built with a 23.0 daemon, previously cached layers will not be restored correctly. The image may appear to build correctly if no lines are changed in the Dockerfile; however, if partial cache invalidation occurs due to changing some lines in the Dockerfile, the still valid and previously cached layers will not be loaded correctly.\n\nThis most often presents as files that should be present in the image not being present in a `RUN` stage, or any other stage that references files, after changing some lines in the Dockerfile:\n\nTo mitigate this, the previous build cache must be discarded. `docker builder prune -a` will completely empty the build cache, and allow the affected builds to proceed again by removing the mishandled cache layers.\n\n#### [ipvlan networks (](#ipvlan-networks-tracking-issuehttpsgithubcommobymobyissues44925) [tracking issue](https://github.com/moby/moby/issues/44925))\n\nWhen upgrading to the 23.0 branch, the existence of any [ipvlan](https://docs.docker.com/network/drivers/ipvlan/) networks will prevent the daemon from starting:\n\nTo mitigate this, affected users can downgrade and remove the network, then upgrade again. Alternatively, the entire network store can be removed, and networks can be recreated after the upgrade. The network store is located at `/var/lib/docker/network/files/local-kv.db`. If the daemon is using an alternate `--data-root`, substitute `/var/lib/docker` for the alternate path.\n\n#### [Kata Containers (](#kata-containers-tracking-issuehttpsgithubcomkata-containerskata-containersissues6154) [tracking issue](https://github.com/kata-containers/kata-containers/issues/6154))\n\nThe 23.0 branch brings support for alternate containerd shims, such as `io.containerd.runsc.v1` (gVisor) and `io.containerd.kata.v2` (Kata Containers).\n\nWhen using the Kata Containers runtime, exiting an `exec` session stops the running container, and hangs the connected CLI if a TTY was opened. There is no mitigation at this time beyond avoiding execing into containers running on the Kata runtime.\n\nThe root cause of this issue is a long-standing bug in Moby. This will be resolved in a future release. Be advised that support for alternate OCI runtimes is a new feature and that similar issues may be discovered as more users start exercising this functionality.",
  "title": "Docker Engine 23.0 release notes | Docker Docs\n",
  "description": "Learn about the new features, bug fixes, and breaking changes for Docker Engine",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/extend/plugins_volume/",
  "markdown": "# Docker volume plugins | Docker Docs\n\nDocker Engine volume plugins enable Engine deployments to be integrated with external storage systems such as Amazon EBS, and enable data volumes to persist beyond the lifetime of a single Docker host. See the [plugin documentation](https://docs.docker.com/engine/extend/legacy_plugins/) for more information.\n\n### [1.13.0](#1130)\n\n*   If used as part of the v2 plugin architecture, mountpoints that are part of paths returned by the plugin must be mounted under the directory specified by `PropagatedMount` in the plugin configuration ( [#26398](https://github.com/docker/docker/pull/26398))\n\n### [1.12.0](#1120)\n\n*   Add `Status` field to `VolumeDriver.Get` response ( [#21006](https://github.com/docker/docker/pull/21006#))\n*   Add `VolumeDriver.Capabilities` to get capabilities of the volume driver ( [#22077](https://github.com/docker/docker/pull/22077))\n\n### [1.10.0](#1100)\n\n*   Add `VolumeDriver.Get` which gets the details about the volume ( [#16534](https://github.com/docker/docker/pull/16534))\n*   Add `VolumeDriver.List` which lists all volumes owned by the driver ( [#16534](https://github.com/docker/docker/pull/16534))\n\n### [1.8.0](#180)\n\n*   Initial support for volume driver plugins ( [#14659](https://github.com/docker/docker/pull/14659))\n\nTo give a container access to a volume, use the `--volume` and `--volume-driver` flags on the `docker container run` command. The `--volume` (or `-v`) flag accepts a volume name and path on the host, and the `--volume-driver` flag accepts a driver type.\n\n### [`--volume`](#--volume)\n\nThe `--volume` (or `-v`) flag takes a value that is in the format `<volume_name>:<mountpoint>`. The two parts of the value are separated by a colon (`:`) character.\n\n*   The volume name is a human-readable name for the volume, and cannot begin with a `/` character. It is referred to as `volume_name` in the rest of this topic.\n*   The `Mountpoint` is the path on the host (v1) or in the plugin (v2) where the volume has been made available.\n\n### [`volumedriver`](#volumedriver)\n\nSpecifying a `volumedriver` in conjunction with a `volumename` allows you to use plugins such as [Flocker](https://github.com/ScatterHQ/flocker) to manage volumes external to a single host, such as those on EBS.\n\nThe container creation endpoint (`/containers/create`) accepts a `VolumeDriver` field of type `string` allowing to specify the name of the driver. If not specified, it defaults to `\"local\"` (the default driver for local volumes).\n\nIf a plugin registers itself as a `VolumeDriver` when activated, it must provide the Docker Daemon with writeable paths on the host filesystem. The Docker daemon provides these paths to containers to consume. The Docker daemon makes the volumes available by bind-mounting the provided paths into the containers.\n\n> **Note**\n> \n> Volume plugins should _not_ write data to the `/var/lib/docker/` directory, including `/var/lib/docker/volumes`. The `/var/lib/docker/` directory is reserved for Docker.\n\n### [`/VolumeDriver.Create`](#volumedrivercreate)\n\nRequest:\n\nInstruct the plugin that the user wants to create a volume, given a user specified volume name. The plugin does not need to actually manifest the volume on the filesystem yet (until `Mount` is called). `Opts` is a map of driver specific options passed through from the user request.\n\nResponse:\n\nRespond with a string error if an error occurred.\n\n### [`/VolumeDriver.Remove`](#volumedriverremove)\n\nRequest:\n\nDelete the specified volume from disk. This request is issued when a user invokes `docker rm -v` to remove volumes associated with a container.\n\nResponse:\n\nRespond with a string error if an error occurred.\n\n### [`/VolumeDriver.Mount`](#volumedrivermount)\n\nRequest:\n\nDocker requires the plugin to provide a volume, given a user specified volume name. `Mount` is called once per container start. If the same `volume_name` is requested more than once, the plugin may need to keep track of each new mount request and provision at the first mount request and deprovision at the last corresponding unmount request.\n\n`ID` is a unique ID for the caller that is requesting the mount.\n\nResponse:\n\n*   v1\n    \n*   v2\n    \n\n`Mountpoint` is the path on the host (v1) or in the plugin (v2) where the volume has been made available.\n\n`Err` is either empty or contains an error string.\n\n### [`/VolumeDriver.Path`](#volumedriverpath)\n\nRequest:\n\nRequest the path to the volume with the given `volume_name`.\n\nResponse:\n\n*   v1\n    \n*   v2\n    \n\nRespond with the path on the host (v1) or inside the plugin (v2) where the volume has been made available, and/or a string error if an error occurred.\n\n`Mountpoint` is optional. However, the plugin may be queried again later if one is not provided.\n\n### [`/VolumeDriver.Unmount`](#volumedriverunmount)\n\nRequest:\n\nDocker is no longer using the named volume. `Unmount` is called once per container stop. Plugin may deduce that it is safe to deprovision the volume at this point.\n\n`ID` is a unique ID for the caller that is requesting the mount.\n\nResponse:\n\nRespond with a string error if an error occurred.\n\n### [`/VolumeDriver.Get`](#volumedriverget)\n\nRequest:\n\nGet info about `volume_name`.\n\nResponse:\n\n*   v1\n    \n*   v2\n    \n\nRespond with a string error if an error occurred. `Mountpoint` and `Status` are optional.\n\n### [/VolumeDriver.List](#volumedriverlist)\n\nRequest:\n\nGet the list of volumes registered with the plugin.\n\nResponse:\n\n*   v1\n    \n*   v2\n    \n\nRespond with a string error if an error occurred. `Mountpoint` is optional.\n\n### [/VolumeDriver.Capabilities](#volumedrivercapabilities)\n\nRequest:\n\nGet the list of capabilities the driver supports.\n\nThe driver is not required to implement `Capabilities`. If it is not implemented, the default values are used.\n\nResponse:\n\nSupported scopes are `global` and `local`. Any other value in `Scope` will be ignored, and `local` is used. `Scope` allows cluster managers to handle the volume in different ways. For instance, a scope of `global`, signals to the cluster manager that it only needs to create the volume once instead of on each Docker host. More capabilities may be added in the future.",
  "title": "Docker volume plugins | Docker Docs\n",
  "description": "How to manage data with external volume plugins",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/drivers/kubernetes/",
  "markdown": "# Kubernetes driver | Docker Docs\n\nThe Kubernetes driver lets you connect your local development or CI environments to builders in a Kubernetes cluster to allow access to more powerful compute resources, optionally on multiple native architectures.\n\nRun the following command to create a new builder, named `kube`, that uses the Kubernetes driver:\n\nThe following table describes the available driver-specific options that you can pass to `--driver-opt`:\n\n| Parameter | Type | Default | Description |\n| --- | --- | --- | --- |\n| `image` | String |     | Sets the image to use for running BuildKit. |\n| `namespace` | String | Namespace in current Kubernetes context | Sets the Kubernetes namespace. |\n| `default-load` | Boolean | `false` | Automatically load images to the Docker Engine image store. |\n| `replicas` | Integer | 1   | Sets the number of Pod replicas to create. See [scaling BuildKit](#scaling-buildkit) |\n| `requests.cpu` | CPU units |     | Sets the request CPU value specified in units of Kubernetes CPU. For example `requests.cpu=100m` or `requests.cpu=2` |\n| `requests.memory` | Memory size |     | Sets the request memory value specified in bytes or with a valid suffix. For example `requests.memory=500Mi` or `requests.memory=4G` |\n| `requests.ephemeral-storage` | Storage size |     | Sets the request ephemeral-storage value specified in bytes or with a valid suffix. For example `requests.ephemeral-storage=2Gi` |\n| `limits.cpu` | CPU units |     | Sets the limit CPU value specified in units of Kubernetes CPU. For example `requests.cpu=100m` or `requests.cpu=2` |\n| `limits.memory` | Memory size |     | Sets the limit memory value specified in bytes or with a valid suffix. For example `requests.memory=500Mi` or `requests.memory=4G` |\n| `limits.ephemeral-storage` | Storage size |     | Sets the limit ephemeral-storage value specified in bytes or with a valid suffix. For example `requests.ephemeral-storage=100M` |\n| `nodeselector` | CSV string |     | Sets the pod's `nodeSelector` label(s). See [node assignment](#node-assignment). |\n| `annotation` | CSV string |     | Sets additional annotations on the deployments and pods. |\n| `labels` | CSV string |     | Sets additional labels on the deployments and pods. |\n| `tolerations` | CSV string |     | Configures the pod's taint toleration. See [node assignment](#node-assignment). |\n| `serviceaccount` | String |     | Sets the pod's `serviceAccountName`. |\n| `schedulername` | String |     | Sets the scheduler responsible for scheduling the pod. |\n| `timeout` | Time | `120s` | Set the timeout limit that determines how long Buildx will wait for pods to be provisioned before a build. |\n| `rootless` | Boolean | `false` | Run the container as a non-root user. See [rootless mode](#rootless-mode). |\n| `loadbalance` | String | `sticky` | Load-balancing strategy (`sticky` or `random`). If set to `sticky`, the pod is chosen using the hash of the context path. |\n| `qemu.install` | Boolean | `false` | Install QEMU emulation for multi platforms support. See [QEMU](#qemu). |\n| `qemu.image` | String | `tonistiigi/binfmt:latest` | Sets the QEMU emulation image. See [QEMU](#qemu). |\n\nOne of the main advantages of the Kubernetes driver is that you can scale the number of builder replicas up and down to handle increased build load. Scaling is configurable using the following driver options:\n\n*   `replicas=N`\n    \n    This scales the number of BuildKit pods to the desired size. By default, it only creates a single pod. Increasing the number of replicas lets you take advantage of multiple nodes in your cluster.\n    \n*   `requests.cpu`, `requests.memory`, `requests.ephemeral-storage`, `limits.cpu`, `limits.memory`, `limits.ephemeral-storage`\n    \n    These options allow requesting and limiting the resources available to each BuildKit pod according to the official Kubernetes documentation [here](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/).\n    \n\nFor example, to create 4 replica BuildKit pods:\n\nListing the pods, you get this:\n\nAdditionally, you can use the `loadbalance=(sticky|random)` option to control the load-balancing behavior when there are multiple replicas. `random` selects random nodes from the node pool, providing an even workload distribution across replicas. `sticky` (the default) attempts to connect the same build performed multiple times to the same node each time, ensuring better use of local cache.\n\nFor more information on scalability, see the options for [`docker buildx create`](https://docs.docker.com/reference/cli/docker/buildx/create/#driver-opt).\n\nThe Kubernetes driver allows you to control the scheduling of BuildKit pods using the `nodeSelector` and `tolerations` driver options. You can also set the `schedulername` option if you want to use a custom scheduler altogether.\n\nYou can use the `annotations` and `labels` driver options to apply additional metadata to the deployments and pods that's hosting your builders.\n\nThe value of the `nodeSelector` parameter is a comma-separated string of key-value pairs, where the key is the node label and the value is the label text. For example: `\"nodeselector=kubernetes.io/arch=arm64\"`\n\nThe `tolerations` parameter is a semicolon-separated list of taints. It accepts the same values as the Kubernetes manifest. Each `tolerations` entry specifies a taint key and the value, operator, or effect. For example: `\"tolerations=key=foo,value=bar;key=foo2,operator=exists;key=foo3,effect=NoSchedule\"`\n\nThese options accept CSV-delimited strings as values. Due to quoting rules for shell commands, you must wrap the values in single quotes. You can even wrap all of `--driver-opt` in single quotes, for example:\n\nThe Kubernetes driver has support for creating [multi-platform images](https://docs.docker.com/build/building/multi-platform/), either using QEMU or by leveraging the native architecture of nodes.\n\n### [QEMU](#qemu)\n\nLike the `docker-container` driver, the Kubernetes driver also supports using [QEMU](https://www.qemu.org/) (user mode) to build images for non-native platforms. Include the `--platform` flag and specify which platforms you want to output to.\n\nFor example, to build a Linux image for `amd64` and `arm64`:\n\n> **Warning**\n> \n> QEMU performs full-CPU emulation of non-native platforms, which is much slower than native builds. Compute-heavy tasks like compilation and compression/decompression will likely take a large performance hit.\n\nUsing a custom BuildKit image or invoking non-native binaries in builds may require that you explicitly turn on QEMU using the `qemu.install` option when creating the builder:\n\n### [Native](#native)\n\nIf you have access to cluster nodes of different architectures, the Kubernetes driver can take advantage of these for native builds. To do this, use the `--append` flag of `docker buildx create`.\n\nFirst, create your builder with explicit support for a single architecture, for example `amd64`:\n\nThis creates a Buildx builder named `kube`, containing a single builder node named `builder-amd64`. Assigning a node name using `--node` is optional. Buildx generates a random node name if you don't provide one.\n\nNote that the Buildx concept of a node isn't the same as the Kubernetes concept of a node. A Buildx node in this case could connect multiple Kubernetes nodes of the same architecture together.\n\nWith the `kube` builder created, you can now introduce another architecture into the mix using `--append`. For example, to add `arm64`:\n\nListing your builders shows both nodes for the `kube` builder:\n\nYou can now build multi-arch `amd64` and `arm64` images, by specifying those platforms together in your build command:\n\nYou can repeat the `buildx create --append` command for as many architectures that you want to support.\n\nThe Kubernetes driver supports rootless mode. For more information on how rootless mode works, and it's requirements, see [here](https://github.com/moby/buildkit/blob/master/docs/rootless.md).\n\nTo turn it on in your cluster, you can use the `rootless=true` driver option:\n\nThis will create your pods without `securityContext.privileged`.\n\nRequires Kubernetes version 1.19 or later. Using Ubuntu as the host kernel is recommended.\n\nThis guide shows you how to:\n\n*   Create a namespace for your Buildx resources\n*   Create a Kubernetes builder.\n*   List the available builders\n*   Build an image using your Kubernetes builders\n\nPrerequisites:\n\n*   You have an existing Kubernetes cluster. If you don't already have one, you can follow along by installing [minikube](https://minikube.sigs.k8s.io/docs/).\n*   The cluster you want to connect to is accessible via the `kubectl` command, with the `KUBECONFIG` environment variable [set appropriately](https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/#set-the-kubeconfig-environment-variable) if necessary.\n\n1.  Create a `buildkit` namespace.\n    \n    Creating a separate namespace helps keep your Buildx resources separate from other resources in the cluster.\n    \n2.  Create a new builder with the Kubernetes driver:\n    \n    > **Note**\n    > \n    > Remember to specify the namespace in driver options.\n    \n3.  List available builders using `docker buildx ls`\n    \n4.  Inspect the running pods created by the build driver with `kubectl`.\n    \n    The build driver creates the necessary resources on your cluster in the specified namespace (in this case, `buildkit`), while keeping your driver configuration locally.\n    \n5.  Use your new builder by including the `--builder` flag when running buildx commands. For example: :\n    \n\nThat's it! You've now built an image from a Kubernetes pod, using Buildx!\n\nFor more information on the Kubernetes driver, see the [buildx reference](https://docs.docker.com/reference/cli/docker/buildx/create/#driver).",
  "title": "Kubernetes driver | Docker Docs\n",
  "description": "The Kubernetes driver lets you run BuildKit in a Kubernetes cluster. You can connect to, and run your builds in, the cluster using Buildx. ",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/drivers/remote/",
  "markdown": "# Remote driver | Docker Docs\n\nThe Buildx remote driver allows for more complex custom build workloads, allowing you to connect to externally managed BuildKit instances. This is useful for scenarios that require manual management of the BuildKit daemon, or where a BuildKit daemon is exposed from another source.\n\nThe following table describes the available driver-specific options that you can pass to `--driver-opt`:\n\n| Parameter | Type | Default | Description |\n| --- | --- | --- | --- |\n| `key` | String |     | Sets the TLS client key. |\n| `cert` | String |     | Absolute path to the TLS client certificate to present to `buildkitd`. |\n| `cacert` | String |     | Absolute path to the TLS certificate authority used for validation. |\n| `servername` | String | Endpoint hostname. | TLS server name used in requests. |\n| `default-load` | Boolean | `false` | Automatically load images to the Docker Engine image store. |\n\nThis guide shows you how to create a setup with a BuildKit daemon listening on a Unix socket, and have Buildx connect through it.\n\n1.  Ensure that [BuildKit](https://github.com/moby/buildkit) is installed.\n    \n    For example, you can launch an instance of buildkitd with:\n    \n    Alternatively, [see here](https://github.com/moby/buildkit/blob/master/docs/rootless.md) for running buildkitd in rootless mode or [here](https://github.com/moby/buildkit/tree/master/examples/systemd) for examples of running it as a systemd service.\n    \n2.  Check that you have a Unix socket that you can connect to.\n    \n3.  Connect Buildx to it using the remote driver:\n    \n4.  List available builders with `docker buildx ls`. You should then see `remote-unix` among them:\n    \n\nYou can switch to this new builder as the default using `docker buildx use remote-unix`, or specify it per build using `--builder`:\n\nRemember that you need to use the `--load` flag if you want to load the build result into the Docker daemon.\n\nThis guide will show you how to create setup similar to the `docker-container` driver, by manually booting a BuildKit Docker container and connecting to it using the Buildx remote driver. This procedure will manually create a container and access it via it's exposed port. (You'd probably be better of just using the `docker-container` driver that connects to BuildKit through the Docker daemon, but this is for illustration purposes.)\n\n1.  Generate certificates for BuildKit.\n    \n    You can use this [bake definition](https://github.com/moby/buildkit/blob/master/examples/create-certs) as a starting point:\n    \n    Note that while it's possible to expose BuildKit over TCP without using TLS, it's not recommended. Doing so allows arbitrary access to BuildKit without credentials.\n    \n2.  With certificates generated in `.certs/`, startup the container:\n    \n    This command starts a BuildKit container and exposes the daemon's port 1234 to localhost.\n    \n3.  Connect to this running container using Buildx:\n    \n    Alternatively, use the `docker-container://` URL scheme to connect to the BuildKit container without specifying a port:\n    \n\nThis guide will show you how to create a setup similar to the `kubernetes` driver by manually creating a BuildKit `Deployment`. While the `kubernetes` driver will do this under-the-hood, it might sometimes be desirable to scale BuildKit manually. Additionally, when executing builds from inside Kubernetes pods, the Buildx builder will need to be recreated from within each pod or copied between them.\n\n1.  Create a Kubernetes deployment of `buildkitd`, as per the instructions [here](https://github.com/moby/buildkit/tree/master/examples/kubernetes).\n    \n    Following the guide, create certificates for the BuildKit daemon and client using [create-certs.sh](https://github.com/moby/buildkit/blob/master/examples/kubernetes/create-certs.sh), and create a deployment of BuildKit pods with a service that connects to them.\n    \n2.  Assuming that the service is called `buildkitd`, create a remote builder in Buildx, ensuring that the listed certificate files are present:\n    \n\nNote that this only works internally, within the cluster, since the BuildKit setup guide only creates a `ClusterIP` service. To access a builder remotely, you can set up and use an ingress, which is outside the scope of this guide.\n\n### [Debug a remote builder in Kubernetes](#debug-a-remote-builder-in-kubernetes)\n\nIf you're having trouble accessing a remote builder deployed in Kubernetes, you can use the `kube-pod://` URL scheme to connect directly to a BuildKit pod through the Kubernetes API. Note that this method only connects to a single pod in the deployment.\n\nAlternatively, use the port forwarding mechanism of `kubectl`:\n\nThen you can point the remote driver at `tcp://localhost:1234`.",
  "title": "Remote driver | Docker Docs\n",
  "description": "The remote driver lets you connect to a remote BuildKit instance that you set up and configure manually. ",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/extend/config/",
  "markdown": "# Plugin Config Version 1 of Plugin V2\n\n```\n{\n  \"Args\": {\n    \"Description\": \"\",\n    \"Name\": \"\",\n    \"Settable\": null,\n    \"Value\": null\n  },\n  \"Description\": \"A sample volume plugin for Docker\",\n  \"Documentation\": \"https://docs.docker.com/engine/extend/plugins/\",\n  \"Entrypoint\": [\n    \"/usr/bin/sample-volume-plugin\",\n    \"/data\"\n  ],\n  \"Env\": [\n    {\n      \"Description\": \"\",\n      \"Name\": \"DEBUG\",\n      \"Settable\": [\n        \"value\"\n      ],\n      \"Value\": \"0\"\n    }\n  ],\n  \"Interface\": {\n    \"Socket\": \"plugin.sock\",\n    \"Types\": [\n      \"docker.volumedriver/1.0\"\n    ]\n  },\n  \"Linux\": {\n    \"Capabilities\": null,\n    \"AllowAllDevices\": false,\n    \"Devices\": null\n  },\n  \"Mounts\": null,\n  \"Network\": {\n    \"Type\": \"\"\n  },\n  \"PropagatedMount\": \"/data\",\n  \"User\": {},\n  \"Workdir\": \"\"\n}\n```",
  "title": "Plugin Config Version 1 of Plugin V2 | Docker Docs\n",
  "description": "How to develop and use a plugin with the managed plugin system",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/exporters/",
  "markdown": "# Exporters overview | Docker Docs\n\nExporters save your build results to a specified output type. You specify the exporter to use with the [`--output` CLI option](https://docs.docker.com/reference/cli/docker/buildx/build/#output). Buildx supports the following exporters:\n\n*   `image`: exports the build result to a container image.\n*   `registry`: exports the build result into a container image, and pushes it to the specified registry.\n*   `local`: exports the build root filesystem into a local directory.\n*   `tar`: packs the build root filesystem into a local tarball.\n*   `oci`: exports the build result to the local filesystem in the [OCI image layout](https://github.com/opencontainers/image-spec/blob/v1.0.1/image-layout.md) format.\n*   `docker`: exports the build result to the local filesystem in the [Docker Image Specification v1.2.0](https://github.com/moby/moby/blob/v25.0.0/image/spec/v1.2.md) format.\n*   `cacheonly`: doesn't export a build output, but runs the build and creates a cache.\n\nTo specify an exporter, use the following command syntax:\n\nMost common use cases don't require that you specify which exporter to use explicitly. You only need to specify the exporter if you intend to customize the output, or if you want to save it to disk. The `--load` and `--push` options allow Buildx to infer the exporter settings to use.\n\nFor example, if you use the `--push` option in combination with `--tag`, Buildx automatically uses the `image` exporter, and configures the exporter to push the results to the specified registry.\n\nTo get the full flexibility out of the various exporters BuildKit has to offer, you use the `--output` flag that lets you configure exporter options.\n\nEach exporter type is designed for different use cases. The following sections describe some common scenarios, and how you can use exporters to generate the output that you need.\n\n### [Load to image store](#load-to-image-store)\n\nBuildx is often used to build container images that can be loaded to an image store. That's where the `docker` exporter comes in. The following example shows how to build an image using the `docker` exporter, and have that image loaded to the local image store, using the `--output` option:\n\nBuildx CLI will automatically use the `docker` exporter and load it to the image store if you supply the `--tag` and `--load` options:\n\nBuilding images using the `docker` driver are automatically loaded to the local image store.\n\nImages loaded to the image store are available to `docker run` immediately after the build finishes, and you'll see them in the list of images when you run the `docker images` command.\n\n### [Push to registry](#push-to-registry)\n\nTo push a built image to a container registry, you can use the `registry` or `image` exporters.\n\nWhen you pass the `--push` option to the Buildx CLI, you instruct BuildKit to push the built image to the specified registry:\n\nUnder the hood, this uses the `image` exporter, and sets the `push` parameter. It's the same as using the following long-form command using the `--output` option:\n\nYou can also use the `registry` exporter, which does the same thing:\n\n### [Export image layout to file](#export-image-layout-to-file)\n\nYou can use either the `oci` or `docker` exporters to save the build results to image layout on your local filesystem. Both of these exporters generate a tar archive file containing the corresponding image layout. The `dest` parameter defines the target output path for the tarball.\n\n### [Export filesystem](#export-filesystem)\n\nIf you don't want to build an image from your build results, but instead export the filesystem that was built, you can use the `local` and `tar` exporters.\n\nThe `local` exporter unpacks the filesystem into a directory structure in the specified location. The `tar` exporter creates a tarball archive file.\n\nThe `local` exporter is useful in [multi-stage builds](https://docs.docker.com/build/building/multi-stage/) since it allows you to export only a minimal number of build artifacts, such as self-contained binaries.\n\n### [Cache-only export](#cache-only-export)\n\nThe `cacheonly` exporter can be used if you just want to run a build, without exporting any output. This can be useful if, for example, you want to run a test build. Or, if you want to run the build first, and create exports using subsequent commands. The `cacheonly` exporter creates a build cache, so any successive builds are instant.\n\nIf you don't specify an exporter, and you don't provide short-hand options like `--load` that automatically selects the appropriate exporter, Buildx defaults to using the `cacheonly` exporter. Except if you build using the `docker` driver, in which case you use the `docker` exporter.\n\nBuildx logs a warning message when using `cacheonly` as a default:\n\nIntroduced in Buildx version 0.13.0\n\nYou can use multiple exporters for any given build by specifying the `--output` flag multiple times. This requires **both Buildx and BuildKit** version 0.13.0 or later.\n\nThe following example runs a single build, using three different exporters:\n\n*   The `registry` exporter to push the image to a registry\n*   The `local` exporter to extract the build results to the local filesystem\n*   The `--load` flag (a shorthand for the `image` exporter) to load the results to the local image store.\n\nThis section describes some configuration options available for exporters.\n\nThe options described here are common for at least two or more exporter types. Additionally, the different exporters types support specific parameters as well. See the detailed page about each exporter for more information about which configuration parameters apply.\n\nThe common parameters described here are:\n\n*   [Compression](#compression)\n*   [OCI media type](#oci-media-types)\n\n### [Compression](#compression)\n\nWhen you export a compressed output, you can configure the exact compression algorithm and level to use. While the default values provide a good out-of-the-box experience, you may wish to tweak the parameters to optimize for storage vs compute costs. Changing the compression parameters can reduce storage space required, and improve image download times, but will increase build times.\n\nTo select the compression algorithm, you can use the `compression` option. For example, to build an `image` with `compression=zstd`:\n\nUse the `compression-level=<value>` option alongside the `compression` parameter to choose a compression level for the algorithms which support it:\n\n*   0-9 for `gzip` and `estargz`\n*   0-22 for `zstd`\n\nAs a general rule, the higher the number, the smaller the resulting file will be, and the longer the compression will take to run.\n\nUse the `force-compression=true` option to force re-compressing layers imported from a previous image, if the requested compression algorithm is different from the previous compression algorithm.\n\n> **Note**\n> \n> The `gzip` and `estargz` compression methods use the [`compress/gzip` package](https://pkg.go.dev/compress/gzip), while `zstd` uses the [`github.com/klauspost/compress/zstd` package](https://github.com/klauspost/compress/tree/master/zstd).\n\n### [OCI media types](#oci-media-types)\n\nThe `image`, `registry`, `oci` and `docker` exporters create container images. These exporters support both Docker media types (default) and OCI media types\n\nTo export images with OCI media types set, use the `oci-mediatypes` property.\n\nRead about each of the exporters to learn about how they work and how to use them:\n\n*   [Image and registry exporters](https://docs.docker.com/build/exporters/image-registry/)\n*   [OCI and Docker exporters](https://docs.docker.com/build/exporters/oci-docker/).\n*   [Local and tar exporters](https://docs.docker.com/build/exporters/local-tar/)",
  "title": "Exporters overview | Docker Docs\n",
  "description": "Build exporters define the output format of your build result",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/deploy-service/",
  "markdown": "# Deploy a service to the swarm\n\nAfter you [create a swarm](https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/), you can deploy a service to the swarm. For this tutorial, you also [added worker nodes](https://docs.docker.com/engine/swarm/swarm-tutorial/add-nodes/), but that is not a requirement to deploy a service.\n\n1.  Open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n    \n2.  Run the following command:\n    \n    *   The `docker service create` command creates the service.\n    *   The `--name` flag names the service `helloworld`.\n    *   The `--replicas` flag specifies the desired state of 1 running instance.\n    *   The arguments `alpine ping docker.com` define the service as an Alpine Linux container that executes the command `ping docker.com`.\n3.  Run `docker service ls` to see the list of running services:\n    \n\nNow you're ready to inspect the service.",
  "title": "Deploy a service to the swarm | Docker Docs\n",
  "description": "Deploy a service to the swarm",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/add-nodes/",
  "markdown": "# Add nodes to the swarm\n\nOnce you've [created a swarm](https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/) with a manager node, you're ready to add worker nodes.\n\n1.  Open a terminal and ssh into the machine where you want to run a worker node. This tutorial uses the name `worker1`.\n    \n2.  Run the command produced by the `docker swarm init` output from the [Create a swarm](https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/) tutorial step to create a worker node joined to the existing swarm:\n    \n    If you don't have the command available, you can run the following command on a manager node to retrieve the join command for a worker:\n    \n3.  Open a terminal and ssh into the machine where you want to run a second worker node. This tutorial uses the name `worker2`.\n    \n4.  Run the command produced by the `docker swarm init` output from the [Create a swarm](https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/) tutorial step to create a second worker node joined to the existing swarm:\n    \n5.  Open a terminal and ssh into the machine where the manager node runs and run the `docker node ls` command to see the worker nodes:\n    \n    The `MANAGER` column identifies the manager nodes in the swarm. The empty status in this column for `worker1` and `worker2` identifies them as worker nodes.\n    \n    Swarm management commands like `docker node ls` only work on manager nodes.\n    \n\nNow your swarm consists of a manager and two worker nodes. Next, you'll deploy a service.",
  "title": "Add nodes to the swarm | Docker Docs\n",
  "description": "Add nodes to the swarm",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/20.10/",
  "markdown": "# Docker Engine 20.10 release notes\n\nThis document describes the latest changes, additions, known issues, and fixes for Docker Engine version 20.10.\n\n_2023-04-04_\n\n### [Updates](#updates)\n\n*   Update Go runtime to [1.19.7](https://go.dev/doc/devel/release#go1.19.minor).\n*   Update Docker Buildx to [v0.10.4](https://github.com/docker/buildx/releases/tag/v0.10.4).\n*   Update containerd to [v1.6.20](https://github.com/containerd/containerd/releases/tag/v1.6.20).\n*   Update runc to [v1.1.5](https://github.com/opencontainers/runc/releases/tag/v1.1.5).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements)\n\n*   Fixed a number of issues that can cause Swarm encrypted overlay networks to fail to uphold their guarantees, addressing [CVE-2023-28841](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-28841), [CVE-2023-28840](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-28840), and [CVE-2023-28842](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-28842).\n    *   A lack of kernel support for encrypted overlay networks now reports as an error.\n    *   Encrypted overlay networks are eagerly set up, rather than waiting for multiple nodes to attach.\n    *   Encrypted overlay networks are now usable on Red Hat Enterprise Linux 9 through the use of the `xt_bpf` kernel module.\n    *   Users of Swarm overlay networks should review [GHSA-vwm3-crmr-xfxw](https://github.com/moby/moby/security/advisories/GHSA-vwm3-crmr-xfxw) to ensure that unintentional exposure has not occurred.\n*   Upgrade github.com/containerd/fifo to v1.1.0 to fix a potential panic [moby/moby#45216](https://github.com/moby/moby/pull/45242).\n*   Fix missing Bash completion for installed cli-plugins [docker/cli#4091](https://github.com/docker/cli/pull/4091).\n\n_2023-01-19_\n\nThis release of Docker Engine contains updated versions of Docker Compose, Docker Buildx, containerd, and some minor bug fixes and enhancements.\n\n### [Updates](#updates-1)\n\n*   Update Docker Compose to [v2.15.1](https://github.com/docker/compose/releases/tag/v2.15.1).\n*   Update Docker Buildx to [v0.10.0](https://github.com/docker/buildx/releases/tag/v0.10.0).\n*   Update containerd (`containerd.io` package) to [v1.6.15](https://github.com/containerd/containerd/releases/tag/v1.6.15).\n*   Update the package versioning format for `docker-compose-cli` to allow distro version updates [docker/docker-ce-packaging#822](https://github.com/docker/docker-ce-packaging/pull/822).\n*   Update Go runtime to [1.18.10](https://go.dev/doc/devel/release#go1.18.minor),\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-1)\n\n*   Fix an issue where `docker build` would fail when using `--add-host=host.docker.internal:host-gateway` with BuildKit enabled [moby/moby#44650](https://github.com/moby/moby/pull/44650).\n    \n*   Revert seccomp: block socket calls to `AF_VSOCK` in default profile [moby/moby#44712](https://github.com/moby/moby/pull/44712).\n    \n    This change, while favorable from a security standpoint, caused a change in behavior for some use-cases. As such, we are reverting it to ensure stability and compatibility for the affected users.\n    \n    However, users of `AF_VSOCK` in containers should recognize that this (special) address family is not currently namespaced in any version of the Linux kernel, and may result in unexpected behavior, like containers communicating directly with host hypervisors.\n    \n    Future releases, will filter `AF_VSOCK`. Users who need to allow containers to communicate over the unnamespaced `AF_VSOCK` will need to turn off seccomp confinement or set a custom seccomp profile.\n    \n\n_2022-12-16_\n\nThis release of Docker Engine contains updated versions of Docker Compose, Docker Scan, containerd, and some minor bug fixes and enhancements.\n\n### [Updates](#updates-2)\n\n*   Update Docker Compose to [v2.14.1](https://github.com/docker/compose/releases/tag/v2.14.1).\n*   Update Docker Scan to [v0.23.0](https://github.com/docker/scan-cli-plugin/releases/tag/v0.23.0).\n*   Update containerd (`containerd.io` package) to [v1.6.13](https://github.com/containerd/containerd/releases/tag/v1.6.13), to include a fix for [CVE-2022-23471](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23471).\n*   Update Go runtime to [1.18.9](https://go.dev/doc/devel/release#go1.18.minor), to include fixes for [CVE-2022-41716](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41716), [CVE-2022-41717](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41717), and [CVE-2022-41720](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41720).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-2)\n\n*   Improve error message when attempting to pull an unsupported image format or OCI artifact [moby/moby#44413](https://github.com/moby/moby/pull/44413), [moby/moby#44569](https://github.com/moby/moby/pull/44569).\n*   Fix an issue where the host's ephemeral port-range was ignored when selecting random ports for containers [moby/moby#44476](https://github.com/moby/moby/pull/44476).\n*   Fix `ssh: parse error in message type 27` errors during `docker build` on hosts using OpenSSH 8.9 or above [moby/moby#3862](https://github.com/moby/moby/pull/3862).\n*   seccomp: block socket calls to `AF_VSOCK` in default profile [moby/moby#44564](https://github.com/moby/moby/pull/44564).\n\n_2022-10-25_\n\nThis release of Docker Engine contains updated versions of Docker Compose, Docker Scan, containerd, added packages for Ubuntu 22.10, and some minor bug fixes and enhancements.\n\n### [New](#new)\n\n*   Provide packages for Ubuntu 22.10 (Kinetic Kudu).\n*   Add support for `allow-nondistributable-artifacts` towards Docker Hub [moby/moby#44313](https://github.com/moby/moby/pull/44313).\n\n### [Updates](#updates-3)\n\n*   Update Docker Compose to [v2.12.2](https://github.com/docker/compose/releases/tag/v2.12.2).\n*   Update Docker Scan to [v0.21.0](https://github.com/docker/scan-cli-plugin/releases/tag/v0.21.0).\n*   Update containerd (`containerd.io` package) to [v1.6.9](https://github.com/containerd/containerd/releases/tag/v1.6.9).\n*   Update bundled BuildKit version to fix `output clipped, log limit 1MiB reached` errors [moby/moby#44339](https://github.com/moby/moby/pull/44339).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-3)\n\n*   Remove experimental gate for `--platform` in bash completion [docker/cli#3824](https://github.com/docker/cli/pull/3824).\n*   Fix an `Invalid standard handle identifier` panic when registering the Docker Engine as a service from a legacy CLI on Windows [moby/moby#44326](https://github.com/moby/moby/pull/44326).\n*   Fix running Git commands in Cygwin on Windows [moby/moby#44332](https://github.com/moby/moby/pull/44332).\n\n_2022-10-18_\n\nThis release of Docker Engine contains partial mitigations for a Git vulnerability ( [CVE-2022-39253](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-39253)), and has updated handling of `image:tag@digest` image references.\n\nThe Git vulnerability allows a maliciously crafted Git repository, when used as a build context, to copy arbitrary filesystem paths into resulting containers/images; this can occur in both the daemon, and in API clients, depending on the versions and tools in use.\n\nThe mitigations available in this release and in other consumers of the daemon API are partial and only protect users who build a Git URL context (e.g. `git+protocol://`). As the vulnerability could still be exploited by manually run Git commands that interact with and check out submodules, users should immediately upgrade to a patched version of Git to protect against this vulnerability. Further details are available from the GitHub blog ( [\"Git security vulnerabilities announced\"](https://github.blog/2022-10-18-git-security-vulnerabilities-announced/)).\n\n### [Updates](#updates-4)\n\n*   Update Docker Compose to [v2.12.0](https://github.com/docker/compose/releases/tag/v2.12.0).\n*   Updated handling of `image:tag@digest` references. When pulling an image using the `image:tag@digest` (\"pull by digest\"), image resolution happens through the content-addressable digest and the `image` and `tag` are not used. While this is expected, this could lead to confusing behavior, and could potentially be exploited through social engineering to run an image that is already present in the local image store. Docker now checks if the digest matches the repository name used to pull the image, and otherwise will produce an error.\n*   Updated handling of `image:tag@digest` references. Refer to the \"Daemon\" section above for details.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-4)\n\n*   Added a mitigation for [CVE-2022-39253](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-39253), when using the classic Builder with a Git URL as the build context.\n*   Added a mitigation to the classic Builder and updated BuildKit to [v0.8.3-31-gc0149372](https://github.com/moby/buildkit/commit/c014937225cba29cfb1d5161fd134316c0e9bdaa), for [CVE-2022-39253](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-39253).\n\n_2022-10-14_\n\nThis release of Docker Engine comes with some bug-fixes, and an updated version of Docker Compose.\n\n### [Updates](#updates-5)\n\n*   Update Docker Compose to [v2.11.2](https://github.com/docker/compose/releases/tag/v2.11.2).\n*   Update Go runtime to [1.18.7](https://go.dev/doc/devel/release#go1.18.minor), which contains fixes for [CVE-2022-2879](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-2879), [CVE-2022-2880](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-2880), and [CVE-2022-41715](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41715).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-5)\n\n*   Fix an issue that could result in a panic during `docker builder prune` or `docker system prune` [moby/moby#44122](https://github.com/moby/moby/pull/44122).\n*   Fix a bug where using `docker volume prune` would remove volumes that were still in use if the daemon was running with \"live restore\" and was restarted [moby/moby#44238](https://github.com/moby/moby/pull/44238).\n\n_2022-09-09_\n\nThis release of Docker Engine comes with a fix for a low-severity security issue, some minor bug fixes, and updated versions of Docker Compose, Docker Buildx, `containerd`, and `runc`.\n\n### [Updates](#updates-6)\n\n*   Update Docker Buildx to [v0.9.1](https://github.com/docker/buildx/releases/tag/v0.9.1).\n*   Update Docker Compose to [v2.10.2](https://github.com/docker/compose/releases/tag/v2.10.2).\n*   Update containerd (`containerd.io` package) to [v1.6.8](https://github.com/containerd/containerd/releases/tag/v1.6.8).\n*   Update runc version to [v1.1.4](https://github.com/opencontainers/runc/releases/tag/v1.1.4).\n*   Update Go runtime to [1.18.6](https://go.dev/doc/devel/release#go1.18.minor), which contains fixes for [CVE-2022-27664](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-27664) and [CVE-2022-32190](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-32190).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-6)\n\n*   Add Bash completion for Docker Compose [docker/cli#3752](https://github.com/docker/cli/pull/3752).\n*   Fix an issue where file-capabilities were not preserved during build [moby/moby#43876](https://github.com/moby/moby/pull/43876).\n*   Fix an issue that could result in a panic caused by a concurrent map read and map write [moby/moby#44067](https://github.com/moby/moby/pull/44067).\n*   Fix a security vulnerability relating to supplementary group permissions, which could allow a container process to bypass primary group restrictions within the container [CVE-2022-36109](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36109), [GHSA-rc4r-wh2q-q6c4](https://github.com/moby/moby/security/advisories/GHSA-rc4r-wh2q-q6c4).\n*   seccomp: add support for Landlock syscalls in default policy [moby/moby#43991](https://github.com/moby/moby/pull/43991).\n*   seccomp: update default policy to support new syscalls introduced in kernel 5.12 - 5.16 [moby/moby#43991](https://github.com/moby/moby/pull/43991).\n*   Fix an issue where cache lookup for image manifests would fail, resulting in a redundant round-trip to the image registry [moby/moby#44109](https://github.com/moby/moby/pull/44109).\n*   Fix an issue where `exec` processes and healthchecks were not terminated when they timed out [moby/moby#44018](https://github.com/moby/moby/pull/44018).\n\n_2022-06-06_\n\nThis release of Docker Engine comes with updated versions of Docker Compose and the `containerd`, and `runc` components, as well as some minor bug fixes.\n\n### [Updates](#updates-7)\n\n*   Update Docker Compose to [v2.6.0](https://github.com/docker/compose/releases/tag/v2.6.0).\n*   Update containerd (`containerd.io` package) to [v1.6.6](https://github.com/containerd/containerd/releases/tag/v1.6.6), which contains a fix for [CVE-2022-31030](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-31030)\n*   Update runc version to [v1.1.2](https://github.com/opencontainers/runc/releases/tag/v1.1.2), which contains a fix for [CVE-2022-29162](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29162).\n*   Update Go runtime to [1.17.11](https://go.dev/doc/devel/release#go1.17.minor), which contains fixes for [CVE-2022-30634](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-30634), [CVE-2022-30629](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-30629), [CVE-2022-30580](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-30580) and [CVE-2022-29804](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29804)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-7)\n\n*   Remove asterisk from docker commands in zsh completion script [docker/cli#3648](https://github.com/docker/cli/pull/3648).\n*   Fix Windows port conflict with published ports in host mode for overlay [moby/moby#43644](https://github.com/moby/moby/pull/43644).\n*   Ensure performance tuning is always applied to libnetwork sandboxes [moby/moby#43683](https://github.com/moby/moby/pull/43683).\n\n_2022-05-12_\n\nThis release of Docker Engine fixes a regression in the Docker CLI builds for macOS, fixes an issue with `docker stats` when using containerd 1.5 and up, and updates the Go runtime to include a fix for [CVE-2022-29526](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29526).\n\n### [Updates](#updates-8)\n\n*   Update golang.org/x/sys dependency which contains a fix for [CVE-2022-29526](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29526).\n*   Updated the `golang.org/x/sys` build-time dependency which contains a fix for [CVE-2022-29526](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29526).\n*   Updated Go runtime to [1.17.10](https://go.dev/doc/devel/release#go1.17.minor), which contains a fix for [CVE-2022-29526](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29526).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-8)\n\n*   Fixed a regression in binaries for macOS introduced in [20.10.15](#201015), which resulted in a panic [docker/cli#43426](https://github.com/docker/cli/pull/3592).\n*   Fixed an issue where `docker stats` was showing empty stats when running with containerd 1.5.0 or up [moby/moby#43567](https://github.com/moby/moby/pull/43567).\n*   Used \"weak\" dependencies for the `docker scan` CLI plugin, to prevent a \"conflicting requests\" error when users performed an off-line installation from downloaded RPM packages [docker/docker-ce-packaging#659](https://github.com/docker/docker-ce-packaging/pull/659).\n\n_2022-05-05_\n\nThis release of Docker Engine comes with updated versions of the `compose`, `buildx`, `containerd`, and `runc` components, as well as some minor bug fixes.\n\n### [Updates](#updates-9)\n\n*   Update Docker Compose to [v2.5.0](https://github.com/docker/compose/releases/tag/v2.5.0).\n*   Update Docker Buildx to [v0.8.2](https://github.com/docker/buildx/releases/tag/v0.8.2).\n*   Update Go runtime to [1.17.9](https://go.dev/doc/devel/release#go1.17.minor).\n*   Update containerd (`containerd.io` package) to [v1.6.4](https://github.com/containerd/containerd/releases/tag/v1.6.4).\n*   Update runc version to [v1.1.1](https://github.com/opencontainers/runc/releases/tag/v1.1.1).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-9)\n\n*   Use a RWMutex for stateCounter to prevent potential locking congestion [moby/moby#43426](https://github.com/moby/moby/pull/43426).\n*   Prevent an issue where the daemon was unable to find an available IP-range in some conditions [moby/moby#43360](https://github.com/moby/moby/pull/43360)\n*   Add packages for CentOS 9 stream and Fedora 36.\n\n### [Known issues](#known-issues)\n\n*   We've identified an issue with the [macOS CLI binaries](https://download.docker.com/mac/static/stable/) in the 20.10.15 release. This issue has been resolved in the [20.10.16](#201016) release.\n\n_2022-03-23_\n\nThis release of Docker Engine updates the default inheritable capabilities for containers to address [CVE-2022-24769](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-24769), a new version of the `containerd.io` runtime is also included to address the same issue.\n\n### [Updates](#updates-10)\n\n*   Update the default inheritable capabilities.\n*   Update the default inheritable capabilities for containers used during build.\n*   Update containerd (`containerd.io` package) to [v1.5.11](https://github.com/containerd/containerd/releases/tag/v1.5.11).\n*   Update `docker buildx` to [v0.8.1](https://github.com/docker/buildx/releases/tag/v0.8.1).\n\n_2022-03-10_\n\nThis release of Docker Engine contains some bug-fixes and packaging changes, updates to the `docker scan` and `docker buildx` commands, an updated version of the Go runtime, and new versions of the `containerd.io` runtime. Together with this release, we now also provide `.deb` and `.rpm` packages of Docker Compose V2, which can be installed using the (optional) `docker-compose-plugin` package.\n\n### [New](#new-1)\n\n*   Provide `.deb` and `.rpm` packages for Docker Compose V2. [Docker Compose v2.3.3](https://github.com/docker/compose/releases/tag/v2.3.3) can now be installed on Linux using the `docker-compose-plugin` packages, which provides the `docker compose` subcommand on the Docker CLI. The Docker Compose plugin can also be installed and run standalone to be used as a drop-in replacement for `docker-compose` (Docker Compose V1) [docker/docker-ce-packaging#638](https://github.com/docker/docker-ce-packaging/pull/638). The `compose-cli-plugin` package can also be used on older version of the Docker CLI with support for CLI plugins (Docker CLI 18.09 and up).\n*   Provide packages for the upcoming Ubuntu 22.04 \"Jammy Jellyfish\" LTS release [docker/docker-ce-packaging#645](https://github.com/docker/docker-ce-packaging/pull/645), [docker/containerd-packaging#271](https://github.com/docker/containerd-packaging/pull/271).\n\n### [Updates](#updates-11)\n\n*   Updated the bundled version of buildx to [v0.8.0](https://github.com/docker/buildx/releases/tag/v0.8.0).\n*   Update `docker buildx` to [v0.8.0](https://github.com/docker/buildx/releases/tag/v0.8.0).\n*   Update `docker scan` (`docker-scan-plugin`) to [v0.17.0](https://github.com/docker/scan-cli-plugin/releases/tag/v0.17.0).\n*   Update containerd (`containerd.io` package) to [v1.5.10](https://github.com/containerd/containerd/releases/tag/v1.5.10).\n*   Update the bundled runc version to [v1.0.3](https://github.com/opencontainers/runc/releases/tag/v1.0.3).\n*   Update Golang runtime to Go 1.16.15.\n*   Updates the fluentd log driver to prevent a potential daemon crash, and prevent containers from hanging when using the `fluentd-async-connect=true` and the remote server is unreachable [moby/moby#43147](https://github.com/moby/moby/pull/43147).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-10)\n\n*   Fix a race condition when updating the container's state [moby/moby#43166](https://github.com/moby/moby/pull/43166).\n*   Update the etcd dependency to prevent the daemon from incorrectly holding file locks [moby/moby#43259](https://github.com/moby/moby/pull/43259)\n*   Fix detection of user-namespaces when configuring the default `net.ipv4.ping_group_range` sysctl [moby/moby#43084](https://github.com/moby/moby/pull/43084).\n*   Retry downloading image-manifests if a connection failure happens during image pull [moby/moby#43333](https://github.com/moby/moby/pull/43333).\n*   Various fixes in command-line reference and API documentation.\n*   Prevent an OOM when using the \"local\" logging driver with containers that produce a large amount of log messages [moby/moby#43165](https://github.com/moby/moby/pull/43165).\n\n2021-12-13\n\nThis release of Docker Engine contains changes in packaging only, and provides updates to the `docker scan` and `docker buildx` commands. Versions of `docker scan` before v0.11.0 are not able to detect the [Log4j 2 CVE-2021-44228](https://nvd.nist.gov/vuln/detail/CVE-2021-44228). We are shipping an updated version of `docker scan` in this release to help you scan your images for this vulnerability.\n\n> **Note**\n> \n> The `docker scan` command on Linux is currently only supported on x86 platforms. We do not yet provide a package for other hardware architectures on Linux.\n\nThe `docker scan` feature is provided as a separate package and, depending on your upgrade or installation method, 'docker scan' may not be updated automatically to the latest version. Use the instructions below to update `docker scan` to the latest version. You can also use these instructions to install, or upgrade the `docker scan` package without upgrading the Docker Engine:\n\nOn `.deb` based distros, such as Ubuntu and Debian:\n\nOn rpm-based distros, such as CentOS or Fedora:\n\nAfter upgrading, verify you have the latest version of `docker scan` installed:\n\n[Read our blog post on CVE-2021-44228](https://www.docker.com/blog/apache-log4j-2-cve-2021-44228/) to learn how to use the `docker scan` command to check if images are vulnerable.\n\n### [Packaging](#packaging)\n\n*   Update `docker scan` to [v0.12.0](https://github.com/docker/scan-cli-plugin/releases/tag/v0.12.0).\n*   Update `docker buildx` to [v0.7.1](https://github.com/docker/buildx/releases/tag/v0.7.1).\n*   Update Golang runtime to Go 1.16.12.\n\n2021-11-17\n\n> **IMPORTANT**\n> \n> Due to [net/http changes](https://github.com/golang/go/issues/40909) in [Go 1.16](https://golang.org/doc/go1.16#net/http), HTTP proxies configured through the `$HTTP_PROXY` environment variable are no longer used for TLS (`https://`) connections. Make sure you also set an `$HTTPS_PROXY` environment variable for handling requests to `https://` URLs.\n> \n> Refer to [Configure the daemon to use a proxy](https://docs.docker.com/config/daemon/proxy/) to learn how to configure the Docker Daemon to use a proxy server.\n\n### [Distribution](#distribution)\n\n*   Handle ambiguous OCI manifest parsing to mitigate [CVE-2021-41190](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41190) / [GHSA-mc8v-mgrf-8f4m](https://github.com/opencontainers/distribution-spec/security/advisories/GHSA-mc8v-mgrf-8f4m). See [GHSA-xmmx-7jpf-fx42](https://github.com/moby/moby/security/advisories/GHSA-xmmx-7jpf-fx42) for details.\n\n### [Windows](#windows)\n\n*   Fix panic.log file having read-only attribute set [moby/moby#42987](https://github.com/moby/moby/pull/42987).\n\n### [Packaging](#packaging-1)\n\n*   Update containerd to [v1.4.12](https://github.com/containerd/containerd/releases/tag/v1.4.12) to mitigate [CVE-2021-41190](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41190).\n*   Update Golang runtime to Go 1.16.10.\n\n2021-10-25\n\n> **IMPORTANT**\n> \n> Due to [net/http changes](https://github.com/golang/go/issues/40909) in [Go 1.16](https://golang.org/doc/go1.16#net/http), HTTP proxies configured through the `$HTTP_PROXY` environment variable are no longer used for TLS (`https://`) connections. Make sure you also set an `$HTTPS_PROXY` environment variable for handling requests to `https://` URLs.\n> \n> Refer to the [HTTP/HTTPS proxy section](https://docs.docker.com/config/daemon/proxy/#httphttps-proxy) to learn how to configure the Docker Daemon to use a proxy server.\n\n### [Builder](#builder)\n\n*   Fix platform-matching logic to fix `docker build` using not finding images in the local image cache on Arm machines when using BuildKit [moby/moby#42954](https://github.com/moby/moby/pull/42954)\n\n### [Runtime](#runtime)\n\n*   Add support for `clone3` syscall in the default seccomp policy to support running containers based on recent versions of Fedora and Ubuntu. [moby/moby/#42836](https://github.com/moby/moby/pull/42836).\n*   Windows: update hcsshim library to fix a bug in sparse file handling in container layers, which was exposed by recent changes in Windows [moby/moby#42944](https://github.com/moby/moby/pull/42944).\n*   Fix some situations where `docker stop` could hang forever [moby/moby#42956](https://github.com/moby/moby/pull/42956).\n\n### [Swarm](#swarm)\n\n*   Fix an issue where updating a service did not roll back on failure [moby/moby#42875](https://github.com/moby/moby/pull/42875).\n\n### [Packaging](#packaging-2)\n\n*   Add packages for Ubuntu 21.10 \"Impish Indri\" and Fedora 35.\n*   Update `docker scan` to v0.9.0\n*   Update Golang runtime to Go 1.16.9.\n\n2021-10-04\n\nThis release is a security release with security fixes in the CLI, runtime, as well as updated versions of the containerd.io package.\n\n> **IMPORTANT**\n> \n> Due to [net/http changes](https://github.com/golang/go/issues/40909) in [Go 1.16](https://golang.org/doc/go1.16#net/http), HTTP proxies configured through the `$HTTP_PROXY` environment variable are no longer used for TLS (`https://`) connections. Make sure you also set an `$HTTPS_PROXY` environment variable for handling requests to `https://` URLs.\n> \n> Refer to the [HTTP/HTTPS proxy section](https://docs.docker.com/config/daemon/proxy/#httphttps-proxy) to learn how to configure the Docker Daemon to use a proxy server.\n\n### [Client](#client)\n\n*   [CVE-2021-41092](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41092) Ensure default auth config has address field set, to prevent credentials being sent to the default registry.\n\n### [Runtime](#runtime-1)\n\n*   [CVE-2021-41089](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41089) Create parent directories inside a chroot during `docker cp` to prevent a specially crafted container from changing permissions of existing files in the hostâ€™s filesystem.\n*   [CVE-2021-41091](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41091) Lock down file permissions to prevent unprivileged users from discovering and executing programs in `/var/lib/docker`.\n\n### [Packaging](#packaging-3)\n\n> **Known issue**\n> \n> The `ctr` binary shipping with the static packages of this release is not statically linked, and will not run in Docker images using alpine as a base image. Users can install the `libc6-compat` package, or download a previous version of the `ctr` binary as a workaround. Refer to the containerd ticket related to this issue for more details: [containerd/containerd#5824](https://github.com/containerd/containerd/issues/5824).\n\n*   Update Golang runtime to Go 1.16.8, which contains fixes for [CVE-2021-36221](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-36221) and [CVE-2021-39293](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-39293)\n*   Update static binaries and containerd.io rpm and deb packages to containerd v1.4.11 and runc v1.0.2 to address [CVE-2021-41103](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41103).\n*   Update the bundled buildx version to v0.6.3 for rpm and deb packages.\n\n2021-08-03\n\n> **IMPORTANT**\n> \n> Due to [net/http changes](https://github.com/golang/go/issues/40909) in [Go 1.16](https://golang.org/doc/go1.16#net/http), HTTP proxies configured through the `$HTTP_PROXY` environment variable are no longer used for TLS (`https://`) connections. Make sure you also set an `$HTTPS_PROXY` environment variable for handling requests to `https://` URLs.\n> \n> Refer to the [HTTP/HTTPS proxy section](https://docs.docker.com/config/daemon/proxy/#httphttps-proxy) to learn how to configure the Docker Daemon to use a proxy server.\n\n### [Deprecation](#deprecation)\n\n*   Deprecate support for encrypted TLS private keys. Legacy PEM encryption as specified in RFC 1423 is insecure by design. Because it does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext. Support for encrypted TLS private keys is now marked as deprecated, and will be removed in an upcoming release. [docker/cli#3219](https://github.com/docker/cli/pull/3219)\n*   Deprecate Kubernetes stack support. Following the deprecation of [Compose on Kubernetes](https://github.com/docker/compose-on-kubernetes), support for Kubernetes in the `stack` and `context` commands in the Docker CLI is now marked as deprecated, and will be removed in an upcoming release [docker/cli#3174](https://github.com/docker/cli/pull/3174).\n\n### [Client](#client-1)\n\n*   Fix `Invalid standard handle identifier` errors on Windows [docker/cli#3132](https://github.com/docker/cli/pull/3132).\n\n### [Rootless](#rootless)\n\n*   Avoid `can't open lock file /run/xtables.lock: Permission denied` error on SELinux hosts [moby/moby#42462](https://github.com/moby/moby/pull/42462).\n*   Disable overlay2 when running with SELinux to prevent permission denied errors [moby/moby#42462](https://github.com/moby/moby/pull/42462).\n*   Fix `x509: certificate signed by unknown authority` error on openSUSE Tumbleweed [moby/moby#42462](https://github.com/moby/moby/pull/42462).\n\n### [Runtime](#runtime-2)\n\n*   Print a warning when using the `--platform` option to pull a single-arch image that does not match the specified architecture [moby/moby#42633](https://github.com/moby/moby/pull/42633).\n*   Fix incorrect `Your kernel does not support swap memory limit` warning when running with cgroups v2 [moby/moby#42479](https://github.com/moby/moby/pull/42479).\n*   Windows: Fix a situation where containers were not stopped if `HcsShutdownComputeSystem` returned an `ERROR_PROC_NOT_FOUND` error [moby/moby#42613](https://github.com/moby/moby/pull/42613)\n\n### [Swarm](#swarm-1)\n\n*   Fix a possibility where overlapping IP addresses could exist as a result of the node failing to clean up its old loadbalancer IPs [moby/moby#42538](https://github.com/moby/moby/pull/42538)\n*   Fix a deadlock in log broker (\"dispatcher is stopped\") [moby/moby#42537](https://github.com/moby/moby/pull/42537)\n\n### [Packaging](#packaging-4)\n\n> **Known issue**\n> \n> The `ctr` binary shipping with the static packages of this release is not statically linked, and will not run in Docker images using alpine as a base image. Users can install the `libc6-compat` package, or download a previous version of the `ctr` binary as a workaround. Refer to the containerd ticket related to this issue for more details: [containerd/containerd#5824](https://github.com/containerd/containerd/issues/5824).\n\n*   Remove packaging for Ubuntu 16.04 \"Xenial\" and Fedora 32, as they reached EOL [docker/docker-ce-packaging#560](https://github.com/docker/docker-ce-packaging/pull/560)\n*   Update Golang runtime to Go 1.16.6\n*   Update the bundled buildx version to v0.6.1 for rpm and deb packages [docker/docker-ce-packaging#562](https://github.com/docker/docker-ce-packaging/pull/562)\n*   Update static binaries and containerd.io rpm and deb packages to containerd v1.4.9 and runc v1.0.1: [docker/containerd-packaging#241](https://github.com/docker/containerd-packaging/pull/241), [docker/containerd-packaging#245](https://github.com/docker/containerd-packaging/pull/245), [docker/containerd-packaging#247](https://github.com/docker/containerd-packaging/pull/247).\n\n2021-06-02\n\n### [Client](#client-2)\n\n*   Suppress warnings for deprecated cgroups [docker/cli#3099](https://github.com/docker/cli/pull/3099).\n*   Prevent sending `SIGURG` signals to container on Linux and macOS. The Go runtime (starting with Go 1.14) uses `SIGURG` signals internally as an interrupt to support preemptable syscalls. In situations where the Docker CLI was attached to a container, these interrupts were forwarded to the container. This fix changes the Docker CLI to ignore `SIGURG` signals [docker/cli#3107](https://github.com/docker/cli/pull/3107), [moby/moby#42421](https://github.com/moby/moby/pull/42421).\n\n### [Builder](#builder-1)\n\n*   Update BuildKit to version v0.8.3-3-g244e8cde [moby/moby#42448](https://github.com/moby/moby/pull/42448):\n    *   Transform relative mountpoints for exec mounts in the executor to work around a breaking change in runc v1.0.0-rc94 and up. [moby/buildkit#2137](https://github.com/moby/buildkit/pull/2137).\n    *   Add retry on image push 5xx errors. [moby/buildkit#2043](https://github.com/moby/buildkit/pull/2043).\n    *   Fix build-cache not being invalidated when renaming a file that is copied using a `COPY` command with a wildcard. Note that this change invalidates existing build caches for copy commands that use a wildcard. [moby/buildkit#2018](https://github.com/moby/buildkit/pull/2018).\n    *   Fix build-cache not being invalidated when using mounts [moby/buildkit#2076](https://github.com/moby/buildkit/pull/2076).\n*   Fix build failures when `FROM` image is not cached when using legacy schema 1 images [moby/moby#42382](https://github.com/moby/moby/pull/42382).\n\n### [Logging](#logging)\n\n*   Update the hcsshim SDK to make daemon logs on Windows less verbose [moby/moby#42292](https://github.com/moby/moby/pull/42292).\n\n### [Rootless](#rootless-1)\n\n*   Fix capabilities not being honored when an image was built on a daemon with user-namespaces enabled [moby/moby#42352](https://github.com/moby/moby/pull/42352).\n\n### [Networking](#networking)\n\n*   Update libnetwork to fix publishing ports on environments with kernel boot parameter `ipv6.disable=1`, and to fix a deadlock causing internal DNS lookups to fail [moby/moby#42413](https://github.com/moby/moby/pull/42413).\n\n### [Contrib](#contrib)\n\n*   Update rootlesskit to v0.14.2 to fix a timeout when starting the userland proxy with the `slirp4netns` port driver [moby/moby#42294](https://github.com/moby/moby/pull/42294).\n*   Fix \"Device or resource busy\" errors when running docker-in-docker on a rootless daemon [moby/moby#42342](https://github.com/moby/moby/pull/42342).\n\n### [Packaging](#packaging-5)\n\n*   Update containerd to v1.4.6, runc v1.0.0-rc95 to address [CVE-2021-30465](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-30465) [moby/moby#42398](https://github.com/moby/moby/pull/42398), [moby/moby#42395](https://github.com/moby/moby/pull/42395), [docker/containerd-packaging#234](https://github.com/docker/containerd-packaging/pull/234)\n*   Update containerd to v1.4.5, runc v1.0.0-rc94 [moby/moby#42372](https://github.com/moby/moby/pull/42372), [moby/moby#42388](https://github.com/moby/moby/pull/42388), [docker/containerd-packaging#232](https://github.com/docker/containerd-packaging/pull/232).\n*   Update Docker Scan plugin packages (`docker-scan-plugin`) to v0.8 [docker/docker-ce-packaging#545](https://github.com/docker/docker-ce-packaging/pull/545).\n\n2021-04-12\n\n### [Client](#client-3)\n\n*   Apple Silicon (darwin/arm64) support for Docker CLI [docker/cli#3042](https://github.com/docker/cli/pull/3042)\n*   config: print deprecation warning when falling back to pre-v1.7.0 config file `~/.dockercfg`. Support for this file will be removed in a future release [docker/cli#3000](https://github.com/docker/cli/pull/3000)\n\n### [Builder](#builder-2)\n\n*   Fix classic builder silently ignoring unsupported Dockerfile options and prompt to enable BuildKit instead [moby/moby#42197](https://github.com/moby/moby/pull/42197)\n\n### [Logging](#logging-1)\n\n*   json-file: fix sporadic unexpected EOF errors [moby/moby#42174](https://github.com/moby/moby/pull/42174)\n\n### [Networking](#networking-1)\n\n*   Fix a regression in docker 20.10, causing IPv6 addresses no longer to be bound by default when mapping ports [moby/moby#42205](https://github.com/moby/moby/pull/42205)\n*   Fix implicit IPv6 port-mappings not included in API response. Before docker 20.10, published ports were accessible through both IPv4 and IPv6 by default, but the API only included information about the IPv4 (0.0.0.0) mapping [moby/moby#42205](https://github.com/moby/moby/pull/42205)\n*   Fix a regression in docker 20.10, causing the docker-proxy to not be terminated in all cases [moby/moby#42205](https://github.com/moby/moby/pull/42205)\n*   Fix iptables forwarding rules not being cleaned up upon container removal [moby/moby#42205](https://github.com/moby/moby/pull/42205)\n\n### [Packaging](#packaging-6)\n\n*   Update containerd to [v1.4.4](https://github.com/containerd/containerd/releases/tag/v1.4.4) for static binaries. The containerd.io package on apt/yum repos already had this update out of band. Includes a fix for [CVE-2021-21334](https://github.com/containerd/containerd/security/advisories/GHSA-6g2q-w5j3-fwh4). [moby/moby#42124](https://github.com/moby/moby/pull/42124)\n*   Packages for Debian/Raspbian 11 Bullseye, Ubuntu 21.04 Hirsute Hippo and Fedora 34 [docker/docker-ce-packaging#521](https://github.com/docker/docker-ce-packaging/pull/521) [docker/docker-ce-packaging#522](https://github.com/docker/docker-ce-packaging/pull/522) [docker/docker-ce-packaging#533](https://github.com/docker/docker-ce-packaging/pull/533)\n*   Provide the [Docker Scan CLI](https://github.com/docker/scan-cli-plugin) plugin on Linux amd64 via a `docker-scan-plugin` package as a recommended dependency for the `docker-ce-cli` package [docker/docker-ce-packaging#537](https://github.com/docker/docker-ce-packaging/pull/537)\n*   Include VPNKit binary for arm64 [moby/moby#42141](https://github.com/moby/moby/pull/42141)\n\n### [Plugins](#plugins)\n\n*   Fix docker plugin create making plugins that were incompatible with older versions of Docker [moby/moby#42256](https://github.com/moby/moby/pull/42256)\n\n### [Rootless](#rootless-2)\n\n*   Update RootlessKit to [v0.14.1](https://github.com/rootless-containers/rootlesskit/releases/tag/v0.14.1) (see also [v0.14.0](https://github.com/rootless-containers/rootlesskit/releases/tag/v0.14.0) [v0.13.2](https://github.com/rootless-containers/rootlesskit/releases/tag/v0.13.2)) [moby/moby#42186](https://github.com/moby/moby/pull/42186) [moby/moby#42232](https://github.com/moby/moby/pull/42232)\n*   dockerd-rootless-setuptool.sh: create CLI context \"rootless\" [moby/moby#42109](https://github.com/moby/moby/pull/42109)\n*   dockerd-rootless.sh: prohibit running as root [moby/moby#42072](https://github.com/moby/moby/pull/42072)\n*   Fix \"operation not permitted\" when bind mounting existing mounts [moby/moby#42233](https://github.com/moby/moby/pull/42233)\n*   overlay2: fix \"createDirWithOverlayOpaque(...) ... input/output error\" [moby/moby#42235](https://github.com/moby/moby/pull/42235)\n*   overlay2: support \"userxattr\" option (kernel 5.11) [moby/moby#42168](https://github.com/moby/moby/pull/42168)\n*   btrfs: allow unprivileged user to delete subvolumes (kernel >= 4.18) [moby/moby#42253](https://github.com/moby/moby/pull/42253)\n*   cgroup2: Move cgroup v2 out of experimental [moby/moby#42263](https://github.com/moby/moby/pull/42263)\n\n2021-03-02\n\n### [Client](#client-4)\n\n*   Revert [docker/cli#2960](https://github.com/docker/cli/pull/2960) to fix hanging in `docker start --attach` and remove spurious `Unsupported signal: <nil>. Discarding` messages. [docker/cli#2987](https://github.com/docker/cli/pull/2987).\n\n2021-02-26\n\n### [Builder](#builder-3)\n\n*   Fix incorrect cache match for inline cache import with empty layers [moby/moby#42061](https://github.com/moby/moby/pull/42061)\n*   Update BuildKit to v0.8.2 [moby/moby#42061](https://github.com/moby/moby/pull/42061)\n    *   resolver: avoid error caching on token fetch\n    *   fileop: fix checksum to contain indexes of inputs preventing certain cache misses\n    *   Fix reference count issues on typed errors with mount references (fixing `invalid mutable ref` errors)\n    *   git: set token only for main remote access allowing cloning submodules with different credentials\n*   Ensure blobs get deleted in /var/lib/docker/buildkit/content/blobs/sha256 after pull. To clean up old state run `builder prune` [moby/moby#42065](https://github.com/moby/moby/pull/42065)\n*   Fix parallel pull synchronization regression [moby/moby#42049](https://github.com/moby/moby/pull/42049)\n*   Ensure libnetwork state files do not leak [moby/moby#41972](https://github.com/moby/moby/pull/41972)\n\n### [Client](#client-5)\n\n*   Fix a panic on `docker login` if no config file is present [docker/cli#2959](https://github.com/docker/cli/pull/2959)\n*   Fix `WARNING: Error loading config file: .dockercfg: $HOME is not defined` [docker/cli#2958](https://github.com/docker/cli/pull/2958)\n\n### [Runtime](#runtime-3)\n\n*   docker info: silence unhandleable warnings [moby/moby#41958](https://github.com/moby/moby/pull/41958)\n*   Avoid creating parent directories for XGlobalHeader [moby/moby#42017](https://github.com/moby/moby/pull/42017)\n*   Use 0755 permissions when creating missing directories [moby/moby#42017](https://github.com/moby/moby/pull/42017)\n*   Fallback to manifest list when no platform matches in image config [moby/moby#42045](https://github.com/moby/moby/pull/42045) [moby/moby#41873](https://github.com/moby/moby/pull/41873)\n*   Fix a daemon panic on setups with a custom default runtime configured [moby/moby#41974](https://github.com/moby/moby/pull/41974)\n*   Fix a panic when daemon configuration is empty [moby/moby#41976](https://github.com/moby/moby/pull/41976)\n*   Fix daemon panic when starting container with invalid device cgroup rule [moby/moby#42001](https://github.com/moby/moby/pull/42001)\n*   Fix userns-remap option when username & UID match [moby/moby#42013](https://github.com/moby/moby/pull/42013)\n*   static: update runc binary to v1.0.0-rc93 [moby/moby#42014](https://github.com/moby/moby/pull/42014)\n\n### [Logger](#logger)\n\n*   Honor `labels-regex` config even if `labels` is not set [moby/moby#42046](https://github.com/moby/moby/pull/42046)\n*   Handle long log messages correctly preventing awslogs in non-blocking mode to split events bigger than 16kB [mobymoby#41975](https://github.com/moby/moby/pull/41975)\n\n### [Rootless](#rootless-3)\n\n*   Prevent the service hanging when stopping by setting systemd KillMode to mixed [moby/moby#41956](https://github.com/moby/moby/pull/41956)\n*   dockerd-rootless.sh: add typo guard [moby/moby#42070](https://github.com/moby/moby/pull/42070)\n*   Update rootlesskit to v0.13.1 to fix handling of IPv6 addresses [moby/moby#42025](https://github.com/moby/moby/pull/42025)\n*   allow mknodding FIFO inside userns [moby/moby#41957](https://github.com/moby/moby/pull/41957)\n\n### [Security](#security)\n\n*   profiles: seccomp: update to Linux 5.11 syscall list [moby/moby#41971](https://github.com/moby/moby/pull/41971)\n\n### [Swarm](#swarm-2)\n\n*   Fix issue with heartbeat not persisting upon restart [moby/moby#42060](https://github.com/moby/moby/pull/42060)\n*   Fix potential stalled tasks [moby/moby#42060](https://github.com/moby/moby/pull/42060)\n*   Fix `--update-order` and `--rollback-order` flags when only `--update-order` or `--rollback-order` is provided [docker/cli#2963](https://github.com/docker/cli/pull/2963)\n*   Fix `docker service rollback` returning a non-zero exit code in some situations [docker/cli#2964](https://github.com/docker/cli/pull/2964)\n*   Fix inconsistent progress-bar direction on `docker service rollback` [docker/cli#2964](https://github.com/docker/cli/pull/2964)\n\n2021-02-01\n\n### [Security](#security-1)\n\n*   [CVE-2021-21285](https://github.com/moby/moby/security/advisories/GHSA-6fj5-m822-rqx8) Prevent an invalid image from crashing docker daemon\n*   [CVE-2021-21284](https://github.com/moby/moby/security/advisories/GHSA-7452-xqpj-6rpc) Lock down file permissions to prevent remapped root from accessing docker state\n*   Ensure AppArmor and SELinux profiles are applied when building with BuildKit\n\n### [Client](#client-6)\n\n*   Check contexts before importing them to reduce risk of extracted files escaping context store\n*   Windows: prevent executing certain binaries from current directory [docker/cli#2950](https://github.com/docker/cli/pull/2950)\n\n2021-01-04\n\n### [Runtime](#runtime-4)\n\n*   Fix a daemon start up hang when restoring containers with restart policies but that keep failing to start [moby/moby#41729](https://github.com/moby/moby/pull/41729)\n*   overlay2: fix an off-by-one error preventing to build or run containers when data-root is 24-bytes long [moby/moby#41830](https://github.com/moby/moby/pull/41830)\n*   systemd: send `sd_notify STOPPING=1` when shutting down [moby/moby#41832](https://github.com/moby/moby/pull/41832)\n\n### [Networking](#networking-2)\n\n*   Fix IPv6 port forwarding [moby/moby#41805](https://github.com/moby/moby/pull/41805) [moby/libnetwork#2604](https://github.com/moby/libnetwork/pull/2604)\n\n### [Swarm](#swarm-3)\n\n*   Fix filtering for `replicated-job` and `global-job` service modes [moby/moby#41806](https://github.com/moby/moby/pull/41806)\n\n### [Packaging](#packaging-7)\n\n*   buildx updated to [v0.5.1](https://github.com/docker/buildx/releases/tag/v0.5.1) [docker/docker-ce-packaging#516](https://github.com/docker/docker-ce-packaging/pull/516)\n\n2020-12-14\n\n### [Builder](#builder-4)\n\n*   buildkit: updated to [v0.8.1](https://github.com/moby/buildkit/releases/tag/v0.8.1) with various bugfixes [moby/moby#41793](https://github.com/moby/moby/pull/41793)\n\n### [Packaging](#packaging-8)\n\n*   Revert a change in the systemd unit that could prevent docker from starting due to a startup order conflict [docker/docker-ce-packaging#514](https://github.com/docker/docker-ce-packaging/pull/514)\n*   buildx updated to [v0.5.0](https://github.com/docker/buildx/releases/tag/v0.5.0) [docker/docker-ce-packaging#515](https://github.com/docker/docker-ce-packaging/pull/515)\n\n2020-12-08\n\n### [Deprecation / Removal](#deprecation--removal)\n\nFor an overview of all deprecated features, refer to the [Deprecated Engine Features](https://docs.docker.com/engine/deprecated/) page.\n\n*   Warnings and deprecation notice when `docker pull`\\-ing from non-compliant registries not supporting pull-by-digest [docker/cli#2872](https://github.com/docker/cli/pull/2872)\n*   Sterner warnings and deprecation notice for unauthenticated tcp access [moby/moby#41285](https://github.com/moby/moby/pull/41285)\n*   Deprecate KernelMemory (`docker run --kernel-memory`) [moby/moby#41254](https://github.com/moby/moby/pull/41254) [docker/cli#2652](https://github.com/docker/cli/pull/2652)\n*   Deprecate `aufs` storage driver [docker/cli#1484](https://github.com/docker/cli/pull/1484)\n*   Deprecate host-discovery and overlay networks with external k/v stores [moby/moby#40614](https://github.com/moby/moby/pull/40614) [moby/moby#40510](https://github.com/moby/moby/pull/40510)\n*   Deprecate Dockerfile legacy 'ENV name value' syntax, use `ENV name=value` instead [docker/cli#2743](https://github.com/docker/cli/pull/2743)\n*   Remove deprecated \"filter\" parameter for API v1.41 and up [moby/moby#40491](https://github.com/moby/moby/pull/40491)\n*   Disable distribution manifest v2 schema 1 on push [moby/moby#41295](https://github.com/moby/moby/pull/41295)\n*   Remove hack MalformedHostHeaderOverride breaking old docker clients (<= 1.12) in which case, set `DOCKER_API_VERSION` [moby/moby#39076](https://github.com/moby/moby/pull/39076)\n*   Remove \"docker engine\" subcommands [docker/cli#2207](https://github.com/docker/cli/pull/2207)\n*   Remove experimental \"deploy\" from \"dab\" files [docker/cli#2216](https://github.com/docker/cli/pull/2216)\n*   Remove deprecated `docker search --automated` and `--stars` flags [docker/cli#2338](https://github.com/docker/cli/pull/2338)\n*   No longer allow reserved namespaces in engine labels [docker/cli#2326](https://github.com/docker/cli/pull/2326)\n\n### [API](#api)\n\n*   Update API version to v1.41\n*   Do not require \"experimental\" for metrics API [moby/moby#40427](https://github.com/moby/moby/pull/40427)\n*   `GET /events` now returns `prune` events after pruning resources have completed [moby/moby#41259](https://github.com/moby/moby/pull/41259)\n    *   Prune events are returned for `container`, `network`, `volume`, `image`, and `builder`, and have a `reclaimed` attribute, indicating the amount of space reclaimed (in bytes)\n*   Add `one-shot` stats option to not prime the stats [moby/moby#40478](https://github.com/moby/moby/pull/40478)\n*   Adding OS version info to the system info's API (`/info`) [moby/moby#38349](https://github.com/moby/moby/pull/38349)\n*   Add DefaultAddressPools to docker info [moby/moby#40714](https://github.com/moby/moby/pull/40714)\n*   Add API support for PidsLimit on services [moby/moby#39882](https://github.com/moby/moby/pull/39882)\n\n### [Builder](#builder-5)\n\n*   buildkit,dockerfile: Support for `RUN --mount` options without needing to specify experimental dockerfile `#syntax` directive. [moby/buildkit#1717](https://github.com/moby/buildkit/pull/1717)\n*   dockerfile: `ARG` command now supports defining multiple build args on the same line similarly to `ENV` [moby/buildkit#1692](https://github.com/moby/buildkit/pull/1692)\n*   dockerfile: `--chown` flag in `ADD` now allows parameter expansion [moby/buildkit#1473](https://github.com/moby/buildkit/pull/1473)\n*   buildkit: Fetching authorization tokens has been moved to client-side (if the client supports it). Passwords do not leak into the build daemon anymore and users can see from build output when credentials or tokens are accessed. [moby/buildkit#1660](https://github.com/moby/buildkit/pull/1660)\n*   buildkit: Connection errors while communicating with the registry for push and pull now trigger a retry [moby/buildkit#1791](https://github.com/moby/buildkit/pull/1791)\n*   buildkit: Git source now supports token authentication via build secrets [moby/moby#41234](https://github.com/moby/moby/pull/41234) [docker/cli#2656](https://github.com/docker/cli/pull/2656) [moby/buildkit#1533](https://github.com/moby/buildkit/pull/1533)\n*   buildkit: Building from git source now supports forwarding SSH socket for authentication [moby/buildkit#1782](https://github.com/moby/buildkit/pull/1782)\n*   buildkit: Avoid builds that generate excessive logs to cause a crash or slow down the build. Clipping is performed if needed. [moby/buildkit#1754](https://github.com/moby/buildkit/pull/1754)\n*   buildkit: Change default Seccomp profile to the one provided by Docker [moby/buildkit#1807](https://github.com/moby/buildkit/pull/1807)\n*   buildkit: Support for exposing SSH agent socket on Windows has been improved [moby/buildkit#1695](https://github.com/moby/buildkit/pull/1695)\n*   buildkit: Disable truncating by default when using --progress=plain [moby/buildkit#1435](https://github.com/moby/buildkit/pull/1435)\n*   buildkit: Allow better handling client sessions dropping while it is being shared by multiple builds [moby/buildkit#1551](https://github.com/moby/buildkit/pull/1551)\n*   buildkit: secrets: allow providing secrets with env [moby/moby#41234](https://github.com/moby/moby/pull/41234) [docker/cli#2656](https://github.com/docker/cli/pull/2656) [moby/buildkit#1534](https://github.com/moby/buildkit/pull/1534)\n    *   Support `--secret id=foo,env=MY_ENV` as an alternative for storing a secret value to a file.\n    *   `--secret id=GIT_AUTH_TOKEN` will load env if it exists and the file does not.\n*   buildkit: Support for mirrors fallbacks, insecure TLS and custom TLS config [moby/moby#40814](https://github.com/moby/moby/pull/40814)\n*   buildkit: remotecache: Only visit each item once when walking results [moby/moby#41234](https://github.com/moby/moby/pull/41234) [moby/buildkit#1577](https://github.com/moby/buildkit/pull/1577)\n    *   Improves performance and CPU use on bigger graphs\n*   buildkit: Check remote when local image platform doesn't match [moby/moby#40629](https://github.com/moby/moby/pull/40629)\n*   buildkit: image export: Use correct media type when creating new layer blobs [moby/moby#41234](https://github.com/moby/moby/pull/41234) [moby/buildkit#1541](https://github.com/moby/buildkit/pull/1541)\n*   buildkit: progressui: fix logs time formatting [moby/moby#41234](https://github.com/moby/moby/pull/41234) [docker/cli#2656](https://github.com/docker/cli/pull/2656) [moby/buildkit#1549](https://github.com/moby/buildkit/pull/1549)\n*   buildkit: mitigate containerd issue on parallel push [moby/moby#41234](https://github.com/moby/moby/pull/41234) [moby/buildkit#1548](https://github.com/moby/buildkit/pull/1548)\n*   buildkit: inline cache: fix handling of duplicate blobs [moby/moby#41234](https://github.com/moby/moby/pull/41234) [moby/buildkit#1568](https://github.com/moby/buildkit/pull/1568)\n    *   Fixes [https://github.com/moby/buildkit/issues/1388](https://github.com/moby/buildkit/issues/1388) cache-from working unreliably\n    *   Fixes [https://github.com/moby/moby/issues/41219](https://github.com/moby/moby/issues/41219) Image built from cached layers is missing data\n*   Allow ssh:// for remote context URLs [moby/moby#40179](https://github.com/moby/moby/pull/40179)\n*   builder: remove legacy build's session handling (was experimental) [moby/moby#39983](https://github.com/moby/moby/pull/39983)\n\n### [Client](#client-7)\n\n*   Add swarm jobs support to CLI [docker/cli#2262](https://github.com/docker/cli/pull/2262)\n*   Add `-a/--all-tags` to docker push [docker/cli#2220](https://github.com/docker/cli/pull/2220)\n*   Add support for Kubernetes username/password auth [docker/cli#2308](https://github.com/docker/cli/pull/2308)\n*   Add `--pull=missing|always|never` to `run` and `create` commands [docker/cli#1498](https://github.com/docker/cli/pull/1498)\n*   Add `--env-file` flag to `docker exec` for parsing environment variables from a file [docker/cli#2602](https://github.com/docker/cli/pull/2602)\n*   Add shorthand `-n` for `--tail` option [docker/cli#2646](https://github.com/docker/cli/pull/2646)\n*   Add log-driver and options to service inspect \"pretty\" format [docker/cli#1950](https://github.com/docker/cli/pull/1950)\n*   docker run: specify cgroup namespace mode with `--cgroupns` [docker/cli#2024](https://github.com/docker/cli/pull/2024)\n*   `docker manifest rm` command to remove manifest list draft from local storage [docker/cli#2449](https://github.com/docker/cli/pull/2449)\n*   Add \"context\" to \"docker version\" and \"docker info\" [docker/cli#2500](https://github.com/docker/cli/pull/2500)\n*   Propagate platform flag to container create API [docker/cli#2551](https://github.com/docker/cli/pull/2551)\n*   The `docker ps --format` flag now has a `.State` placeholder to print the container's state without additional details about uptime and health check [docker/cli#2000](https://github.com/docker/cli/pull/2000)\n*   Add support for docker-compose schema v3.9 [docker/cli#2073](https://github.com/docker/cli/pull/2073)\n*   Add support for docker push `--quiet` [docker/cli#2197](https://github.com/docker/cli/pull/2197)\n*   Hide flags that are not supported by BuildKit, if BuildKit is enabled [docker/cli#2123](https://github.com/docker/cli/pull/2123)\n*   Update flag description for `docker rm -v` to clarify the option only removes anonymous (unnamed) volumes [docker/cli#2289](https://github.com/docker/cli/pull/2289)\n*   Improve tasks printing for docker services [docker/cli#2341](https://github.com/docker/cli/pull/2341)\n*   docker info: list CLI plugins alphabetically [docker/cli#2236](https://github.com/docker/cli/pull/2236)\n*   Fix order of processing of `--label-add/--label-rm`, `--container-label-add/--container-label-rm`, and `--env-add/--env-rm` flags on `docker service update` to allow replacing existing values [docker/cli#2668](https://github.com/docker/cli/pull/2668)\n*   Fix `docker rm --force` returning a non-zero exit code if one or more containers did not exist [docker/cli#2678](https://github.com/docker/cli/pull/2678)\n*   Improve memory stats display by using `total_inactive_file` instead of `cache` [docker/cli#2415](https://github.com/docker/cli/pull/2415)\n*   Mitigate against YAML files that has excessive aliasing [docker/cli#2117](https://github.com/docker/cli/pull/2117)\n*   Allow using advanced syntax when setting a config or secret with only the source field [docker/cli#2243](https://github.com/docker/cli/pull/2243)\n*   Fix reading config files containing `username` and `password` auth even if `auth` is empty [docker/cli#2122](https://github.com/docker/cli/pull/2122)\n*   docker cp: prevent NPE when failing to stat destination [docker/cli#2221](https://github.com/docker/cli/pull/2221)\n*   config: preserve ownership and permissions on configfile [docker/cli#2228](https://github.com/docker/cli/pull/2228)\n\n### [Logging](#logging-2)\n\n*   Support reading `docker logs` with all logging drivers (best effort) [moby/moby#40543](https://github.com/moby/moby/pull/40543)\n*   Add `splunk-index-acknowledgment` log option to work with Splunk HECs with index acknowledgment enabled [moby/moby#39987](https://github.com/moby/moby/pull/39987)\n*   Add partial metadata to journald logs [moby/moby#41407](https://github.com/moby/moby/pull/41407)\n*   Reduce allocations for logfile reader [moby/moby#40796](https://github.com/moby/moby/pull/40796)\n*   Fluentd: add fluentd-async, fluentd-request-ack, and deprecate fluentd-async-connect [moby/moby#39086](https://github.com/moby/moby/pull/39086)\n\n### [Runtime](#runtime-5)\n\n*   Support cgroup2 [moby/moby#40174](https://github.com/moby/moby/pull/40174) [moby/moby#40657](https://github.com/moby/moby/pull/40657) [moby/moby#40662](https://github.com/moby/moby/pull/40662)\n*   cgroup2: use \"systemd\" cgroup driver by default when available [moby/moby#40846](https://github.com/moby/moby/pull/40846)\n*   new storage driver: fuse-overlayfs [moby/moby#40483](https://github.com/moby/moby/pull/40483)\n*   Update containerd binary to v1.4.3 [moby/moby#41732](https://github.com/moby/moby/pull/41732)\n*   `docker push` now defaults to `latest` tag instead of all tags [moby/moby#40302](https://github.com/moby/moby/pull/40302)\n*   Added ability to change the number of reconnect attempts during connection loss while pulling an image by adding max-download-attempts to the config file [moby/moby#39949](https://github.com/moby/moby/pull/39949)\n*   Add support for containerd v2 shim by using the now default `io.containerd.runc.v2` runtime [moby/moby#41182](https://github.com/moby/moby/pull/41182)\n*   cgroup v1: change the default runtime to io.containerd.runc.v2. Requires containerd v1.3.0 or later. v1.3.5 or later is recommended [moby/moby#41210](https://github.com/moby/moby/pull/41210)\n*   Start containers in their own cgroup namespaces [moby/moby#38377](https://github.com/moby/moby/pull/38377)\n*   Enable DNS Lookups for CIFS Volumes [moby/moby#39250](https://github.com/moby/moby/pull/39250)\n*   Use MemAvailable instead of MemFree to estimate actual available memory [moby/moby#39481](https://github.com/moby/moby/pull/39481)\n*   The `--device` flag in `docker run` will now be honored when the container is started in privileged mode [moby/moby#40291](https://github.com/moby/moby/pull/40291)\n*   Enforce reserved internal labels [moby/moby#40394](https://github.com/moby/moby/pull/40394)\n*   Raise minimum memory limit to 6M, to account for higher memory use by runtimes during container startup [moby/moby#41168](https://github.com/moby/moby/pull/41168)\n*   vendor runc v1.0.0-rc92 [moby/moby#41344](https://github.com/moby/moby/pull/41344) [moby/moby#41317](https://github.com/moby/moby/pull/41317)\n*   info: add warnings about missing blkio cgroup support [moby/moby#41083](https://github.com/moby/moby/pull/41083)\n*   Accept platform spec on container create [moby/moby#40725](https://github.com/moby/moby/pull/40725)\n*   Fix handling of looking up user- and group-names with spaces [moby/moby#41377](https://github.com/moby/moby/pull/41377)\n\n### [Networking](#networking-3)\n\n*   Support host.docker.internal in dockerd on Linux [moby/moby#40007](https://github.com/moby/moby/pull/40007)\n*   Include IPv6 address of linked containers in /etc/hosts [moby/moby#39837](https://github.com/moby/moby/pull/39837)\n*   `--ip6tables` enables IPv6 iptables rules (only if experimental) [moby/moby#41622](https://github.com/moby/moby/pull/41622)\n*   Add alias for hostname if hostname != container name [moby/moby#39204](https://github.com/moby/moby/pull/39204)\n*   Better selection of DNS server (with systemd) [moby/moby#41022](https://github.com/moby/moby/pull/41022)\n*   Add docker interfaces to firewalld docker zone [moby/moby#41189](https://github.com/moby/moby/pull/41189) [moby/libnetwork#2548](https://github.com/moby/libnetwork/pull/2548)\n    *   Fixes DNS issue on CentOS8 [docker/for-linux#957](https://github.com/docker/for-linux/issues/957)\n    *   Fixes Port Forwarding on RHEL 8 with Firewalld running with FirewallBackend=nftables [moby/libnetwork#2496](https://github.com/moby/libnetwork/issues/2496)\n*   Fix an issue reporting 'failed to get network during CreateEndpoint' [moby/moby#41189](https://github.com/moby/moby/pull/41189) [moby/libnetwork#2554](https://github.com/moby/libnetwork/pull/2554)\n*   Log error instead of disabling IPv6 router advertisement failed [moby/moby#41189](https://github.com/moby/moby/pull/41189) [moby/libnetwork#2563](https://github.com/moby/libnetwork/pull/2563)\n*   No longer ignore `--default-address-pool` option in certain cases [moby/moby#40711](https://github.com/moby/moby/pull/40711)\n*   Produce an error with invalid address pool [moby/moby#40808](https://github.com/moby/moby/pull/40808) [moby/libnetwork#2538](https://github.com/moby/libnetwork/pull/2538)\n*   Fix `DOCKER-USER` chain not created when IPTableEnable=false [moby/moby#40808](https://github.com/moby/moby/pull/40808) [moby/libnetwork#2471](https://github.com/moby/libnetwork/pull/2471)\n*   Fix panic on startup in systemd environments [moby/moby#40808](https://github.com/moby/moby/pull/40808) [moby/libnetwork#2544](https://github.com/moby/libnetwork/pull/2544)\n*   Fix issue preventing containers to communicate over macvlan internal network [moby/moby#40596](https://github.com/moby/moby/pull/40596) [moby/libnetwork#2407](https://github.com/moby/libnetwork/pull/2407)\n*   Fix InhibitIPv4 nil panic [moby/moby#40596](https://github.com/moby/moby/pull/40596)\n*   Fix VFP leak in Windows overlay network deletion [moby/moby#40596](https://github.com/moby/moby/pull/40596) [moby/libnetwork#2524](https://github.com/moby/libnetwork/pull/2524)\n\n### [Packaging](#packaging-9)\n\n*   docker.service: Add multi-user.target to After= in unit file [moby/moby#41297](https://github.com/moby/moby/pull/41297)\n*   docker.service: Allow socket activation [moby/moby#37470](https://github.com/moby/moby/pull/37470)\n*   seccomp: Remove dependency in dockerd on libseccomp [moby/moby#41395](https://github.com/moby/moby/pull/41395)\n\n### [Rootless](#rootless-4)\n\n*   rootless: graduate from experimental [moby/moby#40759](https://github.com/moby/moby/pull/40759)\n*   Add dockerd-rootless-setuptool.sh [moby/moby#40950](https://github.com/moby/moby/pull/40950)\n*   Support `--exec-opt native.cgroupdriver=systemd` [moby/moby#40486](https://github.com/moby/moby/pull/40486)\n\n### [Security](#security-2)\n\n*   Fix CVE-2019-14271 loading of nsswitch based config inside chroot under Glibc [moby/moby#39612](https://github.com/moby/moby/pull/39612)\n*   seccomp: Whitelist `clock_adjtime`. `CAP_SYS_TIME` is still required for time adjustment [moby/moby#40929](https://github.com/moby/moby/pull/40929)\n*   seccomp: Add openat2 and faccessat2 to default seccomp profile [moby/moby#41353](https://github.com/moby/moby/pull/41353)\n*   seccomp: allow 'rseq' syscall in default seccomp profile [moby/moby#41158](https://github.com/moby/moby/pull/41158)\n*   seccomp: allow syscall membarrier [moby/moby#40731](https://github.com/moby/moby/pull/40731)\n*   seccomp: whitelist io-uring related system calls [moby/moby#39415](https://github.com/moby/moby/pull/39415)\n*   Add default sysctls to allow ping sockets and privileged ports with no capabilities [moby/moby#41030](https://github.com/moby/moby/pull/41030)\n*   Fix seccomp profile for clone syscall [moby/moby#39308](https://github.com/moby/moby/pull/39308)\n\n### [Swarm](#swarm-4)\n\n*   Add support for swarm jobs [moby/moby#40307](https://github.com/moby/moby/pull/40307)\n*   Add capabilities support to stack/service commands [docker/cli#2687](https://github.com/docker/cli/pull/2687) [docker/cli#2709](https://github.com/docker/cli/pull/2709) [moby/moby#39173](https://github.com/moby/moby/pull/39173) [moby/moby#41249](https://github.com/moby/moby/pull/41249)\n*   Add support for sending down service Running and Desired task counts [moby/moby#39231](https://github.com/moby/moby/pull/39231)\n*   service: support `--mount type=bind,bind-nonrecursive` [moby/moby#38788](https://github.com/moby/moby/pull/38788)\n*   Support ulimits on Swarm services. [moby/moby#41284](https://github.com/moby/moby/pull/41284) [docker/cli#2712](https://github.com/docker/cli/pull/2712)\n*   Fixed an issue where service logs could leak goroutines on the worker [moby/moby#40426](https://github.com/moby/moby/pull/40426)",
  "title": "Docker Engine 20.10 release notes | Docker Docs\n",
  "description": "Learn about the new features, bug fixes, and breaking changes for Docker Engine",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/extend/plugin_api/",
  "markdown": "# Docker Plugin API | Docker Docs\n\nDocker plugins are out-of-process extensions which add capabilities to the Docker Engine.\n\nThis document describes the Docker Engine plugin API. To view information on plugins managed by Docker Engine, refer to [Docker Engine plugin system](https://docs.docker.com/engine/extend/).\n\nThis page is intended for people who want to develop their own Docker plugin. If you just want to learn about or use Docker plugins, look [here](https://docs.docker.com/engine/extend/legacy_plugins/).\n\nA plugin is a process running on the same or a different host as the Docker daemon, which registers itself by placing a file on the daemon host in one of the plugin directories described in [Plugin discovery](#plugin-discovery).\n\nPlugins have human-readable names, which are short, lowercase strings. For example, `flocker` or `weave`.\n\nPlugins can run inside or outside containers. Currently running them outside containers is recommended.\n\nDocker discovers plugins by looking for them in the plugin directory whenever a user or container tries to use one by name.\n\nThere are three types of files which can be put in the plugin directory.\n\n*   `.sock` files are Unix domain sockets.\n*   `.spec` files are text files containing a URL, such as `unix:///other.sock` or `tcp://localhost:8080`.\n*   `.json` files are text files containing a full json specification for the plugin.\n\nPlugins with Unix domain socket files must run on the same host as the Docker daemon. Plugins with `.spec` or `.json` files can run on a different host if you specify a remote URL.\n\nUnix domain socket files must be located under `/run/docker/plugins`, whereas spec files can be located either under `/etc/docker/plugins` or `/usr/lib/docker/plugins`.\n\nThe name of the file (excluding the extension) determines the plugin name.\n\nFor example, the `flocker` plugin might create a Unix socket at `/run/docker/plugins/flocker.sock`.\n\nYou can define each plugin into a separated subdirectory if you want to isolate definitions from each other. For example, you can create the `flocker` socket under `/run/docker/plugins/flocker/flocker.sock` and only mount `/run/docker/plugins/flocker` inside the `flocker` container.\n\nDocker always searches for Unix sockets in `/run/docker/plugins` first. It checks for spec or json files under `/etc/docker/plugins` and `/usr/lib/docker/plugins` if the socket doesn't exist. The directory scan stops as soon as it finds the first plugin definition with the given name.\n\n### [JSON specification](#json-specification)\n\nThis is the JSON format for a plugin:\n\nThe `TLSConfig` field is optional and TLS will only be verified if this configuration is present.\n\nPlugins should be started before Docker, and stopped after Docker. For example, when packaging a plugin for a platform which supports `systemd`, you might use [`systemd` dependencies](https://www.freedesktop.org/software/systemd/man/systemd.unit.html#Before=) to manage startup and shutdown order.\n\nWhen upgrading a plugin, you should first stop the Docker daemon, upgrade the plugin, then start Docker again.\n\nWhen a plugin is first referred to -- either by a user referring to it by name (e.g. `docker run --volume-driver=foo`) or a container already configured to use a plugin being started -- Docker looks for the named plugin in the plugin directory and activates it with a handshake. See Handshake API below.\n\nPlugins are not activated automatically at Docker daemon startup. Rather, they are activated only lazily, or on-demand, when they are needed.\n\nPlugins may also be socket activated by `systemd`. The official [Plugins helpers](https://github.com/docker/go-plugins-helpers) natively supports socket activation. In order for a plugin to be socket activated it needs a `service` file and a `socket` file.\n\nThe `service` file (for example `/lib/systemd/system/your-plugin.service`):\n\nThe `socket` file (for example `/lib/systemd/system/your-plugin.socket`):\n\nThis will allow plugins to be actually started when the Docker daemon connects to the sockets they're listening on (for instance the first time the daemon uses them or if one of the plugin goes down accidentally).\n\nThe Plugin API is RPC-style JSON over HTTP, much like webhooks.\n\nRequests flow from the Docker daemon to the plugin. The plugin needs to implement an HTTP server and bind this to the Unix socket mentioned in the \"plugin discovery\" section.\n\nAll requests are HTTP `POST` requests.\n\nThe API is versioned via an Accept header, which currently is always set to `application/vnd.docker.plugins.v1+json`.\n\nPlugins are activated via the following \"handshake\" API call.\n\n### [/Plugin.Activate](#pluginactivate)\n\nRequest: empty body\n\nResponse:\n\nResponds with a list of Docker subsystems which this plugin implements. After activation, the plugin will then be sent events from this subsystem.\n\nPossible values are:\n\n*   [`authz`](https://docs.docker.com/engine/extend/plugins_authorization/)\n*   [`NetworkDriver`](https://docs.docker.com/engine/extend/plugins_network/)\n*   [`VolumeDriver`](https://docs.docker.com/engine/extend/plugins_volume/)\n\nAttempts to call a method on a plugin are retried with an exponential backoff for up to 30 seconds. This may help when packaging plugins as containers, since it gives plugin containers a chance to start up before failing any user containers which depend on them.\n\nTo ease plugins development, we're providing an `sdk` for each kind of plugins currently supported by Docker at [docker/go-plugins-helpers](https://github.com/docker/go-plugins-helpers).",
  "title": "Docker Plugin API | Docker Docs\n",
  "description": "How to write Docker plugins extensions ",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/19.03/",
  "markdown": "# Docker Engine 19.03 release notes\n\n2021-02-01\n\n### [Security](#security)\n\n*   [CVE-2021-21285](https://github.com/moby/moby/security/advisories/GHSA-6fj5-m822-rqx8) Prevent an invalid image from crashing docker daemon\n*   [CVE-2021-21284](https://github.com/moby/moby/security/advisories/GHSA-7452-xqpj-6rpc) Lock down file permissions to prevent remapped root from accessing docker state\n*   Ensure AppArmor and SELinux profiles are applied when building with BuildKit\n\n### [Client](#client)\n\n*   Check contexts before importing them to reduce risk of extracted files escaping context store\n\n2020-12-01\n\n### [Security](#security-1)\n\n*   [CVE-2020-15257](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15257): Update bundled static binaries of containerd to v1.3.9 [moby/moby#41731](https://github.com/moby/moby/pull/41731). Package managers should update the containerd.io package.\n\n### [Builder](#builder)\n\n*   Beta versions of apparmor are now parsed correctly preventing build failures [moby/moby#41542](https://github.com/moby/moby/pull/41542)\n\n### [Networking](#networking)\n\n*   Fix panic when swarmkit service keeps failing to start [moby/moby#41635](https://github.com/moby/moby/pull/41635)\n\n### [Runtime](#runtime)\n\n*   Return correct errors instead of spurrious -EINVAL [moby/moby#41293](https://github.com/moby/moby/pull/41293)\n\n### [Rootless](#rootless)\n\n*   Lock state dir for preventing automatic clean-up by systemd-tmpfiles [moby/moby#41635](https://github.com/moby/moby/pull/41635)\n*   dockerd-rootless.sh: support new containerd shim socket path convention [moby/moby#41557](https://github.com/moby/moby/pull/41557)\n\n### [Logging](#logging)\n\n*   gcplogs: Fix memory/connection leak [moby/moby#41522](https://github.com/moby/moby/pull/41522)\n*   awslogs: Support for AWS imdsv2 [moby/moby#41494](https://github.com/moby/moby/pull/41494)\n\n2020-09-16\n\n### [Builder](#builder-1)\n\n*   buildkit: Fix nil dereference in cache logic [moby/moby#41279](https://github.com/moby/moby/pull/41279)\n*   buildkit: Treat Unix sockets as regular files during COPY/ADD [moby/moby#41269](https://github.com/moby/moby/pull/41269)\n*   buildkit: Ignore system and security xattrs in calculation to ensure consistent COPY caching regardless of SELinux environment [moby/moby#41222](https://github.com/moby/moby/pull/41222)\n*   buildkit: Make `--cache-from` behavior more reliable [moby/moby#41222](https://github.com/moby/moby/pull/41222)\n*   buildkit: Fix infinite loop burning CPU when exporting cache [moby/moby#41185](https://github.com/moby/moby/pull/41185)\n\n### [Client](#client-1)\n\n*   Bump Golang 1.13.15 [docker/cli#2674](https://github.com/docker/cli/pull/2674)\n*   Fix config file permission issues (~/.docker/config.json) [docker/cli#2631](https://github.com/docker/cli/pull/2631)\n*   build: Fix panic on terminals with zero height [docker/cli#2719](https://github.com/docker/cli/pull/2719)\n*   windows: Fix potential issue with newline character in console [docker/cli#2623](https://github.com/docker/cli/pull/2623)\n\n### [Networking](#networking-1)\n\n*   Clean up network sandbox on failure [moby/moby#41081](https://github.com/moby/moby/pull/41081)\n*   Fix shallow error messages by forwarding deadline-related errors to user [moby/moby#41312](https://github.com/moby/moby/pull/41312)\n*   Fix leaking of netns file descriptors [moby/moby#41287](https://github.com/moby/moby/41287)\n\n### [Rootless](#rootless-1)\n\n*   Fix port forwarder resource leak [moby/moby#41277](https://github.com/moby/moby/pull/41277)\n\n### [Runtime](#runtime-1)\n\n*   Bump Golang 1.13.15 [moby/moby#41334](https://github.com/moby/moby/pull/41334)\n*   Update to containerd 1.3.7 [moby/moby#40408](https://github.com/moby/moby/pull/40408)\n\n### [Windows](#windows)\n\n*   Fix slow Windows container start time when using servercore image [moby/moby#41192](https://github.com/moby/moby/pull/41192)\n\n2020-06-18\n\n### [Client](#client-2)\n\n*   Fix bug preventing logout from registry when using multiple config files (e.g. Windows vs WSL2 when using Docker Desktop) [docker/cli#2592](https://github.com/docker/cli/pull/2592)\n*   Fix regression preventing context metadata to be read [docker/cli#2586](https://github.com/docker/cli/pull/2586)\n*   Bump Golang 1.13.12 [docker/cli#2575](https://github.com/docker/cli/pull/2575)\n\n### [Networking](#networking-2)\n\n*   Fix regression preventing daemon start up in a systemd-nspawn environment [moby/moby#41124](https://github.com/moby/moby/pull/41124) [moby/libnetwork#2567](https://github.com/moby/libnetwork/pull/2567)\n*   Fix the retry logic for creating overlay networks in swarm [moby/moby#41124](https://github.com/moby/moby/pull/41124) [moby/libnetwork#2565](https://github.com/moby/libnetwork/pull/2565)\n\n### [Runtime](#runtime-2)\n\n*   Bump Golang 1.13.12 [moby/moby#41082](https://github.com/moby/moby/pull/41082)\n\n2020-06-01\n\n### [Network](#network)\n\nDisable IPv6 Router Advertisements to prevent address spoofing. [CVE-2020-13401](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13401)\n\n**Description**\n\nIn the Docker default configuration, the container network interface is a virtual ethernet link going to the host (veth interface). In this configuration, an attacker able to run a process as root in a container can send and receive arbitrary packets to the host using the `CAP_NET_RAW` capability (present in the default configuration).\n\nIf IPv6 is not totally disabled on the host (via `ipv6.disable=1` on the kernel cmdline), it will be either unconfigured or configured on some interfaces, but itâ€™s pretty likely that ipv6 forwarding is disabled, that is, `/proc/sys/net/ipv6/conf//forwarding == 0`. Also by default, `/proc/sys/net/ipv6/conf//accept_ra == 1`. The combination of these 2 sysctls means that the host accepts router advertisements and configures the IPv6 stack using them.\n\nBy sending â€œrogueâ€ router advertisements from a container, an attacker can reconfigure the host to redirect part or all of the IPv6 traffic of the host to the attacker-controlled container.\n\nEven if there was no IPv6 traffic before, if the DNS returns A (IPv4) and AAAA (IPv6) records, many HTTP libraries will try to connect via IPv6 first then fallback to IPv4, giving an opportunity to the attacker to respond. If by chance the host has a vulnerability like last yearâ€™s RCE in apt (CVE-2019-3462), the attacker can now escalate to the host.\n\nAs `CAP_NET_ADMIN` is not present by default for Docker containers, the attacker canâ€™t configure the IPs they want to MitM, they canâ€™t use iptables to NAT or REDIRECT the traffic, and they canâ€™t use `IP_TRANSPARENT`. The attacker can however still use `CAP_NET_RAW` and implement a tcp/ip stack in user space.\n\nSee [kubernetes/kubernetes#91507](https://github.com/kubernetes/kubernetes/issues/91507) for related issues.\n\n2020-05-29\n\n### [Client](#client-3)\n\n*   Fix version negotiation with older engine. [docker/cli#2538](https://github.com/docker/cli/pull/2538)\n*   Avoid setting SSH flags through hostname. [docker/cli#2560](https://github.com/docker/cli/pull/2560)\n*   Fix panic when DOCKER\\_CLI\\_EXPERIMENTAL is invalid. [docker/cli#2558](https://github.com/docker/cli/pull/2558)\n*   Avoid potential panic on s390x by upgrading Go to 1.13.11. [docker/cli#2532](https://github.com/docker/cli/pull/2532)\n\n### [Networking](#networking-3)\n\n*   Fix DNS fallback regression. [moby/moby#41009](https://github.com/moby/moby/pull/41009)\n\n### [Runtime](#runtime-3)\n\n*   Avoid potential panic on s390x by upgrading Go to 1.13.11. [moby/moby#40978](https://github.com/moby/moby/pull/40978)\n\n### [Packaging](#packaging)\n\n*   Fix ARM builds on ARM64. [moby/moby#41027](https://github.com/moby/moby/pull/41027)\n\n2020-05-14\n\n### [Builder](#builder-2)\n\n*   buildkit: Fix concurrent map write panic when building multiple images in parallel. [moby/moby#40780](https://github.com/moby/moby/pull/40780)\n*   buildkit: Fix issue preventing chowning of non-root-owned files between stages with userns. [moby/moby#40955](https://github.com/moby/moby/pull/40955)\n*   Avoid creation of irrelevant temporary files on Windows. [moby/moby#40877](https://github.com/moby/moby/pull/40877)\n\n### [Client](#client-4)\n\n*   Fix panic on single-character volumes. [docker/cli#2471](https://github.com/docker/cli/pull/2471)\n*   Lazy daemon feature detection to avoid long timeouts on simple commands. [docker/cli#2442](https://github.com/docker/cli/pull/2442)\n*   docker context inspect on Windows is now faster. [docker/cli#2516](https://github.com/docker/cli/pull/2516)\n*   Bump Golang 1.13.10. [docker/cli#2431](https://github.com/docker/cli/pull/2431)\n*   Bump gopkg.in/yaml.v2 to v2.2.8. [docker/cli#2470](https://github.com/docker/cli/pull/2470)\n\n### [Logging](#logging-1)\n\n*   Avoid situation preventing container logs to rotate due to closing a closed log file. [moby/moby#40921](https://github.com/moby/moby/pull/40921)\n\n### [Networking](#networking-4)\n\n*   Fix potential panic upon restart. [moby/moby#40809](https://github.com/moby/moby/pull/40809)\n*   Assign the correct network value to the default bridge Subnet field. [moby/moby#40565](https://github.com/moby/moby/pull/40565)\n\n### [Runtime](#runtime-4)\n\n*   Fix docker crash when creating namespaces with UID in /etc/subuid and /etc/subgid. [moby/moby#40562](https://github.com/moby/moby/pull/40562)\n*   Improve ARM platform matching. [moby/moby#40758](https://github.com/moby/moby/pull/40758)\n*   overlay2: show backing filesystem. [moby/moby#40652](https://github.com/moby/moby/pull/40652)\n*   Update CRIU to v3.13 \"Silicon Willet\". [moby/moby#40850](https://github.com/moby/moby/pull/40850)\n*   Only show registry v2 schema1 deprecation warning upon successful fallback, as opposed to any registry error. [moby/moby#40681](https://github.com/moby/moby/pull/40681)\n*   Use FILE\\_SHARE\\_DELETE for log files on Windows. [moby/moby#40563](https://github.com/moby/moby/pull/40563)\n*   Bump Golang 1.13.10. [moby/moby#40803](https://github.com/moby/moby/pull/40803)\n\n### [Rootless](#rootless-2)\n\n*   Now rootlesskit-docker-proxy returns detailed error message on exposing privileged ports. [moby/moby#40863](https://github.com/moby/moby/pull/40863)\n*   Supports numeric ID in /etc/subuid and /etc/subgid. [moby/moby#40951](https://github.com/moby/moby/pull/40951)\n\n### [Security](#security-2)\n\n*   apparmor: add missing rules for userns. [moby/moby#40564](https://github.com/moby/moby/pull/40564)\n*   SElinux: fix ENOTSUP errors not being detected when relabeling. [moby/moby#40946](https://github.com/moby/moby/pull/40946)\n\n### [Swarm](#swarm)\n\n*   Increase refill rate for logger to avoid hanging on service logs. [moby/moby#40628](https://github.com/moby/moby/pull/40628)\n*   Fix issue where single swarm manager is stuck in Down state after reboot. [moby/moby#40831](https://github.com/moby/moby/pull/40831)\n*   tasks.db no longer grows indefinitely. [moby/moby#40831](https://github.com/moby/moby/pull/40831)\n\n2020-03-10\n\n### [Runtime](#runtime-5)\n\n*   Improve mitigation for [CVE-2019-14271](https://nvd.nist.gov/vuln/detail/CVE-2019-14271) for some nscd configuration.\n\n2020-03-03\n\n### [Builder](#builder-3)\n\n*   builder-next: Fix deadlock issues in corner cases. [moby/moby#40557](https://github.com/moby/moby/pull/40557)\n\n### [Runtime](#runtime-6)\n\n*   overlay: remove modprobe execs. [moby/moby#40462](https://github.com/moby/moby/pull/40462)\n*   selinux: display better error messages when setting file labels. [moby/moby#40547](https://github.com/moby/moby/pull/40547)\n*   Speed up initial stats collection. [moby/moby#40549](https://github.com/moby/moby/pull/40549)\n\n*   rootless: use certs.d from XDG\\_CONFIG\\_HOME. [moby/moby#40461](https://github.com/moby/moby/pull/40461)\n*   Bump Golang 1.12.17. [moby/moby#40533](https://github.com/moby/moby/pull/40533)\n*   Bump google.golang.org/grpc to v1.23.1. [moby/moby#40566](https://github.com/moby/moby/pull/40566)\n*   Update containerd binary to v1.2.13. [moby/moby#40540](https://github.com/moby/moby/pull/40540)\n*   Prevent showing stopped containers as running in an edge case. [moby/moby#40555](https://github.com/moby/moby/pull/40555)\n*   Prevent potential lock. [moby/moby#40604](https://github.com/moby/moby/pull/40604)\n\n### [Client](#client-5)\n\n*   Bump Golang 1.12.17. [docker/cli#2342](https://github.com/docker/cli/pull/2342)\n*   Bump google.golang.org/grpc to v1.23.1. [docker/cli#1884](https://github.com/docker/cli/pull/1884) [docker/cli#2373](https://github.com/docker/cli/pull/2373)\n\n2020-02-12\n\n### [Builder](#builder-4)\n\n*   builder-next: Allow modern sign hashes for ssh forwarding. [docker/engine#453](https://github.com/docker/engine/pull/453)\n*   builder-next: Clear onbuild rules after triggering. [docker/engine#453](https://github.com/docker/engine/pull/453)\n*   builder-next: Fix issue with directory permissions when usernamespaces is enabled. [moby/moby#40440](https://github.com/moby/moby/pull/40440)\n*   Bump hcsshim to fix docker build failing on Windows 1903. [docker/engine#429](https://github.com/docker/engine/pull/429)\n\n### [Networking](#networking-5)\n\n*   Shorten controller ID in exec-root to not hit UNIX\\_PATH\\_MAX. [docker/engine#424](https://github.com/docker/engine/pull/424)\n*   Fix panic in drivers/overlay/encryption.go. [docker/engine#424](https://github.com/docker/engine/pull/424)\n*   Fix hwaddr set race between us and udev. [docker/engine#439](https://github.com/docker/engine/pull/439)\n\n### [Runtime](#runtime-7)\n\n*   Bump Golang 1.12.16. [moby/moby#40433](https://github.com/moby/moby/pull/40433)\n*   Update containerd binary to v1.2.12. [moby/moby#40433](https://github.com/moby/moby/pull/40453)\n*   Update to runc v1.0.0-rc10. [moby/moby#40433](https://github.com/moby/moby/pull/40453)\n\n*   Fix possible runtime panic in Lgetxattr. [docker/engine#454](https://github.com/docker/engine/pull/454)\n*   rootless: fix proxying UDP packets. [docker/engine#434](https://github.com/docker/engine/pull/434)\n\n2019-11-14\n\n### [Builder](#builder-5)\n\n*   builder-next: Added `entitlements` in builder config. [docker/engine#412](https://github.com/docker/engine/pull/412)\n*   Fix builder-next: permission errors on using build secrets or ssh forwarding with userns-remap. [docker/engine#420](https://github.com/docker/engine/pull/420)\n*   Fix builder-next: copying a symlink inside an already copied directory. [docker/engine#420](https://github.com/docker/engine/pull/420)\n\n### [Packaging](#packaging-1)\n\n*   Support RHEL 8 packages\n\n### [Runtime](#runtime-8)\n\n*   Bump Golang to 1.12.12. [docker/engine#418](https://github.com/docker/engine/pull/418)\n*   Update to RootlessKit to v0.7.0 to harden slirp4netns with mount namespace and seccomp. [docker/engine#397](https://github.com/docker/engine/pull/397)\n*   Fix to propagate GetContainer error from event processor. [docker/engine#407](https://github.com/docker/engine/pull/407)\n*   Fix push of OCI image. [docker/engine#405](https://github.com/docker/engine/pull/405)\n\n2019-10-17\n\n### [Networking](#networking-6)\n\n*   Rollback libnetwork changes to fix `DOCKER-USER` iptables chain issue. [docker/engine#404](https://github.com/docker/engine/pull/404)\n\n### [Known Issues](#known-issues)\n\n#### [Existing](#existing)\n\n*   In some circumstances with large clusters, Docker information might, as part of the Swarm section, include the error `code = ResourceExhausted desc = grpc: received message larger than max (5351376 vs. 4194304)`. This does not indicate any failure or misconfiguration by the user, and requires no response.\n*   Orchestrator port conflict can occur when redeploying all services as new. Due to many Swarm manager requests in a short amount of time, some services are not able to receive traffic and are causing a `404` error after being deployed.\n    *   **Workaround:** restart all tasks via `docker service update --force`.\n*   [CVE-2018-15664](https://nvd.nist.gov/vuln/detail/CVE-2018-15664) symlink-exchange attack with directory traversal. Workaround until proper fix is available in upcoming patch release: `docker pause` container before doing file operations. [moby/moby#39252](https://github.com/moby/moby/pull/39252)\n*   `docker cp` regression due to CVE mitigation. An error is produced when the source of `docker cp` is set to `/`.\n\n2019-10-08\n\n### [Security](#security-3)\n\n*   Patched `runc` in containerd. [CVE-2017-18367](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-18367)\n\n### [Builder](#builder-6)\n\n*   Fix builder-next: resolve digest for third party registries. [docker/engine#339](https://github.com/docker/engine/pull/339)\n    \n*   Fix builder-next: user namespace builds when daemon started with socket activation. [docker/engine#373](https://github.com/docker/engine/pull/373)\n    \n*   Fix builder-next; session: release forwarded ssh socket connection per connection. [docker/engine#373](https://github.com/docker/engine/pull/373)\n    \n*   Fix build-next: llbsolver: error on multiple cache importers. [docker/engine#373](https://github.com/docker/engine/pull/373)\n    \n\n### [Client](#client-6)\n\n*   Added support for Docker Template 0.1.6.\n    \n*   Mitigate against YAML files that have excessive aliasing. [docker/cli#2119](https://github.com/docker/cli/pull/2119)\n    \n\n### [Runtime](#runtime-9)\n\n*   Bump Golang to 1.12.10. [docker/engine#387](https://github.com/docker/engine/pull/387)\n    \n*   Bump containerd to 1.2.10. [docker/engine#385](https://github.com/docker/engine/pull/385)\n    \n*   Distribution: modify warning logic when pulling v2 schema1 manifests. [docker/engine#368](https://github.com/docker/engine/pull/368)\n    \n*   Fix `POST /images/create` returning a 500 status code when providing an incorrect platform option. [docker/engine#365](https://github.com/docker/engine/pull/365)\n    \n*   Fix `POST /build` returning a 500 status code when providing an incorrect platform option. [docker/engine#365](https://github.com/docker/engine/pull/365)\n    \n*   Fix panic on 32-bit ARMv7 caused by misaligned struct member. [docker/engine#363](https://github.com/docker/engine/pull/363)\n    \n*   Fix to return \"invalid parameter\" when linking to non-existing container. [docker/engine#352](https://github.com/docker/engine/pull/352)\n    \n*   Fix overlay2: busy error on mount when using kernel >= 5.2. [docker/engine#332](https://github.com/docker/engine/pull/332)\n    \n*   Fix `docker rmi` stuck in certain misconfigured systems, e.g. dead NFS share. [docker/engine#335](https://github.com/docker/engine/pull/335)\n    \n*   Fix handling of blocked I/O of exec'd processes. [docker/engine#296](https://github.com/docker/engine/pull/296)\n    \n*   Fix jsonfile logger: follow logs stuck when `max-size` is set and `max-file=1`. [docker/engine#378](https://github.com/docker/engine/pull/378)\n    \n\n### [Known Issues](#known-issues-1)\n\n#### [New](#new)\n\n*   `DOCKER-USER` iptables chain is missing: [docker/for-linux#810](https://github.com/docker/for-linux/issues/810). Users cannot perform additional container network traffic filtering on top of this iptables chain. You are not affected by this issue if you are not customizing iptable chains on top of `DOCKER-USER`.\n    *   **Workaround:** Insert the iptables chain after the docker daemon starts. For example:\n\n#### [Existing](#existing-1)\n\n*   In some circumstances with large clusters, docker information might, as part of the Swarm section, include the error `code = ResourceExhausted desc = grpc: received message larger than max (5351376 vs. 4194304)`. This does not indicate any failure or misconfiguration by the user, and requires no response.\n*   Orchestrator port conflict can occur when redeploying all services as new. Due to many swarm manager requests in a short amount of time, some services are not able to receive traffic and are causing a `404` error after being deployed.\n    *   **Workaround:** restart all tasks via `docker service update --force`.\n*   [CVE-2018-15664](https://nvd.nist.gov/vuln/detail/CVE-2018-15664) symlink-exchange attack with directory traversal. Workaround until proper fix is available in upcoming patch release: `docker pause` container before doing file operations. [moby/moby#39252](https://github.com/moby/moby/pull/39252)\n*   `docker cp` regression due to CVE mitigation. An error is produced when the source of `docker cp` is set to `/`.\n\n2019-09-03\n\n### [Builder](#builder-7)\n\n*   Fix `COPY --from` to non-existing directory on Windows. [moby/moby#39695](https://github.com/moby/moby/pull/39695)\n    \n*   Fix builder-next: metadata commands not having created time in history. [moby/moby#39456](https://github.com/moby/moby/issues/39456)\n    \n*   Fix builder-next: close progress on layer export error. [moby/moby#39782](https://github.com/moby/moby/pull/39782)\n    \n*   Update buildkit to 588c73e1e4. [moby/moby#39781](https://github.com/moby/moby/pull/39781)\n    \n\n### [Client](#client-7)\n\n*   Fix Windows absolute path detection on non-Windows [docker/cli#1990](https://github.com/docker/cli/pull/1990)\n    \n*   Fix to zsh completion script for `docker login --username`.\n    \n*   Fix context: produce consistent output on `context create`. [docker/cli#1985](https://github.com/docker/cli/pull/1874)\n    \n*   Fix support for HTTP proxy env variable. [docker/cli#2059](https://github.com/docker/cli/pull/2059)\n    \n\n### [Logging](#logging-2)\n\n*   Fix for reading journald logs. [moby/moby#37819](https://github.com/moby/moby/pull/37819) [moby/moby#38859](https://github.com/moby/moby/pull/38859)\n\n### [Networking](#networking-7)\n\n*   Prevent panic on network attached to a container with disabled networking. [moby/moby#39589](https://github.com/moby/moby/pull/39589)\n\n### [Runtime](#runtime-10)\n\n*   Bump Golang to 1.12.8.\n    \n*   Fix a potential engine panic when using XFS disk quota for containers. [moby/moby#39644](https://github.com/moby/moby/pull/39644)\n    \n\n### [Swarm](#swarm-1)\n\n*   Fix an issue where nodes with several tasks could not be removed. [docker/swarmkit#2867](https://github.com/docker/swarmkit/pull/2867)\n\n### [Known issues](#known-issues-2)\n\n*   In some circumstances with large clusters, docker information might, as part of the Swarm section, include the error `code = ResourceExhausted desc = grpc: received message larger than max (5351376 vs. 4194304)`. This does not indicate any failure or misconfiguration by the user, and requires no response.\n    \n*   Orchestrator port conflict can occur when redeploying all services as new. Due to many swarm manager requests in a short amount of time, some services are not able to receive traffic and are causing a `404` error after being deployed.\n    \n    *   Workaround: restart all tasks via `docker service update --force`.\n*   Traffic cannot egress the HOST because of missing Iptables rules in the FORWARD chain The missing rules are :\n    \n    *   Workaround: Add these rules back using a script and cron definitions. The script must contain '-C' commands to check for the presence of a rule and '-A' commands to add rules back. Run the script on a cron in regular intervals, for example, every minutes.\n    *   Affected versions: 18.09.1, 19.03.0\n*   [CVE-2018-15664](https://nvd.nist.gov/vuln/detail/CVE-2018-15664) symlink-exchange attack with directory traversal. Workaround until proper fix is available in upcoming patch release: `docker pause` container before doing file operations. [moby/moby#39252](https://github.com/moby/moby/pull/39252)\n    \n*   `docker cp` regression due to CVE mitigation. An error is produced when the source of `docker cp` is set to `/`.\n    \n\n2019-07-25\n\n### [Security](#security-4)\n\n*   Fixed loading of nsswitch based config inside chroot under Glibc. [CVE-2019-14271](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-14271)\n\n### [Known issues](#known-issues-3)\n\n*   In some circumstances, in large clusters, docker information might, as part of the Swarm section, include the error `code = ResourceExhausted desc = grpc: received message larger than max (5351376 vs. 4194304)`. This does not indicate any failure or misconfiguration by the user, and requires no response.\n    \n*   Orchestrator port conflict can occur when redeploying all services as new. Due to many swarm manager requests in a short amount of time, some services are not able to receive traffic and are causing a `404` error after being deployed.\n    \n    *   Workaround: restart all tasks via `docker service update --force`.\n*   Traffic cannot egress the HOST because of missing Iptables rules in the FORWARD chain The missing rules are :\n    \n    *   Workaround: Add these rules back using a script and cron definitions. The script must contain '-C' commands to check for the presence of a rule and '-A' commands to add rules back. Run the script on a cron in regular intervals, for example, every minutes.\n    *   Affected versions: 18.09.1, 19.03.0\n*   [CVE-2018-15664](https://nvd.nist.gov/vuln/detail/CVE-2018-15664) symlink-exchange attack with directory traversal. Workaround until proper fix is available in upcoming patch release: `docker pause` container before doing file operations. [moby/moby#39252](https://github.com/moby/moby/pull/39252)\n    \n*   `docker cp` regression due to CVE mitigation. An error is produced when the source of `docker cp` is set to `/`.\n    \n\n2019-07-22\n\n### [Builder](#builder-8)\n\n*   Fixed `COPY --from` to preserve ownership. [moby/moby#38599](https://github.com/moby/moby/pull/38599)\n    \n*   builder-next:\n    \n    *   Added inline cache support `--cache-from`. [docker/engine#215](https://github.com/docker/engine/pull/215)\n    *   Outputs configuration allowed. [moby/moby#38898](https://github.com/moby/moby/pull/38898)\n    *   Fixed gcr workaround token cache. [docker/engine#212](https://github.com/docker/engine/pull/212)\n    *   `stopprogress` called on download error. [docker/engine#215](https://github.com/docker/engine/pull/215)\n    *   Buildkit now uses systemd's `resolv.conf`. [docker/engine#260](https://github.com/docker/engine/pull/260).\n    *   Setting buildkit outputs now allowed. [docker/cli#1766](https://github.com/docker/cli/pull/1766)\n    *   Look for Dockerfile specific dockerignore file (for example, Dockerfile.dockerignore) for ignored paths. [docker/engine#215](https://github.com/docker/engine/pull/215)\n    *   Automatically detect if process execution is possible for x86, arm, and arm64 binaries. [docker/engine#215](https://github.com/docker/engine/pull/215)\n    *   Updated buildkit to 1f89ec1. [docker/engine#260](https://github.com/docker/engine/pull/260)\n    *   Use Dockerfile frontend version `docker/dockerfile:1.1` by default. [docker/engine#215](https://github.com/docker/engine/pull/215)\n    *   No longer rely on an external image for COPY/ADD operations. [docker/engine#215](https://github.com/docker/engine/pull/215)\n\n### [Client](#client-8)\n\n*   Added `--pids-limit` flag to `docker update`. [docker/cli#1765](https://github.com/docker/cli/pull/1765)\n*   Added systctl support for services. [docker/cli#1754](https://github.com/docker/cli/pull/1754)\n*   Added support for `template_driver` in compose files. [docker/cli#1746](https://github.com/docker/cli/pull/1746)\n*   Added `--device` support for Windows. [docker/cli#1606](https://github.com/docker/cli/pull/1606)\n*   Added support for Data Path Port configuration. [docker/cli#1509](https://github.com/docker/cli/pull/1509)\n*   Added fast context switch: commands. [docker/cli#1501](https://github.com/docker/cli/pull/1501)\n*   Support added for `--mount type=bind,bind-nonrecursive,...` [docker/cli#1430](https://github.com/docker/cli/pull/1430)\n*   Added maximum replicas per node. [docker/cli#1612](https://github.com/docker/cli/pull/1612)\n*   Added option to pull images quietly. [docker/cli#882](https://github.com/docker/cli/pull/882)\n*   Added a separate `--domainname` flag. [docker/cli#1130](https://github.com/docker/cli/pull/1130)\n*   Added support for secret drivers in `docker stack deploy`. [docker/cli#1783](https://github.com/docker/cli/pull/1783)\n*   Added ability to use swarm `Configs` as `CredentialSpecs` on services. [docker/cli#1781](https://github.com/docker/cli/pull/1781)\n*   Added `--security-opt systempaths=unconfined` support. [docker/cli#1808](https://github.com/docker/cli/pull/1808)\n*   Added basic framework for writing and running CLI plugins. [docker/cli#1564](https://github.com/docker/cli/pull/1564) [docker/cli#1898](https://github.com/docker/cli/pull/1898)\n*   Bumped Docker App to v0.8.0. [docker/docker-ce-packaging#341](https://github.com/docker/docker-ce-packaging/pull/341)\n*   Added support for Docker buildx. [docker/docker-ce-packaging#336](https://github.com/docker/docker-ce-packaging/pull/336)\n*   Added support for Docker Assemble v0.36.0.\n*   Added support for Docker Cluster v1.0.0-rc2.\n*   Added support for Docker Template v0.1.4.\n*   Added support for Docker Registry v0.1.0-rc1.\n*   Bumped google.golang.org/grpc to v1.20.1. [docker/cli#1884](https://github.com/docker/cli/pull/1884)\n*   CLI changed to pass driver specific options to `docker run`. [docker/cli#1767](https://github.com/docker/cli/pull/1767)\n*   Bumped Golang 1.12.5. [docker/cli#1875](https://github.com/docker/cli/pull/1875)\n*   `docker system info` output now segregates information relevant to the client and daemon. [docker/cli#1638](https://github.com/docker/cli/pull/1638)\n*   (Experimental) When targeting Kubernetes, added support for `x-pull-secret: some-pull-secret` in compose-files service configs. [docker/cli#1617](https://github.com/docker/cli/pull/1617)\n*   (Experimental) When targeting Kubernetes, added support for `x-pull-policy: <Never|Always|IfNotPresent>` in compose-files service configs. [docker/cli#1617](https://github.com/docker/cli/pull/1617)\n*   cp, save, export: Now preventing overwriting irregular files. [docker/cli#1515](https://github.com/docker/cli/pull/1515)\n*   npipe volume type on stack file now allowed. [docker/cli#1195](https://github.com/docker/cli/pull/1195)\n*   Fixed tty initial size error. [docker/cli#1529](https://github.com/docker/cli/pull/1529)\n*   Fixed problem with labels copying value from environment variables. [docker/cli#1671](https://github.com/docker/cli/pull/1671)\n\n### [API](#api)\n\n*   Updated API version to v1.40. [moby/moby#38089](https://github.com/moby/moby/pull/38089)\n*   Added warnings to `/info` endpoint, and moved detection to the daemon. [moby/moby#37502](https://github.com/moby/moby/pull/37502)\n*   Added HEAD support for `/_ping` endpoint. [moby/moby#38570](https://github.com/moby/moby/pull/38570)\n*   Added `Cache-Control` headers to disable caching `/_ping` endpoint. [moby/moby#38569](https://github.com/moby/moby/pull/38569)\n*   Added `containerd`, `runc`, and `docker-init` versions to `/version`. [moby/moby#37974](https://github.com/moby/moby/pull/37974)\n*   Added undocumented `/grpc` endpoint and registered BuildKit's controller. [moby/moby#38990](https://github.com/moby/moby/pull/38990)\n\n### [Experimental](#experimental)\n\n*   Enabled checkpoint/restore of containers with TTY. [moby/moby#38405](https://github.com/moby/moby/pull/38405)\n*   LCOW: Added support for memory and CPU limits. [moby/moby#37296](https://github.com/moby/moby/pull/37296)\n*   Windows: Added ContainerD runtime. [moby/moby#38541](https://github.com/moby/moby/pull/38541)\n*   Windows: LCOW now requires Windows RS5+. [moby/moby#39108](https://github.com/moby/moby/pull/39108)\n\n### [Security](#security-5)\n\n*   mount: added BindOptions.NonRecursive (API v1.40). [moby/moby#38003](https://github.com/moby/moby/pull/38003)\n*   seccomp: whitelisted `io_pgetevents()`. [moby/moby#38895](https://github.com/moby/moby/pull/38895)\n*   seccomp: `ptrace(2)` for 4.8+ kernels now allowed. [moby/moby#38137](https://github.com/moby/moby/pull/38137)\n\n### [Runtime](#runtime-11)\n\n*   Running `dockerd` as a non-root user (Rootless mode) is now allowed. [moby/moby#380050](https://github.com/moby/moby/pull/38050)\n*   Rootless: optional support provided for `lxc-user-nic` SUID binary. [docker/engine#208](https://github.com/docker/engine/pull/208)\n*   Added DeviceRequests to HostConfig to support NVIDIA GPUs. [moby/moby#38828](https://github.com/moby/moby/pull/38828)\n*   Added `--device` support for Windows. [moby/moby#37638](https://github.com/moby/moby/pull/37638)\n*   Added `memory.kernelTCP` support for linux. [moby/moby#37043](https://github.com/moby/moby/pull/37043)\n*   Windows credential specs can now be passed directly to the engine. [moby/moby#38777](https://github.com/moby/moby/pull/38777)\n*   Added pids-limit support in docker update. [moby/moby#32519](https://github.com/moby/moby/pull/32519)\n*   Added support for exact list of capabilities. [moby/moby#38380](https://github.com/moby/moby/pull/38380)\n*   daemon: Now use 'private' ipc mode by default. [moby/moby#35621](https://github.com/moby/moby/pull/35621)\n*   daemon: switched to semaphore-gated WaitGroup for startup tasks. [moby/moby#38301](https://github.com/moby/moby/pull/38301)\n*   Now use `idtools.LookupGroup` instead of parsing `/etc/group` file for docker.sock ownership to fix: `api.go doesn't respect nsswitch.conf`. [moby/moby#38126](https://github.com/moby/moby/pull/38126)\n*   cli: fixed images filter when using multi reference filter. [moby/moby#38171](https://github.com/moby/moby/pull/38171)\n*   Bumped Golang to 1.12.5. [docker/engine#209](https://github.com/docker/engine/pull/209)\n*   Bumped `containerd` to 1.2.6. [moby/moby#39016](https://github.com/moby/moby/pull/39016)\n*   Bumped `runc` to 1.0.0-rc8, opencontainers/selinux v1.2.2. [docker/engine#210](https://github.com/docker/engine/pull/210)\n*   Bumped `google.golang.org/grpc` to v1.20.1. [docker/engine#215](https://github.com/docker/engine/pull/215)\n*   Performance optimized in aufs and layer store for massively parallel container creation/removal. [moby/moby#39135](https://github.com/moby/moby/pull/39135) [moby/moby#39209](https://github.com/moby/moby/pull/39209)\n*   Root is now passed to chroot for chroot Tar/Untar (CVE-2018-15664) [moby/moby#39292](https://github.com/moby/moby/pull/39292)\n*   Fixed `docker --init` with /dev bind mount. [moby/moby#37665](https://github.com/moby/moby/pull/37665)\n*   The right device number is now fetched when greater than 255 and using the `--device-read-bps` option. [moby/moby#39212](https://github.com/moby/moby/pull/39212)\n*   Fixed `Path does not exist` error when path definitely exists. [moby/moby#39251](https://github.com/moby/moby/pull/39251)\n\n### [Networking](#networking-8)\n\n*   Moved IPVLAN driver out of experimental. [moby/moby#38983](https://github.com/moby/moby/pull/38983)\n*   Added support for 'dangling' filter. [moby/moby#31551](https://github.com/moby/moby/pull/31551) [docker/libnetwork#2230](https://github.com/docker/libnetwork/pull/2230)\n*   Load balancer sandbox is now deleted when a service is updated with `--network-rm`. [docker/engine#213](https://github.com/docker/engine/pull/213)\n*   Windows: Now forcing a nil IP specified in `PortBindings` to IPv4zero (0.0.0.0). [docker/libnetwork#2376](https://github.com/docker/libnetwork/pull/2376)\n\n### [Swarm](#swarm-2)\n\n*   Added support for maximum replicas per node. [moby/moby#37940](https://github.com/moby/moby/pull/37940)\n*   Added support for GMSA CredentialSpecs from Swarmkit configs. [moby/moby#38632](https://github.com/moby/moby/pull/38632)\n*   Added support for sysctl options in services. [moby/moby#37701](https://github.com/moby/moby/pull/37701)\n*   Added support for filtering on node labels. [moby/moby#37650](https://github.com/moby/moby/pull/37650)\n*   Windows: Support added for named pipe mounts in docker service create + stack yml. [moby/moby#37400](https://github.com/moby/moby/pull/37400)\n*   VXLAN UDP Port configuration now supported. [moby/moby#38102](https://github.com/moby/moby/pull/38102)\n*   Now using Service Placement Constraints in Enforcer. [docker/swarmkit#2857](https://github.com/docker/swarmkit/pull/2857)\n*   Increased max recv gRPC message size for nodes and secrets. [docker/engine#256](https://github.com/docker/engine/pull/256)\n\n### [Logging](#logging-3)\n\n*   Enabled gcplogs driver on Windows. [moby/moby#37717](https://github.com/moby/moby/pull/37717)\n*   Added zero padding for RFC5424 syslog format. [moby/moby#38335](https://github.com/moby/moby/pull/38335)\n*   Added `IMAGE_NAME` attribute to `journald` log events. [moby/moby#38032](https://github.com/moby/moby/pull/38032)\n\n### [Deprecation](#deprecation)\n\n*   Deprecate image manifest v2 schema1 in favor of v2 schema2. Future version of Docker will remove support for v2 schema1 althogether. [moby/moby#39365](https://github.com/moby/moby/pull/39365)\n*   Removed v1.10 migrator. [moby/moby#38265](https://github.com/moby/moby/pull/38265)\n*   Now skipping deprecated storage-drivers in auto-selection. [moby/moby#38019](https://github.com/moby/moby/pull/38019)\n*   Deprecated `aufs` storage driver and added warning. [moby/moby#38090](https://github.com/moby/moby/pull/38090)\n*   Removed support for 17.09.\n\nFor more information on deprecated flags and APIs, refer to [deprecation information](https://docs.docker.com/engine/deprecated/) for target removal dates.\n\n### [Known issues](#known-issues-4)\n\n*   In some circumstances with large clusters, docker information might, as part of the Swarm section, include the error `code = ResourceExhausted desc = grpc: received message larger than max (5351376 vs. 4194304)`. This does not indicate any failure or misconfiguration by the user, and requires no response.\n    \n*   Orchestrator port conflict can occur when redeploying all services as new. Due to many swarm manager requests in a short amount of time, some services are not able to receive traffic and are causing a `404` error after being deployed.\n    \n    *   Workaround: restart all tasks via `docker service update --force`.\n*   Traffic cannot egress the HOST because of missing Iptables rules in the FORWARD chain The missing rules are :\n    \n    *   Workaround: Add these rules back using a script and cron definitions. The script must contain '-C' commands to check for the presence of a rule and '-A' commands to add rules back. Run the script on a cron in regular intervals, for example, every minutes.\n    *   Affected versions: 18.09.1, 19.03.0\n*   [CVE-2018-15664](https://nvd.nist.gov/vuln/detail/CVE-2018-15664) symlink-exchange attack with directory traversal. Workaround until proper fix is available in upcoming patch release: `docker pause` container before doing file operations. [moby/moby#39252](https://github.com/moby/moby/pull/39252)\n    \n*   `docker cp` regression due to CVE mitigation. An error is produced when the source of `docker cp` is set to `/`.",
  "title": "Docker Engine 19.03 release notes | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/18.05/",
  "markdown": "# Docker Engine 18.05 release notes\n\n2018-05-09\n\n### [Builder](#builder)\n\n*   Adding `netbsd` compatibility to the package `pkg/term`. [moby/moby#36887](https://github.com/moby/moby/pull/36887)\n*   Standardizes output path for artifacts of intermediate builds to `/build/`. [moby/moby#36858](https://github.com/moby/moby/pull/36858)\n\n### [Client](#client)\n\n*   Fix `docker stack deploy` reference flag. [docker/cli#981](https://github.com/docker/cli/pull/981)\n*   Fix docker stack deploy re-deploying services after the service was updated with `--force`. [docker/cli#963](https://github.com/docker/cli/pull/963)\n\n*   Add bash completion for `secret|config create --template-driver`. [docker/cli#1004](https://github.com/docker/cli/pull/1004)\n*   Add fish completions for docker trust subcommand. [docker/cli#984](https://github.com/docker/cli/pull/984)\n\n*   Fix --format example for docker history. [docker/cli#980](https://github.com/docker/cli/pull/980)\n*   Fix error with merge composefile with networks. [docker/cli#983](https://github.com/docker/cli/pull/983)\n\n### [Logging](#logging)\n\n*   Standardized the properties of storage-driver log messages. [moby/moby#36492](https://github.com/moby/moby/pull/36492)\n*   Improve partial message support in logger. [moby/moby#35831](https://github.com/moby/moby/pull/35831)\n\n### [Networking](#networking)\n\n*   Allow for larger preset property values, do not override. [docker/libnetwork#2124](https://github.com/docker/libnetwork/pull/2124)\n*   networkdb: User write lock in handleNodeEvent. [docker/libnetwork#2136](https://github.com/docker/libnetwork/pull/2136)\n\n*   Import libnetwork fix for rolling updates. [moby/moby#36638](https://github.com/moby/moby/pull/36638)\n*   Update libnetwork to improve scalabiltiy of bridge network isolation rules. [moby/moby#36774](https://github.com/moby/moby/pull/36774)\n\n*   Fix a misused network object name. [moby/moby#36745](https://github.com/moby/moby/pull/36745)\n\n### [Runtime](#runtime)\n\n*   LCOW: Implement `docker save`. [moby/moby#36599](https://github.com/moby/moby/pull/36599)\n*   Pkg: devmapper: dynamically load dm\\_task\\_deferred\\_remove. [moby/moby#35518](https://github.com/moby/moby/pull/35518)\n*   Windows: Add GetLayerPath implementation in graphdriver. [moby/moby#36738](https://github.com/moby/moby/pull/36738)\n\n*   Fix Windows layer leak when write fails. [moby/moby#36728](https://github.com/moby/moby/pull/36728)\n*   Fix FIFO, sockets and device files when run in user NS. [moby/moby#36756](https://github.com/moby/moby/pull/36756)\n*   Fix docker version output alignment. [docker/cli#965](https://github.com/docker/cli/pull/965)\n\n*   Always make sysfs read-write with privileged. [moby/moby#36808](https://github.com/moby/moby/pull/36808)\n*   Bump Golang to 1.10.1. [moby/moby#35739](https://github.com/moby/moby/pull/35739)\n*   Bump containerd client. [moby/moby#36684](https://github.com/moby/moby/pull/36684)\n*   Bump golang.org/x/net to go1.10 release commit. [moby/moby#36894](https://github.com/moby/moby/pull/36894)\n*   Context.WithTimeout: do call the cancel func. [moby/moby#36920](https://github.com/moby/moby/pull/36920)\n*   Copy: avoid using all system memory with authz plugins. [moby/moby#36595](https://github.com/moby/moby/pull/36595)\n*   Daemon/cluster: handle partial attachment entries during configure. [moby/moby#36769](https://github.com/moby/moby/pull/36769)\n*   Don't make container mount unbindable. [moby/moby#36768](https://github.com/moby/moby/pull/36768)\n*   Extra check before unmounting on shutdown. [moby/moby#36879](https://github.com/moby/moby/pull/36879)\n*   Move mount parsing to separate package. [moby/moby#36896](https://github.com/moby/moby/pull/36896)\n*   No global volume driver store. [moby/moby#36637](https://github.com/moby/moby/pull/36637)\n*   Pkg/mount improvements. [moby/moby#36091](https://github.com/moby/moby/pull/36091)\n*   Relax some libcontainerd client locking. [moby/moby#36848](https://github.com/moby/moby/pull/36848)\n*   Remove daemon dependency on api packages. [moby/moby#36912](https://github.com/moby/moby/pull/36912)\n*   Remove the retries for service update. [moby/moby#36827](https://github.com/moby/moby/pull/36827)\n*   Revert unencryted storage warning prompt. [docker/cli#1008](https://github.com/docker/cli/pull/1008)\n*   Support cancellation in `directory.Size()`. [moby/moby#36734](https://github.com/moby/moby/pull/36734)\n*   Switch from x/net/context -> context. [moby/moby#36904](https://github.com/moby/moby/pull/36904)\n*   Fixed a function to check Content-type is `application/json` or not. [moby/moby#36778](https://github.com/moby/moby/pull/36778)\n\n*   Add default pollSettings config functions. [moby/moby#36706](https://github.com/moby/moby/pull/36706)\n*   Add if judgment before receiving operations on daemonWaitCh. [moby/moby#36651](https://github.com/moby/moby/pull/36651)\n\n*   Fix issues with running volume tests as non-root.. [moby/moby#36935](https://github.com/moby/moby/pull/36935)\n\n### [Swarm Mode](#swarm-mode)\n\n*   RoleManager will remove detected nodes from the cluster membership [docker/swarmkit#2548](https://github.com/docker/swarmkit/pull/2548)\n*   Scheduler/TaskReaper: handle unassigned tasks marked for shutdown [docker/swarmkit#2574](https://github.com/docker/swarmkit/pull/2574)\n*   Avoid predefined error log. [docker/swarmkit#2561](https://github.com/docker/swarmkit/pull/2561)\n*   Task reaper should delete tasks with removed slots that were not yet assigned. [docker/swarmkit#2557](https://github.com/docker/swarmkit/pull/2557)\n*   Agent reports FIPS status. [docker/swarmkit#2587](https://github.com/docker/swarmkit/pull/2587)\n\n*   Fix: timeMutex critical operation outside of critical section. [docker/swarmkit#2603](https://github.com/docker/swarmkit/pull/2603)\n\n*   Expose swarmkit's Raft tuning parameters in engine config. [moby/moby#36726](https://github.com/moby/moby/pull/36726)\n*   Make internal/test/daemon.Daemon swarm aware. [moby/moby#36826](https://github.com/moby/moby/pull/36826)",
  "title": "Docker Engine 18.05 release notes | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/exporters/image-registry/",
  "markdown": "# Image and registry exporters | Docker Docs\n\nThe `image` exporter outputs the build result into a container image format. The `registry` exporter is identical, but it automatically pushes the result by setting `push=true`.\n\nBuild a container image using the `image` and `registry` exporters:\n\nThe following table describes the available parameters that you can pass to `--output` for `type=image`:\n\n| Parameter | Type | Default | Description |\n| --- | --- | --- | --- |\n| `name` | String |     | Specify image name(s) |\n| `push` | `true`,`false` | `false` | Push after creating the image. |\n| `push-by-digest` | `true`,`false` | `false` | Push image without name. |\n| `registry.insecure` | `true`,`false` | `false` | Allow pushing to insecure registry. |\n| `dangling-name-prefix` | `<value>` |     | Name image with `prefix@<digest>`, used for anonymous images |\n| `name-canonical` | `true`,`false` |     | Add additional canonical name `name@<digest>` |\n| `compression` | `uncompressed`,`gzip`,`estargz`,`zstd` | `gzip` | Compression type, see [compression](https://docs.docker.com/build/exporters/#compression) |\n| `compression-level` | `0..22` |     | Compression level, see [compression](https://docs.docker.com/build/exporters/#compression) |\n| `force-compression` | `true`,`false` | `false` | Forcefully apply compression, see [compression](https://docs.docker.com/build/exporters/#compression) |\n| `oci-mediatypes` | `true`,`false` | `false` | Use OCI media types in exporter manifests, see [OCI Media types](https://docs.docker.com/build/exporters/#oci-media-types) |\n| `unpack` | `true`,`false` | `false` | Unpack image after creation (for use with containerd) |\n| `store` | `true`,`false` | `true` | Store the result images to the worker's (for example, containerd) image store, and ensures that the image has all blobs in the content store. Ignored if the worker doesn't have image store (when using OCI workers, for example). |\n| `annotation.<key>` | String |     | Attach an annotation with the respective `key` and `value` to the built image,see [annotations](#annotations) |\n\nThese exporters support adding OCI annotation using `annotation` parameter, followed by the annotation name using dot notation. The following example sets the `org.opencontainers.image.title` annotation:\n\nFor more information about annotations, see [BuildKit documentation](https://github.com/moby/buildkit/blob/master/docs/annotations.md).\n\nFor more information on the `image` or `registry` exporters, see the [BuildKit README](https://github.com/moby/buildkit/blob/master/README.md#imageregistry).",
  "title": "Image and registry exporters | Docker Docs\n",
  "description": "The image and registry exporters create an image that can be loaded to your local image store or pushed to a registry ",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/security/",
  "markdown": "# Docker security | Docker Docs\n\nThere are four major areas to consider when reviewing Docker security:\n\n*   The intrinsic security of the kernel and its support for namespaces and cgroups\n*   The attack surface of the Docker daemon itself\n*   Loopholes in the container configuration profile, either by default, or when customized by users.\n*   The \"hardening\" security features of the kernel and how they interact with containers.\n\nDocker containers are very similar to LXC containers, and they have similar security features. When you start a container with `docker run`, behind the scenes Docker creates a set of namespaces and control groups for the container.\n\nNamespaces provide the first and most straightforward form of isolation. Processes running within a container cannot see, and even less affect, processes running in another container, or in the host system.\n\nEach container also gets its own network stack, meaning that a container doesn't get privileged access to the sockets or interfaces of another container. Of course, if the host system is setup accordingly, containers can interact with each other through their respective network interfaces â€” just like they can interact with external hosts. When you specify public ports for your containers or use [links](https://docs.docker.com/network/links/) then IP traffic is allowed between containers. They can ping each other, send/receive UDP packets, and establish TCP connections, but that can be restricted if necessary. From a network architecture point of view, all containers on a given Docker host are sitting on bridge interfaces. This means that they are just like physical machines connected through a common Ethernet switch; no more, no less.\n\nHow mature is the code providing kernel namespaces and private networking? Kernel namespaces were introduced [between kernel version 2.6.15 and 2.6.26](https://man7.org/linux/man-pages/man7/namespaces.7.html). This means that since July 2008 (date of the 2.6.26 release ), namespace code has been exercised and scrutinized on a large number of production systems. And there is more: the design and inspiration for the namespaces code are even older. Namespaces are actually an effort to reimplement the features of [OpenVZ](https://en.wikipedia.org/wiki/OpenVZ) in such a way that they could be merged within the mainstream kernel. And OpenVZ was initially released in 2005, so both the design and the implementation are pretty mature.\n\nControl Groups are another key component of Linux containers. They implement resource accounting and limiting. They provide many useful metrics, but they also help ensure that each container gets its fair share of memory, CPU, disk I/O; and, more importantly, that a single container cannot bring the system down by exhausting one of those resources.\n\nSo while they do not play a role in preventing one container from accessing or affecting the data and processes of another container, they are essential to fend off some denial-of-service attacks. They are particularly important on multi-tenant platforms, like public and private PaaS, to guarantee a consistent uptime (and performance) even when some applications start to misbehave.\n\nControl Groups have been around for a while as well: the code was started in 2006, and initially merged in kernel 2.6.24.\n\nRunning containers (and applications) with Docker implies running the Docker daemon. This daemon requires `root` privileges unless you opt-in to [Rootless mode](https://docs.docker.com/engine/security/rootless/), and you should therefore be aware of some important details.\n\nFirst of all, only trusted users should be allowed to control your Docker daemon. This is a direct consequence of some powerful Docker features. Specifically, Docker allows you to share a directory between the Docker host and a guest container; and it allows you to do so without limiting the access rights of the container. This means that you can start a container where the `/host` directory is the `/` directory on your host; and the container can alter your host filesystem without any restriction. This is similar to how virtualization systems allow filesystem resource sharing. Nothing prevents you from sharing your root filesystem (or even your root block device) with a virtual machine.\n\nThis has a strong security implication: for example, if you instrument Docker from a web server to provision containers through an API, you should be even more careful than usual with parameter checking, to make sure that a malicious user cannot pass crafted parameters causing Docker to create arbitrary containers.\n\nFor this reason, the REST API endpoint (used by the Docker CLI to communicate with the Docker daemon) changed in Docker 0.5.2, and now uses a Unix socket instead of a TCP socket bound on 127.0.0.1 (the latter being prone to cross-site request forgery attacks if you happen to run Docker directly on your local machine, outside of a VM). You can then use traditional Unix permission checks to limit access to the control socket.\n\nYou can also expose the REST API over HTTP if you explicitly decide to do so. However, if you do that, be aware of the above mentioned security implications. Note that even if you have a firewall to limit accesses to the REST API endpoint from other hosts in the network, the endpoint can be still accessible from containers, and it can easily result in the privilege escalation. Therefore it is _mandatory_ to secure API endpoints with [HTTPS and certificates](https://docs.docker.com/engine/security/protect-access/). Exposing the daemon API over HTTP without TLS is not permitted, and such a configuration causes the daemon to fail early on startup, see [Unauthenticated TCP connections](https://docs.docker.com/engine/deprecated/#unauthenticated-tcp-connections). It is also recommended to ensure that it is reachable only from a trusted network or VPN.\n\nYou can also use `DOCKER_HOST=ssh://USER@HOST` or `ssh -L /path/to/docker.sock:/var/run/docker.sock` instead if you prefer SSH over TLS.\n\nThe daemon is also potentially vulnerable to other inputs, such as image loading from either disk with `docker load`, or from the network with `docker pull`. As of Docker 1.3.2, images are now extracted in a chrooted subprocess on Linux/Unix platforms, being the first-step in a wider effort toward privilege separation. As of Docker 1.10.0, all images are stored and accessed by the cryptographic checksums of their contents, limiting the possibility of an attacker causing a collision with an existing image.\n\nFinally, if you run Docker on a server, it is recommended to run exclusively Docker on the server, and move all other services within containers controlled by Docker. Of course, it is fine to keep your favorite admin tools (probably at least an SSH server), as well as existing monitoring/supervision processes, such as NRPE and collectd.\n\nBy default, Docker starts containers with a restricted set of capabilities. What does that mean?\n\nCapabilities turn the binary \"root/non-root\" dichotomy into a fine-grained access control system. Processes (like web servers) that just need to bind on a port below 1024 do not need to run as root: they can just be granted the `net_bind_service` capability instead. And there are many other capabilities, for almost all the specific areas where root privileges are usually needed. This means a lot for container security.\n\nTypical servers run several processes as `root`, including the SSH daemon, `cron` daemon, logging daemons, kernel modules, network configuration tools, and more. A container is different, because almost all of those tasks are handled by the infrastructure around the container:\n\n*   SSH access are typically managed by a single server running on the Docker host\n*   `cron`, when necessary, should run as a user process, dedicated and tailored for the app that needs its scheduling service, rather than as a platform-wide facility\n*   Log management is also typically handed to Docker, or to third-party services like Loggly or Splunk\n*   Hardware management is irrelevant, meaning that you never need to run `udevd` or equivalent daemons within containers\n*   Network management happens outside of the containers, enforcing separation of concerns as much as possible, meaning that a container should never need to perform `ifconfig`, `route`, or ip commands (except when a container is specifically engineered to behave like a router or firewall, of course)\n\nThis means that in most cases, containers do not need \"real\" root privileges at all\\* And therefore, containers can run with a reduced capability set; meaning that \"root\" within a container has much less privileges than the real \"root\". For instance, it is possible to:\n\n*   Deny all \"mount\" operations\n*   Deny access to raw sockets (to prevent packet spoofing)\n*   Deny access to some filesystem operations, like creating new device nodes, changing the owner of files, or altering attributes (including the immutable flag)\n*   Deny module loading\n\nThis means that even if an intruder manages to escalate to root within a container, it is much harder to do serious damage, or to escalate to the host.\n\nThis doesn't affect regular web apps, but reduces the vectors of attack by malicious users considerably. By default Docker drops all capabilities except [those needed](https://github.com/moby/moby/blob/master/oci/caps/defaults.go#L6-L19), an allowlist instead of a denylist approach. You can see a full list of available capabilities in [Linux manpages](https://man7.org/linux/man-pages/man7/capabilities.7.html).\n\nOne primary risk with running Docker containers is that the default set of capabilities and mounts given to a container may provide incomplete isolation, either independently, or when used in combination with kernel vulnerabilities.\n\nDocker supports the addition and removal of capabilities, allowing use of a non-default profile. This may make Docker more secure through capability removal, or less secure through the addition of capabilities. The best practice for users would be to remove all capabilities except those explicitly required for their processes.\n\n## [Docker Content Trust signature verification](#docker-content-trust-signature-verification)\n\nDocker Engine can be configured to only run signed images. The Docker Content Trust signature verification feature is built directly into the `dockerd` binary.  \nThis is configured in the Dockerd configuration file.\n\nTo enable this feature, trustpinning can be configured in `daemon.json`, whereby only repositories signed with a user-specified root key can be pulled and run.\n\nThis feature provides more insight to administrators than previously available with the CLI for enforcing and performing image signature verification.\n\nFor more information on configuring Docker Content Trust Signature Verification, go to [Content trust in Docker](https://docs.docker.com/engine/security/trust/).\n\nCapabilities are just one of the many security features provided by modern Linux kernels. It is also possible to leverage existing, well-known systems like TOMOYO, AppArmor, SELinux, GRSEC, etc. with Docker.\n\nWhile Docker currently only enables capabilities, it doesn't interfere with the other systems. This means that there are many different ways to harden a Docker host. Here are a few examples.\n\n*   You can run a kernel with GRSEC and PAX. This adds many safety checks, both at compile-time and run-time; it also defeats many exploits, thanks to techniques like address randomization. It doesn't require Docker-specific configuration, since those security features apply system-wide, independent of containers.\n*   If your distribution comes with security model templates for Docker containers, you can use them out of the box. For instance, we ship a template that works with AppArmor and Red Hat comes with SELinux policies for Docker. These templates provide an extra safety net (even though it overlaps greatly with capabilities).\n*   You can define your own policies using your favorite access control mechanism.\n\nJust as you can use third-party tools to augment Docker containers, including special network topologies or shared filesystems, tools exist to harden Docker containers without the need to modify Docker itself.\n\nAs of Docker 1.10 User Namespaces are supported directly by the docker daemon. This feature allows for the root user in a container to be mapped to a non uid-0 user outside the container, which can help to mitigate the risks of container breakout. This facility is available but not enabled by default.\n\nRefer to the [daemon command](https://docs.docker.com/reference/cli/dockerd/#daemon-user-namespace-options) in the command line reference for more information on this feature. Additional information on the implementation of User Namespaces in Docker can be found in [this blog post](https://integratedcode.us/2015/10/13/user-namespaces-have-arrived-in-docker/).\n\nDocker containers are, by default, quite secure; especially if you run your processes as non-privileged users inside the container.\n\nYou can add an extra layer of safety by enabling AppArmor, SELinux, GRSEC, or another appropriate hardening system.\n\nIf you think of ways to make docker more secure, we welcome feature requests, pull requests, or comments on the Docker community forums.\n\n*   [Use trusted images](https://docs.docker.com/engine/security/trust/)\n*   [Seccomp security profiles for Docker](https://docs.docker.com/engine/security/seccomp/)\n*   [AppArmor security profiles for Docker](https://docs.docker.com/engine/security/apparmor/)\n*   [On the Security of Containers (2014)](https://medium.com/@ewindisch/on-the-security-of-containers-2c60ffe25a9e)\n*   [Docker swarm mode overlay network security model](https://docs.docker.com/network/drivers/overlay/)",
  "title": "Docker security | Docker Docs\n",
  "description": "Review of the Docker Daemon attack surface",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/inspect-service/",
  "markdown": "# Inspect a service on the swarm\n\nWhen you have [deployed a service](https://docs.docker.com/engine/swarm/swarm-tutorial/deploy-service/) to your swarm, you can use the Docker CLI to see details about the service running in the swarm.\n\n1.  If you haven't already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n    \n2.  Run `docker service inspect --pretty <SERVICE-ID>` to display the details about a service in an easily readable format.\n    \n    To see the details on the `helloworld` service:\n    \n    > **Tip**\n    > \n    > To return the service details in json format, run the same command without the `--pretty` flag.\n    \n3.  Run `docker service ps <SERVICE-ID>` to see which nodes are running the service:\n    \n    In this case, the one instance of the `helloworld` service is running on the `worker2` node. You may see the service running on your manager node. By default, manager nodes in a swarm can execute tasks just like worker nodes.\n    \n    Swarm also shows you the `DESIRED STATE` and `CURRENT STATE` of the service task so you can see if tasks are running according to the service definition.\n    \n4.  Run `docker ps` on the node where the task is running to see details about the container for the task.\n    \n    > **Tip**\n    > \n    > If `helloworld` is running on a node other than your manager node, you must ssh to that node.\n    \n\nNext, you'll change the scale for the service running in the swarm.",
  "title": "Inspect a service on the swarm | Docker Docs\n",
  "description": "Inspect the application",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/18.09/",
  "markdown": "# Docker Engine 18.09 release notes\n\n> **Note:**\n> \n> With this release, the daemon, client and container runtime are now all shipped in separate packages. When updating, you need to update all packages at the same time to get the latest patch releases for each. For example, on Ubuntu:\n> \n> See the [installation instructions](https://docs.docker.com/engine/install/) for the corresponding Linux distro for details.\n\n2019-09-03\n\n### [Client](#client)\n\n*   Fix Windows absolute path detection on non-Windows. [docker/cli#1990](https://github.com/docker/cli/pull/1990)\n*   Fix Docker refusing to load key from delegation.key on Windows. [docker/cli#1968](https://github.com/docker/cli/pull/1968)\n*   Completion scripts updates for bash and zsh.\n\n### [Logging](#logging)\n\n*   Fix for reading journald logs. [moby/moby#37819](https://github.com/moby/moby/pull/37819) [moby/moby#38859](https://github.com/moby/moby/pull/38859)\n\n### [Networking](#networking)\n\n*   Prevent panic on network attached to a container with disabled networking. [moby/moby#39589](https://github.com/moby/moby/pull/39589)\n*   Fix service port for an application becomes unavailable randomly. [docker/libnetwork#2069](https://github.com/docker/libnetwork/pull/2069)\n*   Fix cleaning up `--config-only` networks `--config-from` networkshave ungracefully exited. [docker/libnetwork#2373](https://github.com/docker/libnetwork/pull/2373)\n\n### [Runtime](#runtime)\n\n*   Update to Go 1.11.13.\n*   Fix a potential engine panic when using XFS disk quota for containers. [moby/moby#39644](https://github.com/moby/moby/pull/39644)\n\n### [Swarm](#swarm)\n\n*   Fix \"grpc: received message larger than max\" errors. [moby/moby#39306](https://github.com/moby/moby/pull/39306)\n*   Fix an issue where nodes several tasks could not be removed. [docker/swarmkit#2867](https://github.com/docker/swarmkit/pull/2867)\n\n2019-07-17\n\n### [Runtime](#runtime-1)\n\n*   Masked the secrets updated to the log files when running Docker Engine in debug mode. [CVE-2019-13509](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-13509): If a Docker engine is running in debug mode, and `docker stack deploy` is used to redeploy a stack which includes non-external secrets, the logs will contain the secret.\n\n### [Client](#client-1)\n\n*   Fixed rollback config type interpolation for `parallelism` and `max_failure_ratio` fields.\n\n### [Known Issue](#known-issue)\n\n*   There are important changes to the upgrade process that, if not correctly followed, can have an impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or later.\n\n2019-06-27\n\n### [Builder](#builder)\n\n*   Fixed a panic error when building dockerfiles that contain only comments. [moby/moby#38487](https://github.com/moby/moby/pull/38487)\n*   Added a workaround for GCR authentication issue. [moby/moby#38246](https://github.com/moby/moby/pull/38246)\n*   Builder-next: Fixed a bug in the GCR token cache implementation workaround. [moby/moby#39183](https://github.com/moby/moby/pull/39183)\n\n### [Networking](#networking-1)\n\n*   Fixed an error where `--network-rm` would fail to remove a network. [moby/moby#39174](https://github.com/moby/moby/pull/39174)\n\n### [Runtime](#runtime-2)\n\n*   Added performance optimizations in aufs and layer store that helps in massively parallel container creation and removal. [moby/moby#39107](https://github.com/moby/moby/pull/39107), [moby/moby#39135](https://github.com/moby/moby/pull/39135)\n*   Updated containerd to version 1.2.6. [moby/moby#39016](https://github.com/moby/moby/pull/39016)\n*   Fixed [CVE-2018-15664](https://nvd.nist.gov/vuln/detail/CVE-2018-15664) symlink-exchange attack with directory traversal. [moby/moby#39357](https://github.com/moby/moby/pull/39357)\n*   Windows: fixed support for `docker service create --limit-cpu`. [moby/moby#39190](https://github.com/moby/moby/pull/39190)\n*   daemon: fixed a mirrors validation issue. [moby/moby#38991](https://github.com/moby/moby/pull/38991)\n*   Docker no longer supports sorting UID and GID ranges in ID maps. [moby/moby#39288](https://github.com/moby/moby/pull/39288)\n\n### [Logging](#logging-1)\n\n*   Added a fix that now allows large log lines for logger plugins. [moby/moby#39038](https://github.com/moby/moby/pull/39038)\n\n### [Known Issue](#known-issue-1)\n\n*   There are important changes to the upgrade process that, if not correctly followed, can have an impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or later.\n\n2019-05-06\n\n### [Builder](#builder-1)\n\n*   Fixed `COPY` and `ADD` with multiple `<src>` to not invalidate cache if `DOCKER_BUILDKIT=1`. [moby/moby#38964](https://github.com/moby/moby/issues/38964)\n\n### [Networking](#networking-2)\n\n*   Cleaned up the cluster provider when the agent is closed. [docker/libnetwork#2354](https://github.com/docker/libnetwork/pull/2354)\n*   Windows: Now selects a random host port if the user does not specify a host port. [docker/libnetwork#2369](https://github.com/docker/libnetwork/pull/2369)\n\n### [Known Issues](#known-issues)\n\n*   There are important changes to the upgrade process that, if not correctly followed, can have an impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or later.\n\n2019-04-11\n\n### [Builder](#builder-2)\n\n*   Fixed `DOCKER_BUILDKIT=1 docker build --squash ..` [docker/engine#176](https://github.com/docker/engine/pull/176)\n\n### [Client](#client-2)\n\n*   Fixed tty initial size error. [docker/cli#1775](https://github.com/docker/cli/pull/1775)\n*   Fixed dial-stdio goroutine leakage. [docker/cli#1795](https://github.com/docker/cli/pull/1795)\n*   Fixed the stack informer's selector used to track deployment. [docker/cli#1794](https://github.com/docker/cli/pull/1794)\n\n### [Networking](#networking-3)\n\n*   Fixed `network=host` using wrong `resolv.conf` with `systemd-resolved`. [docker/engine#180](https://github.com/docker/engine/pull/180)\n*   Fixed Windows ARP entries getting corrupted randomly under load. [docker/engine#192](https://github.com/docker/engine/pull/192)\n\n### [Runtime](#runtime-3)\n\n*   Now showing stopped containers with restart policy as `Restarting`. [docker/engine#181](https://github.com/docker/engine/pull/181)\n*   Now using original process spec for execs. [docker/engine#178](https://github.com/docker/engine/pull/178)\n\n### [Swarm Mode](#swarm-mode)\n\n*   Fixed leaking task resources when nodes are deleted. [docker/engine#185](https://github.com/docker/engine/pull/185)\n\n### [Known Issues](#known-issues-1)\n\n*   There are important changes to the upgrade process that, if not correctly followed, can have an impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or later.\n\n2019-03-28\n\n### [Builder](#builder-3)\n\n*   Fixed [CVE-2019-13139](https://nvd.nist.gov/vuln/detail/CVE-2019-13139) by adding validation for `git ref` to avoid misinterpretation as a flag. [moby/moby#38944](https://github.com/moby/moby/pull/38944)\n\n### [Runtime](#runtime-4)\n\n*   Fixed `docker cp` error for filenames greater than 100 characters. [moby/moby#38634](https://github.com/moby/moby/pull/38634)\n*   Fixed `layer/layer_store` to ensure `NewInputTarStream` resources are released. [moby/moby#38413](https://github.com/moby/moby/pull/38413)\n*   Increased GRPC limit for `GetConfigs`. [moby/moby#38800](https://github.com/moby/moby/pull/38800)\n*   Updated `containerd` 1.2.5. [docker/engine#173](https://github.com/docker/engine/pull/173)\n\n### [Swarm Mode](#swarm-mode-1)\n\n*   Fixed nil pointer exception when joining node to swarm. [moby/moby#38618](https://github.com/moby/moby/issues/38618)\n*   Fixed issue for swarm nodes not being able to join as masters if http proxy is set. \\[moby/moby#36951\\]\n\n### [Known Issues](#known-issues-2)\n\n*   There are important changes to the upgrade process that, if not correctly followed, can have impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or later.\n\n2019-02-28\n\n### [Networking fixes](#networking-fixes)\n\n*   Windows: now avoids regeneration of network IDs to prevent broken references to networks. [docker/engine#149](https://github.com/docker/engine/pull/149)\n*   Windows: Fixed an issue to address `- restart always` flag on standalone containers not working when specifying a network. (docker/escalation#1037)\n*   Fixed an issue to address the IPAM state from networkdb if the manager is not attached to the overlay network. (docker/escalation#1049)\n\n### [Runtime fixes and updates](#runtime-fixes-and-updates)\n\n*   Updated to Go version 1.10.8.\n*   Modified names in the container name generator. [docker/engine#159](https://github.com/docker/engine/pull/159)\n*   When copying an existing folder, xattr set errors when the target filesystem doesn't support xattr are now ignored. [docker/engine#135](https://github.com/docker/engine/pull/135)\n*   Graphdriver: fixed \"device\" mode not being detected if \"character-device\" bit is set. [docker/engine#160](https://github.com/docker/engine/pull/160)\n*   Fixed nil pointer derefence on failure to connect to containerd. [docker/engine#162](https://github.com/docker/engine/pull/162)\n*   Deleted stale containerd object on start failure. [docker/engine#154](https://github.com/docker/engine/pull/154)\n\n### [Known Issues](#known-issues-3)\n\n*   There are important changes to the upgrade process that, if not correctly followed, can have impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or greater.\n\n2019-02-11\n\n### [Security fixes](#security-fixes)\n\n*   Update `runc` to address a critical vulnerability that allows specially-crafted containers to gain administrative privileges on the host. [CVE-2019-5736](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-5736)\n*   Ubuntu 14.04 customers using a 3.13 kernel will need to upgrade to a supported Ubuntu 4.x kernel\n\nFor additional information, [refer to the Docker blog post](https://blog.docker.com/2019/02/docker-security-update-cve-2018-5736-and-container-security-best-practices/).\n\n### [Known Issues](#known-issues-4)\n\n*   There are important changes to the upgrade process that, if not correctly followed, can have impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or greater.\n\n2019-01-09\n\n#### [Important notes about this release](#important-notes-about-this-release)\n\nIn Docker versions prior to 18.09, containerd was managed by the Docker engine daemon. In Docker Engine 18.09, containerd is managed by systemd. Since containerd is managed by systemd, any custom configuration to the `docker.service` systemd configuration which changes mount settings (for example, `MountFlags=slave`) breaks interactions between the Docker Engine daemon and containerd, and you will not be able to start containers.\n\nRun the following command to get the current value of the `MountFlags` property for the `docker.service`:\n\nUpdate your configuration if this command prints a non-empty value for `MountFlags`, and restart the docker service.\n\n### [Security fixes](#security-fixes-1)\n\n*   Upgraded Go language to 1.10.6 to resolve [CVE-2018-16873](https://nvd.nist.gov/vuln/detail/CVE-2018-16873), [CVE-2018-16874](https://nvd.nist.gov/vuln/detail/CVE-2018-16874), and [CVE-2018-16875](https://nvd.nist.gov/vuln/detail/CVE-2018-16875).\n*   Fixed authz plugin for 0-length content and path validation.\n*   Added `/proc/asound` to masked paths [docker/engine#126](https://github.com/docker/engine/pull/126)\n\n### [Improvements](#improvements)\n\n*   Updated to BuildKit 0.3.3 [docker/engine#122](https://github.com/docker/engine/pull/122)\n*   Updated to containerd 1.2.2 [docker/engine#144](https://github.com/docker/engine/pull/144)\n*   Provided additional warnings for use of deprecated legacy overlay and devicemapper storage drivers [docker/engine#85](https://github.com/docker/engine/pull/85)\n*   prune: perform image pruning before build cache pruning [docker/cli#1532](https://github.com/docker/cli/pull/1532)\n*   Added bash completion for experimental CLI commands (manifest) [docker/cli#1542](https://github.com/docker/cli/pull/1542)\n*   Windows: allow process isolation on Windows 10 [docker/engine#81](https://github.com/docker/engine/pull/81)\n\n### [Fixes](#fixes)\n\n*   Disable kmem accounting in runc on RHEL/CentOS (docker/escalation#614, docker/escalation#692) [docker/engine#121](https://github.com/docker/engine/pull/121)\n*   Fixed inefficient networking configuration [docker/engine#123](https://github.com/docker/engine/pull/123)\n*   Fixed docker system prune doesn't accept until filter [docker/engine#122](https://github.com/docker/engine/pull/122)\n*   Avoid unset credentials in `containerd` [docker/engine#122](https://github.com/docker/engine/pull/122)\n*   Fixed iptables compatibility on Debian [docker/engine#107](https://github.com/docker/engine/pull/107)\n*   Fixed setting default schema to tcp for docker host [docker/cli#1454](https://github.com/docker/cli/pull/1454)\n*   Fixed bash completion for `service update --force` [docker/cli#1526](https://github.com/docker/cli/pull/1526)\n*   Windows: DetachVhd attempt in cleanup [docker/engine#113](https://github.com/docker/engine/pull/113)\n*   API: properly handle invalid JSON to return a 400 status [docker/engine#110](https://github.com/docker/engine/pull/110)\n*   API: ignore default address-pools on API < 1.39 [docker/engine#118](https://github.com/docker/engine/pull/118)\n*   API: add missing default address pool fields to swagger [docker/engine#119](https://github.com/docker/engine/pull/119)\n*   awslogs: account for UTF-8 normalization in limits [docker/engine#112](https://github.com/docker/engine/pull/112)\n*   Prohibit reading more than 1MB in HTTP error responses [docker/engine#114](https://github.com/docker/engine/pull/114)\n*   apparmor: allow receiving of signals from `docker kill` [docker/engine#116](https://github.com/docker/engine/pull/116)\n*   overlay2: use index=off if possible (fix EBUSY on mount) [docker/engine#84](https://github.com/docker/engine/pull/84)\n\n### [Packaging](#packaging)\n\n*   Add docker.socket requirement for docker.service. [docker/docker-ce-packaging#276](https://github.com/docker/docker-ce-packaging/pull/276)\n*   Add socket activation for RHEL-based distributions. [docker/docker-ce-packaging#274](https://github.com/docker/docker-ce-packaging/pull/274)\n*   Add libseccomp requirement for RPM packages. [docker/docker-ce-packaging#266](https://github.com/docker/docker-ce-packaging/pull/266)\n\n### [Known Issues](#known-issues-5)\n\n*   When upgrading from 18.09.0 to 18.09.1, `containerd` is not upgraded to the correct version on Ubuntu.\n*   There are important changes to the upgrade process that, if not correctly followed, can have impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or greater.\n\n2018-11-08\n\n### [Important notes about this release](#important-notes-about-this-release-1)\n\nIn Docker versions prior to 18.09, containerd was managed by the Docker engine daemon. In Docker Engine 18.09, containerd is managed by systemd. Since containerd is managed by systemd, any custom configuration to the `docker.service` systemd configuration which changes mount settings (for example, `MountFlags=slave`) breaks interactions between the Docker Engine daemon and containerd, and you will not be able to start containers.\n\nRun the following command to get the current value of the `MountFlags` property for the `docker.service`:\n\nUpdate your configuration if this command prints a non-empty value for `MountFlags`, and restart the docker service.\n\n### [New features](#new-features)\n\n*   Updated API version to 1.39 [moby/moby#37640](https://github.com/moby/moby/pull/37640)\n*   Added support for remote connections using SSH [docker/cli#1014](https://github.com/docker/cli/pull/1014)\n*   Builder: added prune options to the API [moby/moby#37651](https://github.com/moby/moby/pull/37651)\n*   Added \"Warnings\" to `/info` endpoint, and move detection to the daemon [moby/moby#37502](https://github.com/moby/moby/pull/37502)\n*   Allows BuildKit builds to run without experimental mode enabled. Buildkit can now be configured with an option in daemon.json [moby/moby#37593](https://github.com/moby/moby/pull/37593) [moby/moby#37686](https://github.com/moby/moby/pull/37686) [moby/moby#37692](https://github.com/moby/moby/pull/37692) [docker/cli#1303](https://github.com/docker/cli/pull/1303) [docker/cli#1275](https://github.com/docker/cli/pull/1275)\n*   Added support for build-time secrets using a `--secret` flag when using BuildKit [docker/cli#1288](https://github.com/docker/cli/pull/1288)\n*   Added SSH agent socket forwarder (`docker build --ssh $SSHMOUNTID=$SSH_AUTH_SOCK`) when using BuildKit [docker/cli#1438](https://github.com/docker/cli/pull/1438) / [docker/cli#1419](https://github.com/docker/cli/pull/1419)\n*   Added `--chown` flag support for `ADD` and `COPY` commands on Windows [moby/moby#35521](https://github.com/moby/moby/pull/35521)\n*   Added `builder prune` subcommand to prune BuildKit build cache [docker/cli#1295](https://github.com/docker/cli/pull/1295) [docker/cli#1334](https://github.com/docker/cli/pull/1334)\n*   BuildKit: Adds configurable garbage collection policy for the BuildKit build cache [docker/engine#59](https://github.com/docker/engine/pull/59) / [moby/moby#37846](https://github.com/moby/moby/pull/37846)\n*   BuildKit: Adds support for `docker build --pull ...` when using BuildKit [moby/moby#37613](https://github.com/moby/moby/pull/37613)\n*   BuildKit: Adds support or \"registry-mirrors\" and \"insecure-registries\" when using BuildKit [docker/engine#59](https://github.com/docker/engine/pull/59) / [moby/moby#37852](https://github.com/moby/moby/pull/37852)\n*   BuildKit: Enables net modes and bridge. [moby/moby#37620](https://github.com/moby/moby/pull/37620)\n*   Added `docker engine` subcommand to manage the lifecycle of a Docker Engine running as a privileged container on top of containerd, and to allow upgrades to Docker Engine Enterprise [docker/cli#1260](https://github.com/docker/cli/pull/1260)\n*   Exposed product license in `docker info` output [docker/cli#1313](https://github.com/docker/cli/pull/1313)\n*   Showed warnings produced by daemon in `docker info` output [docker/cli#1225](https://github.com/docker/cli/pull/1225)\n*   Added \"local\" log driver [moby/moby#37092](https://github.com/moby/moby/pull/37092)\n*   Amazon CloudWatch: adds `awslogs-endpoint` logging option [moby/moby#37374](https://github.com/moby/moby/pull/37374)\n*   Added support for global default address pools [moby/moby#37558](https://github.com/moby/moby/pull/37558) [docker/cli#1233](https://github.com/docker/cli/pull/1233)\n*   Configured containerd log-level to be the same as dockerd [moby/moby#37419](https://github.com/moby/moby/pull/37419)\n*   Added configuration option for cri-containerd [moby/moby#37519](https://github.com/moby/moby/pull/37519)\n*   Updates containerd client to v1.2.0-rc.1 [moby/moby#37664](https://github.com/moby/moby/pull/37664), [docker/engine#75](https://github.com/docker/engine/pull/75) / [moby/moby#37710](https://github.com/moby/moby/pull/37710)\n*   Added support for global default address pools [moby/moby#37558](https://github.com/moby/moby/pull/37558) [docker/cli#1233](https://github.com/docker/cli/pull/1233)\n*   Moved the `POST /session` endpoint out of experimental. [moby/moby#40028](https://github.com/moby/moby/pull/40028)\n\n### [Improvements](#improvements-1)\n\n*   Does not return \"`<unknown>`\" in /info response [moby/moby#37472](https://github.com/moby/moby/pull/37472)\n*   BuildKit: Changes `--console=[auto,false,true]` to `--progress=[auto,plain,tty]` [docker/cli#1276](https://github.com/docker/cli/pull/1276)\n*   BuildKit: Sets BuildKit's ExportedProduct variable to show useful errors in the future. [moby/moby#37439](https://github.com/moby/moby/pull/37439)\n*   Hides `--data-path-addr` flags when connected to a daemon that doesn't support this option [docker/docker/cli#1240](https://github.com/docker/cli/pull/1240)\n*   Only shows buildkit-specific flags if BuildKit is enabled [docker/cli#1438](https://github.com/docker/cli/pull/1438) / [docker/cli#1427](https://github.com/docker/cli/pull/1427)\n*   Improves version output alignment [docker/cli#1204](https://github.com/docker/cli/pull/1204)\n*   Sorts plugin names and networks in a natural order [docker/cli#1166](https://github.com/docker/cli/pull/1166), [docker/cli#1266](https://github.com/docker/cli/pull/1266)\n*   Updates bash and zsh [completion scripts](https://github.com/docker/cli/issues?q=label%3Aarea%2Fcompletion+milestone%3A18.09.0+is%3Aclosed)\n*   Passes log-level to containerd. [moby/moby#37419](https://github.com/moby/moby/pull/37419)\n*   Uses direct server return (DSR) in east-west overlay load balancing [docker/engine#93](https://github.com/docker/engine/pull/93) / [docker/libnetwork#2270](https://github.com/docker/libnetwork/pull/2270)\n*   Builder: temporarily disables bridge networking when using buildkit. [moby/moby#37691](https://github.com/moby/moby/pull/37691)\n*   Blocks task starting until node attachments are ready [moby/moby#37604](https://github.com/moby/moby/pull/37604)\n*   Propagates the provided external CA certificate to the external CA object in swarm. [docker/cli#1178](https://github.com/docker/cli/pull/1178)\n*   Removes Ubuntu 14.04 \"Trusty Tahr\" as a supported platform [docker-ce-packaging#255](https://github.com/docker/docker-ce-packaging/pull/255) / [docker-ce-packaging#254](https://github.com/docker/docker-ce-packaging/pull/254)\n*   Removes Debian 8 \"Jessie\" as a supported platform [docker-ce-packaging#255](https://github.com/docker/docker-ce-packaging/pull/255) / [docker-ce-packaging#254](https://github.com/docker/docker-ce-packaging/pull/254)\n*   Removes 'docker-' prefix for containerd and runc binaries [docker/engine#61](https://github.com/docker/engine/pull/61) / [moby/moby#37907](https://github.com/moby/moby/pull/37907), [docker-ce-packaging#241](https://github.com/docker/docker-ce-packaging/pull/241)\n*   Splits \"engine\", \"cli\", and \"containerd\" to separate packages, and run containerd as a separate systemd service [docker-ce-packaging#131](https://github.com/docker/docker-ce-packaging/pull/131), [docker-ce-packaging#158](https://github.com/docker/docker-ce-packaging/pull/158)\n*   Builds binaries with Go 1.10.4 [docker-ce-packaging#181](https://github.com/docker/docker-ce-packaging/pull/181)\n*   Removes `-ce` suffix from version string [docker-ce-packaging#206](https://github.com/docker/docker-ce-packaging/pull/206)\n\n### [Fixes](#fixes-1)\n\n*   BuildKit: Do not cancel buildkit status request. [moby/moby#37597](https://github.com/moby/moby/pull/37597)\n*   Fixes no error is shown if build args are missing during docker build [moby/moby#37396](https://github.com/moby/moby/pull/37396)\n*   Fixes error \"unexpected EOF\" when adding an 8GB file [moby/moby#37771](https://github.com/moby/moby/pull/37771)\n*   LCOW: Ensures platform is populated on `COPY`/`ADD`. [moby/moby#37563](https://github.com/moby/moby/pull/37563)\n*   Fixes mapping a range of host ports to a single container port [docker/cli#1102](https://github.com/docker/cli/pull/1102)\n*   Fixes `trust inspect` typo: \"`AdminstrativeKeys`\" [docker/cli#1300](https://github.com/docker/cli/pull/1300)\n*   Fixes environment file parsing for imports of absent variables and those with no name. [docker/cli#1019](https://github.com/docker/cli/pull/1019)\n*   Fixes a potential \"out of memory exception\" when running `docker image prune` with a large list of dangling images [docker/cli#1432](https://github.com/docker/cli/pull/1432) / [docker/cli#1423](https://github.com/docker/cli/pull/1423)\n*   Fixes pipe handling in ConEmu and ConsoleZ on Windows [moby/moby#37600](https://github.com/moby/moby/pull/37600)\n*   Fixes long startup on windows, with non-hns governed Hyper-V networks [docker/engine#67](https://github.com/docker/engine/pull/67) / [moby/moby#37774](https://github.com/moby/moby/pull/37774)\n*   Fixes daemon won't start when \"runtimes\" option is defined both in config file and cli [docker/engine#57](https://github.com/docker/engine/pull/57) / [moby/moby#37871](https://github.com/moby/moby/pull/37871)\n*   Loosens permissions on `/etc/docker` directory to prevent \"permission denied\" errors when using `docker manifest inspect` [docker/engine#56](https://github.com/docker/engine/pull/56) / [moby/moby#37847](https://github.com/moby/moby/pull/37847)\n*   Fixes denial of service with large numbers in `cpuset-cpus` and `cpuset-mems` [docker/engine#70](https://github.com/docker/engine/pull/70) / [moby/moby#37967](https://github.com/moby/moby/pull/37967)\n*   LCOW: Add `--platform` to `docker import` [docker/cli#1375](https://github.com/docker/cli/pull/1375) / [docker/cli#1371](https://github.com/docker/cli/pull/1371)\n*   LCOW: Add LinuxMetadata support by default on Windows [moby/moby#37514](https://github.com/moby/moby/pull/37514)\n*   LCOW: Mount to short container paths to avoid command-line length limit [moby/moby#37659](https://github.com/moby/moby/pull/37659)\n*   LCOW: Fix builder using wrong cache layer [moby/moby#37356](https://github.com/moby/moby/pull/37356)\n*   Fixes json-log file descriptors leaking when using `--follow` [docker/engine#48](https://github.com/docker/engine/pull/48) [moby/moby#37576](https://github.com/moby/moby/pull/37576) [moby/moby#37734](https://github.com/moby/moby/pull/37734)\n*   Fixes a possible deadlock on closing the watcher on kqueue [moby/moby#37392](https://github.com/moby/moby/pull/37392)\n*   Uses poller based watcher to work around the file caching issue in Windows [moby/moby#37412](https://github.com/moby/moby/pull/37412)\n*   Handles systemd-resolved case by providing appropriate resolv.conf to networking layer [moby/moby#37485](https://github.com/moby/moby/pull/37485)\n*   Removes support for TLS < 1.2 [moby/moby#37660](https://github.com/moby/moby/pull/37660)\n*   Seccomp: Whitelist syscalls linked to `CAP_SYS_NICE` in default seccomp profile [moby/moby#37242](https://github.com/moby/moby/pull/37242)\n*   Seccomp: move the syslog syscall to be gated by `CAP_SYS_ADMIN` or `CAP_SYSLOG` [docker/engine#64](https://github.com/docker/engine/pull/64) / [moby/moby#37929](https://github.com/moby/moby/pull/37929)\n*   SELinux: Fix relabeling of local volumes specified via Mounts API on selinux-enabled systems [moby/moby#37739](https://github.com/moby/moby/pull/37739)\n*   Adds warning if REST API is accessible through an insecure connection [moby/moby#37684](https://github.com/moby/moby/pull/37684)\n*   Masks proxy credentials from URL when displayed in system info [docker/engine#72](https://github.com/docker/engine/pull/72) / [moby/moby#37934](https://github.com/moby/moby/pull/37934)\n*   Fixes mount propagation for btrfs [docker/engine#86](https://github.com/docker/engine/pull/86) / [moby/moby#38026](https://github.com/moby/moby/pull/38026)\n*   Fixes nil pointer dereference in node allocation [docker/engine#94](https://github.com/docker/engine/pull/94) / [docker/swarmkit#2764](https://github.com/docker/swarmkit/pull/2764)\n\n### [Known Issues](#known-issues-6)\n\n*   There are important changes to the upgrade process that, if not correctly followed, can have impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or greater.\n    \n*   With [https://github.com/boot2docker/boot2docker/releases/download/v18.09.0/boot2docker.iso](https://github.com/boot2docker/boot2docker/releases/download/v18.09.0/boot2docker.iso), connection is being refused from a node on the virtual machine. Any publishing of swarm ports in virtualbox-created docker-machine VM's will not respond. This is occurring on macOS and Windows 10, using docker-machine version 0.15 and 0.16.\n    \n    The following `docker run` command works, allowing access from host browser:\n    \n    `docker run -d -p 4000:80 nginx`\n    \n    However, the following `docker service` command fails, resulting in curl/chrome unable to connect (connection refused):\n    \n    `docker service create -p 5000:80 nginx`\n    \n    This issue is not apparent when provisioning 18.09.0 cloud VM's using docker-machine.\n    \n    Workarounds:\n    \n    *   Use cloud VM's that don't rely on boot2docker.\n    *   `docker run` is unaffected.\n    *   For Swarm, set VIRTUALBOX\\_BOOT2DOCKER\\_URL=https://github.com/boot2docker/boot2docker/releases/download/v18.06.1-ce/boot2docker.iso.\n    \n    This issue is resolved in 18.09.1.\n    \n\n### [Deprecation Notices](#deprecation-notices)\n\n*   Docker has deprecated support for Device Mapper as a storage driver. It will continue to be supported at this time, but support will be removed in a future release.\n    \n    The [Overlay2 storage driver](https://docs.docker.com/storage/storagedriver/overlayfs-driver/) is now the default for Docker engine implementations.\n    \n\nFor more information on the list of deprecated flags and APIs, have a look at the [deprecation information](https://docs.docker.com/engine/deprecated/) where you can find the target removal dates.\n\n### [End of Life Notification](#end-of-life-notification)\n\nIn this release, Docker has also removed support for TLS < 1.2 [moby/moby#37660](https://github.com/moby/moby/pull/37660), Ubuntu 14.04 \"Trusty Tahr\" [docker-ce-packaging#255](https://github.com/docker/docker-ce-packaging/pull/255) / [docker-ce-packaging#254](https://github.com/docker/docker-ce-packaging/pull/254), and Debian 8 \"Jessie\" [docker-ce-packaging#255](https://github.com/docker/docker-ce-packaging/pull/255) / [docker-ce-packaging#254](https://github.com/docker/docker-ce-packaging/pull/254).",
  "title": "Docker Engine 18.09 release notes | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/18.04/",
  "markdown": "# Docker Engine 18.04 release notes\n\n2018-04-10\n\n### [Builder](#builder)\n\n*   Fix typos in builder and client. [moby/moby#36424](https://github.com/moby/moby/pull/36424)\n\n### [Client](#client)\n\n*   Print Stack API and Kubernetes versions in version command. [docker/cli#898](https://github.com/docker/cli/pull/898)\n\n*   Fix Kubernetes duplication in version command. [docker/cli#953](https://github.com/docker/cli/pull/953)\n\n*   Use HasAvailableFlags instead of HasFlags for Options in help. [docker/cli#959](https://github.com/docker/cli/pull/959)\n\n*   Add support for mandatory variables to stack deploy. [docker/cli#893](https://github.com/docker/cli/pull/893)\n\n*   Fix docker stack services command Port output. [docker/cli#943](https://github.com/docker/cli/pull/943)\n\n*   Deprecate unencrypted storage. [docker/cli#561](https://github.com/docker/cli/pull/561)\n*   Don't set a default filename for ConfigFile. [docker/cli#917](https://github.com/docker/cli/pull/917)\n\n*   Fix compose network name. [docker/cli#941](https://github.com/docker/cli/pull/941)\n\n### [Logging](#logging)\n\n*   Silent login: use credentials from cred store to login. [docker/cli#139](https://github.com/docker/cli/pull/139)\n\n*   Add support for compressibility of log file. [moby/moby#29932](https://github.com/moby/moby/pull/29932)\n\n*   Fix empty LogPath with non-blocking logging mode. [moby/moby#36272](https://github.com/moby/moby/pull/36272)\n\n### [Networking](#networking)\n\n*   Prevent explicit removal of ingress network. [moby/moby#36538](https://github.com/moby/moby/pull/36538)\n\n### [Runtime](#runtime)\n\n*   Devmapper cleanup improvements. [moby/moby#36307](https://github.com/moby/moby/pull/36307)\n*   Devmapper.Mounted: remove. [moby/moby#36437](https://github.com/moby/moby/pull/36437)\n*   Devmapper/Remove(): use Rmdir, ignore errors. [moby/moby#36438](https://github.com/moby/moby/pull/36438)\n*   LCOW - Change platform parser directive to FROM statement flag. [moby/moby#35089](https://github.com/moby/moby/pull/35089)\n*   Split daemon service code to windows file. [moby/moby#36653](https://github.com/moby/moby/pull/36653)\n*   Windows: Block pulling uplevel images. [moby/moby#36327](https://github.com/moby/moby/pull/36327)\n*   Windows: Hyper-V containers are broken after 36586 was merged. [moby/moby#36610](https://github.com/moby/moby/pull/36610)\n*   Windows: Move kernel\\_windows to use golang registry functions. [moby/moby#36617](https://github.com/moby/moby/pull/36617)\n*   Windows: Pass back system errors on container exit. [moby/moby#35967](https://github.com/moby/moby/pull/35967)\n*   Windows: Remove servicing mode. [moby/moby#36267](https://github.com/moby/moby/pull/36267)\n*   Windows: Report Version and UBR. [moby/moby#36451](https://github.com/moby/moby/pull/36451)\n*   Bump Runc to 1.0.0-rc5. [moby/moby#36449](https://github.com/moby/moby/pull/36449)\n*   Mount failure indicates the path that failed. [moby/moby#36407](https://github.com/moby/moby/pull/36407)\n*   Change return for errdefs.getImplementer(). [moby/moby#36489](https://github.com/moby/moby/pull/36489)\n*   Client: fix hijackedconn reading from buffer. [moby/moby#36663](https://github.com/moby/moby/pull/36663)\n*   Content encoding negotiation added to archive request. [moby/moby#36164](https://github.com/moby/moby/pull/36164)\n*   Daemon/stats: more resilient cpu sampling. [moby/moby#36519](https://github.com/moby/moby/pull/36519)\n*   Daemon/stats: remove obnoxious types file. [moby/moby#36494](https://github.com/moby/moby/pull/36494)\n*   Daemon: use context error rather than inventing new one. [moby/moby#36670](https://github.com/moby/moby/pull/36670)\n*   Enable CRIU on non-amd64 architectures (v2). [moby/moby#36676](https://github.com/moby/moby/pull/36676)\n\n*   Fixes intermittent client hang after closing stdin to attached container [moby/moby#36517](https://github.com/moby/moby/pull/36517)\n*   Fix daemon panic on container export after restart [moby/moby#36586](https://github.com/moby/moby/pull/36586)\n*   Follow-up fixes on multi-stage moby's Dockerfile. [moby/moby#36425](https://github.com/moby/moby/pull/36425)\n\n*   Freeze busybox and latest glibc in Docker image. [moby/moby#36375](https://github.com/moby/moby/pull/36375)\n*   If container will run as non root user, drop permitted, effective caps early. [moby/moby#36587](https://github.com/moby/moby/pull/36587)\n*   Layer: remove metadata store interface. [moby/moby#36504](https://github.com/moby/moby/pull/36504)\n*   Minor optimizations to dockerd. [moby/moby#36577](https://github.com/moby/moby/pull/36577)\n*   Whitelist statx syscall. [moby/moby#36417](https://github.com/moby/moby/pull/36417)\n\n*   Add missing error return for plugin creation. [moby/moby#36646](https://github.com/moby/moby/pull/36646)\n\n*   Fix AppArmor not being applied to Exec processes. [moby/moby#36466](https://github.com/moby/moby/pull/36466)\n\n*   Daemon/logger/ring.go: log error not instance. [moby/moby#36475](https://github.com/moby/moby/pull/36475)\n\n*   Fix stats collector spinning CPU if no stats are collected. [moby/moby#36609](https://github.com/moby/moby/pull/36609)\n*   Fix(distribution): digest cache should not be moved if it was an auth. [moby/moby#36509](https://github.com/moby/moby/pull/36509)\n*   Make sure plugin container is removed on failure. [moby/moby#36715](https://github.com/moby/moby/pull/36715)\n\n*   Bump to containerd 1.0.3. [moby/moby#36749](https://github.com/moby/moby/pull/36749)\n*   Don't sort plugin mount slice. [moby/moby#36711](https://github.com/moby/moby/pull/36711)\n\n### [Swarm Mode](#swarm-mode)\n\n*   Fixes for synchronizing the dispatcher shutdown with in-progress rpcs. [moby/moby#36371](https://github.com/moby/moby/pull/36371)\n*   Increase raft ElectionTick to 10xHeartbeatTick. [moby/moby#36672](https://github.com/moby/moby/pull/36672)\n*   Make Swarm manager Raft quorum parameters configurable in daemon config. [moby/moby#36726](https://github.com/moby/moby/pull/36726)\n*   Ingress network should not be attachable. [docker/swarmkit#2523](https://github.com/docker/swarmkit/pull/2523)\n*   \\[manager/state\\] Add fernet as an option for raft encryption. [docker/swarmkit#2535](https://github.com/docker/swarmkit/pull/2535)\n*   Log GRPC server errors. [docker/swarmkit#2541](https://github.com/docker/swarmkit/pull/2541)\n*   Log leadership changes at the manager level. [docker/swarmkit#2542](https://github.com/docker/swarmkit/pull/2542)\n*   Remove the containerd executor. [docker/swarmkit#2568](https://github.com/docker/swarmkit/pull/2568)\n*   Agent: backoff session when no remotes are available. [docker/swarmkit#2570](https://github.com/docker/swarmkit/pull/2570)\n*   \\[ca/manager\\] Remove root CA key encryption support entirely. [docker/swarmkit#2573](https://github.com/docker/swarmkit/pull/2573)\n\n*   Fix agent logging race. [docker/swarmkit#2578](https://github.com/docker/swarmkit/pull/2578)\n\n*   Adding logic to restore networks in order. [docker/swarmkit#2571](https://github.com/docker/swarmkit/pull/2571)",
  "title": "Docker Engine 18.04 release notes | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/security/non-events/",
  "markdown": "# Docker security non-events | Docker Docs\n\nThis page lists security vulnerabilities which Docker mitigated, such that processes run in Docker containers were never vulnerable to the bugâ€”even before it was fixed. This assumes containers are run without adding extra capabilities or not run as `--privileged`.\n\nThe list below is not even remotely complete. Rather, it is a sample of the few bugs we've actually noticed to have attracted security review and publicly disclosed vulnerabilities. In all likelihood, the bugs that haven't been reported far outnumber those that have. Luckily, since Docker's approach to secure by default through apparmor, seccomp, and dropping capabilities, it likely mitigates unknown bugs just as well as it does known ones.\n\nBugs mitigated:\n\n*   [CVE-2013-1956](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1956), [1957](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1957), [1958](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1958), [1959](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1959), [1979](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1979), [CVE-2014-4014](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-4014), [5206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-5206), [5207](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-5207), [7970](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-7970), [7975](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-7975), [CVE-2015-2925](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-2925), [8543](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-8543), [CVE-2016-3134](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-3134), [3135](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-3135), etc.: The introduction of unprivileged user namespaces lead to a huge increase in the attack surface available to unprivileged users by giving such users legitimate access to previously root-only system calls like `mount()`. All of these CVEs are examples of security vulnerabilities due to introduction of user namespaces. Docker can use user namespaces to set up containers, but then disallows the process inside the container from creating its own nested namespaces through the default seccomp profile, rendering these vulnerabilities unexploitable.\n*   [CVE-2014-0181](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-0181), [CVE-2015-3339](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-3339): These are bugs that require the presence of a setuid binary. Docker disables setuid binaries inside containers via the `NO_NEW_PRIVS` process flag and other mechanisms.\n*   [CVE-2014-4699](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-4699): A bug in `ptrace()` could allow privilege escalation. Docker disables `ptrace()` inside the container using apparmor, seccomp and by dropping `CAP_PTRACE`. Three times the layers of protection there!\n*   [CVE-2014-9529](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-9529): A series of crafted `keyctl()` calls could cause kernel DoS / memory corruption. Docker disables `keyctl()` inside containers using seccomp.\n*   [CVE-2015-3214](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-3214), [4036](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-4036): These are bugs in common virtualization drivers which could allow a guest OS user to execute code on the host OS. Exploiting them requires access to virtualization devices in the guest. Docker hides direct access to these devices when run without `--privileged`. Interestingly, these seem to be cases where containers are \"more secure\" than a VM, going against common wisdom that VMs are \"more secure\" than containers.\n*   [CVE-2016-0728](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-0728): Use-after-free caused by crafted `keyctl()` calls could lead to privilege escalation. Docker disables `keyctl()` inside containers using the default seccomp profile.\n*   [CVE-2016-2383](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-2383): A bug in eBPF -- the special in-kernel DSL used to express things like seccomp filters -- allowed arbitrary reads of kernel memory. The `bpf()` system call is blocked inside Docker containers using (ironically) seccomp.\n*   [CVE-2016-3134](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-3134), [4997](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-4997), [4998](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-4998): A bug in setsockopt with `IPT_SO_SET_REPLACE`, `ARPT_SO_SET_REPLACE`, and `ARPT_SO_SET_REPLACE` causing memory corruption / local privilege escalation. These arguments are blocked by `CAP_NET_ADMIN`, which Docker does not allow by default.\n\nBugs not mitigated:\n\n*   [CVE-2015-3290](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-3290), [5157](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-5157): Bugs in the kernel's non-maskable interrupt handling allowed privilege escalation. Can be exploited in Docker containers because the `modify_ldt()` system call is not currently blocked using seccomp.\n*   [CVE-2016-5195](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-5195): A race condition was found in the way the Linux kernel's memory subsystem handled the copy-on-write (COW) breakage of private read-only memory mappings, which allowed unprivileged local users to gain write access to read-only memory. Also known as \"dirty COW.\" _Partial mitigations:_ on some operating systems this vulnerability is mitigated by the combination of seccomp filtering of `ptrace` and the fact that `/proc/self/mem` is read-only.",
  "title": "Docker security non-events | Docker Docs\n",
  "description": "Review of security vulnerabilities Docker mitigated",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/scale-service/",
  "markdown": "# Scale the service in the swarm\n\nOnce you have [deployed a service](https://docs.docker.com/engine/swarm/swarm-tutorial/deploy-service/) to a swarm, you are ready to use the Docker CLI to scale the number of containers in the service. Containers running in a service are called tasks.\n\n1.  If you haven't already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n    \n2.  Run the following command to change the desired state of the service running in the swarm:\n    \n    For example:\n    \n3.  Run `docker service ps <SERVICE-ID>` to see the updated task list:\n    \n    You can see that swarm has created 4 new tasks to scale to a total of 5 running instances of Alpine Linux. The tasks are distributed between the three nodes of the swarm. One is running on `manager1`.\n    \n4.  Run `docker ps` to see the containers running on the node where you're connected. The following example shows the tasks running on `manager1`:\n    \n    If you want to see the containers running on other nodes, ssh into those nodes and run the `docker ps` command.\n    \n\nAt this point in the tutorial, you're finished with the `helloworld` service. Next, you'll delete the service",
  "title": "Scale the service in the swarm | Docker Docs\n",
  "description": "Scale the service running in the swarm",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/18.06/",
  "markdown": "# Docker Engine 18.06 release notes\n\n2019-02-19\n\n### [Security fixes for Docker Engine](#security-fixes-for-docker-engine)\n\n*   Change how the `runc` critical vulnerability patch is applied to include the fix in RPM packages. [docker/engine#156](https://github.com/docker/engine/pull/156)\n\n2019-02-11\n\n### [Security fixes for Docker Engine](#security-fixes-for-docker-engine-1)\n\n*   Update `runc` to address a critical vulnerability that allows specially-crafted containers to gain administrative privileges on the host. [CVE-2019-5736](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-5736)\n*   Ubuntu 14.04 customers using a 3.13 kernel will need to upgrade to a supported Ubuntu 4.x kernel\n\n2018-08-21\n\n### [Builder](#builder)\n\n*   Fix no error if build args are missing during docker build. [docker/engine#25](https://github.com/docker/engine/pull/25)\n\n*   Set BuildKit's ExportedProduct variable to show useful errors. [docker/engine#21](https://github.com/docker/engine/pull/21)\n\n### [Client](#client)\n\n*   Various shell completion script updates: [docker/cli#1229](https://github.com/docker/cli/pull/1229), [docker/cli#1268](https://github.com/docker/cli/pull/1268), and [docker/cli#1272](https://github.com/docker/cli/pull/1272)\n\n*   Fix `DOCKER_CONFIG` warning message and fallback search. [docker/cli#1241](https://github.com/docker/cli/pull/1241)\n*   Fix help message flags on `docker stack` commands and sub-commands. [docker/cli#1267](https://github.com/docker/cli/pull/1267)\n\n### [Runtime](#runtime)\n\n*   Disable CRI plugin listening on port 10010 by default. [docker/engine#29](https://github.com/docker/engine/pull/29)\n*   Update containerd to v1.1.2. [docker/engine#33](https://github.com/docker/engine/pull/33)\n\n*   Windows: Do not invoke HCS shutdown if terminate called. [docker/engine#31](https://github.com/docker/engine/pull/31)\n\n*   Windows: Select polling-based watcher for Windows log watcher. [docker/engine#34](https://github.com/docker/engine/pull/34)\n\n### [Swarm Mode](#swarm-mode)\n\n*   Fix the condition used for skipping over running tasks. [docker/swarmkit#2677](https://github.com/docker/swarmkit/pull/2677)\n*   Fix task sorting. [docker/swarmkit#2712](https://github.com/docker/swarmkit/pull/2712)\n\n2018-07-18\n\n### [Important notes about this release](#important-notes-about-this-release)\n\n*   Docker 18.06 CE will be the last release with a 4-month maintenance lifecycle. The planned Docker 18.09 CE release will be supported for 7 months with Docker 19.03 CE being the next release in line. More details about the release process can be found [here](https://docs.docker.com/get-docker/).\n\n### [Builder](#builder-1)\n\n*   Builder: fix layer leak on multi-stage wildcard copy. [moby/moby#37178](https://github.com/moby/moby/pull/37178)\n*   Fix parsing of invalid environment variable substitution . [moby/moby#37134](https://github.com/moby/moby/pull/37134)\n*   Builder: use the arch info from base image. [moby/moby#36816](https://github.com/moby/moby/pull/36816) [moby/moby#37197](https://github.com/moby/moby/pull/37197)\n\n*   New experimental builder backend based on [BuildKit](https://github.com/moby/buildkit). To enable, run daemon in experimental mode and set `DOCKER_BUILDKIT=1` environment variable on the docker CLI. [moby/moby#37151](https://github.com/moby/moby/pull/37151) [docker/cli#1111](https://github.com/docker/cli/pull/1111)\n\n*   Fix handling uppercase targets names in multi-stage builds. [moby/moby#36960](https://github.com/moby/moby/pull/36960)\n\n### [Client](#client-1)\n\n*   Bump spf13/cobra to v0.0.3, pflag to v1.0.1. [moby/moby#37106](https://github.com/moby/moby/pull/37106)\n*   Add support for the new Stack API for Kubernetes v1beta2. [docker/cli#899](https://github.com/docker/cli/pull/899)\n*   K8s: more robust stack error detection on deploy. [docker/cli#948](https://github.com/docker/cli/pull/948)\n*   Support for rollback config in compose 3.7. [docker/cli#409](https://github.com/docker/cli/pull/409)\n*   Update Cobra and pflag, and use built-in --version feature. [docker/cli#1069](https://github.com/docker/cli/pull/1069)\n*   Fix `docker stack deploy --prune` with empty name removing all services. [docker/cli#1088](https://github.com/docker/cli/pull/1088)\n*   \\[Kubernetes\\] stack services filters. [docker/cli#1023](https://github.com/docker/cli/pull/1023)\n\n*   Only show orchestrator flag in root, stack and version commands in help. [docker/cli#1106](https://github.com/docker/cli/pull/1106)\n*   Add an `Extras` field on the compose config types. [docker/cli#1126](https://github.com/docker/cli/pull/1126)\n*   Add options to the compose loader. [docker/cli#1128](https://github.com/docker/cli/pull/1128)\n\n*   Fix always listing nodes in docker stack ps command on Kubernetes. [docker/cli#1093](https://github.com/docker/cli/pull/1093)\n*   Fix output being shown twice on stack rm error message. [docker/cli#1093](https://github.com/docker/cli/pull/1093)\n\n*   Extend client API with custom HTTP requests. [moby/moby#37071](https://github.com/moby/moby/pull/37071)\n*   Changed error message for unreadable files to clarify possibility of a .Dockerignore entry. [docker/cli#1053](https://github.com/docker/cli/pull/1053)\n*   Restrict kubernetes.allNamespaces value to 'enabled' or 'disabled' in configuration file. [docker/cli#1087](https://github.com/docker/cli/pull/1087)\n*   Check errors when initializing the docker client in the help command. [docker/cli#1119](https://github.com/docker/cli/pull/1119)\n*   Better namespace experience with Kubernetes. Fix using namespace defined in ~/.kube/config for stack commands. Add a NAMESPACE column for docker stack ls command. Add a --all-namespaces flag for docker stack ls command. [docker/cli#991](https://github.com/docker/cli/pull/991)\n*   Export Push and Save. [docker/cli#1123](https://github.com/docker/cli/pull/1123)\n*   Export pull as a public function. [docker/cli#1026](https://github.com/docker/cli/pull/1026)\n*   Remove Kubernetes commands from experimental. [docker/cli#1068](https://github.com/docker/cli/pull/1068)\n*   Adding configs/secrets to service inspect pretty. [docker/cli#1006](https://github.com/docker/cli/pull/1006)\n\n*   Fix service filtering by name on Kubernetes. [docker/cli#1101](https://github.com/docker/cli/pull/1101)\n*   Fix component information alignment in `docker version`. [docker/cli#1065](https://github.com/docker/cli/pull/1065)\n*   Fix cpu/memory limits and reservations being reset on service update. [docker/cli#1079](https://github.com/docker/cli/pull/1079)\n\n*   Manifest list: request specific permissions. [docker/cli#1024](https://github.com/docker/cli/pull/1024)\n*   Setting --orchestrator=all also sets --all-namespaces unless specific --namespace are set. [docker/cli#1059](https://github.com/docker/cli/pull/1059)\n\n*   Fix panics when --compress and --stream are used together. [docker/cli#1105](https://github.com/docker/cli/pull/1105)\n\n*   Switch from x/net/context to context. [docker/cli#1038](https://github.com/docker/cli/pull/1038)\n\n*   Add --init option to `docker service create`. [docker/cli#479](https://github.com/docker/cli/pull/479)\n*   Fixed bug displaying garbage output for build command when --stream and --quiet flags combined. [docker/cli#1090](https://github.com/docker/cli/pull/1090)\n*   Add `init` support in 3.7 schema. [docker/cli#1129](https://github.com/docker/cli/pull/1129)\n\n*   Fix docker trust signer removal. [docker/cli#1112](https://github.com/docker/cli/pull/1112)\n*   Fix error message from docker inspect. [docker/cli#1071](https://github.com/docker/cli/pull/1071)\n\n*   Allow `x-*` extension on 3rd level objects. [docker/cli#1097](https://github.com/docker/cli/pull/1097)\n*   An invalid orchestrator now generates an error instead of being silently ignored. [docker/cli#1055](https://github.com/docker/cli/pull/1055)\n*   Added ORCHESTRATOR column to docker stack ls command. [docker/cli#973](https://github.com/docker/cli/pull/973)\n*   Warn when using host-ip for published ports for services. [docker/cli#1017](https://github.com/docker/cli/pull/1017)\n\n*   Added the option to enable experimental cli features through the `DOCKER_CLI_EXPERIMENTAL` environment variable. [docker/cli#1138](https://github.com/docker/cli/pull/1138)\n*   Add exec\\_die to the list of known container events. [docker/cli#1028](https://github.com/docker/cli/pull/1028)\n\n*   \\[K8s\\] Do env-variable expansion on the uninterpreted Config files. [docker/cli#974](https://github.com/docker/cli/pull/974)\n\n*   Print warnings on stderr for each unsupported features while parsing a compose file for deployment on Kubernetes. [docker/cli#903](https://github.com/docker/cli/pull/903)\n*   Added description about pids count. [docker/cli#1045](https://github.com/docker/cli/pull/1045)\n\n*   Warn user of filter when pruning. [docker/cli#1043](https://github.com/docker/cli/pull/1043)\n*   Fix `--rollback-*` options overwriting `--update-*` options. [docker/cli#1052](https://github.com/docker/cli/pull/1052)\n\n*   Update Attach, Build, Commit, Cp, Create subcommand fish completions. [docker/cli#1005](https://github.com/docker/cli/pull/1005)\n\n*   Add bash completion for `dockerd --default-address-pool`. [docker/cli#1173](https://github.com/docker/cli/pull/1173)\n*   Add bash completion for `exec_die` event. [docker/cli#1173](https://github.com/docker/cli/pull/1173)\n\n*   Update docker-credential-helper so `pass` is not called on every docker command. [docker/cli#1184](https://github.com/docker/cli/pull/1184)\n*   Fix for rotating swarm external CA. [docker/cli#1199](https://github.com/docker/cli/pull/1199)\n*   Improve version output alignment. [docker/cli#1207](https://github.com/docker/cli/pull/1207)\n\n*   Add bash completion for `service create|update --init`. [docker/cli#1210](https://github.com/docker/cli/pull/1210)\n\n### [Deprecation](#deprecation)\n\n*   Document reserved namespaces deprecation. [docker/cli#1040](https://github.com/docker/cli/pull/1040)\n\n### [Logging](#logging)\n\n*   Allow awslogs to use non-blocking mode. [moby/moby#36522](https://github.com/moby/moby/pull/36522)\n*   Improve logging of long log lines on fluentd log driver.. [moby/moby#36159](https://github.com/moby/moby/pull/36159)\n*   Re-order CHANGELOG.md to pass `make validate` test. [moby/moby#37047](https://github.com/moby/moby/pull/37047)\n*   Update Events, Exec, Export, History, Images, Import, Inspect, Load, and Login subcommand fish completions. [docker/cli#1061](https://github.com/docker/cli/pull/1061)\n*   Update documentation for RingLogger's ring buffer. [moby/moby#37084](https://github.com/moby/moby/pull/37084)\n\n*   Add metrics for log failures/partials. [moby/moby#37034](https://github.com/moby/moby/pull/37034)\n\n*   Fix logging plugin crash unrecoverable. [moby/moby#37028](https://github.com/moby/moby/pull/37028)\n*   Fix logging test type. [moby/moby#37070](https://github.com/moby/moby/pull/37070)\n*   Fix race conditions in logs API. [moby/moby#37062](https://github.com/moby/moby/pull/37062)\n*   Fix some issues in logfile reader and rotation. [moby/moby#37063](https://github.com/moby/moby/pull/37063)\n\n### [Networking](#networking)\n\n*   Allow user to specify default address pools for docker networks. [moby/moby#36396](https://github.com/moby/moby/pull/36396) [docker/cli#818](https://github.com/docker/cli/pull/818)\n*   Adding logs for ipam state [doccker/libnetwork#2417](https://github.com/docker/libnetwork/pull/2147)\n*   Fix race conditions in the overlay network driver [doccker/libnetwork#2143](https://github.com/docker/libnetwork/pull/2143)\n*   Add wait time into xtables lock warning [doccker/libnetwork#2142](https://github.com/docker/libnetwork/pull/2142)\n*   filter xtables lock warnings when firewalld is active [doccker/libnetwork#2135](https://github.com/docker/libnetwork/pull/2135)\n*   Switch from x/net/context to context [doccker/libnetwork#2140](https://github.com/docker/libnetwork/pull/2140)\n*   Adding a recovery mechanism for a split gossip cluster [doccker/libnetwork#2134](https://github.com/docker/libnetwork/pull/2134)\n*   Running docker inspect on network attachment tasks now returns a full task object. [moby/moby#35246](https://github.com/moby/moby/pull/35246)\n*   Some container/network cleanups. [moby/moby#37033](https://github.com/moby/moby/pull/37033)\n\n*   Fix network inspect for overlay network. [moby/moby#37045](https://github.com/moby/moby/pull/37045)\n\n*   Improve Scalability of the Linux load balancing. [docker/engine#16](https://github.com/docker/engine/pull/16)\n*   Change log level from error to warning. [docker/engine#19](https://github.com/docker/engine/pull/19)\n\n### [Runtime](#runtime-1)\n\n*   Aufs: log why aufs is not supported. [moby/moby#36995](https://github.com/moby/moby/pull/36995)\n*   Hide experimental checkpoint features on Windows. [docker/cli#1094](https://github.com/docker/cli/pull/1094)\n*   Lcow: Allow the client to customize capabilities and device cgroup rules for LCOW containers. [moby/moby#37294](https://github.com/moby/moby/pull/37294)\n*   Changed path given for executable output in windows to actual location of executable output. [moby/moby#37295](https://github.com/moby/moby/pull/37295)\n\n*   Add windows recycle bin test and update hcsshim to v0.6.11. [moby/moby#36994](https://github.com/moby/moby/pull/36994)\n\n*   Allow to add any args when doing a make run. [moby/moby#37190](https://github.com/moby/moby/pull/37190)\n*   Optimize ContainerTop() aka docker top. [moby/moby#37131](https://github.com/moby/moby/pull/37131)\n\n*   Fix compilation on 32bit machines. [moby/moby#37292](https://github.com/moby/moby/pull/37292)\n\n*   Update API version to v1 38. [moby/moby#37141](https://github.com/moby/moby/pull/37141)\n\n*   Fix `docker service update --host-add` does not update existing host entry. [docker/cli#1054](https://github.com/docker/cli/pull/1054)\n*   Fix swagger file type for ExecIds. [moby/moby#36962](https://github.com/moby/moby/pull/36962)\n*   Fix swagger volume type generation. [moby/moby#37060](https://github.com/moby/moby/pull/37060)\n*   Fix wrong assertion in volume/service package. [moby/moby#37211](https://github.com/moby/moby/pull/37211)\n*   Fix daemon panic on restart when a plugin is running. [moby/moby#37234](https://github.com/moby/moby/pull/37234)\n\n*   Construct and add 'LABEL' command from 'label' option to last stage. [moby/moby#37011](https://github.com/moby/moby/pull/37011)\n\n*   Fix race condition between exec start and resize.. [moby/moby#37172](https://github.com/moby/moby/pull/37172)\n\n*   Alternative failure mitigation of `TestExecInteractiveStdinClose`. [moby/moby#37143](https://github.com/moby/moby/pull/37143)\n*   RawAccess allows a set of paths to be not set as masked or readonly. [moby/moby#36644](https://github.com/moby/moby/pull/36644)\n*   Be explicit about github.com prefix being a legacy feature. [moby/moby#37174](https://github.com/moby/moby/pull/37174)\n*   Bump Golang to 1.10.3. [docker/cli#1122](https://github.com/docker/cli/pull/1122)\n*   Close ReadClosers to prevent xz zombies. [moby/moby#34218](https://github.com/moby/moby/pull/34218)\n*   Daemon.ContainerStop(): fix for a negative timeout. [moby/moby#36874](https://github.com/moby/moby/pull/36874)\n*   Daemon.setMounts(): copy slice in place. [moby/moby#36991](https://github.com/moby/moby/pull/36991)\n*   Describe IP field of swagger Port definition. [moby/moby#36971](https://github.com/moby/moby/pull/36971)\n*   Extract volume interaction to a volumes service. [moby/moby#36688](https://github.com/moby/moby/pull/36688)\n*   Fixed markdown formatting in docker image v1, v1.1, and v1.2 spec. [moby/moby#37051](https://github.com/moby/moby/pull/37051)\n*   Improve GetTimestamp parsing. [moby/moby#35402](https://github.com/moby/moby/pull/35402)\n*   Jsonmessage: pass message to aux callback. [moby/moby#37064](https://github.com/moby/moby/pull/37064)\n*   Overlay2: remove unused cdMountFrom() helper function. [moby/moby#37041](https://github.com/moby/moby/pull/37041)\n\n*   Overlay: Fix overlay storage-driver silently ignoring unknown storage-driver options. [moby/moby#37040](https://github.com/moby/moby/pull/37040)\n\n*   Remove some unused contrib items. [moby/moby#36977](https://github.com/moby/moby/pull/36977)\n*   Restartmanager: do not apply restart policy on created containers. [moby/moby#36924](https://github.com/moby/moby/pull/36924)\n*   Set item-type for ExecIDs. [moby/moby#37121](https://github.com/moby/moby/pull/37121)\n*   Use go-systemd const instead of magic string in Linux version of dockerd. [moby/moby#37136](https://github.com/moby/moby/pull/37136)\n*   Use stdlib TLS dialer. [moby/moby#36687](https://github.com/moby/moby/pull/36687)\n*   Warn when an engine label using a reserved namespace (com.docker.\\*, io.docker.\\*, or org.dockerproject.\\*) is configured, as per [Docker object labels](https://docs.docker.com/config/labels-custom-metadata/). [moby/moby#36921](https://github.com/moby/moby/pull/36921)\n\n*   Fix missing plugin name in message. [moby/moby#37052](https://github.com/moby/moby/pull/37052)\n*   Fix link anchors in CONTRIBUTING.md. [moby/moby#37276](https://github.com/moby/moby/pull/37276)\n*   Fix link to Docker Toolbox. [moby/moby#37240](https://github.com/moby/moby/pull/37240)\n*   Fix mis-used skip condition. [moby/moby#37179](https://github.com/moby/moby/pull/37179)\n*   Fix bind mounts not working in some cases. [moby/moby#37031](https://github.com/moby/moby/pull/37031)\n*   Fix fd leak on attach. [moby/moby#37184](https://github.com/moby/moby/pull/37184)\n*   Fix fluentd partial detection. [moby/moby#37029](https://github.com/moby/moby/pull/37029)\n*   Fix incorrect link in version-history.md. [moby/moby#37049](https://github.com/moby/moby/pull/37049)\n\n*   Allow vim to be case insensitive for D in dockerfile. [moby/moby#37235](https://github.com/moby/moby/pull/37235)\n\n*   Add `t.Name()` to tests so that service names are unique. [moby/moby#37166](https://github.com/moby/moby/pull/37166)\n*   Add additional message when backendfs is extfs without d\\_type support. [moby/moby#37022](https://github.com/moby/moby/pull/37022)\n*   Add api version checking for tests from new feature. [moby/moby#37169](https://github.com/moby/moby/pull/37169)\n*   Add image metrics for push and pull. [moby/moby#37233](https://github.com/moby/moby/pull/37233)\n*   Add support for `init` on services. [moby/moby#37183](https://github.com/moby/moby/pull/37183)\n*   Add verification of escapeKeys array length in pkg/term/proxy.go. [moby/moby#36918](https://github.com/moby/moby/pull/36918)\n\n*   When link id is empty for overlay2, do not remove this link.. [moby/moby#36161](https://github.com/moby/moby/pull/36161)\n\n*   Fix build on OpenBSD by defining Self(). [moby/moby#37301](https://github.com/moby/moby/pull/37301)\n*   Windows: Fix named pipe support for hyper-v isolated containers. [docker/engine#2](https://github.com/docker/engine/pull/2) [docker/cli#1165](https://github.com/docker/cli/pull/1165)\n*   Fix manifest lists to always use correct size. [docker/cli#1183](https://github.com/docker/cli/pull/1183)\n\n*   Register OCI media types. [docker/engine#4](https://github.com/docker/engine/pull/4)\n*   Update containerd to v1.1.1 [docker/engine#17](https://github.com/docker/engine/pull/17)\n*   LCOW: Prefer Windows over Linux in a manifest list. [docker/engine#3](https://github.com/docker/engine/pull/3)\n*   Add updated `MaskPaths` that are used in code paths directly using containerd to address [CVE-2018-10892](https://cve.mitre.org/cgi-bin/cvename.cgi?name=2018-10892). [docker/engine#15](https://github.com/docker/engine/pull/15)\n*   Add `/proc/acpi` to masked paths to address [CVE-2018-10892](https://cve.mitre.org/cgi-bin/cvename.cgi?name=2018-10892). [docker/engine#14](https://github.com/docker/engine/pull/14)\n\n*   Fix bindmount autocreate race. [docker/engine#11](https://github.com/docker/engine/pull/11)\n\n### [Swarm Mode](#swarm-mode-1)\n\n*   List stacks for both Swarm and Kubernetes with --orchestrator=all in docker stack ls. Allow several occurrences of --namespace for Kubernetes with docker stack ls. [docker/cli#1031](https://github.com/docker/cli/pull/1031)\n*   Bump SwarmKit to remove deprecated grpc metadata wrappers. [moby/moby#36905](https://github.com/moby/moby/pull/36905)\n*   Issue an error for --orchestrator=all when working on mismatched Swarm and Kubernetes hosts. [docker/cli#1035](https://github.com/docker/cli/pull/1035)\n\n*   Fix broken swarm commands with Kubernetes defined as orchestrator. \"--orchestrator\" flag is no longer global but local to stack commands and subcommands [docker/cli#1137](https://github.com/docker/cli/pull/1137) [docker/cli#1139](https://github.com/docker/cli/pull/1139)\n\n*   Bump swarmkit to include task reaper fixes and more metrics. [docker/engine#13](https://github.com/docker/engine/pull/13)\n\n*   Avoid a leak when a service with unassigned tasks is deleted. [docker/engine#27](https://github.com/docker/engine/pull/27)\n*   Fix racy batching on the dispatcher. [docker/engine#27](https://github.com/docker/engine/pull/27)",
  "title": "Docker Engine 18.06 release notes | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/18.03/",
  "markdown": "# Docker Engine 18.03 release notes\n\n2018-04-26\n\n### [Client](#client)\n\n*   Fix error with merge compose file with networks [docker/cli#983](https://github.com/docker/cli/pull/983)\n\n*   Fix docker stack deploy re-deploying services after the service was updated with `--force` [docker/cli#963](https://github.com/docker/cli/pull/963)\n*   Fix docker version output alignment [docker/cli#965](https://github.com/docker/cli/pull/965)\n\n### [Runtime](#runtime)\n\n*   Fix AppArmor profiles not being applied to `docker exec` processes [moby/moby#36466](https://github.com/moby/moby/pull/36466)\n*   Don't sort plugin mount slice [moby/moby#36711](https://github.com/moby/moby/pull/36711)\n*   Daemon/cluster: handle partial attachment entries during configure [moby/moby#36769](https://github.com/moby/moby/pull/36769)\n\n*   Bump Golang to 1.9.5 [moby/moby#36779](https://github.com/moby/moby/pull/36779) [docker/cli#986](https://github.com/docker/cli/pull/986)\n\n*   Daemon/stats: more resilient cpu sampling [moby/moby#36519](https://github.com/moby/moby/pull/36519)\n\n*   Containerd: update to 1.0.3 release [moby/moby#36749](https://github.com/moby/moby/pull/36749)\n\n*   Fix Windows layer leak when write fails [moby/moby#36728](https://github.com/moby/moby/pull/36728)\n\n*   Don't make container mount unbindable [moby/moby#36768](https://github.com/moby/moby/pull/36768)\n\n*   Fix Daemon panics on container export after a daemon restart [moby/moby/36586](https://github.com/moby/moby/pull/36586)\n*   Fix digest cache being removed on autherrors [moby/moby#36509](https://github.com/moby/moby/pull/36509)\n*   Make sure plugin container is removed on failure [moby/moby#36715](https://github.com/moby/moby/pull/36715)\n*   Copy: avoid using all system memory with authz plugins [moby/moby#36595](https://github.com/moby/moby/pull/36595)\n*   Relax some libcontainerd client locking [moby/moby#36848](https://github.com/moby/moby/pull/36848)\n*   Update `hcsshim` to v0.6.10 to address [CVE-2018-8115](https://portal.msrc.microsoft.com/en-us/security-guidance/advisory/CVE-2018-8115)\n\n### [Swarm Mode](#swarm-mode)\n\n*   Increase raft Election tick to 10 times Heartbeat tick [moby/moby#36672](https://github.com/moby/moby/pull/36672)\n\n### [Networking](#networking)\n\n*   Gracefully remove LB endpoints from services [docker/libnetwork#2112](https://github.com/docker/libnetwork/pull/2112)\n*   Retry other external DNS servers on ServFail [docker/libnetwork#2121](https://github.com/docker/libnetwork/pull/2121)\n*   Improve scalabiltiy of bridge network isolation rules [docker/libnetwork#2117](https://github.com/docker/libnetwork/pull/2117)\n*   Allow for larger preset property values, do not override [docker/libnetwork#2124](https://github.com/docker/libnetwork/pull/2124)\n*   Prevent panics on concurrent reads/writes when calling `changeNodeState` [docker/libnetwork#2136](https://github.com/docker/libnetwork/pull/2136)\n\n2018-03-21\n\n### [Builder](#builder)\n\n*   Switch to -buildmode=pie [moby/moby#34369](https://github.com/moby/moby/pull/34369)\n*   Allow Dockerfile to be outside of build-context [docker/cli#886](https://github.com/docker/cli/pull/886)\n*   Builder: fix wrong cache hits building from tars [moby/moby#36329](https://github.com/moby/moby/pull/36329)\n\n*   Fixes files leaking to other images in a multi-stage build [moby/moby#36338](https://github.com/moby/moby/pull/36338)\n\n### [Client](#client-1)\n\n*   Simplify the marshaling of compose types.Config [docker/cli#895](https://github.com/docker/cli/pull/895)\n\n*   Add support for multiple composefile when deploying [docker/cli#569](https://github.com/docker/cli/pull/569)\n\n*   Fix broken Kubernetes stack flags [docker/cli#831](https://github.com/docker/cli/pull/831)\n*   Fix stack marshaling for Kubernetes [docker/cli#890](https://github.com/docker/cli/pull/890)\n*   Fix and simplify bash completion for service env, mounts and labels [docker/cli#682](https://github.com/docker/cli/pull/682)\n*   Fix `before` and `since` filter for `docker ps` [moby/moby#35938](https://github.com/moby/moby/pull/35938)\n*   Fix `--label-file` weird behavior [docker/cli#838](https://github.com/docker/cli/pull/838)\n*   Fix compilation of defaultCredentialStore() on unsupported platforms [docker/cli#872](https://github.com/docker/cli/pull/872)\n\n*   Improve and fix bash completion for images [docker/cli#717](https://github.com/docker/cli/pull/717)\n\n*   Added check for empty source in bind mount [docker/cli#824](https://github.com/docker/cli/pull/824)\n\n*   Fix TLS from environment variables in client [moby/moby#36270](https://github.com/moby/moby/pull/36270)\n\n*   docker build now runs faster when registry-specific credential helper(s) are configured [docker/cli#840](https://github.com/docker/cli/pull/840)\n*   Update event filter zsh completion with `disable`, `enable`, `install` and `remove` [docker/cli#372](https://github.com/docker/cli/pull/372)\n*   Produce errors when empty ids are passed into inspect calls [moby/moby#36144](https://github.com/moby/moby/pull/36144)\n*   Marshall version for the k8s controller [docker/cli#891](https://github.com/docker/cli/pull/891)\n*   Set a non-zero timeout for HTTP client communication with plugin backend [docker/cli#883](https://github.com/docker/cli/pull/883)\n\n*   Add DOCKER\\_TLS environment variable for --tls option [docker/cli#863](https://github.com/docker/cli/pull/863)\n*   Add --template-driver option for secrets/configs [docker/cli#896](https://github.com/docker/cli/pull/896)\n*   Move `docker trust` commands out of experimental [docker/cli#934](https://github.com/docker/cli/pull/934) [docker/cli#935](https://github.com/docker/cli/pull/935) [docker/cli#944](https://github.com/docker/cli/pull/944)\n\n### [Logging](#logging)\n\n*   AWS logs - don't add new lines to maximum sized events [moby/moby#36078](https://github.com/moby/moby/pull/36078)\n*   Move log validator logic after plugins are loaded [moby/moby#36306](https://github.com/moby/moby/pull/36306)\n*   Support a proxy in Splunk log driver [moby/moby#36220](https://github.com/moby/moby/pull/36220)\n\n*   Fix log tail with empty logs [moby/moby#36305](https://github.com/moby/moby/pull/36305)\n\n### [Networking](#networking-1)\n\n*   Libnetwork revendoring [moby/moby#36137](https://github.com/moby/moby/pull/36137)\n\n*   Fix for deadlock on exit with Memberlist revendor [docker/libnetwork#2040](https://github.com/docker/libnetwork/pull/2040)\n\n*   Fix user specified ndots option [docker/libnetwork#2065](https://github.com/docker/libnetwork/pull/2065)\n\n*   Fix to use ContainerID for Windows instead of SandboxID [docker/libnetwork#2010](https://github.com/docker/libnetwork/pull/2010)\n\n*   Verify NetworkingConfig to make sure EndpointSettings is not nil [moby/moby#36077](https://github.com/moby/moby/pull/36077)\n\n*   Fix `DockerNetworkInternalMode` issue [moby/moby#36298](https://github.com/moby/moby/pull/36298)\n*   Fix race in attachable network attachment [moby/moby#36191](https://github.com/moby/moby/pull/36191)\n*   Fix timeout issue of `InspectNetwork` on AArch64 [moby/moby#36257](https://github.com/moby/moby/pull/36257)\n\n*   Verbose info is missing for partial overlay ID [moby/moby#35989](https://github.com/moby/moby/pull/35989)\n*   Update `FindNetwork` to address network name duplications [moby/moby#30897](https://github.com/moby/moby/pull/30897)\n*   Disallow attaching ingress network [docker/swarmkit#2523](https://github.com/docker/swarmkit/pull/2523)\n\n*   Prevent implicit removal of the ingress network [moby/moby#36538](https://github.com/moby/moby/pull/36538)\n*   Fix stale HNS endpoints on Windows [moby/moby#36603](https://github.com/moby/moby/pull/36603)\n*   IPAM fixes for duplicate IP addresses [docker/libnetwork#2104](https://github.com/docker/libnetwork/pull/2104) [docker/libnetwork#2105](https://github.com/docker/libnetwork/pull/2105)\n\n### [Runtime](#runtime-1)\n\n*   Enable HotAdd for Windows [moby/moby#35414](https://github.com/moby/moby/pull/35414)\n*   LCOW: Graphdriver fix deadlock in hotRemoveVHDs [moby/moby#36114](https://github.com/moby/moby/pull/36114)\n*   LCOW: Regular mount if only one layer [moby/moby#36052](https://github.com/moby/moby/pull/36052)\n*   Remove interim env var LCOW\\_API\\_PLATFORM\\_IF\\_OMITTED [moby/moby#36269](https://github.com/moby/moby/pull/36269)\n*   Revendor Microsoft/opengcs @ v0.3.6 [moby/moby#36108](https://github.com/moby/moby/pull/36108)\n\n*   Fix issue of ExitCode and PID not show up in Task.Status.ContainerStatus [moby/moby#36150](https://github.com/moby/moby/pull/36150)\n*   Fix issue with plugin scanner going too deep [moby/moby#36119](https://github.com/moby/moby/pull/36119)\n\n*   Do not make graphdriver homes private mounts [moby/moby#36047](https://github.com/moby/moby/pull/36047)\n*   Do not recursive unmount on cleanup of zfs/btrfs [moby/moby#36237](https://github.com/moby/moby/pull/36237)\n*   Don't restore image if layer does not exist [moby/moby#36304](https://github.com/moby/moby/pull/36304)\n*   Adjust minimum API version for templated configs/secrets [moby/moby#36366](https://github.com/moby/moby/pull/36366)\n*   Bump containerd to 1.0.2 (cfd04396dc68220d1cecbe686a6cc3aa5ce3667c) [moby/moby#36308](https://github.com/moby/moby/pull/36308)\n*   Bump Golang to 1.9.4 [moby/moby#36243](https://github.com/moby/moby/pull/36243)\n*   Ensure daemon root is unmounted on shutdown [moby/moby#36107](https://github.com/moby/moby/pull/36107)\n*   Update runc to 6c55f98695e902427906eed2c799e566e3d3dfb5 [moby/moby#36222](https://github.com/moby/moby/pull/36222)\n\n*   Fix container cleanup on daemon restart [moby/moby#36249](https://github.com/moby/moby/pull/36249)\n\n*   Support SCTP port mapping (bump up API to v1.37) [moby/moby#33922](https://github.com/moby/moby/pull/33922)\n*   Support SCTP port mapping [docker/cli#278](https://github.com/docker/cli/pull/278)\n\n*   Fix Volumes property definition in ContainerConfig [moby/moby#35946](https://github.com/moby/moby/pull/35946)\n\n*   Bump moby and dependencies [docker/cli#829](https://github.com/docker/cli/pull/829)\n*   C.RWLayer: check for nil before use [moby/moby#36242](https://github.com/moby/moby/pull/36242)\n\n*   Add `REMOVE` and `ORPHANED` to TaskState [moby/moby#36146](https://github.com/moby/moby/pull/36146)\n\n*   Fixed error detection using `IsErrNotFound` and `IsErrNotImplemented` for `ContainerStatPath`, `CopyFromContainer`, and `CopyToContainer` methods [moby/moby#35979](https://github.com/moby/moby/pull/35979)\n\n*   Add an integration/internal/container helper package [moby/moby#36266](https://github.com/moby/moby/pull/36266)\n*   Add canonical import path [moby/moby#36194](https://github.com/moby/moby/pull/36194)\n*   Add/use container.Exec() to integration [moby/moby#36326](https://github.com/moby/moby/pull/36326)\n\n*   Fix \"--node-generic-resource\" singular/plural [moby/moby#36125](https://github.com/moby/moby/pull/36125)\n\n*   Daemon.cleanupContainer: nullify container RWLayer upon release [moby/moby#36160](https://github.com/moby/moby/pull/36160)\n*   Daemon: passdown the `--oom-kill-disable` option to containerd [moby/moby#36201](https://github.com/moby/moby/pull/36201)\n*   Display a warn message when there is binding ports and net mode is host [moby/moby#35510](https://github.com/moby/moby/pull/35510)\n*   Refresh containerd remotes on containerd restarted [moby/moby#36173](https://github.com/moby/moby/pull/36173)\n*   Set daemon root to use shared propagation [moby/moby#36096](https://github.com/moby/moby/pull/36096)\n*   Optimizations for recursive unmount [moby/moby#34379](https://github.com/moby/moby/pull/34379)\n*   Perform plugin mounts in the runtime [moby/moby#35829](https://github.com/moby/moby/pull/35829)\n*   Graphdriver: Fix RefCounter memory leak [moby/moby#36256](https://github.com/moby/moby/pull/36256)\n*   Use continuity fs package for volume copy [moby/moby#36290](https://github.com/moby/moby/pull/36290)\n*   Use proc/exe for reexec [moby/moby#36124](https://github.com/moby/moby/pull/36124)\n\n*   Add API support for templated secrets and configs [moby/moby#33702](https://github.com/moby/moby/pull/33702) and [moby/moby#36366](https://github.com/moby/moby/pull/36366)\n\n*   Use rslave propagation for mounts from daemon root [moby/moby#36055](https://github.com/moby/moby/pull/36055)\n\n*   Add /proc/keys to masked paths [moby/moby#36368](https://github.com/moby/moby/pull/36368)\n\n*   Bump Runc to 1.0.0-rc5 [moby/moby#36449](https://github.com/moby/moby/pull/36449)\n\n*   Fixes `runc exec` on big-endian architectures [moby/moby#36449](https://github.com/moby/moby/pull/36449)\n\n*   Use chroot when mount namespaces aren't provided [moby/moby#36449](https://github.com/moby/moby/pull/36449)\n\n*   Fix systemd slice expansion so that it could be consumed by cAdvisor [moby/moby#36449](https://github.com/moby/moby/pull/36449)\n*   Fix devices mounted with wrong uid/gid [moby/moby#36449](https://github.com/moby/moby/pull/36449)\n*   Fix read-only containers with IPC private mounts `/dev/shm` read-only [moby/moby#36526](https://github.com/moby/moby/pull/36526)\n\n### [Swarm Mode](#swarm-mode-1)\n\n*   Replace EC Private Key with PKCS#8 PEMs [docker/swarmkit#2246](https://github.com/docker/swarmkit/pull/2246)\n*   Fix IP overlap with empty EndpointSpec [docker/swarmkit #2505](https://github.com/docker/swarmkit/pull/2505)\n*   Add support for Support SCTP port mapping [docker/swarmkit#2298](https://github.com/docker/swarmkit/pull/2298)\n*   Do not reschedule tasks if only placement constraints change and are satisfied by the assigned node [docker/swarmkit#2496](https://github.com/docker/swarmkit/pull/2496)\n*   Ensure task reaper stopChan is closed no more than once [docker/swarmkit #2491](https://github.com/docker/swarmkit/pull/2491)\n*   Synchronization fixes [docker/swarmkit#2495](https://github.com/docker/swarmkit/pull/2495)\n*   Add log message to indicate message send retry if streaming unimplemented [docker/swarmkit#2483](https://github.com/docker/swarmkit/pull/2483)\n*   Debug logs for session, node events on dispatcher, heartbeats [docker/swarmkit#2486](https://github.com/docker/swarmkit/pull/2486)\n\n*   Add swarm types to bash completion event type filter [docker/cli#888](https://github.com/docker/cli/pull/888)\n\n*   Fix issue where network inspect does not show Created time for networks in swarm scope [moby/moby#36095](https://github.com/moby/moby/pull/36095)",
  "title": "Docker Engine 18.03 release notes | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/exporters/local-tar/",
  "markdown": "# Local and tar exporters | Docker Docs\n\nThe `local` and `tar` exporters output the root filesystem of the build result into a local directory. They're useful for producing artifacts that aren't container images.\n\n*   `local` exports files and directories.\n*   `tar` exports the same, but bundles the export into a tarball.\n\nBuild a container image using the `local` exporter:\n\nThe following table describes the available parameters:\n\n| Parameter | Type | Default | Description |\n| --- | --- | --- | --- |\n| `dest` | String |     | Path to copy files to |\n\nFor more information on the `local` or `tar` exporters, see the [BuildKit README](https://github.com/moby/buildkit/blob/master/README.md#local-directory).",
  "title": "Local and tar exporters | Docker Docs\n",
  "description": "The local and tar exporters save the build result to the local filesystem ",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/delete-service/",
  "markdown": "# Delete the service running on the swarm\n\nThe remaining steps in the tutorial don't use the `helloworld` service, so now you can delete the service from the swarm.\n\n1.  If you haven't already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n    \n2.  Run `docker service rm helloworld` to remove the `helloworld` service.\n    \n3.  Run `docker service inspect <SERVICE-ID>` to verify that the swarm manager removed the service. The CLI returns a message that the service is not found:\n    \n4.  Even though the service no longer exists, the task containers take a few seconds to clean up. You can use `docker ps` on the nodes to verify when the tasks have been removed.\n    \n\nNext, you'll set up a new service and apply a rolling update.",
  "title": "Delete the service running on the swarm | Docker Docs\n",
  "description": "Remove the service from the swarm",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/security/rootless/",
  "markdown": "# Run the Docker daemon as a non-root user (Rootless mode)\n\nRootless mode allows running the Docker daemon and containers as a non-root user to mitigate potential vulnerabilities in the daemon and the container runtime.\n\nRootless mode does not require root privileges even during the installation of the Docker daemon, as long as the [prerequisites](#prerequisites) are met.\n\nRootless mode executes the Docker daemon and containers inside a user namespace. This is very similar to [`userns-remap` mode](https://docs.docker.com/engine/security/userns-remap/), except that with `userns-remap` mode, the daemon itself is running with root privileges, whereas in rootless mode, both the daemon and the container are running without root privileges.\n\nRootless mode does not use binaries with `SETUID` bits or file capabilities, except `newuidmap` and `newgidmap`, which are needed to allow multiple UIDs/GIDs to be used in the user namespace.\n\n*   You must install `newuidmap` and `newgidmap` on the host. These commands are provided by the `uidmap` package on most distros.\n    \n*   `/etc/subuid` and `/etc/subgid` should contain at least 65,536 subordinate UIDs/GIDs for the user. In the following example, the user `testuser` has 65,536 subordinate UIDs/GIDs (231072-296607).\n    \n\n### [Distribution-specific hint](#distribution-specific-hint)\n\n> **Tip**\n> \n> We recommend that you use the Ubuntu kernel.\n\n* * *\n\n*   Install `dbus-user-session` package if not installed. Run `sudo apt-get install -y dbus-user-session` and relogin.\n    \n*   Install `uidmap` package if not installed. Run `sudo apt-get install -y uidmap`.\n    \n*   If running in a terminal where the user was not directly logged into, you will need to install `systemd-container` with `sudo apt-get install -y systemd-container`, then switch to TheUser with the command `sudo machinectl shell TheUser@`.\n    \n*   `overlay2` storage driver is enabled by default ( [Ubuntu-specific kernel patch](https://kernel.ubuntu.com/git/ubuntu/ubuntu-bionic.git/commit/fs/overlayfs?id=3b7da90f28fe1ed4b79ef2d994c81efbc58f1144)).\n    \n*   Ubuntu 24.04 and later enables restricted unprivileged user namespaces by default, which prevents unprivileged processes in creating user namespaces unless an AppArmor profile is configured to allow programs to use unprivileged user namespaces.\n    \n    If you install `docker-ce-rootless-extras` using the deb package (`apt-get install docker-ce-rootless-extras`), then the AppArmor profile for `rootlesskit` is already bundled with the `apparmor` deb package. With this installation method, you don't need to add any manual the AppArmor configuration. If you install the rootless extras using the [installation script](https://get.docker.com/rootless), however, you must add an AppArmor profile for `rootlesskit` manually:\n    \n    1.  Create and install the currently logged-in user's AppArmor profile:\n        \n    2.  Restart AppArmor.\n        \n\n*   Install `dbus-user-session` package if not installed. Run `sudo apt-get install -y dbus-user-session` and relogin.\n    \n*   For Debian 10, add `kernel.unprivileged_userns_clone=1` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system`. This step is not required on Debian 11.\n    \n*   Installing `fuse-overlayfs` is recommended. Run `sudo apt-get install -y fuse-overlayfs`. Using `overlay2` storage driver with Debian-specific modprobe option `sudo modprobe overlay permit_mounts_in_userns=1` is also possible, however, highly discouraged due to [instability](https://github.com/moby/moby/issues/42302).\n    \n*   Rootless docker requires version of `slirp4netns` greater than `v0.4.0` (when `vpnkit` is not installed). Check you have this with\n    \n    If you do not have this download and install with `sudo apt-get install -y slirp4netns` or download the latest [release](https://github.com/rootless-containers/slirp4netns/releases).\n    \n\n*   Installing `fuse-overlayfs` is recommended. Run `sudo pacman -S fuse-overlayfs`.\n    \n*   Add `kernel.unprivileged_userns_clone=1` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system`\n    \n\n*   Installing `fuse-overlayfs` is recommended. Run `sudo zypper install -y fuse-overlayfs`.\n    \n*   `sudo modprobe ip_tables iptable_mangle iptable_nat iptable_filter` is required. This might be required on other distros as well depending on the configuration.\n    \n*   Known to work on openSUSE 15 and SLES 15.\n    \n\n*   Installing `fuse-overlayfs` is recommended. Run `sudo dnf install -y fuse-overlayfs`.\n    \n*   You might need `sudo dnf install -y iptables`.\n    \n\n* * *\n\n*   Only the following storage drivers are supported:\n    *   `overlay2` (only if running with kernel 5.11 or later, or Ubuntu-flavored kernel)\n    *   `fuse-overlayfs` (only if running with kernel 4.18 or later, and `fuse-overlayfs` is installed)\n    *   `btrfs` (only if running with kernel 4.18 or later, or `~/.local/share/docker` is mounted with `user_subvol_rm_allowed` mount option)\n    *   `vfs`\n*   Cgroup is supported only when running with cgroup v2 and systemd. See [Limiting resources](#limiting-resources).\n*   Following features are not supported:\n    *   AppArmor\n    *   Checkpoint\n    *   Overlay network\n    *   Exposing SCTP ports\n*   To use the `ping` command, see [Routing ping packets](#routing-ping-packets).\n*   To expose privileged TCP/UDP ports (< 1024), see [Exposing privileged ports](#exposing-privileged-ports).\n*   `IPAddress` shown in `docker inspect` is namespaced inside RootlessKit's network namespace. This means the IP address is not reachable from the host without `nsenter`\\-ing into the network namespace.\n*   Host network (`docker run --net=host`) is also namespaced inside RootlessKit.\n*   NFS mounts as the docker \"data-root\" is not supported. This limitation is not specific to rootless mode.\n\n> **Note**\n> \n> If the system-wide Docker daemon is already running, consider disabling it:\n> \n> Should you choose not to shut down the `docker` service and socket, you will need to use the `--force` parameter in the next section. There are no known issues, but until you shutdown and disable you're still running rootful Docker.\n\n* * *\n\nIf you installed Docker 20.10 or later with [RPM/DEB packages](https://docs.docker.com/engine/install), you should have `dockerd-rootless-setuptool.sh` in `/usr/bin`.\n\nRun `dockerd-rootless-setuptool.sh install` as a non-root user to set up the daemon:\n\nIf `dockerd-rootless-setuptool.sh` is not present, you may need to install the `docker-ce-rootless-extras` package manually, e.g.,\n\nIf you do not have permission to run package managers like `apt-get` and `dnf`, consider using the installation script available at [https://get.docker.com/rootless](https://get.docker.com/rootless). Since static packages are not available for `s390x`, hence it is not supported for `s390x`.\n\nThe binaries will be installed at `~/bin`.\n\n* * *\n\nSee [Troubleshooting](#troubleshooting) if you faced an error.\n\nTo remove the systemd service of the Docker daemon, run `dockerd-rootless-setuptool.sh uninstall`:\n\nUnset environment variables PATH and DOCKER\\_HOST if you have added them to `~/.bashrc`.\n\nTo remove the data directory, run `rootlesskit rm -rf ~/.local/share/docker`.\n\nTo remove the binaries, remove `docker-ce-rootless-extras` package if you installed Docker with package managers. If you installed Docker with [https://get.docker.com/rootless](https://get.docker.com/rootless) ( [Install without packages](#install)), remove the binary files under `~/bin`:\n\n### [Daemon](#daemon)\n\n* * *\n\nThe systemd unit file is installed as `~/.config/systemd/user/docker.service`.\n\nUse `systemctl --user` to manage the lifecycle of the daemon:\n\nTo launch the daemon on system startup, enable the systemd service and lingering:\n\nStarting Rootless Docker as a systemd-wide service (`/etc/systemd/system/docker.service`) is not supported, even with the `User=` directive.\n\nTo run the daemon directly without systemd, you need to run `dockerd-rootless.sh` instead of `dockerd`.\n\nThe following environment variables must be set:\n\n*   `$HOME`: the home directory\n*   `$XDG_RUNTIME_DIR`: an ephemeral directory that is only accessible by the expected user, e,g, `~/.docker/run`. The directory should be removed on every host shutdown. The directory can be on tmpfs, however, should not be under `/tmp`. Locating this directory under `/tmp` might be vulnerable to TOCTOU attack.\n\n* * *\n\nRemarks about directory paths:\n\n*   The socket path is set to `$XDG_RUNTIME_DIR/docker.sock` by default. `$XDG_RUNTIME_DIR` is typically set to `/run/user/$UID`.\n*   The data dir is set to `~/.local/share/docker` by default. The data dir should not be on NFS.\n*   The daemon config dir is set to `~/.config/docker` by default. This directory is different from `~/.docker` that is used by the client.\n\n### [Client](#client)\n\nYou need to specify either the socket path or the CLI context explicitly.\n\nTo specify the socket path using `$DOCKER_HOST`:\n\nTo specify the CLI context using `docker context`:\n\n### [Rootless Docker in Docker](#rootless-docker-in-docker)\n\nTo run Rootless Docker inside \"rootful\" Docker, use the `docker:<version>-dind-rootless` image instead of `docker:<version>-dind`.\n\nThe `docker:<version>-dind-rootless` image runs as a non-root user (UID 1000). However, `--privileged` is required for disabling seccomp, AppArmor, and mount masks.\n\n### [Expose Docker API socket through TCP](#expose-docker-api-socket-through-tcp)\n\nTo expose the Docker API socket through TCP, you need to launch `dockerd-rootless.sh` with `DOCKERD_ROOTLESS_ROOTLESSKIT_FLAGS=\"-p 0.0.0.0:2376:2376/tcp\"`.\n\n### [Expose Docker API socket through SSH](#expose-docker-api-socket-through-ssh)\n\nTo expose the Docker API socket through SSH, you need to make sure `$DOCKER_HOST` is set on the remote host.\n\n### [Routing ping packets](#routing-ping-packets)\n\nOn some distributions, `ping` does not work by default.\n\nAdd `net.ipv4.ping_group_range = 0 2147483647` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system` to allow using `ping`.\n\n### [Exposing privileged ports](#exposing-privileged-ports)\n\nTo expose privileged ports (< 1024), set `CAP_NET_BIND_SERVICE` on `rootlesskit` binary and restart the daemon.\n\nOr add `net.ipv4.ip_unprivileged_port_start=0` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system`.\n\n### [Limiting resources](#limiting-resources)\n\nLimiting resources with cgroup-related `docker run` flags such as `--cpus`, `--memory`, `--pids-limit` is supported only when running with cgroup v2 and systemd. See [Changing cgroup version](https://docs.docker.com/config/containers/runmetrics/) to enable cgroup v2.\n\nIf `docker info` shows `none` as `Cgroup Driver`, the conditions are not satisfied. When these conditions are not satisfied, rootless mode ignores the cgroup-related `docker run` flags. See [Limiting resources without cgroup](#limiting-resources-without-cgroup) for workarounds.\n\nIf `docker info` shows `systemd` as `Cgroup Driver`, the conditions are satisfied. However, typically, only `memory` and `pids` controllers are delegated to non-root users by default.\n\nTo allow delegation of all controllers, you need to change the systemd configuration as follows:\n\n> **Note**\n> \n> Delegating `cpuset` requires systemd 244 or later.\n\n#### [Limiting resources without cgroup](#limiting-resources-without-cgroup)\n\nEven when cgroup is not available, you can still use the traditional `ulimit` and [`cpulimit`](https://github.com/opsengine/cpulimit), though they work in process-granularity rather than in container-granularity, and can be arbitrarily disabled by the container process.\n\nFor example:\n\n*   To limit CPU usage to 0.5 cores (similar to `docker run --cpus 0.5`): `docker run <IMAGE> cpulimit --limit=50 --include-children <COMMAND>`\n    \n*   To limit max VSZ to 64MiB (similar to `docker run --memory 64m`): `docker run <IMAGE> sh -c \"ulimit -v 65536; <COMMAND>\"`\n    \n*   To limit max number of processes to 100 per namespaced UID 2000 (similar to `docker run --pids-limit=100`): `docker run --user 2000 --ulimit nproc=100 <IMAGE> <COMMAND>`\n    \n\n### [Unable to install with systemd when systemd is present on the system](#unable-to-install-with-systemd-when-systemd-is-present-on-the-system)\n\n`rootlesskit` cannot detect systemd properly if you switch to your user via `sudo su`. For users which cannot be logged-in, you must use the `machinectl` command which is part of the `systemd-container` package. After installing `systemd-container` switch to `myuser` with the following command:\n\nWhere `myuser@` is your desired username and @ signifies this machine.\n\n### [Errors when starting the Docker daemon](#errors-when-starting-the-docker-daemon)\n\n**\\[rootlesskit:parent\\] error: failed to start the child: fork/exec /proc/self/exe: operation not permitted**\n\nThis error occurs mostly when the value of `/proc/sys/kernel/unprivileged_userns_clone` is set to 0:\n\nTo fix this issue, add `kernel.unprivileged_userns_clone=1` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system`.\n\n**\\[rootlesskit:parent\\] error: failed to start the child: fork/exec /proc/self/exe: no space left on device**\n\nThis error occurs mostly when the value of `/proc/sys/user/max_user_namespaces` is too small:\n\nTo fix this issue, add `user.max_user_namespaces=28633` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system`.\n\n**\\[rootlesskit:parent\\] error: failed to setup UID/GID map: failed to compute uid/gid map: No subuid ranges found for user 1001 (\"testuser\")**\n\nThis error occurs when `/etc/subuid` and `/etc/subgid` are not configured. See [Prerequisites](#prerequisites).\n\n**could not get XDG\\_RUNTIME\\_DIR**\n\nThis error occurs when `$XDG_RUNTIME_DIR` is not set.\n\nOn a non-systemd host, you need to create a directory and then set the path:\n\n> **Note**\n> \n> You must remove the directory every time you log out.\n\nOn a systemd host, log into the host using `pam_systemd` (see below). The value is automatically set to `/run/user/$UID` and cleaned up on every logout.\n\n**`systemctl --user` fails with \"Failed to connect to bus: No such file or directory\"**\n\nThis error occurs mostly when you switch from the root user to an non-root user with `sudo`:\n\nInstead of `sudo -iu <USERNAME>`, you need to log in using `pam_systemd`. For example:\n\n*   Log in through the graphic console\n*   `ssh <USERNAME>@localhost`\n*   `machinectl shell <USERNAME>@`\n\n**The daemon does not start up automatically**\n\nYou need `sudo loginctl enable-linger $(whoami)` to enable the daemon to start up automatically. See [Usage](#usage).\n\n**iptables failed: iptables -t nat -N DOCKER: Fatal: can't open lock file /run/xtables.lock: Permission denied**\n\nThis error may happen with an older version of Docker when SELinux is enabled on the host.\n\nThe issue has been fixed in Docker 20.10.8. A known workaround for older version of Docker is to run the following commands to disable SELinux for `iptables`:\n\n### [`docker pull` errors](#docker-pull-errors)\n\n**docker: failed to register layer: Error processing tar file(exit status 1): lchown <FILE>: invalid argument**\n\nThis error occurs when the number of available entries in `/etc/subuid` or `/etc/subgid` is not sufficient. The number of entries required vary across images. However, 65,536 entries are sufficient for most images. See [Prerequisites](#prerequisites).\n\n**docker: failed to register layer: ApplyLayer exit status 1 stdout: stderr: lchown <FILE>: operation not permitted**\n\nThis error occurs mostly when `~/.local/share/docker` is located on NFS.\n\nA workaround is to specify non-NFS `data-root` directory in `~/.config/docker/daemon.json` as follows:\n\n### [`docker run` errors](#docker-run-errors)\n\n**docker: Error response from daemon: OCI runtime create failed: ...: read unix @->/run/systemd/private: read: connection reset by peer: unknown.**\n\nThis error occurs on cgroup v2 hosts mostly when the dbus daemon is not running for the user.\n\nTo fix the issue, run `sudo apt-get install -y dbus-user-session` or `sudo dnf install -y dbus-daemon`, and then relogin.\n\nIf the error still occurs, try running `systemctl --user enable --now dbus` (without sudo).\n\n**`--cpus`, `--memory`, and `--pids-limit` are ignored**\n\nThis is an expected behavior on cgroup v1 mode. To use these flags, the host needs to be configured for enabling cgroup v2. For more information, see [Limiting resources](#limiting-resources).\n\n### [Networking errors](#networking-errors)\n\nThis section provides troubleshooting tips for networking in rootless mode.\n\nNetworking in rootless mode is supported via network and port drivers in RootlessKit. Network performance and characteristics depend on the combination of network and port driver you use. If you're experiencing unexpected behavior or performance related to networking, review the following table which shows the configurations supported by RootlessKit, and how they compare:\n\n| Network driver | Port driver | Net throughput | Port throughput | Source IP propagation | No SUID | Note |\n| --- | --- | --- | --- | --- | --- | --- |\n| `slirp4netns` | `builtin` | Slow | Fast âœ… | âŒ   | âœ…   | Default in a typical setup |\n| `vpnkit` | `builtin` | Slow | Fast âœ… | âŒ   | âœ…   | Default when `slirp4netns` isn't installed |\n| `slirp4netns` | `slirp4netns` | Slow | Slow | âœ…   | âœ…   |     |\n| `pasta` | `implicit` | Slow | Fast âœ… | âœ…   | âœ…   | Experimental; Needs pasta version 2023\\_12\\_04 or later |\n| `lxc-user-nic` | `builtin` | Fast âœ… | Fast âœ… | âŒ   | âŒ   | Experimental |\n| `bypass4netns` | `bypass4netns` | Fast âœ… | Fast âœ… | âœ…   | âœ…   | **Note:** Not integrated to RootlessKit as it needs a custom seccomp profile |\n\nFor information about troubleshooting specific networking issues, see:\n\n*   [`docker run -p` fails with `cannot expose privileged port`](#docker-run--p-fails-with-cannot-expose-privileged-port)\n*   [Ping doesn't work](#ping-doesnt-work)\n*   [`IPAddress` shown in `docker inspect` is unreachable](#ipaddress-shown-in-docker-inspect-is-unreachable)\n*   [`--net=host` doesn't listen ports on the host network namespace](#--nethost-doesnt-listen-ports-on-the-host-network-namespace)\n*   [Newtork is slow](#network-is-slow)\n*   [`docker run -p` does not propagate source IP addresses](#docker-run--p-does-not-propagate-source-ip-addresses)\n\n#### [`docker run -p` fails with `cannot expose privileged port`](#docker-run--p-fails-with-cannot-expose-privileged-port)\n\n`docker run -p` fails with this error when a privileged port (< 1024) is specified as the host port.\n\nWhen you experience this error, consider using an unprivileged port instead. For example, 8080 instead of 80.\n\nTo allow exposing privileged ports, see [Exposing privileged ports](#exposing-privileged-ports).\n\n#### [Ping doesn't work](#ping-doesnt-work)\n\nPing does not work when `/proc/sys/net/ipv4/ping_group_range` is set to `1 0`:\n\nFor details, see [Routing ping packets](#routing-ping-packets).\n\n#### [`IPAddress` shown in `docker inspect` is unreachable](#ipaddress-shown-in-docker-inspect-is-unreachable)\n\nThis is an expected behavior, as the daemon is namespaced inside RootlessKit's network namespace. Use `docker run -p` instead.\n\n#### [`--net=host` doesn't listen ports on the host network namespace](#--nethost-doesnt-listen-ports-on-the-host-network-namespace)\n\nThis is an expected behavior, as the daemon is namespaced inside RootlessKit's network namespace. Use `docker run -p` instead.\n\n#### [Network is slow](#network-is-slow)\n\nDocker with rootless mode uses [slirp4netns](https://github.com/rootless-containers/slirp4netns) as the default network stack if slirp4netns v0.4.0 or later is installed. If slirp4netns is not installed, Docker falls back to [VPNKit](https://github.com/moby/vpnkit). Installing slirp4netns may improve the network throughput.\n\nFor more information about network drivers for RootlessKit, see [RootlessKit documentation](https://github.com/rootless-containers/rootlesskit/blob/v2.0.0/docs/network.md).\n\nAlso, changing MTU value may improve the throughput. The MTU value can be specified by creating `~/.config/systemd/user/docker.service.d/override.conf` with the following content:\n\nAnd then restart the daemon:\n\n#### [`docker run -p` does not propagate source IP addresses](#docker-run--p-does-not-propagate-source-ip-addresses)\n\nThis is because Docker in rootless mode uses RootlessKit's `builtin` port driver by default, which doesn't support source IP propagation. To enable source IP propagation, you can:\n\n*   Use the `slirp4netns` RootlessKit port driver\n*   Use the `pasta` RootlessKit network driver, with the `implicit` port driver\n\nThe `pasta` network driver is experimental, but provides improved throughput performance compared to the `slirp4netns` port driver. The `pasta` driver requires Docker Engine version 25.0 or later.\n\nTo change the RootlessKit networking configuration:\n\n1.  Create a file at `~/.config/systemd/user/docker.service.d/override.conf`.\n    \n2.  Add the following contents, depending on which configuration you would like to use:\n    \n    *   `slirp4netns`\n        \n    *   `pasta` network driver with `implicit` port driver\n        \n3.  Restart the daemon:\n    \n\nFor more information about networking options for RootlessKit, see:\n\n*   [Network drivers](https://github.com/rootless-containers/rootlesskit/blob/v2.0.0/docs/network.md)\n*   [Port drivers](https://github.com/rootless-containers/rootlesskit/blob/v2.0.0/docs/port.md)\n\n### [Tips for debugging](#tips-for-debugging)\n\n**Entering into `dockerd` namespaces**\n\nThe `dockerd-rootless.sh` script executes `dockerd` in its own user, mount, and network namespaces.\n\nFor debugging, you can enter the namespaces by running `nsenter -U --preserve-credentials -n -m -t $(cat $XDG_RUNTIME_DIR/docker.pid)`.",
  "title": "Run the Docker daemon as a non-root user (Rootless mode) | Docker Docs\n",
  "description": "Run the Docker daemon as a non-root user (Rootless mode)",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/exporters/oci-docker/",
  "markdown": "# OCI and Docker exporters | Docker Docs\n\nThe `oci` exporter outputs the build result into an [OCI image layout](https://github.com/opencontainers/image-spec/blob/main/image-layout.md) tarball. The `docker` exporter behaves the same way, except it exports a Docker image layout instead.\n\nThe [`docker` driver](https://docs.docker.com/build/drivers/docker/) doesn't support these exporters. You must use `docker-container` or some other driver if you want to generate these outputs.\n\nBuild a container image using the `oci` and `docker` exporters:\n\nThe following table describes the available parameters:\n\n| Parameter | Type | Default | Description |\n| --- | --- | --- | --- |\n| `name` | String |     | Specify image name(s) |\n| `dest` | String |     | Path |\n| `tar` | `true`,`false` | `true` | Bundle the output into a tarball layout |\n| `compression` | `uncompressed`,`gzip`,`estargz`,`zstd` | `gzip` | Compression type, see [compression](https://docs.docker.com/build/exporters/#compression) |\n| `compression-level` | `0..22` |     | Compression level, see [compression](https://docs.docker.com/build/exporters/#compression) |\n| `force-compression` | `true`,`false` | `false` | Forcefully apply compression, see [compression](https://docs.docker.com/build/exporters/#compression) |\n| `oci-mediatypes` | `true`,`false` |     | Use OCI media types in exporter manifests. Defaults to `true` for `type=oci`, and `false` for `type=docker`. See [OCI Media types](https://docs.docker.com/build/exporters/#oci-media-types) |\n| `annotation.<key>` | String |     | Attach an annotation with the respective `key` and `value` to the built image,see [annotations](#annotations) |\n\nThese exporters support adding OCI annotation using `annotation` parameter, followed by the annotation name using dot notation. The following example sets the `org.opencontainers.image.title` annotation:\n\nFor more information about annotations, see [BuildKit documentation](https://github.com/moby/buildkit/blob/master/docs/annotations.md).\n\nFor more information on the `oci` or `docker` exporters, see the [BuildKit README](https://github.com/moby/buildkit/blob/master/README.md#docker-tarball).",
  "title": "OCI and Docker exporters | Docker Docs\n",
  "description": "The OCI and Docker exporters create an image layout tarball on the local filesystem ",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/18.02/",
  "markdown": "# Docker Engine 18.02 release notes\n\n2018-02-07\n\n### [Builder](#builder)\n\n*   Gitutils: fix checking out submodules [moby/moby#35737](https://github.com/moby/moby/pull/35737)\n\n### [Client](#client)\n\n*   Attach: Ensure attach exit code matches container's [docker/cli#696](https://github.com/docker/cli/pull/696)\n\n*   Added support for tmpfs-mode in compose file [docker/cli#808](https://github.com/docker/cli/pull/808)\n*   Adds a new compose file version 3.6 [docker/cli#808](https://github.com/docker/cli/pull/808)\n\n*   Fix issue of filter in `docker ps` where `health=starting` returns nothing [moby/moby#35940](https://github.com/moby/moby/pull/35940)\n\n*   Improve presentation of published port ranges [docker/cli#581](https://github.com/docker/cli/pull/581)\n\n*   Bump Go to 1.9.3 [docker/cli#827](https://github.com/docker/cli/pull/827)\n\n*   Fix broken Kubernetes stack flags [docker/cli#831](https://github.com/docker/cli/pull/831)\n\n*   Annotate \"stack\" commands to be \"swarm\" and \"kubernetes\" [docker/cli#804](https://github.com/docker/cli/pull/804)\n\n### [Experimental](#experimental)\n\n*   Add manifest command [docker/cli#138](https://github.com/docker/cli/pull/138)\n\n*   LCOW remotefs - return error in Read() implementation [moby/moby#36051](https://github.com/moby/moby/pull/36051)\n\n*   LCOW: Coalesce daemon stores, allow dual LCOW and WCOW mode [moby/moby#34859](https://github.com/moby/moby/pull/34859)\n\n*   LCOW: Fix OpenFile parameters [moby/moby#36043](https://github.com/moby/moby/pull/36043)\n\n*   LCOW: Raise minimum requirement to Windows RS3 RTM build (16299) [moby/moby#36065](https://github.com/moby/moby/pull/36065)\n\n### [Logging](#logging)\n\n*   Improve daemon config reload; log active configuration [moby/moby#36019](https://github.com/moby/moby/pull/36019)\n\n*   Fixed error detection using IsErrNotFound and IsErrNotImplemented for the ContainerLogs method [moby/moby#36000](https://github.com/moby/moby/pull/36000)\n\n*   Add journald tag as SYSLOG\\_IDENTIFIER [moby/moby#35570](https://github.com/moby/moby/pull/35570)\n\n*   Splunk: limit the reader size on error responses [moby/moby#35509](https://github.com/moby/moby/pull/35509)\n\n### [Networking](#networking)\n\n*   Disable service on release network results in zero-downtime deployments with rolling upgrades [moby/moby#35960](https://github.com/moby/moby/pull/35960)\n\n*   Fix services failing to start if multiple networks with the same name exist in different spaces [moby/moby#30897](https://github.com/moby/moby/pull/30897)\n*   Fix duplicate networks being added with `docker service update --network-add` [docker/cli#780](https://github.com/docker/cli/pull/780)\n*   Fixing ingress network when upgrading from 17.09 to 17.12. [moby/moby#36003](https://github.com/moby/moby/pull/36003)\n*   Fix ndots configuration [docker/libnetwork#1995](https://github.com/docker/libnetwork/pull/1995)\n*   Fix IPV6 networking being deconfigured if live-restore is enabled [docker/libnetwork#2043](https://github.com/docker/libnetwork/pull/2043)\n\n*   Add support for MX type DNS queries in the embedded DNS server [docker/libnetwork#2041](https://github.com/docker/libnetwork/pull/2041)\n\n### [Packaging](#packaging)\n\n*   Added packaging for Fedora 26, Fedora 27, and Centos 7 on aarch64 [docker/docker-ce-packaging#71](https://github.com/docker/docker-ce-packaging/pull/71)\n\n*   Removed support for Ubuntu Zesty [docker/docker-ce-packaging#73](https://github.com/docker/docker-ce-packaging/pull/73)\n*   Removed support for Fedora 25 [docker/docker-ce-packaging#72](https://github.com/docker/docker-ce-packaging/pull/72)\n\n### [Runtime](#runtime)\n\n*   Fixes unexpected Docker Daemon shutdown based on pipe error [moby/moby#35968](https://github.com/moby/moby/pull/35968)\n*   Fix some occurrences of hcsshim::ImportLayer failed in Win32: The system cannot find the path specified [moby/moby#35924](https://github.com/moby/moby/pull/35924)\n\n*   Windows: increase the maximum layer size during build to 127GB [moby/moby#35925](https://github.com/moby/moby/pull/35925)\n\n*   Fix Devicemapper: Error running DeleteDevice dm\\_task\\_run failed [moby/moby#35919](https://github.com/moby/moby/pull/35919)\n\n*   Introduce Â« exec\\_die Â» event [moby/moby#35744](https://github.com/moby/moby/pull/35744)\n\n*   Update API to version 1.36 [moby/moby#35744](https://github.com/moby/moby/pull/35744)\n\n*   Fix `docker update` not updating cpu quota, and cpu-period of a running container [moby/moby#36030](https://github.com/moby/moby/pull/36030)\n\n*   Make container shm parent unbindable [moby/moby#35830](https://github.com/moby/moby/pull/35830)\n\n*   Make image (layer) downloads faster by using pigz [moby/moby#35697](https://github.com/moby/moby/pull/35697)\n*   Protect the daemon from volume plugins that are slow or deadlocked [moby/moby#35441](https://github.com/moby/moby/pull/35441)\n\n*   Fix `DOCKER_RAMDISK` environment variable not being honoured [moby/moby#35957](https://github.com/moby/moby/pull/35957)\n\n*   Bump containerd to 1.0.1 (9b55aab90508bd389d7654c4baf173a981477d55) [moby/moby#35986](https://github.com/moby/moby/pull/35986)\n*   Update runc to fix hang during start and exec [moby/moby#36097](https://github.com/moby/moby/pull/36097)\n\n*   Fix \"--node-generic-resource\" singular/plural [moby/moby#36125](https://github.com/moby/moby/pull/36125)",
  "title": "Docker Engine 18.02 release notes | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/rolling-update/",
  "markdown": "# Apply rolling updates to a service\n\nIn a previous step of the tutorial, you [scaled](https://docs.docker.com/engine/swarm/swarm-tutorial/scale-service/) the number of instances of a service. In this part of the tutorial, you deploy a service based on the Redis 3.0.6 container tag. Then you upgrade the service to use the Redis 3.0.7 container image using rolling updates.\n\n1.  If you haven't already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n    \n2.  Deploy your Redis tag to the swarm and configure the swarm with a 10 second update delay. Note that the following example shows an older Redis tag:\n    \n    You configure the rolling update policy at service deployment time.\n    \n    The `--update-delay` flag configures the time delay between updates to a service task or sets of tasks. You can describe the time `T` as a combination of the number of seconds `Ts`, minutes `Tm`, or hours `Th`. So `10m30s` indicates a 10 minute 30 second delay.\n    \n    By default the scheduler updates 1 task at a time. You can pass the `--update-parallelism` flag to configure the maximum number of service tasks that the scheduler updates simultaneously.\n    \n    By default, when an update to an individual task returns a state of `RUNNING`, the scheduler schedules another task to update until all tasks are updated. If at any time during an update a task returns `FAILED`, the scheduler pauses the update. You can control the behavior using the `--update-failure-action` flag for `docker service create` or `docker service update`.\n    \n3.  Inspect the `redis` service:\n    \n4.  Now you can update the container image for `redis`. The swarm manager applies the update to nodes according to the `UpdateConfig` policy:\n    \n    The scheduler applies rolling updates as follows by default:\n    \n    *   Stop the first task.\n    *   Schedule update for the stopped task.\n    *   Start the container for the updated task.\n    *   If the update to a task returns `RUNNING`, wait for the specified delay period then start the next task.\n    *   If, at any time during the update, a task returns `FAILED`, pause the update.\n5.  Run `docker service inspect --pretty redis` to see the new image in the desired state:\n    \n    The output of `service inspect` shows if your update paused due to failure:\n    \n    To restart a paused update run `docker service update <SERVICE-ID>`. For example:\n    \n    To avoid repeating certain update failures, you may need to reconfigure the service by passing flags to `docker service update`.\n    \n6.  Run `docker service ps <SERVICE-ID>` to watch the rolling update:\n    \n    Before Swarm updates all of the tasks, you can see that some are running `redis:3.0.6` while others are running `redis:3.0.7`. The output above shows the state once the rolling updates are done.\n    \n\nNext, you'll learn how to drain a node in the swarm.",
  "title": "Apply rolling updates to a service | Docker Docs\n",
  "description": "Apply rolling updates to a service on the swarm",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/cache/",
  "markdown": "# Docker build cache | Docker Docs\n\nWhen you build the same Docker image multiple times, knowing how to optimize the build cache is a great tool for making sure the builds run fast.\n\nUnderstanding Docker's build cache helps you write better Dockerfiles that result in faster builds.\n\nThe following example shows a small Dockerfile for a program written in C.\n\nEach instruction in this Dockerfile translates to a layer in your final image. You can think of image layers as a stack, with each layer adding more content on top of the layers that came before it:\n\n![Image layer diagram](https://docs.docker.com/build/images/cache-stack.png)\n\nWhenever a layer changes, that layer will need to be re-built. For example, suppose you make a change to your program in the `main.c` file. After this change, the `COPY` command will have to run again in order for those changes to appear in the image. In other words, Docker will invalidate the cache for this layer.\n\nIf a layer changes, all other layers that come after it are also affected. When the layer with the `COPY` command gets invalidated, all layers that follow will need to run again, too:\n\n![Image layer diagram, showing cache invalidation](https://docs.docker.com/build/images/cache-stack-invalidated.png)\n\nAnd that's the Docker build cache in a nutshell. Once a layer changes, then all downstream layers need to be rebuilt as well. Even if they wouldn't build anything differently, they still need to re-run.\n\nFor more details about how cache invalidation works, see [Cache invalidation](https://docs.docker.com/build/cache/invalidation/).\n\nNow that you understand how the cache works, you can begin to use the cache to your advantage. While the cache will automatically work on any `docker build` that you run, you can often refactor your Dockerfile to get even better performance. These optimizations can save precious seconds (or even minutes) off of your builds.\n\n### [Order your layers](#order-your-layers)\n\nPutting the commands in your Dockerfile into a logical order is a great place to start. Because a change causes a rebuild for steps that follow, try to make expensive steps appear near the beginning of the Dockerfile. Steps that change often should appear near the end of the Dockerfile, to avoid triggering rebuilds of layers that haven't changed.\n\nConsider the following example. A Dockerfile snippet that runs a JavaScript build from the source files in the current directory:\n\nThis Dockerfile is rather inefficient. Updating any file causes a reinstall of all dependencies every time you build the Docker image even if the dependencies didn't change since last time!\n\nInstead, the `COPY` command can be split in two. First, copy over the package management files (in this case, `package.json` and `yarn.lock`). Then, install the dependencies. Finally, copy over the project source code, which is subject to frequent change.\n\nBy installing dependencies in earlier layers of the Dockerfile, there is no need to rebuild those layers when a project file has changed.\n\n### [Keep layers small](#keep-layers-small)\n\nOne of the best things you can do to speed up image building is to just put less stuff into your build. Fewer parts means the cache stay smaller, but also that there should be fewer things that could be out-of-date and need rebuilding.\n\nTo get started, here are a few tips and tricks:\n\n#### [Don't include unnecessary files](#dont-include-unnecessary-files)\n\nBe considerate of what files you add to the image.\n\nRunning a command like `COPY . /src` will copy your entire [build context](https://docs.docker.com/build/building/context/) into the image. If you've got logs, package manager artifacts, or even previous build results in your current directory, those will also be copied over. This could make your image larger than it needs to be, especially as those files are usually not useful.\n\nAvoid adding unnecessary files to your builds by explicitly stating the files or directories you intend to copy over. For example, you might only want to add a `Makefile` and your `src` directory to the image filesystem. In that case, consider adding this to your Dockerfile:\n\nAs opposed to this:\n\nYou can also create a [`.dockerignore` file](https://docs.docker.com/build/building/context/#dockerignore-files), and use that to specify which files and directories to exclude from the build context.\n\n#### [Use your package manager wisely](#use-your-package-manager-wisely)\n\nMost Docker image builds involve using a package manager to help install software into the image. Debian has `apt`, Alpine has `apk`, Python has `pip`, NodeJS has `npm`, and so on.\n\nWhen installing packages, be considerate. Make sure to only install the packages that you need. If you're not going to use them, don't install them. Remember that this might be a different list for your local development environment and your production environment. You can use multi-stage builds to split these up efficiently.\n\n#### [Use the dedicated `RUN` cache](#use-the-dedicated-run-cache)\n\nThe `RUN` command supports a specialized cache, which you can use when you need a more fine-grained cache between runs. For example, when installing packages, you don't always need to fetch all of your packages from the internet each time. You only need the ones that have changed.\n\nTo solve this problem, you can use `RUN --mount type=cache`. For example, for your Debian-based image you might use the following:\n\nUsing the explicit cache with the `--mount` flag keeps the contents of the `target` directory preserved between builds. When this layer needs to be rebuilt, then it'll use the `apt` cache in `/var/cache/apt`.\n\n### [Minimize the number of layers](#minimize-the-number-of-layers)\n\nKeeping your layers small is a good first step, and the logical next step is to reduce the number of layers that you have. Fewer layers mean that you have less to rebuild, when something in your Dockerfile changes, so your build will complete faster.\n\nThe following sections outline some tips you can use to keep the number of layers to a minimum.\n\n#### [Use an appropriate base image](#use-an-appropriate-base-image)\n\nDocker provides over 170 pre-built [official images](https://hub.docker.com/search?q=&image_filter=official) for almost every common development scenario. For example, if you're building a Java web server, use a dedicated image such as [`eclipse-temurin`](https://hub.docker.com/_/eclipse-temurin/). Even when there's not an official image for what you might want, Docker provides images from [verified publishers](https://hub.docker.com/search?q=&image_filter=store) and [open source partners](https://hub.docker.com/search?q=&image_filter=open_source) that can help you on your way. The Docker community often produces third-party images to use as well.\n\nUsing official images saves you time and ensures you stay up to date and secure by default.\n\n#### [Use multi-stage builds](#use-multi-stage-builds)\n\n[Multi-stage builds](https://docs.docker.com/build/building/multi-stage/) let you split up your Dockerfile into multiple distinct stages. Each stage completes a step in the build process, and you can bridge the different stages to create your final image at the end. The Docker builder will work out dependencies between the stages and run them using the most efficient strategy. This even allows you to run multiple builds concurrently.\n\nMulti-stage builds use two or more `FROM` commands. The following example illustrates building a simple web server that serves HTML from your `docs` directory in Git:\n\nThis build has 3 stages: `git`, `fetch` and `site`. In this example, `git` is the base for the `fetch` stage. It uses the `COPY --from` flag to copy the data from the `docs/` directory into the Nginx server directory.\n\nEach stage has only a few instructions, and when possible, Docker will run these stages in parallel. Only the instructions in the `site` stage will end up as layers in the final image. The entire `git` history doesn't get embedded into the final result, which helps keep the image small and secure.\n\n#### [Combine commands together wherever possible](#combine-commands-together-wherever-possible)\n\nMost Dockerfile commands, and `RUN` commands in particular, can often be joined together. For example, instead of using `RUN` like this:\n\nIt's possible to run both of these commands inside a single `RUN`, which means that they will share the same cache! This is achievable using the `&&` shell operator to run one command after another:\n\nAnother shell feature that allows you to simplify and concatenate commands in a neat way are [`heredocs`](https://en.wikipedia.org/wiki/Here_document). It enables you to create multi-line scripts with good readability:\n\n(Note the `set -e` command to exit immediately after any command fails, instead of continuing.)\n\nFor more information on using cache to do efficient builds, see:\n\n*   [Cache invalidation](https://docs.docker.com/build/cache/invalidation/)\n*   [Garbage collection](https://docs.docker.com/build/cache/garbage-collection/)\n*   [Cache storage backends](https://docs.docker.com/build/cache/backends/)",
  "title": "Docker build cache | Docker Docs\n",
  "description": "Improve your build speed with effective use of the build cache",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/18.01/",
  "markdown": "# Docker Engine 18.01 release notes\n\n2018-01-10\n\n### [Builder](#builder)\n\n*   Fix files not being deleted if user-namespaces are enabled [moby/moby#35822](https://github.com/moby/moby/pull/35822)\n\n*   Add support for expanding environment-variables in `docker commit --change ...` [moby/moby#35582](https://github.com/moby/moby/pull/35582)\n\n### [Client](#client)\n\n*   Return errors from client in stack deploy configs [docker/cli#757](https://github.com/docker/cli/pull/757)\n\n*   Fix description of filter flag in prune commands [docker/cli#774](https://github.com/docker/cli/pull/774)\n\n*   Add \"pid\" to unsupported options list [docker/cli#768](https://github.com/docker/cli/pull/768)\n*   Add support for experimental Cli configuration [docker/cli#758](https://github.com/docker/cli/pull/758)\n*   Add support for generic resources to bash completion [docker/cli#749](https://github.com/docker/cli/pull/749)\n\n*   Fix error in zsh completion script for docker exec [docker/cli#751](https://github.com/docker/cli/pull/751)\n\n*   Add a debug message when client closes websocket attach connection [moby/moby#35720](https://github.com/moby/moby/pull/35720)\n\n*   Fix bash completion for `\"docker swarm\"` [docker/cli#772](https://github.com/docker/cli/pull/772)\n\n### [Documentation](#documentation)\n\n*   Correct references to `--publish` long syntax in docs [docker/cli#746](https://github.com/docker/cli/pull/746)\n*   Corrected descriptions for MAC\\_ADMIN and MAC\\_OVERRIDE [docker/cli#761](https://github.com/docker/cli/pull/761)\n*   Updated developer doc to explain external CLI [moby/moby#35681](https://github.com/moby/moby/pull/35681)\n\n*   Fix `\"on-failure\"` restart policy being documented as \"failure\" [docker/cli#754](https://github.com/docker/cli/pull/754)\n*   Fix anchors to \"Storage driver options\" [docker/cli#748](https://github.com/docker/cli/pull/748)\n\n### [Experimental](#experimental)\n\n*   Add kubernetes support to `docker stack` command [docker/cli#721](https://github.com/docker/cli/pull/721)\n\n*   Don't append the container id to custom directory checkpoints. [moby/moby#35694](https://github.com/moby/moby/pull/35694)\n\n### [Logging](#logging)\n\n*   Fix daemon crash when using the GELF log driver over TCP when the GELF server goes down [moby/moby#35765](https://github.com/moby/moby/pull/35765)\n\n*   Fix awslogs batch size calculation for large logs [moby/moby#35726](https://github.com/moby/moby/pull/35726)\n\n### [Networking](#networking)\n\n*   Windows: Fix to allow docker service to start on Windows VM [docker/libnetwork#1916](https://github.com/docker/libnetwork/pull/1916)\n*   Fix for docker intercepting DNS requests on ICS network [docker/libnetwork#2014](https://github.com/docker/libnetwork/pull/2014)\n\n*   Windows: Added a new network creation driver option [docker/libnetwork#2021](https://github.com/docker/libnetwork/pull/2021)\n\n### [Runtime](#runtime)\n\n*   Validate Mount-specs on container start to prevent missing host-path [moby/moby#35833](https://github.com/moby/moby/pull/35833)\n\n*   Fix overlay2 storage driver inside a user namespace [moby/moby#35794](https://github.com/moby/moby/pull/35794)\n\n*   Zfs: fix busy error on container stop [moby/moby#35674](https://github.com/moby/moby/pull/35674)\n\n*   Fix health checks not using the container's working directory [moby/moby#35845](https://github.com/moby/moby/pull/35845)\n*   Fix VFS graph driver failure to initialize because of failure to setup fs quota [moby/moby#35827](https://github.com/moby/moby/pull/35827)\n*   Fix containerd events being processed twice [moby/moby#35896](https://github.com/moby/moby/pull/35896)\n\n### [Swarm mode](#swarm-mode)\n\n*   Fix published ports not being updated if a service has the same number of host-mode published ports with Published Port 0 [docker/swarmkit#2376](https://github.com/docker/swarmkit/pull/2376)\n\n*   Make the task termination order deterministic [docker/swarmkit#2265](https://github.com/docker/swarmkit/pull/2265)",
  "title": "Docker Engine 18.01 release notes | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/drain-node/",
  "markdown": "# Drain a node on the swarm\n\nIn earlier steps of the tutorial, all the nodes have been running with `Active` availability. The swarm manager can assign tasks to any `Active` node, so up to now all nodes have been available to receive tasks.\n\nSometimes, such as planned maintenance times, you need to set a node to `Drain` availability. `Drain` availability prevents a node from receiving new tasks from the swarm manager. It also means the manager stops tasks running on the node and launches replica tasks on a node with `Active` availability.\n\n> **Important**:\n> \n> Setting a node to `Drain` does not remove standalone containers from that node, such as those created with `docker run`, `docker compose up`, or the Docker Engine API. A node's status, including `Drain`, only affects the node's ability to schedule swarm service workloads.\n\n1.  If you haven't already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n    \n2.  Verify that all your nodes are actively available.\n    \n3.  If you aren't still running the `redis` service from the [rolling update](https://docs.docker.com/engine/swarm/swarm-tutorial/rolling-update/) tutorial, start it now:\n    \n4.  Run `docker service ps redis` to see how the swarm manager assigned the tasks to different nodes:\n    \n    In this case the swarm manager distributed one task to each node. You may see the tasks distributed differently among the nodes in your environment.\n    \n5.  Run `docker node update --availability drain <NODE-ID>` to drain a node that had a task assigned to it:\n    \n6.  Inspect the node to check its availability:\n    \n    The drained node shows `Drain` for `Availability`.\n    \n7.  Run `docker service ps redis` to see how the swarm manager updated the task assignments for the `redis` service:\n    \n    The swarm manager maintains the desired state by ending the task on a node with `Drain` availability and creating a new task on a node with `Active` availability.\n    \n8.  Run `docker node update --availability active <NODE-ID>` to return the drained node to an active state:\n    \n9.  Inspect the node to see the updated state:\n    \n    When you set the node back to `Active` availability, it can receive new tasks:\n    \n    *   during a service update to scale up\n    *   during a rolling update\n    *   when you set another node to `Drain` availability\n    *   when a task fails on another active node\n\nNext, you'll learn how to use a Swarm mode routing mesh",
  "title": "Drain a node on the swarm | Docker Docs\n",
  "description": "Drain nodes on the swarm",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/cache/invalidation/",
  "markdown": "# Build cache invalidation | Docker Docs\n\nWhen building an image, Docker steps through the instructions in your Dockerfile, executing each in the order specified. For each instruction, Docker checks whether it can reuse the instruction from the build cache.\n\nThe basic rules of build cache invalidation are as follows:\n\n*   Starting with a base image that's already in the cache, the next instruction is compared against all child images derived from that base image to see if one of them was built using the exact same instruction. If not, the cache is invalidated.\n    \n*   In most cases, simply comparing the instruction in the Dockerfile with one of the child images is sufficient. However, certain instructions require more examination and explanation.\n    \n*   For the `ADD` and `COPY` instructions, the modification time and size file metadata is used to determine whether cache is valid. During cache lookup, cache is invalidated if the file metadata has changed for any of the files involved.\n    \n*   Aside from the `ADD` and `COPY` commands, cache checking doesn't look at the files in the container to determine a cache match. For example, when processing a `RUN apt-get -y update` command the files updated in the container aren't examined to determine if a cache hit exists. In that case just the command string itself is used to find a match.\n    \n\nOnce the cache is invalidated, all subsequent Dockerfile commands generate new images and the cache isn't used.\n\nIf your build contains several layers and you want to ensure the build cache is reusable, order the instructions from less frequently changed to more frequently changed where possible.\n\nThe cache for `RUN` instructions isn't invalidated automatically between builds. Suppose you have a step in your Dockerfile to install `curl`:\n\nThis doesn't mean that the version of `curl` in your image is always up-to-date. Rebuilding the image one week later will still get you the same packages as before. To force a re-execution of the `RUN` instruction, you can:\n\n*   Make sure that a layer before it has changed\n*   Clear the build cache ahead of the build using [`docker builder prune`](https://docs.docker.com/reference/cli/docker/builder/prune/)\n*   Use the `--no-cache` or `--no-cache-filter` options\n\nThe `--no-cache-filter` option lets you specify a specific build stage to invalidate the cache for:\n\nThe contents of build secrets are not part of the build cache. Changing the value of a secret doesn't result in cache invalidation.\n\nIf you want to force cache invalidation after changing a secret value, you can pass a build argument with an arbitrary value that you also change when changing the secret. Build arguments do result in cache invalidation.\n\nProperties of secrets such as IDs and mount paths do participate in the cache checksum, and result in cache invalidation if changed.",
  "title": "Build cache invalidation | Docker Docs\n",
  "description": "Dig into the details abouw how cache invalidation works for Docker's build cache",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/cache/garbage-collection/",
  "markdown": "# Build garbage collection | Docker Docs\n\nWhile [`docker builder prune`](https://docs.docker.com/reference/cli/docker/builder/prune/) or [`docker buildx prune`](https://docs.docker.com/reference/cli/docker/buildx/prune/) commands run at once, garbage collection runs periodically and follows an ordered list of prune policies.\n\nGarbage collection runs in the BuildKit daemon. The daemon clears the build cache when the cache size becomes too big, or when the cache age expires. The following sections describe how you can configure both the size and age parameters by defining garbage collection policies.\n\nDepending on the [driver](https://docs.docker.com/build/drivers/) used by your builder instance, the garbage collection will use a different configuration file.\n\nIf you're using the [`docker` driver](https://docs.docker.com/build/drivers/docker/), garbage collection can be configured in the [Docker Daemon configuration](https://docs.docker.com/reference/cli/dockerd/#daemon-configuration-file). file:\n\nFor other drivers, garbage collection can be configured using the [BuildKit configuration](https://docs.docker.com/build/buildkit/toml-configuration/) file:\n\nDefault garbage collection policies apply to all builders if not set:\n\n*   `rule#0`: if build cache uses more than 512MB delete the most easily reproducible data after it has not been used for 2 days.\n*   `rule#1`: remove any data not used for 60 days.\n*   `rule#2`: keep the unshared build cache under cap.\n*   `rule#3`: if previous policies were insufficient start deleting internal data to keep build cache under cap.\n\n> **Note**\n> \n> `Keep Bytes` defaults to 10% of the size of the disk. If the disk size cannot be determined, it uses 2GB as a fallback.",
  "title": "Build garbage collection | Docker Docs\n",
  "description": "Learn about garbage collection in the BuildKit daemon",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/ingress/",
  "markdown": "# Use Swarm mode routing mesh\n\nDocker Engine Swarm mode makes it easy to publish ports for services to make them available to resources outside the swarm. All nodes participate in an ingress routing mesh. The routing mesh enables each node in the swarm to accept connections on published ports for any service running in the swarm, even if there's no task running on the node. The routing mesh routes all incoming requests to published ports on available nodes to an active container.\n\nTo use the ingress network in the swarm, you need to have the following ports open between the swarm nodes before you enable Swarm mode:\n\n*   Port `7946` TCP/UDP for container network discovery.\n*   Port `4789` UDP (configurable) for the container ingress network.\n\nWhen setting up networking in a Swarm, special care should be taken. Consult the [tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/#open-protocols-and-ports-between-the-hosts) for an overview.\n\nYou must also open the published port between the swarm nodes and any external resources, such as an external load balancer, that require access to the port.\n\nYou can also [bypass the routing mesh](#bypass-the-routing-mesh) for a given service.\n\nUse the `--publish` flag to publish a port when you create a service. `target` is used to specify the port inside the container, and `published` is used to specify the port to bind on the routing mesh. If you leave off the `published` port, a random high-numbered port is bound for each service task. You need to inspect the task to determine the port.\n\n> **Note**\n> \n> The older form of this syntax is a colon-separated string, where the published port is first and the target port is second, such as `-p 8080:80`. The new syntax is preferred because it is easier to read and allows more flexibility.\n\nThe `<PUBLISHED-PORT>` is the port where the swarm makes the service available. If you omit it, a random high-numbered port is bound. The `<CONTAINER-PORT>` is the port where the container listens. This parameter is required.\n\nFor example, the following command publishes port 80 in the nginx container to port 8080 for any node in the swarm:\n\nWhen you access port 8080 on any node, Docker routes your request to an active container. On the swarm nodes themselves, port 8080 may not actually be bound, but the routing mesh knows how to route the traffic and prevents any port conflicts from happening.\n\nThe routing mesh listens on the published port for any IP address assigned to the node. For externally routable IP addresses, the port is available from outside the host. For all other IP addresses the access is only available from within the host.\n\n![Service ingress image](https://docs.docker.com/engine/swarm/images/ingress-routing-mesh.webp)\n\nYou can publish a port for an existing service using the following command:\n\nYou can use `docker service inspect` to view the service's published port. For instance:\n\nThe output shows the `<CONTAINER-PORT>` (labeled `TargetPort`) from the containers and the `<PUBLISHED-PORT>` (labeled `PublishedPort`) where nodes listen for requests for the service.\n\n### [Publish a port for TCP only or UDP only](#publish-a-port-for-tcp-only-or-udp-only)\n\nBy default, when you publish a port, it is a TCP port. You can specifically publish a UDP port instead of or in addition to a TCP port. When you publish both TCP and UDP ports, if you omit the protocol specifier, the port is published as a TCP port. If you use the longer syntax (recommended), set the `protocol` key to either `tcp` or `udp`.\n\n#### [TCP only](#tcp-only)\n\nLong syntax:\n\nShort syntax:\n\n#### [TCP and UDP](#tcp-and-udp)\n\nLong syntax:\n\nShort syntax:\n\n#### [UDP only](#udp-only)\n\nLong syntax:\n\nShort syntax:\n\nBy default, swarm services which publish ports do so using the routing mesh. When you connect to a published port on any swarm node (whether it is running a given service or not), you are redirected to a worker which is running that service, transparently. Effectively, Docker acts as a load balancer for your swarm services.\n\nYou can bypass the routing mesh, so that when you access the bound port on a given node, you are always accessing the instance of the service running on that node. This is referred to as `host` mode. There are a few things to keep in mind.\n\n*   If you access a node which is not running a service task, the service does not listen on that port. It is possible that nothing is listening, or that a completely different application is listening.\n    \n*   If you expect to run multiple service tasks on each node (such as when you have 5 nodes but run 10 replicas), you cannot specify a static target port. Either allow Docker to assign a random high-numbered port (by leaving off the `published`), or ensure that only a single instance of the service runs on a given node, by using a global service rather than a replicated one, or by using placement constraints.\n    \n\nTo bypass the routing mesh, you must use the long `--publish` service and set `mode` to `host`. If you omit the `mode` key or set it to `ingress`, the routing mesh is used. The following command creates a global service using `host` mode and bypassing the routing mesh.\n\nYou can configure an external load balancer for swarm services, either in combination with the routing mesh or without using the routing mesh at all.\n\n### [Using the routing mesh](#using-the-routing-mesh)\n\nYou can configure an external load balancer to route requests to a swarm service. For example, you could configure [HAProxy](https://www.haproxy.org/) to balance requests to an nginx service published to port 8080.\n\n![Ingress with external load balancer image](https://docs.docker.com/engine/swarm/images/ingress-lb.webp)\n\nIn this case, port 8080 must be open between the load balancer and the nodes in the swarm. The swarm nodes can reside on a private network that is accessible to the proxy server, but that is not publicly accessible.\n\nYou can configure the load balancer to balance requests between every node in the swarm even if there are no tasks scheduled on the node. For example, you could have the following HAProxy configuration in `/etc/haproxy/haproxy.cfg`:\n\nWhen you access the HAProxy load balancer on port 80, it forwards requests to nodes in the swarm. The swarm routing mesh routes the request to an active task. If, for any reason the swarm scheduler dispatches tasks to different nodes, you don't need to reconfigure the load balancer.\n\nYou can configure any type of load balancer to route requests to swarm nodes. To learn more about HAProxy, see the [HAProxy documentation](https://cbonte.github.io/haproxy-dconv/).\n\n### [Without the routing mesh](#without-the-routing-mesh)\n\nTo use an external load balancer without the routing mesh, set `--endpoint-mode` to `dnsrr` instead of the default value of `vip`. In this case, there is not a single virtual IP. Instead, Docker sets up DNS entries for the service such that a DNS query for the service name returns a list of IP addresses, and the client connects directly to one of these.\n\nYou can't use `--endpoint-mode dnsrr` together with `--publish mode=ingress`. You must run your own load balancer in front of the service. A DNS query for the service name on the Docker host returns a list of IP addresses for the nodes running the service. Configure your load balancer to consume this list and balance the traffic across the nodes. See [Configure service discovery](https://docs.docker.com/engine/swarm/networking/#configure-service-discovery).\n\n*   [Deploy services to a swarm](https://docs.docker.com/engine/swarm/services/)",
  "title": "Use Swarm mode routing mesh | Docker Docs\n",
  "description": "Use the routing mesh to publish services externally to a swarm",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/cache/backends/",
  "markdown": "# Cache storage backends | Docker Docs\n\nTo ensure fast builds, BuildKit automatically caches the build result in its own internal cache. Additionally, BuildKit also supports exporting build cache to an external location, making it possible to import in future builds.\n\nAn external cache becomes almost essential in CI/CD build environments. Such environments usually have little-to-no persistence between runs, but it's still important to keep the runtime of image builds as low as possible.\n\nThe default `docker` driver supports the `inline`, `local`, `registry`, and `gha` cache backends, but only if you have enabled the [containerd image store](https://docs.docker.com/desktop/containerd/). Other cache backends require you to select a different [driver](https://docs.docker.com/build/drivers/).\n\n> **Warning**\n> \n> If you use secrets or credentials inside your build process, ensure you manipulate them using the dedicated [`--secret` option](https://docs.docker.com/reference/cli/docker/buildx/build/#secret). Manually managing secrets using `COPY` or `ARG` could result in leaked credentials.\n\nBuildx supports the following cache storage backends:\n\n*   `inline`: embeds the build cache into the image.\n    \n    The inline cache gets pushed to the same location as the main output result. This only works with the [`image` exporter](https://docs.docker.com/build/exporters/image-registry/).\n    \n*   `registry`: embeds the build cache into a separate image, and pushes to a dedicated location separate from the main output.\n    \n*   `local`: writes the build cache to a local directory on the filesystem.\n    \n*   `gha`: uploads the build cache to [GitHub Actions cache](https://docs.github.com/en/rest/actions/cache) (beta).\n    \n*   `s3`: uploads the build cache to an [AWS S3 bucket](https://aws.amazon.com/s3/) (unreleased).\n    \n*   `azblob`: uploads the build cache to [Azure Blob Storage](https://azure.microsoft.com/en-us/services/storage/blobs/) (unreleased).\n    \n\nTo use any of the cache backends, you first need to specify it on build with the [`--cache-to` option](https://docs.docker.com/reference/cli/docker/buildx/build/#cache-to) to export the cache to your storage backend of choice. Then, use the [`--cache-from` option](https://docs.docker.com/reference/cli/docker/buildx/build/#cache-from) to import the cache from the storage backend into the current build. Unlike the local BuildKit cache (which is always enabled), all of the cache storage backends must be explicitly exported to, and explicitly imported from.\n\nExample `buildx` command using the `registry` backend, using import and export cache:\n\n> **Warning**\n> \n> As a general rule, each cache writes to some location. No location can be written to twice, without overwriting the previously cached data. If you want to maintain multiple scoped caches (for example, a cache per Git branch), then ensure that you use different locations for exported cache.\n\nBuildKit currently only supports [a single cache exporter](https://github.com/moby/buildkit/pull/3024). But you can import from as many remote caches as you like. For example, a common pattern is to use the cache of both the current branch and the main branch. The following example shows importing cache from multiple locations using the registry cache backend:\n\nThis section describes some configuration options available when generating cache exports. The options described here are common for at least two or more backend types. Additionally, the different backend types support specific parameters as well. See the detailed page about each backend type for more information about which configuration parameters apply.\n\nThe common parameters described here are:\n\n*   [Cache mode](#cache-mode)\n*   [Cache compression](#cache-compression)\n*   [OCI media type](#oci-media-types)\n\n### [Cache mode](#cache-mode)\n\nWhen generating a cache output, the `--cache-to` argument accepts a `mode` option for defining which layers to include in the exported cache. This is supported by all cache backends except for the `inline` cache.\n\nMode can be set to either of two options: `mode=min` or `mode=max`. For example, to build the cache with `mode=max` with the registry backend:\n\nThis option is only set when exporting a cache, using `--cache-to`. When importing a cache (`--cache-from`) the relevant parameters are automatically detected.\n\nIn `min` cache mode (the default), only layers that are exported into the resulting image are cached, while in `max` cache mode, all layers are cached, even those of intermediate steps.\n\nWhile `min` cache is typically smaller (which speeds up import/export times, and reduces storage costs), `max` cache is more likely to get more cache hits. Depending on the complexity and location of your build, you should experiment with both parameters to find the results that work best for you.\n\n### [Cache compression](#cache-compression)\n\nThe cache compression options are the same as the [exporter compression options](https://docs.docker.com/build/exporters/#compression). This is supported by the `local` and `registry` cache backends.\n\nFor example, to compress the `registry` cache with `zstd` compression:\n\n### [OCI media types](#oci-media-types)\n\nThe cache OCI options are the same as the [exporter OCI options](https://docs.docker.com/build/exporters/#oci-media-types). These are supported by the `local` and `registry` cache backends.\n\nFor example, to export OCI media type cache, use the `oci-mediatypes` property:\n\nThis property is only meaningful with the `--cache-to` flag. When fetching cache, BuildKit will auto-detect the correct media types to use.",
  "title": "Cache storage backends | Docker Docs\n",
  "description": "Cache backends let you manage your build cache externally. External cache is useful to create a shared cache that can help speed up inner loop and CI builds. ",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/17.12/",
  "markdown": "# Docker Engine 17.12 release notes\n\n2018-02-27\n\n### [Client](#client)\n\n*   Fix `node-generic-resource` typo [moby/moby#35970](https://github.com/moby/moby/pull/35970) and [moby/moby#36125](https://github.com/moby/moby/pull/36125)\n\n*   Return errors from daemon on stack deploy configs create/update [docker/cli#757](https://github.com/docker/cli/pull/757)\n\n### [Logging](#logging)\n\n*   awslogs: fix batch size calculation for large logs [moby/moby#35726](https://github.com/moby/moby/pull/35726)\n\n*   Support a proxy in splunk log driver [moby/moby#36220](https://github.com/moby/moby/pull/36220)\n\n### [Networking](#networking)\n\n*   Fix ingress network when upgrading from 17.09 to 17.12 [moby/moby#36003](https://github.com/moby/moby/pull/36003)\n\n*   Add verbose info to partial overlay ID [moby/moby#35989](https://github.com/moby/moby/pull/35989)\n\n*   Fix IPv6 networking being deconfigured if live-restore is being enabled [docker/libnetwork#2043](https://github.com/docker/libnetwork/pull/2043)\n*   Fix watchMiss thread context [docker/libnetwork#2051](https://github.com/docker/libnetwork/pull/2051)\n\n### [Packaging](#packaging)\n\n*   Set TasksMax in docker.service [docker/docker-ce-packaging#78](https://github.com/docker/docker-ce-packaging/pull/78)\n\n### [Runtime](#runtime)\n\n*   Bump Golang to 1.9.4\n*   Bump containerd to 1.0.1\n\n*   Fix dockerd not being able to reconnect to containerd when it is restarted [moby/moby#36173](https://github.com/moby/moby/pull/36173)\n*   Fix containerd events from being processed twice [moby/moby#35891](https://github.com/moby/moby/issues/35891)\n*   Fix vfs graph driver failure to initialize because of failure to setup fs quota [moby/moby#35827](https://github.com/moby/moby/pull/35827)\n*   Fix regression of health check not using container's working directory [moby/moby#35845](https://github.com/moby/moby/pull/35845)\n*   Honor `DOCKER_RAMDISK` with containerd 1.0 [moby/moby#35957](https://github.com/moby/moby/pull/35957)\n*   Update runc to fix hang during start and exec [moby/moby#36097](https://github.com/moby/moby/pull/36097)\n*   Windows: Vendor of Microsoft/hcsshim @v.0.6.8 partial fix for import layer failing [moby/moby#35924](https://github.com/moby/moby/pull/35924)\n\n*   Do not make graphdriver homes private mounts [moby/moby#36047](https://github.com/moby/moby/pull/36047)\n*   Use rslave propagation for mounts from daemon root [moby/moby#36055](https://github.com/moby/moby/pull/36055)\n*   Set daemon root to use shared mount propagation [moby/moby#36096](https://github.com/moby/moby/pull/36096)\n*   Validate that mounted paths exist when container is started, not just during creation [moby/moby#35833](https://github.com/moby/moby/pull/35833)\n*   Add `REMOVE` and `ORPHANED` to TaskState [moby/moby#36146](https://github.com/moby/moby/pull/36146)\n\n*   Fix issue where network inspect does not show Created time for networks in swarm scope [moby/moby#36095](https://github.com/moby/moby/pull/36095)\n\n*   Nullify container read write layer upon release [moby/moby#36130](https://github.com/moby/moby/pull/36160) and [moby/moby#36343](https://github.com/moby/moby/pull/36242)\n\n### [Swarm](#swarm)\n\n*   Remove watchMiss from swarm mode [docker/libnetwork#2047](https://github.com/docker/libnetwork/pull/2047)\n\n### [Known Issues](#known-issues)\n\n*   Health check no longer uses the container's working directory [moby/moby#35843](https://github.com/moby/moby/issues/35843)\n*   Errors not returned from client in stack deploy configs [moby/moby#757](https://github.com/docker/cli/pull/757)\n*   Docker cannot use memory limit when using systemd options [moby/moby#35123](https://github.com/moby/moby/issues/35123)\n\n2017-12-27\n\n### [Known Issues](#known-issues-1)\n\n*   AWS logs batch size calculation [moby/moby#35726](https://github.com/moby/moby/pull/35726)\n*   Health check no longer uses the container's working directory [moby/moby#35843](https://github.com/moby/moby/issues/35843)\n*   Errors not returned from client in stack deploy configs [moby/moby#757](https://github.com/docker/cli/pull/757)\n*   Daemon aborts when project quota fails [moby/moby#35827](https://github.com/moby/moby/pull/35827)\n*   Docker cannot use memory limit when using systemd options [moby/moby#35123](https://github.com/moby/moby/issues/35123)\n\n### [Builder](#builder)\n\n*   Fix build cache hash for broken symlink [moby/moby#34271](https://github.com/moby/moby/pull/34271)\n*   Fix long stream sync [moby/moby#35404](https://github.com/moby/moby/pull/35404)\n*   Fix dockerfile parser failing silently on long tokens [moby/moby#35429](https://github.com/moby/moby/pull/35429)\n\n### [Client](#client-1)\n\n*   Remove secret/config duplication in cli/compose [docker/cli#671](https://github.com/docker/cli/pull/671)\n*   Add `--local` flag to `docker trust sign` [docker/cli#575](https://github.com/docker/cli/pull/575)\n*   Add `docker trust inspect` [docker/cli#694](https://github.com/docker/cli/pull/694)\n\n*   Add `name` field to secrets and configs to allow interpolation in Compose files [docker/cli#668](https://github.com/docker/cli/pull/668)\n*   Add `--isolation` for setting swarm service isolation mode [docker/cli#426](https://github.com/docker/cli/pull/426)\n\n*   Remove deprecated \"daemon\" subcommand [docker/cli#689](https://github.com/docker/cli/pull/689)\n\n*   Fix behaviour of `rmi -f` with unexpected errors [docker/cli#654](https://github.com/docker/cli/pull/654)\n\n*   Integrated Generic resource in service create [docker/cli#429](https://github.com/docker/cli/pull/429)\n\n*   Fix external networks in stacks [docker/cli#743](https://github.com/docker/cli/pull/743)\n\n*   Remove support for referencing images by image shortid [docker/cli#753](https://github.com/docker/cli/pull/753) and [moby/moby#35790](https://github.com/moby/moby/pull/35790)\n*   Use commit-sha instead of tag for containerd [moby/moby#35770](https://github.com/moby/moby/pull/35770)\n\n### [Documentation](#documentation)\n\n*   Update API version history for 1.35 [moby/moby#35724](https://github.com/moby/moby/pull/35724)\n\n### [Logging](#logging-1)\n\n*   Logentries driver line-only=true \\[\\]byte output fix [moby/moby#35612](https://github.com/moby/moby/pull/35612)\n*   Logentries line-only logopt fix to maintain backwards compatibility [moby/moby#35628](https://github.com/moby/moby/pull/35628)\n\n*   Add `--until` flag for docker logs [moby/moby#32914](https://github.com/moby/moby/pull/32914)\n*   Add gelf log driver plugin to Windows build [moby/moby#35073](https://github.com/moby/moby/pull/35073)\n\n*   Set timeout on splunk batch send [moby/moby#35496](https://github.com/moby/moby/pull/35496)\n*   Update Graylog2/go-gelf [moby/moby#35765](https://github.com/moby/moby/pull/35765)\n\n### [Networking](#networking-1)\n\n*   Move load balancer sandbox creation/deletion into libnetwork [moby/moby#35422](https://github.com/moby/moby/pull/35422)\n*   Only chown network files within container metadata [moby/moby#34224](https://github.com/moby/moby/pull/34224)\n*   Restore error type in FindNetwork [moby/moby#35634](https://github.com/moby/moby/pull/35634)\n\n*   Fix consumes MIME type for NetworkConnect [moby/moby#35542](https://github.com/moby/moby/pull/35542)\n\n*   Added support for persisting Windows network driver specific options [moby/moby#35563](https://github.com/moby/moby/pull/35563)\n\n*   Fix timeout on netlink sockets and watchmiss leak [moby/moby#35677](https://github.com/moby/moby/pull/35677)\n\n*   New daemon config for networking diagnosis [moby/moby#35677](https://github.com/moby/moby/pull/35677)\n\n*   Clean up node management logic [docker/libnetwork#2036](https://github.com/docker/libnetwork/pull/2036)\n*   Allocate VIPs when endpoints are restored [docker/swarmkit#2474](https://github.com/docker/swarmkit/pull/2474)\n\n### [Runtime](#runtime-1)\n\n*   Update to containerd v1.0.0 [moby/moby#35707](https://github.com/moby/moby/pull/35707)\n*   Have VFS graphdriver use accelerated in-kernel copy [moby/moby#35537](https://github.com/moby/moby/pull/35537)\n*   Introduce `workingdir` option for docker exec [moby/moby#35661](https://github.com/moby/moby/pull/35661)\n*   Bump Go to 1.9.2 [moby/moby#33892](https://github.com/moby/moby/pull/33892) [docker/cli#716](https://github.com/docker/cli/pull/716)\n*   `/dev` should not be readonly with `--readonly` flag [moby/moby#35344](https://github.com/moby/moby/pull/35344)\n\n*   Add custom build-time Graphdrivers priority list [moby/moby#35522](https://github.com/moby/moby/pull/35522)\n\n*   LCOW: CLI changes to add platform flag - pull, run, create and build [docker/cli#474](https://github.com/docker/cli/pull/474)\n*   Fix width/height on Windows for `docker exec` [moby/moby#35631](https://github.com/moby/moby/pull/35631)\n*   Detect overlay2 support on pre-4.0 kernels [moby/moby#35527](https://github.com/moby/moby/pull/35527)\n*   Devicemapper: remove container rootfs mountPath after umount [moby/moby#34573](https://github.com/moby/moby/pull/34573)\n*   Disallow overlay/overlay2 on top of NFS [moby/moby#35483](https://github.com/moby/moby/pull/35483)\n\n*   Fix potential panic during plugin set. [moby/moby#35632](https://github.com/moby/moby/pull/35632)\n*   Fix some issues with locking on the container [moby/moby#35501](https://github.com/moby/moby/pull/35501)\n*   Fixup some issues with plugin refcounting [moby/moby#35265](https://github.com/moby/moby/pull/35265)\n\n*   Add missing lock in ProcessEvent [moby/moby#35516](https://github.com/moby/moby/pull/35516)\n*   Add vfs quota support [moby/moby#35231](https://github.com/moby/moby/pull/35231)\n\n*   Skip empty directories on prior graphdriver detection [moby/moby#35528](https://github.com/moby/moby/pull/35528)\n*   Skip xfs quota tests when running in user namespace [moby/moby#35526](https://github.com/moby/moby/pull/35526)\n\n*   Added SubSecondPrecision to config option. [moby/moby#35529](https://github.com/moby/moby/pull/35529)\n\n*   Update fsnotify to fix deadlock in removing watch [moby/moby#35453](https://github.com/moby/moby/pull/35453)\n\n*   Fix \"duplicate mount point\" when `--tmpfs /dev/shm` is used [moby/moby#35467](https://github.com/moby/moby/pull/35467)\n*   Fix honoring tmpfs-size for user `/dev/shm` mount [moby/moby#35316](https://github.com/moby/moby/pull/35316)\n*   Fix EBUSY errors under overlayfs and v4.13+ kernels [moby/moby#34948](https://github.com/moby/moby/pull/34948)\n\n*   Container: protect health monitor channel [moby/moby#35482](https://github.com/moby/moby/pull/35482)\n*   Container: protect the health status with mutex [moby/moby#35517](https://github.com/moby/moby/pull/35517)\n*   Container: update real-time resources [moby/moby#33731](https://github.com/moby/moby/pull/33731)\n*   Create labels when volume exists only remotely [moby/moby#34896](https://github.com/moby/moby/pull/34896)\n\n*   Fix leaking container/exec state [moby/moby#35484](https://github.com/moby/moby/pull/35484)\n\n*   Disallow using legacy (v1) registries [moby/moby#35751](https://github.com/moby/moby/pull/35751) and [docker/cli#747](https://github.com/docker/cli/pull/747)\n\n*   Windows: Fix case insensitive filename matching against builder cache [moby/moby#35793](https://github.com/moby/moby/pull/35793)\n*   Fix race conditions around process handling and error checks [moby/moby#35809](https://github.com/moby/moby/pull/35809)\n\n*   Ensure containers are stopped on daemon startup [moby/moby#35805](https://github.com/moby/moby/pull/35805)\n*   Follow containerd namespace conventions [moby/moby#35812](https://github.com/moby/moby/pull/35812)\n\n### [Swarm Mode](#swarm-mode)\n\n*   Added support for swarm service isolation mode [moby/moby#34424](https://github.com/moby/moby/pull/34424)\n\n*   Fix task clean up for tasks that are complete [docker/swarmkit#2477](https://github.com/docker/swarmkit/pull/2477)\n\n### [Packaging](#packaging-1)\n\n*   Add Packaging for Fedora 27 [docker/docker-ce-packaging#59](https://github.com/docker/docker-ce-packaging/pull/59)\n\n*   Change default versioning scheme to 0.0.0-dev unless specified for packaging [docker/docker-ce-packaging#67](https://github.com/docker/docker-ce-packaging/pull/67)\n*   Pass Version to engine static builds [docker/docker-ce-packaging#70](https://github.com/docker/docker-ce-packaging/pull/70)\n\n*   Added support for aarch64 on Debian (stretch/jessie) and Ubuntu Zesty or newer [docker/docker-ce-packaging#35](https://github.com/docker/docker-ce-packaging/pull/35)",
  "title": "Docker Engine 17.12 release notes | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/17.11/",
  "markdown": "# Docker Engine 17.11 release notes\n\n**Important**: Docker CE 17.11 is the first Docker release based on [containerd 1.0 beta](https://github.com/containerd/containerd/releases/tag/v1.0.0-beta.2). Docker CE 17.11 and later don't recognize containers started with previous Docker versions. If using [Live Restore](https://docs.docker.com/config/containers/live-restore/), you must stop all containers before upgrading to Docker CE 17.11. If you don't, any containers started by Docker versions that predate 17.11 aren't recognized by Docker after the upgrade and keep running, un-managed, on the system.",
  "title": "Docker Engine 17.11 release notes | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/",
  "markdown": "# How nodes work | Docker Docs\n\nSwarm mode lets you create a cluster of one or more Docker Engines called a swarm. A swarm consists of one or more nodes: physical or virtual machines running Docker Engine.\n\nThere are two types of nodes: [managers](#manager-nodes) and [workers](#worker-nodes).\n\n![Swarm mode cluster](https://docs.docker.com/engine/swarm/images/swarm-diagram.webp)\n\nIf you haven't already, read through the [Swarm mode overview](https://docs.docker.com/engine/swarm/) and [key concepts](https://docs.docker.com/engine/swarm/key-concepts/).\n\nManager nodes handle cluster management tasks:\n\n*   Maintaining cluster state\n*   Scheduling services\n*   Serving Swarm mode [HTTP API endpoints](https://docs.docker.com/engine/api/)\n\nUsing a [Raft](https://raft.github.io/raft.pdf) implementation, the managers maintain a consistent internal state of the entire swarm and all the services running on it. For testing purposes it is OK to run a swarm with a single manager. If the manager in a single-manager swarm fails, your services continue to run, but you need to create a new cluster to recover.\n\nTo take advantage of Swarm mode's fault-tolerance features, we recommend you implement an odd number of nodes according to your organization's high-availability requirements. When you have multiple managers you can recover from the failure of a manager node without downtime.\n\n*   A three-manager swarm tolerates a maximum loss of one manager.\n    \n*   A five-manager swarm tolerates a maximum simultaneous loss of two manager nodes.\n    \n*   An odd number `N` of manager nodes in the cluster tolerates the loss of at most `(N-1)/2` managers. Docker recommends a maximum of seven manager nodes for a swarm.\n    \n    > **Important**\n    > \n    > Adding more managers does NOT mean increased scalability or higher performance. In general, the opposite is true.\n    \n\nWorker nodes are also instances of Docker Engine whose sole purpose is to execute containers. Worker nodes don't participate in the Raft distributed state, make scheduling decisions, or serve the swarm mode HTTP API.\n\nYou can create a swarm of one manager node, but you cannot have a worker node without at least one manager node. By default, all managers are also workers. In a single manager node cluster, you can run commands like `docker service create` and the scheduler places all tasks on the local engine.\n\nTo prevent the scheduler from placing tasks on a manager node in a multi-node swarm, set the availability for the manager node to `Drain`. The scheduler gracefully stops tasks on nodes in `Drain` mode and schedules the tasks on an `Active` node. The scheduler does not assign new tasks to nodes with `Drain` availability.\n\nRefer to the [`docker node update`](https://docs.docker.com/reference/cli/docker/node/update/) command line reference to see how to change node availability.\n\nYou can promote a worker node to be a manager by running `docker node promote`. For example, you may want to promote a worker node when you take a manager node offline for maintenance. See [node promote](https://docs.docker.com/reference/cli/docker/node/promote/).\n\nYou can also demote a manager node to a worker node. See [node demote](https://docs.docker.com/reference/cli/docker/node/demote/).\n\n*   Read about how Swarm mode [services](https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/) work.\n*   Learn how [PKI](https://docs.docker.com/engine/swarm/how-swarm-mode-works/pki/) works in Swarm mode.",
  "title": "How nodes work | Docker Docs\n",
  "description": "How swarm nodes work",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/cache/backends/inline/",
  "markdown": "# Inline cache | Docker Docs\n\nThe `inline` cache storage backend is the simplest way to get an external cache and is easy to get started using if you're already building and pushing an image.\n\nThe downside of inline cache is that it doesn't scale with multi-stage builds as well as the other drivers do. It also doesn't offer separation between your output artifacts and your cache output. This means that if you're using a particularly complex build flow, or not exporting your images directly to a registry, then you may want to consider the [registry](https://docs.docker.com/build/cache/backends/registry/) cache.\n\nNo additional parameters are supported for the `inline` cache.\n\nTo export cache using `inline` storage, pass `type=inline` to the `--cache-to` option:\n\nAlternatively, you can also export inline cache by setting the build argument `BUILDKIT_INLINE_CACHE=1`, instead of using the `--cache-to` flag:\n\nTo import the resulting cache on a future build, pass `type=registry` to `--cache-from` which lets you extract the cache from inside a Docker image in the specified registry:\n\nFor an introduction to caching see [Docker build cache](https://docs.docker.com/build/cache/).\n\nFor more information on the `inline` cache backend, see the [BuildKit README](https://github.com/moby/buildkit#inline-push-image-and-cache-together).",
  "title": "Inline cache | Docker Docs\n",
  "description": "Embed the build cache into the image",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/17.10/",
  "markdown": "# Docker Engine 17.10 release notes\n\n**Important**: Starting with this release, `docker service create`, `docker service update`, `docker service scale` and `docker service rollback` use non-detached mode as default, use `--detach` to keep the old behaviour.",
  "title": "Docker Engine 17.10 release notes | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/17.09/",
  "markdown": "# Docker Engine 17.09 release notes\n\n2017-12-07\n\n### [Builder](#builder)\n\n*   Fix config leakage on shared parent stage [moby/moby#33753](https://github.com/moby/moby/issues/33753)\n*   Warn on empty continuation lines only, not on comment-only lines [moby/moby#35004](https://github.com/moby/moby/pull/35004)\n\n### [Client](#client)\n\n*   Set API version on Client even when Ping fails [docker/cli#546](https://github.com/docker/cli/pull/546)\n\n### [Networking](#networking)\n\n*   Overlay fix for transient IP reuse [docker/libnetwork#2016](https://github.com/docker/libnetwork/pull/2016)\n*   Fix reapTime logic in NetworkDB and handle DNS cleanup for attachable container [docker/libnetwork#2017](https://github.com/docker/libnetwork/pull/2017)\n*   Disable hostname lookup on chain exists check [docker/libnetwork#2019](https://github.com/docker/libnetwork/pull/2019)\n*   Fix lint issues [docker/libnetwork#2020](https://github.com/docker/libnetwork/pull/2020)\n*   Restore error type in FindNetwork [moby/moby#35634](https://github.com/moby/moby/pull/35634)\n\n### [Runtime](#runtime)\n\n*   Protect `health monitor` Go channel [moby/moby#35482](https://github.com/moby/moby/pull/35482)\n*   Fix leaking container/exec state [moby/moby#35484](https://github.com/moby/moby/pull/35484)\n*   Add /proc/scsi to masked paths (patch to work around [CVE-2017-16539](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-16539) [moby/moby/#35399](https://github.com/moby/moby/pull/35399)\n*   Vendor tar-split: fix to prevent memory exhaustion issue that could crash Docker daemon [moby/moby/#35424](https://github.com/moby/moby/pull/35424) Fixes [CVE-2017-14992](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-14992)\n*   Fix P/Z HubPullSuite tests [moby/moby#34837](https://github.com/moby/moby/pull/34837)\n\n*   Windows: Add support for version filtering on pull [moby/moby#35090](https://github.com/moby/moby/pull/35090)\n\n*   Windows: Stop filtering Windows manifest lists by version [moby/moby#35117](https://github.com/moby/moby/pull/35117)\n*   Use rslave instead of rprivate in chroot archive [moby/moby/#35217](https://github.com/moby/moby/pull/35217)\n*   Remove container rootfs mountPath after unmount [moby/moby#34573](https://github.com/moby/moby/pull/34573)\n*   Fix honoring tmpfs size of user /dev/shm mount [moby/moby#35316](https://github.com/moby/moby/pull/35316)\n*   Don't abort when setting may\\_detach\\_mounts (log the error instead) [moby/moby#35172](https://github.com/moby/moby/pull/35172)\n*   Fix version comparison when negotiating the API version [moby/moby#35008](https://github.com/moby/moby/pull/35008)\n\n### [Swarm mode](#swarm-mode)\n\n*   Increase gRPC request timeout when sending snapshots [docker/swarmkit#2404](https://github.com/docker/swarmkit/pull/2404)\n\n*   Fix node filtering when there is no log driver [docker/swarmkit#2442](https://github.com/docker/swarmkit/pull/2442)\n*   Add an error on attempt to change cluster name [docker/swarmkit/#2454](https://github.com/docker/swarmkit/pull/2454)\n*   Delete node attachments when node is removed [docker/swarmkit/#2456](https://github.com/docker/swarmkit/pull/2456)\n*   Provide custom gRPC dialer to override default proxy dialer [docker/swarmkit/#2457](https://github.com/docker/swarmkit/pull/2457)\n*   Avoids recursive readlock on swarm info [moby/moby#35388](https://github.com/moby/moby/pull/35388)\n\n2017-09-26\n\n### [Builder](#builder-1)\n\n*   Add `--chown` flag to `ADD/COPY` commands in Dockerfile [moby/moby#34263](https://github.com/moby/moby/pull/34263)\n\n*   Fix cloning unneeded files while building from git repositories [moby/moby#33704](https://github.com/moby/moby/pull/33704)\n\n### [Client](#client-1)\n\n*   Allow extension fields in the v3.4 version of the compose format [docker/cli#452](https://github.com/docker/cli/pull/452)\n*   Make compose file allow to specify names for non-external volume [docker/cli#306](https://github.com/docker/cli/pull/306)\n*   Support `--compose-file -` as stdin [docker/cli#347](https://github.com/docker/cli/pull/347)\n*   Support `start_period` for healthcheck in Docker Compose [docker/cli#475](https://github.com/docker/cli/pull/475)\n\n*   Add support for `stop-signal` in docker stack commands [docker/cli#388](https://github.com/docker/cli/pull/388)\n*   Add support for update order in compose deployments [docker/cli#360](https://github.com/docker/cli/pull/360)\n*   Add ulimits to unsupported compose fields [docker/cli#482](https://github.com/docker/cli/pull/482)\n*   Add `--format` to `docker-search` [docker/cli#440](https://github.com/docker/cli/pull/440)\n\n*   Show images digests when `{{.Digest}}` is in format [docker/cli#439](https://github.com/docker/cli/pull/439)\n*   Print output of `docker stack rm` on `stdout` instead of `stderr` [docker/cli#491](https://github.com/docker/cli/pull/491)\n\n*   Fix `docker history --format {{json .}}` printing human-readable timestamps instead of ISO8601 when `--human=true` [docker/cli#438](https://github.com/docker/cli/pull/438)\n*   Fix idempotence of `docker stack deploy` when secrets or configs are used [docker/cli#509](https://github.com/docker/cli/pull/509)\n*   Fix presentation of random host ports [docker/cli#404](https://github.com/docker/cli/pull/404)\n*   Fix redundant service restarts when service created with multiple secrets [moby/moby#34746](https://github.com/moby/moby/issues/34746)\n\n### [Logging](#logging)\n\n*   Fix Splunk logger not transmitting log data when tag is empty and raw-mode is used [moby/moby#34520](https://github.com/moby/moby/pull/34520)\n\n### [Networking](#networking-1)\n\n*   Add the control plane MTU option in the daemon config [moby/moby#34103](https://github.com/moby/moby/pull/34103)\n*   Add service virtual IP to sandbox's loopback address [docker/libnetwork#1877](https://github.com/docker/libnetwork/pull/1877)\n\n### [Runtime](#runtime-1)\n\n*   Graphdriver: promote overlay2 over aufs [moby/moby#34430](https://github.com/moby/moby/pull/34430)\n*   LCOW: Additional flags for VHD boot [moby/moby#34451](https://github.com/moby/moby/pull/34451)\n*   LCOW: Don't block export [moby/moby#34448](https://github.com/moby/moby/pull/34448)\n*   LCOW: Dynamic sandbox management [moby/moby#34170](https://github.com/moby/moby/pull/34170)\n*   LCOW: Force Hyper-V Isolation [moby/moby#34468](https://github.com/moby/moby/pull/34468)\n*   LCOW: Move toolsScratchPath to /tmp [moby/moby#34396](https://github.com/moby/moby/pull/34396)\n*   LCOW: Remove hard-coding [moby/moby#34398](https://github.com/moby/moby/pull/34398)\n*   LCOW: WORKDIR correct handling [moby/moby#34405](https://github.com/moby/moby/pull/34405)\n*   Windows: named pipe mounts [moby/moby#33852](https://github.com/moby/moby/pull/33852)\n\n*   Fix \"permission denied\" errors when accessing volume with SELinux enforcing mode [moby/moby#34684](https://github.com/moby/moby/pull/34684)\n*   Fix layers size reported as `0` in `docker system df` [moby/moby#34826](https://github.com/moby/moby/pull/34826)\n*   Fix some \"device or resource busy\" errors when removing containers on RHEL 7.4 based kernels [moby/moby#34886](https://github.com/moby/moby/pull/34886)\n\n### [Swarm mode](#swarm-mode-1)\n\n*   Include whether the managers in the swarm are autolocked as part of `docker info` [docker/cli#471](https://github.com/docker/cli/pull/471)\n\n*   Add 'docker service rollback' subcommand [docker/cli#205](https://github.com/docker/cli/pull/205)\n\n*   Fix managers failing to join if the gRPC snapshot is larger than 4MB [docker/swarmkit#2375](https://github.com/docker/swarmkit/pull/2375)\n*   Fix \"permission denied\" errors for configuration file in SELinux-enabled containers [moby/moby#34732](https://github.com/moby/moby/pull/34732)\n*   Fix services failing to deploy on ARM nodes [moby/moby#34021](https://github.com/moby/moby/pull/34021)\n\n### [Packaging](#packaging)\n\n*   Build scripts for ppc64el on Ubuntu [docker/docker-ce-packaging#43](https://github.com/docker/docker-ce-packaging/pull/43)\n\n### [Deprecation](#deprecation)\n\n*   Remove deprecated `--enable-api-cors` daemon flag [moby/moby#34821](https://github.com/moby/moby/pull/34821)",
  "title": "Docker Engine 17.09 release notes | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/cache/backends/local/",
  "markdown": "# Local cache | Docker Docs\n\nThe `local` cache store is a simple cache option that stores your cache as files in a directory on your filesystem, using an [OCI image layout](https://github.com/opencontainers/image-spec/blob/main/image-layout.md) for the underlying directory structure. Local cache is a good choice if you're just testing, or if you want the flexibility to self-manage a shared storage solution.\n\nThe following table describes the available CSV parameters that you can pass to `--cache-to` and `--cache-from`.\n\n| Name | Option | Type | Default | Description |\n| --- | --- | --- | --- | --- |\n| `src` | `cache-from` | String |     | Path of the local directory where cache gets imported from. |\n| `digest` | `cache-from` | String |     | Digest of manifest to import, see [cache versioning](#cache-versioning). |\n| `dest` | `cache-to` | String |     | Path of the local directory where cache gets exported to. |\n| `mode` | `cache-to` | `min`,`max` | `min` | Cache layers to export, see [cache mode](https://docs.docker.com/build/cache/backends/#cache-mode). |\n| `oci-mediatypes` | `cache-to` | `true`,`false` | `true` | Use OCI media types in exported manifests, see [OCI media types](https://docs.docker.com/build/cache/backends/#oci-media-types). |\n| `compression` | `cache-to` | `gzip`,`estargz`,`zstd` | `gzip` | Compression type, see [cache compression](https://docs.docker.com/build/cache/backends/#cache-compression). |\n| `compression-level` | `cache-to` | `0..22` |     | Compression level, see [cache compression](https://docs.docker.com/build/cache/backends/#cache-compression). |\n| `force-compression` | `cache-to` | `true`,`false` | `false` | Forcibly apply compression, see [cache compression](https://docs.docker.com/build/cache/backends/#cache-compression). |\n| `ignore-error` | `cache-to` | Boolean | `false` | Ignore errors caused by failed cache exports. |\n\nIf the `src` cache doesn't exist, then the cache import step will fail, but the build continues.\n\nThis section describes how versioning works for caches on a local filesystem, and how you can use the `digest` parameter to use older versions of cache.\n\nIf you inspect the cache directory manually, you can see the resulting OCI image layout:\n\nLike other cache types, local cache gets replaced on export, by replacing the contents of the `index.json` file. However, previous caches will still be available in the `blobs` directory. These old caches are addressable by digest, and kept indefinitely. Therefore, the size of the local cache will continue to grow (see [`moby/buildkit#1896`](https://github.com/moby/buildkit/issues/1896) for more information).\n\nWhen importing cache using `--cache-to`, you can specify the `digest` parameter to force loading an older version of the cache, for example:\n\nFor an introduction to caching see [Docker build cache](https://docs.docker.com/build/cache/).\n\nFor more information on the `local` cache backend, see the [BuildKit README](https://github.com/moby/buildkit#local-directory-1).",
  "title": "Local cache | Docker Docs\n",
  "description": "Manage build cache with Amazon S3 buckets",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/17.07/",
  "markdown": "# Docker Engine 17.07 release notes\n\n2017-08-29\n\n### [API & Client](#api--client)\n\n*   Add support for proxy configuration in config.json [docker/cli#93](https://github.com/docker/cli/pull/93)\n*   Enable pprof/debug endpoints by default [moby/moby#32453](https://github.com/moby/moby/pull/32453)\n*   Passwords can now be passed using `STDIN` using the new `--password-stdin` flag on `docker login` [docker/cli#271](https://github.com/docker/cli/pull/271)\n\n*   Add `--detach` to docker scale [docker/cli#243](https://github.com/docker/cli/pull/243)\n\n*   Prevent `docker logs --no-stream` from hanging due to non-existing containers [moby/moby#34004](https://github.com/moby/moby/pull/34004)\n\n*   Fix `docker stack ps` printing error to `stdout` instead of `stderr` [docker/cli#298](https://github.com/docker/cli/pull/298)\n\n*   Fix progress bar being stuck on `docker service create` if an error occurs during deploy [docker/cli#259](https://github.com/docker/cli/pull/259)\n*   Improve presentation of progress bars in interactive mode [docker/cli#260](https://github.com/docker/cli/pull/260) [docker/cli#237](https://github.com/docker/cli/pull/237)\n*   Print a warning if `docker login --password` is used, and recommend `--password-stdin` [docker/cli#270](https://github.com/docker/cli/pull/270)\n*   Make API version negotiation more robust [moby/moby#33827](https://github.com/moby/moby/pull/33827)\n*   Hide `--detach` when connected to daemons older than Docker 17.05 [docker/cli#219](https://github.com/docker/cli/pull/219)\n\n*   Add `scope` filter in `GET /networks/(id or name)` [moby/moby#33630](https://github.com/moby/moby/pull/33630)\n\n### [Builder](#builder)\n\n*   Implement long running interactive session and sending build context incrementally [moby/moby#32677](https://github.com/moby/moby/pull/32677) [docker/cli#231](https://github.com/docker/cli/pull/231) [moby/moby#33859](https://github.com/moby/moby/pull/33859)\n*   Warn on empty continuation lines [moby/moby#33719](https://github.com/moby/moby/pull/33719)\n\n*   Fix `.dockerignore` entries with a leading `/` not matching anything [moby/moby#32088](https://github.com/moby/moby/pull/32088)\n\n### [Logging](#logging)\n\n*   Fix wrong filemode for rotate log files [moby/moby#33926](https://github.com/moby/moby/pull/33926)\n*   Fix stderr logging for journald and syslog [moby/moby#33832](https://github.com/moby/moby/pull/33832)\n\n### [Runtime](#runtime)\n\n*   Allow stopping of paused container [moby/moby#34027](https://github.com/moby/moby/pull/34027)\n\n*   Add quota support for the overlay2 storage driver [moby/moby#32977](https://github.com/moby/moby/pull/32977)\n\n*   Remove container locks on `docker ps` [moby/moby#31273](https://github.com/moby/moby/pull/31273)\n*   Store container names in memdb [moby/moby#33886](https://github.com/moby/moby/pull/33886)\n*   Fix race condition between `docker exec` and `docker pause` [moby/moby#32881](https://github.com/moby/moby/pull/32881)\n*   Devicemapper: Rework logging and add `--storage-opt dm.libdm_log_level` [moby/moby#33845](https://github.com/moby/moby/pull/33845)\n*   Devicemapper: Prevent \"device in use\" errors if deferred removal is enabled, but not deferred deletion [moby/moby#33877](https://github.com/moby/moby/pull/33877)\n*   Devicemapper: Use KeepAlive to prevent tasks being garbage-collected while still in use [moby/moby#33376](https://github.com/moby/moby/pull/33376)\n*   Report intermediate prune results if prune is cancelled [moby/moby#33979](https://github.com/moby/moby/pull/33979)\n\n*   Fix run `docker rename <container-id> new_name` concurrently resulting in the having multiple names [moby/moby#33940](https://github.com/moby/moby/pull/33940)\n\n*   Fix file-descriptor leak and error handling [moby/moby#33713](https://github.com/moby/moby/pull/33713)\n\n*   Fix SIGSEGV when running containers [docker/cli#303](https://github.com/docker/cli/pull/303)\n\n*   Prevent a goroutine leak when healthcheck gets stopped [moby/moby#33781](https://github.com/moby/moby/pull/33781)\n*   Image: Improve store locking [moby/moby#33755](https://github.com/moby/moby/pull/33755)\n*   Fix Btrfs quota groups not being removed when container is destroyed [moby/moby#29427](https://github.com/moby/moby/pull/29427)\n*   Libcontainerd: fix defunct containerd processes not being properly reaped [moby/moby#33419](https://github.com/moby/moby/pull/33419)\n*   Preparations for Linux Containers on Windows\n    *   LCOW: Dedicated scratch space for service VM utilities [moby/moby#33809](https://github.com/moby/moby/pull/33809)\n    *   LCOW: Support most operations excluding remote filesystem [moby/moby#33241](https://github.com/moby/moby/pull/33241) [moby/moby#33826](https://github.com/moby/moby/pull/33826)\n    *   LCOW: Change directory from lcow to \"Linux Containers\" [moby/moby#33835](https://github.com/moby/moby/pull/33835)\n    *   LCOW: pass command arguments without extra quoting [moby/moby#33815](https://github.com/moby/moby/pull/33815)\n    *   LCOW: Updates necessary due to platform schema change [moby/moby#33785](https://github.com/moby/moby/pull/33785)\n\n### [Swarm mode](#swarm-mode)\n\n*   Initial support for plugable secret backends [moby/moby#34157](https://github.com/moby/moby/pull/34157) [moby/moby#34123](https://github.com/moby/moby/pull/34123)\n*   Sort swarm stacks and nodes using natural sorting [docker/cli#315](https://github.com/docker/cli/pull/315)\n*   Make engine support cluster config event [moby/moby#34032](https://github.com/moby/moby/pull/34032)\n*   Only pass a join address when in the process of joining a cluster [moby/moby#33361](https://github.com/moby/moby/pull/33361)\n*   Fix error during service creation if a network with the same name exists both as \"local\" and \"swarm\" scoped network [docker/cli#184](https://github.com/docker/cli/pull/184)\n*   (experimental) Add support for plugins on swarm [moby/moby#33575](https://github.com/moby/moby/pull/33575)",
  "title": "Docker Engine 17.07 release notes | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/cache/backends/registry/",
  "markdown": "# Registry cache | Docker Docs\n\nThe `registry` cache storage can be thought of as an extension to the `inline` cache. Unlike the `inline` cache, the `registry` cache is entirely separate from the image, which allows for more flexible usage - `registry`\\-backed cache can do everything that the inline cache can do, and more:\n\n*   Allows for separating the cache and resulting image artifacts so that you can distribute your final image without the cache inside.\n*   It can efficiently cache multi-stage builds in `max` mode, instead of only the final stage.\n*   It works with other exporters for more flexibility, instead of only the `image` exporter.\n\nThis cache storage backend is not supported with the default `docker` driver. To use this feature, create a new builder using a different driver. See [Build drivers](https://docs.docker.com/build/drivers/) for more information.\n\nUnlike the simpler `inline` cache, the `registry` cache supports several configuration parameters:\n\nThe following table describes the available CSV parameters that you can pass to `--cache-to` and `--cache-from`.\n\n| Name | Option | Type | Default | Description |\n| --- | --- | --- | --- | --- |\n| `ref` | `cache-to`,`cache-from` | String |     | Full name of the cache image to import. |\n| `mode` | `cache-to` | `min`,`max` | `min` | Cache layers to export, see [cache mode](https://docs.docker.com/build/cache/backends/#cache-mode). |\n| `oci-mediatypes` | `cache-to` | `true`,`false` | `true` | Use OCI media types in exported manifests, see [OCI media types](https://docs.docker.com/build/cache/backends/#oci-media-types). |\n| `compression` | `cache-to` | `gzip`,`estargz`,`zstd` | `gzip` | Compression type, see [cache compression](https://docs.docker.com/build/cache/backends/#cache-compression). |\n| `compression-level` | `cache-to` | `0..22` |     | Compression level, see [cache compression](https://docs.docker.com/build/cache/backends/#cache-compression). |\n| `force-compression` | `cache-to` | `true`,`false` | `false` | Forcibly apply compression, see [cache compression](https://docs.docker.com/build/cache/backends/#cache-compression). |\n| `ignore-error` | `cache-to` | Boolean | `false` | Ignore errors caused by failed cache exports. |\n\nYou can choose any valid value for `ref`, as long as it's not the same as the target location that you push your image to. You might choose different tags (e.g. `foo/bar:latest` and `foo/bar:build-cache`), separate image names (e.g. `foo/bar` and `foo/bar-cache`), or even different repositories (e.g. `docker.io/foo/bar` and `ghcr.io/foo/bar`). It's up to you to decide the strategy that you want to use for separating your image from your cache images.\n\nIf the `--cache-from` target doesn't exist, then the cache import step will fail, but the build continues.\n\nFor an introduction to caching see [Docker build cache](https://docs.docker.com/build/cache/).\n\nFor more information on the `registry` cache backend, see the [BuildKit README](https://github.com/moby/buildkit#registry-push-image-and-cache-separately).",
  "title": "Registry cache | Docker Docs\n",
  "description": "Manage build cache with an OCI registry",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/17.06/",
  "markdown": "# Docker Engine 17.06 release notes\n\n2017-09-05\n\n### [Client](#client)\n\n*   Enable TCP keepalive in the client to prevent loss of connection [docker/cli#415](https://github.com/docker/cli/pull/415)\n\n### [Runtime](#runtime)\n\n*   Devmapper: ensure UdevWait is called after calls to setCookie [moby/moby#33732](https://github.com/moby/moby/pull/33732)\n*   Aufs: ensure diff layers are correctly removed to prevent leftover files from using up storage [moby/moby#34587](https://github.com/moby/moby/pull/34587)\n\n### [Swarm mode](#swarm-mode)\n\n*   Ignore PullOptions for running tasks [docker/swarmkit#2351](https://github.com/docker/swarmkit/pull/2351)\n\n2017-08-15\n\n### [Builder](#builder)\n\n*   Fix a regression, where `ADD` from remote URL's extracted archives [#89](https://github.com/docker/docker-ce/pull/89)\n*   Fix handling of remote \"git@\" notation [#100](https://github.com/docker/docker-ce/pull/100)\n*   Fix copy `--from` conflict with force pull [#86](https://github.com/docker/docker-ce/pull/86)\n\n### [Client](#client-1)\n\n*   Make pruning volumes optional when running `docker system prune`, and add a `--volumes` flag [#109](https://github.com/docker/docker-ce/pull/109)\n*   Show progress of replicated tasks before they are assigned [#97](https://github.com/docker/docker-ce/pull/97)\n*   Fix `docker wait` hanging if the container does not exist [#106](https://github.com/docker/docker-ce/pull/106)\n*   If `docker swarm ca` is called without the `--rotate` flag, warn if other flags are passed [#110](https://github.com/docker/docker-ce/pull/110)\n*   Fix API version negotiation not working if the daemon returns an error [#115](https://github.com/docker/docker-ce/pull/115)\n*   Print an error if \"until\" filter is combined with \"--volumes\" on system prune [#154](https://github.com/docker/docker-ce/pull/154)\n\n### [Logging](#logging)\n\n*   Fix stderr logging for `journald` and `syslog` [#95](https://github.com/docker/docker-ce/pull/95)\n*   Fix log readers can block writes indefinitely [#98](https://github.com/docker/docker-ce/pull/98)\n*   Fix `awslogs` driver repeating last event [#151](https://github.com/docker/docker-ce/pull/151)\n\n### [Networking](#networking)\n\n*   Fix issue with driver options not received by network drivers [#127](https://github.com/docker/docker-ce/pull/127)\n\n### [Plugins](#plugins)\n\n*   Make plugin removes more resilient to failure [#91](https://github.com/docker/docker-ce/pull/91)\n\n### [Runtime](#runtime-1)\n\n*   Prevent a `goroutine` leak when `healthcheck` gets stopped [#90](https://github.com/docker/docker-ce/pull/90)\n*   Do not error on relabel when relabel not supported [#92](https://github.com/docker/docker-ce/pull/92)\n*   Limit max backoff delay to 2 seconds for GRPC connection [#94](https://github.com/docker/docker-ce/pull/94)\n*   Fix issue preventing containers to run when memory cgroup was specified due to bug in certain kernels [#102](https://github.com/docker/docker-ce/pull/102)\n*   Fix container not responding to SIGKILL when paused [#102](https://github.com/docker/docker-ce/pull/102)\n*   Improve error message if an image for an incompatible OS is loaded [#108](https://github.com/docker/docker-ce/pull/108)\n*   Fix a handle leak in `go-winio` [#112](https://github.com/docker/docker-ce/pull/112)\n*   Fix issue upon upgrade, preventing docker from showing running containers when `--live-restore` is enabled [#117](https://github.com/docker/docker-ce/pull/117)\n*   Fix bug where services using secrets would fail to start on daemons using the `userns-remap` feature [#121](https://github.com/docker/docker-ce/pull/121)\n*   Fix error handling with `not-exist` errors on remove [#142](https://github.com/docker/docker-ce/pull/142)\n*   Fix REST API Swagger representation cannot be loaded with SwaggerUI [#156](https://github.com/docker/docker-ce/pull/156)\n\n### [Security](#security)\n\n*   Redact secret data on secret creation [#99](https://github.com/docker/docker-ce/pull/99)\n\n### [Swarm mode](#swarm-mode-1)\n\n*   Do not add duplicate platform information to service spec [#107](https://github.com/docker/docker-ce/pull/107)\n*   Cluster update and memory issue fixes [#114](https://github.com/docker/docker-ce/pull/114)\n*   Changing get network request to return predefined network in swarm [#150](https://github.com/docker/docker-ce/pull/150)\n\n2017-06-28\n\n> **Note**: Docker 17.06.0 has an issue in the image builder causing a change in the behavior of the `ADD` instruction of Dockerfile when referencing a remote `.tar.gz` file. The issue will be fixed in Docker 17.06.1.\n\n> **Note**: Starting with Docker CE 17.06, Ubuntu packages are also available for IBM Z using the s390x architecture.\n\n> **Note**: Docker 17.06 by default disables communication with legacy (v1) registries. If you require interaction with registries that have not yet migrated to the v2 protocol, set the `--disable-legacy-registry=false` daemon option. Interaction with v1 registries will be removed in Docker 17.12.\n\n### [Builder](#builder-1)\n\n*   Add `--iidfile` option to docker build. It allows specifying a location where to save the resulting image ID\n*   Allow specifying any remote ref in git checkout URLs [#32502](https://github.com/moby/moby/pull/32502)\n\n### [Client](#client-2)\n\n*   Add `--format` option to `docker stack ls` [#31557](https://github.com/moby/moby/pull/31557)\n*   Add support for labels in compose initiated builds [#32632](https://github.com/moby/moby/pull/32632) [#32972](https://github.com/moby/moby/pull/32972)\n*   Add `--format` option to `docker history` [#30962](https://github.com/moby/moby/pull/30962)\n*   Add `--format` option to `docker system df` [#31482](https://github.com/moby/moby/pull/31482)\n*   Allow specifying Nameservers and Search Domains in stack files [#32059](https://github.com/moby/moby/pull/32059)\n*   Add support for `read_only` service to `docker stack deploy` [#docker/cli/73](https://github.com/docker/cli/pull/73)\n\n*   Display Swarm cluster and node TLS information [#docker/cli/44](https://github.com/docker/cli/pull/44)\n\n*   Add support for placement preference to `docker stack deploy` [#docker/cli/35](https://github.com/docker/cli/pull/35)\n*   Add new `ca` subcommand to `docker swarm` to allow managing a swarm CA [#docker/cli/48](https://github.com/docker/cli/pull/48)\n*   Add credential-spec to compose [#docker/cli/71](https://github.com/docker/cli/pull/71)\n*   Add support for csv format options to `--network` and `--network-add` [#docker/cli/62](https://github.com/docker/cli/pull/62) [#33130](https://github.com/moby/moby/pull/33130)\n\n*   Fix stack compose bind-mount volumes on Windows [#docker/cli/136](https://github.com/docker/cli/pull/136)\n*   Correctly handle a Docker daemon without registry info [#docker/cli/126](https://github.com/docker/cli/pull/126)\n\n*   Allow `--detach` and `--quiet` flags when using --rollback [#docker/cli/144](https://github.com/docker/cli/pull/144)\n*   Remove deprecated `--email` flag from `docker login` [#docker/cli/143](https://github.com/docker/cli/pull/143)\n\n*   Adjusted `docker stats` memory output [#docker/cli/80](https://github.com/docker/cli/pull/80)\n\n### [Distribution](#distribution)\n\n*   Select digest over tag when both are provided during a pull [#33214](https://github.com/moby/moby/pull/33214)\n\n### [Logging](#logging-1)\n\n*   Add monitored resource type metadata for GCP logging driver [#32930](https://github.com/moby/moby/pull/32930)\n*   Add multiline processing to the AWS CloudWatch logs driver [#30891](https://github.com/moby/moby/pull/30891)\n\n### [Networking](#networking-1)\n\n*   Add Support swarm-mode services with node-local networks such as macvlan, ipvlan, bridge, host [#32981](https://github.com/moby/moby/pull/32981)\n*   Pass driver-options to network drivers on service creation [#32981](https://github.com/moby/moby/pull/33130)\n*   Isolate Swarm Control-plane traffic from Application data traffic using --data-path-addr [#32717](https://github.com/moby/moby/pull/32717)\n\n*   Several improvements to Service Discovery [#docker/libnetwork/1796](https://github.com/docker/libnetwork/pull/1796)\n\n### [Packaging](#packaging)\n\n*   Rely on `container-selinux` on Centos/Fedora/RHEL when available [#32437](https://github.com/moby/moby/pull/32437)\n\n### [Runtime](#runtime-2)\n\n*   Add build & engine info prometheus metrics [#32792](https://github.com/moby/moby/pull/32792)\n\n*   Update containerd to d24f39e203aa6be4944f06dd0fe38a618a36c764 [#33007](https://github.com/moby/moby/pull/33007)\n*   Update runc to 992a5be178a62e026f4069f443c6164912adbf09 [#33007](https://github.com/moby/moby/pull/33007)\n\n*   Add option to auto-configure blkdev for devmapper [#31104](https://github.com/moby/moby/pull/31104)\n*   Add log driver list to `docker info` [#32540](https://github.com/moby/moby/pull/32540)\n*   Add API endpoint to allow retrieving an image manifest [#32061](https://github.com/moby/moby/pull/32061)\n\n*   Do not remove container from memory on error with `forceremove` [#31012](https://github.com/moby/moby/pull/31012)\n\n*   Add support for metric plugins [#32874](https://github.com/moby/moby/pull/32874)\n\n*   Return an error when an invalid filter is given to `prune` commands [#33023](https://github.com/moby/moby/pull/33023)\n\n*   Add daemon option to allow pushing foreign layers [#33151](https://github.com/moby/moby/pull/33151)\n\n*   Fix an issue preventing containerd to be restarted after it died [#32986](https://github.com/moby/moby/pull/32986)\n\n*   Add cluster events to Docker event stream. [#32421](https://github.com/moby/moby/pull/32421)\n*   Add support for DNS search on windows [#33311](https://github.com/moby/moby/pull/33311)\n\n*   Upgrade to Go 1.8.3 [#33387](https://github.com/moby/moby/pull/33387)\n\n*   Prevent a containerd crash when journald is restarted [#containerd/930](https://github.com/containerd/containerd/pull/930)\n*   Fix healthcheck failures due to invalid environment variables [#33249](https://github.com/moby/moby/pull/33249)\n*   Prevent a directory to be created in lieu of the daemon socket when a container mounting it is to be restarted during a shutdown [#30348](https://github.com/moby/moby/pull/33330)\n*   Prevent a container to be restarted upon stop if its stop signal is set to `SIGKILL` [#33335](https://github.com/moby/moby/pull/33335)\n*   Ensure log drivers get passed the same filename to both StartLogging and StopLogging endpoints [#33583](https://github.com/moby/moby/pull/33583)\n*   Remove daemon data structure dump on `SIGUSR1` to avoid a panic [#33598](https://github.com/moby/moby/pull/33598)\n\n### [Security](#security-1)\n\n*   Allow personality with UNAME26 bit set in default seccomp profile [#32965](https://github.com/moby/moby/pull/32965)\n\n### [Swarm Mode](#swarm-mode-2)\n\n*   Add an option to allow specifying a different interface for the data traffic (as opposed to control traffic) [#32717](https://github.com/moby/moby/pull/32717)\n\n*   Allow specifying a secret location within the container [#32571](https://github.com/moby/moby/pull/32571)\n\n*   Add support for secrets on Windows [#32208](https://github.com/moby/moby/pull/32208)\n*   Add TLS Info to swarm info and node info endpoint [#32875](https://github.com/moby/moby/pull/32875)\n*   Add support for services to carry arbitrary config objects [#32336](https://github.com/moby/moby/pull/32336), [#docker/cli/45](https://github.com/docker/cli/pull/45), [#33169](https://github.com/moby/moby/pull/33169)\n*   Add API to rotate swarm CA certificate [#32993](https://github.com/moby/moby/pull/32993)\n\n*   Service digest pining is now handled client side [#32388](https://github.com/moby/moby/pull/32388), [#33239](https://github.com/moby/moby/pull/33239)\n\n*   Placement now also take platform in account [#33144](https://github.com/moby/moby/pull/33144)\n\n*   Fix possible hang when joining fails [#docker-ce/19](https://github.com/docker/docker-ce/pull/19)\n*   Fix an issue preventing external CA to be accepted [#33341](https://github.com/moby/moby/pull/33341)\n*   Fix possible orchestration panic in mixed version clusters [#swarmkit/2233](https://github.com/docker/swarmkit/pull/2233)\n*   Avoid assigning duplicate IPs during initialization [#swarmkit/2237](https://github.com/docker/swarmkit/pull/2237)\n\n### [Deprecation](#deprecation)\n\n*   Disable legacy registry (v1) by default [#33629](https://github.com/moby/moby/pull/33629)",
  "title": "Docker Engine 17.06 release notes | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/cache/backends/gha/",
  "markdown": "# GitHub Actions cache | Docker Docs\n\n> **Experimental**\n> \n> This is an experimental feature. The interface and behavior are unstable and may change in future releases.\n\nThe GitHub Actions cache utilizes the [GitHub-provided Action's cache](https://github.com/actions/cache) or other cache services supporting the GitHub Actions cache protocol. This is the recommended cache to use inside your GitHub Actions workflows, as long as your use case falls within the [size and usage limits set by GitHub](https://docs.github.com/en/actions/using-workflows/caching-dependencies-to-speed-up-workflows#usage-limits-and-eviction-policy).\n\nThis cache storage backend is not supported with the default `docker` driver. To use this feature, create a new builder using a different driver. See [Build drivers](https://docs.docker.com/build/drivers/) for more information.\n\nThe following table describes the available CSV parameters that you can pass to `--cache-to` and `--cache-from`.\n\n| Name | Option | Type | Default | Description |\n| --- | --- | --- | --- | --- |\n| `url` | `cache-to`,`cache-from` | String | `$ACTIONS_CACHE_URL` | Cache server URL, see [authentication](#authentication). |\n| `token` | `cache-to`,`cache-from` | String | `$ACTIONS_RUNTIME_TOKEN` | Access token, see [authentication](#authentication). |\n| `scope` | `cache-to`,`cache-from` | String | `buildkit` | Which scope cache object belongs to, see [scope](#scope) |\n| `mode` | `cache-to` | `min`,`max` | `min` | Cache layers to export, see [cache mode](https://docs.docker.com/build/cache/backends/#cache-mode). |\n| `ignore-error` | `cache-to` | Boolean | `false` | Ignore errors caused by failed cache exports. |\n| `timeout` | `cache-to`,`cache-from` | String | `10m` | Max duration for importing or exporting cache before it's timed out. |\n| `repository` | `cache-to` | String |     | GitHub repository used for cache storage. |\n| `ghtoken` | `cache-to` | String |     | GitHub token required for accessing the GitHub API. |\n\nIf the `url` or `token` parameters are left unspecified, the `gha` cache backend will fall back to using environment variables. If you invoke the `docker buildx` command manually from an inline step, then the variables must be manually exposed. Consider using the [`crazy-max/ghaction-github-runtime`](https://github.com/crazy-max/ghaction-github-runtime), GitHub Action as a helper for exposing the variables.\n\nScope is a key used to identify the cache object. By default, it is set to `buildkit`. If you build multiple images, each build will overwrite the cache of the previous, leaving only the final cache.\n\nTo preserve the cache for multiple builds, you can specify this scope attribute with a specific name. In the following example, the cache is set to the image name, to ensure each image gets its own cache:\n\nGitHub's [cache access restrictions](https://docs.github.com/en/actions/advanced-guides/caching-dependencies-to-speed-up-workflows#restrictions-for-accessing-a-cache), still apply. Only the cache for the current branch, the base branch and the default branch is accessible by a workflow.\n\n### [Using `docker/build-push-action`](#using-dockerbuild-push-action)\n\nWhen using the [`docker/build-push-action`](https://github.com/docker/build-push-action), the `url` and `token` parameters are automatically populated. No need to manually specify them, or include any additional workarounds.\n\nFor example:\n\nGitHub's [usage limits and eviction policy](https://docs.github.com/en/actions/using-workflows/caching-dependencies-to-speed-up-workflows#usage-limits-and-eviction-policy) causes stale cache entries to be removed after a certain period of time. By default, the `gha` cache backend uses the GitHub Actions cache API to check the status of cache entries.\n\nThe GitHub Actions cache API is subject to rate limiting if you make too many requests in a short period of time, which may happen as a result of cache lookups during a build using the `gha` cache backend.\n\nTo mitigate this issue, you can supply a GitHub token to BuildKit. This lets BuildKit utilize the standard GitHub API for checking cache keys, thereby reducing the number of requests made to the cache API.\n\nTo provide a GitHub token, you can use the `ghtoken` parameter, and a `repository` parameter to specify the repository to use for cache storage. The `ghtoken` parameter is a GitHub token with the `repo` scope, which is required to access the GitHub Actions cache API.\n\nThe `ghtoken` parameter is automatically set to the value of `secrets.GITHUB_TOKEN` when you build with the `docker/build-push-action` action. You can also set the `ghtoken` parameter manually using the `github-token` input, as shown in the following example:\n\nFor an introduction to caching see [Docker build cache](https://docs.docker.com/build/cache/).\n\nFor more information on the `gha` cache backend, see the [BuildKit README](https://github.com/moby/buildkit#github-actions-cache-experimental).\n\nFor more information about using GitHub Actions with Docker, see [Introduction to GitHub Actions](https://docs.docker.com/build/ci/github-actions/)",
  "title": "GitHub Actions cache | Docker Docs\n",
  "description": "Use the GitHub Actions cache to manage your build cache in CI",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/cache/backends/azblob/",
  "markdown": "# Azure Blob Storage cache | Docker Docs\n\n> **Experimental**\n> \n> This is an experimental feature. The interface and behavior are unstable and may change in future releases.\n\nThe `azblob` cache store uploads your resulting build cache to [Azure's blob storage service](https://azure.microsoft.com/en-us/services/storage/blobs/).\n\nThis cache storage backend is not supported with the default `docker` driver. To use this feature, create a new builder using a different driver. See [Build drivers](https://docs.docker.com/build/drivers/) for more information.\n\nThe following table describes the available CSV parameters that you can pass to `--cache-to` and `--cache-from`.\n\n| Name | Option | Type | Default | Description |\n| --- | --- | --- | --- | --- |\n| `name` | `cache-to`,`cache-from` | String |     | Required. The name of the cache image. |\n| `account_url` | `cache-to`,`cache-from` | String |     | Base URL of the storage account. |\n| `secret_access_key` | `cache-to`,`cache-from` | String |     | Blob storage account key, see [authentication](#authentication). |\n| `mode` | `cache-to` | `min`,`max` | `min` | Cache layers to export, see [cache mode](https://docs.docker.com/build/cache/backends/#cache-mode). |\n| `ignore-error` | `cache-to` | Boolean | `false` | Ignore errors caused by failed cache exports. |\n\nThe `secret_access_key`, if left unspecified, is read from environment variables on the BuildKit server following the scheme for the [Azure Go SDK](https://docs.microsoft.com/en-us/azure/developer/go/azure-sdk-authentication). The environment variables are read from the server, not the Buildx client.\n\nFor an introduction to caching see [Docker build cache](https://docs.docker.com/build/cache/).\n\nFor more information on the `azblob` cache backend, see the [BuildKit README](https://github.com/moby/buildkit#azure-blob-storage-cache-experimental).",
  "title": "Azure Blob Storage cache | Docker Docs\n",
  "description": "Manage build cache with Azure blob storage",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/17.05/",
  "markdown": "# Docker Engine 17.05 release notes\n\n2017-05-04\n\n### [Builder](#builder)\n\n*   Add multi-stage build support [#31257](https://github.com/docker/docker/pull/31257) [#32063](https://github.com/docker/docker/pull/32063)\n*   Allow using build-time args (`ARG`) in `FROM` [#31352](https://github.com/docker/docker/pull/31352)\n*   Add an option for specifying build target [#32496](https://github.com/docker/docker/pull/32496)\n\n*   Accept `-f -` to read Dockerfile from `stdin`, but use local context for building [#31236](https://github.com/docker/docker/pull/31236)\n*   The values of default build time arguments (e.g `HTTP_PROXY`) are no longer displayed in docker image history unless a corresponding `ARG` instruction is written in the Dockerfile. [#31584](https://github.com/docker/docker/pull/31584)\n\n*   Fix setting command if a custom shell is used in a parent image [#32236](https://github.com/docker/docker/pull/32236)\n*   Fix `docker build --label` when the label includes single quotes and a space [#31750](https://github.com/docker/docker/pull/31750)\n\n### [Client](#client)\n\n*   Add `--mount` flag to `docker run` and `docker create` [#32251](https://github.com/docker/docker/pull/32251)\n*   Add `--type=secret` to `docker inspect` [#32124](https://github.com/docker/docker/pull/32124)\n*   Add `--format` option to `docker secret ls` [#31552](https://github.com/docker/docker/pull/31552)\n*   Add `--filter` option to `docker secret ls` [#30810](https://github.com/docker/docker/pull/30810)\n*   Add `--filter scope=<swarm|local>` to `docker network ls` [#31529](https://github.com/docker/docker/pull/31529)\n*   Add `--cpus` support to `docker update` [#31148](https://github.com/docker/docker/pull/31148)\n*   Add label filter to `docker system prune` and other `prune` commands [#30740](https://github.com/docker/docker/pull/30740)\n*   `docker stack rm` now accepts multiple stacks as input [#32110](https://github.com/docker/docker/pull/32110)\n*   Improve `docker version --format` option when the client has downgraded the API version [#31022](https://github.com/docker/docker/pull/31022)\n*   Prompt when using an encrypted client certificate to connect to a docker daemon [#31364](https://github.com/docker/docker/pull/31364)\n*   Display created tags on successful `docker build` [#32077](https://github.com/docker/docker/pull/32077)\n*   Cleanup compose convert error messages [#32087](https://github.com/moby/moby/pull/32087)\n\n### [Contrib](#contrib)\n\n*   Add support for building docker debs for Ubuntu 17.04 Zesty on amd64 [#32435](https://github.com/docker/docker/pull/32435)\n\n### [Daemon](#daemon)\n\n*   Fix `--api-cors-header` being ignored if `--api-enable-cors` is not set [#32174](https://github.com/docker/docker/pull/32174)\n*   Cleanup docker tmp dir on start [#31741](https://github.com/docker/docker/pull/31741)\n*   Deprecate `--graph` flag in favor or `--data-root` [#28696](https://github.com/docker/docker/pull/28696)\n\n### [Logging](#logging)\n\n*   Add support for logging driver plugins [#28403](https://github.com/docker/docker/pull/28403)\n\n*   Add support for showing logs of individual tasks to `docker service logs`, and add `/task/{id}/logs` REST endpoint [#32015](https://github.com/docker/docker/pull/32015)\n*   Add `--log-opt env-regex` option to match environment variables using a regular expression [#27565](https://github.com/docker/docker/pull/27565)\n\n### [Networking](#networking)\n\n*   Allow user to replace, and customize the ingress network [#31714](https://github.com/docker/docker/pull/31714)\n\n*   Fix UDP traffic in containers not working after the container is restarted [#32505](https://github.com/docker/docker/pull/32505)\n*   Fix files being written to `/var/lib/docker` if a different data-root is set [#32505](https://github.com/docker/docker/pull/32505)\n\n### [Runtime](#runtime)\n\n*   Ensure health probe is stopped when a container exits [#32274](https://github.com/docker/docker/pull/32274)\n\n### [Swarm Mode](#swarm-mode)\n\n*   Add update/rollback order for services (`--update-order` / `--rollback-order`) [#30261](https://github.com/docker/docker/pull/30261)\n*   Add support for synchronous `service create` and `service update` [#31144](https://github.com/docker/docker/pull/31144)\n*   Add support for \"grace periods\" on healthchecks through the `HEALTHCHECK --start-period` and `--health-start-period` flag to `docker service create`, `docker service update`, `docker create`, and `docker run` to support containers with an initial startup time [#28938](https://github.com/docker/docker/pull/28938)\n\n*   `docker service create` now omits fields that are not specified by the user, when possible. This will allow defaults to be applied inside the manager [#32284](https://github.com/docker/docker/pull/32284)\n*   `docker service inspect` now shows default values for fields that are not specified by the user [#32284](https://github.com/docker/docker/pull/32284)\n*   Move `docker service logs` out of experimental [#32462](https://github.com/docker/docker/pull/32462)\n*   Add support for Credential Spec and SELinux to services to the API [#32339](https://github.com/docker/docker/pull/32339)\n*   Add `--entrypoint` flag to `docker service create` and `docker service update` [#29228](https://github.com/docker/docker/pull/29228)\n*   Add `--network-add` and `--network-rm` to `docker service update` [#32062](https://github.com/docker/docker/pull/32062)\n*   Add `--credential-spec` flag to `docker service create` and `docker service update` [#32339](https://github.com/docker/docker/pull/32339)\n*   Add `--filter mode=<global|replicated>` to `docker service ls` [#31538](https://github.com/docker/docker/pull/31538)\n*   Resolve network IDs on the client side, instead of in the daemon when creating services [#32062](https://github.com/docker/docker/pull/32062)\n*   Add `--format` option to `docker node ls` [#30424](https://github.com/docker/docker/pull/30424)\n*   Add `--prune` option to `docker stack deploy` to remove services that are no longer defined in the docker-compose file [#31302](https://github.com/docker/docker/pull/31302)\n*   Add `PORTS` column for `docker service ls` when using `ingress` mode [#30813](https://github.com/docker/docker/pull/30813)\n\n*   Fix unnescessary re-deploying of tasks when environment-variables are used [#32364](https://github.com/docker/docker/pull/32364)\n*   Fix `docker stack deploy` not supporting `endpoint_mode` when deploying from a docker compose file [#32333](https://github.com/docker/docker/pull/32333)\n*   Proceed with startup if cluster component cannot be created to allow recovering from a broken swarm setup [#31631](https://github.com/docker/docker/pull/31631)\n\n### [Security](#security)\n\n*   Allow setting SELinux type or MCS labels when using `--ipc=container:` or `--ipc=host` [#30652](https://github.com/docker/docker/pull/30652)\n\n### [Deprecation](#deprecation)\n\n*   Deprecate `--api-enable-cors` daemon flag. This flag was marked deprecated in Docker 1.6.0 but not listed in deprecated features [#32352](https://github.com/docker/docker/pull/32352)\n*   Remove Ubuntu 12.04 (Precise Pangolin) as supported platform. Ubuntu 12.04 is EOL, and no longer receives updates [#32520](https://github.com/docker/docker/pull/32520)",
  "title": "Docker Engine 17.05 release notes | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/17.03/",
  "markdown": "# Docker Engine 17.03 release notes\n\n2018-08-30\n\n### [Runtime](#runtime)\n\n*   Update go-connections to d217f8e [#28](https://github.com/docker/engine/pull/28)\n\n2017-05-29\n\n### [Networking](#networking)\n\n*   Fix a concurrency issue preventing network creation [#33273](https://github.com/moby/moby/pull/33273)\n\n### [Runtime](#runtime-1)\n\n*   Relabel secrets path to avoid a Permission Denied on selinux enabled systems [#33236](https://github.com/moby/moby/pull/33236) (ref [#32529](https://github.com/moby/moby/pull/32529)\n*   Fix cases where local volume were not properly relabeled if needed [#33236](https://github.com/moby/moby/pull/33236) (ref [#29428](https://github.com/moby/moby/pull/29428))\n*   Fix an issue while upgrading if a plugin rootfs was still mounted [#33236](https://github.com/moby/moby/pull/33236) (ref [#32525](https://github.com/moby/moby/pull/32525))\n*   Fix an issue where volume wouldn't default to the `rprivate` propagation mode [#33236](https://github.com/moby/moby/pull/33236) (ref [#32851](https://github.com/moby/moby/pull/32851))\n*   Fix a panic that could occur when a volume driver could not be retrieved [#33236](https://github.com/moby/moby/pull/33236) (ref [#32347](https://github.com/moby/moby/pull/32347))\n\n*   Add a warning in `docker info` when the `overlay` or `overlay2` graphdriver is used on a filesystem without `d_type` support [#33236](https://github.com/moby/moby/pull/33236) (ref [#31290](https://github.com/moby/moby/pull/31290))\n\n*   Fix an issue with backporting mount spec to older volumes [#33207](https://github.com/moby/moby/pull/33207)\n*   Fix issue where a failed unmount can lead to data loss on local volume remove [#33120](https://github.com/moby/moby/pull/33120)\n\n### [Swarm Mode](#swarm-mode)\n\n*   Fix a case where tasks could get killed unexpectedly [#33118](https://github.com/moby/moby/pull/33118)\n*   Fix an issue preventing to deploy services if the registry cannot be reached despite the needed images being locally present [#33117](https://github.com/moby/moby/pull/33117)\n\n2017-03-27\n\n### [Remote API (v1.27) & Client](#remote-api-v127--client)\n\n*   Fix autoremove on older api [#31692](https://github.com/docker/docker/pull/31692)\n*   Fix default network customization for a stack [#31258](https://github.com/docker/docker/pull/31258/)\n*   Correct CPU usage calculation in presence of offline CPUs and newer Linux [#31802](https://github.com/docker/docker/pull/31802)\n*   Fix issue where service healthcheck is `{}` in remote API [#30197](https://github.com/docker/docker/pull/30197)\n\n### [Runtime](#runtime-2)\n\n*   Update runc to 54296cf40ad8143b62dbcaa1d90e520a2136ddfe [#31666](https://github.com/docker/docker/pull/31666)\n*   Ignore cgroup2 mountpoints [opencontainers/runc#1266](https://github.com/opencontainers/runc/pull/1266)\n*   Update containerd to 4ab9917febca54791c5f071a9d1f404867857fcc [#31662](https://github.com/docker/docker/pull/31662) [#31852](https://github.com/docker/docker/pull/31852)\n*   Register healtcheck service before calling restore() [docker/containerd#609](https://github.com/docker/containerd/pull/609)\n*   Fix `docker exec` not working after unattended upgrades that reload apparmor profiles [#31773](https://github.com/docker/docker/pull/31773)\n*   Fix unmounting layer without merge dir with Overlay2 [#31069](https://github.com/docker/docker/pull/31069)\n*   Do not ignore \"volume in use\" errors when force-delete [#31450](https://github.com/docker/docker/pull/31450)\n\n### [Swarm Mode](#swarm-mode-1)\n\n*   Update swarmkit to 17756457ad6dc4d8a639a1f0b7a85d1b65a617bb [#31807](https://github.com/docker/docker/pull/31807)\n*   Scheduler now correctly considers tasks which have been assigned to a node but aren't yet running [docker/swarmkit#1980](https://github.com/docker/swarmkit/pull/1980)\n*   Allow removal of a network when only dead tasks reference it [docker/swarmkit#2018](https://github.com/docker/swarmkit/pull/2018)\n*   Retry failed network allocations less aggressively [docker/swarmkit#2021](https://github.com/docker/swarmkit/pull/2021)\n*   Avoid network allocation for tasks that are no longer running [docker/swarmkit#2017](https://github.com/docker/swarmkit/pull/2017)\n*   Bookkeeping fixes inside network allocator allocator [docker/swarmkit#2019](https://github.com/docker/swarmkit/pull/2019) [docker/swarmkit#2020](https://github.com/docker/swarmkit/pull/2020)\n\n### [Windows](#windows)\n\n*   Cleanup HCS on restore [#31503](https://github.com/docker/docker/pull/31503)\n\n2017-03-01\n\n**IMPORTANT**: Starting with this release, Docker is on a monthly release cycle and uses a new YY.MM versioning scheme to reflect this. Two channels are available: monthly and quarterly. Any given monthly release will only receive security and bugfixes until the next monthly release is available. Quarterly releases receive security and bugfixes for 4 months after initial release. This release includes bugfixes for 1.13.1 but there are no major feature additions and the API version stays the same. Upgrading from Docker 1.13.1 to 17.03.0 is expected to be simple and low-risk.\n\n### [Client](#client)\n\n*   Fix panic in `docker stats --format` [#30776](https://github.com/docker/docker/pull/30776)\n\n### [Contrib](#contrib)\n\n*   Update various `bash` and `zsh` completion scripts [#30823](https://github.com/docker/docker/pull/30823), [#30945](https://github.com/docker/docker/pull/30945) and more...\n*   Block obsolete socket families in default seccomp profile - mitigates unpatched kernels' CVE-2017-6074 [#29076](https://github.com/docker/docker/pull/29076)\n\n### [Networking](#networking-1)\n\n*   Fix bug on overlay encryption keys rotation in cross-datacenter swarm [#30727](https://github.com/docker/docker/pull/30727)\n*   Fix side effect panic in overlay encryption and network control plane communication failure (\"No installed keys could decrypt the message\") on frequent swarm leader re-election [#25608](https://github.com/docker/docker/pull/25608)\n*   Several fixes around system responsiveness and datapath programming when using overlay network with external kv-store [docker/libnetwork#1639](https://github.com/docker/libnetwork/pull/1639), [docker/libnetwork#1632](https://github.com/docker/libnetwork/pull/1632) and more...\n*   Discard incoming plain vxlan packets for encrypted overlay network [#31170](https://github.com/docker/docker/pull/31170)\n*   Release the network attachment on allocation failure [#31073](https://github.com/docker/docker/pull/31073)\n*   Fix port allocation when multiple published ports map to the same target port [docker/swarmkit#1835](https://github.com/docker/swarmkit/pull/1835)\n\n### [Runtime](#runtime-3)\n\n*   Fix a deadlock in docker logs [#30223](https://github.com/docker/docker/pull/30223)\n*   Fix CPU spin waiting for log write events [#31070](https://github.com/docker/docker/pull/31070)\n*   Fix a possible crash when using journald [#31231](https://github.com/docker/docker/pull/31231) [#31263](https://github.com/docker/docker/pull/31263)\n*   Fix a panic on close of nil channel [#31274](https://github.com/docker/docker/pull/31274)\n*   Fix duplicate mount point for `--volumes-from` in `docker run` [#29563](https://github.com/docker/docker/pull/29563)\n*   Fix `--cache-from` does not cache last step [#31189](https://github.com/docker/docker/pull/31189)\n\n### [Swarm Mode](#swarm-mode-2)\n\n*   Shutdown leaks an error when the container was never started [#31279](https://github.com/docker/docker/pull/31279)\n*   Fix possibility of tasks getting stuck in the \"NEW\" state during a leader failover [docker/swarmkit#1938](https://github.com/docker/swarmkit/pull/1938)\n*   Fix extraneous task creations for global services that led to confusing replica counts in `docker service ls` [docker/swarmkit#1957](https://github.com/docker/swarmkit/pull/1957)\n*   Fix problem that made rolling updates slow when `task-history-limit` was set to 1 [docker/swarmkit#1948](https://github.com/docker/swarmkit/pull/1948)\n*   Restart tasks elsewhere, if appropriate, when they are shut down as a result of nodes no longer satisfying constraints [docker/swarmkit#1958](https://github.com/docker/swarmkit/pull/1958)\n*   (experimental)",
  "title": "Docker Engine 17.03 release notes | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/bake/",
  "markdown": "# Buildx Bake | Docker Docs\n\n> **Experimental**\n> \n> Bake is an experimental feature, and we are looking for [feedback from users](https://github.com/docker/buildx/issues).\n\nBake is a feature of Docker Buildx that lets you define your build configuraton using a declarative file, as opposed to specifying a complex CLI expression. It also lets you run multiple builds concurrently with a single invocation.\n\nA Bake file can be written in HCL, JSON, or YAML formats, where the YAML format is an extension of a Docker Compose file. Here's an example Bake file in HCL format:\n\nThe `group` block defines a group of targets that can be built concurrently. Each `target` block defines a build target with its own configuration, such as the build context, Dockerfile, and tags.\n\nTo invoke a build using the above Bake file, you can run:\n\nThis executes the `default` group, which builds the `frontend` and `backend` targets concurrently.\n\nTo learn how to get started with Bake, head over to the [Bake introduction](https://docs.docker.com/build/bake/introduction/).",
  "title": "Buildx Bake | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/cache/backends/s3/",
  "markdown": "# Amazon S3 cache | Docker Docs\n\n> **Experimental**\n> \n> This is an experimental feature. The interface and behavior are unstable and may change in future releases.\n\nThe `s3` cache storage uploads your resulting build cache to [Amazon S3 file storage service](https://aws.amazon.com/s3/) or other S3-compatible services, such as [MinIO](https://min.io/).\n\nThis cache storage backend is not supported with the default `docker` driver. To use this feature, create a new builder using a different driver. See [Build drivers](https://docs.docker.com/build/drivers/) for more information.\n\nThe following table describes the available CSV parameters that you can pass to `--cache-to` and `--cache-from`.\n\n| Name | Option | Type | Default | Description |\n| --- | --- | --- | --- | --- |\n| `region` | `cache-to`,`cache-from` | String |     | Required. Geographic location. |\n| `bucket` | `cache-to`,`cache-from` | String |     | Required. Name of the S3 bucket. |\n| `name` | `cache-to`,`cache-from` | String |     | Name of the cache image. |\n| `endpoint_url` | `cache-to`,`cache-from` | String |     | Endpoint of the S3 bucket. |\n| `blobs_prefix` | `cache-to`,`cache-from` | String |     | Prefix to prepend to blob filenames. |\n| `manifests_prefix` | `cache-to`,`cache-from` | String |     | Prefix to prepend on manifest filenames. |\n| `use_path_style` | `cache-to`,`cache-from` | Boolean | `false` | When `true`, uses `bucket` in the URL instead of hostname. |\n| `access_key_id` | `cache-to`,`cache-from` | String |     | See [authentication](#authentication). |\n| `secret_access_key` | `cache-to`,`cache-from` | String |     | See [authentication](#authentication). |\n| `session_token` | `cache-to`,`cache-from` | String |     | See [authentication](#authentication). |\n| `mode` | `cache-to` | `min`,`max` | `min` | Cache layers to export, see [cache mode](https://docs.docker.com/build/cache/backends/#cache-mode). |\n| `ignore-error` | `cache-to` | Boolean | `false` | Ignore errors caused by failed cache exports. |\n\nBuildx can reuse existing AWS credentials, configured either using a credentials file or environment variables, for pushing and pulling cache to S3. Alternatively, you can use the `access_key_id`, `secret_access_key`, and `session_token` attributes to specify credentials directly on the CLI.\n\nRefer to [AWS Go SDK, Specifying Credentials](https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials) for details about authentication using environment variables and credentials file.\n\nFor an introduction to caching see [Docker build cache](https://docs.docker.com/build/cache/).\n\nFor more information on the `s3` cache backend, see the [BuildKit README](https://github.com/moby/buildkit#s3-cache-experimental).",
  "title": "Amazon S3 cache | Docker Docs\n",
  "description": "Manage build cache with Amazon S3 buckets",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/17.04/",
  "markdown": "# Docker Engine 17.04 release notes\n\n2017-04-05\n\n### [Builder](#builder)\n\n*   Disable container logging for build containers [#29552](https://github.com/docker/docker/pull/29552)\n*   Fix use of `**/` in `.dockerignore` [#29043](https://github.com/docker/docker/pull/29043)\n\n### [Client](#client)\n\n*   Sort `docker stack ls` by name [#31085](https://github.com/docker/docker/pull/31085)\n*   Flags for specifying bind mount consistency [#31047](https://github.com/docker/docker/pull/31047)\n\n*   Output of docker CLI --help is now wrapped to the terminal width [#28751](https://github.com/docker/docker/pull/28751)\n*   Suppress image digest in docker ps [#30848](https://github.com/docker/docker/pull/30848)\n*   Hide command options that are related to Windows [#30788](https://github.com/docker/docker/pull/30788)\n*   Fix `docker plugin install` prompt to accept \"enter\" for the \"N\" default [#30769](https://github.com/docker/docker/pull/30769)\n\n*   Add `truncate` function for Go templates [#30484](https://github.com/docker/docker/pull/30484)\n\n*   Support expanded syntax of ports in `stack deploy` [#30476](https://github.com/docker/docker/pull/30476)\n*   Support expanded syntax of mounts in `stack deploy` [#30597](https://github.com/docker/docker/pull/30597) [#31795](https://github.com/docker/docker/pull/31795)\n\n*   Add `--add-host` for docker build [#30383](https://github.com/docker/docker/pull/30383)\n*   Add `.CreatedAt` placeholder for `docker network ls --format` [#29900](https://github.com/docker/docker/pull/29900)\n\n*   Update order of `--secret-rm` and `--secret-add` [#29802](https://github.com/docker/docker/pull/29802)\n\n*   Add `--filter enabled=true` for `docker plugin ls` [#28627](https://github.com/docker/docker/pull/28627)\n*   Add `--format` to `docker service ls` [#28199](https://github.com/docker/docker/pull/28199)\n*   Add `publish` and `expose` filter for `docker ps --filter` [#27557](https://github.com/docker/docker/pull/27557)\n\n*   Support multiple service IDs on `docker service ps` [#25234](https://github.com/docker/docker/pull/25234)\n\n*   Allow swarm join with `--availability=drain` [#24993](https://github.com/docker/docker/pull/24993)\n\n*   Docker inspect now shows \"docker-default\" when AppArmor is enabled and no other profile was defined [#27083](https://github.com/docker/docker/pull/27083)\n\n### [Logging](#logging)\n\n*   Implement optional ring buffer for container logs [#28762](https://github.com/docker/docker/pull/28762)\n*   Add `--log-opt awslogs-create-group=<true|false>` for awslogs (CloudWatch) to support creation of log groups as needed [#29504](https://github.com/docker/docker/pull/29504)\n\n*   Fix segfault when using the gcplogs logging driver with a \"static\" binary [#29478](https://github.com/docker/docker/pull/29478)\n\n### [Networking](#networking)\n\n*   Check parameter `--ip`, `--ip6` and `--link-local-ip` in `docker network connect` [#30807](https://github.com/docker/docker/pull/30807)\n\n*   Added support for `dns-search` [#30117](https://github.com/docker/docker/pull/30117)\n*   Added --verbose option for docker network inspect to show task details from all swarm nodes [#31710](https://github.com/docker/docker/pull/31710)\n\n*   Clear stale datapath encryption states when joining the cluster [docker/libnetwork#1354](https://github.com/docker/libnetwork/pull/1354)\n\n*   Ensure iptables initialization only happens once [docker/libnetwork#1676](https://github.com/docker/libnetwork/pull/1676)\n\n*   Fix bad order of iptables filter rules [docker/libnetwork#961](https://github.com/docker/libnetwork/pull/961)\n\n*   Add anonymous container alias to service record on attachable network [docker/libnetwork#1651](https://github.com/docker/libnetwork/pull/1651)\n*   Support for `com.docker.network.container_iface_prefix` driver label [docker/libnetwork#1667](https://github.com/docker/libnetwork/pull/1667)\n*   Improve network list performance by omitting network details that are not used [#30673](https://github.com/docker/docker/pull/30673)\n\n### [Runtime](#runtime)\n\n*   Handle paused container when restoring without live-restore set [#31704](https://github.com/docker/docker/pull/31704)\n\n*   Do not allow sub second in healthcheck options in Dockerfile [#31177](https://github.com/docker/docker/pull/31177)\n\n*   Support name and id prefix in `secret update` [#30856](https://github.com/docker/docker/pull/30856)\n*   Use binary frame for websocket attach endpoint [#30460](https://github.com/docker/docker/pull/30460)\n*   Fix linux mount calls not applying propagation type changes [#30416](https://github.com/docker/docker/pull/30416)\n*   Fix ExecIds leak on failed `exec -i` [#30340](https://github.com/docker/docker/pull/30340)\n*   Prune named but untagged images if `danglingOnly=true` [#30330](https://github.com/docker/docker/pull/30330)\n\n*   Add daemon flag to set `no_new_priv` as default for unprivileged containers [#29984](https://github.com/docker/docker/pull/29984)\n*   Add daemon option `--default-shm-size` [#29692](https://github.com/docker/docker/pull/29692)\n*   Support registry mirror config reload [#29650](https://github.com/docker/docker/pull/29650)\n\n*   Ignore the daemon log config when building images [#29552](https://github.com/docker/docker/pull/29552)\n\n*   Move secret name or ID prefix resolving from client to daemon [#29218](https://github.com/docker/docker/pull/29218)\n\n*   Allow adding rules to `cgroup devices.allow` on container create/run [#22563](https://github.com/docker/docker/pull/22563)\n\n*   Fix `cpu.cfs_quota_us` being reset when running `systemd daemon-reload` [#31736](https://github.com/docker/docker/pull/31736)\n\n### [Swarm Mode](#swarm-mode)\n\n*   Topology-aware scheduling [#30725](https://github.com/docker/docker/pull/30725)\n*   Automatic service rollback on failure [#31108](https://github.com/docker/docker/pull/31108)\n*   Worker and manager on the same node are now connected through a UNIX socket [docker/swarmkit#1828](https://github.com/docker/swarmkit/pull/1828), [docker/swarmkit#1850](https://github.com/docker/swarmkit/pull/1850), [docker/swarmkit#1851](https://github.com/docker/swarmkit/pull/1851)\n\n*   Improve raft transport package [docker/swarmkit#1748](https://github.com/docker/swarmkit/pull/1748)\n*   No automatic manager shutdown on demotion/removal [docker/swarmkit#1829](https://github.com/docker/swarmkit/pull/1829)\n*   Use TransferLeadership to make leader demotion safer [docker/swarmkit#1939](https://github.com/docker/swarmkit/pull/1939)\n*   Decrease default monitoring period [docker/swarmkit#1967](https://github.com/docker/swarmkit/pull/1967)\n\n*   Add Service logs formatting [#31672](https://github.com/docker/docker/pull/31672)\n\n*   Fix service logs API to be able to specify stream [#31313](https://github.com/docker/docker/pull/31313)\n\n*   Add `--stop-signal` for `service create` and `service update` [#30754](https://github.com/docker/docker/pull/30754)\n*   Add `--read-only` for `service create` and `service update` [#30162](https://github.com/docker/docker/pull/30162)\n*   Renew the context after communicating with the registry [#31586](https://github.com/docker/docker/pull/31586)\n*   (experimental) Add `--tail` and `--since` options to `docker service logs` [#31500](https://github.com/docker/docker/pull/31500)\n*   (experimental) Add `--no-task-ids` and `--no-trunc` options to `docker service logs` [#31672](https://github.com/docker/docker/pull/31672)\n\n### [Windows](#windows)\n\n*   Block pulling Windows images on non-Windows daemons [#29001](https://github.com/docker/docker/pull/29001)",
  "title": "Docker Engine 17.04 release notes | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/building/packaging/",
  "markdown": "# Packaging your software | Docker Docs\n\nIt all starts with a Dockerfile.\n\nDocker builds images by reading the instructions from a Dockerfile. A Dockerfile is a text file containing instructions for building your source code. The Dockerfile instruction syntax is defined by the specification reference in the [Dockerfile reference](https://docs.docker.com/reference/dockerfile/).\n\nHere are the most common types of instructions:\n\n| Instruction | Description |\n| --- | --- |\n| [`FROM <image>`](https://docs.docker.com/reference/dockerfile/#from) | Defines a base for your image. |\n| [`RUN <command>`](https://docs.docker.com/reference/dockerfile/#run) | Executes any commands in a new layer on top of the current image and commits the result. `RUN` also has a shell form for running commands. |\n| [`WORKDIR <directory>`](https://docs.docker.com/reference/dockerfile/#workdir) | Sets the working directory for any `RUN`, `CMD`, `ENTRYPOINT`, `COPY`, and `ADD` instructions that follow it in the Dockerfile. |\n| [`COPY <src> <dest>`](https://docs.docker.com/reference/dockerfile/#copy) | Copies new files or directories from `<src>` and adds them to the filesystem of the container at the path `<dest>`. |\n| [`CMD <command>`](https://docs.docker.com/reference/dockerfile/#cmd) | Lets you define the default program that is run once you start the container based on this image. Each Dockerfile only has one `CMD`, and only the last `CMD` instance is respected when multiple exist. |\n\nDockerfiles are crucial inputs for image builds and can facilitate automated, multi-layer image builds based on your unique configurations. Dockerfiles can start simple and grow with your needs to support more complex scenarios.\n\n### [Filename](#filename)\n\nThe default filename to use for a Dockerfile is `Dockerfile`, without a file extension. Using the default name allows you to run the `docker build` command without having to specify additional command flags.\n\nSome projects may need distinct Dockerfiles for specific purposes. A common convention is to name these `<something>.Dockerfile`. You can specify the Dockerfile filename using the `--file` flag for the `docker build` command. Refer to the [`docker build` CLI reference](https://docs.docker.com/reference/cli/docker/image/build/#file) to learn about the `--file` flag.\n\n> **Note**\n> \n> We recommend using the default (`Dockerfile`) for your project's primary Dockerfile.\n\nDocker images consist of layers. Each layer is the result of a build instruction in the Dockerfile. Layers are stacked sequentially, and each one is a delta representing the changes applied to the previous layer.\n\n### [Example](#example)\n\nHere's what a typical workflow for building applications with Docker looks like.\n\nThe following example code shows a small \"Hello World\" application written in Python, using the Flask framework.\n\nIn order to ship and deploy this application without Docker Build, you would need to make sure that:\n\n*   The required runtime dependencies are installed on the server\n*   The Python code gets uploaded to the server's filesystem\n*   The server starts your application, using the necessary parameters\n\nThe following Dockerfile creates a container image, which has all the dependencies installed and that automatically starts your application.\n\nHere's a breakdown of what this Dockerfile does:\n\n*   [Dockerfile syntax](#dockerfile-syntax)\n*   [Base image](#base-image)\n*   [Environment setup](#environment-setup)\n*   [Comments](#comments)\n*   [Installing dependencies](#installing-dependencies)\n*   [Copying files](#copying-files)\n*   [Setting environment variables](#setting-environment-variables)\n*   [Exposed ports](#exposed-ports)\n*   [Starting the application](#starting-the-application)\n\n### [Dockerfile syntax](#dockerfile-syntax)\n\nThe first line to add to a Dockerfile is a [`# syntax` parser directive](https://docs.docker.com/reference/dockerfile/#syntax). While optional, this directive instructs the Docker builder what syntax to use when parsing the Dockerfile, and allows older Docker versions with [BuildKit enabled](https://docs.docker.com/build/buildkit/#getting-started) to use a specific [Dockerfile frontend](https://docs.docker.com/build/dockerfile/frontend/) before starting the build. [Parser directives](https://docs.docker.com/reference/dockerfile/#parser-directives) must appear before any other comment, whitespace, or Dockerfile instruction in your Dockerfile, and should be the first line in Dockerfiles.\n\n> **Tip**\n> \n> We recommend using `docker/dockerfile:1`, which always points to the latest release of the version 1 syntax. BuildKit automatically checks for updates of the syntax before building, making sure you are using the most current version.\n\n### [Base image](#base-image)\n\nThe line following the syntax directive defines what base image to use:\n\nThe [`FROM` instruction](https://docs.docker.com/reference/dockerfile/#from) sets your base image to the 22.04 release of Ubuntu. All instructions that follow are executed in this base image: an Ubuntu environment. The notation `ubuntu:22.04`, follows the `name:tag` standard for naming Docker images. When you build images, you use this notation to name your images. There are many public images you can leverage in your projects, by importing them into your build steps using the Dockerfile `FROM` instruction.\n\n[Docker Hub](https://hub.docker.com/search?image_filter=official&q=&type=image) contains a large set of official images that you can use for this purpose.\n\n### [Environment setup](#environment-setup)\n\nThe following line executes a build command inside the base image.\n\nThis [`RUN` instruction](https://docs.docker.com/reference/dockerfile/#run) executes a shell in Ubuntu that updates the APT package index and installs Python tools in the container.\n\nNote the `# install app dependencies` line. This is a comment. Comments in Dockerfiles begin with the `#` symbol. As your Dockerfile evolves, comments can be instrumental to document how your Dockerfile works for any future readers and editors of the file, including your future self!\n\n> **Note**\n> \n> You might've noticed that comments are denoted using the same symbol as the [syntax directive](#dockerfile-syntax) on the first line of the file. The symbol is only interpreted as a directive if the pattern matches a directive and appears at the beginning of the Dockerfile. Otherwise, it's treated as a comment.\n\n### [Installing dependencies](#installing-dependencies)\n\nThe second `RUN` instruction installs the `flask` dependency required by the Python application.\n\nA prerequisite for this instruction is that `pip` is installed into the build container. The first `RUN` command installs `pip`, which ensures that we can use the command to install the flask web framework.\n\n### [Copying files](#copying-files)\n\nThe next instruction uses the [`COPY` instruction](https://docs.docker.com/reference/dockerfile/#copy) to copy the `hello.py` file from the local build context into the root directory of our image.\n\nA [build context](https://docs.docker.com/build/building/context/) is the set of files that you can access in Dockerfile instructions such as `COPY` and `ADD`.\n\nAfter the `COPY` instruction, the `hello.py` file is added to the filesystem of the build container.\n\n### [Setting environment variables](#setting-environment-variables)\n\nIf your application uses environment variables, you can set environment variables in your Docker build using the [`ENV` instruction](https://docs.docker.com/reference/dockerfile/#env).\n\nThis sets a Linux environment variable we'll need later. Flask, the framework used in this example, uses this variable to start the application. Without this, flask wouldn't know where to find our application to be able to run it.\n\n### [Exposed ports](#exposed-ports)\n\nThe [`EXPOSE` instruction](https://docs.docker.com/reference/dockerfile/#expose) marks that our final image has a service listening on port `8000`.\n\nThis instruction isn't required, but it is a good practice and helps tools and team members understand what this application is doing.\n\n### [Starting the application](#starting-the-application)\n\nFinally, [`CMD` instruction](https://docs.docker.com/reference/dockerfile/#cmd) sets the command that is run when the user starts a container based on this image.\n\nThis command starts the flask development server listening on all addresses on port `8000`. The example here uses the \"exec form\" version of `CMD`. It's also possible to use the \"shell form\":\n\nThere are subtle differences between these two versions, for example in how they trap signals like `SIGTERM` and `SIGKILL`. For more information about these differences, see [Shell and exec form](https://docs.docker.com/reference/dockerfile/#shell-and-exec-form)\n\nTo build a container image using the Dockerfile example from the [previous section](#example), you use the `docker build` command:\n\nThe `-t test:latest` option specifies the name and tag of the image.\n\nThe single dot (`.`) at the end of the command sets the [build context](https://docs.docker.com/build/building/context/) to the current directory. This means that the build expects to find the Dockerfile and the `hello.py` file in the directory where the command is invoked. If those files aren't there, the build fails.\n\nAfter the image has been built, you can run the application as a container with `docker run`, specifying the image name:\n\nThis publishes the container's port 8000 to `http://localhost:8000` on the Docker host.\n\nIf you are interested in examples in other languages, such as Go, check out our [language-specific guides](https://docs.docker.com/language/) in the Guides section.\n\nFor more information about building, including advanced use cases and patterns, refer to the [Build with Docker](https://docs.docker.com/build/guide/) guide.",
  "title": "Packaging your software | Docker Docs\n",
  "description": "Learn about Dockerfiles and how to use them with Docker Images to build and package your software",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/architecture/",
  "markdown": "# Docker Build architecture | Docker Docs\n\nDocker Build implements a client-server architecture, where:\n\n*   Buildx is the client and the user interface for running and managing builds\n*   BuildKit is the server, or builder, that handles the build execution.\n\n![Build high-level architecture](https://docs.docker.com/build/images/build-high-level-arch.png)\n\nAs of Docker Engine 23.0 and Docker Desktop 4.19, Buildx is the default build client.\n\nBuildx is a CLI tool that provides a user interface for working with builds. Buildx is a drop-in replacement for the legacy build client used in earlier versions of Docker Engine and Docker Desktop. In newer versions of Docker Desktop and Docker Engine, you're using Buildx by default when you invoke the `docker build` command. In earlier versions, to build using Buildx you would use the `docker buildx build` command.\n\nBuildx is more than just an updated `build` command. It also contains utilities for creating and managing [builders](#builders).\n\n### [Install Buildx](#install-buildx)\n\nDocker Buildx is installed by default with Docker Desktop. Docker Engine version 23.0 and later requires that you install Buildx from a separate package. Buildx is included in the Docker Engine installation instructions, see [Install Docker Engine](https://docs.docker.com/engine/install/).\n\nYou can also build the CLI plugin from source, or grab a binary from the GitHub repository and install it manually. See [docker/buildx README](https://github.com/docker/buildx#manual-download) for more information\n\n\"Builder\" is a term used to describe an instance of a BuildKit backend.\n\nA builder may run on the same system as the Buildx client, or it may run remotely, on a different system. You can run it as a single node, or as a cluster of nodes. Builder nodes may be containers, virtual machines, or physical machines.\n\nFor more information, see [Builders](https://docs.docker.com/build/builders/).\n\nBuildKit, or `buildkitd`, is the daemon process that executes the build workloads.\n\nA build execution starts with the invocation of a `docker build` command. Buildx interprets your build command and sends a build request to the BuildKit backend. The build request includes:\n\n*   The Dockerfile\n*   Build arguments\n*   Export options\n*   Caching options\n\nBuildKit resolves the build instruction and executes the build steps. For the duration of the build, Buildx monitors the build status and prints the progress to the terminal.\n\nIf the build requires resources from the client, such as local files or build secrets, BuildKit requests the resources that it needs from Buildx.\n\nThis is one way in which BuildKit is more efficient compared to the legacy builder it replaces. BuildKit only requests the resources that the build needs, when they're needed. The legacy builder, in comparison, always takes a copy of the local filesystem.\n\nExamples of resources that BuildKit can request from Buildx include:\n\n*   Local filesystem build contexts\n*   Build secrets\n*   SSH sockets\n*   Registry authentication tokens\n\nFor more information about BuildKit, see [BuildKit](https://docs.docker.com/build/buildkit/).\n\nThe following diagram shows an example build sequence involving Buildx and BuildKit.\n\n![Buildx and BuildKit sequence diagram](https://docs.docker.com/build/images/build-execution.png)",
  "title": "Docker Build architecture | Docker Docs\n",
  "description": "Learn about Docker Build and its components.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/bake/introduction/",
  "markdown": "# Introduction to Bake | Docker Docs\n\nBake is an abstraction for the `docker build` command that lets you more easily manage your build configuration (CLI flags, environment variables, etc.) in a consistent way for everyone on your team.\n\nBake is a command built into the Buildx CLI, so as long as you have Buildx installed, you also have access to bake, via the `docker buildx bake` command.\n\nHere's a simple example of a `docker build` command:\n\nThis command builds the Dockerfile in the current directory and tags the resulting image as `myapp:latest`.\n\nTo express the same build configuration using Bake:\n\nBake provides a structured way to manage your build configuration, and it saves you from having to remember all the CLI flags for `docker build` every time. With this file, building the image is as simple as running:\n\nFor simple builds, the difference between `docker build` and `docker buildx bake` is minimal. However, as your build configuration grows more complex, Bake provides a more structured way to manage that complexity, that would be difficult to manage with CLI flags for the `docker build`. It also provides a way to share build configurations across your team, so that everyone is building images in a consistent way, with the same configuration.\n\nYou can write Bake files in HCL, YAML (Docker Compose files), or JSON. In general, HCL is the most expressive and flexible format, which is why you'll see it used in most of the examples in this documentation, and in projects that use Bake.\n\nThe properties that can be set for a target closely resemble the CLI flags for `docker build`. For instance, consider the following `docker build` command:\n\nThe Bake equivalent would be:\n\nTo learn more about using Bake, see the following topics:\n\n*   Learn how to define and use [targets](https://docs.docker.com/build/bake/targets/) in Bake\n*   To see all the properties that can be set for a target, refer to the [Bake file reference](https://docs.docker.com/build/bake/reference/).",
  "title": "Introduction to Bake | Docker Docs\n",
  "description": "Get started with using Bake to build your project",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/building/variables/",
  "markdown": "# Build variables | Docker Docs\n\nIn Docker Build, build arguments (`ARG`) and environment variables (`ENV`) both serve as a means to pass information into the build process. You can use them to parameterize the build, allowing for more flexible and configurable builds.\n\n> **Warning**\n> \n> Build arguments and environment variables are inappropriate for passing secrets to your build, because they're exposed in the final image. Instead, use secret mounts or SSH mounts, which expose secrets to your builds securely.\n> \n> See [Build secrets](https://docs.docker.com/build/building/secrets/) for more information.\n\nBuild arguments and environment variables are similar. They're both declared in the Dockerfile and can be set using flags for the `docker build` command. Both can be used to parametrize the build. But they each serve a distinct purpose.\n\n### [Build arguments](#build-arguments)\n\nBuild arguments are variables for the Dockerfile itself. Use them to parametrize values of Dockerfile instructions. For example, you might use a build argument to specify the version of a dependency to install.\n\nBuild arguments have no effect on the build unless it's used in an instruction. They're not accessible or present in containers instantiated from the image unless explicitly passed through from the Dockerfile into the image filesystem or configuration. They may persist in the image metadata, as provenance attestations and in the image history, which is why they're not suitable for holding secrets.\n\nThey make Dockerfiles more flexible, and easier to maintain.\n\nFor an example on how you can use build arguments, see [`ARG` usage example](#arg-usage-example).\n\n### [Environment variables](#environment-variables)\n\nEnvironment variables are passed through to the build execution environment, and persist in containers instantiated from the image.\n\nEnvironment variables are primarily used to:\n\n*   Configure the execution environment for builds\n*   Set default environment variables for containers\n\nEnvironment variables, if set, can directly influence the execution of your build, and the behavior or configuration of the application.\n\nYou can't override or set an environment variable at build-time. Values for environment variables must be declared in the Dockerfile. You can combine environment variables and build arguments to allow environment variables to be configured at build-time.\n\nFor an example on how to use environment variables for configuring builds, see [`ENV` usage example](#env-usage-example).\n\nBuild arguments are commonly used to specify versions of components, such as image variants or package versions, used in a build.\n\nSpecifying versions as build arguments lets build with different versions without having to manually update the Dockerfile. It also makes it easier to maintain the Dockerfile, since it lets you declare versions at the top of the file.\n\nBuild arguments can also be a way to reuse a value in multiple places. For example, if you use multiple flavors of `alpine` in your build, you can ensure you're using the same version of `alpine` everywhere:\n\n*   `golang:1.22-alpine${ALPINE_VERSION}`\n*   `python:3.12-alpine${ALPINE_VERSION}`\n*   `nginx:1-alpine${ALPINE_VERSION}`\n\nThe following example defines the version of `node` and `alpine` using build arguments.\n\nIn this case, the build arguments have default values. Specifying their values when you invoke a build is optional. To override the defaults, you would use the `--build-arg` CLI flag:\n\nFor more information on how to use build arguments, refer to:\n\n*   [`ARG` Dockerfile reference](https://docs.docker.com/reference/dockerfile/#arg)\n*   [`docker build --build-arg` reference](https://docs.docker.com/reference/cli/docker/image/build/#build-arg)\n\nDeclaring an environment variable with `ENV` makes the variable available to all subsequent instructions in the build stage. The following example shows an example setting `NODE_ENV` to `production` before installing JavaScript dependencies with `npm`. Setting the variable makes `npm` omits packages needed only for local development.\n\nEnvironment variables aren't configurable at build-time by default. If you want to change the value of an `ENV` at build-time, you can combine environment variables and build arguments:\n\nWith this Dockerfile, you can use `--build-arg` to override the default value of `ENV`:\n\nNote that, because the environment variables you set persist in containers, using them can lead to unintended side-effects for the application's runtime.\n\nFor more information on how to use environment variables in builds, refer to:\n\n*   [`ENV` Dockerfile reference](https://docs.docker.com/reference/dockerfile/#env)\n\nBuild arguments declared in the global scope of a Dockerfile aren't automatically inherited into the build stages. They're only accessible in the global scope.\n\nThe `echo` command in this example evaluates to `hello !` because the value of the `NAME` build argument is out of scope. To inherit global build arguments into a stage, you must consume them:\n\nOnce a build argument is declared or consumed in a stage, it's automatically inherited by child stages.\n\nThe following diagram further exemplifies how build argument and environment variable inheritance works for multi-stage builds.\n\n![](https://docs.docker.com/build/images/build-variables.svg)\n\nThis section describes pre-defined build arguments available to all builds by default.\n\n### [Multi-platform build arguments](#multi-platform-build-arguments)\n\nMulti-platform build arguments describe the build and target platforms for the build.\n\nThe build platform is the operating system, architecture, and platform variant of the host system where the builder (the BuildKit daemon) is running.\n\n*   `BUILDPLATFORM`\n*   `BUILDOS`\n*   `BUILDARCH`\n*   `BUILDVARIANT`\n\nThe target platform arguments hold the same values for the target platforms for the build, specified using the `--platform` flag for the `docker build` command.\n\n*   `TARGETPLATFORM`\n*   `TARGETOS`\n*   `TARGETARCH`\n*   `TARGETVARIANT`\n\nThese arguments are useful for doing cross-compilation in multi-platform builds. They're available in the global scope of the Dockerfile, but they aren't automatically inherited by build stages. To use them inside stage, you must declare them:\n\nFor more information about multi-platform build arguments, refer to [Multi-platform arguments](https://docs.docker.com/reference/dockerfile/#automatic-platform-args-in-the-global-scope)\n\n### [Proxy arguments](#proxy-arguments)\n\nProxy build arguments let you specify proxies to use for your build. You don't need to declare or reference these arguments in the Dockerfile. Specifying a proxy with `--build-arg` is enough to make your build use the proxy.\n\nProxy arguments are automatically excluded from the build cache and the output of `docker history` by default. If you do reference the arguments in your Dockerfile, the proxy configuration ends up in the build cache.\n\nThe builder respects the following proxy build arguments. The variables are case insensitive.\n\n*   `HTTP_PROXY`\n*   `HTTPS_PROXY`\n*   `FTP_PROXY`\n*   `NO_PROXY`\n*   `ALL_PROXY`\n\nTo configure a proxy for your build:\n\nFor more information about proxy build arguments, refer to [Proxy arguments](https://docs.docker.com/reference/dockerfile/#predefined-args).\n\nThe following environment variables enable, disable, or change the behavior of Buildx and BuildKit. Note that these variables aren't used to configure the build container; they aren't available inside the build and they have no relation to the `ENV` instruction. They're used to configure the Buildx client, or the BuildKit daemon.\n\n| Variable | Type | Description |\n| --- | --- | --- |\n| [BUILDKIT\\_COLORS](#buildkit_colors) | String | Configure text color for the terminal output. |\n| [BUILDKIT\\_HOST](#buildkit_host) | String | Specify host to use for remote builders. |\n| [BUILDKIT\\_PROGRESS](#buildkit_progress) | String | Configure type of progress output. |\n| [BUILDKIT\\_TTY\\_LOG\\_LINES](#buildkit_tty_log_lines) | String | Number of log lines (for active steps in tty mode). |\n| [BUILDX\\_BAKE\\_GIT\\_AUTH\\_HEADER](#buildx_bake_git_auth_header) | String | HTTP authentication scheme for remote Bake files. |\n| [BUILDX\\_BAKE\\_GIT\\_AUTH\\_TOKEN](#buildx_bake_git_auth_token) | String | HTTP authentication token for remote Bake files. |\n| [BUILDX\\_BAKE\\_GIT\\_SSH](#buildx_bake_git_ssh) | String | SSH authentication for remote Bake files. |\n| [BUILDX\\_BUILDER](#buildx_builder) | String | Specify the builder instance to use. |\n| [BUILDX\\_CONFIG](#buildx_config) | String | Specify location for configuration, state, and logs. |\n| [BUILDX\\_EXPERIMENTAL](#buildx_experimental) | Boolean | Turn on experimental features. |\n| [BUILDX\\_GIT\\_CHECK\\_DIRTY](#buildx_git_check_dirty) | Boolean | Enable dirty Git checkout detection. |\n| [BUILDX\\_GIT\\_INFO](#buildx_git_info) | Boolean | Remove Git information in provenance attestations. |\n| [BUILDX\\_GIT\\_LABELS](#buildx_git_labels) | String \\| Boolean | Add Git provenance labels to images. |\n| [BUILDX\\_NO\\_DEFAULT\\_ATTESTATIONS](#buildx_no_default_attestations) | Boolean | Turn off default provenance attestations. |\n| [BUILDX\\_NO\\_DEFAULT\\_LOAD](#buildx_no_default_load) | Boolean | Turn off loading images to image store by default. |\n| [EXPERIMENTAL\\_BUILDKIT\\_SOURCE\\_POLICY](#experimental_buildkit_source_policy) | String | Specify a BuildKit source policy file. |\n\nBuildKit also supports a few additional configuration parameters. Refer to [BuildKit built-in build args](https://docs.docker.com/reference/dockerfile/#buildkit-built-in-build-args).\n\nYou can express Boolean values for environment variables in different ways. For example, `true`, `1`, and `T` all evaluate to true. Evaluation is done using the `strconv.ParseBool` function in the Go standard library. See the [reference documentation](https://pkg.go.dev/strconv#ParseBool) for details.\n\n### [BUILDKIT\\_COLORS](#buildkit_colors)\n\nChanges the colors of the terminal output. Set `BUILDKIT_COLORS` to a CSV string in the following format:\n\nColor values can be any valid RGB hex code, or one of the [BuildKit predefined colors](https://github.com/moby/buildkit/blob/master/util/progress/progressui/colors.go).\n\nSetting `NO_COLOR` to anything turns off colorized output, as recommended by [no-color.org](https://no-color.org/).\n\n### [BUILDKIT\\_HOST](#buildkit_host)\n\nYou use the `BUILDKIT_HOST` to specify the address of a BuildKit daemon to use as a remote builder. This is the same as specifying the address as a positional argument to `docker buildx create`.\n\nUsage:\n\nIf you specify both the `BUILDKIT_HOST` environment variable and a positional argument, the argument takes priority.\n\n### [BUILDKIT\\_PROGRESS](#buildkit_progress)\n\nSets the type of the BuildKit progress output. Valid values are:\n\n*   `auto` (default)\n*   `plain`\n*   `tty`\n*   `rawjson`\n\nUsage:\n\n### [BUILDKIT\\_TTY\\_LOG\\_LINES](#buildkit_tty_log_lines)\n\nYou can change how many log lines are visible for active steps in tty mode by setting `BUILDKIT_TTY_LOG_LINES` to a number (default to `6`).\n\n### [EXPERIMENTAL\\_BUILDKIT\\_SOURCE\\_POLICY](#experimental_buildkit_source_policy)\n\nLets you specify a [BuildKit source policy](https://github.com/moby/buildkit/blob/master/docs/build-repro.md#reproducing-the-pinned-dependencies) file for creating reproducible builds with pinned dependencies.\n\nExample:\n\nIntroduced in Buildx version 0.14.0\n\nSets the HTTP authentication scheme when using a remote Bake definition in a private Git repository. This is equivalent to the [`GIT_AUTH_HEADER` secret](https://docs.docker.com/build/building/secrets/#http-authentication-scheme), but facilitates the pre-flight authentication in Bake when loading the remote Bake file. Supported values are `bearer` (default) and `basic`.\n\nUsage:\n\n### [BUILDX\\_BAKE\\_GIT\\_AUTH\\_TOKEN](#buildx_bake_git_auth_token)\n\nIntroduced in Buildx version 0.14.0\n\nSets the HTTP authentication token when using a remote Bake definition in a private Git repository. This is equivalent to the [`GIT_AUTH_TOKEN` secret](https://docs.docker.com/build/building/secrets/#git-authentication-for-remote-contexts), but facilitates the pre-flight authentication in Bake when loading the remote Bake file.\n\nUsage:\n\n### [BUILDX\\_BAKE\\_GIT\\_SSH](#buildx_bake_git_ssh)\n\nIntroduced in Buildx version 0.14.0\n\nLets you specify a list of SSH agent socket filepaths to forward to Bake for authenticating to a Git server when using a remote Bake definition in a private repository. This is similar to SSH mounts for builds, but facilitates the pre-flight authentication in Bake when resolving the build definition.\n\nSetting this environment is typically not necessary, because Bake will use the `SSH_AUTH_SOCK` agent socket by default. You only need to specify this variable if you want to use a socket with a different filepath. This variable can take multiple paths using a comma-separated string.\n\nUsage:\n\n### [BUILDX\\_BUILDER](#buildx_builder)\n\nOverrides the configured builder instance. Same as the `docker buildx --builder` CLI flag.\n\nUsage:\n\n### [BUILDX\\_CONFIG](#buildx_config)\n\nYou can use `BUILDX_CONFIG` to specify the directory to use for build configuration, state, and logs. The lookup order for this directory is as follows:\n\n*   `$BUILDX_CONFIG`\n*   `$DOCKER_CONFIG/buildx`\n*   `~/.docker/buildx` (default)\n\nUsage:\n\n### [BUILDX\\_EXPERIMENTAL](#buildx_experimental)\n\nEnables experimental build features.\n\nUsage:\n\n### [BUILDX\\_GIT\\_CHECK\\_DIRTY](#buildx_git_check_dirty)\n\nIntroduced in Buildx version [0.10.4](https://docs.docker.com/build/release-notes/#0104)\n\nWhen set to true, checks for dirty state in source control information for [provenance attestations](https://docs.docker.com/build/attestations/slsa-provenance/).\n\nUsage:\n\n### [BUILDX\\_GIT\\_INFO](#buildx_git_info)\n\nIntroduced in Buildx version [0.10.0](https://docs.docker.com/build/release-notes/#0100)\n\nWhen set to false, removes source control information from [provenance attestations](https://docs.docker.com/build/attestations/slsa-provenance/).\n\nUsage:\n\n### [BUILDX\\_GIT\\_LABELS](#buildx_git_labels)\n\nIntroduced in Buildx version [0.10.0](https://docs.docker.com/build/release-notes/#0100)\n\nAdds provenance labels, based on Git information, to images that you build. The labels are:\n\n*   `com.docker.image.source.entrypoint`: Location of the Dockerfile relative to the project root\n*   `org.opencontainers.image.revision`: Git commit revision\n*   `org.opencontainers.image.source`: SSH or HTTPS address of the repository\n\nExample:\n\nUsage:\n\n*   Set `BUILDX_GIT_LABELS=1` to include the `entrypoint` and `revision` labels.\n*   Set `BUILDX_GIT_LABELS=full` to include all labels.\n\nIf the repository is in a dirty state, the `revision` gets a `-dirty` suffix.\n\n### [BUILDX\\_NO\\_DEFAULT\\_ATTESTATIONS](#buildx_no_default_attestations)\n\nIntroduced in Buildx version [0.10.4](https://docs.docker.com/build/release-notes/#0104)\n\nBy default, BuildKit v0.11 and later adds [provenance attestations](https://docs.docker.com/build/attestations/slsa-provenance/) to images you build. Set `BUILDX_NO_DEFAULT_ATTESTATIONS=1` to disable the default provenance attestations.\n\nUsage:\n\n### [BUILDX\\_NO\\_DEFAULT\\_LOAD](#buildx_no_default_load)\n\nWhen you build an image using the `docker` driver, the image is automatically loaded to the image store when the build finishes. Set `BUILDX_NO_DEFAULT_LOAD` to disable automatic loading of images to the local container store.\n\nUsage:",
  "title": "Build variables | Docker Docs\n",
  "description": "Using build arguments and environment variables to configure builds",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/building/context/",
  "markdown": "# Build context | Docker Docs\n\nThe `docker build` and `docker buildx build` commands build Docker images from a [Dockerfile](https://docs.docker.com/reference/dockerfile/) and a context.\n\n## [What is a build context?](#what-is-a-build-context)\n\nThe build context is the set of files that your build can access. The positional argument that you pass to the build command specifies the context that you want to use for the build:\n\nYou can pass any of the following inputs as the context for a build:\n\n*   The relative or absolute path to a local directory\n*   A remote URL of a Git repository, tarball, or plain-text file\n*   A plain-text file or tarball piped to the `docker build` command through standard input\n\n### [Filesystem contexts](#filesystem-contexts)\n\nWhen your build context is a local directory, a remote Git repository, or a tar file, then that becomes the set of files that the builder can access during the build. Build instructions such as `COPY` and `ADD` can refer to any of the files and directories in the context.\n\nA filesystem build context is processed recursively:\n\n*   When you specify a local directory or a tarball, all subdirectories are included\n*   When you specify a remote Git repository, the repository and all submodules are included\n\nFor more information about the different types of filesystem contexts that you can use with your builds, see:\n\n*   [Local files](#local-context)\n*   [Git repositories](#git-repositories)\n*   [Remote tarballs](#remote-tarballs)\n\n### [Text file contexts](#text-file-contexts)\n\nWhen your build context is a plain-text file, the builder interprets the file as a Dockerfile. With this approach, the build doesn't use a filesystem context.\n\nFor more information, see [empty build context](#empty-context).\n\n## [Local context](#local-context)\n\nTo use a local build context, you can specify a relative or absolute filepath to the `docker build` command. The following example shows a build command that uses the current directory (`.`) as a build context:\n\nThis makes files and directories in the current working directory available to the builder. The builder loads the files it needs from the build context when needed.\n\nYou can also use local tarballs as build context, by piping the tarball contents to the `docker build` command. See [Tarballs](#local-tarballs).\n\n### [Local directories](#local-directories)\n\nConsider the following directory structure:\n\nDockerfile instructions can reference and include these files in the build if you pass this directory as a context.\n\n### [Local context with Dockerfile from stdin](#local-context-with-dockerfile-from-stdin)\n\nUse the following syntax to build an image using files on your local filesystem, while using a Dockerfile from stdin.\n\nThe syntax uses the -f (or --file) option to specify the Dockerfile to use, and it uses a hyphen (-) as filename to instruct Docker to read the Dockerfile from stdin.\n\nThe following example uses the current directory (.) as the build context, and builds an image using a Dockerfile passed through stdin using a here-document.\n\n### [Local tarballs](#local-tarballs)\n\nWhen you pipe a tarball to the build command, the build uses the contents of the tarball as a filesystem context.\n\nFor example, given the following project directory:\n\nYou can create a tarball of the directory and pipe it to the build for use as a context:\n\nThe build resolves the Dockerfile from the tarball context. You can use the `--file` flag to specify the name and location of the Dockerfile relative to the root of the tarball. The following command builds using `test.Dockerfile` in the tarball:\n\n## [Remote context](#remote-context)\n\nYou can specify the address of a remote Git repository, tarball, or plain-text file as your build context.\n\n*   For Git repositories, the builder automatically clones the repository. See [Git repositories](#git-repositories).\n*   For tarballs, the builder downloads and extracts the contents of the tarball. See [Tarballs](#remote-tarballs).\n\nIf the remote tarball is a text file, the builder receives no [filesystem context](#filesystem-contexts), and instead assumes that the remote file is a Dockerfile. See [Empty build context](#empty-context).\n\n### [Git repositories](#git-repositories)\n\nWhen you pass a URL pointing to the location of a Git repository as an argument to `docker build`, the builder uses the repository as the build context.\n\nThe builder performs a shallow clone of the repository, downloading only the HEAD commit, not the entire history.\n\nThe builder recursively clones the repository and any submodules it contains.\n\nBy default, the builder clones the latest commit on the default branch of the repository that you specify.\n\n#### [URL fragments](#url-fragments)\n\nYou can append URL fragments to the Git repository address to make the builder clone a specific branch, tag, and subdirectory of a repository.\n\nThe format of the URL fragment is `#ref:dir`, where:\n\n*   `ref` is the name of the branch, tag, or commit hash\n*   `dir` is a subdirectory inside the repository\n\nFor example, the following command uses the `container` branch, and the `docker` subdirectory in that branch, as the build context:\n\nThe following table represents all the valid suffixes with their build contexts:\n\n| Build Syntax Suffix | Commit Used | Build Context Used |\n| --- | --- | --- |\n| `myrepo.git` | `refs/heads/<default branch>` | `/` |\n| `myrepo.git#mytag` | `refs/tags/mytag` | `/` |\n| `myrepo.git#mybranch` | `refs/heads/mybranch` | `/` |\n| `myrepo.git#pull/42/head` | `refs/pull/42/head` | `/` |\n| `myrepo.git#:myfolder` | `refs/heads/<default branch>` | `/myfolder` |\n| `myrepo.git#master:myfolder` | `refs/heads/master` | `/myfolder` |\n| `myrepo.git#mytag:myfolder` | `refs/tags/mytag` | `/myfolder` |\n| `myrepo.git#mybranch:myfolder` | `refs/heads/mybranch` | `/myfolder` |\n\nWhen you use a commit hash as the `ref` in the URL fragment, use the full, 40-character string SHA-1 hash of the commit. A short hash, for example a hash truncated to 7 characters, is not supported.\n\n#### [Keep `.git` directory](#keep-git-directory)\n\nBy default, BuildKit doesn't keep the `.git` directory when using Git contexts. You can configure BuildKit to keep the directory by setting the [`BUILDKIT_CONTEXT_KEEP_GIT_DIR` build argument](https://docs.docker.com/reference/dockerfile/#buildkit-built-in-build-args). This can be useful to if you want to retrieve Git information during your build:\n\n#### [Private repositories](#private-repositories)\n\nWhen you specify a Git context that's also a private repository, the builder needs you to provide the necessary authentication credentials. You can use either SSH or token-based authentication.\n\nBuildx automatically detects and uses SSH credentials if the Git context you specify is an SSH or Git address. By default, this uses `$SSH_AUTH_SOCK`. You can configure the SSH credentials to use with the [`--ssh` flag](https://docs.docker.com/reference/cli/docker/buildx/build/#ssh).\n\nIf you want to use token-based authentication instead, you can pass the token using the [`--secret` flag](https://docs.docker.com/reference/cli/docker/buildx/build/#secret).\n\n> **Note**\n> \n> Don't use `--build-arg` for secrets.\n\n### [Remote context with Dockerfile from stdin](#remote-context-with-dockerfile-from-stdin)\n\nUse the following syntax to build an image using files on your local filesystem, while using a Dockerfile from stdin.\n\nThe syntax uses the -f (or --file) option to specify the Dockerfile to use, and it uses a hyphen (-) as filename to instruct Docker to read the Dockerfile from stdin.\n\nThis can be useful in situations where you want to build an image from a repository that doesn't contain a Dockerfile. Or if you want to build with a custom Dockerfile, without maintaining your own fork of the repository.\n\nThe following example builds an image using a Dockerfile from stdin, and adds the `hello.c` file from the [hello-world](https://github.com/docker-library/hello-world) repository on GitHub.\n\n### [Remote tarballs](#remote-tarballs)\n\nIf you pass the URL to a remote tarball, the URL itself is sent to the builder.\n\nThe download operation will be performed on the host where the BuildKit daemon is running. Note that if you're using a remote Docker context or a remote builder, that's not necessarily the same machine as where you issue the build command. BuildKit fetches the `context.tar.gz` and uses it as the build context. Tarball contexts must be tar archives conforming to the standard `tar` Unix format and can be compressed with any one of the `xz`, `bzip2`, `gzip` or `identity` (no compression) formats.\n\n## [Empty context](#empty-context)\n\nWhen you use a text file as the build context, the builder interprets the file as a Dockerfile. Using a text file as context means that the build has no filesystem context.\n\nYou can build with an empty build context when your Dockerfile doesn't depend on any local files.\n\n### [How to build without a context](#how-to-build-without-a-context)\n\nYou can pass the text file using a standard input stream, or by pointing at the URL of a remote text file.\n\nWhen you build without a filesystem context, Dockerfile instructions such as `COPY` can't refer to local files:\n\nYou can use a `.dockerignore` file to exclude files or directories from the build context.\n\nThis helps avoid sending unwanted files and directories to the builder, improving build speed, especially when using a remote builder.\n\n### [Filename and location](#filename-and-location)\n\nWhen you run a build command, the build client looks for a file named `.dockerignore` in the root directory of the context. If this file exists, the files and directories that match patterns in the files are removed from the build context before it's sent to the builder.\n\nIf you use multiple Dockerfiles, you can use different ignore-files for each Dockerfile. You do so using a special naming convention for the ignore-files. Place your ignore-file in the same directory as the Dockerfile, and prefix the ignore-file with the name of the Dockerfile, as shown in the following example.\n\nA Dockerfile-specific ignore-file takes precedence over the `.dockerignore` file at the root of the build context if both exist.\n\n### [Syntax](#syntax)\n\nThe `.dockerignore` file is a newline-separated list of patterns similar to the file globs of Unix shells. Leading and trailing slashes in ignore patterns are disregarded. The following patterns all exclude a file or directory named `bar` in the subdirectory `foo` under the root of the build context:\n\n*   `/foo/bar/`\n*   `/foo/bar`\n*   `foo/bar/`\n*   `foo/bar`\n\nIf a line in `.dockerignore` file starts with `#` in column 1, then this line is considered as a comment and is ignored before interpreted by the CLI.\n\nIf you're interested in learning the precise details of the `.dockerignore` pattern matching logic, check out the [moby/patternmatcher repository](https://github.com/moby/patternmatcher/tree/main/ignorefile) on GitHub, which contains the source code.\n\n#### [Matching](#matching)\n\nThe following code snippet shows an example `.dockerignore` file.\n\nThis file causes the following build behavior:\n\n| Rule | Behavior |\n| --- | --- |\n| `# comment` | Ignored. |\n| `*/temp*` | Exclude files and directories whose names start with `temp` in any immediate subdirectory of the root. For example, the plain file `/somedir/temporary.txt` is excluded, as is the directory `/somedir/temp`. |\n| `*/*/temp*` | Exclude files and directories starting with `temp` from any subdirectory that is two levels below the root. For example, `/somedir/subdir/temporary.txt` is excluded. |\n| `temp?` | Exclude files and directories in the root directory whose names are a one-character extension of `temp`. For example, `/tempa` and `/tempb` are excluded. |\n\nMatching is done using Go's [`filepath.Match` function](https://golang.org/pkg/path/filepath#Match) rules. A preprocessing step uses Go's [`filepath.Clean` function](https://golang.org/pkg/path/filepath/#Clean) to trim whitespace and remove `.` and `..`. Lines that are blank after preprocessing are ignored.\n\n> **Note**\n> \n> For historical reasons, the pattern `.` is ignored.\n\nBeyond Go's `filepath.Match` rules, Docker also supports a special wildcard string `**` that matches any number of directories (including zero). For example, `**/*.go` excludes all files that end with `.go` found anywhere in the build context.\n\nYou can use the `.dockerignore` file to exclude the `Dockerfile` and `.dockerignore` files. These files are still sent to the builder as they're needed for running the build. But you can't copy the files into the image using `ADD`, `COPY`, or bind mounts.\n\n#### [Negating matches](#negating-matches)\n\nYou can prepend lines with a `!` (exclamation mark) to make exceptions to exclusions. The following is an example `.dockerignore` file that uses this mechanism:\n\nAll markdown files right under the context directory _except_ `README.md` are excluded from the context. Note that markdown files under subdirectories are still included.\n\nThe placement of `!` exception rules influences the behavior: the last line of the `.dockerignore` that matches a particular file determines whether it's included or excluded. Consider the following example:\n\nNo markdown files are included in the context except README files other than `README-secret.md`.\n\nNow consider this example:\n\nAll of the README files are included. The middle line has no effect because `!README*.md` matches `README-secret.md` and comes last.",
  "title": "Build context | Docker Docs\n",
  "description": "Learn how to use the build context to access files from your Dockerfile",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/release-notes/prior-releases/",
  "markdown": "# Docker Engine release notes | Docker Docs\n\n**Important**: On Linux distributions where `devicemapper` was the default storage driver, the `overlay2`, or `overlay` is now used by default (if the kernel supports it). To use devicemapper, you can manually configure the storage driver to use through the `--storage-driver` daemon option, or by setting \"storage-driver\" in the `daemon.json` configuration file.\n\n**Important**: In Docker 1.13, the managed plugin api changed, as compared to the experimental version introduced in Docker 1.12. You must **uninstall** plugins which you installed with Docker 1.12 _before_ upgrading to Docker 1.13. You can uninstall plugins using the `docker plugin rm` command.\n\nIf you have already upgraded to Docker 1.13 without uninstalling previously-installed plugins, you may see this message when the Docker daemon starts:\n\n```\nError starting daemon: json: cannot unmarshal string into Go value of type types.PluginEnv\n```\n\nTo manually remove all plugins and resolve this problem, take the following steps:\n\n1.  Remove plugins.json from: `/var/lib/docker/plugins/`.\n2.  Restart Docker. Verify that the Docker daemon starts with no errors.\n3.  Reinstall your plugins.\n\n### [Contrib](#contrib)\n\n*   Do not require a custom build of tini [#28454](https://github.com/docker/docker/pull/28454)\n*   Upgrade to Go 1.7.5 [#30489](https://github.com/docker/docker/pull/30489)\n\n### [Remote API (v1.26) & Client](#remote-api-v126--client)\n\n*   Support secrets in docker stack deploy with compose file [#30144](https://github.com/docker/docker/pull/30144)\n\n### [Runtime](#runtime)\n\n*   Fix size issue in `docker system df` [#30378](https://github.com/docker/docker/pull/30378)\n*   Fix error on `docker inspect` when Swarm certificates were expired. [#29246](https://github.com/docker/docker/pull/29246)\n*   Fix deadlock on v1 plugin with activate error [#30408](https://github.com/docker/docker/pull/30408)\n*   Fix SELinux regression [#30649](https://github.com/docker/docker/pull/30649)\n\n### [Plugins](#plugins)\n\n*   Support global scoped network plugins (v2) in swarm mode [#30332](https://github.com/docker/docker/pull/30332)\n\n*   Add `docker plugin upgrade` [#29414](https://github.com/docker/docker/pull/29414)\n\n### [Windows](#windows)\n\n*   Fix small regression with old plugins in Windows [#30150](https://github.com/docker/docker/pull/30150)\n*   Fix warning on Windows [#30730](https://github.com/docker/docker/pull/30730)\n\n**Important**: On Linux distributions where `devicemapper` was the default storage driver, the `overlay2`, or `overlay` is now used by default (if the kernel supports it). To use devicemapper, you can manually configure the storage driver to use through the `--storage-driver` daemon option, or by setting \"storage-driver\" in the `daemon.json` configuration file.\n\n**Important**: In Docker 1.13, the managed plugin api changed, as compared to the experimental version introduced in Docker 1.12. You must **uninstall** plugins which you installed with Docker 1.12 _before_ upgrading to Docker 1.13. You can uninstall plugins using the `docker plugin rm` command.\n\nIf you have already upgraded to Docker 1.13 without uninstalling previously-installed plugins, you may see this message when the Docker daemon starts:\n\n```\nError starting daemon: json: cannot unmarshal string into Go value of type types.PluginEnv\n```\n\nTo manually remove all plugins and resolve this problem, take the following steps:\n\n1.  Remove plugins.json from: `/var/lib/docker/plugins/`.\n2.  Restart Docker. Verify that the Docker daemon starts with no errors.\n3.  Reinstall your plugins.\n\n### [Builder](#builder)\n\n*   Add capability to specify images used as a cache source on build. These images do not need to have local parent chain and can be pulled from other registries [#26839](https://github.com/docker/docker/pull/26839)\n*   (experimental) Add option to squash image layers to the FROM image after successful builds [#22641](https://github.com/docker/docker/pull/22641)\n\n*   Fix dockerfile parser with empty line after escape [#24725](https://github.com/docker/docker/pull/24725)\n\n*   Add step number on `docker build` [#24978](https://github.com/docker/docker/pull/24978)\n\n*   Add support for compressing build context during image build [#25837](https://github.com/docker/docker/pull/25837)\n*   add `--network` to `docker build` [#27702](https://github.com/docker/docker/pull/27702)\n\n*   Fix inconsistent behavior between `--label` flag on `docker build` and `docker run` [#26027](https://github.com/docker/docker/issues/26027)\n*   Fix image layer inconsistencies when using the overlay storage driver [#27209](https://github.com/docker/docker/pull/27209)\n\n*   Unused build-args are now allowed. A warning is presented instead of an error and failed build [#27412](https://github.com/docker/docker/pull/27412)\n\n*   Fix builder cache issue on Windows [#27805](https://github.com/docker/docker/pull/27805)\n\n*   Allow `USER` in builder on Windows [#28415](https://github.com/docker/docker/pull/28415)\n*   Handle env case-insensitive on Windows [#28725](https://github.com/docker/docker/pull/28725)\n\n### [Contrib](#contrib-1)\n\n*   Add support for building docker debs for Ubuntu 16.04 Xenial on PPC64LE [#23438](https://github.com/docker/docker/pull/23438)\n*   Add support for building docker debs for Ubuntu 16.04 Xenial on s390x [#26104](https://github.com/docker/docker/pull/26104)\n*   Add support for building docker debs for Ubuntu 16.10 Yakkety Yak on PPC64LE [#28046](https://github.com/docker/docker/pull/28046)\n\n*   Add RPM builder for VMWare Photon OS [#24116](https://github.com/docker/docker/pull/24116)\n\n*   Add shell completions to tgz [#27735](https://github.com/docker/docker/pull/27735)\n\n*   Update the install script to allow using the mirror in China [#27005](https://github.com/docker/docker/pull/27005)\n\n*   Add DEB builder for Ubuntu 16.10 Yakkety Yak [#27993](https://github.com/docker/docker/pull/27993)\n*   Add RPM builder for Fedora 25 [#28222](https://github.com/docker/docker/pull/28222)\n*   Add `make deb` support for aarch64 [#27625](https://github.com/docker/docker/pull/27625)\n\n### [Distribution](#distribution)\n\n*   Update notary dependency to 0.4.2 (full changelogs [here](https://github.com/docker/notary/releases/tag/v0.4.2)) [#27074](https://github.com/docker/docker/pull/27074)\n    *   Support for compilation on windows [docker/notary#970](https://github.com/docker/notary/pull/970)\n    *   Improved error messages for client authentication errors [docker/notary#972](https://github.com/docker/notary/pull/972)\n    *   Support for finding keys that are anywhere in the `~/.docker/trust/private` directory, not just under `~/.docker/trust/private/root_keys` or `~/.docker/trust/private/tuf_keys` [docker/notary#981](https://github.com/docker/notary/pull/981)\n    *   Previously, on any error updating, the client would fall back on the cache. Now we only do so if there is a network error or if the server is unavailable or missing the TUF data. Invalid TUF data will cause the update to fail - for example if there was an invalid root rotation. [docker/notary#982](https://github.com/docker/notary/pull/982)\n    *   Improve root validation and yubikey debug logging [docker/notary#858](https://github.com/docker/notary/pull/858) [docker/notary#891](https://github.com/docker/notary/pull/891)\n    *   Warn if certificates for root or delegations are near expiry [docker/notary#802](https://github.com/docker/notary/pull/802)\n    *   Warn if role metadata is near expiry [docker/notary#786](https://github.com/docker/notary/pull/786)\n    *   Fix passphrase retrieval attempt counting and terminal detection [docker/notary#906](https://github.com/docker/notary/pull/906)\n\n*   Avoid unnecessary blob uploads when different users push same layers to authenticated registry [#26564](https://github.com/docker/docker/pull/26564)\n\n*   Allow external storage for registry credentials [#26354](https://github.com/docker/docker/pull/26354)\n\n### [Logging](#logging)\n\n*   Standardize the default logging tag value in all logging drivers [#22911](https://github.com/docker/docker/pull/22911)\n\n*   Improve performance and memory use when logging of long log lines [#22982](https://github.com/docker/docker/pull/22982)\n\n*   Enable syslog driver for windows [#25736](https://github.com/docker/docker/pull/25736)\n*   Add Logentries Driver [#27471](https://github.com/docker/docker/pull/27471)\n*   Update of AWS log driver to support tags [#27707](https://github.com/docker/docker/pull/27707)\n*   Unix socket support for fluentd [#26088](https://github.com/docker/docker/pull/26088)\n\n*   Enable fluentd logging driver on Windows [#28189](https://github.com/docker/docker/pull/28189)\n\n*   Sanitize docker labels when used as journald field names [#23725](https://github.com/docker/docker/pull/23725)\n*   Fix an issue where `docker logs --tail` returned less lines than expected [#28203](https://github.com/docker/docker/pull/28203)\n*   Splunk Logging Driver: performance and reliability improvements [#26207](https://github.com/docker/docker/pull/26207)\n*   Splunk Logging Driver: configurable formats and skip for verifying connection [#25786](https://github.com/docker/docker/pull/25786)\n\n### [Networking](#networking)\n\n*   Add `--attachable` network support to enable `docker run` to work in swarm-mode overlay network [#25962](https://github.com/docker/docker/pull/25962)\n*   Add support for host port PublishMode in services using the `--publish` option in `docker service create` [#27917](https://github.com/docker/docker/pull/27917) and [#28943](https://github.com/docker/docker/pull/28943)\n*   Add support for Windows server 2016 overlay network driver (requires upcoming ws2016 update) [#28182](https://github.com/docker/docker/pull/28182)\n\n*   Change the default `FORWARD` policy to `DROP` [#28257](https://github.com/docker/docker/pull/28257)\n\n*   Add support for specifying static IP addresses for predefined network on windows [#22208](https://github.com/docker/docker/pull/22208)\n\n*   Fix `--publish` flag on `docker run` not working with IPv6 addresses [#27860](https://github.com/docker/docker/pull/27860)\n*   Fix inspect network show gateway with mask [#25564](https://github.com/docker/docker/pull/25564)\n*   Fix an issue where multiple addresses in a bridge may cause `--fixed-cidr` to not have the correct addresses [#26659](https://github.com/docker/docker/pull/26659)\n\n*   Add creation timestamp to `docker network inspect` [#26130](https://github.com/docker/docker/pull/26130)\n\n*   Show peer nodes in `docker network inspect` for swarm overlay networks [#28078](https://github.com/docker/docker/pull/28078)\n*   Enable ping for service VIP address [#28019](https://github.com/docker/docker/pull/28019)\n\n### [Plugins](#plugins-1)\n\n*   Move plugins out of experimental [#28226](https://github.com/docker/docker/pull/28226)\n*   Add `--force` on `docker plugin remove` [#25096](https://github.com/docker/docker/pull/25096)\n\n*   Add support for dynamically reloading authorization plugins [#22770](https://github.com/docker/docker/pull/22770)\n\n*   Add description in `docker plugin ls` [#25556](https://github.com/docker/docker/pull/25556)\n*   Add `-f`/`--format` to `docker plugin inspect` [#25990](https://github.com/docker/docker/pull/25990)\n*   Add `docker plugin create` command [#28164](https://github.com/docker/docker/pull/28164)\n\n*   Send request's TLS peer certificates to authorization plugins [#27383](https://github.com/docker/docker/pull/27383)\n*   Support for global-scoped network and ipam plugins in swarm-mode [#27287](https://github.com/docker/docker/pull/27287)\n*   Split `docker plugin install` into two API call `/privileges` and `/pull` [#28963](https://github.com/docker/docker/pull/28963)\n\n### [Remote API (v1.25) & Client](#remote-api-v125--client)\n\n*   Support `docker stack deploy` from a Compose file [#27998](https://github.com/docker/docker/pull/27998)\n*   (experimental) Implement checkpoint and restore [#22049](https://github.com/docker/docker/pull/22049)\n*   Add `--format` flag to `docker info` [#23808](https://github.com/docker/docker/pull/23808)\n\n*   Remove `--name` from `docker volume create` [#23830](https://github.com/docker/docker/pull/23830)\n\n*   Add `docker stack ls` [#23886](https://github.com/docker/docker/pull/23886)\n*   Add a new `is-task` ps filter [#24411](https://github.com/docker/docker/pull/24411)\n*   Add `--env-file` flag to `docker service create` [#24844](https://github.com/docker/docker/pull/24844)\n*   Add `--format` on `docker stats` [#24987](https://github.com/docker/docker/pull/24987)\n*   Make `docker node ps` default to `self` in swarm node [#25214](https://github.com/docker/docker/pull/25214)\n*   Add `--group` in `docker service create` [#25317](https://github.com/docker/docker/pull/25317)\n*   Add `--no-trunc` to service/node/stack ps output [#25337](https://github.com/docker/docker/pull/25337)\n*   Add Logs to `ContainerAttachOptions` so go clients can request to retrieve container logs as part of the attach process [#26718](https://github.com/docker/docker/pull/26718)\n*   Allow client to talk to an older server [#27745](https://github.com/docker/docker/pull/27745)\n\n*   Inform user client-side that a container removal is in progress [#26074](https://github.com/docker/docker/pull/26074)\n\n*   Add `Isolation` to the /info endpoint [#26255](https://github.com/docker/docker/pull/26255)\n*   Add `userns` to the /info endpoint [#27840](https://github.com/docker/docker/pull/27840)\n\n*   Do not allow more than one mode be requested at once in the services endpoint [#26643](https://github.com/docker/docker/pull/26643)\n\n*   Add capability to /containers/create API to specify mounts in a more granular and safer way [#22373](https://github.com/docker/docker/pull/22373)\n*   Add `--format` flag to `network ls` and `volume ls` [#23475](https://github.com/docker/docker/pull/23475)\n\n*   Allow the top-level `docker inspect` command to inspect any kind of resource [#23614](https://github.com/docker/docker/pull/23614)\n\n*   Add --cpus flag to control cpu resources for `docker run` and `docker create`, and add `NanoCPUs` to `HostConfig` [#27958](https://github.com/docker/docker/pull/27958)\n\n*   Allow unsetting the `--entrypoint` in `docker run` or `docker create` [#23718](https://github.com/docker/docker/pull/23718)\n\n*   Restructure CLI commands by adding `docker image` and `docker container` commands for more consistency [#26025](https://github.com/docker/docker/pull/26025)\n\n*   Remove `COMMAND` column from `service ls` output [#28029](https://github.com/docker/docker/pull/28029)\n\n*   Add `--format` to `docker events` [#26268](https://github.com/docker/docker/pull/26268)\n\n*   Allow specifying multiple nodes on `docker node ps` [#26299](https://github.com/docker/docker/pull/26299)\n*   Restrict fractional digits to 2 decimals in `docker images` output [#26303](https://github.com/docker/docker/pull/26303)\n\n*   Add `--dns-option` to `docker run` [#28186](https://github.com/docker/docker/pull/28186)\n*   Add Image ID to container commit event [#28128](https://github.com/docker/docker/pull/28128)\n*   Add external binaries version to docker info [#27955](https://github.com/docker/docker/pull/27955)\n*   Add information for `Manager Addresses` in the output of `docker info` [#28042](https://github.com/docker/docker/pull/28042)\n*   Add a new reference filter for `docker images` [#27872](https://github.com/docker/docker/pull/27872)\n\n### [Runtime](#runtime-1)\n\n*   Add `--experimental` daemon flag to enable experimental features, instead of shipping them in a separate build [#27223](https://github.com/docker/docker/pull/27223)\n*   Add a `--shutdown-timeout` daemon flag to specify the default timeout (in seconds) to stop containers gracefully before daemon exit [#23036](https://github.com/docker/docker/pull/23036)\n*   Add `--stop-timeout` to specify the timeout value (in seconds) for individual containers to stop [#22566](https://github.com/docker/docker/pull/22566)\n*   Add a new daemon flag `--userland-proxy-path` to allow configuring the userland proxy instead of using the hardcoded `docker-proxy` from `$PATH` [#26882](https://github.com/docker/docker/pull/26882)\n*   Add boolean flag `--init` on `dockerd` and on `docker run` to use [tini](https://github.com/krallin/tini) a zombie-reaping init process as PID 1 [#26061](https://github.com/docker/docker/pull/26061) [#28037](https://github.com/docker/docker/pull/28037)\n*   Add a new daemon flag `--init-path` to allow configuring the path to the `docker-init` binary [#26941](https://github.com/docker/docker/pull/26941)\n*   Add support for live reloading insecure registry in configuration [#22337](https://github.com/docker/docker/pull/22337)\n*   Add support for storage-opt size on Windows daemons [#23391](https://github.com/docker/docker/pull/23391)\n\n*   Improve reliability of `docker run --rm` by moving it from the client to the daemon [#20848](https://github.com/docker/docker/pull/20848)\n\n*   Add support for `--cpu-rt-period` and `--cpu-rt-runtime` flags, allowing containers to run real-time threads when `CONFIG_RT_GROUP_SCHED` is enabled in the kernel [#23430](https://github.com/docker/docker/pull/23430)\n\n*   Allow parallel stop, pause, unpause [#24761](https://github.com/docker/docker/pull/24761) / [#26778](https://github.com/docker/docker/pull/26778)\n*   Implement XFS quota for overlay2 [#24771](https://github.com/docker/docker/pull/24771)\n\n*   Fix partial/full filter issue in `service tasks --filter` [#24850](https://github.com/docker/docker/pull/24850)\n*   Allow engine to run inside a user namespace [#25672](https://github.com/docker/docker/pull/25672)\n*   Fix a race condition between device deferred removal and resume device, when using the devicemapper graphdriver [#23497](https://github.com/docker/docker/pull/23497)\n*   Add `docker stats` support in Windows [#25737](https://github.com/docker/docker/pull/25737)\n*   Allow using `--pid=host` and `--net=host` when `--userns=host` [#25771](https://github.com/docker/docker/pull/25771)\n\n*   (experimental) Add metrics (Prometheus) output for basic `container`, `image`, and `daemon` operations [#25820](https://github.com/docker/docker/pull/25820)\n\n*   Fix issue in `docker stats` with `NetworkDisabled=true` [#25905](https://github.com/docker/docker/pull/25905)\n\n*   Add `docker top` support in Windows [#25891](https://github.com/docker/docker/pull/25891)\n*   Record pid of exec'd process [#27470](https://github.com/docker/docker/pull/27470)\n*   Add support for looking up user/groups via `getent` [#27599](https://github.com/docker/docker/pull/27599)\n*   Add new `docker system` command with `df` and `prune` subcommands for system resource management, as well as `docker {container,image,volume,network} prune` subcommands [#26108](https://github.com/docker/docker/pull/26108) [#27525](https://github.com/docker/docker/pull/27525) / [#27525](https://github.com/docker/docker/pull/27525)\n\n*   Fix an issue where containers could not be stopped or killed by setting xfs max\\_retries to 0 upon ENOSPC with devicemapper [#26212](https://github.com/docker/docker/pull/26212)\n*   Fix `docker cp` failing to copy to a container's volume dir on CentOS with devicemapper [#28047](https://github.com/docker/docker/pull/28047)\n\n*   Promote overlay(2) graphdriver [#27932](https://github.com/docker/docker/pull/27932)\n\n*   Add `--seccomp-profile` daemon flag to specify a path to a seccomp profile that overrides the default [#26276](https://github.com/docker/docker/pull/26276)\n\n*   Fix ulimits in `docker inspect` when `--default-ulimit` is set on daemon [#26405](https://github.com/docker/docker/pull/26405)\n*   Add workaround for overlay issues during build in older kernels [#28138](https://github.com/docker/docker/pull/28138)\n\n*   Add `TERM` environment variable on `docker exec -t` [#26461](https://github.com/docker/docker/pull/26461)\n\n*   Honor a containerâ€™s `--stop-signal` setting upon `docker kill` [#26464](https://github.com/docker/docker/pull/26464)\n\n### [Swarm Mode](#swarm-mode)\n\n*   Add secret management [#27794](https://github.com/docker/docker/pull/27794)\n*   Add support for templating service options (hostname, mounts, and environment variables) [#28025](https://github.com/docker/docker/pull/28025)\n\n*   Display the endpoint mode in the output of `docker service inspect --pretty` [#26906](https://github.com/docker/docker/pull/26906)\n*   Make `docker service ps` output more bearable by shortening service IDs in task names [#28088](https://github.com/docker/docker/pull/28088)\n*   Make `docker node ps` default to the current node [#25214](https://github.com/docker/docker/pull/25214)\n\n*   Add `--dns`, -`-dns-opt`, and `--dns-search` to service create. [#27567](https://github.com/docker/docker/pull/27567)\n*   Add `--force` to `docker service update` [#27596](https://github.com/docker/docker/pull/27596)\n*   Add `--health-*` and `--no-healthcheck` flags to `docker service create` and `docker service update` [#27369](https://github.com/docker/docker/pull/27369)\n*   Add `-q` to `docker service ps` [#27654](https://github.com/docker/docker/pull/27654)\n\n*   Display number of global services in `docker service ls` [#27710](https://github.com/docker/docker/pull/27710)\n\n*   Remove `--name` flag from `docker service update`. This flag is only functional on `docker service create`, so was removed from the `update` command [#26988](https://github.com/docker/docker/pull/26988)\n*   Fix worker nodes failing to recover because of transient networking issues [#26646](https://github.com/docker/docker/issues/26646)\n\n*   Add support for health aware load balancing and DNS records [#27279](https://github.com/docker/docker/pull/27279)\n\n*   Add `--hostname` to `docker service create` [#27857](https://github.com/docker/docker/pull/27857)\n*   Add `--host` to `docker service create`, and `--host-add`, `--host-rm` to `docker service update` [#28031](https://github.com/docker/docker/pull/28031)\n*   Add `--tty` flag to `docker service create`/`update` [#28076](https://github.com/docker/docker/pull/28076)\n\n*   Autodetect, store, and expose node IP address as seen by the manager [#27910](https://github.com/docker/docker/pull/27910)\n*   Encryption at rest of manager keys and raft data [#27967](https://github.com/docker/docker/pull/27967)\n\n*   Add `--update-max-failure-ratio`, `--update-monitor` and `--rollback` flags to `docker service update` [#26421](https://github.com/docker/docker/pull/26421)\n\n*   Fix an issue with address autodiscovery on `docker swarm init` running inside a container [#26457](https://github.com/docker/docker/pull/26457)\n\n*   (experimental) Add `docker service logs` command to view logs for a service [#28089](https://github.com/docker/docker/pull/28089)\n*   Pin images by digest for `docker service create` and `update` [#28173](https://github.com/docker/docker/pull/28173)\n\n*   Add short (`-f`) flag for `docker node rm --force` and `docker swarm leave --force` [#28196](https://github.com/docker/docker/pull/28196)\n\n*   Add options to customize Raft snapshots (`--max-snapshots`, `--snapshot-interval`) [#27997](https://github.com/docker/docker/pull/27997)\n\n*   Don't repull image if pinned by digest [#28265](https://github.com/docker/docker/pull/28265)\n\n*   Swarm-mode support for Windows [#27838](https://github.com/docker/docker/pull/27838)\n*   Allow hostname to be updated on service [#28771](https://github.com/docker/docker/pull/28771)\n*   Support v2 plugins [#29433](https://github.com/docker/docker/pull/29433)\n*   Add content trust for services [#29469](https://github.com/docker/docker/pull/29469)\n\n### [Volume](#volume)\n\n*   Add support for labels on volumes [#21270](https://github.com/docker/docker/pull/21270)\n*   Add support for filtering volumes by label [#25628](https://github.com/docker/docker/pull/25628)\n\n*   Add a `--force` flag in `docker volume rm` to forcefully purge the data of the volume that has already been deleted [#23436](https://github.com/docker/docker/pull/23436)\n*   Enhance `docker volume inspect` to show all options used when creating the volume [#26671](https://github.com/docker/docker/pull/26671)\n*   Add support for local NFS volumes to resolve hostnames [#27329](https://github.com/docker/docker/pull/27329)\n\n### [Security](#security)\n\n*   Fix selinux labeling of volumes shared in a container [#23024](https://github.com/docker/docker/pull/23024)\n*   Prohibit `/sys/firmware/**` from being accessed with apparmor [#26618](https://github.com/docker/docker/pull/26618)\n\n### [Deprecation](#deprecation)\n\n*   Marked the `docker daemon` command as deprecated. The daemon is moved to a separate binary (`dockerd`), and should be used instead [#26834](https://github.com/docker/docker/pull/26834)\n*   Deprecate unversioned API endpoints [#28208](https://github.com/docker/docker/pull/28208)\n*   Remove Ubuntu 15.10 (Wily Werewolf) as supported platform. Ubuntu 15.10 is EOL, and no longer receives updates [#27042](https://github.com/docker/docker/pull/27042)\n*   Remove Fedora 22 as supported platform. Fedora 22 is EOL, and no longer receives updates [#27432](https://github.com/docker/docker/pull/27432)\n*   Remove Fedora 23 as supported platform. Fedora 23 is EOL, and no longer receives updates [#29455](https://github.com/docker/docker/pull/29455)\n*   Deprecate the `repo:shortid` syntax on `docker pull` [#27207](https://github.com/docker/docker/pull/27207)\n*   Deprecate backing filesystem without `d_type` for overlay and overlay2 storage drivers [#27433](https://github.com/docker/docker/pull/27433)\n*   Deprecate `MAINTAINER` in Dockerfile [#25466](https://github.com/docker/docker/pull/25466)\n*   Deprecate `filter` param for endpoint `/images/json` [#27872](https://github.com/docker/docker/pull/27872)\n*   Deprecate setting duplicate engine labels [#24533](https://github.com/docker/docker/pull/24533)\n*   Deprecate \"top-level\" network information in `NetworkSettings` [#28437](https://github.com/docker/docker/pull/28437)\n\n**IMPORTANT**: Docker 1.12 ships with an updated systemd unit file for rpm based installs (which includes RHEL, Fedora, CentOS, and Oracle Linux 7). When upgrading from an older version of docker, the upgrade process may not automatically install the updated version of the unit file, or fail to start the docker service if;\n\n*   the systemd unit file (`/usr/lib/systemd/system/docker.service`) contains local changes, or\n*   a systemd drop-in file is present, and contains `-H fd://` in the `ExecStart` directive\n\nStarting the docker service will produce an error:\n\n```\nFailed to start docker.service: Unit docker.socket failed to load: No such file or directory.\n```\n\nor\n\n```\nno sockets found via socket activation: make sure the service was started by systemd.\n```\n\nTo resolve this:\n\n*   Backup the current version of the unit file, and replace the file with the [version that ships with docker 1.12](https://raw.githubusercontent.com/docker/docker/v1.12.0/contrib/init/systemd/docker.service.rpm)\n*   Remove the `Requires=docker.socket` directive from the `/usr/lib/systemd/system/docker.service` file if present\n*   Remove `-H fd://` from the `ExecStart` directive (both in the main unit file, and in any drop-in files present).\n\nAfter making those changes, run `sudo systemctl daemon-reload`, and `sudo systemctl restart docker` to reload changes and (re)start the docker daemon.\n\n**NOTE**: Docker 1.12.5 will correctly validate that either an IPv6 subnet is provided or that the IPAM driver can provide one when you specify the `--ipv6` option.\n\nIf you are currently using the `--ipv6` option _without_ specifying the `--fixed-cidr-v6` option, the Docker daemon will refuse to start with the following message:\n\nTo resolve this error, either remove the `--ipv6` flag (to preserve the same behavior as in Docker 1.12.3 and earlier), or provide an IPv6 subnet as the value of the `--fixed-cidr-v6` flag.\n\nIn a similar way, if you specify the `--ipv6` flag when creating a network with the default IPAM driver, without providing an IPv6 `--subnet`, network creation will fail with the following message:\n\nTo resolve this, either remove the `--ipv6` flag (to preserve the same behavior as in Docker 1.12.3 and earlier), or provide an IPv6 subnet as the value of the `--subnet` flag.\n\nThe network creation will instead succeed if you use an external IPAM driver which supports automatic allocation of IPv6 subnets.\n\n### [Runtime](#runtime-2)\n\n*   Fix runC privilege escalation (CVE-2016-9962)\n\n**IMPORTANT**: Docker 1.12 ships with an updated systemd unit file for rpm based installs (which includes RHEL, Fedora, CentOS, and Oracle Linux 7). When upgrading from an older version of docker, the upgrade process may not automatically install the updated version of the unit file, or fail to start the docker service if;\n\n*   the systemd unit file (`/usr/lib/systemd/system/docker.service`) contains local changes, or\n*   a systemd drop-in file is present, and contains `-H fd://` in the `ExecStart` directive\n\nStarting the docker service will produce an error:\n\n```\nFailed to start docker.service: Unit docker.socket failed to load: No such file or directory.\n```\n\nor\n\n```\nno sockets found via socket activation: make sure the service was started by systemd.\n```\n\nTo resolve this:\n\n*   Backup the current version of the unit file, and replace the file with the [version that ships with docker 1.12](https://raw.githubusercontent.com/docker/docker/v1.12.0/contrib/init/systemd/docker.service.rpm)\n*   Remove the `Requires=docker.socket` directive from the `/usr/lib/systemd/system/docker.service` file if present\n*   Remove `-H fd://` from the `ExecStart` directive (both in the main unit file, and in any drop-in files present).\n\nAfter making those changes, run `sudo systemctl daemon-reload`, and `sudo systemctl restart docker` to reload changes and (re)start the docker daemon.\n\n**NOTE**: Docker 1.12.5 will correctly validate that either an IPv6 subnet is provided or that the IPAM driver can provide one when you specify the `--ipv6` option.\n\nIf you are currently using the `--ipv6` option _without_ specifying the `--fixed-cidr-v6` option, the Docker daemon will refuse to start with the following message:\n\nTo resolve this error, either remove the `--ipv6` flag (to preserve the same behavior as in Docker 1.12.3 and earlier), or provide an IPv6 subnet as the value of the `--fixed-cidr-v6` flag.\n\nIn a similar way, if you specify the `--ipv6` flag when creating a network with the default IPAM driver, without providing an IPv6 `--subnet`, network creation will fail with the following message:\n\nTo resolve this, either remove the `--ipv6` flag (to preserve the same behavior as in Docker 1.12.3 and earlier), or provide an IPv6 subnet as the value of the `--subnet` flag.\n\nThe network network creation will instead succeed if you use an external IPAM driver which supports automatic allocation of IPv6 subnets.\n\n### [Runtime](#runtime-3)\n\n*   Fix race on sending stdin close event [#29424](https://github.com/docker/docker/pull/29424)\n\n### [Networking](#networking-1)\n\n*   Fix panic in docker network ls when a network was created with `--ipv6` and no ipv6 `--subnet` in older docker versions [#29416](https://github.com/docker/docker/pull/29416)\n\n### [Contrib](#contrib-2)\n\n*   Fix compilation on Darwin [#29370](https://github.com/docker/docker/pull/29370)\n\n**IMPORTANT**: Docker 1.12 ships with an updated systemd unit file for rpm based installs (which includes RHEL, Fedora, CentOS, and Oracle Linux 7). When upgrading from an older version of docker, the upgrade process may not automatically install the updated version of the unit file, or fail to start the docker service if;\n\n*   the systemd unit file (`/usr/lib/systemd/system/docker.service`) contains local changes, or\n*   a systemd drop-in file is present, and contains `-H fd://` in the `ExecStart` directive\n\nStarting the docker service will produce an error:\n\n```\nFailed to start docker.service: Unit docker.socket failed to load: No such file or directory.\n```\n\nor\n\n```\nno sockets found via socket activation: make sure the service was started by systemd.\n```\n\nTo resolve this:\n\n*   Backup the current version of the unit file, and replace the file with the [version that ships with docker 1.12](https://raw.githubusercontent.com/docker/docker/v1.12.0/contrib/init/systemd/docker.service.rpm)\n*   Remove the `Requires=docker.socket` directive from the `/usr/lib/systemd/system/docker.service` file if present\n*   Remove `-H fd://` from the `ExecStart` directive (both in the main unit file, and in any drop-in files present).\n\nAfter making those changes, run `sudo systemctl daemon-reload`, and `sudo systemctl restart docker` to reload changes and (re)start the docker daemon.\n\n### [Runtime](#runtime-4)\n\n*   Fix issue where volume metadata was not removed [#29083](https://github.com/docker/docker/pull/29083)\n*   Asynchronously close streams to prevent holding container lock [#29050](https://github.com/docker/docker/pull/29050)\n*   Fix selinux labels for newly created container volumes [#29050](https://github.com/docker/docker/pull/29050)\n*   Remove hostname validation [#28990](https://github.com/docker/docker/pull/28990)\n*   Fix deadlocks caused by IO races [#29095](https://github.com/docker/docker/pull/29095) [#29141](https://github.com/docker/docker/pull/29141)\n*   Return an empty stats if the container is restarting [#29150](https://github.com/docker/docker/pull/29150)\n*   Fix volume store locking [#29151](https://github.com/docker/docker/pull/29151)\n*   Ensure consistent status code in API [#29150](https://github.com/docker/docker/pull/29150)\n*   Fix incorrect opaque directory permission in overlay2 [#29093](https://github.com/docker/docker/pull/29093)\n*   Detect plugin content and error out on `docker pull` [#29297](https://github.com/docker/docker/pull/29297)\n\n### [Swarm Mode](#swarm-mode-1)\n\n*   Update Swarmkit [#29047](https://github.com/docker/docker/pull/29047)\n    *   orchestrator/global: Fix deadlock on updates [docker/swarmkit#1760](https://github.com/docker/swarmkit/pull/1760)\n    *   on leader switchover preserve the vxlan id for existing networks [docker/swarmkit#1773](https://github.com/docker/swarmkit/pull/1773)\n\n*   Refuse swarm spec not named \"default\" [#29152](https://github.com/docker/docker/pull/29152)\n\n### [Networking](#networking-2)\n\n*   Update libnetwork [#29004](https://github.com/docker/docker/pull/29004) [#29146](https://github.com/docker/docker/pull/29146)\n    \n    *   Fix panic in embedded DNS [docker/libnetwork#1561](https://github.com/docker/libnetwork/pull/1561)\n    *   Fix unmarhalling panic when passing --link-local-ip on global scope network [docker/libnetwork#1564](https://github.com/docker/libnetwork/pull/1564)\n    *   Fix panic when network plugin returns nil StaticRoutes [docker/libnetwork#1563](https://github.com/docker/libnetwork/pull/1563)\n    *   Fix panic in `osl.(*networkNamespace).DeleteNeighbor` [docker/libnetwork#1555](https://github.com/docker/libnetwork/pull/1555)\n    *   Fix panic in swarm networking concurrent map read/write [docker/libnetwork#1570](https://github.com/docker/libnetwork/pull/1570)\n    \n    *   Allow encrypted networks when running docker inside a container [docker/libnetwork#1502](https://github.com/docker/libnetwork/pull/1502)\n    \n    *   Do not block autoallocation of IPv6 pool [docker/libnetwork#1538](https://github.com/docker/libnetwork/pull/1538)\n    *   Set timeout for netlink calls [docker/libnetwork#1557](https://github.com/docker/libnetwork/pull/1557)\n    *   Increase networking local store timeout to one minute [docker/libkv#140](https://github.com/docker/libkv/pull/140)\n    *   Fix a panic in `libnetwork.(*sandbox).execFunc` [docker/libnetwork#1556](https://github.com/docker/libnetwork/pull/1556)\n    *   Honor icc=false for internal networks [docker/libnetwork#1525](https://github.com/docker/libnetwork/pull/1525)\n\n### [Logging](#logging-1)\n\n*   Update syslog log driver [#29150](https://github.com/docker/docker/pull/29150)\n\n### [Contrib](#contrib-3)\n\n*   Run \"dnf upgrade\" before installing in fedora [#29150](https://github.com/docker/docker/pull/29150)\n*   Add build-date back to RPM packages [#29150](https://github.com/docker/docker/pull/29150)\n*   deb package filename changed to include distro to distinguish between distro code names [#27829](https://github.com/docker/docker/pull/27829)\n\n**IMPORTANT**: Docker 1.12 ships with an updated systemd unit file for rpm based installs (which includes RHEL, Fedora, CentOS, and Oracle Linux 7). When upgrading from an older version of docker, the upgrade process may not automatically install the updated version of the unit file, or fail to start the docker service if;\n\n*   the systemd unit file (`/usr/lib/systemd/system/docker.service`) contains local changes, or\n*   a systemd drop-in file is present, and contains `-H fd://` in the `ExecStart` directive\n\nStarting the docker service will produce an error:\n\n```\nFailed to start docker.service: Unit docker.socket failed to load: No such file or directory.\n```\n\nor\n\n```\nno sockets found via socket activation: make sure the service was started by systemd.\n```\n\nTo resolve this:\n\n*   Backup the current version of the unit file, and replace the file with the [version that ships with docker 1.12](https://raw.githubusercontent.com/docker/docker/v1.12.0/contrib/init/systemd/docker.service.rpm)\n*   Remove the `Requires=docker.socket` directive from the `/usr/lib/systemd/system/docker.service` file if present\n*   Remove `-H fd://` from the `ExecStart` directive (both in the main unit file, and in any drop-in files present).\n\nAfter making those changes, run `sudo systemctl daemon-reload`, and `sudo systemctl restart docker` to reload changes and (re)start the docker daemon.\n\n### [Runtime](#runtime-5)\n\n*   Fix ambient capability usage in containers (CVE-2016-8867) [#27610](https://github.com/docker/docker/pull/27610)\n*   Prevent a deadlock in libcontainerd for Windows [#27136](https://github.com/docker/docker/pull/27136)\n*   Fix error reporting in CopyFileWithTar [#27075](https://github.com/docker/docker/pull/27075)\n\n*   Reset health status to starting when a container is restarted [#27387](https://github.com/docker/docker/pull/27387)\n*   Properly handle shared mount propagation in storage directory [#27609](https://github.com/docker/docker/pull/27609)\n\n*   Fix docker exec [#27610](https://github.com/docker/docker/pull/27610)\n*   Fix backward compatibility with containerdâ€™s events log [#27693](https://github.com/docker/docker/pull/27693)\n\n### [Swarm Mode](#swarm-mode-2)\n\n*   Fix conversion of restart-policy [#27062](https://github.com/docker/docker/pull/27062)\n\n*   Update Swarmkit [#27554](https://github.com/docker/docker/pull/27554)\n*   Avoid restarting a task that has already been restarted [docker/swarmkit#1305](https://github.com/docker/swarmkit/pull/1305)\n*   Allow duplicate published ports when they use different protocols [docker/swarmkit#1632](https://github.com/docker/swarmkit/pull/1632)\n*   Allow multiple randomly assigned published ports on service [docker/swarmkit#1657](https://github.com/docker/swarmkit/pull/1657)\n\n*   Fix panic when allocations happen at init time [docker/swarmkit#1651](https://github.com/docker/swarmkit/pull/1651)\n\n### [Networking](#networking-3)\n\n*   Update libnetwork [#27559](https://github.com/docker/docker/pull/27559)\n\n*   Fix race in serializing sandbox to string [docker/libnetwork#1495](https://github.com/docker/libnetwork/pull/1495)\n*   Fix race during deletion [docker/libnetwork#1503](https://github.com/docker/libnetwork/pull/1503)\n\n*   Reset endpoint port info on connectivity revoke in bridge driver [docker/libnetwork#1504](https://github.com/docker/libnetwork/pull/1504)\n\n*   Fix a deadlock in networking code [docker/libnetwork#1507](https://github.com/docker/libnetwork/pull/1507)\n*   Fix a race in load balancer state [docker/libnetwork#1512](https://github.com/docker/libnetwork/pull/1512)\n\n### [Logging](#logging-2)\n\n*   Update fluent-logger-golang to v1.2.1 [#27474](https://github.com/docker/docker/pull/27474)\n\n### [Contrib](#contrib-4)\n\n*   Update buildtags for armhf ubuntu-trusty [#27327](https://github.com/docker/docker/pull/27327)\n*   Add AppArmor to runc buildtags for armhf [#27421](https://github.com/docker/docker/pull/27421)\n\n**IMPORTANT**: Docker 1.12 ships with an updated systemd unit file for rpm based installs (which includes RHEL, Fedora, CentOS, and Oracle Linux 7). When upgrading from an older version of docker, the upgrade process may not automatically install the updated version of the unit file, or fail to start the docker service if;\n\n*   the systemd unit file (`/usr/lib/systemd/system/docker.service`) contains local changes, or\n*   a systemd drop-in file is present, and contains `-H fd://` in the `ExecStart` directive\n\nStarting the docker service will produce an error:\n\n```\nFailed to start docker.service: Unit docker.socket failed to load: No such file or directory.\n```\n\nor\n\n```\nno sockets found via socket activation: make sure the service was started by systemd.\n```\n\nTo resolve this:\n\n*   Backup the current version of the unit file, and replace the file with the [version that ships with docker 1.12](https://raw.githubusercontent.com/docker/docker/v1.12.0/contrib/init/systemd/docker.service.rpm)\n*   Remove the `Requires=docker.socket` directive from the `/usr/lib/systemd/system/docker.service` file if present\n*   Remove `-H fd://` from the `ExecStart` directive (both in the main unit file, and in any drop-in files present).\n\nAfter making those changes, run `sudo systemctl daemon-reload`, and `sudo systemctl restart docker` to reload changes and (re)start the docker daemon.\n\n### [Runtime](#runtime-6)\n\n*   Fix a panic due to a race condition filtering `docker ps` [#26049](https://github.com/docker/docker/pull/26049)\n\n*   Implement retry logic to prevent \"Unable to remove filesystem\" errors when using the aufs storage driver [#26536](https://github.com/docker/docker/pull/26536)\n*   Prevent devicemapper from removing device symlinks if `dm.use_deferred_removal` is enabled [#24740](https://github.com/docker/docker/pull/24740)\n\n*   Fix an issue where the CLI did not return correct exit codes if a command was run with invalid options [#26777](https://github.com/docker/docker/pull/26777)\n*   Fix a panic due to a bug in stdout / stderr processing in health checks [#26507](https://github.com/docker/docker/pull/26507)\n*   Fix exec's children handling [#26874](https://github.com/docker/docker/pull/26874)\n*   Fix exec form of HEALTHCHECK CMD [#26208](https://github.com/docker/docker/pull/26208)\n\n### [Networking](#networking-4)\n\n*   Fix a daemon start panic on armv5 [#24315](https://github.com/docker/docker/issues/24315)\n\n*   Vendor libnetwork [#26879](https://github.com/docker/docker/pull/26879) [#26953](https://github.com/docker/docker/pull/26953)\n*   Avoid returning early on agent join failures [docker/libnetwork#1473](https://github.com/docker/libnetwork/pull/1473)\n\n*   Fix service published port cleanup issues [docker/libetwork#1432](https://github.com/docker/libnetwork/pull/1432) [docker/libnetwork#1433](https://github.com/docker/libnetwork/pull/1433)\n\n*   Recover properly from transient gossip failures [docker/libnetwork#1446](https://github.com/docker/libnetwork/pull/1446)\n*   Disambiguate node names known to gossip cluster to avoid node name collision [docker/libnetwork#1451](https://github.com/docker/libnetwork/pull/1451)\n*   Honor user provided listen address for gossip [docker/libnetwork#1460](https://github.com/docker/libnetwork/pull/1460)\n*   Allow reachability via published port across services on the same host [docker/libnetwork#1398](https://github.com/docker/libnetwork/pull/1398)\n*   Change the ingress sandbox name from random id to just `ingress_sbox` [docker/libnetwork#1449](https://github.com/docker/libnetwork/pull/1449)\n\n*   Disable service discovery in ingress network [docker/libnetwork#1489](https://github.com/docker/libnetwork/pull/1489)\n\n### [Swarm Mode](#swarm-mode-3)\n\n*   Fix remote detection of a node's address when it joins the cluster [#26211](https://github.com/docker/docker/pull/26211)\n*   Vendor SwarmKit [#26765](https://github.com/docker/docker/pull/26765)\n*   Bounce session after failed status update [docker/swarmkit#1539](https://github.com/docker/swarmkit/pull/1539)\n\n*   Fix possible raft deadlocks [docker/swarmkit#1537](https://github.com/docker/swarmkit/pull/1537)\n*   Fix panic and endpoint leak when a service is updated with no endpoints [docker/swarmkit#1481](https://github.com/docker/swarmkit/pull/1481)\n\n*   Produce an error if the same port is published twice on `service create` or `service update` [docker/swarmkit#1495](https://github.com/docker/swarmkit/pull/1495)\n\n*   Fix an issue where changes to a service were not detected, resulting in the service not being updated [docker/swarmkit#1497](https://github.com/docker/swarmkit/pull/1497)\n*   Do not allow service creation on ingress network [docker/swarmkit#1600](https://github.com/docker/swarmkit/pull/1600)\n\n### [Contrib](#contrib-5)\n\n*   Update the debian sysv-init script to use `dockerd` instead of `docker daemon` [#25869](https://github.com/docker/docker/pull/25869)\n*   Improve stability when running the docker client on MacOS Sierra [#26875](https://github.com/docker/docker/pull/26875)\n\n*   Fix installation on debian stretch [#27184](https://github.com/docker/docker/pull/27184)\n\n### [Windows](#windows-1)\n\n*   Fix an issue where arrow-navigation did not work when running the docker client in ConEmu [#25578](https://github.com/docker/docker/pull/25578)\n\n**IMPORTANT**: Docker 1.12 ships with an updated systemd unit file for rpm based installs (which includes RHEL, Fedora, CentOS, and Oracle Linux 7). When upgrading from an older version of docker, the upgrade process may not automatically install the updated version of the unit file, or fail to start the docker service if;\n\n*   the systemd unit file (`/usr/lib/systemd/system/docker.service`) contains local changes, or\n*   a systemd drop-in file is present, and contains `-H fd://` in the `ExecStart` directive\n\nStarting the docker service will produce an error:\n\n```\nFailed to start docker.service: Unit docker.socket failed to load: No such file or directory.\n```\n\nor\n\n```\nno sockets found via socket activation: make sure the service was started by systemd.\n```\n\nTo resolve this:\n\n*   Backup the current version of the unit file, and replace the file with the [version that ships with docker 1.12](https://raw.githubusercontent.com/docker/docker/v1.12.0/contrib/init/systemd/docker.service.rpm)\n*   Remove the `Requires=docker.socket` directive from the `/usr/lib/systemd/system/docker.service` file if present\n*   Remove `-H fd://` from the `ExecStart` directive (both in the main unit file, and in any drop-in files present).\n\nAfter making those changes, run `sudo systemctl daemon-reload`, and `sudo systemctl restart docker` to reload changes and (re)start the docker daemon.\n\n### [Client](#client)\n\n*   Add `Joined at` information in `node inspect --pretty` [#25512](https://github.com/docker/docker/pull/25512)\n\n*   Fix a crash on `service inspect` [#25454](https://github.com/docker/docker/pull/25454)\n*   Fix issue preventing `service update --env-add` to work as intended [#25427](https://github.com/docker/docker/pull/25427)\n*   Fix issue preventing `service update --publish-add` to work as intended [#25428](https://github.com/docker/docker/pull/25428)\n*   Remove `service update --network-add` and `service update --network-rm` flags because this feature is not yet implemented in 1.12, but was inadvertently added to the client in 1.12.0 [#25646](https://github.com/docker/docker/pull/25646)\n\n### [Contrib](#contrib-6)\n\n*   Official ARM installation for Debian Jessie, Ubuntu Trusty, and Raspbian Jessie [#24815](https://github.com/docker/docker/pull/24815) [#25591](https://github.com/docker/docker/pull/25637)\n\n*   Add selinux policy per distro/version, fixing issue preventing successful installation on Fedora 24, and Oracle Linux [#25334](https://github.com/docker/docker/pull/25334) [#25593](https://github.com/docker/docker/pull/25593)\n\n### [Networking](#networking-5)\n\n*   Fix issue that prevented containers to be accessed by hostname with Docker overlay driver in Swarm Mode [#25603](https://github.com/docker/docker/pull/25603) [#25648](https://github.com/docker/docker/pull/25648)\n*   Fix random network issues on service with published port [#25603](https://github.com/docker/docker/pull/25603)\n*   Fix unreliable inter-service communication after scaling down and up [#25603](https://github.com/docker/docker/pull/25603)\n*   Fix issue where removing all tasks on a node and adding them back breaks connectivity with other services [#25603](https://github.com/docker/docker/pull/25603)\n*   Fix issue where a task that fails to start results in a race, causing a `network xxx not found` error that masks the actual error [#25550](https://github.com/docker/docker/pull/25550)\n*   Relax validation of SRV records for external services that use SRV records not formatted according to RFC 2782 [#25739](https://github.com/docker/docker/pull/25739)\n\n### [Plugins (experimental)](#plugins-experimental)\n\n*   Make daemon events listen for plugin lifecycle events [#24760](https://github.com/docker/docker/pull/24760)\n*   Check for plugin state before enabling plugin [#25033](https://github.com/docker/docker/pull/25033)\n\n*   Remove plugin root from filesystem on `plugin rm` [#25187](https://github.com/docker/docker/pull/25187)\n*   Prevent deadlock when more than one plugin is installed [#25384](https://github.com/docker/docker/pull/25384)\n\n### [Runtime](#runtime-7)\n\n*   Mask join tokens in daemon logs [#25346](https://github.com/docker/docker/pull/25346)\n\n*   Fix `docker ps --filter` causing the results to no longer be sorted by creation time [#25387](https://github.com/docker/docker/pull/25387)\n*   Fix various crashes [#25053](https://github.com/docker/docker/pull/25053)\n\n### [Security](#security-1)\n\n*   Add `/proc/timer_list` to the masked paths list to prevent information leak from the host [#25630](https://github.com/docker/docker/pull/25630)\n*   Allow systemd to run with only `--cap-add SYS_ADMIN` rather than having to also add `--cap-add DAC_READ_SEARCH` or disabling seccomp filtering [#25567](https://github.com/docker/docker/pull/25567)\n\n### [Swarm](#swarm)\n\n*   Fix an issue where the swarm can get stuck electing a new leader after quorum is lost [#25055](https://github.com/docker/docker/issues/25055)\n*   Fix unwanted rescheduling of containers after a leader failover [#25017](https://github.com/docker/docker/issues/25017)\n*   Change swarm root CA key to P256 curve [swarmkit#1376](https://github.com/docker/swarmkit/pull/1376)\n*   Allow forced removal of a node from a swarm [#25159](https://github.com/docker/docker/pull/25159)\n*   Fix connection leak when a node leaves a swarm [swarmkit/#1277](https://github.com/docker/swarmkit/pull/1277)\n*   Backdate swarm certificates by one hour to tolerate more clock skew [swarmkit/#1243](https://github.com/docker/swarmkit/pull/1243)\n*   Avoid high CPU use with many unschedulable tasks [swarmkit/#1287](https://github.com/docker/swarmkit/pull/1287)\n*   Fix issue with global tasks not starting up [swarmkit/#1295](https://github.com/docker/swarmkit/pull/1295)\n*   Garbage collect raft logs [swarmkit/#1327](https://github.com/docker/swarmkit/pull/1327)\n\n### [Volume](#volume-1)\n\n*   Persist local volume options after a daemon restart [#25316](https://github.com/docker/docker/pull/25316)\n*   Fix an issue where the mount ID was not returned on volume unmount [#25333](https://github.com/docker/docker/pull/25333)\n*   Fix an issue where a volume mount could inadvertently create a bind mount [#25309](https://github.com/docker/docker/pull/25309)\n*   `docker service create --mount type=bind,...` now correctly validates if the source path exists, instead of creating it [#25494](https://github.com/docker/docker/pull/25494)\n\n**IMPORTANT**: Docker 1.12.0 ships with an updated systemd unit file for rpm based installs (which includes RHEL, Fedora, CentOS, and Oracle Linux 7). When upgrading from an older version of docker, the upgrade process may not automatically install the updated version of the unit file, or fail to start the docker service if;\n\n*   the systemd unit file (`/usr/lib/systemd/system/docker.service`) contains local changes, or\n*   a systemd drop-in file is present, and contains `-H fd://` in the `ExecStart` directive\n\nStarting the docker service will produce an error:\n\n```\nFailed to start docker.service: Unit docker.socket failed to load: No such file or directory.\n```\n\nor\n\n```\nno sockets found via socket activation: make sure the service was started by systemd.\n```\n\nTo resolve this:\n\n*   Backup the current version of the unit file, and replace the file with the [version that ships with docker 1.12](https://raw.githubusercontent.com/docker/docker/v1.12.0/contrib/init/systemd/docker.service.rpm)\n*   Remove the `Requires=docker.socket` directive from the `/usr/lib/systemd/system/docker.service` file if present\n*   Remove `-H fd://` from the `ExecStart` directive (both in the main unit file, and in any drop-in files present).\n\nAfter making those changes, run `sudo systemctl daemon-reload`, and `sudo systemctl restart docker` to reload changes and (re)start the docker daemon.\n\n**IMPORTANT**: With Docker 1.12, a Linux docker installation now has two additional binaries; `dockerd`, and `docker-proxy`. If you have scripts for installing docker, make sure to update them accordingly.\n\n### [Builder](#builder-1)\n\n*   New `HEALTHCHECK` Dockerfile instruction to support user-defined healthchecks [#23218](https://github.com/docker/docker/pull/23218)\n*   New `SHELL` Dockerfile instruction to specify the default shell when using the shell form for commands in a Dockerfile [#22489](https://github.com/docker/docker/pull/22489)\n*   Add `#escape=` Dockerfile directive to support platform-specific parsing of file paths in Dockerfile [#22268](https://github.com/docker/docker/pull/22268)\n*   Add support for comments in `.dockerignore` [#23111](https://github.com/docker/docker/pull/23111)\n\n*   Support for UTF-8 in Dockerfiles [#23372](https://github.com/docker/docker/pull/23372)\n*   Skip UTF-8 BOM bytes from `Dockerfile` and `.dockerignore` if exist [#23234](https://github.com/docker/docker/pull/23234)\n*   Windows: support for `ARG` to match Linux [#22508](https://github.com/docker/docker/pull/22508)\n\n*   Fix error message when building using a daemon with the bridge network disabled [#22932](https://github.com/docker/docker/pull/22932)\n\n### [Contrib](#contrib-7)\n\n*   Enable seccomp for Centos 7 and Oracle Linux 7 [#22344](https://github.com/docker/docker/pull/22344)\n\n*   Remove MountFlags in systemd unit to allow shared mount propagation [#22806](https://github.com/docker/docker/pull/22806)\n\n### [Distribution](#distribution-1)\n\n*   Add `--max-concurrent-downloads` and `--max-concurrent-uploads` daemon flags useful for situations where network connections don't support multiple downloads/uploads [#22445](https://github.com/docker/docker/pull/22445)\n\n*   Registry operations now honor the `ALL_PROXY` environment variable [#22316](https://github.com/docker/docker/pull/22316)\n*   Provide more information to the user on `docker load` [#23377](https://github.com/docker/docker/pull/23377)\n*   Always save registry digest metadata about images pushed and pulled [#23996](https://github.com/docker/docker/pull/23996)\n\n### [Logging](#logging-3)\n\n*   Syslog logging driver now supports DGRAM sockets [#21613](https://github.com/docker/docker/pull/21613)\n*   Add `--details` option to `docker logs` to also display log tags [#21889](https://github.com/docker/docker/pull/21889)\n*   Enable syslog logger to have access to env and labels [#21724](https://github.com/docker/docker/pull/21724)\n*   An additional syslog-format option `rfc5424micro` to allow microsecond resolution in syslog timestamp [#21844](https://github.com/docker/docker/pull/21844)\n\n*   Inherit the daemon log options when creating containers [#21153](https://github.com/docker/docker/pull/21153)\n*   Remove `docker/` prefix from log messages tag and replace it with `{{.DaemonName}}` so that users have the option of changing the prefix [#22384](https://github.com/docker/docker/pull/22384)\n\n### [Networking](#networking-6)\n\n*   Built-in Virtual-IP based internal and ingress load-balancing using IPVS [#23361](https://github.com/docker/docker/pull/23361)\n*   Routing Mesh using ingress overlay network [#23361](https://github.com/docker/docker/pull/23361)\n*   Secured multi-host overlay networking using encrypted control-plane and Data-plane [#23361](https://github.com/docker/docker/pull/23361)\n*   MacVlan driver is out of experimental [#23524](https://github.com/docker/docker/pull/23524)\n*   Add `driver` filter to `network ls` [#22319](https://github.com/docker/docker/pull/22319)\n*   Adding `network` filter to `docker ps --filter` [#23300](https://github.com/docker/docker/pull/23300)\n*   Add `--link-local-ip` flag to `create`, `run` and `network connect` to specify a container's link-local address [#23415](https://github.com/docker/docker/pull/23415)\n*   Add network label filter support [#21495](https://github.com/docker/docker/pull/21495)\n\n*   Removed dependency on external KV-Store for Overlay networking in Swarm-Mode [#23361](https://github.com/docker/docker/pull/23361)\n*   Add container's short-id as default network alias [#21901](https://github.com/docker/docker/pull/21901)\n*   `run` options `--dns` and `--net=host` are no longer mutually exclusive [#22408](https://github.com/docker/docker/pull/22408)\n\n*   Fix DNS issue when renaming containers with generated names [#22716](https://github.com/docker/docker/pull/22716)\n*   Allow both `network inspect -f {{.Id}}` and `network inspect -f {{.ID}}` to address inconsistency with inspect output [#23226](https://github.com/docker/docker/pull/23226)\n\n### [Plugins (experimental)](#plugins-experimental-1)\n\n*   New `plugin` command to manager plugins with `install`, `enable`, `disable`, `rm`, `inspect`, `set` subcommands [#23446](https://github.com/docker/docker/pull/23446)\n\n### [Remote API (v1.24) & Client](#remote-api-v124--client)\n\n*   Split the binary into two: `docker` (client) and `dockerd` (daemon) [#20639](https://github.com/docker/docker/pull/20639)\n*   Add `before` and `since` filters to `docker images --filter` [#22908](https://github.com/docker/docker/pull/22908)\n*   Add `--limit` option to `docker search` [#23107](https://github.com/docker/docker/pull/23107)\n*   Add `--filter` option to `docker search` [#22369](https://github.com/docker/docker/pull/22369)\n*   Add security options to `docker info` output [#21172](https://github.com/docker/docker/pull/21172) [#23520](https://github.com/docker/docker/pull/23520)\n*   Add insecure registries to `docker info` output [#20410](https://github.com/docker/docker/pull/20410)\n*   Extend Docker authorization with TLS user information [#21556](https://github.com/docker/docker/pull/21556)\n*   devicemapper: expose Minimum Thin Pool Free Space through `docker info` [#21945](https://github.com/docker/docker/pull/21945)\n\n*   API now returns a JSON object when an error occurs making it more consistent [#22880](https://github.com/docker/docker/pull/22880)\n\n*   Prevent `docker run -i --restart` from hanging on exit [#22777](https://github.com/docker/docker/pull/22777)\n*   Fix API/CLI discrepancy on hostname validation [#21641](https://github.com/docker/docker/pull/21641)\n*   Fix discrepancy in the format of sizes in `stats` from HumanSize to BytesSize [#21773](https://github.com/docker/docker/pull/21773)\n*   authz: when request is denied return forbbiden exit code (403) [#22448](https://github.com/docker/docker/pull/22448)\n*   Windows: fix tty-related displaying issues [#23878](https://github.com/docker/docker/pull/23878)\n\n### [Runtime](#runtime-8)\n\n*   Split the userland proxy to a separate binary (`docker-proxy`) [#23312](https://github.com/docker/docker/pull/23312)\n*   Add `--live-restore` daemon flag to keep containers running when daemon shuts down, and regain control on startup [#23213](https://github.com/docker/docker/pull/23213)\n*   Ability to add OCI-compatible runtimes (via `--add-runtime` daemon flag) and select one with `--runtime` on `create` and `run` [#22983](https://github.com/docker/docker/pull/22983)\n*   New `overlay2` graphdriver for Linux 4.0+ with multiple lower directory support [#22126](https://github.com/docker/docker/pull/22126)\n*   New load/save image events [#22137](https://github.com/docker/docker/pull/22137)\n*   Add support for reloading daemon configuration through systemd [#22446](https://github.com/docker/docker/pull/22446)\n*   Add disk quota support for btrfs [#19651](https://github.com/docker/docker/pull/19651)\n*   Add disk quota support for zfs [#21946](https://github.com/docker/docker/pull/21946)\n*   Add support for `docker run --pid=container:<id>` [#22481](https://github.com/docker/docker/pull/22481)\n*   Align default seccomp profile with selected capabilities [#22554](https://github.com/docker/docker/pull/22554)\n*   Add a `daemon reload` event when the daemon reloads its configuration [#22590](https://github.com/docker/docker/pull/22590)\n*   Add `trace` capability in the pprof profiler to show execution traces in binary form [#22715](https://github.com/docker/docker/pull/22715)\n*   Add a `detach` event [#22898](https://github.com/docker/docker/pull/22898)\n*   Add support for setting sysctls with `--sysctl` [#19265](https://github.com/docker/docker/pull/19265)\n*   Add `--storage-opt` flag to `create` and `run` allowing to set `size` on devicemapper [#19367](https://github.com/docker/docker/pull/19367)\n*   Add `--oom-score-adjust` daemon flag with a default value of `-500` making the daemon less likely to be killed before containers [#24516](https://github.com/docker/docker/pull/24516)\n\n*   Undeprecate the `-c` short alias of `--cpu-shares` on `run`, `build`, `create`, `update` [#22621](https://github.com/docker/docker/pull/22621)\n*   Prevent from using aufs and overlay graphdrivers on an eCryptfs mount [#23121](https://github.com/docker/docker/pull/23121)\n\n*   Fix issues with tmpfs mount ordering [#22329](https://github.com/docker/docker/pull/22329)\n*   Created containers are no longer listed on `docker ps -a -f exited=0` [#21947](https://github.com/docker/docker/pull/21947)\n*   Fix an issue where containers are stuck in a \"Removal In Progress\" state [#22423](https://github.com/docker/docker/pull/22423)\n*   Fix bug that was returning an HTTP 500 instead of a 400 when not specifying a command on run/create [#22762](https://github.com/docker/docker/pull/22762)\n*   Fix bug with `--detach-keys` whereby input matching a prefix of the detach key was not preserved [#22943](https://github.com/docker/docker/pull/22943)\n*   SELinux labeling is now disabled when using `--privileged` mode [#22993](https://github.com/docker/docker/pull/22993)\n*   If volume-mounted into a container, `/etc/hosts`, `/etc/resolv.conf`, `/etc/hostname` are no longer SELinux-relabeled [#22993](https://github.com/docker/docker/pull/22993)\n*   Fix inconsistency in `--tmpfs` behavior regarding mount options [#22438](https://github.com/docker/docker/pull/22438)\n*   Fix an issue where daemon hangs at startup [#23148](https://github.com/docker/docker/pull/23148)\n*   Ignore SIGPIPE events to prevent journald restarts to crash docker in some cases [#22460](https://github.com/docker/docker/pull/22460)\n*   Containers are not removed from stats list on error [#20835](https://github.com/docker/docker/pull/20835)\n*   Fix `on-failure` restart policy when daemon restarts [#20853](https://github.com/docker/docker/pull/20853)\n*   Fix an issue with `stats` when a container is using another container's network [#21904](https://github.com/docker/docker/pull/21904)\n\n### [Swarm Mode](#swarm-mode-4)\n\n*   New `swarm` command to manage swarms with `init`, `join`, `join-token`, `leave`, `update` subcommands [#23361](https://github.com/docker/docker/pull/23361) [#24823](https://github.com/docker/docker/pull/24823)\n*   New `service` command to manage swarm-wide services with `create`, `inspect`, `update`, `rm`, `ps` subcommands [#23361](https://github.com/docker/docker/pull/23361) [#25140](https://github.com/docker/docker/pull/25140)\n*   New `node` command to manage nodes with `accept`, `promote`, `demote`, `inspect`, `update`, `ps`, `ls` and `rm` subcommands [#23361](https://github.com/docker/docker/pull/23361) [#25140](https://github.com/docker/docker/pull/25140)\n*   (experimental) New `stack` and `deploy` commands to manage and deploy multi-service applications [#23522](https://github.com/docker/docker/pull/23522) [#25140](https://github.com/docker/docker/pull/25140)\n\n### [Volume](#volume-2)\n\n*   Add support for local and global volume scopes (analogous to network scopes) [#22077](https://github.com/docker/docker/pull/22077)\n*   Allow volume drivers to provide a `Status` field [#21006](https://github.com/docker/docker/pull/21006)\n*   Add name/driver filter support for volume [#21361](https://github.com/docker/docker/pull/21361)\n\n*   Mount/Unmount operations now receives an opaque ID to allow volume drivers to differentiate between two callers [#21015](https://github.com/docker/docker/pull/21015)\n\n*   Fix issue preventing to remove a volume in a corner case [#22103](https://github.com/docker/docker/pull/22103)\n*   Windows: Enable auto-creation of host-path to match Linux [#22094](https://github.com/docker/docker/pull/22094)\n\n### [Deprecation](#deprecation-1)\n\n*   Environment variables `DOCKER_CONTENT_TRUST_OFFLINE_PASSPHRASE` and `DOCKER_CONTENT_TRUST_TAGGING_PASSPHRASE` have been renamed to `DOCKER_CONTENT_TRUST_ROOT_PASSPHRASE` and `DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE` respectively [#22574](https://github.com/docker/docker/pull/22574)\n*   Remove deprecated `syslog-tag`, `gelf-tag`, `fluentd-tag` log option in favor of the more generic `tag` one [#22620](https://github.com/docker/docker/pull/22620)\n*   Remove deprecated feature of passing HostConfig at API container start [#22570](https://github.com/docker/docker/pull/22570)\n*   Remove deprecated `-f`/`--force` flag on docker tag [#23090](https://github.com/docker/docker/pull/23090)\n*   Remove deprecated `/containers/<id|name>/copy` endpoint [#22149](https://github.com/docker/docker/pull/22149)\n*   Remove deprecated `docker ps` flags `--since` and `--before` [#22138](https://github.com/docker/docker/pull/22138)\n*   Deprecate the old 3-args form of `docker import` [#23273](https://github.com/docker/docker/pull/23273)\n\n### [Networking](#networking-7)\n\n*   Fix a stale endpoint issue on overlay networks during ungraceful restart ( [#23015](https://github.com/docker/docker/pull/23015))\n*   Fix an issue where the wrong port could be reported by `docker inspect/ps/port` ( [#22997](https://github.com/docker/docker/pull/22997))\n\n### [Runtime](#runtime-9)\n\n*   Fix a potential panic when running `docker build` ( [#23032](https://github.com/docker/docker/pull/23032))\n*   Fix interpretation of `--user` parameter ( [#22998](https://github.com/docker/docker/pull/22998))\n*   Fix a bug preventing container statistics to be correctly reported ( [#22955](https://github.com/docker/docker/pull/22955))\n*   Fix an issue preventing container to be restarted after daemon restart ( [#22947](https://github.com/docker/docker/pull/22947))\n*   Fix issues when running 32 bit binaries on Ubuntu 16.04 ( [#22922](https://github.com/docker/docker/pull/22922))\n*   Fix a possible deadlock on image deletion and container attach ( [#22918](https://github.com/docker/docker/pull/22918))\n*   Fix an issue where containers fail to start after a daemon restart if they depend on a containerized cluster store ( [#22561](https://github.com/docker/docker/pull/22561))\n*   Fix an issue causing `docker ps` to hang on CentOS when using devicemapper ( [#22168](https://github.com/docker/docker/pull/22168), [#23067](https://github.com/docker/docker/pull/23067))\n*   Fix a bug preventing to `docker exec` into a container when using devicemapper ( [#22168](https://github.com/docker/docker/pull/22168), [#23067](https://github.com/docker/docker/pull/23067))\n\n### [Distribution](#distribution-2)\n\n*   Fix schema2 manifest media type to be of type `application/vnd.docker.container.image.v1+json` ( [#21949](https://github.com/docker/docker/pull/21949))\n\n### [Documentation](#documentation)\n\n*   Add missing API documentation for changes introduced with 1.11.0 ( [#22048](https://github.com/docker/docker/pull/22048))\n\n### [Builder](#builder-2)\n\n*   Append label passed to `docker build` as arguments as an implicit `LABEL` command at the end of the processed `Dockerfile` ( [#22184](https://github.com/docker/docker/pull/22184))\n\n### [Networking](#networking-8)\n\n*   Fix a panic that would occur when forwarding DNS query ( [#22261](https://github.com/docker/docker/pull/22261))\n*   Fix an issue where OS threads could end up within an incorrect network namespace when using user defined networks ( [#22261](https://github.com/docker/docker/pull/22261))\n\n### [Runtime](#runtime-10)\n\n*   Fix a bug preventing labels configuration to be reloaded via the config file ( [#22299](https://github.com/docker/docker/pull/22299))\n*   Fix a regression where container mounting `/var/run` would prevent other containers from being removed ( [#22256](https://github.com/docker/docker/pull/22256))\n*   Fix an issue where it would be impossible to update both `memory-swap` and `memory` value together ( [#22255](https://github.com/docker/docker/pull/22255))\n*   Fix a regression from 1.11.0 where the `/auth` endpoint would not initialize `serveraddress` if it is not provided ( [#22254](https://github.com/docker/docker/pull/22254))\n*   Add missing cleanup of container temporary files when cancelling a schedule restart ( [#22237](https://github.com/docker/docker/pull/22237))\n*   Remove scary error message when no restart policy is specified ( [#21993](https://github.com/docker/docker/pull/21993))\n*   Fix a panic that would occur when the plugins were activated via the json spec ( [#22191](https://github.com/docker/docker/pull/22191))\n*   Fix restart backoff logic to correctly reset delay if container ran for at least 10secs ( [#22125](https://github.com/docker/docker/pull/22125))\n*   Remove error message when a container restart get cancelled ( [#22123](https://github.com/docker/docker/pull/22123))\n*   Fix an issue where `docker` would not correctly clean up after `docker exec` ( [#22121](https://github.com/docker/docker/pull/22121))\n*   Fix a panic that could occur when serving concurrent `docker stats` commands ( [#22120](https://github.com/docker/docker/pull/22120))\\`\n*   Revert deprecation of non-existent host directories auto-creation ( [#22065](https://github.com/docker/docker/pull/22065))\n*   Hide misleading rpc error on daemon shutdown ( [#22058](https://github.com/docker/docker/pull/22058))\n\n**IMPORTANT**: With Docker 1.11, a Linux docker installation is now made of 4 binaries (`docker`, [`docker-containerd`](https://github.com/docker/containerd), [`docker-containerd-shim`](https://github.com/docker/containerd) and [`docker-runc`](https://github.com/opencontainers/runc)). If you have scripts relying on docker being a single static binaries, make sure to update them. Interaction with the daemon stay the same otherwise, the usage of the other binaries should be transparent. A Windows docker installation remains a single binary, `docker.exe`.\n\n### [Builder](#builder-3)\n\n*   Fix a bug where Docker would not use the correct uid/gid when processing the `WORKDIR` command ( [#21033](https://github.com/docker/docker/pull/21033))\n*   Fix a bug where copy operations with userns would not use the proper uid/gid ( [#20782](https://github.com/docker/docker/pull/20782), [#21162](https://github.com/docker/docker/pull/21162))\n\n### [Client](#client-1)\n\n*   Usage of the `:` separator for security option has been deprecated. `=` should be used instead ( [#21232](https://github.com/docker/docker/pull/21232))\n\n*   The client user agent is now passed to the registry on `pull`, `build`, `push`, `login` and `search` operations ( [#21306](https://github.com/docker/docker/pull/21306), [#21373](https://github.com/docker/docker/pull/21373))\n\n*   Allow setting the Domainname and Hostname separately through the API ( [#20200](https://github.com/docker/docker/pull/20200))\n*   Docker info will now warn users if it can not detect the kernel version or the operating system ( [#21128](https://github.com/docker/docker/pull/21128))\n\n*   Fix an issue where `docker stats --no-stream` output could be all 0s ( [#20803](https://github.com/docker/docker/pull/20803))\n*   Fix a bug where some newly started container would not appear in a running `docker stats` command ( [#20792](https://github.com/docker/docker/pull/20792))\n\n*   Post processing is no longer enabled for linux-cgo terminals ( [#20587](https://github.com/docker/docker/pull/20587))\n\n*   Values to `--hostname` are now refused if they do not comply with [RFC1123](https://tools.ietf.org/html/rfc1123) ( [#20566](https://github.com/docker/docker/pull/20566))\n\n*   Docker learned how to use a SOCKS proxy ( [#20366](https://github.com/docker/docker/pull/20366), [#18373](https://github.com/docker/docker/pull/18373))\n*   Docker now supports external credential stores ( [#20107](https://github.com/docker/docker/pull/20107))\n\n*   `docker ps` now supports displaying the list of volumes mounted inside a container ( [#20017](https://github.com/docker/docker/pull/20017))\n*   `docker info` now also reports Docker's root directory location ( [#19986](https://github.com/docker/docker/pull/19986))\n\n*   Docker now prohibits login in with an empty username (spaces are trimmed) ( [#19806](https://github.com/docker/docker/pull/19806))\n\n*   Docker events attributes are now sorted by key ( [#19761](https://github.com/docker/docker/pull/19761))\n*   `docker ps` no longer shows exported port for stopped containers ( [#19483](https://github.com/docker/docker/pull/19483))\n\n*   Docker now cleans after itself if a save/export command fails ( [#17849](https://github.com/docker/docker/pull/17849))\n\n*   Docker load learned how to display a progress bar ( [#17329](https://github.com/docker/docker/pull/17329), [#120078](https://github.com/docker/docker/pull/20078))\n\n### [Distribution](#distribution-3)\n\n*   Fix a panic that occurred when pulling an image with 0 layers ( [#21222](https://github.com/docker/docker/pull/21222))\n*   Fix a panic that could occur on error while pushing to a registry with a misconfigured token service ( [#21212](https://github.com/docker/docker/pull/21212))\n\n*   All first-level delegation roles are now signed when doing a trusted push ( [#21046](https://github.com/docker/docker/pull/21046))\n*   OAuth support for registries was added ( [#20970](https://github.com/docker/docker/pull/20970))\n\n*   `docker login` now handles token using the implementation found in [docker/distribution](https://github.com/docker/distribution) ( [#20832](https://github.com/docker/docker/pull/20832))\n*   `docker login` will no longer prompt for an email ( [#20565](https://github.com/docker/docker/pull/20565))\n*   Docker will now fallback to registry V1 if no basic auth credentials are available ( [#20241](https://github.com/docker/docker/pull/20241))\n*   Docker will now try to resume layer download where it left off after a network error/timeout ( [#19840](https://github.com/docker/docker/pull/19840))\n\n*   Fix generated manifest mediaType when pushing cross-repository ( [#19509](https://github.com/docker/docker/pull/19509))\n*   Fix docker requesting additional push credentials when pulling an image if Content Trust is enabled ( [#20382](https://github.com/docker/docker/pull/20382))\n\n### [Logging](#logging-4)\n\n*   Fix a race in the journald log driver ( [#21311](https://github.com/docker/docker/pull/21311))\n\n*   Docker syslog driver now uses the RFC-5424 format when emitting logs ( [#20121](https://github.com/docker/docker/pull/20121))\n*   Docker GELF log driver now allows to specify the compression algorithm and level via the `gelf-compression-type` and `gelf-compression-level` options ( [#19831](https://github.com/docker/docker/pull/19831))\n*   Docker daemon learned to output uncolorized logs via the `--raw-logs` options ( [#19794](https://github.com/docker/docker/pull/19794))\n\n*   Docker, on Windows platform, now includes an ETW (Event Tracing in Windows) logging driver named `etwlogs` ( [#19689](https://github.com/docker/docker/pull/19689))\n\n*   Journald log driver learned how to handle tags ( [#19564](https://github.com/docker/docker/pull/19564))\n\n*   The fluentd log driver learned the following options: `fluentd-address`, `fluentd-buffer-limit`, `fluentd-retry-wait`, `fluentd-max-retries` and `fluentd-async-connect` ( [#19439](https://github.com/docker/docker/pull/19439))\n*   Docker learned to send log to Google Cloud via the new `gcplogs` logging driver. ( [#18766](https://github.com/docker/docker/pull/18766))\n\n### [Misc](#misc)\n\n*   When saving linked images together with `docker save` a subsequent `docker load` will correctly restore their parent/child relationship ( [#21385](https://github.com/docker/docker/pull/21385))\n*   Support for building the Docker cli for OpenBSD was added ( [#21325](https://github.com/docker/docker/pull/21325))\n*   Labels can now be applied at network, volume and image creation ( [#21270](https://github.com/docker/docker/pull/21270))\n\n*   The `dockremap` is now created as a system user ( [#21266](https://github.com/docker/docker/pull/21266))\n\n*   Fix a few response body leaks ( [#21258](https://github.com/docker/docker/pull/21258))\n*   Docker, when run as a service with systemd, will now properly manage its processes cgroups ( [#20633](https://github.com/docker/docker/pull/20633))\n\n*   `docker info` now reports the value of cgroup KernelMemory or emits a warning if it is not supported ( [#20863](https://github.com/docker/docker/pull/20863))\n*   `docker info` now also reports the cgroup driver in use ( [#20388](https://github.com/docker/docker/pull/20388))\n*   Docker completion is now available on PowerShell ( [#19894](https://github.com/docker/docker/pull/19894))\n*   `dockerinit` is no more ( [#19490](https://github.com/docker/docker/pull/19490), [#19851](https://github.com/docker/docker/pull/19851))\n\n*   Support for building Docker on arm64 was added ( [#19013](https://github.com/docker/docker/pull/19013))\n*   Experimental support for building docker.exe in a native Windows Docker installation ( [#18348](https://github.com/docker/docker/pull/18348))\n\n### [Networking](#networking-9)\n\n*   Fix panic if a node is forcibly removed from the cluster ( [#21671](https://github.com/docker/docker/pull/21671))\n*   Fix \"error creating vxlan interface\" when starting a container in a Swarm cluster ( [#21671](https://github.com/docker/docker/pull/21671))\n\n*   `docker network inspect` will now report all endpoints whether they have an active container or not ( [#21160](https://github.com/docker/docker/pull/21160))\n\n*   Experimental support for the MacVlan and IPVlan network drivers has been added ( [#21122](https://github.com/docker/docker/pull/21122))\n\n*   Output of `docker network ls` is now sorted by network name ( [#20383](https://github.com/docker/docker/pull/20383))\n\n*   Fix a bug where Docker would allow a network to be created with the reserved `default` name ( [#19431](https://github.com/docker/docker/pull/19431))\n\n*   `docker network inspect` returns whether a network is internal or not ( [#19357](https://github.com/docker/docker/pull/19357))\n\n*   Control IPv6 via explicit option when creating a network (`docker network create --ipv6`). This shows up as a new `EnableIPv6` field in `docker network inspect` ( [#17513](https://github.com/docker/docker/pull/17513))\n\n*   Support for AAAA Records (aka IPv6 Service Discovery) in embedded DNS Server ( [#21396](https://github.com/docker/docker/pull/21396))\n\n*   Fix to not forward docker domain IPv6 queries to external servers ( [#21396](https://github.com/docker/docker/pull/21396))\n\n*   Multiple A/AAAA records from embedded DNS Server for DNS Round robin ( [#21019](https://github.com/docker/docker/pull/21019))\n\n*   Fix endpoint count inconsistency after an ungraceful dameon restart ( [#21261](https://github.com/docker/docker/pull/21261))\n*   Move the ownership of exposed ports and port-mapping options from Endpoint to Sandbox ( [#21019](https://github.com/docker/docker/pull/21019))\n*   Fixed a bug which prevents docker reload when host is configured with ipv6.disable=1 ( [#21019](https://github.com/docker/docker/pull/21019))\n*   Added inbuilt nil IPAM driver ( [#21019](https://github.com/docker/docker/pull/21019))\n*   Fixed bug in iptables.Exists() logic [#21019](https://github.com/docker/docker/pull/21019)\n*   Fixed a Veth interface leak when using overlay network ( [#21019](https://github.com/docker/docker/pull/21019))\n*   Fixed a bug which prevents docker reload after a network delete during shutdown ( [#20214](https://github.com/docker/docker/pull/20214))\n*   Make sure iptables chains are recreated on firewalld reload ( [#20419](https://github.com/docker/docker/pull/20419))\n*   Allow to pass global datastore during config reload ( [#20419](https://github.com/docker/docker/pull/20419))\n*   For anonymous containers use the alias name for IP to name mapping, ie:DNS PTR record ( [#21019](https://github.com/docker/docker/pull/21019))\n*   Fix a panic when deleting an entry from /etc/hosts file ( [#21019](https://github.com/docker/docker/pull/21019))\n*   Source the forwarded DNS queries from the container net namespace ( [#21019](https://github.com/docker/docker/pull/21019))\n*   Fix to retain the network internal mode config for bridge networks on daemon reload (\\[#21780\\] ( [https://github.com/docker/docker/pull/21780](https://github.com/docker/docker/pull/21780)))\n*   Fix to retain IPAM driver option configs on daemon reload (\\[#21914\\] ( [https://github.com/docker/docker/pull/21914](https://github.com/docker/docker/pull/21914)))\n\n### [Plugins](#plugins-2)\n\n*   Fix a file descriptor leak that would occur every time plugins were enumerated ( [#20686](https://github.com/docker/docker/pull/20686))\n*   Fix an issue where Authz plugin would corrupt the payload body when faced with a large amount of data ( [#20602](https://github.com/docker/docker/pull/20602))\n\n### [Runtime](#runtime-11)\n\n*   Fix a panic that could occur when cleanup after a container started with invalid parameters ( [#21716](https://github.com/docker/docker/pull/21716))\n*   Fix a race with event timers stopping early ( [#21692](https://github.com/docker/docker/pull/21692))\n*   Fix race conditions in the layer store, potentially corrupting the map and crashing the process ( [#21677](https://github.com/docker/docker/pull/21677))\n*   Un-deprecate auto-creation of host directories for mounts. This feature was marked deprecated in ( [#21666](https://github.com/docker/docker/pull/21666)) Docker 1.9, but was decided to be too much of a backward-incompatible change, so it was decided to keep the feature.\n\n*   It is now possible for containers to share the NET and IPC namespaces when `userns` is enabled ( [#21383](https://github.com/docker/docker/pull/21383))\n*   `docker inspect <image-id>` will now expose the rootfs layers ( [#21370](https://github.com/docker/docker/pull/21370))\n*   Docker Windows gained a minimal `top` implementation ( [#21354](https://github.com/docker/docker/pull/21354))\n\n*   Docker learned to report the faulty exe when a container cannot be started due to its condition ( [#21345](https://github.com/docker/docker/pull/21345))\n*   Docker with device mapper will now refuse to run if `udev sync` is not available ( [#21097](https://github.com/docker/docker/pull/21097))\n\n*   Fix a bug where Docker would not validate the config file upon configuration reload ( [#21089](https://github.com/docker/docker/pull/21089))\n*   Fix a hang that would happen on attach if initial start was to fail ( [#21048](https://github.com/docker/docker/pull/21048))\n*   Fix an issue where registry service options in the daemon configuration file were not properly taken into account ( [#21045](https://github.com/docker/docker/pull/21045))\n*   Fix a race between the exec and resize operations ( [#21022](https://github.com/docker/docker/pull/21022))\n*   Fix an issue where nanoseconds were not correctly taken in account when filtering Docker events ( [#21013](https://github.com/docker/docker/pull/21013))\n*   Fix the handling of Docker command when passed a 64 bytes id ( [#21002](https://github.com/docker/docker/pull/21002))\n\n*   Docker will now return a `204` (i.e http.StatusNoContent) code when it successfully deleted a network ( [#20977](https://github.com/docker/docker/pull/20977))\n\n*   Fix a bug where the daemon would wait indefinitely in case the process it was about to killed had already exited on its own ( [#20967](https://github.com/docker/docker/pull/20967)\n\n*   The devmapper driver learned the `dm.min_free_space` option. If the mapped device free space reaches the passed value, new device creation will be prohibited. ( [#20786](https://github.com/docker/docker/pull/20786))\n\n*   Docker can now prevent processes in container to gain new privileges via the `--security-opt=no-new-privileges` flag ( [#20727](https://github.com/docker/docker/pull/20727))\n\n*   Starting a container with the `--device` option will now correctly resolves symlinks ( [#20684](https://github.com/docker/docker/pull/20684))\n\n*   Docker now relies on [`containerd`](https://github.com/docker/containerd) and [`runc`](https://github.com/opencontainers/runc) to spawn containers. ( [#20662](https://github.com/docker/docker/pull/20662))\n\n*   Fix docker configuration reloading to only alter value present in the given config file ( [#20604](https://github.com/docker/docker/pull/20604))\n\n*   Docker now allows setting a container hostname via the `--hostname` flag when `--net=host` ( [#20177](https://github.com/docker/docker/pull/20177))\n*   Docker now allows executing privileged container while running with `--userns-remap` if both `--privileged` and the new `--userns=host` flag are specified ( [#20111](https://github.com/docker/docker/pull/20111))\n\n*   Fix Docker not cleaning up correctly old containers upon restarting after a crash ( [#19679](https://github.com/docker/docker/pull/19679))\n\n*   Docker will now error out if it doesn't recognize a configuration key within the config file ( [#19517](https://github.com/docker/docker/pull/19517))\n\n*   Fix container loading, on daemon startup, when they depends on a plugin running within a container ( [#19500](https://github.com/docker/docker/pull/19500))\n\n*   `docker update` learned how to change a container restart policy ( [#19116](https://github.com/docker/docker/pull/19116))\n*   `docker inspect` now also returns a new `State` field containing the container state in a human readable way (i.e. one of `created`, `restarting`, `running`, `paused`, `exited` or `dead`)( [#18966](https://github.com/docker/docker/pull/18966))\n\n*   Docker learned to limit the number of active pids (i.e. processes) within the container via the `pids-limit` flags. NOTE: This requires `CGROUP_PIDS=y` to be in the kernel configuration. ( [#18697](https://github.com/docker/docker/pull/18697))\n\n*   `docker load` now has a `--quiet` option to suppress the load output ( [#20078](https://github.com/docker/docker/pull/20078))\n*   Fix a bug in neighbor discovery for IPv6 peers ( [#20842](https://github.com/docker/docker/pull/20842))\n*   Fix a panic during cleanup if a container was started with invalid options ( [#21802](https://github.com/docker/docker/pull/21802))\n*   Fix a situation where a container cannot be stopped if the terminal is closed ( [#21840](https://github.com/docker/docker/pull/21840))\n\n### [Security](#security-2)\n\n*   Object with the `pcp_pmcd_t` selinux type were given management access to `/var/lib/docker(/.*)?` ( [#21370](https://github.com/docker/docker/pull/21370))\n*   `restart_syscall`, `copy_file_range`, `mlock2` joined the list of allowed calls in the default seccomp profile ( [#21117](https://github.com/docker/docker/pull/21117), [#21262](https://github.com/docker/docker/pull/21262))\n*   `send`, `recv` and `x32` were added to the list of allowed syscalls and arch in the default seccomp profile ( [#19432](https://github.com/docker/docker/pull/19432))\n*   Docker Content Trust now requests the server to perform snapshot signing ( [#21046](https://github.com/docker/docker/pull/21046))\n*   Support for using YubiKeys for Content Trust signing has been moved out of experimental ( [#21591](https://github.com/docker/docker/pull/21591))\n\n### [Volumes](#volumes)\n\n*   Output of `docker volume ls` is now sorted by volume name ( [#20389](https://github.com/docker/docker/pull/20389))\n*   Local volumes can now accept options similar to the unix `mount` tool ( [#20262](https://github.com/docker/docker/pull/20262))\n\n*   Fix an issue where one letter directory name could not be used as source for volumes ( [#21106](https://github.com/docker/docker/pull/21106))\n\n*   `docker run -v` now accepts a new flag `nocopy`. This tells the runtime not to copy the container path content into the volume (which is the default behavior) ( [#21223](https://github.com/docker/docker/pull/21223))\n\n### [Runtime](#runtime-12)\n\n*   Fix Docker client exiting with an \"Unrecognized input header\" error [#20706](https://github.com/docker/docker/pull/20706)\n*   Fix Docker exiting if Exec is started with both `AttachStdin` and `Detach` [#20647](https://github.com/docker/docker/pull/20647)\n\n### [Distribution](#distribution-4)\n\n*   Fix a crash when pushing multiple images sharing the same layers to the same repository in parallel [#20831](https://github.com/docker/docker/pull/20831)\n*   Fix a panic when pushing images to a registry which uses a misconfigured token service [#21030](https://github.com/docker/docker/pull/21030)\n\n### [Plugin system](#plugin-system)\n\n*   Fix issue preventing volume plugins to start when SELinux is enabled [#20834](https://github.com/docker/docker/pull/20834)\n*   Prevent Docker from exiting if a volume plugin returns a null response for Get requests [#20682](https://github.com/docker/docker/pull/20682)\n*   Fix plugin system leaking file descriptors if a plugin has an error [#20680](https://github.com/docker/docker/pull/20680)\n\n### [Security](#security-3)\n\n*   Fix linux32 emulation to fail during docker build [#20672](https://github.com/docker/docker/pull/20672) It was due to the `personality` syscall being blocked by the default seccomp profile.\n*   Fix Oracle XE 10g failing to start in a container [#20981](https://github.com/docker/docker/pull/20981) It was due to the `ipc` syscall being blocked by the default seccomp profile.\n*   Fix user namespaces not working on Linux From Scratch [#20685](https://github.com/docker/docker/pull/20685)\n*   Fix issue preventing daemon to start if userns is enabled and the `subuid` or `subgid` files contain comments [#20725](https://github.com/docker/docker/pull/20725)\n\n### [Runtime](#runtime-13)\n\n*   Prevent systemd from deleting containers' cgroups when its configuration is reloaded [#20518](https://github.com/docker/docker/pull/20518)\n*   Fix SELinux issues by disregarding `--read-only` when mounting `/dev/mqueue` [#20333](https://github.com/docker/docker/pull/20333)\n*   Fix chown permissions used during `docker cp` when userns is used [#20446](https://github.com/docker/docker/pull/20446)\n*   Fix configuration loading issue with all booleans defaulting to `true` [#20471](https://github.com/docker/docker/pull/20471)\n*   Fix occasional panic with `docker logs -f` [#20522](https://github.com/docker/docker/pull/20522)\n\n### [Distribution](#distribution-5)\n\n*   Keep layer reference if deletion failed to avoid a badly inconsistent state [#20513](https://github.com/docker/docker/pull/20513)\n*   Handle gracefully a corner case when canceling migration [#20372](https://github.com/docker/docker/pull/20372)\n*   Fix docker import on compressed data [#20367](https://github.com/docker/docker/pull/20367)\n*   Fix tar-split files corruption during migration that later cause docker push and docker save to fail [#20458](https://github.com/docker/docker/pull/20458)\n\n### [Networking](#networking-10)\n\n*   Fix daemon crash if embedded DNS is sent garbage [#20510](https://github.com/docker/docker/pull/20510)\n\n### [Volumes](#volumes-1)\n\n*   Fix issue with multiple volume references with same name [#20381](https://github.com/docker/docker/pull/20381)\n\n### [Security](#security-4)\n\n*   Fix potential cache corruption and delegation conflict issues [#20523](https://github.com/docker/docker/pull/20523)\n\n### [Runtime](#runtime-14)\n\n*   Do not stop daemon on migration hard failure [#20156](https://github.com/docker/docker/pull/20156)\n\n*   Fix various issues with migration to content-addressable images [#20058](https://github.com/docker/docker/pull/20058)\n*   Fix ZFS permission bug with user namespaces [#20045](https://github.com/docker/docker/pull/20045)\n*   Do not leak /dev/mqueue from the host to all containers, keep it container-specific [#19876](https://github.com/docker/docker/pull/19876) [#20133](https://github.com/docker/docker/pull/20133)\n*   Fix `docker ps --filter before=...` to not show stopped containers without providing `-a` flag [#20135](https://github.com/docker/docker/pull/20135)\n\n### [Security](#security-5)\n\n*   Fix issue preventing docker events to work properly with authorization plugin [#20002](https://github.com/docker/docker/pull/20002)\n\n### [Distribution](#distribution-6)\n\n*   Add additional verifications and prevent from uploading invalid data to registries [#20164](https://github.com/docker/docker/pull/20164)\n\n*   Fix regression preventing uppercase characters in image reference hostname [#20175](https://github.com/docker/docker/pull/20175)\n\n### [Networking](#networking-11)\n\n*   Fix embedded DNS for user-defined networks in the presence of firewalld [#20060](https://github.com/docker/docker/pull/20060)\n*   Fix issue where removing a network during shutdown left Docker inoperable [#20181](https://github.com/docker/docker/issues/20181) [#20235](https://github.com/docker/docker/issues/20235)\n*   Embedded DNS is now able to return compressed results [#20181](https://github.com/docker/docker/issues/20181)\n*   Fix port-mapping issue with `userland-proxy=false` [#20181](https://github.com/docker/docker/issues/20181)\n\n### [Logging](#logging-5)\n\n*   Fix bug where tcp+tls protocol would be rejected [#20109](https://github.com/docker/docker/pull/20109)\n\n### [Volumes](#volumes-2)\n\n*   Fix issue whereby older volume drivers would not receive volume options [#19983](https://github.com/docker/docker/pull/19983)\n\n### [Misc](#misc-1)\n\n*   Remove TasksMax from Docker systemd service [#20167](https://github.com/docker/docker/pull/20167)\n\n**IMPORTANT**: Docker 1.10 uses a new content-addressable storage for images and layers. A migration is performed the first time docker is run, and can take a significant amount of time depending on the number of images present. Refer to this page on the wiki for more information: [https://github.com/docker/docker/wiki/Engine-v1.10.0-content-addressability-migration](https://github.com/docker/docker/wiki/Engine-v1.10.0-content-addressability-migration) We also released a cool migration utility that enables you to perform the migration before updating to reduce downtime. Engine 1.10 migrator can be found on Docker Hub: [https://hub.docker.com/r/docker/v1.10-migrator/](https://hub.docker.com/r/docker/v1.10-migrator/)\n\n### [Runtime](#runtime-15)\n\n*   New `docker update` command that allows updating resource constraints on running containers [#15078](https://github.com/docker/docker/pull/15078)\n*   Add `--tmpfs` flag to `docker run` to create a tmpfs mount in a container [#13587](https://github.com/docker/docker/pull/13587)\n*   Add `--format` flag to `docker images` command [#17692](https://github.com/docker/docker/pull/17692)\n*   Allow to set daemon configuration in a file and hot-reload it with the `SIGHUP` signal [#18587](https://github.com/docker/docker/pull/18587)\n*   Updated docker events to include more meta-data and event types [#18888](https://github.com/docker/docker/pull/18888) This change is backward compatible in the API, but not on the CLI.\n*   Add `--blkio-weight-device` flag to `docker run` [#13959](https://github.com/docker/docker/pull/13959)\n*   Add `--device-read-bps` and `--device-write-bps` flags to `docker run` [#14466](https://github.com/docker/docker/pull/14466)\n*   Add `--device-read-iops` and `--device-write-iops` flags to `docker run` [#15879](https://github.com/docker/docker/pull/15879)\n*   Add `--oom-score-adj` flag to `docker run` [#16277](https://github.com/docker/docker/pull/16277)\n*   Add `--detach-keys` flag to `attach`, `run`, `start` and `exec` commands to override the default key sequence that detaches from a container [#15666](https://github.com/docker/docker/pull/15666)\n*   Add `--shm-size` flag to `run`, `create` and `build` to set the size of `/dev/shm` [#16168](https://github.com/docker/docker/pull/16168)\n*   Show the number of running, stopped, and paused containers in `docker info` [#19249](https://github.com/docker/docker/pull/19249)\n*   Show the `OSType` and `Architecture` in `docker info` [#17478](https://github.com/docker/docker/pull/17478)\n*   Add `--cgroup-parent` flag on `daemon` to set cgroup parent for all containers [#19062](https://github.com/docker/docker/pull/19062)\n*   Add `-L` flag to docker cp to follow symlinks [#16613](https://github.com/docker/docker/pull/16613)\n*   New `status=dead` filter for `docker ps` [#17908](https://github.com/docker/docker/pull/17908)\n\n*   Change `docker run` exit codes to distinguish between runtime and application errors [#14012](https://github.com/docker/docker/pull/14012)\n*   Enhance `docker events --since` and `--until` to support nanoseconds and timezones [#17495](https://github.com/docker/docker/pull/17495)\n*   Add `--all`/`-a` flag to `stats` to include both running and stopped containers [#16742](https://github.com/docker/docker/pull/16742)\n*   Change the default cgroup-driver to `cgroupfs` [#17704](https://github.com/docker/docker/pull/17704)\n*   Emit a \"tag\" event when tagging an image with `build -t` [#17115](https://github.com/docker/docker/pull/17115)\n*   Best effort for linked containers' start order when starting the daemon [#18208](https://github.com/docker/docker/pull/18208)\n*   Add ability to add multiple tags on `build` [#15780](https://github.com/docker/docker/pull/15780)\n*   Permit `OPTIONS` request against any url, thus fixing issue with CORS [#19569](https://github.com/docker/docker/pull/19569)\n\n*   Fix the `--quiet` flag on `docker build` to actually be quiet [#17428](https://github.com/docker/docker/pull/17428)\n*   Fix `docker images --filter dangling=false` to now show all non-dangling images [#19326](https://github.com/docker/docker/pull/19326)\n*   Fix race condition causing autorestart turning off on restart [#17629](https://github.com/docker/docker/pull/17629)\n*   Recognize GPFS filesystems [#19216](https://github.com/docker/docker/pull/19216)\n*   Fix obscure bug preventing to start containers [#19751](https://github.com/docker/docker/pull/19751)\n*   Forbid `exec` during container restart [#19722](https://github.com/docker/docker/pull/19722)\n*   devicemapper: Increasing `--storage-opt dm.basesize` will now increase the base device size on daemon restart [#19123](https://github.com/docker/docker/pull/19123)\n\n### [Security](#security-6)\n\n*   Add `--userns-remap` flag to `daemon` to support user namespaces (previously in experimental) [#19187](https://github.com/docker/docker/pull/19187)\n*   Add support for custom seccomp profiles in `--security-opt` [#17989](https://github.com/docker/docker/pull/17989)\n*   Add default seccomp profile [#18780](https://github.com/docker/docker/pull/18780)\n*   Add `--authorization-plugin` flag to `daemon` to customize ACLs [#15365](https://github.com/docker/docker/pull/15365)\n*   Docker Content Trust now supports the ability to read and write user delegations [#18887](https://github.com/docker/docker/pull/18887) This is an optional, opt-in feature that requires the explicit use of the Notary command-line utility in order to be enabled. Enabling delegation support in a specific repository will break the ability of Docker 1.9 and 1.8 to pull from that repository, if content trust is enabled.\n\n*   Allow SELinux to run in a container when using the BTRFS storage driver [#16452](https://github.com/docker/docker/pull/16452)\n\n### [Distribution](#distribution-7)\n\n*   Use content-addressable storage for images and layers [#17924](https://github.com/docker/docker/pull/17924) A migration is performed the first time docker is run; it can take a significant amount of time depending on the number of images and containers present. Images no longer depend on the parent chain but contain a list of layer references. `docker load`/`docker save` tarballs now also contain content-addressable image configurations. For more information: [https://github.com/docker/docker/wiki/Engine-v1.10.0-content-addressability-migration](https://github.com/docker/docker/wiki/Engine-v1.10.0-content-addressability-migration)\n*   Add support for the new [manifest format (\"schema2\")](https://github.com/docker/distribution/blob/master/docs/spec/manifest-v2-2.md) [#18785](https://github.com/docker/docker/pull/18785)\n*   Lots of improvements for push and pull: performance++, retries on failed downloads, cancelling on client disconnect [#18353](https://github.com/docker/docker/pull/18353), [#18418](https://github.com/docker/docker/pull/18418), [#19109](https://github.com/docker/docker/pull/19109), [#18353](https://github.com/docker/docker/pull/18353)\n*   Limit v1 protocol fallbacks [#18590](https://github.com/docker/docker/pull/18590)\n\n*   Fix issue where docker could hang indefinitely waiting for a nonexistent process to pull an image [#19743](https://github.com/docker/docker/pull/19743)\n\n### [Networking](#networking-12)\n\n*   Use DNS-based discovery instead of `/etc/hosts` [#19198](https://github.com/docker/docker/pull/19198)\n*   Support for network-scoped alias using `--net-alias` on `run` and `--alias` on `network connect` [#19242](https://github.com/docker/docker/pull/19242)\n*   Add `--ip` and `--ip6` on `run` and `network connect` to support custom IP addresses for a container in a network [#19001](https://github.com/docker/docker/pull/19001)\n*   Add `--ipam-opt` to `network create` for passing custom IPAM options [#17316](https://github.com/docker/docker/pull/17316)\n*   Add `--internal` flag to `network create` to restrict external access to and from the network [#19276](https://github.com/docker/docker/pull/19276)\n*   Add `kv.path` option to `--cluster-store-opt` [#19167](https://github.com/docker/docker/pull/19167)\n*   Add `discovery.heartbeat` and `discovery.ttl` options to `--cluster-store-opt` to configure discovery TTL and heartbeat timer [#18204](https://github.com/docker/docker/pull/18204)\n*   Add `--format` flag to `network inspect` [#17481](https://github.com/docker/docker/pull/17481)\n*   Add `--link` to `network connect` to provide a container-local alias [#19229](https://github.com/docker/docker/pull/19229)\n*   Support for Capability exchange with remote IPAM plugins [#18775](https://github.com/docker/docker/pull/18775)\n*   Add `--force` to `network disconnect` to force container to be disconnected from network [#19317](https://github.com/docker/docker/pull/19317)\n\n*   Support for multi-host networking using built-in overlay driver for all engine supported kernels: 3.10+ [#18775](https://github.com/docker/docker/pull/18775)\n*   `--link` is now supported on `docker run` for containers in user-defined network [#19229](https://github.com/docker/docker/pull/19229)\n*   Enhance `docker network rm` to allow removing multiple networks [#17489](https://github.com/docker/docker/pull/17489)\n*   Include container names in `network inspect` [#17615](https://github.com/docker/docker/pull/17615)\n*   Include auto-generated subnets for user-defined networks in `network inspect` [#17316](https://github.com/docker/docker/pull/17316)\n*   Add `--filter` flag to `network ls` to hide predefined networks [#17782](https://github.com/docker/docker/pull/17782)\n*   Add support for network connect/disconnect to stopped containers [#18906](https://github.com/docker/docker/pull/18906)\n*   Add network ID to container inspect [#19323](https://github.com/docker/docker/pull/19323)\n\n*   Fix MTU issue where Docker would not start with two or more default routes [#18108](https://github.com/docker/docker/pull/18108)\n*   Fix duplicate IP address for containers [#18106](https://github.com/docker/docker/pull/18106)\n*   Fix issue preventing sometimes docker from creating the bridge network [#19338](https://github.com/docker/docker/pull/19338)\n*   Do not substitute 127.0.0.1 name server when using `--net=host` [#19573](https://github.com/docker/docker/pull/19573)\n\n### [Logging](#logging-6)\n\n*   New logging driver for Splunk [#16488](https://github.com/docker/docker/pull/16488)\n*   Add support for syslog over TCP+TLS [#18998](https://github.com/docker/docker/pull/18998)\n\n*   Enhance `docker logs --since` and `--until` to support nanoseconds and time [#17495](https://github.com/docker/docker/pull/17495)\n*   Enhance AWS logs to auto-detect region [#16640](https://github.com/docker/docker/pull/16640)\n\n### [Volumes](#volumes-3)\n\n*   Add support to set the mount propagation mode for a volume [#17034](https://github.com/docker/docker/pull/17034)\n\n*   Add `ls` and `inspect` endpoints to volume plugin API [#16534](https://github.com/docker/docker/pull/16534) Existing plugins need to make use of these new APIs to satisfy users' expectation For that, use the new MIME type `application/vnd.docker.plugins.v1.2+json` [#19549](https://github.com/docker/docker/pull/19549)\n\n*   Fix data not being copied to named volumes [#19175](https://github.com/docker/docker/pull/19175)\n*   Fix issues preventing volume drivers from being containerized [#19500](https://github.com/docker/docker/pull/19500)\n*   Fix `docker volumes ls --dangling=false` to now show all non-dangling volumes [#19671](https://github.com/docker/docker/pull/19671)\n*   Do not remove named volumes on container removal [#19568](https://github.com/docker/docker/pull/19568)\n*   Allow external volume drivers to host anonymous volumes [#19190](https://github.com/docker/docker/pull/19190)\n\n### [Builder](#builder-4)\n\n*   Add support for `**` in `.dockerignore` to wildcard multiple levels of directories [#17090](https://github.com/docker/docker/pull/17090)\n\n*   Fix handling of UTF-8 characters in Dockerfiles [#17055](https://github.com/docker/docker/pull/17055)\n*   Fix permissions problem when reading from STDIN [#19283](https://github.com/docker/docker/pull/19283)\n\n### [Client](#client-2)\n\n*   Add support for overriding the API version to use via an `DOCKER_API_VERSION` environment-variable [#15964](https://github.com/docker/docker/pull/15964)\n\n*   Fix a bug preventing Windows clients to log in to Docker Hub [#19891](https://github.com/docker/docker/pull/19891)\n\n### [Misc](#misc-2)\n\n*   systemd: Set TasksMax in addition to LimitNPROC in systemd service file [#19391](https://github.com/docker/docker/pull/19391)\n\n### [Deprecations](#deprecations)\n\n*   Remove LXC support. The LXC driver was deprecated in Docker 1.8, and has now been removed [#17700](https://github.com/docker/docker/pull/17700)\n*   Remove `--exec-driver` daemon flag, because it is no longer in use [#17700](https://github.com/docker/docker/pull/17700)\n*   Remove old deprecated single-dashed long CLI flags (such as `-rm`; use `--rm` instead) [#17724](https://github.com/docker/docker/pull/17724)\n*   Deprecate HostConfig at API container start [#17799](https://github.com/docker/docker/pull/17799)\n*   Deprecate docker packages for newly EOL'd Linux distributions: Fedora 21 and Ubuntu 15.04 (Vivid) [#18794](https://github.com/docker/docker/pull/18794), [#18809](https://github.com/docker/docker/pull/18809)\n*   Deprecate `-f` flag for docker tag [#18350](https://github.com/docker/docker/pull/18350)\n\n### [Runtime](#runtime-16)\n\n*   Do not prevent daemon from booting if images could not be restored (#17695)\n*   Force IPC mount to unmount on daemon shutdown/init (#17539)\n*   Turn IPC unmount errors into warnings (#17554)\n*   Fix `docker stats` performance regression (#17638)\n*   Clarify cryptic error message upon `docker logs` if `--log-driver=none` (#17767)\n*   Fix seldom panics (#17639, #17634, #17703)\n*   Fix opq whiteouts problems for files with dot prefix (#17819)\n*   devicemapper: try defaulting to xfs instead of ext4 for performance reasons (#17903, #17918)\n*   devicemapper: fix displayed fs in docker info (#17974)\n*   selinux: only relabel if user requested so with the `z` option (#17450, #17834)\n*   Do not make network calls when normalizing names (#18014)\n\n### [Client](#client-3)\n\n*   Fix `docker login` on windows (#17738)\n*   Fix bug with `docker inspect` output when not connected to daemon (#17715)\n*   Fix `docker inspect -f {{.HostConfig.Dns}} somecontainer` (#17680)\n\n### [Builder](#builder-5)\n\n*   Fix regression with symlink behavior in ADD/COPY (#17710)\n\n### [Networking](#networking-13)\n\n*   Allow passing a network ID as an argument for `--net` (#17558)\n*   Fix connect to host and prevent disconnect from host for `host` network (#17476)\n*   Fix `--fixed-cidr` issue when gateway ip falls in ip-range and ip-range is not the first block in the network (#17853)\n*   Restore deterministic `IPv6` generation from `MAC` address on default `bridge` network (#17890)\n*   Allow port-mapping only for endpoints created on docker run (#17858)\n*   Fixed an endpoint delete issue with a possible stale sbox (#18102)\n\n### [Distribution](#distribution-8)\n\n*   Correct parent chain in v2 push when v1Compatibility files on the disk are inconsistent (#18047)\n\n### [Runtime](#runtime-17)\n\n*   `docker stats` now returns block IO metrics (#15005)\n*   `docker stats` now details network stats per interface (#15786)\n*   Add `ancestor=<image>` filter to `docker ps --filter` flag to filter containers based on their ancestor images (#14570)\n*   Add `label=<somelabel>` filter to `docker ps --filter` to filter containers based on label (#16530)\n*   Add `--kernel-memory` flag to `docker run` (#14006)\n*   Add `--message` flag to `docker import` allowing to specify an optional message (#15711)\n*   Add `--privileged` flag to `docker exec` (#14113)\n*   Add `--stop-signal` flag to `docker run` allowing to replace the container process stopping signal (#15307)\n*   Add a new `unless-stopped` restart policy (#15348)\n*   Inspecting an image now returns tags (#13185)\n*   Add container size information to `docker inspect` (#15796)\n*   Add `RepoTags` and `RepoDigests` field to `/images/{name:.*}/json` (#17275)\n\n*   Remove the deprecated `/container/ps` endpoint from the API (#15972)\n*   Send and document correct HTTP codes for `/exec/<name>/start` (#16250)\n*   Share shm and mqueue between containers sharing IPC namespace (#15862)\n*   Event stream now shows OOM status when `--oom-kill-disable` is set (#16235)\n*   Ensure special network files (/etc/hosts etc.) are read-only if bind-mounted with `ro` option (#14965)\n*   Improve `rmi` performance (#16890)\n*   Do not update /etc/hosts for the default bridge network, except for links (#17325)\n*   Fix conflict with duplicate container names (#17389)\n*   Fix an issue with incorrect template execution in `docker inspect` (#17284)\n*   DEPRECATE `-c` short flag variant for `--cpu-shares` in docker run (#16271)\n\n### [Client](#client-4)\n\n*   Allow `docker import` to import from local files (#11907)\n\n### [Builder](#builder-6)\n\n*   Add a `STOPSIGNAL` Dockerfile instruction allowing to set a different stop-signal for the container process (#15307)\n*   Add an `ARG` Dockerfile instruction and a `--build-arg` flag to `docker build` that allows to add build-time environment variables (#15182)\n\n*   Improve cache miss performance (#16890)\n\n### [Storage](#storage)\n\n*   devicemapper: Implement deferred deletion capability (#16381)\n\n### [Networking](#networking-14)\n\n*   `docker network` exits experimental and is part of standard release (#16645)\n*   New network top-level concept, with associated subcommands and API (#16645) WARNING: the API is different from the experimental API\n*   Support for multiple isolated/micro-segmented networks (#16645)\n*   Built-in multihost networking using VXLAN based overlay driver (#14071)\n*   Support for third-party network plugins (#13424)\n*   Ability to dynamically connect containers to multiple networks (#16645)\n*   Support for user-defined IP address management via pluggable IPAM drivers (#16910)\n*   Add daemon flags `--cluster-store` and `--cluster-advertise` for built-in nodes discovery (#16229)\n*   Add `--cluster-store-opt` for setting up TLS settings (#16644)\n*   Add `--dns-opt` to the daemon (#16031)\n\n*   DEPRECATE following container `NetworkSettings` fields in API v1.21: `EndpointID`, `Gateway`, `GlobalIPv6Address`, `GlobalIPv6PrefixLen`, `IPAddress`, `IPPrefixLen`, `IPv6Gateway` and `MacAddress`. Those are now specific to the `bridge` network. Use `NetworkSettings.Networks` to inspect the networking settings of a container per network.\n\n### [Volumes](#volumes-4)\n\n*   New top-level `volume` subcommand and API (#14242)\n\n*   Move API volume driver settings to host-specific config (#15798)\n*   Print an error message if volume name is not unique (#16009)\n*   Ensure volumes created from Dockerfiles always use the local volume driver (#15507)\n*   DEPRECATE auto-creating missing host paths for bind mounts (#16349)\n\n### [Logging](#logging-7)\n\n*   Add `awslogs` logging driver for Amazon CloudWatch (#15495)\n*   Add generic `tag` log option to allow customizing container/image information passed to driver (#15384)\n\n*   Implement the `docker logs` endpoint for the journald driver (#13707)\n*   DEPRECATE driver-specific log tags (#15384)\n\n### [Distribution](#distribution-9)\n\n*   `docker search` now works with partial names (#16509)\n\n*   Push optimization: avoid buffering to file (#15493)\n*   The daemon will display progress for images that were already being pulled by another client (#15489)\n*   Only permissions required for the current action being performed are requested (#)\n\n*   Renaming trust keys (and respective environment variables) from `offline` to `root` and `tagging` to `repository` (#16894)\n\n*   DEPRECATE trust key environment variables `DOCKER_CONTENT_TRUST_OFFLINE_PASSPHRASE` and `DOCKER_CONTENT_TRUST_TAGGING_PASSPHRASE` (#16894)\n\n### [Security](#security-7)\n\n*   Add SELinux profiles to the rpm package (#15832)\n\n*   Fix various issues with AppArmor profiles provided in the deb package (#14609)\n*   Add AppArmor policy that prevents writing to /proc (#15571)\n\n### [Distribution](#distribution-10)\n\n*   Fix layer IDs lead to local graph poisoning (CVE-2014-8178)\n*   Fix manifest validation and parsing logic errors allow pull-by-digest validation bypass (CVE-2014-8179)\n\n*   Add `--disable-legacy-registry` to prevent a daemon from using a v1 registry\n\n### [Distribution](#distribution-11)\n\n*   Fixes rare edge case of handling GNU LongLink and LongName entries.\n*   Fix ^C on docker pull.\n*   Fix docker pull issues on client disconnection.\n*   Fix issue that caused the daemon to panic when loggers weren't configured properly.\n*   Fix goroutine leak pulling images from registry V2.\n\n### [Runtime](#runtime-18)\n\n*   Fix a bug mounting cgroups for docker daemons running inside docker containers.\n*   Initialize log configuration properly.\n\n### [Client:](#client-5)\n\n*   Handle `-q` flag in `docker ps` properly when there is a default format.\n\n### [Networking](#networking-15)\n\n*   Fix several corner cases with netlink.\n\n### [Contrib](#contrib-8)\n\n*   Fix several issues with bash completion.\n\n### [Distribution](#distribution-12)\n\n*   Fix a bug where pushing multiple tags would result in invalid images\n\n### [Distribution](#distribution-13)\n\n*   Trusted pull, push and build, disabled by default\n\n*   Make tar layers deterministic between registries\n*   Don't allow deleting the image of running containers\n*   Check if a tag name to load is a valid digest\n*   Allow one character repository names\n*   Add a more accurate error description for invalid tag name\n*   Make build cache ignore mtime\n\n### [Cli](#cli)\n\n*   Add support for DOCKER\\_CONFIG/--config to specify config file dir\n*   Add --type flag for docker inspect command\n*   Add formatting options to `docker ps` with `--format`\n*   Replace `docker -d` with new subcommand `docker daemon`\n\n*   Zsh completion updates and improvements\n*   Add some missing events to bash completion\n*   Support daemon urls with base paths in `docker -H`\n*   Validate status= filter to docker ps\n*   Display when a container is in --net=host in docker ps\n*   Extend docker inspect to export image metadata related to graph driver\n*   Restore --default-gateway{,-v6} daemon options\n*   Add missing unpublished ports in docker ps\n*   Allow duration strings in `docker events` as --since/--until\n*   Expose more mounts information in `docker inspect`\n\n### [Runtime](#runtime-19)\n\n*   Add new Fluentd logging driver\n*   Allow `docker import` to load from local files\n*   Add logging driver for GELF via UDP\n*   Allow to copy files from host to containers with `docker cp`\n*   Promote volume drivers from experimental to master\n*   Add rollover options to json-file log driver, and --log-driver-opts flag\n*   Add memory swappiness tuning options\n\n*   Remove cgroup read-only flag when privileged\n*   Make /proc, /sys, & /dev readonly for readonly containers\n*   Add cgroup bind mount by default\n*   Overlay: Export metadata for container and image in `docker inspect`\n*   Devicemapper: external device activation\n*   Devicemapper: Compare uuid of base device on startup\n*   Remove RC4 from the list of registry cipher suites\n*   Add syslog-facility option\n*   LXC execdriver compatibility with recent LXC versions\n*   Mark LXC execriver as deprecated (to be removed with the migration to runc)\n\n### [Plugins](#plugins-3)\n\n*   Separate plugin sockets and specs locations\n*   Allow TLS connections to plugins\n\n### [Bug fixes](#bug-fixes)\n\n*   Add missing 'Names' field to /containers/json API output\n*   Make `docker rmi` of dangling images safe while pulling\n*   Devicemapper: Change default basesize to 100G\n*   Go Scheduler issue with sync.Mutex and gcc\n*   Fix issue where Search API endpoint would panic due to empty AuthConfig\n*   Set image canonical names correctly\n*   Check dockerinit only if lxc driver is used\n*   Fix ulimit usage of nproc\n*   Always attach STDIN if -i,--interactive is specified\n*   Show error messages when saving container state fails\n*   Fixed incorrect assumption on --bridge=none treated as disable network\n*   Check for invalid port specifications in host configuration\n*   Fix endpoint leave failure for --net=host mode\n*   Fix goroutine leak in the stats API if the container is not running\n*   Check for apparmor file before reading it\n*   Fix DOCKER\\_TLS\\_VERIFY being ignored\n*   Set umask to the default on startup\n*   Correct the message of pause and unpause a non-running container\n*   Adjust disallowed CpuShares in container creation\n*   ZFS: correctly apply selinux context\n*   Display empty string instead of when IP opt is nil\n*   `docker kill` returns error when container is not running\n*   Fix COPY/ADD quoted/json form\n*   Fix goroutine leak on logs -f with no output\n*   Remove panic in nat package on invalid hostport\n*   Fix container linking in Fedora 22\n*   Fix error caused using default gateways outside of the allocated range\n*   Format times in inspect command with a template as RFC3339Nano\n*   Make registry client to accept 2xx and 3xx http status responses as successful\n*   Fix race issue that caused the daemon to crash with certain layer downloads failed in a specific order.\n*   Fix error when the docker ps format was not valid.\n*   Remove redundant ip forward check.\n*   Fix issue trying to push images to repository mirrors.\n*   Fix error cleaning up network entrypoints when there is an initialization issue.\n\n### [Runtime](#runtime-20)\n\n*   Fix default user spawning exec process with `docker exec`\n*   Make `--bridge=none` not to configure the network bridge\n*   Publish networking stats properly\n*   Fix implicit devicemapper selection with static binaries\n*   Fix socket connections that hung intermittently\n*   Fix bridge interface creation on CentOS/RHEL 6.6\n*   Fix local dns lookups added to resolv.conf\n*   Fix copy command mounting volumes\n*   Fix read/write privileges in volumes mounted with --volumes-from\n\n### [Remote API](#remote-api)\n\n*   Fix unmarshalling of Command and Entrypoint\n*   Set limit for minimum client version supported\n*   Validate port specification\n*   Return proper errors when attach/reattach fail\n\n### [Distribution](#distribution-14)\n\n*   Fix pulling private images\n*   Fix fallback between registry V2 and V1\n\n### [Runtime](#runtime-21)\n\n*   Experimental feature: support for out-of-process volume plugins\n\n*   The userland proxy can be disabled in favor of hairpin NAT using the daemonâ€™s `--userland-proxy=false` flag\n*   The `exec` command supports the `-u|--user` flag to specify the new process owner\n\n*   Default gateway for containers can be specified daemon-wide using the `--default-gateway` and `--default-gateway-v6` flags\n*   The CPU CFS (Completely Fair Scheduler) quota can be set in `docker run` using `--cpu-quota`\n*   Container block IO can be controlled in `docker run` using`--blkio-weight`\n*   ZFS support\n*   The `docker logs` command supports a `--since` argument\n*   UTS namespace can be shared with the host with `docker run --uts=host`\n\n### [Quality](#quality)\n\n*   Networking stack was entirely rewritten as part of the libnetwork effort\n*   Engine internals refactoring\n*   Volumes code was entirely rewritten to support the plugins effort\n\n*   Sending SIGUSR1 to a daemon will dump all goroutines stacks without exiting\n\n### [Build](#build)\n\n*   Support ${variable:-value} and ${variable:+value} syntax for environment variables\n*   Support resource management flags `--cgroup-parent`, `--cpu-period`, `--cpu-quota`, `--cpuset-cpus`, `--cpuset-mems`\n*   git context changes with branches and directories\n\n*   The .dockerignore file support exclusion rules\n\n### [Distribution](#distribution-15)\n\n*   Client support for v2 mirroring support for the official registry\n\n### [Bugfixes](#bugfixes)\n\n*   Firewalld is now supported and will automatically be used when available\n*   mounting --device recursively\n\n### [Runtime](#runtime-22)\n\n*   Revert change prohibiting mounting into /sys\n\n### [Security](#security-8)\n\n*   Fix read/write /proc paths (CVE-2015-3630)\n*   Prohibit VOLUME /proc and VOLUME / (CVE-2015-3631)\n*   Fix opening of file-descriptor 1 (CVE-2015-3627)\n*   Fix symlink traversal on container respawn allowing local privilege escalation (CVE-2015-3629)\n*   Prohibit mount of /sys\n\n### [Runtime](#runtime-23)\n\n*   Update AppArmor policy to not allow mounts\n\n### [Builder](#builder-7)\n\n*   Building images from an image ID\n*   Build containers with resource constraints, ie `docker build --cpu-shares=100 --memory=1024m...`\n*   `commit --change` to apply specified Dockerfile instructions while committing the image\n*   `import --change` to apply specified Dockerfile instructions while importing the image\n*   Builds no longer continue in the background when canceled with CTRL-C\n\n### [Client](#client-6)\n\n*   Windows Support\n\n### [Runtime](#runtime-24)\n\n*   Container and image Labels\n*   `--cgroup-parent` for specifying a parent cgroup to place container cgroup within\n*   Logging drivers, `json-file`, `syslog`, or `none`\n*   Pulling images by ID\n*   `--ulimit` to set the ulimit on a container\n*   `--default-ulimit` option on the daemon which applies to all created containers (and overwritten by `--ulimit` on run)\n\n### [Builder](#builder-8)\n\n*   Dockerfile to use for a given `docker build` can be specified with the `-f` flag\n\n*   Dockerfile and .dockerignore files can be themselves excluded as part of the .dockerignore file, thus preventing modifications to these files invalidating ADD or COPY instructions cache\n*   ADD and COPY instructions accept relative paths\n*   Dockerfile `FROM scratch` instruction is now interpreted as a no-base specifier\n*   Improve performance when exposing a large number of ports\n\n### [Hack](#hack)\n\n*   Allow client-side only integration tests for Windows\n\n*   Include docker-py integration tests against Docker daemon as part of our test suites\n\n### [Packaging](#packaging)\n\n*   Support for the new version of the registry HTTP API\n\n*   Speed up `docker push` for images with a majority of already existing layers\n\n*   Fixed contacting a private registry through a proxy\n\n### [Remote API](#remote-api-1)\n\n*   A new endpoint will stream live container resource metrics and can be accessed with the `docker stats` command\n*   Containers can be renamed using the new `rename` endpoint and the associated `docker rename` command\n\n*   Container `inspect` endpoint show the ID of `exec` commands running in this container\n*   Container `inspect` endpoint show the number of times Docker auto-restarted the container\n*   New types of event can be streamed by the `events` endpoint: â€˜OOMâ€™ (container died with out of memory), â€˜exec\\_createâ€™, and â€˜exec\\_start'\n\n*   Fixed returned string fields which hold numeric characters incorrectly omitting surrounding double quotes\n\n### [Runtime](#runtime-25)\n\n*   Docker daemon has full IPv6 support\n*   The `docker run` command can take the `--pid=host` flag to use the host PID namespace, which makes it possible for example to debug host processes using containerized debugging tools\n*   The `docker run` command can take the `--read-only` flag to make the containerâ€™s root filesystem mounted as readonly, which can be used in combination with volumes to force a containerâ€™s processes to only write to locations that will be persisted\n*   Container total memory usage can be limited for `docker run` using the `--memory-swap` flag\n\n*   Major stability improvements for devicemapper storage driver\n*   Better integration with host system: containers will reflect changes to the host's `/etc/resolv.conf` file when restarted\n*   Better integration with host system: per-container iptable rules are moved to the DOCKER chain\n\n*   Fixed container exiting on out of memory to return an invalid exit code\n\n### [Other](#other)\n\n*   The HTTP\\_PROXY, HTTPS\\_PROXY, and NO\\_PROXY environment variables are properly taken into account by the client when connecting to the Docker daemon\n\n### [Runtime](#runtime-26)\n\n*   Fix issue with volumes-from and bind mounts not being honored after create\n\n### [Notable Features since 1.3.0](#notable-features-since-130)\n\n*   Set key=value labels to the daemon (displayed in `docker info`), applied with new `-label` daemon flag\n*   Add support for `ENV` in Dockerfile of the form: `ENV name=value name2=value2...`\n*   New Overlayfs Storage Driver\n*   `docker info` now returns an `ID` and `Name` field\n*   Filter events by event name, container, or image\n*   `docker cp` now supports copying from container volumes\n\n*   Fixed `docker tag`, so it honors `--force` when overriding a tag for existing image.\n\n### [Security](#security-9)\n\n*   Fix path traversal vulnerability in processing of absolute symbolic links (CVE-2014-9356)\n*   Fix decompression of xz image archives, preventing privilege escalation (CVE-2014-9357)\n*   Validate image IDs (CVE-2014-9358)\n\n### [Runtime](#runtime-27)\n\n*   Fix an issue when image archives are being read slowly\n\n### [Client](#client-7)\n\n*   Fix a regression related to stdin redirection\n*   Fix a regression with `docker cp` when destination is the current directory\n\n### [Security](#security-10)\n\n*   Fix tar breakout vulnerability\n\n*   Extractions are now sandboxed chroot\n\n*   Security options are no longer committed to images\n\n### [Runtime](#runtime-28)\n\n*   Fix deadlock in `docker ps -f exited=1`\n*   Fix a bug when `--volumes-from` references a container that failed to start\n\n### [Registry](#registry)\n\n*   `--insecure-registry` now accepts CIDR notation such as 10.1.0.0/16\n\n*   Private registries whose IPs fall in the 127.0.0.0/8 range do no need the `--insecure-registry` flag\n\n*   Skip the experimental registry v2 API when mirroring is enabled\n\n### [Security](#security-11)\n\n*   Prevent fallback to SSL protocols < TLS 1.0 for client, daemon and registry\n\n*   Secure HTTPS connection to registries with certificate verification and without HTTP fallback unless `--insecure-registry` is specified\n\n### [Runtime](#runtime-29)\n\n*   Fix issue where volumes would not be shared\n\n### [Client](#client-8)\n\n*   Fix issue with `--iptables=false` not automatically setting `--ip-masq=false`\n*   Fix docker run output to non-TTY stdout\n\n### [Builder](#builder-9)\n\n*   Fix escaping `$` for environment variables\n*   Fix issue with lowercase `onbuild` Dockerfile instruction\n*   Restrict environment variable expansion to `ENV`, `ADD`, `COPY`, `WORKDIR`, `EXPOSE`, `VOLUME` and `USER`\n\n### [Notable features since 1.2.0](#notable-features-since-120)\n\n*   Docker `exec` allows you to run additional processes inside existing containers\n*   Docker `create` gives you the ability to create a container via the CLI without executing a process\n*   `--security-opts` options to allow user to customize container labels and apparmor profiles\n*   Docker `ps` filters\n\n*   Wildcard support to COPY/ADD\n\n*   Move production URLs to get.docker.com from get.docker.io\n*   Allocate IP address on the bridge inside a valid CIDR\n*   Use drone.io for PR and CI testing\n*   Ability to setup an official registry mirror\n*   Ability to save multiple images with docker `save`\n\n### [Runtime](#runtime-30)\n\n*   Make /etc/hosts /etc/resolv.conf and /etc/hostname editable at runtime\n*   Auto-restart containers using policies\n*   Use /var/lib/docker/tmp for large temporary files\n*   `--cap-add` and `--cap-drop` to tweak what linux capability you want\n*   `--device` to use devices in containers\n\n### [Client](#client-9)\n\n*   `docker search` on private registries\n*   Add `exited` filter to `docker ps --filter`\n\n*   `docker rm -f` now kills instead of stop\n\n*   Support for IPv6 addresses in `--dns` flag\n\n### [Proxy](#proxy)\n\n*   Proxy instances in separate processes\n\n*   Small bug fix on UDP proxy\n\n### [Runtime](#runtime-31)\n\n*   Fix port allocation for existing containers\n*   Fix containers restart on daemon restart\n\n### [Packaging](#packaging-1)\n\n*   Fix /etc/init.d/docker issue on Debian\n\n### [Builder](#builder-10)\n\n*   Fix issue with ADD\n\n### [Notable features since 1.0.1](#notable-features-since-101)\n\n*   Add `.dockerignore` support\n*   Pause containers during `docker commit`\n*   Add `--tail` to `docker logs`\n\n### [Builder](#builder-11)\n\n*   Allow a tar file as context for `docker build`\n\n*   Fix issue with white-spaces and multi-lines in `Dockerfiles`\n\n### [Runtime](#runtime-32)\n\n*   Overall performance improvements\n*   Allow `/` as source of `docker run -v`\n*   Fix port allocation\n*   Fix bug in `docker save`\n*   Add links information to `docker inspect`\n\n### [Client](#client-10)\n\n*   Improve command line parsing for `docker commit`\n\n### [Remote API](#remote-api-2)\n\n*   Improve status code for the `start` and `stop` endpoints\n\n### [Notable features since 1.0.0](#notable-features-since-100)\n\n*   Enhance security for the LXC driver\n\n### [Builder](#builder-12)\n\n*   Fix `ONBUILD` instruction passed to grandchildren\n\n### [Runtime](#runtime-33)\n\n*   Fix events subscription\n*   Fix /etc/hostname file with host networking\n*   Allow `-h` and `--net=none`\n*   Fix issue with hotplug devices in `--privileged`\n\n### [Client](#client-11)\n\n*   Fix artifacts with events\n*   Fix a panic with empty flags\n*   Fix `docker cp` on Mac OS X\n\n### [Miscellaneous](#miscellaneous)\n\n*   Fix compilation on Mac OS X\n*   Fix several races\n\n### [Notable features since 0.12.0](#notable-features-since-0120)\n\n*   Production support\n\n### [Notable features since 0.11.0](#notable-features-since-0110)\n\n*   40+ various improvements to stability, performance and usability\n*   New `COPY` Dockerfile instruction to allow copying a local file from the context into the container without ever extracting if the file is a tar file\n*   Inherit file permissions from the host on `ADD`\n*   New `pause` and `unpause` commands to allow pausing and unpausing of containers using cgroup freezer\n*   The `images` command has a `-f`/`--filter` option to filter the list of images\n*   Add `--force-rm` to clean up after a failed build\n*   Standardize JSON keys in Remote API to CamelCase\n*   Pull from a docker run now assumes `latest` tag if not specified\n*   Enhance security on Linux capabilities and device nodes\n\n### [Registry](#registry-1)\n\n*   Fix push and pull to private registry\n\n### [Notable features since 0.10.0](#notable-features-since-0100)\n\n*   SELinux support for mount and process labels\n*   Linked containers can be accessed by hostname\n*   Use the net `--net` flag to allow advanced network configuration such as host networking so that containers can use the host's network interfaces\n*   Add a ping endpoint to the Remote API to do healthchecks of your docker daemon\n*   Logs can now be returned with an optional timestamp\n*   Docker now works with registries that support SHA-512\n*   Multiple registry endpoints are supported to allow registry mirrors\n\n### [Builder](#builder-13)\n\n*   Fix printing multiple messages on a single line. Fixes broken output during builds.\n*   Follow symlinks inside container's root for ADD build instructions.\n*   Fix EXPOSE caching.\n\n### [Documentation](#documentation-1)\n\n*   Add the new options of `docker ps` to the documentation.\n*   Add the options of `docker restart` to the documentation.\n*   Update daemon docs and help messages for --iptables and --ip-forward.\n*   Updated apt-cacher-ng docs example.\n*   Remove duplicate description of --mtu from docs.\n*   Add missing -t and -v for `docker images` to the docs.\n*   Add fixes to the cli docs.\n*   Update libcontainer docs.\n*   Update images in docs to remove references to AUFS and LXC.\n*   Update the nodejs\\_web\\_app in the docs to use the new epel RPM address.\n*   Fix external link on security of containers.\n*   Update remote API docs.\n*   Add image size to history docs.\n*   Be explicit about binding to all interfaces in redis example.\n*   Document DisableNetwork flag in the 1.10 remote api.\n*   Document that `--lxc-conf` is lxc only.\n*   Add chef usage documentation.\n*   Add example for an image with multiple for `docker load`.\n*   Explain what `docker run -a` does in the docs.\n\n### [Contrib](#contrib-9)\n\n*   Add variable for DOCKER\\_LOGFILE to sysvinit and use append instead of overwrite in opening the logfile.\n*   Fix init script cgroup mounting workarounds to be more similar to cgroupfs-mount and thus work properly.\n*   Remove inotifywait hack from the upstart host-integration example because it's not necessary any more.\n*   Add check-config script to contrib.\n*   Fix fish shell completion.\n\n### [Hack](#hack-1)\n\n*   Clean up \"go test\" output from \"make test\" to be much more readable/scannable.\n*   Exclude more \"definitely not unit tested Go source code\" directories from hack/make/test.\n\n*   Generate md5 and sha256 hashes when building, and upload them via hack/release.sh.\n\n*   Include contributed completions in Ubuntu PPA.\n\n*   Add cli integration tests.\n\n*   Add tweaks to the hack scripts to make them simpler.\n\n### [Remote API](#remote-api-3)\n\n*   Add TLS auth support for API.\n\n*   Move git clone from daemon to client.\n\n*   Fix content-type detection in docker cp.\n\n*   Split API into 2 go packages.\n\n### [Runtime](#runtime-34)\n\n*   Support hairpin NAT without going through Docker server.\n\n*   devicemapper: succeed immediately when removing non-existent devices.\n*   devicemapper: improve handling of devicemapper devices (add per device lock, increase sleep time and unlock while sleeping).\n*   devicemapper: increase timeout in waitClose to 10 seconds.\n*   devicemapper: ensure we shut down thin pool cleanly.\n*   devicemapper: pass info, rather than hash to activateDeviceIfNeeded, deactivateDevice, setInitialized, deleteDevice.\n*   devicemapper: avoid AB-BA deadlock.\n*   devicemapper: make shutdown better/faster.\n*   improve alpha sorting in mflag.\n*   Remove manual http cookie management because the cookiejar is being used.\n*   Use BSD raw mode on Darwin. Fixes nano, tmux and others.\n*   Add FreeBSD support for the client.\n*   Merge auth package into registry.\n*   Add deprecation warning for -t on `docker pull`.\n*   Remove goroutine leak on error.\n*   Update parseLxcInfo to comply with new lxc1.0 format.\n*   Fix attach exit on darwin.\n*   Improve deprecation message.\n*   Retry to retrieve the layer metadata up to 5 times for `docker pull`.\n*   Only unshare the mount namespace for execin.\n*   Merge existing config when committing.\n*   Disable daemon startup timeout.\n*   Fix issue #4681: add loopback interface when networking is disabled.\n*   Add failing test case for issue #4681.\n*   Send SIGTERM to child, instead of SIGKILL.\n*   Show the driver and the kernel version in `docker info` even when not in debug mode.\n*   Always symlink /dev/ptmx for libcontainer. This fixes console related problems.\n*   Fix issue caused by the absence of /etc/apparmor.d.\n*   Don't leave empty cidFile behind when failing to create the container.\n*   Mount cgroups automatically if they're not mounted already.\n*   Use mock for search tests.\n*   Update to double-dash everywhere.\n*   Move .dockerenv parsing to lxc driver.\n*   Move all bind-mounts in the container inside the namespace.\n*   Don't use separate bind mount for container.\n*   Always symlink /dev/ptmx for libcontainer.\n*   Don't kill by pid for other drivers.\n*   Add initial logging to libcontainer.\n\n*   Sort by port in `docker ps`.\n\n*   Move networking drivers into runtime top level package.\n\n*   Add --no-prune to `docker rmi`.\n*   Add time since exit in `docker ps`.\n\n*   graphdriver: add build tags.\n*   Prevent allocation of previously allocated ports & prevent improve port allocation.\n\n*   Add support for --since/--before in `docker ps`.\n\n*   Clean up container stop.\n\n*   Add support for configurable dns search domains.\n\n*   Add support for relative WORKDIR instructions.\n*   Add --output flag for docker save.\n*   Remove duplication of DNS entries in config merging.\n*   Add cpuset.cpus to cgroups and native driver options.\n*   Remove docker-ci.\n*   Promote btrfs. btrfs is no longer considered experimental.\n*   Add --input flag to `docker load`.\n*   Return error when existing bridge doesn't match IP address.\n*   Strip comments before parsing line continuations to avoid interpreting instructions as comments.\n*   Fix TestOnlyLoopbackExistsWhenUsingDisableNetworkOption to ignore \"DOWN\" interfaces.\n*   Add systemd implementation of cgroups and make containers show up as systemd units.\n*   Fix commit and import when no repository is specified.\n*   Remount /var/lib/docker as --private to fix scaling issue.\n*   Use the environment's proxy when pinging the remote registry.\n*   Reduce error level from harmless errors.\n\n*   Allow --volumes-from to be individual files.\n\n*   Fix expanding buffer in StdCopy.\n*   Set error regardless of attach or stdin. This fixes #3364.\n*   Add support for --env-file to load environment variables from files.\n*   Symlink /etc/mtab and /proc/mounts.\n*   Allow pushing a single tag.\n*   Shut down containers cleanly at shutdown and wait forever for the containers to shut down. This makes container shutdown on daemon shutdown work properly via SIGTERM.\n*   Don't throw error when starting an already running container.\n*   Fix dynamic port allocation limit.\n*   remove setupDev from libcontainer.\n*   Add API version to `docker version`.\n*   Return correct exit code when receiving signal and make SIGQUIT quit without cleanup.\n*   Fix --volumes-from mount failure.\n*   Allow non-privileged containers to create device nodes.\n*   Skip login tests because of external dependency on a hosted service.\n*   Deprecate `docker images --tree` and `docker images --viz`.\n*   Deprecate `docker insert`.\n*   Include base abstraction for apparmor. This fixes some apparmor related problems on Ubuntu 14.04.\n*   Add specific error message when hitting 401 over HTTP on push.\n*   Fix absolute volume check.\n*   Remove volumes-from from the config.\n*   Move DNS options to hostconfig.\n*   Update the apparmor profile for libcontainer.\n*   Add deprecation notice for `docker commit -run`.\n\n### [Builder](#builder-14)\n\n*   Fix printing multiple messages on a single line. Fixes broken output during builds.\n\n### [Documentation](#documentation-2)\n\n*   Fix external link on security of containers.\n\n### [Contrib](#contrib-10)\n\n*   Fix init script cgroup mounting workarounds to be more similar to cgroupfs-mount and thus work properly.\n*   Add variable for DOCKER\\_LOGFILE to sysvinit and use append instead of overwrite in opening the logfile.\n\n### [Hack](#hack-2)\n\n*   Generate md5 and sha256 hashes when building, and upload them via hack/release.sh.\n\n### [Remote API](#remote-api-4)\n\n*   Fix content-type detection in `docker cp`.\n\n### [Runtime](#runtime-35)\n\n*   Use BSD raw mode on Darwin. Fixes nano, tmux and others.\n*   Only unshare the mount namespace for execin.\n*   Retry to retrieve the layer metadata up to 5 times for `docker pull`.\n*   Merge existing config when committing.\n*   Fix panic in monitor.\n*   Disable daemon startup timeout.\n*   Fix issue #4681: add loopback interface when networking is disabled.\n*   Add failing test case for issue #4681.\n*   Send SIGTERM to child, instead of SIGKILL.\n*   Show the driver and the kernel version in `docker info` even when not in debug mode.\n*   Always symlink /dev/ptmx for libcontainer. This fixes console related problems.\n*   Fix issue caused by the absence of /etc/apparmor.d.\n*   Don't leave empty cidFile behind when failing to create the container.\n*   Improve deprecation message.\n*   Fix attach exit on darwin.\n*   devicemapper: improve handling of devicemapper devices (add per device lock, increase sleep time, unlock while sleeping).\n*   devicemapper: succeed immediately when removing non-existent devices.\n*   devicemapper: increase timeout in waitClose to 10 seconds.\n*   Remove goroutine leak on error.\n*   Update parseLxcInfo to comply with new lxc1.0 format.\n\n### [Builder](#builder-15)\n\n*   Avoid extra mount/unmount during build. This fixes mount/unmount related errors during build.\n*   Add error to docker build --rm. This adds missing error handling.\n*   Forbid chained onbuild, `onbuild from` and `onbuild maintainer` triggers.\n*   Make `--rm` the default for `docker build`.\n\n### [Documentation](#documentation-3)\n\n*   Download the docker client binary for Mac over https.\n*   Update the titles of the install instructions & descriptions.\n\n*   Add instructions for upgrading boot2docker.\n*   Add port forwarding example in OS X install docs.\n\n*   Attempt to disentangle repository and registry.\n*   Update docs to explain more about `docker ps`.\n*   Update sshd example to use a Dockerfile.\n*   Rework some examples, including the Python examples.\n*   Update docs to include instructions for a container's lifecycle.\n*   Update docs documentation to discuss the docs branch.\n*   Don't skip cert check for an example & use HTTPS.\n*   Bring back the memory and swap accounting section which was lost when the kernel page was removed.\n*   Explain DNS warnings and how to fix them on systems running and using a local nameserver.\n\n### [Contrib](#contrib-11)\n\n*   Add Tanglu support for mkimage-debootstrap.\n*   Add SteamOS support for mkimage-debootstrap.\n\n### [Hack](#hack-3)\n\n*   Get package coverage when running integration tests.\n*   Remove the Vagrantfile. This is being replaced with boot2docker.\n*   Fix tests on systems where aufs isn't available.\n*   Update packaging instructions and remove the dependency on lxc.\n\n### [Remote API](#remote-api-5)\n\n*   Move code specific to the API to the api package.\n\n*   Fix header content type for the API. Makes all endpoints use proper content type.\n*   Fix registry auth & remove ping calls from CmdPush and CmdPull.\n*   Add newlines to the JSON stream functions.\n\n### [Runtime](#runtime-36)\n\n*   Do not ping the registry from the CLI. All requests to registries flow through the daemon.\n\n*   Check for nil information return in the lxc driver. This fixes panics with older lxc versions.\n*   Devicemapper: cleanups and fix for unmount. Fixes two problems which were causing unmount to fail intermittently.\n*   Devicemapper: remove directory when removing device. Directories don't get left behind when removing the device.\n\n*   Devicemapper: enable skip\\_block\\_zeroing. Improves performance by not zeroing blocks.\n\n*   Devicemapper: fix shutdown warnings. Fixes shutdown warnings concerning pool device removal.\n*   Ensure docker cp stream is closed properly. Fixes problems with files not being copied by `docker cp`.\n*   Stop making `tcp://` default to `127.0.0.1:4243` and remove the default port for tcp.\n*   Fix `--run` in `docker commit`. This makes `docker commit --run` work again.\n*   Fix custom bridge related options. This makes custom bridges work again.\n\n*   Mount-bind the PTY as container console. This allows tmux/screen to run.\n*   Add the pure Go libcontainer library to make it possible to run containers using only features of the Linux kernel.\n*   Add native exec driver which uses libcontainer and make it the default exec driver.\n\n*   Add support for handling extended attributes in archives.\n\n*   Set the container MTU to be the same as the host MTU.\n\n*   Add simple sha256 checksums for layers to speed up `docker push`.\n\n*   Improve kernel version parsing.\n*   Allow flag grouping (`docker run -it`).\n\n*   Remove chroot exec driver.\n*   Fix divide by zero to fix panic.\n*   Rewrite `docker rmi`.\n*   Fix docker info with lxc 1.0.0.\n*   Fix fedora tty with apparmor.\n\n*   Don't always append env vars, replace defaults with vars from config.\n*   Fix a goroutine leak.\n*   Switch to Go 1.2.1.\n\n*   Fix unique constraint error checks.\n\n*   Handle symlinks for Docker's data directory and for TMPDIR.\n\n*   Add deprecation warnings for flags (-flag is deprecated in favor of --flag)\n*   Add apparmor profile for the native execution driver.\n\n*   Move system specific code from archive to pkg/system.\n\n*   Fix duplicate signal for `docker run -i -t` (issue #3336).\n*   Return correct process pid for lxc.\n*   Add a -G option to specify the group which unix sockets belong to.\n\n*   Add `-f` flag to `docker rm` to force removal of running containers.\n*   Kill ghost containers and restart all ghost containers when the docker daemon restarts.\n*   Add `DOCKER_RAMDISK` environment variable to make Docker work when the root is on a ramdisk.\n\n### [Builder](#builder-16)\n\n*   Avoid extra mount/unmount during build. This removes an unneeded mount/unmount operation which was causing problems with devicemapper\n*   Fix regression with ADD of tar files. This stops Docker from decompressing tarballs added via ADD from the local file system\n*   Add error to `docker build --rm`. This adds a missing error check to ensure failures to remove containers are detected and reported\n\n### [Documentation](#documentation-4)\n\n*   Update issue filing instructions\n*   Warn against the use of symlinks for Docker's storage folder\n*   Replace the Firefox example with an IceWeasel example\n*   Rewrite the PostgreSQL example using a Dockerfile and add more details to it\n*   Improve the OS X documentation\n\n### [Remote API](#remote-api-6)\n\n*   Fix broken images API for version less than 1.7\n*   Use the right encoding for all API endpoints which return JSON\n*   Move remote api client to api/\n*   Queue calls to the API using generic socket wait\n\n### [Runtime](#runtime-37)\n\n*   Fix the use of custom settings for bridges and custom bridges\n*   Refactor the devicemapper code to avoid many mount/unmount race conditions and failures\n*   Remove two panics which could make Docker crash in some situations\n*   Don't ping registry from the CLI client\n*   Enable skip\\_block\\_zeroing for devicemapper. This stops devicemapper from always zeroing entire blocks\n*   Fix --run in `docker commit`. This makes docker commit store `--run` in the image configuration\n*   Remove directory when removing devicemapper device. This cleans up leftover mount directories\n*   Drop NET\\_ADMIN capability for non-privileged containers. Unprivileged containers can't change their network configuration\n*   Ensure `docker cp` stream is closed properly\n*   Avoid extra mount/unmount during container registration. This removes an unneeded mount/unmount operation which was causing problems with devicemapper\n*   Stop allowing tcp:// as a default tcp bin address which binds to 127.0.0.1:4243 and remove the default port\n\n*   Mount-bind the PTY as container console. This allows tmux and screen to run in a container\n\n*   Clean up archive closing. This fixes and improves archive handling\n*   Fix engine tests on systems where temp directories are symlinked\n*   Add test methods for save and load\n*   Avoid temporarily unmounting the container when restarting it. This fixes a race for devicemapper during restart\n*   Support submodules when building from a GitHub repository\n*   Quote volume path to allow spaces\n*   Fix remote tar ADD behavior. This fixes a regression which was causing Docker to extract tarballs\n\n### [Notable features since 0.7.0](#notable-features-since-070)\n\n*   Images and containers can be removed much faster\n    \n*   Building an image from source with docker build is now much faster\n    \n*   The Docker daemon starts and stops much faster\n    \n*   The memory footprint of many common operations has been reduced, by streaming files instead of buffering them in memory, fixing memory leaks, and fixing various suboptimal memory allocations\n    \n*   Several race conditions were fixed, making Docker more stable under very high concurrency load. This makes Docker more stable and less likely to crash and reduces the memory footprint of many common operations\n    \n*   All packaging operations are now built on the Go languageâ€™s standard tar implementation, which is bundled with Docker itself. This makes packaging more portable across host distributions, and solves several issues caused by quirks and incompatibilities between different distributions of tar\n    \n*   Docker can now create, remove and modify larger numbers of containers and images graciously thanks to more aggressive releasing of system resources. For example the storage driver API now allows Docker to do reference counting on mounts created by the drivers With the ongoing changes to the networking and execution subsystems of docker testing these areas have been a focus of the refactoring. By moving these subsystems into separate packages we can test, analyze, and monitor coverage and quality of these packages\n    \n*   Many components have been separated into smaller sub-packages, each with a dedicated test suite. As a result the code is better-tested, more readable and easier to change\n    \n*   The ADD instruction now supports caching, which avoids unnecessarily re-uploading the same source content again and again when it hasnâ€™t changed\n    \n*   The new ONBUILD instruction adds to your image a â€œtriggerâ€ instruction to be executed at a later time, when the image is used as the base for another build\n    \n*   Docker now ships with an experimental storage driver which uses the BTRFS filesystem for copy-on-write\n    \n*   Docker is officially supported on Mac OS X\n    \n*   The Docker daemon supports systemd socket activation\n    \n\n### [Builder](#builder-17)\n\n*   Do not follow symlink outside of build context\n\n### [Runtime](#runtime-38)\n\n*   Remount bind mounts when ro is specified\n\n*   Use https for fetching docker version\n\n### [Other](#other-1)\n\n*   Inline the test.docker.io fingerprint\n*   Add ca-certificates to packaging documentation\n\n### [Builder](#builder-18)\n\n*   Disable compression for build. More space usage but a much faster upload\n\n*   Fix ADD caching for certain paths\n*   Do not compress archive from git build\n\n### [Documentation](#documentation-5)\n\n*   Fix error in GROUP add example\n\n*   Make sure the GPG fingerprint is inline in the documentation\n*   Give more specific advice on setting up signing of commits for DCO\n\n### [Runtime](#runtime-39)\n\n*   Fix misspelled container names\n*   Do not add hostname when networking is disabled\n\n*   Return most recent image from the cache by date\n\n*   Return all errors from docker wait\n\n*   Add Content-Type Header \"application/json\" to GET /version and /info responses\n\n### [Other](#other-2)\n\n*   Update DCO to version 1.1\n\n*   Update Makefile to use \"docker:GIT\\_BRANCH\" as the generated image name\n\n*   Update Travis to check for new 1.1 DCO version\n\n### [Builder](#builder-19)\n\n*   Fix ADD caching issue with . prefixed path\n*   Fix docker build on devicemapper by reverting sparse file tar option\n*   Fix issue with file caching and prevent wrong cache hit\n\n*   Use same error handling while unmarshalling CMD and ENTRYPOINT\n\n### [Documentation](#documentation-6)\n\n*   Simplify and streamline Amazon Quickstart\n*   Install instructions use unprefixed Fedora image\n*   Update instructions for mtu flag for Docker on GCE\n\n*   Add Ubuntu Saucy to installation\n\n*   Fix for wrong version warning on master instead of latest\n\n### [Runtime](#runtime-40)\n\n*   Only get the image's rootfs when we need to calculate the image size\n*   Correctly handle unmapping UDP ports\n\n*   Make CopyFileWithTar use a pipe instead of a buffer to save memory on docker build\n\n*   Fix login message to say pull instead of push\n*   Fix \"docker load\" help by removing \"SOURCE\" prompt and mentioning STDIN\n\n*   Make blank -H option default to the same as no -H was sent\n*   Extract cgroups utilities to own submodule\n\n### [Other](#other-3)\n\n*   Add Travis CI configuration to validate DCO and gofmt requirements\n*   Add Developer Certificate of Origin Text\n\n*   Upgrade VBox Guest Additions\n*   Check standalone header when pinging a registry server\n\n### [Builder](#builder-20)\n\n*   Update ADD to use the image cache, based on a hash of the added content\n\n*   Add error message for empty Dockerfile\n\n### [Documentation](#documentation-7)\n\n*   Fix outdated link to the \"Introduction\" on [www.docker.io](https://www.docker.io/)\n\n*   Update the docs to get wider when the screen does\n\n*   Add information about needing to install LXC when using raw binaries\n\n*   Update Fedora documentation to disentangle the docker and docker.io conflict\n*   Add a note about using the new `-mtu` flag in several GCE zones\n\n*   Add FrugalWare installation instructions\n*   Add a more complete example of `docker run`\n\n*   Fix API documentation for creating and starting Privileged containers\n*   Add missing \"name\" parameter documentation on \"/containers/create\"\n\n*   Add a mention of `lxc-checkconfig` as a way to check for some of the necessary kernel configuration\n\n*   Update the 1.8 API documentation with some additions that were added to the docs for 1.7\n\n### [Hack](#hack-4)\n\n*   Add missing libdevmapper dependency to the packagers documentation\n\n*   Update minimum Go requirement to a hard line at Go 1.2+\n*   Many minor improvements to the Vagrantfile\n\n*   Add ability to customize dockerinit search locations when compiling (to be used very sparingly only by packagers of platforms who require a nonstandard location)\n*   Add coverprofile generation reporting\n\n*   Add `-a` to our Go build flags, removing the need for recompiling the stdlib manually\n\n*   Update Dockerfile to be more canonical and have less spurious warnings during build\n\n*   Fix some miscellaneous `docker pull` progress bar display issues\n\n*   Migrate more miscellaneous packages under the \"pkg\" folder\n*   Update TextMate highlighting to automatically be enabled for files named \"Dockerfile\"\n*   Reorganize syntax highlighting files under a common \"contrib/syntax\" directory\n*   Update install.sh script ( [https://get.docker.io/](https://get.docker.io/)) to not fail if busybox fails to download or run at the end of the Ubuntu/Debian installation\n*   Add support for container names in bash completion\n\n### [Packaging](#packaging-2)\n\n*   Add an official Docker client binary for Darwin (Mac OS X)\n\n*   Remove empty \"Vendor\" string and added \"License\" on deb package\n\n*   Add a stubbed version of \"/etc/default/docker\" in the deb package\n\n### [Runtime](#runtime-41)\n\n*   Update layer application to extract tars in place, avoiding file churn while handling whiteouts\n\n*   Fix permissiveness of mtime comparisons in tar handling (since GNU tar and Go tar do not yet support sub-second mtime precision)\n\n*   Reimplement `docker top` in pure Go to work more consistently, and even inside Docker-in-Docker (thus removing the shell injection vulnerability present in some versions of `lxc-ps`)\n\n*   Update `-H unix://` to work similarly to `-H tcp://` by inserting the default values for missing portions\n\n*   Fix more edge cases regarding dockerinit and deleted or replaced docker or dockerinit files\n\n*   Update container name validation to include '.'\n\n*   Fix use of a symlink or non-absolute path as the argument to `-g` to work as expected\n\n*   Update to handle external mounts outside of LXC, fixing many small mounting quirks and making future execution backends and other features simpler\n*   Update to use proper box-drawing characters everywhere in `docker images -tree`\n*   Move MTU setting from LXC configuration to directly use netlink\n*   Add `-S` option to external tar invocation for more efficient spare file handling\n\n*   Add arch/os info to User-Agent string, especially for registry requests\n*   Add `-mtu` option to Docker daemon for configuring MTU\n\n*   Fix `docker build` to exit with a non-zero exit code on error\n\n*   Add `DOCKER_HOST` environment variable to configure the client `-H` flag without specifying it manually for every invocation\n\n### [Runtime](#runtime-42)\n\n*   Validate container names on creation with standard regex\n\n*   Increase maximum image depth to 127 from 42\n*   Continue to move api endpoints to the job api\n\n*   Add -bip flag to allow specification of dynamic bridge IP via CIDR\n\n*   Allow bridge creation when ipv6 is not enabled on certain systems\n\n*   Set hostname and IP address from within dockerinit\n*   Drop capabilities from within dockerinit\n\n*   Fix volumes on host when symlink is present the image\n*   Prevent deletion of image if ANY container is depending on it even if the container is not running\n\n*   Update docker push to use new progress display\n*   Use os.Lstat to allow mounting unix sockets when inspecting volumes\n\n*   Adjust handling of inactive user login\n*   Add missing defines in devicemapper for older kernels\n*   Allow untag operations with no container validation\n*   Add auth config to docker build\n\n### [Documentation](#documentation-8)\n\n*   Add more information about Docker logging\n\n*   Add RHEL documentation\n\n*   Add a direct example for changing the CMD that is run in a container\n*   Update Arch installation documentation\n\n*   Add section on Trusted Builds\n*   Add Network documentation page\n\n### [Other](#other-4)\n\n*   Add new cover bundle for providing code coverage reporting\n\n*   Separate integration tests in bundles\n*   Make Tianon the hack maintainer\n*   Update mkimage-debootstrap with more tweaks for keeping images small\n*   Use https to get the install script\n*   Remove vendored dotcloud/tar now that Go 1.2 has been released\n\n### [Documentation](#documentation-9)\n\n*   Add @SvenDowideit as documentation maintainer\n*   Add links example\n*   Add documentation regarding ambassador pattern\n*   Add Google Cloud Platform docs\n*   Add dockerfile best practices\n\n*   Update doc for RHEL\n*   Update doc for registry\n*   Update Postgres examples\n*   Update doc for Ubuntu install\n*   Improve remote api doc\n\n### [Runtime](#runtime-43)\n\n*   Add hostconfig to docker inspect\n*   Implement `docker log -f` to stream logs\n*   Add env variable to disable kernel version warning\n*   Add -format to `docker inspect`\n*   Support bind-mount for files\n\n*   Fix bridge creation on RHEL\n*   Fix image size calculation\n*   Make sure iptables are called even if the bridge already exists\n*   Fix issue with stderr only attach\n*   Remove init layer when destroying a container\n*   Fix same port binding on different interfaces\n*   `docker build` now returns the correct exit code\n*   Fix `docker port` to display correct port\n*   `docker build` now check that the dockerfile exists client side\n*   `docker attach` now returns the correct exit code\n*   Remove the name entry when the container does not exist\n\n### [Registry](#registry-2)\n\n*   Improve progress bars, add ETA for downloads\n*   Simultaneous pulls now waits for the first to finish instead of failing\n\n*   Tag only the top-layer image when pushing to registry\n*   Fix issue with offline image transfer\n*   Fix issue preventing using ':' in password for registry\n\n### [Other](#other-5)\n\n*   Add pprof handler for debug\n*   Create a Makefile\n\n*   Use stdlib tar that now includes fix\n*   Improve make.sh test script\n*   Handle SIGQUIT on the daemon\n*   Disable verbose during tests\n*   Upgrade to go1.2 for official build\n*   Improve unit tests\n*   The test suite now runs all tests even if one fails\n*   Refactor C in Go (Devmapper)\n\n*   Fix OS X compilation\n\n### [Notable features since 0.6.0](#notable-features-since-060)\n\n*   Storage drivers: choose from aufs, device-mapper, or vfs.\n*   Standard Linux support: docker now runs on unmodified Linux kernels and all major distributions.\n*   Links: compose complex software stacks by connecting containers to each other.\n*   Container naming: organize your containers by giving them memorable names.\n*   Advanced port redirects: specify port redirects per interface, or keep sensitive ports private.\n*   Offline transfer: push and pull images to the filesystem without losing information.\n*   Quality: numerous bugfixes and small usability improvements. Significant increase in test coverage.\n\n### [Runtime](#runtime-44)\n\n*   Improve stability, fixes some race conditions\n*   Skip the volumes mounted when deleting the volumes of container.\n*   Fix layer size computation: handle hard links correctly\n*   Use the work Path for docker cp CONTAINER:PATH\n*   Fix tmp dir never cleanup\n*   Speedup docker ps\n*   More informative error message on name collisions\n*   Fix nameserver regex\n*   Always return long id's\n*   Fix container restart race condition\n*   Keep published ports on docker stop;docker start\n*   Fix container networking on Fedora\n*   Correctly express \"any address\" to iptables\n*   Fix network setup when reconnecting to ghost container\n*   Prevent deletion if image is used by a running container\n*   Lock around read operations in graph\n\n### [RemoteAPI](#remoteapi)\n\n*   Return full ID on docker rmi\n\n### [Client](#client-12)\n\n*   Add -tree option to images\n*   Offline image transfer\n\n*   Exit with status 2 on usage error and display usage on stderr\n*   Do not forward SIGCHLD to container\n*   Use string timestamp for docker events -since\n\n### [Other](#other-6)\n\n*   Update to go 1.2rc5\n\n*   Add /etc/default/docker support to upstart\n\n### [Runtime](#runtime-45)\n\n*   Ensure container name on register\n*   Fix regression in /etc/hosts\n\n*   Add lock around write operations in graph\n\n*   Check if port is valid\n*   Fix restart runtime error with ghost container networking\n\n*   Add some more colors and animals to increase the pool of generated names\n\n*   Fix issues in docker inspect\n\n*   Escape apparmor confinement\n*   Set environment variables using a file.\n\n*   Prevent docker insert to erase something\n\n*   Prevent DNS server conflicts in CreateBridgeIface\n*   Validate bind mounts on the server side\n*   Use parent image config in docker build\n\n*   Fix regression in /etc/hosts\n\n### [Client](#client-13)\n\n*   Add -P flag to publish all exposed ports\n*   Add -notrunc and -q flags to docker history\n\n*   Fix docker commit, tag and import usage\n\n*   Add stars, trusted builds and library flags in docker search\n\n*   Fix docker logs with tty\n\n### [RemoteAPI](#remoteapi-1)\n\n*   Make /events API send headers immediately\n*   Do not split last column docker top\n\n*   Add size to history\n\n### [Other](#other-7)\n\n*   Contrib: Desktop integration. Firefox usecase.\n*   Dockerfile: bump to go1.2rc3\n\n### [Runtime](#runtime-46)\n\n*   Containers can now be named\n*   Containers can now be linked together for service discovery\n*   'run -a', 'start -a' and 'attach' can forward signals to the container for better integration with process supervisors\n*   Automatically start crashed containers after a reboot\n*   Expose IP, port, and proto as separate environment vars for container links\n\n*   Allow ports to be published to specific ips\n*   Prohibit inter-container communication by default\n\n*   Ignore ErrClosedPipe for stdin in Container.Attach\n*   Remove unused field kernelVersion\n\n*   Fix issue when mounting subdirectories of /mnt in container\n\n*   Fix untag during removal of images\n\n*   Check return value of syscall.Chdir when changing working directory inside dockerinit\n\n### [Client](#client-14)\n\n*   Only pass stdin to hijack when needed to avoid closed pipe errors\n\n*   Use less reflection in command-line method invocation\n\n*   Monitor the tty size after starting the container, not prior\n*   Remove useless os.Exit() calls after log.Fatal\n\n### [Hack](#hack-5)\n\n*   Add initial init scripts library and a safer Ubuntu packaging script that works for Debian\n\n*   Add -p option to invoke debootstrap with http\\_proxy\n\n*   Update install.sh with $sh\\_c to get sudo/su for modprobe\n\n*   Update all the mkimage scripts to use --numeric-owner as a tar argument\n*   Update hack/release.sh process to automatically invoke hack/make.sh and bail on build and test issues\n\n### [Other](#other-8)\n\n*   Documentation: Fix the flags for nc in example\n*   Testing: Remove warnings and prevent mount issues\n\n*   Testing: Change logic for tty resize to avoid warning in tests\n*   Builder: Fix race condition in docker build with verbose output\n*   Registry: Fix content-type for PushImageJSONIndex method\n\n*   Contrib: Improve helper tools to generate debian and Arch linux server images\n\n### [Runtime](#runtime-47)\n\n*   Add cleanup of container when Start() fails\n\n*   Add better comments to utils/stdcopy.go\n*   Add utils.Errorf for error logging\n\n*   Add -rm to docker run for removing a container on exit\n\n*   Remove error messages which are not actually errors\n*   Fix `docker rm` with volumes\n*   Fix some error cases where an HTTP body might not be closed\n*   Fix panic with wrong dockercfg file\n*   Fix the attach behavior with -i\n\n*   Record termination time in state.\n\n*   Use empty string so TempDir uses the OS's temp dir automatically\n*   Make sure to close the network allocators\n\n*   Autorestart containers by default\n\n*   Bump vendor kr/pty to commit 3b1f6487b `(syscall.O_NOCTTY)`\n*   lxc: Allow set\\_file\\_cap capability in container\n\n*   Move run -rm to the cli only\n\n*   Split stdout stderr\n*   Always create a new session for the container\n\n### [Testing](#testing)\n\n*   Add aggregated docker-ci email report\n*   Add cleanup to remove leftover containers\n\n*   Add nightly release to docker-ci\n*   Add more tests around auth.ResolveAuthConfig\n\n*   Remove a few errors in tests\n*   Catch errClosing error when TCP and UDP proxies are terminated\n\n*   Only run certain tests with TESTFLAGS='-run TestName' make.sh\n*   Prevent docker-ci to test closing PRs\n*   Replace panic by log.Fatal in tests\n\n*   Increase TestRunDetach timeout\n\n### [Documentation](#documentation-10)\n\n*   Add initial draft of the Docker infrastructure doc\n*   Add devenvironment link to CONTRIBUTING.md\n*   Add `apt-get install curl` to Ubuntu docs\n*   Add explanation for export restrictions\n*   Add .dockercfg doc\n*   Remove Gentoo install notes about #1422 workaround\n*   Fix help text for -v option\n*   Fix Ping endpoint documentation\n\n*   Fix parameter names in docs for ADD command\n*   Fix ironic typo in changelog\n\n*   Various command fixes in postgres example\n*   Document how to edit and release docs\n\n*   Minor updates to `postgresql_service.rst`\n\n*   Clarify LGTM process to contributors\n\n*   Corrected error in the package name\n\n*   Document what `vagrant up` is actually doing\n\n*   improve doc search results\n\n*   Cleanup whitespace in API 1.5 docs\n*   use angle brackets in MAINTAINER example email\n*   Update archlinux.rst\n\n*   Changes to a new style for the docs. Includes version switcher.\n\n*   Formatting, add information about multiline json\n*   Improve registry and index REST API documentation\n\n*   Replace deprecated upgrading reference to docker-latest.tgz, which hasn't been updated since 0.5.3\n\n*   Update Gentoo installation documentation now that we're in the portage tree proper\n*   Cleanup and reorganize docs and tooling for contributors and maintainers\n\n*   Minor spelling correction of protocoll -> protocol\n\n### [Contrib](#contrib-12)\n\n*   Add vim syntax highlighting for Dockerfiles from @honza\n*   Add mkimage-arch.sh\n*   Reorganize contributed completion scripts to add zsh completion\n\n### [Hack](#hack-6)\n\n*   Add vagrant user to the docker group\n*   Add proper bash completion for \"docker push\"\n*   Add xz utils as a runtime dep\n*   Add cleanup/refactor portion of #2010 for hack and Dockerfile updates\n\n*   Add contrib/mkimage-centos.sh back (from #1621), and associated documentation link\n\n*   Add several of the small make.sh fixes from #1920, and make the output more consistent and contributor-friendly\n\n*   Add @tianon to hack/MAINTAINERS\n\n*   Improve network performance for VirtualBox\n*   Revamp install.sh to be usable by more people, and to use official install methods whenever possible (apt repo, portage tree, etc.)\n\n*   Fix contrib/mkimage-debian.sh apt caching prevention\n\n*   Add Dockerfile.tmLanguage to contrib\n\n*   Configured FPM to make /etc/init/docker.conf a config file\n*   Enable SSH Agent forwarding in Vagrant VM\n*   Several small tweaks/fixes for contrib/mkimage-debian.sh\n\n### [Other](#other-9)\n\n*   Builder: Abort build if mergeConfig returns an error and fix duplicate error message\n*   Packaging: Remove deprecated packaging directory\n*   Registry: Use correct auth config when logging in.\n*   Registry: Fix the error message so it is the same as the regex\n\n### [Packaging](#packaging-3)\n\n*   Add 'docker' group on install for ubuntu package\n*   Update tar vendor dependency\n*   Download apt key over HTTPS\n\n### [Runtime](#runtime-48)\n\n*   Only copy and change permissions on non-bindmount volumes\n\n*   Allow multiple volumes-from\n\n*   Fix HTTP imports from STDIN\n\n### [Documentation](#documentation-11)\n\n*   Update section on extracting the docker binary after build\n*   Update development environment docs for new build process\n*   Remove 'base' image from documentation\n\n### [Other](#other-10)\n\n*   Client: Fix detach issue\n*   Registry: Update regular expression to match index\n\n### [Runtime](#runtime-49)\n\n*   Add domainname support\n*   Implement image filtering with path.Match\n\n*   Remove unnecessary warnings\n*   Remove os/user dependency\n*   Only mount the hostname file when the config exists\n*   Handle signals within the `docker login` command\n\n*   UID and GID are now also applied to volumes\n*   `docker start` set error code upon error\n*   `docker run` set the same error code as the process started\n\n### [Builder](#builder-21)\n\n*   Add -rm option in order to remove intermediate containers\n\n*   Allow multiline for the RUN instruction\n\n### [Registry](#registry-3)\n\n*   Implement login with private registry\n\n*   Fix push issues\n\n### [Other](#other-11)\n\n*   Hack: Vendor all dependencies\n\n*   Remote API: Bump to v1.5\n*   Packaging: Break down hack/make.sh into small scripts, one per 'bundle': test, binary, ubuntu etc.\n*   Documentation: General improvements\n\n### [Registry](#registry-4)\n\n*   Pass \"meta\" headers in API calls to the registry\n\n### [Packaging](#packaging-4)\n\n*   Use correct upstart script with new build tool\n*   Use libffi-dev, don't build it from sources\n*   Remove duplicate mercurial install command\n\n### [Runtime](#runtime-50)\n\n*   Add lxc-conf flag to allow custom lxc options\n*   Add an option to set the working directory\n\n*   Add Image name to LogEvent tests\n\n*   Add -privileged flag and relevant tests, docs, and examples\n\n*   Add websocket support to /container//attach/ws\n*   Add warning when net.ipv4.ip\\_forwarding = 0\n*   Add hostname to environment\n*   Add last stable version in `docker version`\n\n*   Fix race conditions in parallel pull\n*   Fix Graph ByParent() to generate list of child images per parent image.\n*   Fix typo: fmt.Sprint -> fmt.Sprintf\n*   Fix small \\\\n error un docker build\n\n*   Fix to \"Inject dockerinit at /.dockerinit\"\n*   Fix #910. print user name to docker info output\n*   Use Go 1.1.2 for dockerbuilder\n*   Use ranged for loop on channels\n\n*   Use utils.ParseRepositoryTag instead of strings.Split(name, \":\") in server.ImageDelete\n*   Improve CMD, ENTRYPOINT, and attach docs.\n*   Improve connect message with socket error\n*   Load authConfig only when needed and fix useless WARNING\n*   Show tag used when image is missing\n\n*   Apply volumes-from before creating volumes\n\n*   Make docker run handle SIGINT/SIGTERM\n*   Prevent crash when .dockercfg not readable\n*   Install script should be fetched over https, not http.\n\n*   API, issue 1471: Use groups for socket permissions\n\n*   Correctly detect IPv4 forwarding\n\n*   Mount /dev/shm as a tmpfs\n\n*   Switch from http to https for get.docker.io\n\n*   Let userland proxy handle container-bound traffic\n*   Update the Docker CLI to specify a value for the \"Host\" header.\n\n*   Change network range to avoid conflict with EC2 DNS\n*   Reduce connect and read timeout when pinging the registry\n\n*   Parallel pull\n\n*   Handle ip route showing mask-less IP addresses\n\n*   Allow ENTRYPOINT without CMD\n\n*   Always consider localhost as a domain name when parsing the FQN repos name\n\n*   Refactor checksum\n\n### [Documentation](#documentation-12)\n\n*   Add MongoDB image example\n*   Add instructions for creating and using the docker group\n*   Add sudo to examples and installation to documentation\n*   Add ufw doc\n*   Add a reference to ps -a\n*   Add information about Docker's high level tools over LXC.\n*   Fix typo in docs for docker run -dns\n*   Fix a typo in the ubuntu installation guide\n*   Fix to docs regarding adding docker groups\n*   Update default -H docs\n*   Update readme with dependencies for building\n*   Update amazon.rst to explain that Vagrant is not necessary for running Docker on ec2\n*   PostgreSQL service example in documentation\n*   Suggest installing linux-headers by default.\n*   Change the twitter handle\n*   Clarify Amazon EC2 installation\n*   'Base' image is deprecated and should no longer be referenced in the docs.\n*   Move note about officially supported kernel\n\n*   Solved the logo being squished in Safari\n\n### [Builder](#builder-22)\n\n*   Add USER instruction do Dockerfile\n*   Add workdir support for the Buildfile\n\n*   Add no cache for docker build\n\n*   Fix docker build and docker events output\n*   Only count known instructions as build steps\n*   Make sure ENV instruction within build perform a commit each time\n*   Forbid certain paths within docker build ADD\n*   Repository name (and optionally a tag) in build usage\n*   Make sure ADD will create everything in 0755\n\n### [Remote API](#remote-api-7)\n\n*   Sort Images by most recent creation date.\n*   Reworking opaque requests in registry module\n*   Add image name in /events\n*   Use mime pkg to parse Content-Type\n*   650 http utils and user agent field\n\n### [Hack](#hack-7)\n\n*   Bash Completion: Limit commands to containers of a relevant state\n\n*   Add docker dependencies coverage testing into docker-ci\n\n### [Packaging](#packaging-5)\n\n*   Docker-brew 0.5.2 support and memory footprint reduction\n\n*   Add new docker dependencies into docker-ci\n\n*   Revert \"docker.upstart: avoid spawning a `sh` process\"\n\n*   Docker-brew and Docker standard library\n*   Release docker with docker\n\n*   Fix the upstart script generated by get.docker.io\n*   Enabled the docs to generate manpages.\n*   Revert Bind daemon to 0.0.0.0 in Vagrant.\n\n### [Register](#register)\n\n*   Improve auth push\n*   Registry unit tests + mock registry\n\n### [Tests](#tests)\n\n*   Improve TestKillDifferentUser to prevent timeout on buildbot\n\n*   Fix typo in TestBindMounts (runContainer called without image)\n\n*   Improve TestGetContainersTop so it does not rely on sleep\n*   Relax the lo interface test to allow iface index != 1\n*   Add registry functional test to docker-ci\n*   Add some tests in server and utils\n\n### [Other](#other-12)\n\n*   Contrib: bash completion script\n*   Client: Add docker cp command and copy api endpoint to copy container files/folders to the host\n*   Don't read from stdout when only attached to stdin\n\n### [Runtime](#runtime-51)\n\n*   Use docker group for socket permissions\n\n*   Spawn shell within upstart script\n*   Handle ip route showing mask-less IP addresses\n*   Add hostname to environment\n\n### [Builder](#builder-23)\n\n*   Make sure ENV instruction within build perform a commit each time\n\n*   Builder: Forbid certain paths within docker build ADD\n\n*   Runtime: Change network range to avoid conflict with EC2 DNS\n\n*   API: Change daemon to listen on unix socket by default\n\n### [Runtime](#runtime-52)\n\n*   Add `ps` args to `docker top`\n*   Add support for container ID files (pidfile like)\n*   Add container=lxc in default env\n*   Support networkless containers with `docker run -n` and `docker -d -b=none`\n\n*   Stdout/stderr logs are now stored in the same file as JSON\n*   Allocate a /16 IP range by default, with fallback to /24. Try 12 ranges instead of 3.\n*   Change .dockercfg format to json and support multiple auth remote\n\n*   Do not override volumes from config\n*   Fix issue with EXPOSE override\n\n### [API](#api)\n\n*   Docker client now sets useragent (RFC 2616)\n*   Add /events endpoint\n\n### [Builder](#builder-24)\n\n*   ADD command now understands URLs\n*   CmdAdd and CmdEnv now respect Dockerfile-set ENV variables\n\n*   Create directories with 755 instead of 700 within ADD instruction\n\n### [Hack](#hack-8)\n\n*   Simplify unit tests with helpers\n*   Improve docker.upstart event\n*   Add coverage testing into docker-ci\n\n### [Runtime](#runtime-53)\n\n*   List all processes running inside a container with 'docker top'\n*   Host directories can be mounted as volumes with 'docker run -v'\n*   Containers can expose public UDP ports (eg, '-p 123/udp')\n*   Optionally specify an exact public port (eg. '-p 80:4500')\n\n*   'docker login' supports additional options\n\n*   Don't save a container's hostname when committing an image.\n\n### [Registry](#registry-5)\n\n*   New image naming scheme inspired by Go packaging convention allows arbitrary combinations of registries\n\n*   Fix issues when uploading images to a private registry\n\n### [Builder](#builder-25)\n\n*   ENTRYPOINT instruction sets a default binary entry point to a container\n*   VOLUME instruction marks a part of the container as persistent data\n\n*   'docker build' displays the full output of a build by default\n\n*   Builder: New build operation ENTRYPOINT adds an executable entry point to the container. - Runtime: Fix a bug which caused 'docker run -d' to no longer print the container ID.\n\n*   Tests: Fix issues in the test suite\n\n### [Remote API](#remote-api-8)\n\n*   The progress bar updates faster when downloading and uploading large files\n\n*   Fix a bug in the optional unix socket transport\n\n### [Runtime](#runtime-54)\n\n*   Improve detection of kernel version\n\n*   Host directories can be mounted as volumes with 'docker run -b'\n\n*   fix an issue when only attaching to stdin\n\n*   Use 'tar --numeric-owner' to avoid uid mismatch across multiple hosts\n\n### [Hack](#hack-9)\n\n*   Improve test suite and dev environment\n*   Remove dependency on unit tests on 'os/user'\n\n### [Other](#other-13)\n\n*   Registry: easier push/pull to a custom registry\n\n*   Documentation: add terminology section\n\n*   Runtime: fix a bug which caused creation of empty images (and volumes) to crash.\n\n*   Builder: 'docker build git://URL' fetches and builds a remote git repository\n\n*   Runtime: 'docker ps -s' optionally prints container size\n*   Tests: improved and simplified\n\n*   Runtime: fix a regression introduced in 0.4.3 which caused the logs command to fail.\n*   Builder: fix a regression when using ADD with single regular file.\n\n*   Builder: fix a regression introduced in 0.4.3 which caused builds to fail on new clients.\n\n### [Builder](#builder-26)\n\n*   ADD of a local file will detect tar archives and unpack them\n\n*   ADD improvements: use tar for copy + automatically unpack local archives\n*   ADD uses tar/untar for copies instead of calling 'cp -ar'\n*   Fix the behavior of ADD to be (mostly) reverse-compatible, predictable and well-documented.\n\n*   Fix a bug which caused builds to fail if ADD was the first command\n\n*   Nicer output for 'docker build'\n\n### [Runtime](#runtime-55)\n\n*   Remove bsdtar dependency\n*   Add unix socket and multiple -H support\n*   Prevent rm of running containers\n*   Use go1.1 cookiejar\n\n*   Fix issue detaching from running TTY container\n*   Forbid parallel push/pull for a single image/repo. Fixes `#311`\n*   Fix race condition within Run command when attaching.\n\n### [Client](#client-15)\n\n*   HumanReadable ProgressBar sizes in pull\n*   Fix docker version's git commit output\n\n### [API](#api-1)\n\n*   Send all tags on History API call\n*   Add tag lookup to history command. Fixes #882\n\n### [Documentation](#documentation-13)\n\n*   Fix missing command in irc bouncer example\n\n*   Packaging: Bumped version to work around an Ubuntu bug\n\n### [Remote Api](#remote-api-9)\n\n*   Add flag to enable cross domain requests\n*   Add images and containers sizes in docker ps and docker images\n\n### [Runtime](#runtime-56)\n\n*   Configure dns configuration host-wide with 'docker -d -dns'\n*   Detect faulty DNS configuration and replace it with a public default\n*   Allow docker run :\n*   You can now specify public port (ex: -p 80:4500)\n\n*   Improve image removal to garbage-collect unreferenced parents\n\n### [Client](#client-16)\n\n*   Allow multiple params in inspect\n*   Print the container id before the hijack in `docker run`\n\n### [Registry](#registry-6)\n\n*   Add regexp check on repo's name\n*   Move auth to the client\n\n*   Remove login check on pull\n\n### [Other](#other-14)\n\n*   Vagrantfile: Add the rest api port to vagrantfile's port\\_forward\n*   Upgrade to Go 1.1\n\n*   Builder: don`t ignore last line in Dockerfile when it doesn`t end with \\\\n\n\n### [Builder](#builder-27)\n\n*   Introducing Builder\n*   'docker build' builds a container, layer by layer, from a source repository containing a Dockerfile\n\n### [Remote API](#remote-api-10)\n\n*   Introducing Remote API\n*   control Docker programmatically using a simple HTTP/json API\n\n### [Runtime](#runtime-57)\n\n*   Various reliability and usability improvements\n\n### [Builder](#builder-28)\n\n*   'docker build' builds a container, layer by layer, from a source repository containing a Dockerfile\n*   'docker build -t FOO' applies the tag FOO to the newly built container.\n\n### [Runtime](#runtime-58)\n\n*   Interactive TTYs correctly handle window resize\n\n*   Fix how configuration is merged between layers\n\n### [Remote API](#remote-api-11)\n\n*   Split stdout and stderr on 'docker run'\n*   Optionally listen on a different IP and port (use at your own risk)\n\n### [Documentation](#documentation-14)\n\n*   Improve install instructions.\n\n*   Registry: Fix push regression\n*   Various bugfixes\n\n### [Registry](#registry-7)\n\n*   Improve the checksum process\n*   Use the size to have a good progress bar while pushing\n*   Use the actual archive if it exists in order to speed up the push\n\n*   Fix error 400 on push\n\n### [Runtime](#runtime-59)\n\n*   Store the actual archive on commit\n\n### [Builder](#builder-29)\n\n*   Implement the autorun capability within docker builder\n*   Add caching to docker builder\n*   Add support for docker builder with native API as top level command\n*   Implement ENV within docker builder\n\n*   Check the command existence prior create and add Unit tests for the case\n\n*   use any whitespaces instead of tabs\n\n### [Runtime](#runtime-60)\n\n*   Add go version to debug infos\n\n*   Kernel version - don't show the dash if flavor is empty\n\n### [Registry](#registry-8)\n\n*   Add docker search top level command in order to search a repository\n\n*   Fix pull for official images with specific tag\n*   Fix issue when login in with a different user and trying to push\n\n*   Improve checksum - async calculation\n\n### [Images](#images)\n\n*   Output graph of images to dot (graphviz)\n\n*   Fix ByParent function\n\n### [Documentation](#documentation-15)\n\n*   New introduction and high-level overview\n*   Add the documentation for docker builder\n\n*   CSS fix for docker documentation to make REST API docs look better.\n*   Fix CouchDB example page header mistake\n*   Fix README formatting\n\n*   Update [www.docker.io](https://www.docker.io/) website.\n\n### [Other](#other-15)\n\n*   Website: new high-level overview\n\n*   Makefile: Swap \"go get\" for \"go get -d\", especially to compile on go1.1rc\n\n*   Packaging: packaging ubuntu; issue #510: Use golang-stable PPA package to build docker\n\n### [Runtime](#runtime-61)\n\n*   Fix the command existence check\n*   strings.Split may return an empty string on no match\n*   Fix an index out of range crash if cgroup memory is not\n\n### [Documentation](#documentation-16)\n\n*   Various improvements\n\n*   New example: sharing data between 2 couchdb databases\n\n### [Other](#other-16)\n\n*   Vagrant: Use only one deb line in /etc/apt\n\n*   Registry: Implement the new registry\n\n*   Support for data volumes ('docker run -v=PATH')\n*   Share data volumes between containers ('docker run -volumes-from')\n*   Improve documentation\n\n*   Upgrade to Go 1.0.3\n*   Various upgrades to the dev environment for contributors\n\n*   'docker commit -run' bundles a layer with default runtime options: command, ports etc.\n\n*   Improve install process on Vagrant\n\n*   New Dockerfile operation: \"maintainer\"\n*   New Dockerfile operation: \"expose\"\n*   New Dockerfile operation: \"cmd\"\n*   Contrib script to build a Debian base layer\n*   'docker -d -r': restart crashed containers at daemon startup\n\n*   Runtime: improve test coverage\n\n*   Runtime: ghost containers can be killed and waited for\n\n*   Documentation: update install instructions\n\n*   Packaging: fix Vagrantfile\n*   Development: automate releasing binaries and ubuntu packages\n\n*   Add a changelog\n\n*   Various bugfixes\n\n*   Dynamically detect cgroup capabilities\n*   Issue stability warning on kernels <3.8\n*   'docker push' buffers on disk instead of memory\n*   Fix 'docker diff' for removed files\n*   Fix 'docker stop' for ghost containers\n*   Fix handling of pidfile\n*   Various bugfixes and stability improvements\n\n*   Container ports are available on localhost\n*   'docker ps' shows allocated TCP ports\n*   Contributors can run 'make hack' to start a continuous integration VM\n*   Streamline ubuntu packaging & uploading\n*   Various bugfixes and stability improvements\n\n*   Record the author an image with 'docker commit -author'\n\n*   Disable standalone mode\n*   Use a custom DNS resolver with 'docker -d -dns'\n*   Detect ghost containers\n*   Improve diagnosis of missing system capabilities\n*   Allow disabling memory limits at compile time\n*   Add debian packaging\n*   Documentation: installing on Arch Linux\n*   Documentation: running Redis on docker\n*   Fix lxc 0.9 compatibility\n*   Automatically load aufs module\n*   Various bugfixes and stability improvements\n\n*   Full support for TTY emulation\n*   Detach from a TTY session with the escape sequence `C-p C-q`\n*   Various bugfixes and stability improvements\n*   Minor UI improvements\n*   Automatically create our own bridge interface 'docker0'\n\n*   Choose TCP frontend port with '-p :PORT'\n*   Layer format is versioned\n*   Major reliability improvements to the process manager\n*   Various bugfixes and stability improvements\n\n*   Set container hostname with 'docker run -h'\n*   Selective attach at run with 'docker run -a \\[stdin\\[,stdout\\[,stderr\\]\\]\\]'\n*   Various bugfixes and stability improvements\n*   UI polish\n*   Progress bar on push/pull\n*   Use XZ compression by default\n*   Make IP allocator lazy\n\n*   Display shorthand IDs for convenience\n*   Stabilize process management\n*   Layers can include a commit message\n*   Simplified 'docker attach'\n*   Fix support for re-attaching\n*   Various bugfixes and stability improvements\n*   Auto-download at run\n*   Auto-login on push\n*   Beefed up documentation\n\nInitial public release\n\n*   Implement registry in order to push/pull images\n*   TCP port allocation\n*   Fix termcaps on Linux\n*   Add documentation\n*   Add Vagrant support with Vagrantfile\n*   Add unit tests\n*   Add repository/tags to ease image management\n*   Improve the layer implementation",
  "title": "Docker Engine release notes | Docker Docs\n",
  "description": "Release notes for Docker CE",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/building/best-practices/",
  "markdown": "# Building best practices | Docker Docs\n\nMulti-stage builds let you reduce the size of your final image, by creating a cleaner separation between the building of your image and the final output. Split your Dockerfile instructions into distinct stages to make sure that the resulting output only contains the files that's needed to run the application.\n\nUsing multiple stages can also let you build more efficiently by executing build steps in parallel.\n\nSee [Multi-stage builds](https://docs.docker.com/build/building/multi-stage/) for more information.\n\n### [Create reusable stages](#create-reusable-stages)\n\nIf you have multiple images with a lot in common, consider creating a reusable stage that includes the shared components, and basing your unique stages on that. Docker only needs to build the common stage once. This means that your derivative images use memory on the Docker host more efficiently and load more quickly.\n\nIt's also easier to maintain a common base stage (\"Don't repeat yourself\"), than it is to have multiple different stages doing similar things.\n\nThe first step towards achieving a secure image is to choose the right base image. When choosing an image, ensure it's built from a trusted source and keep it small.\n\n*   [Docker Official Images](https://hub.docker.com/search?image_filter=official) are some of the most secure and dependable images on Docker Hub. Typically, Docker Official images have few or no packages containing CVEs, and are thoroughly reviewed by Docker and project maintainers.\n    \n*   [Verified Publisher](https://hub.docker.com/search?image_filter=store) images are high-quality images published and maintained by the organizations partnering with Docker, with Docker verifying the authenticity of the content in their repositories.\n    \n*   [Docker-Sponsored Open Source](https://hub.docker.com/search?image_filter=open_source) are published and maintained by open source projects sponsored by Docker through an [open source program](https://docs.docker.com/trusted-content/dsos-program/).\n    \n\nWhen you pick your base image, look out for the badges indicating that the image is part of these programs.\n\n![Docker Hub Official and Verified Publisher images](https://docs.docker.com/build/images/hub-official-images.webp)\n\nWhen building your own image from a Dockerfile, ensure you choose a minimal base image that matches your requirements. A smaller base image not only offers portability and fast downloads, but also shrinks the size of your image and minimizes the number of vulnerabilities introduced through the dependencies.\n\nYou should also consider using two types of base image: one for building and unit testing, and another (typically slimmer) image for production. In the later stages of development, your image may not require build tools such as compilers, build systems, and debugging tools. A small image with minimal dependencies can considerably lower the attack surface.\n\nDocker images are immutable. Building an image is taking a snapshot of that image at that moment. That includes any base images, libraries, or other software you use in your build. To keep your images up-to-date and secure, make sure to rebuild your image often, with updated dependencies.\n\nTo ensure that you're getting the latest versions of dependencies in your build, you can use the `--no-cache` option to avoid cache hits.\n\nThe following Dockerfile uses the `24.04` tag of the `ubuntu` image. Over time, that tag may resolve to a different underlying version of the `ubuntu` image, as the publisher rebuilds the image with new security patches and updated libraries. Using the `--no-cache`, you can avoid cache hits and ensure a fresh download of base images and dependencies.\n\nAlso consider [pinning base image versions](#pin-base-image-versions).\n\nTo exclude files not relevant to the build, without restructuring your source repository, use a `.dockerignore` file. This file supports exclusion patterns similar to `.gitignore` files.\n\nFor example, to exclude all files with the `.md` extension:\n\nFor information on creating one, see [Dockerignore file](https://docs.docker.com/build/building/context/#dockerignore-files).\n\nThe image defined by your Dockerfile should generate containers that are as ephemeral as possible. Ephemeral means that the container can be stopped and destroyed, then rebuilt and replaced with an absolute minimum set up and configuration.\n\nRefer to [Processes](https://12factor.net/processes) under _The Twelve-factor App_ methodology to get a feel for the motivations of running containers in such a stateless fashion.\n\nAvoid installing extra or unnecessary packages just because they might be nice to have. For example, you donâ€™t need to include a text editor in a database image.\n\nWhen you avoid installing extra or unnecessary packages, your images have reduced complexity, reduced dependencies, reduced file sizes, and reduced build times.\n\nEach container should have only one concern. Decoupling applications into multiple containers makes it easier to scale horizontally and reuse containers. For instance, a web application stack might consist of three separate containers, each with its own unique image, to manage the web application, database, and an in-memory cache in a decoupled manner.\n\nLimiting each container to one process is a good rule of thumb, but it's not a hard and fast rule. For example, not only can containers be [spawned with an init process](https://docs.docker.com/engine/reference/run/#specify-an-init-process), some programs might spawn additional processes of their own accord. For instance, [Celery](https://docs.celeryproject.org/) can spawn multiple worker processes, and [Apache](https://httpd.apache.org/) can create one process per request.\n\nUse your best judgment to keep containers as clean and modular as possible. If containers depend on each other, you can use [Docker container networks](https://docs.docker.com/network/) to ensure that these containers can communicate.\n\nWhenever possible, sort multi-line arguments alphanumerically to make maintenance easier. This helps to avoid duplication of packages and make the list much easier to update. This also makes PRs a lot easier to read and review. Adding a space before a backslash (`\\`) helps as well.\n\nHereâ€™s an example from the [buildpack-deps image](https://github.com/docker-library/buildpack-deps):\n\nWhen building an image, Docker steps through the instructions in your Dockerfile, executing each in the order specified. For each instruction, Docker checks whether it can reuse the instruction from the build cache.\n\nUnderstanding how the build cache works, and how cache invalidation occurs, is critical for ensuring faster builds. For more information about the Docker build cache and how to optimize your builds, see [Docker build cache](https://docs.docker.com/build/cache/).\n\nImage tags are mutable, meaning a publisher can update a tag to point to a new image. This is useful because it lets publishers update tags to point to newer versions of an image. And as an image consumer, it means you automatically get the new version when you re-build your image.\n\nFor example, if you specify `FROM alpine:3.19` in your Dockerfile, `3.19` resolves to the latest patch version for `3.19`.\n\nAt one point in time, the `3.19` tag might point to version 3.19.1 of the image. If you rebuild the image 3 months later, the same tag might point to a different version, such as 3.19.4. This publishing workflow is best practice, and most publishers use this tagging strategy, but it isn't enforced.\n\nThe downside with this is that you're not guaranteed to get the same for every build. This could result in breaking changes, and it means you also don't have an audit trail of the exact image versions that you're using.\n\nTo fully secure your supply chain integrity, you can pin the image version to a specific digest. By pinning your images to a digest, you're guaranteed to always use the same image version, even if a publisher replaces the tag with a new image. For example, the following Dockerfile pins the Alpine image to the same tag as earlier, `3.19`, but this time with a digest reference as well.\n\nWith this Dockerfile, even if the publisher updates the `3.19` tag, your builds would still use the pinned image version: `13b7e62e8df80264dbb747995705a986aa530415763a6c58f84a3ca8af9a5bcd`.\n\nWhile this helps you avoid unexpected changes, it's also more tedious to have to look up and include the image digest for base image versions manually each time you want to update it. And you're opting out of automated security fixes, which is likely something you want to get.\n\nDocker Scout has a built-in [**Outdated base images** policy](https://docs.docker.com/scout/policy/#outdated-base-images) that checks for whether the base image version you're using is in fact the latest version. This policy also checks if pinned digests in your Dockerfile correspond to the correct version. If a publisher updates an image that you've pinned, the policy evaluation returns a non-compliant status, indicating that you should update your image.\n\nDocker Scout also supports an automated remediation workflow for keeping your base images up-to-date. When a new image digest is available, Docker Scout can automatically raise a pull request on your repository to update your Dockerfiles to use the latest version. This is better than using a tag that changes the version automatically, because you're in control and you have an audit trail of when and how the change occurred.\n\nFor more information about automatically updating your base images with Docker Scout, see [Remediation](https://docs.docker.com/scout/policy/remediation/#automatic-base-image-updates)\n\nWhen you check in a change to source control or create a pull request, use [GitHub Actions](https://docs.docker.com/build/ci/github-actions/) or another CI/CD pipeline to automatically build and tag a Docker image and test it.\n\nFollow these recommendations on how to properly use the [Dockerfile instructions](https://docs.docker.com/reference/dockerfile/) to create an efficient and maintainable Dockerfile.\n\n### [FROM](#from)\n\nWhenever possible, use current official images as the basis for your images. Docker recommends the [Alpine image](https://hub.docker.com/_/alpine/) as it is tightly controlled and small in size (currently under 6 MB), while still being a full Linux distribution.\n\nFor more information about the `FROM` instruction, see [Dockerfile reference for the FROM instruction](https://docs.docker.com/reference/dockerfile/#from).\n\n### [LABEL](#label)\n\nYou can add labels to your image to help organize images by project, record licensing information, to aid in automation, or for other reasons. For each label, add a line beginning with `LABEL` with one or more key-value pairs. The following examples show the different acceptable formats. Explanatory comments are included inline.\n\nStrings with spaces must be quoted or the spaces must be escaped. Inner quote characters (`\"`), must also be escaped. For example:\n\nAn image can have more than one label. Prior to Docker 1.10, it was recommended to combine all labels into a single `LABEL` instruction, to prevent extra layers from being created. This is no longer necessary, but combining labels is still supported. For example:\n\nThe above example can also be written as:\n\nSee [Understanding object labels](https://docs.docker.com/config/labels-custom-metadata/) for guidelines about acceptable label keys and values. For information about querying labels, refer to the items related to filtering in [Managing labels on objects](https://docs.docker.com/config/labels-custom-metadata/#manage-labels-on-objects). See also [LABEL](https://docs.docker.com/reference/dockerfile/#label) in the Dockerfile reference.\n\n### [RUN](#run)\n\nSplit long or complex `RUN` statements on multiple lines separated with backslashes to make your Dockerfile more readable, understandable, and maintainable.\n\nFor example, you can chain commands with the `&&` operator, and use use escape characters to break long commands into multiple lines.\n\nBy default, backslash escapes a newline character, but you can change it with the [`escape` directive](https://docs.docker.com/reference/dockerfile/#escape).\n\nYou can also use here documents to run multiple commands without chaining them with a pipeline operator:\n\nFor more information about `RUN`, see [Dockerfile reference for the RUN instruction](https://docs.docker.com/reference/dockerfile/#run).\n\n#### [apt-get](#apt-get)\n\nOne common use case for `RUN` instructions in Debian-based images is to install software using `apt-get`. Because `apt-get` installs packages, the `RUN apt-get` command has several counter-intuitive behaviors to look out for.\n\nAlways combine `RUN apt-get update` with `apt-get install` in the same `RUN` statement. For example:\n\nUsing `apt-get update` alone in a `RUN` statement causes caching issues and subsequent `apt-get install` instructions to fail. For example, this issue will occur in the following Dockerfile:\n\nAfter building the image, all layers are in the Docker cache. Suppose you later modify `apt-get install` by adding an extra package as shown in the following Dockerfile:\n\nDocker sees the initial and modified instructions as identical and reuses the cache from previous steps. As a result the `apt-get update` isn't executed because the build uses the cached version. Because the `apt-get update` isn't run, your build can potentially get an outdated version of the `curl` and `nginx` packages.\n\nUsing `RUN apt-get update && apt-get install -y` ensures your Dockerfile installs the latest package versions with no further coding or manual intervention. This technique is known as cache busting. You can also achieve cache busting by specifying a package version. This is known as version pinning. For example:\n\nVersion pinning forces the build to retrieve a particular version regardless of whatâ€™s in the cache. This technique can also reduce failures due to unanticipated changes in required packages.\n\nBelow is a well-formed `RUN` instruction that demonstrates all the `apt-get` recommendations.\n\nThe `s3cmd` argument specifies a version `1.1.*`. If the image previously used an older version, specifying the new one causes a cache bust of `apt-get update` and ensures the installation of the new version. Listing packages on each line can also prevent mistakes in package duplication.\n\nIn addition, when you clean up the apt cache by removing `/var/lib/apt/lists` it reduces the image size, since the apt cache isn't stored in a layer. Since the `RUN` statement starts with `apt-get update`, the package cache is always refreshed prior to `apt-get install`.\n\nOfficial Debian and Ubuntu images [automatically run `apt-get clean`](https://github.com/moby/moby/blob/03e2923e42446dbb830c654d0eec323a0b4ef02a/contrib/mkimage/debootstrap#L82-L105), so explicit invocation is not required.\n\n#### [Using pipes](#using-pipes)\n\nSome `RUN` commands depend on the ability to pipe the output of one command into another, using the pipe character (`|`), as in the following example:\n\nDocker executes these commands using the `/bin/sh -c` interpreter, which only evaluates the exit code of the last operation in the pipe to determine success. In the example above, this build step succeeds and produces a new image so long as the `wc -l` command succeeds, even if the `wget` command fails.\n\nIf you want the command to fail due to an error at any stage in the pipe, prepend `set -o pipefail &&` to ensure that an unexpected error prevents the build from inadvertently succeeding. For example:\n\n> **Note**\n> \n> Not all shells support the `-o pipefail` option.\n> \n> In cases such as the `dash` shell on Debian-based images, consider using the _exec_ form of `RUN` to explicitly choose a shell that does support the `pipefail` option. For example:\n\n### [CMD](#cmd)\n\nThe `CMD` instruction should be used to run the software contained in your image, along with any arguments. `CMD` should almost always be used in the form of `CMD [\"executable\", \"param1\", \"param2\"]`. Thus, if the image is for a service, such as Apache and Rails, you would run something like `CMD [\"apache2\",\"-DFOREGROUND\"]`. Indeed, this form of the instruction is recommended for any service-based image.\n\nIn most other cases, `CMD` should be given an interactive shell, such as bash, python and perl. For example, `CMD [\"perl\", \"-de0\"]`, `CMD [\"python\"]`, or `CMD [\"php\", \"-a\"]`. Using this form means that when you execute something like `docker run -it python`, youâ€™ll get dropped into a usable shell, ready to go. `CMD` should rarely be used in the manner of `CMD [\"param\", \"param\"]` in conjunction with [`ENTRYPOINT`](https://docs.docker.com/reference/dockerfile/#entrypoint), unless you and your expected users are already quite familiar with how `ENTRYPOINT` works.\n\nFor more information about `CMD`, see [Dockerfile reference for the CMD instruction](https://docs.docker.com/reference/dockerfile/#cmd).\n\n### [EXPOSE](#expose)\n\nThe `EXPOSE` instruction indicates the ports on which a container listens for connections. Consequently, you should use the common, traditional port for your application. For example, an image containing the Apache web server would use `EXPOSE 80`, while an image containing MongoDB would use `EXPOSE 27017` and so on.\n\nFor external access, your users can execute `docker run` with a flag indicating how to map the specified port to the port of their choice. For container linking, Docker provides environment variables for the path from the recipient container back to the source (for example, `MYSQL_PORT_3306_TCP`).\n\nFor more information about `EXPOSE`, see [Dockerfile reference for the EXPOSE instruction](https://docs.docker.com/reference/dockerfile/#expose).\n\n### [ENV](#env)\n\nTo make new software easier to run, you can use `ENV` to update the `PATH` environment variable for the software your container installs. For example, `ENV PATH=/usr/local/nginx/bin:$PATH` ensures that `CMD [\"nginx\"]` just works.\n\nThe `ENV` instruction is also useful for providing the required environment variables specific to services you want to containerize, such as Postgresâ€™s `PGDATA`.\n\nLastly, `ENV` can also be used to set commonly used version numbers so that version bumps are easier to maintain, as seen in the following example:\n\nSimilar to having constant variables in a program, as opposed to hard-coding values, this approach lets you change a single `ENV` instruction to automatically bump the version of the software in your container.\n\nEach `ENV` line creates a new intermediate layer, just like `RUN` commands. This means that even if you unset the environment variable in a future layer, it still persists in this layer and its value can be dumped. You can test this by creating a Dockerfile like the following, and then building it.\n\nTo prevent this, and really unset the environment variable, use a `RUN` command with shell commands, to set, use, and unset the variable all in a single layer. You can separate your commands with `;` or `&&`. If you use the second method, and one of the commands fails, the `docker build` also fails. This is usually a good idea. Using `\\` as a line continuation character for Linux Dockerfiles improves readability. You could also put all of the commands into a shell script and have the `RUN` command just run that shell script.\n\nFor more information about `ENV`, see [Dockerfile reference for the ENV instruction](https://docs.docker.com/reference/dockerfile/#env).\n\n### [ADD or COPY](#add-or-copy)\n\n`ADD` and `COPY` are functionally similar. `COPY` supports basic copying of files into the container, from the [build context](https://docs.docker.com/build/building/context/) or from a stage in a [multi-stage build](https://docs.docker.com/build/building/multi-stage/). `ADD` supports features for fetching files from remote HTTPS and Git URLs, and extracting tar files automatically when adding files from the build context.\n\nYou'll mostly want to use `COPY` for copying files from one stage to another in a multi-stage build. If you need to add files from the build context to the container temporarily to execute a `RUN` instruction, you can often substitute the `COPY` instruction with a bind mount instead. For example, to temporarily add a `requirements.txt` file for a `RUN pip install` instruction:\n\nBind mounts are more efficient than `COPY` for including files from the build context in the container. Note that bind-mounted files are only added temporarily for a single `RUN` instruction, and don't persist in the final image. If you need to include files from the build context in the final image, use `COPY`.\n\nThe `ADD` instruction is best for when you need to download a remote artifact as part of your build. `ADD` is better than manually adding files using something like `wget` and `tar`, because it ensures a more precise build cache. `ADD` also has built-in support for checksum validation of the remote resources, and a protocol for parsing branches, tags, and subdirectories from [Git URLs](https://docs.docker.com/reference/cli/docker/image/build/#git-repositories).\n\nThe following example uses `ADD` to download a .NET installer. Combined with multi-stage builds, only the .NET runtime remains in the final stage, no intermediate files.\n\nFor more information about `ADD` or `COPY`, see the following:\n\n*   [Dockerfile reference for the ADD instruction](https://docs.docker.com/reference/dockerfile/#add)\n*   [Dockerfile reference for the COPY instruction](https://docs.docker.com/reference/dockerfile/#copy)\n\n### [ENTRYPOINT](#entrypoint)\n\nThe best use for `ENTRYPOINT` is to set the image's main command, allowing that image to be run as though it was that command, and then use `CMD` as the default flags.\n\nThe following is an example of an image for the command line tool `s3cmd`:\n\nYou can use the following command to run the image and show the command's help:\n\nOr, you can use the right parameters to execute a command, like in the following example:\n\nThis is useful because the image name can double as a reference to the binary as shown in the command above.\n\nThe `ENTRYPOINT` instruction can also be used in combination with a helper script, allowing it to function in a similar way to the command above, even when starting the tool may require more than one step.\n\nFor example, the [Postgres Official Image](https://hub.docker.com/_/postgres/) uses the following script as its `ENTRYPOINT`:\n\nThis script uses [the `exec` Bash command](https://wiki.bash-hackers.org/commands/builtin/exec) so that the final running application becomes the container's PID 1. This allows the application to receive any Unix signals sent to the container. For more information, see the [`ENTRYPOINT` reference](https://docs.docker.com/reference/dockerfile/#entrypoint).\n\nIn the following example, a helper script is copied into the container and run via `ENTRYPOINT` on container start:\n\nThis script lets you interact with Postgres in several ways.\n\nIt can simply start Postgres:\n\nOr, you can use it to run Postgres and pass parameters to the server:\n\nLastly, you can use it to start a totally different tool, such as Bash:\n\nFor more information about `ENTRYPOINT`, see [Dockerfile reference for the ENTRYPOINT instruction](https://docs.docker.com/reference/dockerfile/#entrypoint).\n\n### [VOLUME](#volume)\n\nYou should use the `VOLUME` instruction to expose any database storage area, configuration storage, or files and folders created by your Docker container. You are strongly encouraged to use `VOLUME` for any combination of mutable or user-serviceable parts of your image.\n\nFor more information about `VOLUME`, see [Dockerfile reference for the VOLUME instruction](https://docs.docker.com/reference/dockerfile/#volume).\n\n### [USER](#user)\n\nIf a service can run without privileges, use `USER` to change to a non-root user. Start by creating the user and group in the Dockerfile with something like the following example:\n\n> **Note**\n> \n> Consider an explicit UID/GID.\n> \n> Users and groups in an image are assigned a non-deterministic UID/GID in that the \"next\" UID/GID is assigned regardless of image rebuilds. So, if itâ€™s critical, you should assign an explicit UID/GID.\n\n> **Note**\n> \n> Due to an [unresolved bug](https://github.com/golang/go/issues/13548) in the Go archive/tar package's handling of sparse files, attempting to create a user with a significantly large UID inside a Docker container can lead to disk exhaustion because `/var/log/faillog` in the container layer is filled with NULL (\\\\0) characters. A workaround is to pass the `--no-log-init` flag to useradd. The Debian/Ubuntu `adduser` wrapper does not support this flag.\n\nAvoid installing or using `sudo` as it has unpredictable TTY and signal-forwarding behavior that can cause problems. If you absolutely need functionality similar to `sudo`, such as initializing the daemon as `root` but running it as non-`root`, consider using [â€œgosuâ€](https://github.com/tianon/gosu).\n\nLastly, to reduce layers and complexity, avoid switching `USER` back and forth frequently.\n\nFor more information about `USER`, see [Dockerfile reference for the USER instruction](https://docs.docker.com/reference/dockerfile/#user).\n\n### [WORKDIR](#workdir)\n\nFor clarity and reliability, you should always use absolute paths for your `WORKDIR`. Also, you should use `WORKDIR` instead of proliferating instructions like `RUN cd â€¦ && do-something`, which are hard to read, troubleshoot, and maintain.\n\nFor more information about `WORKDIR`, see [Dockerfile reference for the WORKDIR instruction](https://docs.docker.com/reference/dockerfile/#workdir).\n\n### [ONBUILD](#onbuild)\n\nAn `ONBUILD` command executes after the current Dockerfile build completes. `ONBUILD` executes in any child image derived `FROM` the current image. Think of the `ONBUILD` command as an instruction that the parent Dockerfile gives to the child Dockerfile.\n\nA Docker build executes `ONBUILD` commands before any command in a child Dockerfile.\n\n`ONBUILD` is useful for images that are going to be built `FROM` a given image. For example, you would use `ONBUILD` for a language stack image that builds arbitrary user software written in that language within the Dockerfile, as you can see in [Rubyâ€™s `ONBUILD` variants](https://github.com/docker-library/ruby/blob/c43fef8a60cea31eb9e7d960a076d633cb62ba8d/2.4/jessie/onbuild/Dockerfile).\n\nImages built with `ONBUILD` should get a separate tag. For example, `ruby:1.9-onbuild` or `ruby:2.0-onbuild`.\n\nBe careful when putting `ADD` or `COPY` in `ONBUILD`. The onbuild image fails catastrophically if the new build's context is missing the resource being added. Adding a separate tag, as recommended above, helps mitigate this by allowing the Dockerfile author to make a choice.\n\nFor more information about `ONBUILD`, see [Dockerfile reference for the ONBUILD instruction](https://docs.docker.com/reference/dockerfile/#onbuild).",
  "title": "Building best practices | Docker Docs\n",
  "description": "Hints, tips and guidelines for writing clean, reliable Dockerfiles",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/building/multi-platform/",
  "markdown": "# Multi-platform images | Docker Docs\n\nA multi-platform image refers to a single image that includes variants for multiple different architectures and, in some cases, different operating systems, like Windows. This means that whether you are using an ARM-based system or an x86 machine, Docker automatically detects and selects the appropriate variant for your hosts's operating system and architecture.\n\nMany of the Docker Official Images available on Docker Hub support various architectures. For instance, the `busybox` image includes support for these platforms:\n\n*   x86-64 (`linux/amd64`, `linux/i386`)\n*   ARM architectures (`linux/arm/v5`, `linux/arm/v6`, `linux/arm/v7`, `linux/arm64`)\n*   PowerPC and IBM Z (`linux/ppc64le`, `linux/s390x`)\n\nOn an x86 machine, Docker will automatically use the `linux/amd64` variant when you run a container or invoke a build.\n\nMost Docker images use the `linux/` OS prefix to indicate they are Linux-based. While Docker Desktop on macOS or Windows typically runs Linux containers using a Linux VM, Docker also supports Windows containers if you're operating in Windows container mode.\n\nWhen triggering a build, use the `--platform` flag to define the target platforms for the build output, such as `linux/amd64` and `linux/arm64`:\n\nBy default, Docker can build for only one platform at a time. To build for multiple platforms concurrently, you can:\n\n*   **Enable the containerd image store**: The default image store in Docker Engine doesn't support multi-platform images. The containerd image store does, and lets you create multi-platform images using the default builder. Refer to the [containerd in Docker Desktop documentation](https://docs.docker.com/desktop/containerd/).\n    \n*   **Create a custom builder**: Initialize a [builder](https://docs.docker.com/build/builders/) that uses the `docker-container` driver, which supports multi-platform builds. For more details, see the [`docker-container` driver documentation](https://docs.docker.com/build/drivers/docker-container/).\n    \n\nYou can build multi-platform images using three different strategies, depending on your use case:\n\n1.  Using emulation, via [QEMU](#qemu) support in the Linux kernel\n2.  Building on a single builder backed by [multiple nodes of different architectures](#multiple-native-nodes).\n3.  Using a stage in your Dockerfile to [cross-compile](#cross-compilation) to different architectures\n\n### [QEMU](#qemu)\n\nBuilding multi-platform images under emulation with QEMU is the easiest way to get started if your builder already supports it. Docker Desktop supports it out of the box. It requires no changes to your Dockerfile, and BuildKit automatically detects the secondary architectures that are available. When BuildKit needs to run a binary for a different architecture, it automatically loads it through a binary registered in the `binfmt_misc` handler.\n\n> **Note**\n> \n> Emulation with QEMU can be much slower than native builds, especially for compute-heavy tasks like compilation and compression or decompression.\n> \n> Use [multiple native nodes](#multiple-native-nodes) or [cross-compilation](#cross-compilation) instead, if possible.\n\n#### [Support on Docker Desktop](#support-on-docker-desktop)\n\n[Docker Desktop](https://docs.docker.com/desktop/) provides support for running and building multi-platform images under emulation by default, which means you can run containers for different Linux architectures such as `arm`, `mips`, `ppc64le`, and even `s390x`.\n\nThis doesn't require any special configuration in the container itself as it uses QEMU bundled within the Docker Desktop VM. Because of this, you can run containers of non-native architectures like the `arm32v7` or `ppc64le` automatically.\n\n#### [QEMU without Docker Desktop](#qemu-without-docker-desktop)\n\nIf you're running Docker Engine on Linux, without Docker Desktop, you must install statically compiled QEMU binaries and register them with [`binfmt_misc`](https://en.wikipedia.org/wiki/Binfmt_misc). This enables QEMU to execute non-native file formats for emulation. The QEMU binaries must be statically compiled and registered with the `fix_binary` flag. This requires a kernel version 4.8 or later, and `binfmt-support` version 2.1.7 or later.\n\nOnce QEMU is installed and the executable types are registered on the host OS, they work transparently inside containers. You can verify your registration by checking if `F` is among the flags in `/proc/sys/fs/binfmt_misc/qemu-*`. While Docker Desktop comes preconfigured with `binfmt_misc` support for additional platforms, for other installations it likely needs to be installed using [`tonistiigi/binfmt`](https://github.com/tonistiigi/binfmt) image:\n\n### [Multiple native nodes](#multiple-native-nodes)\n\nUsing multiple native nodes provide better support for more complicated cases that QEMU can't handle, and also provides better performance.\n\nYou can add additional nodes to a builder using the `--append` flag.\n\nThe following command creates a multi-node builder from Docker contexts named `node-amd64` and `node-arm64`. This example assumes that you've already added those contexts.\n\nWhile this approach has advantages over emulation, managing multi-node builders introduces some overhead of setting up and managing builder clusters. Alternatively, you can use Docker Build Cloud, a service that provides managed multi-node builders on Docker's infrastructure. With Docker Build Cloud, you get native multi-platform ARM and X86 builders without the burden of maintaining them. Using cloud builders also provides additional benefits, such as a shared build cache.\n\nAfter signing up for Docker Build Cloud, add the builder to your local environment and start building.\n\nFor more information, see [Docker Build Cloud](https://docs.docker.com/build-cloud/).\n\n### [Cross-compilation](#cross-compilation)\n\nDepending on your project, if the programming language you use has good support for cross-compilation, you can leverage multi-stage builds to build binaries for target platforms from the native architecture of the builder. Special build arguments, such as `BUILDPLATFORM` and `TARGETPLATFORM`, are automatically available for use in your Dockerfile.\n\nIn the following example, the `FROM` instruction is pinned to the native platform of the builder (using the `--platform=$BUILDPLATFORM` option) to prevent emulation from kicking in. Then the pre-defined `$BUILDPLATFORM` and `$TARGETPLATFORM` build arguments are interpolated in a `RUN` instruction. In this case, the values are just printed to stdout with `echo`, but this illustrates how you would pass them to the compiler for cross-compilation.\n\nRun the [`docker buildx ls` command](https://docs.docker.com/reference/cli/docker/buildx/ls/) to list the existing builders:\n\nThis displays the default builtin driver, that uses the BuildKit server components built directly into the Docker Engine, also known as the [`docker` driver](https://docs.docker.com/build/drivers/docker/).\n\nCreate a new builder using the [`docker-container` driver](https://docs.docker.com/build/drivers/docker-container/) which gives you access to more complex features like multi-platform builds and the more advanced cache exporters, which are currently unsupported in the default `docker` driver:\n\nNow listing the existing builders again, you can see that the new builder is registered:\n\nTest the workflow to ensure you can build, push, and run multi-platform images. Create a simple example Dockerfile, build a couple of image variants, and push them to Docker Hub.\n\nThe following example uses a single `Dockerfile` to build an Alpine image with cURL installed for multiple architectures:\n\nBuild the Dockerfile with buildx, passing the list of architectures to build for:\n\n> **Note**\n> \n> *   `<username>` must be a valid Docker ID and `<image>` and valid repository on Docker Hub.\n> *   The `--platform` flag informs buildx to create Linux images for x86 64-bit, ARM 64-bit, and ARMv7 architectures.\n> *   The `--push` flag generates a multi-arch manifest and pushes all the images to Docker Hub.\n\nInspect the image using [`docker buildx imagetools` command](https://docs.docker.com/reference/cli/docker/buildx/imagetools/):\n\nThe image is now available on Docker Hub with the tag `<username>/<image>:latest`. You can use this image to run a container on Intel laptops, Amazon EC2 Graviton instances, Raspberry Pis, and on other architectures. Docker pulls the correct image for the current architecture, so Raspberry PIs run the 32-bit ARM version and EC2 Graviton instances run 64-bit ARM.\n\nThe digest identifies a fully qualified image variant. You can also run images targeted for a different architecture on Docker Desktop. For example, when you run the following on a macOS:\n\nIn the previous example, `uname -m` returns `aarch64` and `armv7l` as expected, even when running the commands on a native macOS or Windows developer machine.",
  "title": "Multi-platform images | Docker Docs\n",
  "description": "Introduction to multi-platform images and how to build them",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/building/multi-stage/",
  "markdown": "# Multi-stage builds | Docker Docs\n\nMulti-stage builds are useful to anyone who has struggled to optimize Dockerfiles while keeping them easy to read and maintain.\n\nWith multi-stage builds, you use multiple `FROM` statements in your Dockerfile. Each `FROM` instruction can use a different base, and each of them begins a new stage of the build. You can selectively copy artifacts from one stage to another, leaving behind everything you don't want in the final image.\n\nThe following Dockerfile has two separate stages: one for building a binary, and another where the binary gets copied from the first stage into the next stage.\n\nYou only need the single Dockerfile. No need for a separate build script. Just run `docker build`.\n\nThe end result is a tiny production image with nothing but the binary inside. None of the build tools required to build the application are included in the resulting image.\n\nHow does it work? The second `FROM` instruction starts a new build stage with the `scratch` image as its base. The `COPY --from=0` line copies just the built artifact from the previous stage into this new stage. The Go SDK and any intermediate artifacts are left behind, and not saved in the final image.\n\nBy default, the stages aren't named, and you refer to them by their integer number, starting with 0 for the first `FROM` instruction. However, you can name your stages, by adding an `AS <NAME>` to the `FROM` instruction. This example improves the previous one by naming the stages and using the name in the `COPY` instruction. This means that even if the instructions in your Dockerfile are re-ordered later, the `COPY` doesn't break.\n\nWhen you build your image, you don't necessarily need to build the entire Dockerfile including every stage. You can specify a target build stage. The following command assumes you are using the previous `Dockerfile` but stops at the stage named `build`:\n\nA few scenarios where this might be useful are:\n\n*   Debugging a specific build stage\n*   Using a `debug` stage with all debugging symbols or tools enabled, and a lean `production` stage\n*   Using a `testing` stage in which your app gets populated with test data, but building for production using a different stage which uses real data\n\nWhen using multi-stage builds, you aren't limited to copying from stages you created earlier in your Dockerfile. You can use the `COPY --from` instruction to copy from a separate image, either using the local image name, a tag available locally or on a Docker registry, or a tag ID. The Docker client pulls the image if necessary and copies the artifact from there. The syntax is:\n\nYou can pick up where a previous stage left off by referring to it when using the `FROM` directive. For example:\n\nThe legacy Docker Engine builder processes all stages of a Dockerfile leading up to the selected `--target`. It will build a stage even if the selected target doesn't depend on that stage.\n\n[BuildKit](https://docs.docker.com/build/buildkit/) only builds the stages that the target stage depends on.\n\nFor example, given the following Dockerfile:\n\nWith [BuildKit enabled](https://docs.docker.com/build/buildkit/#getting-started), building the `stage2` target in this Dockerfile means only `base` and `stage2` are processed. There is no dependency on `stage1`, so it's skipped.\n\nOn the other hand, building the same target without BuildKit results in all stages being processed:\n\nThe legacy builder processes `stage1`, even if `stage2` doesn't depend on it.",
  "title": "Multi-stage builds | Docker Docs\n",
  "description": "Learn about multi-stage builds and how you can use them to improve your builds and get smaller images ",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/building/secrets/",
  "markdown": "# Build secrets | Docker Docs\n\nA build secret is any piece of sensitive information, such as a password or API token, consumed as part of your application's build process.\n\nBuild arguments and environment variables are inappropriate for passing secrets to your build, because they persist in the final image. Instead, you should use secret mounts or SSH mounts, which expose secrets to your builds securely.\n\nSecret mounts expose secrets to the build containers as files. You [mount the secrets to the `RUN` instructions](https://docs.docker.com/reference/dockerfile/#run---mounttypesecret) that need to access them, similar to how you would define a bind mount or cache mount.\n\nTo pass a secret to a build, use the [`docker build --secret` flag](https://docs.docker.com/reference/cli/docker/buildx/build/#secret), or the equivalent options for [Bake](https://docs.docker.com/build/bake/reference/#targetsecret).\n\n### [Sources](#sources)\n\nThe source of a secret can be either a [file](https://docs.docker.com/reference/cli/docker/buildx/build/#file) or an [environment variable](https://docs.docker.com/reference/cli/docker/buildx/build/#env). When you use the CLI or Bake, the type can be detected automatically. You can also specify it explicitly with `type=file` or `type=env`.\n\nThe following example mounts the environment variable `KUBECONFIG` to secret ID `kube`, as a file in the build container at `/run/secrets/kube`.\n\nWhen you use secrets from environment variables, you can omit the `env` parameter to bind the secret to a file with the same name as the variable. In the following example, the value of the `API_TOKEN` variable is mounted to `/run/secrets/API_TOKEN` in the build container.\n\n### [Target](#target)\n\nBy default, secrets are mounted to `/run/secrets/<id>`. You can customize the mount point in the build container using the `target` option in the Dockerfile.\n\nThe following example mounts the secret to a `/root/.aws/credentials` file in the build container.\n\nIf the credential you want to use in your build is an SSH agent socket or key, you can use the SSH mount instead of a secret mount. Cloning private Git repositories is a common use case for SSH mounts.\n\nThe following example clones a private GitHub repository using a [Dockerfile SSH mount](https://docs.docker.com/reference/dockerfile/#run---mounttypessh).\n\nTo pass an SSH socket the build, you use the [`docker build --ssh` flag](https://docs.docker.com/reference/cli/docker/buildx/build/#ssh), or equivalent options for [Bake](https://docs.docker.com/build/bake/reference/#targetssh).\n\n## [Git authentication for remote contexts](#git-authentication-for-remote-contexts)\n\nBuildKit supports two pre-defined build secrets, `GIT_AUTH_TOKEN` and `GIT_AUTH_HEADER`. Use them to specify HTTP authentication parameters when building with remote, private Git repositories, including:\n\n*   Building with a private Git repository as build context\n*   Fetching private Git repositories in a build with `ADD`\n\nFor example, say you have a private GitLab project at `https://gitlab.com/example/todo-app.git`, and you want to run a build using that repository as the build context. An unauthenticated `docker build` command fails because the builder isn't authorized to pull the repository:\n\nTo authenticate the builder to the Git server, set the `GIT_AUTH_TOKEN` environment variable to contain a valid GitLab access token, and pass it as a secret to the build:\n\nThe `GIT_AUTH_TOKEN` also works with `ADD` to fetch private Git repositories as part of your build:\n\n### [HTTP authentication scheme](#http-authentication-scheme)\n\nBy default, Git authentication over HTTP uses the Bearer authentication scheme:\n\nIf you need to use a Basic scheme, with a username and password, you can set the `GIT_AUTH_HEADER` build secret:\n\nBuildKit currently only supports the Bearer and Basic schemes.\n\n### [Multiple hosts](#multiple-hosts)\n\nYou can set the `GIT_AUTH_TOKEN` and `GIT_AUTH_HEADER` secrets on a per-host basis, which lets you use different authentication parameters for different hostnames. To specify a hostname, append the hostname as a suffix to the secret ID:",
  "title": "Build secrets | Docker Docs\n",
  "description": "Manage credentials and other secrets securely",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/building/annotations/",
  "markdown": "# Annotations | Docker Docs\n\nAnnotations provide descriptive metadata for images. Use annotations to record arbitrary information and attach it to your image, which helps consumers and tools understand the origin, contents, and how to use the image.\n\nAnnotations are similar to, and in some sense overlap with, [labels](https://docs.docker.com/config/labels-custom-metadata/). Both serve the same purpose: attach metadata to a resource. As a general principle, you can think of the difference between annotations and labels as follows:\n\n*   Annotations describe OCI image components, such as [manifests](https://github.com/opencontainers/image-spec/blob/main/manifest.md), [indexes](https://github.com/opencontainers/image-spec/blob/main/image-index.md), and [descriptors](https://github.com/opencontainers/image-spec/blob/main/descriptor.md).\n*   Labels describe Docker resources, such as images, containers, networks, and volumes.\n\nThe OCI image [specification](https://github.com/opencontainers/image-spec/blob/main/annotations.md) defines the format of annotations, as well as a set of pre-defined annotation keys. Adhering to the specified standards ensures that metadata about images can be surfaced automatically and consistently, by tools like Docker Scout.\n\nAnnotations are not to be confused with [attestations](https://docs.docker.com/build/attestations/):\n\n*   Attestations contain information about how an image was built and what it contains. An attestation is attached as a separate manifest on the image index. Attestations are not standardized by the Open Container Initiative.\n*   Annotations contain arbitrary metadata about an image. Annotations attach to the image [config](https://github.com/opencontainers/image-spec/blob/main/config.md) as labels, or on the image index or manifest as properties.\n\nYou can add annotations to an image at build-time, or when creating the image manifest or index.\n\n> **Note**\n> \n> The Docker Engine image store doesn't support loading images with annotations. To build with annotations, make sure to push the image directly to a registry, using the `--push` CLI flag or the [registry exporter](https://docs.docker.com/build/exporters/image-registry/).\n\nTo specify annotations on the command line, use the `--annotation` flag for the `docker build` command:\n\nIf you're using [Bake](https://docs.docker.com/build/bake/), you can use the `annotations` attribute to specify annotations for a given target:\n\nFor examples on how to add annotations to images built with GitHub Actions, see [Add image annotations with GitHub Actions](https://docs.docker.com/build/ci/github-actions/annotations/)\n\nYou can also add annotations to an image created using `docker buildx imagetools create`. This command only supports adding annotations to an index or manifest descriptors, see [CLI reference](https://docs.docker.com/reference/cli/docker/buildx/imagetools/create/#annotations).\n\nTo view annotations on an **image index**, use the `docker buildx imagetools inspect` command. This shows you any annotations for the index and descriptors (references to manifests) that the index contains. The following example shows an `org.opencontainers.image.documentation` annotation on a descriptor, and an `org.opencontainers.image.authors` annotation on the index.\n\nTo inspect annotations on a manifest, use the `docker buildx imagetools inspect` command and specify `<IMAGE>@<DIGEST>`, where `<DIGEST>` is the digest of the manifest:\n\nBy default, annotations are added to the image manifest. You can specify which level(s) to attach the manifest to, by prefixing the annotation string with a special type declaration:\n\n*   `manifest`: annotates manifests.\n*   `index`: annotates the root index.\n*   `manifest-descriptor`: annotates manifest descriptors in the index.\n*   `index-descriptor`: annotates the index descriptor in the image layout.\n\nFor example, to build an image with the annotation `foo=bar` attached to the image index:\n\nIt's possible to specify types, separated by a comma, to add the annotation to more than one level. The following example creates an image with the annotation `foo=bar` on both the image index and the image manifest:\n\nYou can also specify a platform qualifier in the type prefix, to annotate only components matching specific OS and architectures. The following example adds the `foo=bar` annotation only to the `linux/amd64` manifest:\n\nRelated articles:\n\n*   [Add image annotations with GitHub Actions](https://docs.docker.com/build/ci/github-actions/annotations/)\n*   [Annotations OCI specification](https://github.com/opencontainers/image-spec/blob/main/annotations.md)\n\nReference information:\n\n*   [`docker buildx build --annotation`](https://docs.docker.com/reference/cli/docker/buildx/build/#annotation)\n*   [Bake file reference: `annotations`](https://docs.docker.com/build/bake/reference/#targetannotations)\n*   [`docker buildx imagetools create --annotation`](https://docs.docker.com/reference/cli/docker/buildx/imagetools/create/#annotation)",
  "title": "Annotations | Docker Docs\n",
  "description": "Annotations specify additional metadata about OCI images",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/building/opentelemetry/",
  "markdown": "# OpenTelemetry support | Docker Docs\n\nBoth Buildx and BuildKit support [OpenTelemetry](https://opentelemetry.io/).\n\nTo capture the trace to [Jaeger](https://github.com/jaegertracing/jaeger), set `JAEGER_TRACE` environment variable to the collection address using a `driver-opt`.\n\nFirst create a Jaeger container:\n\nThen [create a `docker-container` builder](https://docs.docker.com/build/drivers/docker-container/) that will use the Jaeger instance via the `JAEGER_TRACE` env var:\n\nBoot and [inspect `mybuilder`](https://docs.docker.com/reference/cli/docker/buildx/inspect/):\n\nBuildx commands should be traced at `http://127.0.0.1:16686/`:\n\n![OpenTelemetry Buildx Bake](https://docs.docker.com/build/images/opentelemetry.png)",
  "title": "OpenTelemetry support | Docker Docs\n",
  "description": "Analyze telemetry data for builds",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/bake/funcs/",
  "markdown": "# HCL functions | Docker Docs\n\nHCL functions are great for when you need to manipulate values in your build configuration in more complex ways than just concatenation or interpolation.\n\nBake ships with built-in support for the [`go-cty` standard library functions](https://github.com/zclconf/go-cty/tree/main/cty/function/stdlib). The following example shows the `add` function.\n\nYou can create [user-defined functions](https://github.com/hashicorp/hcl/tree/main/ext/userfunc) that do just what you want, if the built-in standard library functions don't meet your needs.\n\nThe following example defines an `increment` function.\n\nYou can make references to [variables](https://docs.docker.com/build/bake/variables/) and standard library functions inside your functions.\n\nYou can't reference user-defined functions from other functions.\n\nThe following example uses a global variable (`REPO`) in a custom function.\n\nPrinting the Bake file with the `--print` flag shows that the `tag` function uses the value of `REPO` to set the prefix of the tag.",
  "title": "HCL functions | Docker Docs\n",
  "description": "Learn about built-in and user-defined HCL functions with Bake",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/bake/targets/",
  "markdown": "# Bake targets | Docker Docs\n\nA target in a Bake file represents a build invocation. It holds all the information you would normally pass to a `docker build` command using flags.\n\nTo build a target with Bake, pass name of the target to the `bake` command.\n\nYou can build multiple targets at once by passing multiple target names to the `bake` command.\n\nIf you don't specify a target when running `docker buildx bake`, Bake will build the target named `default`.\n\nTo build this target, run `docker buildx bake` without any arguments:\n\nThe properties you can set for a target closely resemble the CLI flags for `docker build`, with a few additional properties that are specific to Bake.\n\nFor all the properties you can set for a target, see the [Bake reference](https://docs.docker.com/build/bake/reference#target).\n\nYou can group targets together using the `group` block. This is useful when you want to build multiple targets at once.\n\nTo build all the targets in a group, pass the name of the group to the `bake` command.\n\nRefer to the following pages to learn more about Bake's features:\n\n*   Learn how to use [variables](https://docs.docker.com/build/bake/variables/) in Bake to make your build configuration more flexible.\n*   Learn how you can use matrices to build multiple images with different configurations in [Matrices](https://docs.docker.com/build/bake/matrices/).\n*   Head to the [Bake file reference](https://docs.docker.com/build/bake/reference/) to learn about all the properties you can set in a Bake file, and its syntax.",
  "title": "Bake targets | Docker Docs\n",
  "description": "Learn how to define and use targets in Bake",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/bake/contexts/",
  "markdown": "# Using Bake with additional contexts\n\nIn addition to the main `context` key that defines the build context, each target can also define additional named contexts with a map defined with key `contexts`. These values map to the `--build-context` flag in the [build command](https://docs.docker.com/reference/cli/docker/buildx/build/#build-context).\n\nInside the Dockerfile these contexts can be used with the `FROM` instruction or `--from` flag.\n\nSupported context values are:\n\n*   Local filesystem directories\n*   Container images\n*   Git URLs\n*   HTTP URLs\n*   Name of another target in the Bake file\n\n## [Using a target as a build context](#using-a-target-as-a-build-context)\n\nTo use a result of one target as a build context of another, specify the target name with `target:` prefix.\n\nIn most cases you should just use a single multi-stage Dockerfile with multiple targets for similar behavior. This case is only recommended when you have multiple Dockerfiles that can't be easily merged into one.\n\n## [Deduplicate context transfer](#deduplicate-context-transfer)\n\nWhen you build targets concurrently, using groups, build contexts are loaded independently for each target. If the same context is used by multiple targets in a group, that context is transferred once for each time it's used. This can result in significant impact on build time, depending on your build configuration. For example, say you have a Bake file that defines the following group of targets:\n\nIn this case, the context `.` is transferred twice when you build the default group: once for `target1` and once for `target2`.\n\nIf your context is small, and if you are using a local builder, duplicate context transfers may not be a big deal. But if your build context is big, or you have a large number of targets, or you're transferring the context over a network to a remote builder, context transfer becomes a performance bottleneck.\n\nTo avoid transferring the same context multiple times, you can define a named context that only loads the context files, and have each target that needs those files reference that named context. For example, the following Bake file defines a named target `ctx`, which is used by both `target1` and `target2`:\n\nThe named context `ctx` represents a Dockerfile stage, which copies the files from its context (`.`). Other stages in the Dockerfile can now reference the `ctx` named context and, for example, mount its files with `--mount=from=ctx`.",
  "title": "Using Bake with additional contexts | Docker Docs\n",
  "description": "Additional contexts are useful when you want to pin image versions, or reference the output of other targets ",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/bake/expressions/",
  "markdown": "# Expression evaluation in Bake | Docker Docs\n\nBake files in the HCL format support expression evaluation, which lets you perform arithmetic operations, conditionally set values, and more.\n\nYou can perform arithmetic operations in expressions. The following example shows how to multiply two numbers.\n\nPrinting the Bake file with the `--print` flag shows the evaluated value for the `answer` build argument.\n\nYou can use ternary operators to conditionally register a value.\n\nThe following example adds a tag only when a variable is not empty, using the built-in `notequal` [function](https://docs.docker.com/build/bake/funcs/).\n\nIn this case, `TAG` is an empty string, so the resulting build configuration only contains the hard-coded `my-image:latest` tag.\n\nYou can use expressions with [variables](https://docs.docker.com/build/bake/variables/) to conditionally set values, or to perform arithmetic operations.\n\nThe following example uses expressions to set values based on the value of variables. The `v1` build argument is set to \"higher\" if the variable `FOO` is greater than 5, otherwise it is set to \"lower\". The `v2` build argument is set to \"yes\" if the `IS_FOO` variable is true, otherwise it is set to \"no\".\n\nPrinting the Bake file with the `--print` flag shows the evaluated values for the `v1` and `v2` build arguments.",
  "title": "Expression evaluation in Bake | Docker Docs\n",
  "description": "Learn about advanced Bake features, like user-defined functions",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/bake/variables/",
  "markdown": "# Variables in Bake | Docker Docs\n\nYou can define and use variables in a Bake file to set attribute values, interpolate them into other values, and perform arithmetic operations. Variables can be defined with default values, and can be overridden with environment variables.\n\nUse the `variable` block to define a variable.\n\nThe following example shows how to use the `TAG` variable in a target.\n\nBake supports string interpolation of variables into values. You can use the `${}` syntax to interpolate a variable into a value. The following example defines a `TAG` variable with a value of `latest`.\n\nTo interpolate the `TAG` variable into the value of an attribute, use the `${TAG}` syntax.\n\nPrinting the Bake file with the `--print` flag shows the interpolated value in the resolved build configuration.\n\nWhen multiple files are specified, one file can use variables defined in another file. In the following example, the `vars.hcl` file defines a `BASE_IMAGE` variable with a default value of `docker.io/library/alpine`.\n\nThe following `docker-bake.hcl` file defines a `BASE_LATEST` variable that references the `BASE_IMAGE` variable.\n\nWhen you print the resolved build configuration, using the `-f` flag to specify the `vars.hcl` and `docker-bake.hcl` files, you see that the `BASE_LATEST` variable is resolved to `docker.io/library/alpine:latest`.\n\nHere are some additional resources that show how you can use variables in Bake:\n\n*   You can override `variable` values using environment variables. See [Overriding configurations](https://docs.docker.com/build/bake/overrides/#environment-variables) for more information.\n*   You can refer to and use global variables in functions. See [HCL functions](https://docs.docker.com/build/bake/funcs/#variables-in-functions)\n*   You can use variable values when evaluating expressions. See [Expression evaluation](https://docs.docker.com/build/bake/expressions/#expressions-with-variables)",
  "title": "Variables in Bake | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/bake/matrices/",
  "markdown": "# Matrix targets | Docker Docs\n\nA matrix strategy lets you fork a single target into multiple different variants, based on parameters that you specify. This works in a similar way to [Matrix strategies for GitHub Actions](https://docs.github.com/en/actions/using-jobs/using-a-matrix-for-your-jobs). You can use this to reduce duplication in your Bake definition.\n\nThe matrix attribute is a map of parameter names to lists of values. Bake builds each possible combination of values as a separate target.\n\nEach generated target must have a unique name. To specify how target names should resolve, use the name attribute.\n\nThe following example resolves the app target to `app-foo` and `app-bar`. It also uses the matrix value to define the [target build stage](https://docs.docker.com/build/bake/reference/#targettarget).\n\nYou can specify multiple keys in your matrix to fork a target on multiple axes. When using multiple matrix keys, Bake builds every possible variant.\n\nThe following example builds four targets:\n\n*   `app-foo-1-0`\n*   `app-foo-2-0`\n*   `app-bar-1-0`\n*   `app-bar-2-0`\n\nIf you want to differentiate the matrix on more than just a single value, you can use maps as matrix values. Bake creates a target for each map, and you can access the nested values using dot notation.\n\nThe following example builds two targets:\n\n*   `app-foo-1-0`\n*   `app-bar-2-0`",
  "title": "Matrix targets | Docker Docs\n",
  "description": "Learn how to define and use matrix targets in Bake to fork a single target into multiple different variants",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/bake/inheritance/",
  "markdown": "# Inheritance in Bake | Docker Docs\n\nTargets can inherit attributes from other targets, using the `inherits` attribute. For example, imagine that you have a target that builds a Docker image for a development environment:\n\nYou can create a new target that uses the same build configuration, but with slightly different attributes for a production build. In this example, the `app-release` target inherits the `app-dev` target, but overrides the `tags` attribute and adds a new `platforms` attribute:\n\nOne common inheritance pattern is to define a common target that contains shared attributes for all or many of the build targets in the project. For example, the following `_common` target defines a common set of build arguments:\n\nYou can then inherit the `_common` target in other targets to apply the shared attributes:\n\nWhen a target inherits another target, it can override any of the inherited attributes. For example, the following target overrides the `args` attribute from the inherited target:\n\nThe `GO_VERSION` argument in `app-release` is set to `1.17`, overriding the `GO_VERSION` argument from the `app-dev` target.\n\nFor more information about overriding attributes, see the [Overriding configurations](https://docs.docker.com/build/bake/overrides/) page.\n\nThe `inherits` attribute is a list, meaning you can reuse attributes from multiple other targets. In the following example, the app-release target reuses attributes from both the `app-dev` and `_common` targets.\n\nWhen inheriting attributes from multiple targets and there's a conflict, the target that appears last in the inherits list takes precedence. The previous example defines the `BUILDKIT_CONTEXT_KEEP_GIT_DIR` in the `_common` target and overrides it in the `app-dev` target.\n\nThe `app-release` target inherits both `app-dev` target and the `_common` target. The `BUILDKIT_CONTEXT_KEEP_GIT_DIR` argument is set to 0 in the `app-dev` target and 1 in the `_common` target. The `BUILDKIT_CONTEXT_KEEP_GIT_DIR` argument in the `app-release` target is set to 1, not 0, because the `_common` target appears last in the inherits list.\n\nIf you only want to inherit a single attribute from a target, you can reference an attribute from another target using dot notation. For example, in the following Bake file, the `bar` target reuses the `tags` attribute from the `foo` target:",
  "title": "Inheritance in Bake | Docker Docs\n",
  "description": "Learn how to inherit attributes from other targets in Bake",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/bake/overrides/",
  "markdown": "# Overriding configurations | Docker Docs\n\nBake supports loading build definitions from files, but sometimes you need even more flexibility to configure these definitions. For example, you might want to override an attribute when building in a particular environment or for a specific target.\n\nThe following list of attributes can be overridden:\n\n*   `args`\n*   `cache-from`\n*   `cache-to`\n*   `context`\n*   `dockerfile`\n*   `labels`\n*   `no-cache`\n*   `output`\n*   `platform`\n*   `pull`\n*   `secrets`\n*   `ssh`\n*   `tags`\n*   `target`\n\nTo override these attributes, you can use the following methods:\n\n*   [File overrides](#file-overrides)\n*   [CLI overrides](#command-line)\n*   [Environment variable overrides](#environment-variables)\n\nYou can load multiple Bake files that define build configurations for your targets. This is useful when you want to separate configurations into different files for better organization, or to conditionally override configurations based on which files are loaded.\n\n### [Default file lookup](#default-file-lookup)\n\nYou can use the `--file` or `-f` flag to specify which files to load. If you don't specify any files, Bake will use the following lookup order:\n\n1.  `compose.yaml`\n2.  `compose.yml`\n3.  `docker-compose.yml`\n4.  `docker-compose.yaml`\n5.  `docker-bake.json`\n6.  `docker-bake.override.json`\n7.  `docker-bake.hcl`\n8.  `docker-bake.override.hcl`\n\nIf more than one Bake file is found, all files are loaded and merged into a single definition. Files are merged according to the lookup order.\n\nIf merged files contain duplicate attribute definitions, those definitions are either merged or overridden by the last occurrence, depending on the attribute.\n\nBake will attempt to load all of the files in the order they are found. If multiple files define the same target, attributes are either merged or overridden. In the case of overrides, the last one loaded takes precedence.\n\nFor example, given the following files:\n\nSince `docker-bake.override.hcl` is loaded last in the default lookup order, the `TAG` variable is overridden with the value `bar`.\n\n### [Manual file overrides](#manual-file-overrides)\n\nYou can use the `--file` flag to explicitly specify which files to load, and use this as a way to conditionally apply override files.\n\nFor example, you can create a file that defines a set of configurations for a specific environment, and load it only when building for that environment. The following example shows how to load an `override.hcl` file that sets the `TAG` variable to `bar`. The `TAG` variable is then used in the `default` target.\n\nPrinting the build configuration without the `--file` flag shows the `TAG` variable is set to the default value `foo`.\n\nUsing the `--file` flag to load the `overrides.hcl` file overrides the `TAG` variable with the value `bar`.\n\nYou can also override target configurations from the command line with the [`--set` flag](https://docs.docker.com/reference/cli/docker/buildx/bake/#set):\n\nPattern matching syntax defined in [https://golang.org/pkg/path/#Match](https://golang.org/pkg/path/#Match) is also supported:\n\nComplete list of attributes that can be overridden with `--set` are:\n\n*   `args`\n*   `cache-from`\n*   `cache-to`\n*   `context`\n*   `dockerfile`\n*   `labels`\n*   `no-cache`\n*   `output`\n*   `platform`\n*   `pull`\n*   `secrets`\n*   `ssh`\n*   `tags`\n*   `target`\n\nYou can also use environment variables to override configurations.\n\nBake lets you use environment variables to override the value of a `variable` block. Only `variable` blocks can be overridden with environment variables. This means you need to define the variables in the bake file and then set the environment variable with the same name to override it.\n\nThe following example shows how you can define a `TAG` variable with a default value in the Bake file, and override it with an environment variable.\n\nThe `TAG` variable is overridden with the value of the environment variable, which is the short commit hash generated by `git rev-parse --short HEAD`.\n\n### [Type coercion](#type-coercion)\n\nOverriding non-string variables with environment variables is supported. Values passed as environment variables are coerced into suitable types first.\n\nThe following example defines a `PORT` variable with a default value of `8080`. The `default` target uses a [ternary operator](https://docs.docker.com/build/bake/expressions/#ternary-operators) to set the `PORT` variable to the value of the environment variable `PORT` if it is greater than `1024`, otherwise it uses the default value.\n\nIn this case, the `PORT` variable is coerced to an integer before the ternary operator is evaluated.\n\nAttempting to set the `PORT` variable with a value less than `1024` will result in the default value being used.",
  "title": "Overriding configurations | Docker Docs\n",
  "description": "Learn how to override configurations in Bake files to build with different attributes.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/attestations/",
  "markdown": "# Build attestations | Docker Docs\n\nBuild attestations describe how an image was built, and what it contains. The attestations are created at build-time by BuildKit, and become attached to the final image as metadata.\n\nThe purpose of attestations is to make it possible to inspect an image and see where it comes from, who created it and how, and what it contains. This enables you to make informed decisions about how an image impacts the supply chain security of your application. It also enables the use of policy engines for validating images based on policy rules you've defined.\n\nTwo types of build annotations are available:\n\n*   Software Bill of Material (SBOM): list of software artifacts that an image contains, or that were used to build the image.\n*   Provenance: how an image was built.\n\nThe use of open source and third-party packages is more widespread than ever before. Developers share and reuse code because it helps increase productivity, allowing teams to create better products, faster.\n\nImporting and using code created elsewhere without vetting it introduces a severe security risk. Even if you do review the software that you consume, new zero-day vulnerabilities are frequently discovered, requiring development teams take action to remediate them.\n\nBuild attestations make it easier to see the contents of an image, and where it comes from. Use attestations to analyze and decide whether to use an image, or to see if images you are already using are exposed to vulnerabilities.\n\nWhen you build an image with `docker buildx build`, you can add attestation records to the resulting image using the `--provenance` and `--sbom` options. You can opt in to add either the SBOM or provenance attestation type, or both.\n\n> **Note**\n> \n> The default image store doesn't support attestations. If you're using the default image store and you build an image using the default `docker` driver, or using a different driver with the `--load` flag, the attestations are lost.\n> \n> To make sure the attestations are preserved, you can:\n> \n> *   Use a `docker-container` driver with the `--push` flag to push the image to a registry directly.\n> *   Enable the [containerd image store](https://docs.docker.com/desktop/containerd/).\n\n> **Note**\n> \n> Provenance attestations are enabled by default, with the `mode=min` option. You can disable provenance attestations using the `--provenance=false` flag, or by setting the [`BUILDX_NO_DEFAULT_ATTESTATIONS`](https://docs.docker.com/build/building/variables/#buildx_no_default_attestations) environment variable.\n> \n> Using the `--provenance=true` flag attaches provenance attestations with `mode=max` by default. See [Provenance attestation](https://docs.docker.com/build/attestations/slsa-provenance/) for more details.\n\nBuildKit generates the attestations when building the image. The attestation records are wrapped in the in-toto JSON format and attached to the image index in a manifest for the final image.\n\nBuildKit produces attestations in the [in-toto format](https://github.com/in-toto/attestation), as defined by the [in-toto framework](https://in-toto.io/), a standard supported by the Linux Foundation.\n\nAttestations attach to images as a manifest in the image index. The data records of the attestations are stored as JSON blobs.\n\nBecause attestations attach to images as a manifest, it means that you can inspect the attestations for any image in a registry without having to pull the whole image.\n\nAll BuildKit exporters support attestations. The `local` and `tar` can't save the attestations to an image manifest, since it's outputting a directory of files or a tarball, not an image. Instead, these exporters write the attestations to one or more JSON files in the root directory of the export.\n\nThe following example shows a truncated in-toto JSON representation of an SBOM attestation.\n\nTo deep-dive into the specifics about how attestations are stored, see [Image Attestation Storage (BuildKit)](https://docs.docker.com/build/attestations/attestation-storage/).\n\nLearn more about the available attestation types and how to use them:\n\n*   [Provenance](https://docs.docker.com/build/attestations/slsa-provenance/)\n*   [SBOM](https://docs.docker.com/build/attestations/sbom/)",
  "title": "Build attestations | Docker Docs\n",
  "description": "Introduction to SBOM and provenance attestations with Docker Build, what they are, and why they exist ",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/bake/compose-file/",
  "markdown": "# Building with Bake from a Compose file\n\n```\n{\n  \"group\": {\n    \"default\": {\n      \"targets\": [\"aws\", \"addon\"]\n    }\n  },\n  \"target\": {\n    \"addon\": {\n      \"context\": \".\",\n      \"dockerfile\": \"./Dockerfile\",\n      \"args\": {\n        \"CT_ECR\": \"foo\",\n        \"CT_TAG\": \"bar\"\n      },\n      \"tags\": [\"ct-addon:foo\", \"ct-addon:alp\"],\n      \"cache-from\": [\"user/app:cache\", \"type=local,src=path/to/cache\"],\n      \"cache-to\": [\"type=local,dest=path/to/cache\"],\n      \"platforms\": [\"linux/amd64\", \"linux/arm64\"],\n      \"pull\": true\n    },\n    \"aws\": {\n      \"context\": \".\",\n      \"dockerfile\": \"./aws.Dockerfile\",\n      \"args\": {\n        \"CT_ECR\": \"foo\",\n        \"CT_TAG\": \"bar\"\n      },\n      \"tags\": [\"ct-fake-aws:bar\"],\n      \"secret\": [\"id=mysecret,src=./secret\", \"id=mysecret2,src=./secret2\"],\n      \"platforms\": [\"linux/arm64\"],\n      \"output\": [\"type=docker\"],\n      \"no-cache\": true\n    }\n  }\n}\n```",
  "title": "Building with Bake from a Compose file | Docker Docs\n",
  "description": "Build your compose services with Bake",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/bake/reference/",
  "markdown": "# Bake file reference | Docker Docs\n\nThe Bake file is a file for defining workflows that you run using `docker buildx bake`.\n\nYou can define your Bake file in the following file formats:\n\n*   HashiCorp Configuration Language (HCL)\n*   JSON\n*   YAML (Compose file)\n\nBy default, Bake uses the following lookup order to find the configuration file:\n\n1.  `compose.yaml`\n2.  `compose.yml`\n3.  `docker-compose.yml`\n4.  `docker-compose.yaml`\n5.  `docker-bake.json`\n6.  `docker-bake.override.json`\n7.  `docker-bake.hcl`\n8.  `docker-bake.override.hcl`\n\nYou can specify the file location explicitly using the `--file` flag:\n\nIf you don't specify a file explicitly, Bake searches for the file in the current working directory. If more than one Bake file is found, all files are merged into a single definition. Files are merged according to the lookup order. That means that if your project contains both a `compose.yaml` file and a `docker-bake.hcl` file, Bake loads the `compose.yaml` file first, and then the `docker-bake.hcl` file.\n\nIf merged files contain duplicate attribute definitions, those definitions are either merged or overridden by the last occurrence, depending on the attribute. The following attributes are overridden by the last occurrence:\n\n*   `target.cache-to`\n*   `target.dockerfile-inline`\n*   `target.dockerfile`\n*   `target.outputs`\n*   `target.platforms`\n*   `target.pull`\n*   `target.tags`\n*   `target.target`\n\nFor example, if `compose.yaml` and `docker-bake.hcl` both define the `tags` attribute, the `docker-bake.hcl` is used.\n\nAll other attributes are merged. For example, if `compose.yaml` and `docker-bake.hcl` both define unique entries for the `labels` attribute, all entries are included. Duplicate entries for the same label are overridden.\n\nThe Bake file supports the following property types:\n\n*   `target`: build targets\n*   `group`: collections of build targets\n*   `variable`: build arguments and variables\n*   `function`: custom Bake functions\n\nYou define properties as hierarchical blocks in the Bake file. You can assign one or more attributes to a property.\n\nThe following snippet shows a JSON representation of a simple Bake file. This Bake file defines three properties: a variable, a group, and a target.\n\nIn the JSON representation of a Bake file, properties are objects, and attributes are values assigned to those objects.\n\nThe following example shows the same Bake file in the HCL format:\n\nHCL is the preferred format for Bake files. Aside from syntactic differences, HCL lets you use features that the JSON and YAML formats don't support.\n\nThe examples in this document use the HCL format.\n\nA target reflects a single `docker build` invocation. Consider the following build command:\n\nYou can express this command in a Bake file as follows:\n\nThe following table shows the complete list of attributes that you can assign to a target:\n\n| Name | Type | Description |\n| --- | --- | --- |\n| [`args`](#targetargs) | Map | Build arguments |\n| [`annotations`](#targetannotations) | List | Exporter annotations |\n| [`attest`](#targetattest) | List | Build attestations |\n| [`cache-from`](#targetcache-from) | List | External cache sources |\n| [`cache-to`](#targetcache-to) | List | External cache destinations |\n| [`context`](#targetcontext) | String | Set of files located in the specified path or URL |\n| [`contexts`](#targetcontexts) | Map | Additional build contexts |\n| [`dockerfile-inline`](#targetdockerfile-inline) | String | Inline Dockerfile string |\n| [`dockerfile`](#targetdockerfile) | String | Dockerfile location |\n| [`inherits`](#targetinherits) | List | Inherit attributes from other targets |\n| [`labels`](#targetlabels) | Map | Metadata for images |\n| [`matrix`](#targetmatrix) | Map | Define a set of variables that forks a target into multiple targets. |\n| [`name`](#targetname) | String | Override the target name when using a matrix. |\n| [`no-cache-filter`](#targetno-cache-filter) | List | Disable build cache for specific stages |\n| [`no-cache`](#targetno-cache) | Boolean | Disable build cache completely |\n| [`output`](#targetoutput) | List | Output destinations |\n| [`platforms`](#targetplatforms) | List | Target platforms |\n| [`pull`](#targetpull) | Boolean | Always pull images |\n| [`secret`](#targetsecret) | List | Secrets to expose to the build |\n| [`shm-size`](#targetshm-size) | List | Size of `/dev/shm` |\n| [`ssh`](#targetssh) | List | SSH agent sockets or keys to expose to the build |\n| [`tags`](#targettags) | List | Image names and tags |\n| [`target`](#targettarget) | String | Target build stage |\n| [`ulimits`](#targetulimits) | List | Ulimit options |\n\n### [`target.args`](#targetargs)\n\nUse the `args` attribute to define build arguments for the target. This has the same effect as passing a [`--build-arg`](https://docs.docker.com/reference/cli/docker/image/build/#build-arg) flag to the build command.\n\nYou can set `args` attributes to use `null` values. Doing so forces the `target` to use the `ARG` value specified in the Dockerfile.\n\n### [`target.annotations`](#targetannotations)\n\nThe `annotations` attribute lets you add annotations to images built with bake. The key takes a list of annotations, in the format of `KEY=VALUE`.\n\nis the same as\n\nBy default, the annotation is added to image manifests. You can configure the level of the annotations by adding a prefix to the annotation, containing a comma-separated list of all the levels that you want to annotate. The following example adds annotations to both the image index and manifests.\n\nRead about the supported levels in [Specifying annotation levels](https://docs.docker.com/build/building/annotations/#specifying-annotation-levels).\n\n### [`target.attest`](#targetattest)\n\nThe `attest` attribute lets you apply [build attestations](https://docs.docker.com/build/attestations/) to the target. This attribute accepts the long-form CSV version of attestation parameters.\n\n### [`target.cache-from`](#targetcache-from)\n\nBuild cache sources. The builder imports cache from the locations you specify. It uses the [Buildx cache storage backends](https://docs.docker.com/build/cache/backends/), and it works the same way as the [`--cache-from`](https://docs.docker.com/reference/cli/docker/buildx/build/#cache-from) flag. This takes a list value, so you can specify multiple cache sources.\n\n### [`target.cache-to`](#targetcache-to)\n\nBuild cache export destinations. The builder exports its build cache to the locations you specify. It uses the [Buildx cache storage backends](https://docs.docker.com/build/cache/backends/), and it works the same way as the [`--cache-to` flag](https://docs.docker.com/reference/cli/docker/buildx/build/#cache-to). This takes a list value, so you can specify multiple cache export targets.\n\n### [`target.context`](#targetcontext)\n\nSpecifies the location of the build context to use for this target. Accepts a URL or a directory path. This is the same as the [build context](https://docs.docker.com/reference/cli/docker/buildx/build/#build-context) positional argument that you pass to the build command.\n\nThis resolves to the current working directory (`\".\"`) by default.\n\n### [`target.contexts`](#targetcontexts)\n\nAdditional build contexts. This is the same as the [`--build-context` flag](https://docs.docker.com/reference/cli/docker/buildx/build/#build-context). This attribute takes a map, where keys result in named contexts that you can reference in your builds.\n\nYou can specify different types of contexts, such local directories, Git URLs, and even other Bake targets. Bake automatically determines the type of a context based on the pattern of the context value.\n\n| Context type | Example |\n| --- | --- |\n| Container image | `docker-image://alpine@sha256:0123456789` |\n| Git URL | `https://github.com/user/proj.git` |\n| HTTP URL | `https://example.com/files` |\n| Local directory | `../path/to/src` |\n| Bake target | `target:base` |\n\n#### [Pin an image version](#pin-an-image-version)\n\n#### [Use a local directory](#use-a-local-directory)\n\n#### [Use another target as base](#use-another-target-as-base)\n\n> **Note**\n> \n> You should prefer to use regular multi-stage builds over this option. You can Use this feature when you have multiple Dockerfiles that can't be easily merged into one.\n\n### [`target.dockerfile-inline`](#targetdockerfile-inline)\n\nUses the string value as an inline Dockerfile for the build target.\n\nThe `dockerfile-inline` takes precedence over the `dockerfile` attribute. If you specify both, Bake uses the inline version.\n\n### [`target.dockerfile`](#targetdockerfile)\n\nName of the Dockerfile to use for the build. This is the same as the [`--file` flag](https://docs.docker.com/reference/cli/docker/image/build/#file) for the `docker build` command.\n\nResolves to `\"Dockerfile\"` by default.\n\n### [`target.inherits`](#targetinherits)\n\nA target can inherit attributes from other targets. Use `inherits` to reference from one target to another.\n\nIn the following example, the `app-dev` target specifies an image name and tag. The `app-release` target uses `inherits` to reuse the tag name.\n\nThe `inherits` attribute is a list, meaning you can reuse attributes from multiple other targets. In the following example, the `app-release` target reuses attributes from both the `app-dev` and `_release` targets.\n\nWhen inheriting attributes from multiple targets and there's a conflict, the target that appears last in the `inherits` list takes precedence. The previous example defines the `BUILDX_EXPERIMENTAL` argument twice for the `app-release` target. It resolves to `0` because the `_release` target appears last in the inheritance chain:\n\n### [`target.labels`](#targetlabels)\n\nAssigns image labels to the build. This is the same as the `--label` flag for `docker build`.\n\nIt's possible to use a `null` value for labels. If you do, the builder uses the label value specified in the Dockerfile.\n\n### [`target.matrix`](#targetmatrix)\n\nA matrix strategy lets you fork a single target into multiple different variants, based on parameters that you specify. This works in a similar way to \\[Matrix strategies for GitHub Actions\\]. You can use this to reduce duplication in your bake definition.\n\nThe `matrix` attribute is a map of parameter names to lists of values. Bake builds each possible combination of values as a separate target.\n\nEach generated target **must** have a unique name. To specify how target names should resolve, use the `name` attribute.\n\nThe following example resolves the `app` target to `app-foo` and `app-bar`. It also uses the matrix value to define the [target build stage](#targettarget).\n\n#### [Multiple axes](#multiple-axes)\n\nYou can specify multiple keys in your matrix to fork a target on multiple axes. When using multiple matrix keys, Bake builds every possible variant.\n\nThe following example builds four targets:\n\n*   `app-foo-1-0`\n*   `app-foo-2-0`\n*   `app-bar-1-0`\n*   `app-bar-2-0`\n\n#### [Multiple values per matrix target](#multiple-values-per-matrix-target)\n\nIf you want to differentiate the matrix on more than just a single value, you can use maps as matrix values. Bake creates a target for each map, and you can access the nested values using dot notation.\n\nThe following example builds two targets:\n\n*   `app-foo-1-0`\n*   `app-bar-2-0`\n\n### [`target.name`](#targetname)\n\nSpecify name resolution for targets that use a matrix strategy. The following example resolves the `app` target to `app-foo` and `app-bar`.\n\n### [`target.no-cache-filter`](#targetno-cache-filter)\n\nDon't use build cache for the specified stages. This is the same as the `--no-cache-filter` flag for `docker build`. The following example avoids build cache for the `foo` build stage.\n\n### [`target.no-cache`](#targetno-cache)\n\nDon't use cache when building the image. This is the same as the `--no-cache` flag for `docker build`.\n\n### [`target.output`](#targetoutput)\n\nConfiguration for exporting the build output. This is the same as the [`--output` flag](https://docs.docker.com/reference/cli/docker/buildx/build/#output). The following example configures the target to use a cache-only output,\n\n### [`target.platforms`](#targetplatforms)\n\nSet target platforms for the build target. This is the same as the [`--platform` flag](https://docs.docker.com/reference/cli/docker/buildx/build/#platform). The following example creates a multi-platform build for three architectures.\n\n### [`target.pull`](#targetpull)\n\nConfigures whether the builder should attempt to pull images when building the target. This is the same as the `--pull` flag for `docker build`. The following example forces the builder to always pull all images referenced in the build target.\n\n### [`target.secret`](#targetsecret)\n\nDefines secrets to expose to the build target. This is the same as the [`--secret` flag](https://docs.docker.com/reference/cli/docker/buildx/build/#secret).\n\nThis lets you [mount the secret](https://docs.docker.com/reference/dockerfile/#run---mounttypesecret) in your Dockerfile.\n\n### [`target.shm-size`](#targetshm-size)\n\nSets the size of the shared memory allocated for build containers when using `RUN` instructions.\n\nThe format is `<number><unit>`. `number` must be greater than `0`. Unit is optional and can be `b` (bytes), `k` (kilobytes), `m` (megabytes), or `g` (gigabytes). If you omit the unit, the system uses bytes.\n\nThis is the same as the `--shm-size` flag for `docker build`.\n\n> **Note**\n> \n> In most cases, it is recommended to let the builder automatically determine the appropriate configurations. Manual adjustments should only be considered when specific performance tuning is required for complex build scenarios.\n\n### [`target.ssh`](#targetssh)\n\nDefines SSH agent sockets or keys to expose to the build. This is the same as the [`--ssh` flag](https://docs.docker.com/reference/cli/docker/buildx/build/#ssh). This can be useful if you need to access private repositories during a build.\n\n### [`target.tags`](#targettags)\n\nImage names and tags to use for the build target. This is the same as the [`--tag` flag](https://docs.docker.com/reference/cli/docker/image/build/#tag).\n\n### [`target.target`](#targettarget)\n\nSet the target build stage to build. This is the same as the [`--target` flag](https://docs.docker.com/reference/cli/docker/image/build/#target).\n\n### [`target.ulimits`](#targetulimits)\n\nUlimits overrides the default ulimits of build's containers when using `RUN` instructions and are specified with a soft and hard limit as such: `<type>=<soft limit>[:<hard limit>]`, for example:\n\n> **Note**\n> \n> If you do not provide a `hard limit`, the `soft limit` is used for both values. If no `ulimits` are set, they are inherited from the default `ulimits` set on the daemon.\n\n> **Note**\n> \n> In most cases, it is recommended to let the builder automatically determine the appropriate configurations. Manual adjustments should only be considered when specific performance tuning is required for complex build scenarios.\n\nGroups allow you to invoke multiple builds (targets) at once.\n\nGroups take precedence over targets, if both exist with the same name. The following bake file builds the `default` group. Bake ignores the `default` target.\n\nThe HCL file format supports variable block definitions. You can use variables as build arguments in your Dockerfile, or interpolate them in attribute values in your Bake file.\n\nYou can assign a default value for a variable in the Bake file, or assign a `null` value to it. If you assign a `null` value, Buildx uses the default value from the Dockerfile instead.\n\nYou can override variable defaults set in the Bake file using environment variables. The following example sets the `TAG` variable to `dev`, overriding the default `latest` value shown in the previous example.\n\n### [Built-in variables](#built-in-variables)\n\nThe following variables are built-ins that you can use with Bake without having to define them.\n\n| Variable | Description |\n| --- | --- |\n| `BAKE_CMD_CONTEXT` | Holds the main context when building using a remote Bake file. |\n| `BAKE_LOCAL_PLATFORM` | Returns the current platformâ€™s default platform specification (e.g. `linux/amd64`). |\n\n### [Use environment variable as default](#use-environment-variable-as-default)\n\nYou can set a Bake variable to use the value of an environment variable as a default value:\n\n### [Interpolate variables into attributes](#interpolate-variables-into-attributes)\n\nTo interpolate a variable into an attribute string value, you must use curly brackets. The following doesn't work:\n\nWrap the variable in curly brackets where you want to insert it:\n\nBefore you can interpolate a variable into an attribute, first you must declare it in the bake file, as demonstrated in the following example.\n\nA [set of general-purpose functions](https://github.com/docker/buildx/blob/master/bake/hclparser/stdlib.go) provided by [go-cty](https://github.com/zclconf/go-cty/tree/main/cty/function/stdlib) are available for use in HCL files:\n\nIn addition, [user defined functions](https://github.com/hashicorp/hcl/tree/main/ext/userfunc) are also supported:\n\n> **Note**\n> \n> See [User defined HCL functions](https://docs.docker.com/build/bake/hcl-funcs/) page for more details.",
  "title": "Bake file reference | Docker Docs\n",
  "description": "Learn about the syntax and available commands for the Buildx Bake file.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/attestations/sbom/",
  "markdown": "# SBOM attestations | Docker Docs\n\nSoftware Bill of Materials (SBOM) attestations describe what software artifacts an image contains, and artifacts used to create the image. Metadata included in an SBOM for describing software artifacts may include:\n\n*   Name of the artifact\n*   Version\n*   License type\n*   Authors\n*   Unique package identifier\n\nThere are benefits to indexing contents of an image during the build, as opposed to scanning a final image. When scanning happens as part of the build, you're able to detect software you use to build the image, that may not show up in the final image.\n\nThe SBOMs generated by BuildKit follow the SPDX standard. SBOMs attach to the final image as a JSON-encoded SPDX document, using the format defined by the [in-toto SPDX predicate](https://github.com/in-toto/attestation/blob/main/spec/predicates/spdx.md).\n\nTo create an SBOM attestation, pass the `--attest type=sbom` option to the `docker buildx build` command:\n\nAlternatively, you can use the shorthand `--sbom=true` option instead of `--attest type=sbom`.\n\nFor an example on how to add SBOM attestations with GitHub Actions, see [Add attestations with GitHub Actions](https://docs.docker.com/build/ci/github-actions/attestations/).\n\nAlways validate the generated SBOM for your image before you push your image to a registry.\n\nTo validate, you can build the image using the `local` exporter. Building with the `local` exporter saves the build result to your local filesystem instead of creating an image. Attestations are written to a JSON file in the root directory of your export.\n\nThe SBOM file appears in the root directory of the output, named `sbom.spdx.json`:\n\nBy default, BuildKit only scans the final stage of an image. The resulting SBOM doesn't include build-time dependencies installed in earlier stages, or that exist in the build context. This may cause you to overlook vulnerabilities in those dependencies, which could impact the security of your final build artifacts.\n\nFor instance, you might use [multi-stage builds](https://docs.docker.com/build/building/multi-stage/), with a `FROM scratch` stanza for your final stage to achieve a smaller image size.\n\nScanning the resulting image built using this Dockerfile example would not reveal build-time dependencies used in the `build` stage.\n\nTo include build-time dependencies from your Dockerfile, you can set the build arguments `BUILDKIT_SBOM_SCAN_CONTEXT` and `BUILDKIT_SBOM_SCAN_STAGE`. This expands the scanning scope to include the build context and additional stages.\n\nYou can set the arguments as global arguments (after declaring the Dockerfile syntax directive, before the first `FROM` command) or individually in each stage. If set globally, the value propagates to each stage in the Dockerfile.\n\nThe `BUILDKIT_SBOM_SCAN_CONTEXT` and `BUILDKIT_SBOM_SCAN_STAGE` build arguments are special values. You can't perform variable substitution using these arguments, and you can't set them using environment variables from within the Dockerfile. The only way to set these values is using explicit `ARG` command in the Dockerfile.\n\n### [Scan build context](#scan-build-context)\n\nTo scan the build context, set the `BUILDKIT_SBOM_SCAN_CONTEXT` to `true`.\n\nYou can use the `--build-arg` CLI option to override the value specified in the Dockerfile.\n\nNote that passing the option as a CLI argument only, without having declared it using `ARG` in the Dockerfile, will have no effect. You must specify the `ARG` in the Dockerfile, whereby you can override the context scanning behavior using `--build-arg`.\n\n### [Scan stages](#scan-stages)\n\nTo scan more than just the final stage, set the `BUILDKIT_SBOM_SCAN_STAGE` argument to true, either globally or in the specific stages that you want to scan. The following table demonstrates the different possible settings for this argument.\n\n| Value | Description |\n| --- | --- |\n| `BUILDKIT_SBOM_SCAN_STAGE=true` | Enables scanning for the current stage |\n| `BUILDKIT_SBOM_SCAN_STAGE=false` | Disables scanning for the current stage |\n| `BUILDKIT_SBOM_SCAN_STAGE=base,bin` | Enables scanning for the stages named `base` and `bin` |\n\nOnly stages that are built will be scanned. Stages that aren't dependencies of the target stage won't be built, or scanned.\n\nThe following Dockerfile example uses multi-stage builds to build a static website with [Hugo](https://gohugo.io/).\n\nSetting `ARG BUILDKIT_SBOM_SCAN_STAGE=true` in the `hugo` stage ensures that the final SBOM includes the information that Alpine Linux and Hugo were used to create the website.\n\nBuilding this image with the `local` exporter creates two JSON files:\n\nTo explore created SBOMs exported through the `image` exporter, you can use [`imagetools inspect`](https://docs.docker.com/reference/cli/docker/buildx/imagetools/inspect/).\n\nUsing the `--format` option, you can specify a template for the output. All SBOM-related data is available under the `.SBOM` attribute. For example, to get the raw contents of an SBOM in SPDX format:\n\n> **Tip**\n> \n> If the image is multi-platform, you can check the SBOM for a platform-specific index using `--format '{{ json (index .SBOM \"linux/amd64\").SPDX }}'`.\n\nYou can also construct more complex expressions using the full functionality of Go templates. For example, you can list all the installed packages and their version identifiers:\n\nBuildKit generates the SBOM using a scanner plugin. By default, it uses is the [BuildKit Syft scanner](https://github.com/docker/buildkit-syft-scanner) plugin. This plugin is built on top of [Anchore's Syft](https://github.com/anchore/syft), an open source tool for generating an SBOM.\n\nYou can select a different plugin to use with the `generator` option, specifying an image that implements the [BuildKit SBOM scanner protocol](https://github.com/moby/buildkit/blob/master/docs/attestations/sbom-protocol.md).\n\n> **Tip**\n> \n> The Docker Scout SBOM generator is available. See [Docker Scout SBOMs](https://docs.docker.com/scout/how-tos/view-create-sboms/).\n\nThe following JSON example shows what an SBOM attestation might look like.",
  "title": "SBOM attestations | Docker Docs\n",
  "description": "SBOM build attestations describe the contents of your image, and the packages used to build it. ",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/bake/remote-definition/",
  "markdown": "# Remote Bake file definition | Docker Docs\n\nYou can also build Bake files directly from a remote Git repository or HTTPS URL:\n\nAs you can see the context is fixed to `https://github.com/docker/cli.git` even if [no context is actually defined](https://github.com/docker/cli/blob/2776a6d694f988c0c1df61cad4bfac0f54e481c8/docker-bake.hcl#L17-L26) in the definition.\n\nIf you want to access the main context for bake command from a bake file that has been imported remotely, you can use the [`BAKE_CMD_CONTEXT` built-in var](https://docs.docker.com/build/bake/reference/#built-in-variables).\n\nYou can also specify the Bake definition to load from the remote repository, using the `--file` or `-f` flag:\n\nIf you want to use a combination of local and remote definitions, you can specify a local definition using the `cwd://` prefix with `-f`:\n\nIf you want to use a remote definition that lives in a private repository, you may need to specify credentials for Bake to use when fetching the definition.\n\nIf you can authenticate to the private repository using the default `SSH_AUTH_SOCK`, then you don't need to specify any additional authentication parameters for Bake. Bake automatically uses your default agent socket.\n\nFor authentication using an HTTP token, or custom SSH agents, use the following environment variables to configure Bake's authentication strategy:\n\n*   [`BUILDX_BAKE_GIT_AUTH_TOKEN`](https://docs.docker.com/build/building/variables/#buildx_bake_git_auth_token)\n*   [`BUILDX_BAKE_GIT_AUTH_HEADER`](https://docs.docker.com/build/building/variables/#buildx_bake_git_auth_header)\n*   [`BUILDX_BAKE_GIT_SSH`](https://docs.docker.com/build/building/variables/#buildx_bake_git_ssh)",
  "title": "Remote Bake file definition | Docker Docs\n",
  "description": "Build with Bake using a remote file definition using Git or HTTP",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/attestations/slsa-provenance/",
  "markdown": "# Provenance attestations | Docker Docs\n\n```\n{\n  \"_type\": \"https://in-toto.io/Statement/v0.1\",\n  \"predicateType\": \"https://slsa.dev/provenance/v0.2\",\n  \"subject\": [\n    {\n      \"name\": \"pkg:docker/<registry>/<image>@<tag/digest>?platform=<platform>\",\n      \"digest\": {\n        \"sha256\": \"e8275b2b76280af67e26f068e5d585eb905f8dfd2f1918b3229db98133cb4862\"\n      }\n    }\n  ],\n  \"predicate\": {\n    \"builder\": { \"id\": \"\" },\n    \"buildType\": \"https://mobyproject.org/buildkit@v1\",\n    \"materials\": [\n      {\n        \"uri\": \"pkg:docker/docker/dockerfile@1\",\n        \"digest\": {\n          \"sha256\": \"9ba7531bd80fb0a858632727cf7a112fbfd19b17e94c4e84ced81e24ef1a0dbc\"\n        }\n      },\n      {\n        \"uri\": \"pkg:docker/golang@1.19.4-alpine?platform=linux%2Farm64\",\n        \"digest\": {\n          \"sha256\": \"a9b24b67dc83b3383d22a14941c2b2b2ca6a103d805cac6820fd1355943beaf1\"\n        }\n      }\n    ],\n    \"buildConfig\": {\n      \"llbDefinition\": [\n        {\n          \"id\": \"step4\",\n          \"op\": {\n            \"Op\": {\n              \"exec\": {\n                \"meta\": {\n                  \"args\": [\"/bin/sh\", \"-c\", \"go mod download -x\"],\n                  \"env\": [\n                    \"PATH=/go/bin:/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n                    \"GOLANG_VERSION=1.19.4\",\n                    \"GOPATH=/go\",\n                    \"CGO_ENABLED=0\"\n                  ],\n                  \"cwd\": \"/src\"\n                },\n                \"mounts\": [\n                  { \"input\": 0, \"dest\": \"/\", \"output\": 0 },\n                  {\n                    \"input\": -1,\n                    \"dest\": \"/go/pkg/mod\",\n                    \"output\": -1,\n                    \"mountType\": 3,\n                    \"cacheOpt\": { \"ID\": \"//go/pkg/mod\" }\n                  },\n                  {\n                    \"input\": 1,\n                    \"selector\": \"/go.mod\",\n                    \"dest\": \"/src/go.mod\",\n                    \"output\": -1,\n                    \"readonly\": true\n                  },\n                  {\n                    \"input\": 1,\n                    \"selector\": \"/go.sum\",\n                    \"dest\": \"/src/go.sum\",\n                    \"output\": -1,\n                    \"readonly\": true\n                  }\n                ]\n              }\n            },\n            \"platform\": { \"Architecture\": \"arm64\", \"OS\": \"linux\" },\n            \"constraints\": {}\n          },\n          \"inputs\": [\"step3:0\", \"step1:0\"]\n        }\n      ]\n    },\n    \"metadata\": {\n      \"buildInvocationID\": \"edf52vxjyf9b6o5qd7vgx0gru\",\n      \"buildStartedOn\": \"2022-12-15T15:38:13.391980297Z\",\n      \"buildFinishedOn\": \"2022-12-15T15:38:14.274565297Z\",\n      \"reproducible\": false,\n      \"completeness\": {\n        \"parameters\": true,\n        \"environment\": true,\n        \"materials\": false\n      },\n      \"https://mobyproject.org/buildkit@v1#metadata\": {\n        \"vcs\": {\n          \"revision\": \"a9ba846486420e07d30db1107411ac3697ecab68-dirty\",\n          \"source\": \"git@github.com:<org>/<repo>.git\"\n        },\n        \"source\": {\n          \"locations\": {\n            \"step4\": {\n              \"locations\": [\n                {\n                  \"ranges\": [\n                    { \"start\": { \"line\": 5 }, \"end\": { \"line\": 5 } },\n                    { \"start\": { \"line\": 6 }, \"end\": { \"line\": 6 } },\n                    { \"start\": { \"line\": 7 }, \"end\": { \"line\": 7 } },\n                    { \"start\": { \"line\": 8 }, \"end\": { \"line\": 8 } }\n                  ]\n                }\n              ]\n            }\n          },\n          \"infos\": [\n            {\n              \"filename\": \"Dockerfile\",\n              \"data\": \"RlJPTSBhbHBpbmU6bGF0ZXN0Cg==\",\n              \"llbDefinition\": [\n                {\n                  \"id\": \"step0\",\n                  \"op\": {\n                    \"Op\": {\n                      \"source\": {\n                        \"identifier\": \"local://dockerfile\",\n                        \"attrs\": {\n                          \"local.differ\": \"none\",\n                          \"local.followpaths\": \"[\\\"Dockerfile\\\",\\\"Dockerfile.dockerignore\\\",\\\"dockerfile\\\"]\",\n                          \"local.session\": \"s4j58ngehdal1b5hn7msiqaqe\",\n                          \"local.sharedkeyhint\": \"dockerfile\"\n                        }\n                      }\n                    },\n                    \"constraints\": {}\n                  }\n                },\n                { \"id\": \"step1\", \"op\": { \"Op\": null }, \"inputs\": [\"step0:0\"] }\n              ]\n            }\n          ]\n        },\n        \"layers\": {\n          \"step2:0\": [\n            [\n              {\n                \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n                \"digest\": \"sha256:261da4162673b93e5c0e7700a3718d40bcc086dbf24b1ec9b54bca0b82300626\",\n                \"size\": 3259190\n              },\n              {\n                \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n                \"digest\": \"sha256:bc729abf26b5aade3c4426d388b5ea6907fe357dec915ac323bb2fa592d6288f\",\n                \"size\": 286218\n              },\n              {\n                \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n                \"digest\": \"sha256:7f1d6579712341e8062db43195deb2d84f63b0f2d1ed7c3d2074891085ea1b56\",\n                \"size\": 116878653\n              },\n              {\n                \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n                \"digest\": \"sha256:652874aefa1343799c619d092ab9280b25f96d97939d5d796437e7288f5599c9\",\n                \"size\": 156\n              }\n            ]\n          ]\n        }\n      }\n    }\n  }\n}\n```",
  "title": "Provenance attestations | Docker Docs\n",
  "description": "Provenance build attestations describe how and where your image was built. ",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/multi-platform/",
  "markdown": "# Multi-platform image with GitHub Actions\n\nYou can build [multi-platform images](https://docs.docker.com/build/building/multi-platform/) using the `platforms` option, as shown in the following example:\n\n> **Note**\n> \n> *   For a list of available platforms, see the [Docker Setup Buildx](https://github.com/marketplace/actions/docker-setup-buildx) action.\n> *   If you want support for more platforms, you can use QEMU with the [Docker Setup QEMU](https://github.com/docker/setup-qemu-action) action.\n\nIn the previous example, each platform is built on the same runner which can take a long time depending on the number of platforms and your Dockerfile.\n\nTo solve this issue you can use a matrix strategy to distribute the build for each platform across multiple runners and create manifest list using the [`buildx imagetools create` command](https://docs.docker.com/reference/cli/docker/buildx/imagetools/create/).\n\nThe following workflow will build the image for each platform on a dedicated runner using a matrix strategy and push by digest. Then, the `merge` job will create a manifest list and push it to Docker Hub.\n\nThis example also uses the [`metadata` action](https://github.com/docker/metadata-action) to set tags and labels.\n\n### [With Bake](#with-bake)\n\nIt's also possible to build on multiple runners using Bake, with the [bake action](https://github.com/docker/bake-action).\n\nYou can find a live example [in this GitHub repository](https://github.com/crazy-max/docker-linguist).\n\nThe following example achieves the same results as described in [the previous section](#distribute-build-across-multiple-runners).",
  "title": "Multi-platform image with GitHub Actions | Docker Docs\n",
  "description": "Build for multiple architectures with GitHub Actions using QEMU emulation or multiple native builders",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/push-multi-registries/",
  "markdown": "# Push to multiple registries with GitHub Actions\n\nThe following workflow will connect you to Docker Hub and GitHub Container Registry, and push the image to both registries:",
  "title": "Push to multiple registries with GitHub Actions | Docker Docs\n",
  "description": "Push to multiple registries with GitHub Actions",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/attestations/attestation-storage/",
  "markdown": "# Image Attestation Storage | Docker Docs\n\nBuildkit supports creating and attaching attestations to build artifacts. These attestations can provide valuable information from the build process, including, but not limited to: [SBOMs](https://en.wikipedia.org/wiki/Software_supply_chain), [SLSA Provenance](https://slsa.dev/provenance), build logs, etc.\n\nThis document describes the current custom format used to store attestations, which is designed to be compatible with current registry implementations today. In the future, we may support exporting attestations in additional formats.\n\nAttestations are stored as manifest objects in the image index, similar in style to OCI artifacts.\n\n### [Attestation Manifest](#attestation-manifest)\n\nAttestation manifests are attached to the root image index object, under a separate [OCI image manifest](https://github.com/opencontainers/image-spec/blob/main/manifest.md). Each attestation manifest can contain multiple [attestation blobs](#attestation-blob), with all the of the attestations in a manifest applying to a single platform manifest. All properties of standard OCI and Docker manifests continue to apply.\n\nThe image `config` descriptor will point to a valid [image config](https://github.com/opencontainers/image-spec/blob/main/config.md), however, it will not contain attestation-specific details, and should be ignored as it is only included for compatibility purposes.\n\nEach image layer in `layers` will contain a descriptor for a single [attestation blob](#attestation-blob). The `mediaType` of each layer will be set in accordance to its contents, one of:\n\n*   `application/vnd.in-toto+json` (currently, the only supported option)\n    \n    Indicates an in-toto attestation blob\n    \n\nAny unknown `mediaType`s should be ignored.\n\nTo assist attestation traversal, the following annotations may be set on each layer descriptor:\n\n*   `in-toto.io/predicate-type`\n    \n    This annotation will be set if the enclosed attestation is an in-toto attestation (currently, the only supported option). The annotation will be set to contain the same value as the `predicateType` property present inside the attestation.\n    \n    When present, this annotation may be used to find the specific attestation(s) they are looking for to avoid pulling the contents of the others.\n    \n\n### [Attestation Blob](#attestation-blob)\n\nThe contents of each layer will be a blob dependent on its `mediaType`.\n\n*   `application/vnd.in-toto+json`\n    \n    The blob contents will contain a full [in-toto attestation statement](https://github.com/in-toto/attestation/blob/main/spec/README.md#statement):\n    \n    The subject of the attestation should be set to be the same digest as the target manifest described in the [Attestation Manifest Descriptor](#attestation-manifest-descriptor), or some object within.\n    \n\n### [Attestation Manifest Descriptor](#attestation-manifest-descriptor)\n\nAttestation manifests are attached to the root [image index](https://github.com/opencontainers/image-spec/blob/main/image-index.md), in the `manifests` key, after all the original runnable manifests. All properties of standard OCI and Docker manifest descriptors continue to apply.\n\nTo prevent container runtimes from accidentally pulling or running the image described in the manifest, the `platform` property of the attestation manifest will be set to `unknown/unknown`, as follows:\n\nTo assist index traversal, the following annotations will be set on the manifest descriptor descriptor:\n\n*   `vnd.docker.reference.type`\n    \n    This annotation describes the type of the artifact, and will be set to `attestation-manifest`. If any other value is specified, the entire manifest should be ignored.\n    \n*   `vnd.docker.reference.digest`\n    \n    This annotation will contain the digest of the object in the image index that the attestation manifest refers to.\n    \n    When present, this annotation can be used to find the matching attestation manifest for a selected image manifest.\n    \n\n_Example showing an SBOM attestation attached to a `linux/amd64` image_\n\n#### [Image index (`sha256:94acc2ca70c40f3f6291681f37ce9c767e3d251ce01c7e4e9b98ccf148c26260`):](#image-index-sha25694acc2ca70c40f3f6291681f37ce9c767e3d251ce01c7e4e9b98ccf148c26260)\n\nThis image index defines two descriptors: an AMD64 image `sha256:23678f31..` and an attestation manifest `sha256:02cb9aa7..` for that image.\n\n#### [Attestation manifest (`sha256:02cb9aa7600e73fcf41ee9f0f19cc03122b2d8be43d41ce4b21335118f5dd943`):](#attestation-manifest-sha25602cb9aa7600e73fcf41ee9f0f19cc03122b2d8be43d41ce4b21335118f5dd943)\n\nThis attestation manifest contains one attestation that is an in-toto attestation that contains a \"https://spdx.dev/Document\" predicate, signifying that it is defining a SBOM for the image.\n\n#### [Image config (`sha256:a781560066f20ec9c28f2115a95a886e5e71c7c7aa9d8fd680678498b82f3ea3`):](#image-config-sha256a781560066f20ec9c28f2115a95a886e5e71c7c7aa9d8fd680678498b82f3ea3)\n\n#### [Layer content (`sha256:1ea07d5e55eb47ad0e6bbfa2ec180fb580974411e623814e519064c88f022f5c`):](#layer-content-sha2561ea07d5e55eb47ad0e6bbfa2ec180fb580974411e623814e519064c88f022f5c)\n\nAttestation body containing the SBOM data listing the packages used during the build in SPDX format.",
  "title": "Image Attestation Storage | Docker Docs\n",
  "description": "How SBOM and provenance attestations are stored for images.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/attestations/slsa-definitions/",
  "markdown": "# SLSA definitions | Docker Docs\n\nBuildKit supports the [creation of SLSA Provenance](https://docs.docker.com/build/attestations/slsa-provenance/) for builds that it runs.\n\nThe provenance format generated by BuildKit is defined by the [SLSA Provenance format](https://slsa.dev/provenance/v0.2).\n\nThis page describes how BuildKit populate each field, and whether the field gets included when you generate attestations `mode=min` and `mode=max`.\n\nCorresponds to [SLSA `builder.id`](https://slsa.dev/provenance/v0.2#builder.id).\n\nIncluded with `mode=min` and `mode=max`.\n\nThe `builder.id` field is set to the URL of the build, if available.\n\nThis value can be set using the `builder-id` attestation parameter.\n\nCorresponds to [SLSA `buildType`](https://slsa.dev/provenance/v0.2#buildType).\n\nIncluded with `mode=min` and `mode=max`.\n\nThe `buildType` field is set to `https://mobyproject.org/buildkit@v1` can be used to determine the structure of the provenance content.\n\nCorresponds to [SLSA `invocation.configSource`](https://slsa.dev/provenance/v0.2#invocation.configSource).\n\nIncluded with `mode=min` and `mode=max`.\n\nDescribes the config that initialized the build.\n\nFor builds initialized from a remote context, like a Git or HTTP URL, this object defines the context URL and its immutable digest in the `uri` and `digest` fields. For builds using a local frontend, such as a Dockerfile, the `entryPoint` field defines the path for the frontend file that initialized the build (`filename` frontend option).\n\nCorresponds to [SLSA `invocation.parameters`](https://slsa.dev/provenance/v0.2#invocation.parameters).\n\nPartially included with `mode=min`.\n\nDescribes build inputs passed to the build.\n\nThe following fields are included with both `mode=min` and `mode=max`:\n\n*   `locals` lists any local sources used in the build, including the build context and frontend file.\n    \n*   `frontend` defines type of BuildKit frontend used for the build. Currently, this can be `dockerfile.v0` or `gateway.v0`.\n    \n*   `args` defines the build arguments passed to the BuildKit frontend.\n    \n    The keys inside the `args` object reflect the options as BuildKit receives them. For example, `build-arg` and `label` prefixes are used for build arguments and labels, and `target` key defines the target stage that was built. The `source` key defines the source image for the Gateway frontend, if used.\n    \n\nThe following fields are only included with `mode=max`:\n\n*   `secrets` defines secrets used during the build. Note that actual secret values are not included.\n*   `ssh` defines the ssh forwards used during the build.\n\nCorresponds to [SLSA `invocation.environment`](https://slsa.dev/provenance/v0.2#invocation.environment).\n\nIncluded with `mode=min` and `mode=max`.\n\nThe only value BuildKit currently sets is the `platform` of the current build machine. Note that this is not necessarily the platform of the build result that can be determined from the `in-toto` subject field.\n\nCorresponds to [SLSA `materials`](https://slsa.dev/provenance/v0.2#materials).\n\nIncluded with `mode=min` and `mode=max`.\n\nDefines all the external artifacts that were part of the build. The value depends on the type of artifact:\n\n*   The URL of Git repositories containing source code for the image\n*   HTTP URLs if you are building from a remote tarball, or that was included using an `ADD` command in Dockerfile\n*   Any Docker images used during the build\n\nThe URLs to the Docker images will be in [Package URL](https://github.com/package-url/purl-spec) format.\n\nAll the build materials will include the immutable checksum of the artifact. When building from a mutable tag, you can use the digest information to determine if the artifact has been updated compared to when the build ran.\n\nCorresponds to [SLSA `buildConfig`](https://slsa.dev/provenance/v0.2#buildConfig).\n\nOnly included with `mode=max`.\n\nDefines the build steps performed during the build.\n\nBuildKit internally uses LLB definition to execute the build steps. The LLB definition of the build steps is defined in `buildConfig.llbDefinition` field.\n\nEach LLB step is the JSON definition of the [LLB ProtoBuf API](https://github.com/moby/buildkit/blob/v0.10.0/solver/pb/ops.proto). The dependencies for a vertex in the LLB graph can be found in the `inputs` field for every step.\n\nCorresponds to [SLSA `metadata.buildInvocationId`](https://slsa.dev/provenance/v0.2#metadata.buildIncocationId).\n\nIncluded with `mode=min` and `mode=max`.\n\nUnique identifier for the build invocation. When building a multi-platform image with a single build request, this value will be the shared by all the platform versions of the image.\n\nCorresponds to [SLSA `metadata.buildStartedOn`](https://slsa.dev/provenance/v0.2#metadata.buildStartedOn).\n\nIncluded with `mode=min` and `mode=max`.\n\nTimestamp when the build started.\n\nCorresponds to [SLSA `metadata.buildFinishedOn`](https://slsa.dev/provenance/v0.2#metadata.buildFinishedOn).\n\nIncluded with `mode=min` and `mode=max`.\n\nTimestamp when the build finished.\n\nCorresponds to [SLSA `metadata.completeness`](https://slsa.dev/provenance/v0.2#metadata.completeness).\n\nIncluded with `mode=min` and `mode=max`.\n\nDefines if the provenance information is complete.\n\n`completeness.parameters` is true if all the build arguments are included in the `invocation.parameters` field. When building with `min` mode, the build arguments are not included in the provenance information and parameters are not complete. Parameters are also not complete on direct LLB builds that did not use a frontend.\n\n`completeness.environment` is always true for BuildKit builds.\n\n`completeness.materials` is true if `materials` field includes all the dependencies of the build. When building from un-tracked source in a local directory, the materials are not complete, while when building from a remote Git repository all materials can be tracked by BuildKit and `completeness.materials` is true.\n\nCorresponds to [SLSA `metadata.reproducible`](https://slsa.dev/provenance/v0.2#metadata.reproducible).\n\nDefines if the build result is supposed to be byte-by-byte reproducible. This value can be set by the user with the `reproducible=true` attestation parameter.\n\nIncluded with `mode=min` and `mode=max`.\n\nThis extension field is set to true if the build was hermetic and did not access the network. In Dockerfiles, a build is hermetic if it does not use `RUN` commands or disables network with `--network=none` flag.\n\nPartially included with `mode=min`.\n\nThis extension field defines BuildKit-specific additional metadata that is not part of the SLSA provenance spec.\n\n### [`source`](#source)\n\nOnly included with `mode=max`.\n\nDefines a source mapping of LLB build steps, defined in the `buildConfig.llbDefinition` field, to their original source code (for example, Dockerfile commands). The `source.locations` field contains the ranges of all the Dockerfile commands ran in an LLB step. `source.infos` array contains the source code itself. This mapping is present if the BuildKit frontend provided it when creating the LLB definition.\n\n### [`layers`](#layers)\n\nOnly included with `mode=max`.\n\nDefines the layer mapping of LLB build step mounts defined in `buildConfig.llbDefinition` to the OCI descriptors of equivalent layers. This mapping is present if the layer data was available, usually when attestation is for an image or if the build step pulled in image data as part of the build.\n\n### [`vcs`](#vcs)\n\nIncluded with `mode=min` and `mode=max`.\n\nDefines optional metadata for the version control system used for the build. If a build uses a remote context from Git repository, BuildKit extracts the details of the version control system automatically and displays it in the `invocation.configSource` field. But if the build uses a source from a local directory, the VCS information is lost even if the directory contained a Git repository. In this case, the build client can send additional `vcs:source` and `vcs:revision` build options and BuildKit will add them to the provenance attestations as extra metadata. Note that, contrary to the `invocation.configSource` field, BuildKit doesn't verify the `vcs` values, and as such they can't be trusted and should only be used as a metadata hint.\n\nTo inspect the provenance that was generated and attached to a container image, you can use the `docker buildx imagetools` command to inspect the image in a registry. Inspecting the attestation displays the format described in the [attestation storage specification](https://docs.docker.com/build/attestations/attestation-storage/).\n\nFor example, inspecting a simple Docker image based on `alpine:latest` results in a provenance attestation similar to the following, for a `mode=min` build:\n\nFor a similar build, but with `mode=max`:",
  "title": "SLSA definitions | Docker Docs\n",
  "description": "How BuildKit populates the fields in the SLSA provenance attestations.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/dockerfile/frontend/",
  "markdown": "# Custom Dockerfile syntax | Docker Docs\n\nBuildKit supports loading frontends dynamically from container images. To use an external Dockerfile frontend, the first line of your [Dockerfile](https://docs.docker.com/reference/dockerfile/) needs to set the [`syntax` directive](https://docs.docker.com/reference/dockerfile/#syntax) pointing to the specific image you want to use:\n\nFor example:\n\nYou can also use the predefined `BUILDKIT_SYNTAX` build argument to set the frontend image reference on the command line:\n\nThis defines the location of the Dockerfile syntax that is used to build the Dockerfile. The BuildKit backend allows seamlessly using external implementations that are distributed as Docker images and execute inside a container sandbox environment.\n\nCustom Dockerfile implementations allow you to:\n\n*   Automatically get bug fixes without updating the Docker daemon\n*   Make sure all users are using the same implementation to build your Dockerfile\n*   Use the latest features without updating the Docker daemon\n*   Try out new features or third-party features before they are integrated in the Docker daemon\n*   Use [alternative build definitions, or create your own](https://github.com/moby/buildkit#exploring-llb)\n*   Build your own Dockerfile frontend with custom features\n\n> **Note**\n> \n> BuildKit ships with a built-in Dockerfile frontend, but it's recommended to use an external image to make sure that all users use the same version on the builder and to pick up bug fixes automatically without waiting for a new version of BuildKit or Docker Engine.\n\nDocker distributes official versions of the images that can be used for building Dockerfiles under `docker/dockerfile` repository on Docker Hub. There are two channels where new images are released: `stable` and `labs`.\n\n### [Stable channel](#stable-channel)\n\nThe `stable` channel follows [semantic versioning](https://semver.org/). For example:\n\n*   `docker/dockerfile:1` - kept updated with the latest `1.x.x` minor _and_ patch release.\n*   `docker/dockerfile:1.2` - kept updated with the latest `1.2.x` patch release, and stops receiving updates once version `1.3.0` is released.\n*   `docker/dockerfile:1.2.1` - immutable: never updated.\n\nWe recommend using `docker/dockerfile:1`, which always points to the latest stable release of the version 1 syntax, and receives both \"minor\" and \"patch\" updates for the version 1 release cycle. BuildKit automatically checks for updates of the syntax when performing a build, making sure you are using the most current version.\n\nIf a specific version is used, such as `1.2` or `1.2.1`, the Dockerfile needs to be updated manually to continue receiving bugfixes and new features. Old versions of the Dockerfile remain compatible with the new versions of the builder.\n\n### [Labs channel](#labs-channel)\n\nThe `labs` channel provides early access to Dockerfile features that are not yet available in the `stable` channel. `labs` images are released at the same time as stable releases, and follow the same version pattern, but use the `-labs` suffix, for example:\n\n*   `docker/dockerfile:labs` - latest release on `labs` channel.\n*   `docker/dockerfile:1-labs` - same as `dockerfile:1`, with experimental features enabled.\n*   `docker/dockerfile:1.2-labs` - same as `dockerfile:1.2`, with experimental features enabled.\n*   `docker/dockerfile:1.2.1-labs` - immutable: never updated. Same as `dockerfile:1.2.1`, with experimental features enabled.\n\nChoose a channel that best fits your needs. If you want to benefit from new features, use the `labs` channel. Images in the `labs` channel contain all the features in the `stable` channel, plus early access features. Stable features in the `labs` channel follow [semantic versioning](https://semver.org/), but early access features don't, and newer releases may not be backwards compatible. Pin the version to avoid having to deal with breaking changes.\n\nFor documentation on `labs` features, master builds, and nightly feature releases, refer to the description in [the BuildKit source repository on GitHub](https://github.com/moby/buildkit/blob/master/README.md). For a full list of available images, visit the [`docker/dockerfile` repository on Docker Hub](https://hub.docker.com/r/docker/dockerfile), and the [`docker/dockerfile-upstream` repository on Docker Hub](https://hub.docker.com/r/docker/dockerfile-upstream) for development builds.",
  "title": "Custom Dockerfile syntax | Docker Docs\n",
  "description": "Dive deep into the Dockerfile frontend, and learn about custom frontends",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/manage-tags-labels/",
  "markdown": "# Manage tags and labels with GitHub Actions\n\nIf you want an \"automatic\" tag management and [OCI Image Format Specification](https://github.com/opencontainers/image-spec/blob/master/annotations.md) for labels, you can do it in a dedicated setup step. The following workflow will use the [Docker Metadata Action](https://github.com/docker/metadata-action) to handle tags and labels based on GitHub Actions events and Git metadata:",
  "title": "Manage tags and labels with GitHub Actions | Docker Docs\n",
  "description": "Assign tags and labels to images automatically with GitHub Actions",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/secrets/",
  "markdown": "# Using secrets with GitHub Actions\n\nA build secret is sensitive information, such as a password or API token, consumed as part of the build process. Docker Build supports two forms of secrets:\n\n*   [Secret mounts](#secret-mounts) add secrets as files in the build container (under `/run/secrets` by default).\n*   [SSH mounts](#ssh-mounts) add SSH agent sockets or keys into the build container.\n\nThis page shows how to use secrets with GitHub Actions. For an introduction to secrets in general, see [Build secrets](https://docs.docker.com/build/building/secrets/).\n\nIn the following example uses and exposes the [`GITHUB_TOKEN` secret](https://docs.github.com/en/actions/security-guides/automatic-token-authentication#about-the-github_token-secret) as provided by GitHub in your workflow.\n\nFirst, create a `Dockerfile` that uses the secret:\n\nIn this example, the secret name is `github_token`. The following workflow exposes this secret using the `secrets` input:\n\n> **Note**\n> \n> You can also expose a secret file to the build with the `secret-files` input:\n\nIf you're using [GitHub secrets](https://docs.github.com/en/actions/security-guides/encrypted-secrets) and need to handle multi-line value, you will need to place the key-value pair between quotes:\n\n| Key | Value |\n| --- | --- |\n| `MYSECRET` | `***********************` |\n| `GIT_AUTH_TOKEN` | `abcdefghi,jklmno=0123456789` |\n| `MYSECRET` | `aaaaaaaa\\nbbbbbbb\\nccccccccc` |\n| `FOO` | `bar` |\n| `EMPTYLINE` | `aaaa\\n\\nbbbb\\nccc` |\n| `JSON_SECRET` | `{\"key1\":\"value1\",\"key2\":\"value2\"}` |\n\n> **Note**\n> \n> Double escapes are needed for quote signs.\n\nSSH mounts let you authenticate with SSH servers. For example to perform a `git clone`, or to fetch application packages from a private repository.\n\nThe following Dockerfile example uses an SSH mount to fetch Go modules from a private GitHub repository.\n\nTo build this Dockerfile, you must specify an SSH mount that the builder can use in the steps with `--mount=type=ssh`.\n\nThe following GitHub Action workflow uses the `MrSquaare/ssh-setup-action` third-party action to bootstrap SSH setup on the GitHub runner. The action creates a private key defined by the GitHub Action secret `SSH_GITHUB_PPK` and adds it to the SSH agent socket file at `SSH_AUTH_SOCK`. The SSH mount in the build step assume `SSH_AUTH_SOCK` by default, so there's no need to specify the ID or path for the SSH agent socket explicitly.",
  "title": "Using secrets with GitHub Actions | Docker Docs\n",
  "description": "Example using secret mounts with GitHub Actions",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/dockerfile/release-notes/",
  "markdown": "# Dockerfile release notes | Docker Docs\n\nThis page contains information about the new features, improvements, known issues, and bug fixes in [Dockerfile reference](https://docs.docker.com/reference/dockerfile/).\n\nFor usage, see the [Dockerfile frontend syntax](https://docs.docker.com/build/dockerfile/frontend/) page.\n\n_2024-03-06_\n\n### [Stable](#stable)\n\n*   Variable expansion now allows string substitutions and trimming. [moby/buildkit#4427](https://github.com/moby/buildkit/pull/4427), [moby/buildkit#4287](https://github.com/moby/buildkit/pull/4287)\n*   Named contexts with local sources now correctly transfer only the files used in the Dockerfile instead of the full source directory. [moby/buildkit#4161](https://github.com/moby/buildkit/pull/4161)\n*   Dockerfile now better validates the order of stages and returns nice errors with stack traces if stages are in incorrect order. [moby/buildkit#4568](https://github.com/moby/buildkit/pull/4568), [moby/buildkit#4567](https://github.com/moby/buildkit/pull/4567)\n*   History commit messages now contain flags used with `COPY` and `ADD`. [moby/buildkit#4597](https://github.com/moby/buildkit/pull/4597)\n*   Progress messages for `ADD` commands from Git and HTTP sources have been improved. [moby/buildkit#4408](https://github.com/moby/buildkit/pull/4408)\n\n### [Labs](#labs)\n\n*   New `--parents` flag has been added to `COPY` for copying files while keeping the parent directory structure. [moby/buildkit#4598](https://github.com/moby/buildkit/pull/4598), [moby/buildkit#3001](https://github.com/moby/buildkit/pull/3001), [moby/buildkit#4720](https://github.com/moby/buildkit/pull/4720), [moby/buildkit#4728](https://github.com/moby/buildkit/pull/4728), [docs](https://docs.docker.com/reference/dockerfile/#copy---parents)\n*   New `--exclude` flag can be used in `COPY` and `ADD` commands to apply filter to copied files. [moby/buildkit#4561](https://github.com/moby/buildkit/pull/4561), [docs](https://docs.docker.com/reference/dockerfile/#copy---exclude)\n\n_2023-06-13_\n\n### [New](#new)\n\n*   Add `--start-interval` flag to the [`HEALTHCHECK` instruction](https://docs.docker.com/reference/dockerfile/#healthcheck).\n\nThe following features have graduated from the labs channel to stable:\n\n*   The `ADD` instruction can now [import files directly from Git URLs](https://docs.docker.com/reference/dockerfile/#adding-a-git-repository-add-git-ref-dir)\n*   The `ADD` instruction now supports [`--checksum` flag](https://docs.docker.com/reference/dockerfile/#verifying-a-remote-file-checksum-add---checksumchecksum-http-src-dest) to validate the contents of the remote URL contents\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements)\n\n*   Variable substitution now supports additional POSIX compatible variants without `:`. [moby/buildkit#3611](https://github.com/moby/buildkit/pull/3611)\n*   Exported Windows images now contain OSVersion and OSFeatures values from base image. [moby/buildkit#3619](https://github.com/moby/buildkit/pull/3619)\n*   Changed the permissions for Heredocs to 0644. [moby/buildkit#3992](https://github.com/moby/buildkit/pull/3992)\n\n_2023-02-14_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-1)\n\n*   Fix building from Git reference that is missing branch name but contains a subdir\n*   386 platform image is now included in the release\n\n_2023-01-18_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-2)\n\n*   Fix possible panic when warning conditions appear in multi-platform builds\n\n_2023-01-10_\n\n> Experimental\n> \n> The \"labs\" channel provides early access to Dockerfile features that are not yet available in the stable channel.\n\n### [New](#new-1)\n\n*   `ADD` command now supports [`--checksum` flag](https://docs.docker.com/reference/dockerfile/#verifying-a-remote-file-checksum-add---checksumchecksum-http-src-dest) to validate the contents of the remote URL contents\n\n_2023-01-10_\n\n### [New](#new-2)\n\n*   `ADD` command can now [import files directly from Git URLs](https://docs.docker.com/reference/dockerfile/#adding-a-git-repository-add-git-ref-dir)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-3)\n\n*   Named contexts now support `oci-layout://` protocol for including images from local OCI layout structure\n*   Dockerfile now supports secondary requests for listing all build targets or printing outline of accepted parameters for a specific build target\n*   Dockerfile `#syntax` directive that redirects to an external frontend image now allows the directive to be also set with `//` comments or JSON. The file may also contain a shebang header\n*   Named context can now be initialized with an empty scratch image\n*   Named contexts can now be initialized with an SSH Git URL\n*   Fix handling of `ONBUILD` when importing Schema1 images\n\n_2022-08-23_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-4)\n\n*   Fix creation timestamp not getting reset when building image from `docker-image://` named context\n*   Fix passing `--platform` flag of `FROM` command when loading `docker-image://` named context\n\n_2022-05-06_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-5)\n\n*   Fix loading certain environment variables from an image passed with built context\n\n_2022-04-08_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-6)\n\n*   Fix named context resolution for cross-compilation cases from input when input is built for a different platform\n\n_2022-03-09_\n\n### [New](#new-3)\n\n*   [`COPY --link` and `ADD --link`](https://docs.docker.com/reference/dockerfile/#copy---link) allow copying files with increased cache efficiency and rebase images without requiring them to be rebuilt. `--link` copies files to a separate layer and then uses new LLB MergeOp implementation to chain independent layers together\n*   [Heredocs](https://docs.docker.com/reference/dockerfile/#here-documents) support have been promoted from labs channel to stable. This feature allows writing multiline inline scripts and files\n*   Additional [named build contexts](https://docs.docker.com/reference/cli/docker/buildx/build/#build-context) can be passed to build to add or overwrite a stage or an image inside the build. A source for the context can be a local source, image, Git, or HTTP URL\n*   [`BUILDKIT_SANDBOX_HOSTNAME` build-arg](https://docs.docker.com/reference/dockerfile/#buildkit-built-in-build-args) can be used to set the default hostname for the `RUN` steps\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-7)\n\n*   When using a cross-compilation stage, the target platform for a step is now seen on progress output\n*   Fix some cases where Heredocs incorrectly removed quotes from content\n\n_2021-10-04_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-8)\n\n*   Fix parsing \"required\" mount key without a value\n\n_2021-07-16_\n\n> Experimental\n> \n> The \"labs\" channel provides early access to Dockerfile features that are not yet available in the stable channel.\n\n### [New](#new-4)\n\n*   `RUN` and `COPY` commands now support [Here-document syntax](https://docs.docker.com/reference/dockerfile/#here-documents) allowing writing multiline inline scripts and files\n\n_2021-07-16_\n\n### [New](#new-5)\n\n*   `RUN` command allows [`--network` flag](https://docs.docker.com/reference/dockerfile/#run---network) for requesting a specific type of network conditions. `--network=host` requires allowing `network.host` entitlement. This feature was previously only available on labs channel\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-9)\n\n*   `ADD` command with a remote URL input now correctly handles the `--chmod` flag\n*   Values for [`RUN --mount` flag](https://docs.docker.com/reference/dockerfile/#run---mount) now support variable expansion, except for the `from` field\n*   Allow [`BUILDKIT_MULTI_PLATFORM` build arg](https://docs.docker.com/reference/dockerfile/#buildkit-built-in-build-args) to force always creating multi-platform image, even if only contains single platform\n\n_2020-12-12_\n\n> Experimental\n> \n> The \"labs\" channel provides early access to Dockerfile features that are not yet available in the stable channel.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-10)\n\n*   `RUN` command allows [`--network` flag](https://docs.docker.com/reference/dockerfile/#run---network) for requesting a specific type of network conditions. `--network=host` requires allowing `network.host` entitlement\n\n_2020-12-12_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-11)\n\n*   Revert \"Ensure ENTRYPOINT command has at least one argument\"\n*   Optimize processing `COPY` calls on multi-platform cross-compilation builds\n\n_2020-12-03_\n\n> Experimental\n> \n> The \"labs\" channel provides early access to Dockerfile features that are not yet available in the stable channel.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-12)\n\n*   Experimental channel has been renamed to _labs_\n\n_2020-12-03_\n\n### [New](#new-6)\n\n*   [`RUN --mount` syntax](https://docs.docker.com/reference/dockerfile/#run---mount) for creating secret, ssh, bind, and cache mounts have been moved to mainline channel\n*   [`ARG` command](https://docs.docker.com/reference/dockerfile/#arg) now supports defining multiple build args on the same line similarly to `ENV`\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-13)\n\n*   Metadata load errors are now handled as fatal to avoid incorrect build results\n*   Allow lowercase Dockerfile name\n*   `--chown` flag in `ADD` now allows parameter expansion\n*   `ENTRYPOINT` requires at least one argument to avoid creating broken images\n\n_2020-04-18_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-14)\n\n*   Forward `FrontendInputs` to the gateway\n\n_2019-07-31_\n\n> Experimental\n> \n> The \"labs\" channel provides early access to Dockerfile features that are not yet available in the stable channel.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-15)\n\n*   Allow setting security mode for a process with `RUN --security=sandbox|insecure`\n*   Allow setting uid/gid for [cache mounts](https://docs.docker.com/reference/dockerfile/#run---mounttypecache)\n*   Avoid requesting internally linked paths to be pulled to build context\n*   Ensure missing cache IDs default to target paths\n*   Allow setting namespace for cache mounts with [`BUILDKIT_CACHE_MOUNT_NS` build arg](https://docs.docker.com/reference/dockerfile/#buildkit-built-in-build-args)\n\n_2019-07-31_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-16)\n\n*   Fix workdir creation with correct user and don't reset custom ownership\n*   Fix handling empty build args also used as `ENV`\n*   Detect circular dependencies\n\n_2019-04-27_\n\n### [New](#new-7)\n\n*   `ADD/COPY` commands now support implementation based on `llb.FileOp` and do not require helper image if builtin file operations support is available\n*   `--chown` flag for `COPY` command now supports variable expansion\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-17)\n\n*   To find the files ignored from the build context Dockerfile frontend will first look for a file `<path/to/Dockerfile>.dockerignore` and if it is not found `.dockerignore` file will be looked up from the root of the build context. This allows projects with multiple Dockerfiles to use different `.dockerignore` definitions",
  "title": "Dockerfile release notes | Docker Docs\n",
  "description": "Release notes for Dockerfile frontend",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/buildkit/",
  "markdown": "# BuildKit | Docker Docs\n\n[BuildKit](https://github.com/moby/buildkit) is an improved backend to replace the legacy builder. BuildKit is the default builder for users on Docker Desktop, and Docker Engine as of version 23.0.\n\nBuildKit provides new functionality and improves your builds' performance. It also introduces support for handling more complex scenarios:\n\n*   Detect and skip executing unused build stages\n*   Parallelize building independent build stages\n*   Incrementally transfer only the changed files in your [build context](https://docs.docker.com/build/building/context/) between builds\n*   Detect and skip transferring unused files in your [build context](https://docs.docker.com/build/building/context/)\n*   Use [Dockerfile frontend](https://docs.docker.com/build/dockerfile/frontend/) implementations with many new features\n*   Avoid side effects with rest of the API (intermediate images and containers)\n*   Prioritize your build cache for automatic pruning\n\nApart from many new features, the main areas BuildKit improves on the current experience are performance, storage management, and extensibility. From the performance side, a significant update is a new fully concurrent build graph solver. It can run build steps in parallel when possible and optimize out commands that don't have an impact on the final result. We have also optimized the access to the local source files. By tracking only the updates made to these files between repeated build invocations, there is no need to wait for local files to be read or uploaded before the work can begin.\n\nAt the core of BuildKit is a [Low-Level Build (LLB)](https://github.com/moby/buildkit#exploring-llb) definition format. LLB is an intermediate binary format that allows developers to extend BuildKit. LLB defines a content-addressable dependency graph that can be used to put together very complex build definitions. It also supports features not exposed in Dockerfiles, like direct data mounting and nested invocation.\n\n![](https://docs.docker.com/build/images/buildkit-dag.svg)\n\nEverything about execution and caching of your builds is defined in LLB. The caching model is entirely rewritten compared to the legacy builder. Rather than using heuristics to compare images, LLB directly tracks the checksums of build graphs and content mounted to specific operations. This makes it much faster, more precise, and portable. The build cache can even be exported to a registry, where it can be pulled on-demand by subsequent invocations on any host.\n\nLLB can be generated directly using a [golang client package](https://pkg.go.dev/github.com/moby/buildkit/client/llb) that allows defining the relationships between your build operations using Go language primitives. This gives you full power to run anything you can imagine, but will probably not be how most people will define their builds. Instead, most users would use a frontend component, or LLB nested invocation, to run a prepared set of build steps.\n\nA frontend is a component that takes a human-readable build format and converts it to LLB so BuildKit can execute it. Frontends can be distributed as images, and the user can target a specific version of a frontend that is guaranteed to work for the features used by their definition.\n\nFor example, to build a [Dockerfile](https://docs.docker.com/reference/dockerfile/) with BuildKit, you would [use an external Dockerfile frontend](https://docs.docker.com/build/dockerfile/frontend/).\n\nBuildKit is the default builder for users on Docker Desktop and Docker Engine v23.0 and later.\n\nIf you have installed Docker Desktop, you don't need to enable BuildKit. If you are running a version of Docker Engine version earlier than 23.0, you can enable BuildKit either by setting an environment variable, or by making BuildKit the default setting in the daemon configuration.\n\nTo set the BuildKit environment variable when running the `docker build` command, run:\n\n> **Note**\n> \n> [Buildx](https://docs.docker.com/build/architecture/#buildx) always uses BuildKit.\n\nTo use Docker BuildKit by default, edit the Docker daemon configuration in `/etc/docker/daemon.json` as follows, and restart the daemon.\n\nIf the `/etc/docker/daemon.json` file doesn't exist, create new file called `daemon.json` and then add the following to the file. And restart the Docker daemon.\n\n> **Warning**\n> \n> BuildKit only fully supports building Linux containers. Windows container support is experimental, and is tracked in [`moby/buildkit#616`](https://github.com/moby/buildkit/issues/616).\n\nBuildKit has experimental support for Windows containers (WCOW) as of version 0.13. This section walks you through the steps for trying it out. We appreciate any feedback you submit by [opening an issue here](https://github.com/moby/buildkit/issues/new), especially `buildkitd.exe`.\n\n### [Known limitations](#known-limitations)\n\n*   BuildKit on Windows currently only supports the `containerd` worker. Support for non-OCI workers is tracked in [moby/buildkit#4836](https://github.com/moby/buildkit/issues/4836).\n\n### [Prerequisites](#prerequisites)\n\n*   Architecture: `amd64`, `arm64` (binaries available but not officially tested yet).\n*   Supported OS: Windows Server 2019, Windows Server 2022, Windows 11.\n*   Base images: `ServerCore:ltsc2019`, `ServerCore:ltsc2022`, `NanoServer:ltsc2022`. See the [compatibility map here](https://learn.microsoft.com/en-us/virtualization/windowscontainers/deploy-containers/version-compatibility?tabs=windows-server-2019%2Cwindows-11#windows-server-host-os-compatibility).\n*   Docker Desktop version 4.29 or later\n\n### [Steps](#steps)\n\n> **Note**\n> \n> The following commands require administrator (elevated) privileges in a PowerShell terminal.\n\n1.  Enable the **Hyper-V** and **Containers** Windows features.\n    \n    If you see `RestartNeeded` as `True`, restart your machine and re-open a PowerShell terminal as an administrator. Otherwise, continue with the next step.\n    \n2.  Switch to Windows containers in Docker Desktop.\n    \n    Select the Docker icon in the taskbar, and then **Switch to Windows containers...**.\n    \n3.  Install containerd version 1.7.7 or later following the setup instructions [here](https://github.com/containerd/containerd/blob/main/docs/getting-started.md#installing-containerd-on-windows).\n    \n4.  Download and extract the latest BuildKit release.\n    \n5.  Install BuildKit binaries on `PATH`.\n    \n6.  Start the BuildKit daemon.\n    \n7.  In another terminal with administrator privileges, create a remote builder that uses the local BuildKit daemon.\n    \n    > **Note**\n    > \n    > This requires Docker Desktop version 4.29 or later.\n    \n8.  Verify the builder connection by running `docker buildx inspect`.\n    \n    The output should indicate that the builder platform is Windows, and that the endpoint of the builder is a named pipe.\n    \n9.  Create a Dockerfile and build a `hello-world` image.\n    \n10.  Build and push the image to a registry.\n    \n11.  After pushing to the registry, run the image with `docker run`.",
  "title": "BuildKit | Docker Docs\n",
  "description": "Introduction and overview of BuildKit",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/cache/",
  "markdown": "# Cache management with GitHub Actions\n\nThis page contains examples on using the cache storage backends with GitHub Actions.\n\n> **Note**\n> \n> See [Cache storage backends](https://docs.docker.com/build/cache/backends/) for more details about cache storage backends.\n\nIn most cases you want to use the [inline cache exporter](https://docs.docker.com/build/cache/backends/inline/). However, note that the `inline` cache exporter only supports `min` cache mode. To use `max` cache mode, push the image and the cache separately using the registry cache exporter with the `cache-to` option, as shown in the [registry cache example](#registry-cache).\n\nYou can import/export cache from a cache manifest or (special) image configuration on the registry with the [registry cache exporter](https://docs.docker.com/build/cache/backends/registry/).\n\n### [Cache backend API](#cache-backend-api)\n\n> Experimental\n> \n> This cache exporter is experimental. Please provide feedback on [BuildKit repository](https://github.com/moby/buildkit) if you experience any issues.\n\nThe [GitHub Actions cache exporter](https://docs.docker.com/build/cache/backends/gha/) backend uses the [GitHub Cache API](https://github.com/tonistiigi/go-actions-cache/blob/master/api.md) to fetch and upload cache blobs. That's why you should only use this cache backend in a GitHub Action workflow, as the `url` (`$ACTIONS_CACHE_URL`) and `token` (`$ACTIONS_RUNTIME_TOKEN`) attributes only get populated in a workflow context.\n\n### [Cache mounts](#cache-mounts)\n\nBuildKit doesn't preserve cache mounts in the GitHub Actions cache by default. If you wish to put your cache mounts into GitHub Actions cache and reuse it between builds, you can use a workaround provided by [`reproducible-containers/buildkit-cache-dance`](https://github.com/reproducible-containers/buildkit-cache-dance).\n\nThis GitHub Action creates temporary containers to extract and inject the cache mount data with your Docker build steps.\n\nThe following example shows how to use this workaround with a Go project.\n\nExample Dockerfile in `build/package/Dockerfile`\n\nExample CI action\n\nFor more information about this workaround, refer to the [GitHub repository](https://github.com/reproducible-containers/buildkit-cache-dance).\n\n### [Local cache](#local-cache)\n\n> **Warning**\n> \n> At the moment, old cache entries aren't deleted, so the cache size [keeps growing](https://github.com/docker/build-push-action/issues/252). The following example uses the `Move cache` step as a workaround (see [`moby/buildkit#1896`](https://github.com/moby/buildkit/issues/1896) for more info).\n\nYou can also leverage [GitHub cache](https://docs.github.com/en/actions/using-workflows/caching-dependencies-to-speed-up-workflows) using the [actions/cache](https://github.com/actions/cache) and [local cache exporter](https://docs.docker.com/build/cache/backends/local/) with this action:",
  "title": "Cache management with GitHub Actions | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/test-before-push/",
  "markdown": "# Test before push with GitHub Actions\n\nIn some cases, you might want to validate that the image works as expected before pushing it. The following workflow implements several steps to achieve this:\n\n1.  Build and export the image to Docker\n2.  Test your image\n3.  Multi-platform build and push the image\n\n> **Note**\n> \n> The `linux/amd64` image is only built once in this workflow. The image is built once, and the following steps use the internal cache from the first `Build and push` step. The second `Build and push` step only builds `linux/arm64`.",
  "title": "Test before push with GitHub Actions | Docker Docs\n",
  "description": "Here's how you can validate an image, before pushing it to a registry",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/buildkit/configure/",
  "markdown": "# Configure BuildKit | Docker Docs\n\nIf you create a `docker-container` or `kubernetes` builder with Buildx, you can apply a custom [BuildKit configuration](https://docs.docker.com/build/buildkit/toml-configuration/) by passing the [`--config` flag](https://docs.docker.com/reference/cli/docker/buildx/create/#config) to the `docker buildx create` command.\n\nYou can define a registry mirror to use for your builds. Doing so redirects BuildKit to pull images from a different hostname. The following steps exemplify defining a mirror for `docker.io` (Docker Hub) to `mirror.gcr.io`.\n\n1.  Create a TOML at `/etc/buildkitd.toml` with the following content:\n    \n    > **Note**\n    > \n    > `debug = true` turns on debug requests in the BuildKit daemon, which logs a message that shows when a mirror is being used.\n    \n2.  Create a `docker-container` builder that uses this BuildKit configuration:\n    \n3.  Build an image:\n    \n\nThe BuildKit logs for this builder now shows that it uses the GCR mirror. You can tell by the fact that the response messages include the `x-goog-*` HTTP headers.\n\nIf you specify registry certificates in the BuildKit configuration, the daemon copies the files into the container under `/etc/buildkit/certs`. The following steps show adding a self-signed registry certificate to the BuildKit configuration.\n\n1.  Add the following configuration to `/etc/buildkitd.toml`:\n    \n    This tells the builder to push images to the `myregistry.com` registry using the certificates in the specified location (`/etc/certs`).\n    \n2.  Create a `docker-container` builder that uses this configuration:\n    \n3.  Inspect the builder's configuration file (`/etc/buildkit/buildkitd.toml`), it shows that the certificate configuration is now configured in the builder.\n    \n4.  Verify that the certificates are inside the container:\n    \n\nNow you can push to the registry using this builder, and it will authenticate using the certificates:\n\nCNI networking for builders can be useful for dealing with network port contention during concurrent builds. CNI is [not yet](https://github.com/moby/buildkit/issues/28) available in the default BuildKit image. But you can create your own image that includes CNI support.\n\nThe following Dockerfile example shows a custom BuildKit image with CNI support. It uses the [CNI config for integration tests](https://github.com/moby/buildkit/blob/master//hack/fixtures/cni.json) in BuildKit as an example. Feel free to include your own CNI configuration.\n\nNow you can build this image, and create a builder instance from it using [the `--driver-opt image` option](https://docs.docker.com/reference/cli/docker/buildx/create/#driver-opt):\n\n### [Max parallelism](#max-parallelism)\n\nYou can limit the parallelism of the BuildKit solver, which is particularly useful for low-powered machines, using a [BuildKit configuration](https://docs.docker.com/build/buildkit/toml-configuration/) while creating a builder with the [`--config` flags](https://docs.docker.com/reference/cli/docker/buildx/create/#config).\n\nNow you can [create a `docker-container` builder](https://docs.docker.com/build/drivers/docker-container/) that will use this BuildKit configuration to limit parallelism.\n\n### [TCP connection limit](#tcp-connection-limit)\n\nTCP connections are limited to 4 simultaneous connections per registry for pulling and pushing images, plus one additional connection dedicated to metadata requests. This connection limit prevents your build from getting stuck while pulling images. The dedicated metadata connection helps reduce the overall build time.\n\nMore information: [moby/buildkit#2259](https://github.com/moby/buildkit/pull/2259)",
  "title": "Configure BuildKit | Docker Docs\n",
  "description": "Learn how to configure BuildKit for your builder.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/local-registry/",
  "markdown": "# Local registry with GitHub Actions\n\n```\nname: ci\n\non:\n  push:\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    services:\n      registry:\n        image: registry:2\n        ports:\n          - 5000:5000\n    steps:\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n      \n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          driver-opts: network=host\n      \n      - name: Build and push to local registry\n        uses: docker/build-push-action@v6\n        with:\n          push: true\n          tags: localhost:5000/name/app:latest\n      \n      - name: Inspect\n        run: |\n          docker buildx imagetools inspect localhost:5000/name/app:latest          \n```",
  "title": "Local registry with GitHub Actions | Docker Docs\n",
  "description": "Create and use a local OCI registry with GitHub Actions",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/export-docker/",
  "markdown": "# Export to Docker with GitHub Actions\n\nYou may want your build result to be available in the Docker client through `docker images` to be able to use it in another step of your workflow:",
  "title": "Export to Docker with GitHub Actions | Docker Docs\n",
  "description": "Load the build results to the image store with GitHub Actions",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/buildkit/toml-configuration/",
  "markdown": "# buildkitd.toml | Docker Docs\n\n```\n# debug enables additional debug logging\ndebug = true\n# trace enables additional trace logging (very verbose, with potential performance impacts)\ntrace = true\n# root is where all buildkit state is stored.\nroot = \"/var/lib/buildkit\"\n# insecure-entitlements allows insecure entitlements, disabled by default.\ninsecure-entitlements = [ \"network.host\", \"security.insecure\" ]\n\n[log]\n  # log formatter: json or text\n  format = \"text\"\n\n[dns]\n  nameservers=[\"1.1.1.1\",\"8.8.8.8\"]\n  options=[\"edns0\"]\n  searchDomains=[\"example.com\"]\n\n[grpc]\n  address = [ \"tcp://0.0.0.0:1234\" ]\n  # debugAddress is address for attaching go profiles and debuggers.\n  debugAddress = \"0.0.0.0:6060\"\n  uid = 0\n  gid = 0\n  [grpc.tls]\n    cert = \"/etc/buildkit/tls.crt\"\n    key = \"/etc/buildkit/tls.key\"\n    ca = \"/etc/buildkit/tlsca.crt\"\n\n[otel]\n  # OTEL collector trace socket path\n  socketPath = \"/run/buildkit/otel-grpc.sock\"\n\n# config for build history API that stores information about completed build commands\n[history]\n  # maxAge is the maximum age of history entries to keep, in seconds.\n  maxAge = 172800\n  # maxEntries is the maximum number of history entries to keep.\n  maxEntries = 50\n\n[worker.oci]\n  enabled = true\n  # platforms is manually configure platforms, detected automatically if unset.\n  platforms = [ \"linux/amd64\", \"linux/arm64\" ]\n  snapshotter = \"auto\" # overlayfs or native, default value is \"auto\".\n  rootless = false # see docs/rootless.md for the details on rootless mode.\n  # Whether run subprocesses in main pid namespace or not, this is useful for\n  # running rootless buildkit inside a container.\n  noProcessSandbox = false\n  gc = true\n  # gckeepstorage can be an integer number of bytes (e.g. 512000000), a string\n  # with a unit (e.g. \"512MB\"), or a string percentage of the total disk\n  # space (e.g. \"10%\")\n  gckeepstorage = 9000\n  # alternate OCI worker binary name(example 'crun'), by default either \n  # buildkit-runc or runc binary is used\n  binary = \"\"\n  # name of the apparmor profile that should be used to constrain build containers.\n  # the profile should already be loaded (by a higher level system) before creating a worker.\n  apparmor-profile = \"\"\n  # limit the number of parallel build steps that can run at the same time\n  max-parallelism = 4\n  # maintain a pool of reusable CNI network namespaces to amortize the overhead\n  # of allocating and releasing the namespaces\n  cniPoolSize = 16\n\n  [worker.oci.labels]\n    \"foo\" = \"bar\"\n\n  [[worker.oci.gcpolicy]]\n    # keepBytes can be an integer number of bytes (e.g. 512000000), a string\n    # with a unit (e.g. \"512MB\"), or a string percentage of the total disk\n    # space (e.g. \"10%\")\n    keepBytes = \"512MB\"\n    # keepDuration can be an integer number of seconds (e.g. 172800), or a\n    # string duration (e.g. \"48h\")\n    keepDuration = \"48h\"\n    filters = [ \"type==source.local\", \"type==exec.cachemount\", \"type==source.git.checkout\"]\n  [[worker.oci.gcpolicy]]\n    all = true\n    keepBytes = 1024000000\n\n[worker.containerd]\n  address = \"/run/containerd/containerd.sock\"\n  enabled = true\n  platforms = [ \"linux/amd64\", \"linux/arm64\" ]\n  namespace = \"buildkit\"\n  gc = true\n  # gckeepstorage sets storage limit for default gc profile, in bytes.\n  gckeepstorage = 9000\n  # maintain a pool of reusable CNI network namespaces to amortize the overhead\n  # of allocating and releasing the namespaces\n  cniPoolSize = 16\n\n  [worker.containerd.labels]\n    \"foo\" = \"bar\"\n\n  # configure the containerd runtime\n  [worker.containerd.runtime]\n    name = \"io.containerd.runc.v2\"\n    path = \"/path/to/containerd/runc/shim\"\n    options = { BinaryName = \"runc\" }\n\n  [[worker.containerd.gcpolicy]]\n    keepBytes = 512000000\n    keepDuration = 172800\n    filters = [ \"type==source.local\", \"type==exec.cachemount\", \"type==source.git.checkout\"]\n  [[worker.containerd.gcpolicy]]\n    all = true\n    keepBytes = 1024000000\n\n# registry configures a new Docker register used for cache import or output.\n[registry.\"docker.io\"]\n  # mirror configuration to handle path in case a mirror registry requires a /project path rather than just a host:port\n  mirrors = [\"yourmirror.local:5000\", \"core.harbor.domain/proxy.docker.io\"]\n  http = true\n  insecure = true\n  ca=[\"/etc/config/myca.pem\"]\n  [[registry.\"docker.io\".keypair]]\n    key=\"/etc/config/key.pem\"\n    cert=\"/etc/config/cert.pem\"\n\n# optionally mirror configuration can be done by defining it as a registry.\n[registry.\"yourmirror.local:5000\"]\n  http = true\n\n# Frontend control\n[frontend.\"dockerfile.v0\"]\n  enabled = true\n\n[frontend.\"gateway.v0\"]\n  enabled = true\n\n  # If allowedRepositories is empty, all gateway sources are allowed.\n  # Otherwise, only the listed repositories are allowed as a gateway source.\n  # \n  # NOTE: Only the repository name (without tag) is compared.\n  #\n  # Example:\n  # allowedRepositories = [ \"docker-registry.wikimedia.org/repos/releng/blubber/buildkit\" ]\n  allowedRepositories = []\n\n[system]\n  # how often buildkit scans for changes in the supported emulated platforms\n  platformsCacheMaxAge = \"1h\"\n```",
  "title": "buildkitd.toml | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/",
  "markdown": "# Continuous integration with Docker | Docker Docs\n\nContinuous Integration (CI) is the part of the development process where you're looking to get your code changes merged with the main branch of the project. At this point, development teams run tests and builds to vet that the code changes don't cause any unwanted or unexpected behaviors.\n\n![Git branches about to get merged](https://docs.docker.com/build/ci/images/continuous-integration.svg)\n\nThere are several uses for Docker at this stage of development, even if you don't end up packaging your application as a container image.\n\nContainers are reproducible, isolated environments that yield predictable results. Building and testing your application in a Docker container makes it easier to prevent unexpected behaviors from occurring. Using a Dockerfile, you define the exact requirements for the build environment, including programming runtimes, operating system, binaries, and more.\n\nUsing Docker to manage your build environment also eases maintenance. For example, updating to a new version of a programming runtime can be as simple as changing a tag or digest in a Dockerfile. No need to SSH into a pet VM to manually reinstall a newer version and update the related configuration files.\n\nAdditionally, just as you expect third-party open source packages to be secure, the same should go for your build environment. You can scan and index a builder image, just like you would for any other containerized application.\n\nThe following links provide instructions for how you can get started using Docker for building your applications in CI:\n\n*   [GitHub Actions](https://docs.github.com/en/actions/creating-actions/creating-a-docker-container-action)\n*   [GitLab](https://docs.gitlab.com/runner/executors/docker.html)\n*   [Circle CI](https://circleci.com/docs/using-docker/)\n*   [Render](https://render.com/docs/docker)\n\n### [Docker in Docker](#docker-in-docker)\n\nYou can also use a Dockerized build environment to build container images using Docker. That is, your build environment runs inside a container which itself is equipped to run Docker builds. This method is referred to as \"Docker in Docker\".\n\nDocker provides an official [Docker image](https://hub.docker.com/_/docker) that you can use for this purpose.\n\nDocker maintains a set of official GitHub Actions that you can use to build, annotate, and push container images on the GitHub Actions platform. See [Introduction to GitHub Actions](https://docs.docker.com/build/ci/github-actions/) to learn more and get started.",
  "title": "Continuous integration with Docker | Docker Docs\n",
  "description": "Using Docker for continuous integration",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/",
  "markdown": "# Introduction to GitHub Actions | Docker Docs\n\nGitHub Actions is a popular CI/CD platform for automating your build, test, and deployment pipeline. Docker provides a set of official GitHub Actions for you to use in your workflows. These official actions are reusable, easy-to-use components for building, annotating, and pushing images.\n\nThe following GitHub Actions are available:\n\n*   [Build and push Docker images](https://github.com/marketplace/actions/build-and-push-docker-images): build and push Docker images with BuildKit.\n*   [Docker Login](https://github.com/marketplace/actions/docker-login): sign in to a Docker registry.\n*   [Docker Setup Buildx](https://github.com/marketplace/actions/docker-setup-buildx): initiates a BuildKit builder.\n*   [Docker Metadata action](https://github.com/marketplace/actions/docker-metadata-action): extracts metadata from Git reference and GitHub events.\n*   [Docker Setup QEMU](https://github.com/marketplace/actions/docker-setup-qemu): installs [QEMU](https://github.com/qemu/qemu) static binaries for multi-arch builds.\n*   [Docker Buildx Bake](https://github.com/marketplace/actions/docker-buildx-bake): enables using high-level builds with [Bake](https://docs.docker.com/build/bake/).\n*   [Docker Scout](https://github.com/docker/scout-action): analyze Docker images for security vulnerabilities.\n\nUsing Docker's actions provides an easy-to-use interface, while still allowing flexibility for customizing build parameters.\n\nIf you're looking for examples on how to use the Docker GitHub Actions, refer to the following sections:\n\n*   [Add image annotations with GitHub Actions](https://docs.docker.com/build/ci/github-actions/annotations/)\n    \n*   [Add SBOM and provenance attestations with GitHub Actions](https://docs.docker.com/build/ci/github-actions/attestations/)\n    \n*   [Cache management with GitHub Actions](https://docs.docker.com/build/ci/github-actions/cache/)\n    \n*   [Configuring your GitHub Actions builder](https://docs.docker.com/build/ci/github-actions/configure-builder/)\n    \n*   [Copy image between registries with GitHub Actions](https://docs.docker.com/build/ci/github-actions/copy-image-registries/)\n    \n*   [Export to Docker with GitHub Actions](https://docs.docker.com/build/ci/github-actions/export-docker/)\n    \n*   [GitHub Actions build summary](https://docs.docker.com/build/ci/github-actions/build-summary/)\n    \n*   [Local registry with GitHub Actions](https://docs.docker.com/build/ci/github-actions/local-registry/)\n    \n*   [Manage tags and labels with GitHub Actions](https://docs.docker.com/build/ci/github-actions/manage-tags-labels/)\n    \n*   [Multi-platform image with GitHub Actions](https://docs.docker.com/build/ci/github-actions/multi-platform/)\n    \n*   [Named contexts with GitHub Actions](https://docs.docker.com/build/ci/github-actions/named-contexts/)\n    \n*   [Push to multiple registries with GitHub Actions](https://docs.docker.com/build/ci/github-actions/push-multi-registries/)\n    \n*   [Reproducible builds with GitHub Actions](https://docs.docker.com/build/ci/github-actions/reproducible-builds/)\n    \n*   [Share built image between jobs with GitHub Actions](https://docs.docker.com/build/ci/github-actions/share-image-jobs/)\n    \n*   [Test before push with GitHub Actions](https://docs.docker.com/build/ci/github-actions/test-before-push/)\n    \n*   [Update Docker Hub description with GitHub Actions](https://docs.docker.com/build/ci/github-actions/update-dockerhub-desc/)\n    \n*   [Using secrets with GitHub Actions](https://docs.docker.com/build/ci/github-actions/secrets/)\n    \n\nThis tutorial walks you through the process of setting up and using Docker GitHub Actions for building Docker images, and pushing images to Docker Hub. You will complete the following steps:\n\n1.  Create a new repository on GitHub.\n2.  Define the GitHub Actions workflow.\n3.  Run the workflow.\n\nTo follow this tutorial, you need a Docker ID and a GitHub account.\n\n### [Step one: Create the repository](#step-one-create-the-repository)\n\nCreate a GitHub repository and configure the Docker Hub credentials.\n\n1.  Create a new GitHub repository using [this template repository](https://github.com/dvdksn/clockbox/generate).\n    \n    The repository contains a simple Dockerfile, and nothing else. Feel free to use another repository containing a working Dockerfile if you prefer.\n    \n2.  Open the repository **Settings**, and go to **Secrets and variables** > **Actions**.\n    \n3.  Create a new **Repository variable** named `DOCKER_USERNAME` and your Docker ID as value.\n    \n4.  Create a new [Personal Access Token (PAT)](https://docs.docker.com/security/for-developers/access-tokens/#create-an-access-token) for Docker Hub. You can name this token `clockboxci`.\n    \n5.  Add the PAT as a **Repository secret** in your GitHub repository, with the name `DOCKERHUB_TOKEN`.\n    \n\nWith your repository created, and credentials configured, you're now ready for action!\n\n### [Step two: Set up the workflow](#step-two-set-up-the-workflow)\n\nSet up your GitHub Actions workflow for building and pushing the image to Docker Hub.\n\n1.  Go to your repository on GitHub and then select the **Actions** tab.\n    \n2.  Select **set up a workflow yourself**.\n    \n    This takes you to a page for creating a new GitHub actions workflow file in your repository, under `.github/workflows/main.yml` by default.\n    \n3.  In the editor window, copy and paste the following YAML configuration.\n    \n    *   `name`: the name of this workflow.\n    *   `on.push.branches`: specifies that this workflow should run on every push event for the branches in the list.\n    *   `jobs`: creates a job ID (`build`) and declares the type of machine that the job should run on.\n\nFor more information about the YAML syntax used here, see [Workflow syntax for GitHub Actions](https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions).\n\n### [Step three: Define the workflow steps](#step-three-define-the-workflow-steps)\n\nNow the essentials: what steps to run, and in what order to run them.\n\nThe previous YAML snippet contains a sequence of steps that:\n\n1.  Signs in to Docker Hub, using the [Docker Login](https://github.com/marketplace/actions/docker-login) action and your Docker Hub credentials.\n    \n2.  Creates a BuildKit builder instance using the [Docker Setup Buildx](https://github.com/marketplace/actions/docker-setup-buildx) action.\n    \n3.  Builds the container image and pushes it to the Docker Hub repository, using [Build and push Docker images](https://github.com/marketplace/actions/build-and-push-docker-images).\n    \n    The `with` key lists a number of input parameters that configures the step:\n    \n    *   `push`: tells the action to upload the image to a registry after building it.\n    *   `tags`: tags that specify where to push the image.\n\nAdd these steps to your workflow file. The full workflow configuration should look as follows:\n\n### [Run the workflow](#run-the-workflow)\n\nSave the workflow file and run the job.\n\n1.  Select **Commit changes...** and push the changes to the `main` branch.\n    \n    After pushing the commit, the workflow starts automatically.\n    \n2.  Go to the **Actions** tab. It displays the workflow.\n    \n    Selecting the workflow shows you the breakdown of all the steps.\n    \n3.  When the workflow is complete, go to your [repositories on Docker Hub](https://hub.docker.com/repositories).\n    \n    If you see the new repository in that list, it means the GitHub Actions successfully pushed the image to Docker Hub!\n    \n\nThis tutorial has shown you how to create a simple GitHub Actions workflow, using the official Docker actions, to build and push an image to Docker Hub.\n\nThere are many more things you can do to customize your workflow to better suit your needs. To learn more about some of the more advanced use cases, take a look at the advanced examples, such as [building multi-platform images](https://docs.docker.com/build/ci/github-actions/multi-platform/), or [using cache storage backends](https://docs.docker.com/build/ci/github-actions/cache/) and also how to [configure your builder](https://docs.docker.com/build/ci/github-actions/configure-builder/).",
  "title": "Introduction to GitHub Actions | Docker Docs\n",
  "description": "Docker maintains a set of official GitHub Actions for building Docker images.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/share-image-jobs/",
  "markdown": "# Share built image between jobs with GitHub Actions\n\nAs each job is isolated in its own runner, you can't use your built image between jobs, except if you're using [self-hosted runners](https://docs.github.com/en/actions/hosting-your-own-runners/about-self-hosted-runners) However, you can [pass data between jobs](https://docs.github.com/en/actions/using-workflows/storing-workflow-data-as-artifacts#passing-data-between-jobs-in-a-workflow) in a workflow using the [actions/upload-artifact](https://github.com/actions/upload-artifact) and [actions/download-artifact](https://github.com/actions/download-artifact) actions:\n\n```\nname: ci\n\non:\n  push:\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n      \n      - name: Build and export\n        uses: docker/build-push-action@v6\n        with:\n          tags: myimage:latest\n          outputs: type=docker,dest=/tmp/myimage.tar\n      \n      - name: Upload artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: myimage\n          path: /tmp/myimage.tar\n\n  use:\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Download artifact\n        uses: actions/download-artifact@v4\n        with:\n          name: myimage\n          path: /tmp\n      \n      - name: Load image\n        run: |\n          docker load --input /tmp/myimage.tar\n          docker image ls -a          \n```",
  "title": "Share built image between jobs with GitHub Actions | Docker Docs\n",
  "description": "Share an image between runners without pushing to a registry",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/build-summary/",
  "markdown": "# GitHub Actions build summary | Docker Docs\n\nDocker's GitHub Actions for building and pushing images generate a job summary for your build that outlines the execution and materials used:\n\n*   A summary showing the Dockerfile used, the build duration, and cache utilization\n*   Inputs for the build, such as build arguments, tags, labels, and build contexts\n*   For builds with [Bake](https://docs.docker.com/build/bake/), the full bake definition for the build\n\n![A GitHub Actions build summary](https://docs.docker.com/build/ci/images/gha_build_summary.png)\n\nJob summaries for Docker builds appear automatically if you use the following versions of the [Build and push Docker images](https://github.com/marketplace/actions/build-and-push-docker-images) or [Docker Buildx Bake](https://github.com/marketplace/actions/docker-buildx-bake) GitHub Actions:\n\n*   `docker/build-push-action@v6`\n*   `docker/bake-action@v5`\n\nTo view the job summary, open the details page for the job in GitHub after the job has finished. The summary is available for both failed and successful builds. In the case of a failed build, the summary also displays the error message that caused the build to fail:\n\n![Builds summary error message](https://docs.docker.com/build/ci/images/build_summary_error.png)\n\nIntroduced in Docker Desktop version 4.31\n\n> **Beta feature**\n> \n> Import builds is currently in [Beta](https://docs.docker.com/release-lifecycle/#Beta).\n\nThe job summary includes a link for downloading a build record archive for the run. The build record archive is a ZIP file containing the details about a build (or builds, if you use `docker/bake-action` to build multiple targets). You can import this build record archive into Docker Desktop, which gives you a powerful, graphical interface for further analyzing the build's performance via the [Docker Desktop **Builds** view](https://docs.docker.com/desktop/use-desktop/builds/).\n\nTo import the build record archive into Docker Desktop:\n\n1.  Download and install [Docker Desktop](https://docs.docker.com/get-docker/).\n    \n2.  Download the build record archive from the job summary in GitHub Actions.\n    \n3.  Open the **Builds** view in Docker Desktop.\n    \n4.  Select the **Import build** button, and then browse for the `.zip` archive job summary that you downloaded. Alternatively, you can drag-and-drop the build record archive ZIP file onto the Docker Desktop window after opening the import build dialog.\n    \n5.  Select **Import** to add the build records.\n    \n\nAfter a few seconds, the builds from the GitHub Actions run appear under the **Completed builds** tab in the Builds view. To inspect a build and see a detailed view of all the inputs, results, build steps, and cache utilization, select the item in the list.\n\nTo disable job summaries, set the `DOCKER_BUILD_SUMMARY` environment variable in the YAML configuration for your build step:\n\nTo disable the upload of the build record archive to GitHub, set the `DOCKER_BUILD_RECORD_UPLOAD` environment variable in the YAML configuration for your build step:\n\nWith this configuration, the build summary is still generated, but does not contain a link to download the build record archive.\n\nBuild summaries are currently not supported for:\n\n*   Builds using [Docker Build Cloud](https://docs.docker.com/build-cloud/). Support for Docker Build Cloud is planned for a future release.\n*   Repositories hosted on GitHub Enterprise Servers. Summaries can only be viewed for repositories hosted on GitHub.com.",
  "title": "GitHub Actions build summary | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/named-contexts/",
  "markdown": "# Named contexts with GitHub Actions\n\nYou can define [additional build contexts](https://docs.docker.com/reference/cli/docker/buildx/build/#build-context), and access them in your Dockerfile with `FROM name` or `--from=name`. When Dockerfile defines a stage with the same name it's overwritten.\n\nThis can be useful with GitHub Actions to reuse results from other builds or pin an image to a specific tag in your workflow.\n\nReplace `alpine:latest` with a pinned one:\n\nBy default, the [Docker Setup Buildx](https://github.com/marketplace/actions/docker-setup-buildx) action uses `docker-container` as a build driver, so built Docker images aren't loaded automatically.\n\nWith named contexts you can reuse the built image:\n\nAs shown in the previous section we are not using the default [`docker-container` driver](https://docs.docker.com/build/drivers/docker-container/) for building with named contexts. That's because this driver can't load an image from the Docker store as it's isolated. To solve this problem you can use a [local registry](https://docs.docker.com/build/ci/github-actions/local-registry/) to push your base image in your workflow:",
  "title": "Named contexts with GitHub Actions | Docker Docs\n",
  "description": "Use additional contexts in multi-stage builds with GitHub Actions",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/copy-image-registries/",
  "markdown": "# Copy image between registries with GitHub Actions\n\n```\nname: ci\n\non:\n  push:\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n      \n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n      \n      - name: Login to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ vars.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      \n      - name: Login to GitHub Container Registry\n        uses: docker/login-action@v3\n        with:\n          registry: ghcr.io\n          username: ${{ github.repository_owner }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n      \n      - name: Build and push\n        uses: docker/build-push-action@v6\n        with:\n          platforms: linux/amd64,linux/arm64\n          push: true\n          tags: |\n            user/app:latest\n            user/app:1.0.0            \n      \n      - name: Push image to GHCR\n        run: |\n          docker buildx imagetools create \\\n            --tag ghcr.io/user/app:latest \\\n            --tag ghcr.io/user/app:1.0.0 \\\n            user/app:latest          \n```",
  "title": "Copy image between registries with GitHub Actions | Docker Docs\n",
  "description": "Build multi-platform images and copy them between registries with GitHub Actions",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/configure-builder/",
  "markdown": "# Configuring your GitHub Actions builder\n\nThis page contains instructions on configuring your BuildKit instances when using our [Setup Buildx Action](https://github.com/docker/setup-buildx-action).\n\nBy default, the action will attempt to use the latest version of [Buildx](https://github.com/docker/buildx) available on the GitHub Runner (the build client) and the latest release of [BuildKit](https://github.com/moby/buildkit) (the build server).\n\nTo pin to a specific version of Buildx, use the `version` input. For example, to pin to Buildx v0.10.0:\n\nTo pin to a specific version of BuildKit, use the `image` option in the `driver-opts` input. For example, to pin to BuildKit v0.11.0:\n\nTo display BuildKit container logs when using the `docker-container` driver, you must either [enable step debug logging](https://docs.github.com/en/actions/monitoring-and-troubleshooting-workflows/enabling-debug-logging#enabling-step-debug-logging), or set the `--debug` buildkitd flag in the [Docker Setup Buildx](https://github.com/marketplace/actions/docker-setup-buildx) action:\n\nLogs will be available at the end of a job:\n\n![BuildKit container logs](https://docs.docker.com/build/ci/github-actions/images/buildkit-container-logs.png)\n\nYou can provide a [BuildKit configuration](https://docs.docker.com/build/buildkit/toml-configuration/) to your builder if you're using the [`docker-container` driver](https://docs.docker.com/build/drivers/docker-container/) (default) with the `config` or `config-inline` inputs:\n\n### [Registry mirror](#registry-mirror)\n\nYou can configure a registry mirror using an inline block directly in your workflow with the `config-inline` input:\n\nFor more information about using a registry mirror, see [Registry mirror](https://docs.docker.com/build/buildkit/configure/#registry-mirror).\n\n### [Max parallelism](#max-parallelism)\n\nYou can limit the parallelism of the BuildKit solver which is particularly useful for low-powered machines.\n\nYou can use the `config-inline` input like the previous example, or you can use a dedicated BuildKit config file from your repository if you want with the `config` input:\n\nBuildx supports running builds on multiple machines. This is useful for building [multi-platform images](https://docs.docker.com/build/building/multi-platform/) on native nodes for more complicated cases that aren't handled by QEMU. Building on native nodes generally has better performance, and allows you to distribute the build across multiple machines.\n\nYou can append nodes to the builder you're creating using the `append` option. It takes input in the form of a YAML string document to remove limitations intrinsically linked to GitHub Actions: you can only use strings in the input fields:\n\n| Name | Type | Description |\n| --- | --- | --- |\n| `name` | String | [Name of the node](https://docs.docker.com/reference/cli/docker/buildx/create/#node). If empty, it's the name of the builder it belongs to, with an index number suffix. This is useful to set it if you want to modify/remove a node in an underlying step of you workflow. |\n| `endpoint` | String | [Docker context or endpoint](https://docs.docker.com/reference/cli/docker/buildx/create/#description) of the node to add to the builder |\n| `driver-opts` | List | List of additional [driver-specific options](https://docs.docker.com/reference/cli/docker/buildx/create/#driver-opt) |\n| `buildkitd-flags` | String | [Flags for buildkitd](https://docs.docker.com/reference/cli/docker/buildx/create/#buildkitd-flags) daemon |\n| `platforms` | String | Fixed [platforms](https://docs.docker.com/reference/cli/docker/buildx/create/#platform) for the node. If not empty, values take priority over the detected ones. |\n\nHere is an example using remote nodes with the [`remote` driver](https://docs.docker.com/build/drivers/remote/) and [TLS authentication](#tls-authentication):\n\nThe following examples show how to handle authentication for remote builders, using SSH or TLS.\n\n### [SSH authentication](#ssh-authentication)\n\nTo be able to connect to an SSH endpoint using the [`docker-container` driver](https://docs.docker.com/build/drivers/docker-container/), you have to set up the SSH private key and configuration on the GitHub Runner:\n\n### [TLS authentication](#tls-authentication)\n\nYou can also [set up a remote BuildKit instance](https://docs.docker.com/build/drivers/remote/#example-remote-buildkit-in-docker-container) using the remote driver. To ease the integration in your workflow, you can use an environment variables that sets up authentication using the BuildKit client certificates for the `tcp://`:\n\n*   `BUILDER_NODE_<idx>_AUTH_TLS_CACERT`\n*   `BUILDER_NODE_<idx>_AUTH_TLS_CERT`\n*   `BUILDER_NODE_<idx>_AUTH_TLS_KEY`\n\nThe `<idx>` placeholder is the position of the node in the list of nodes.\n\nIf you don't have the Docker CLI installed on the GitHub Runner, the Buildx binary gets invoked directly, instead of calling it as a Docker CLI plugin. This can be useful if you want to use the `kubernetes` driver in your self-hosted runner:\n\nThe following example shows how you can select different builders for different jobs.\n\nAn example scenario where this might be useful is when you are using a monorepo, and you want to pinpoint different packages to specific builders. For example, some packages may be particularly resource-intensive to build and require more compute. Or they require a builder equipped with a particular capability or hardware.\n\nFor more information about remote builder, see [`remote` driver](https://docs.docker.com/build/drivers/remote/) and the [append builder nodes example](#append-additional-nodes-to-the-builder).",
  "title": "Configuring your GitHub Actions builder | Docker Docs\n",
  "description": "Configuring BuildKit instances for building in CI with GitHub Actions",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/attestations/",
  "markdown": "# Add SBOM and provenance attestations with GitHub Actions\n\nSoftware Bill of Material (SBOM) and provenance [attestations](https://docs.docker.com/build/attestations/) add metadata about the contents of your image, and how it was built.\n\nAttestations are supported with version 4 and later of the `docker/build-push-action`.\n\nThe `docker/build-push-action` GitHub Action automatically adds provenance attestations to your image, with the following conditions:\n\n*   If the GitHub repository is public, provenance attestations with `mode=max` are automatically added to the image.\n*   If the GitHub repository is private, provenance attestations with `mode=min` are automatically added to the image.\n*   If you're using the [`docker` exporter](https://docs.docker.com/build/exporters/oci-docker/), or you're loading the build results to the runner with `load: true`, no attestations are added to the image. These output formats don't support attestations.\n\n> **Warning**\n> \n> If you're using `docker/build-push-action` to build images for code in a public GitHub repository, the provenance attestations attached to your image by default contains the values of build arguments. If you're misusing build arguments to pass secrets to your build, such as user credentials or authentication tokens, those secrets are exposed in the provenance attestation. Refactor your build to pass those secrets using [secret mounts](https://docs.docker.com/reference/cli/docker/buildx/build/#secret) instead. Also remember to rotate any secrets you may have exposed.\n\nIt's recommended that you build your images with max-level provenance attestations. Private repositories only add min-level provenance by default, but you can manually override the provenance level by setting the `provenance` input on the `docker/build-push-action` GitHub Action to `mode=max`.\n\nNote that adding attestations to an image means you must push the image to a registry directly, as opposed to loading the image to the local image store of the runner. This is because the local image store doesn't support loading images with attestations.\n\nSBOM attestations aren't automatically added to the image. To add SBOM attestations, set the `sbom` input of the `docker/build-push-action` to true.\n\nNote that adding attestations to an image means you must push the image to a registry directly, as opposed to loading the image to the local image store of the runner. This is because the local image store doesn't support loading images with attestations.",
  "title": "Add SBOM and provenance attestations with GitHub Actions | Docker Docs\n",
  "description": "Add SBOM and provenance attestations to your images with GitHub Actions",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/update-dockerhub-desc/",
  "markdown": "# Update Docker Hub description with GitHub Actions\n\nYou can update the Docker Hub repository description using a third party action called [Docker Hub Description](https://github.com/peter-evans/dockerhub-description) with this action:",
  "title": "Update Docker Hub description with GitHub Actions | Docker Docs\n",
  "description": "How to update the repository README in Docker Hub using with GitHub Actions",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/environment-variables/",
  "markdown": "# Overview | Docker Docs\n\nBy leveraging environment variables and interpolation in Docker Compose, you can create versatile and reusable configurations, making your Dockerized applications easier to manage and deploy across different environments.\n\n> **Tip**\n> \n> Before using environment variables, read through all of the information first to get a full picture of environment variables in Docker Compose.\n\nThis section covers:\n\n*   [How to set environment variables within your container's environment](https://docs.docker.com/compose/environment-variables/set-environment-variables/).\n*   [How environment variable precedence works within your container's environment](https://docs.docker.com/compose/environment-variables/envvars-precedence/).\n*   [Pre-defined environment variables](https://docs.docker.com/compose/environment-variables/envvars/).\n\nIt also covers:\n\n*   How [interpolation](https://docs.docker.com/compose/environment-variables/variable-interpolation/) can be used to set variables within your Compose file and how it relates to a container's environment.\n*   Some [best practices](https://docs.docker.com/compose/environment-variables/best-practices/).",
  "title": "Overview | Docker Docs\n",
  "description": "Explainer on the ways to set, use and manage environment variables in Compose",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/annotations/",
  "markdown": "# Add image annotations with GitHub Actions\n\nAnnotations let you specify arbitrary metadata for OCI image components, such as manifests, indexes, and descriptors.\n\nTo add annotations when building images with GitHub Actions, use the [metadata-action](https://github.com/docker/metadata-action#overwrite-labels-and-annotations) to automatically create OCI-compliant annotations. The metadata action creates an `annotations` output that you can reference, both with [build-push-action](https://github.com/docker/build-push-action/) and [bake-action](https://github.com/docker/bake-action/).\n\nBy default, annotations are placed on image manifests. To configure the [annotation level](https://docs.docker.com/build/building/annotations/#specify-annotation-level), set the `DOCKER_METADATA_ANNOTATIONS_LEVELS` environment variable on the `metadata-action` step to a comma-separated list of all the levels that you want to annotate. For example, setting `DOCKER_METADATA_ANNOTATIONS_LEVELS` to `index` results in annotations on the image index instead of the manifests.\n\nThe following example creates annotations on both the image index and manifests.",
  "title": "Add image annotations with GitHub Actions | Docker Docs\n",
  "description": "Add OCI annotations to image components using GitHub Actions",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/intro/features-uses/",
  "markdown": "# Why use Compose? | Docker Docs\n\nUsing Docker Compose offers several benefits that streamline the development, deployment, and management of containerized applications:\n\n*   Simplified control: Docker Compose allows you to define and manage multi-container applications in a single YAML file. This simplifies the complex task of orchestrating and coordinating various services, making it easier to manage and replicate your application environment.\n    \n*   Efficient collaboration: Docker Compose configuration files are easy to share, facilitating collaboration among developers, operations teams, and other stakeholders. This collaborative approach leads to smoother workflows, faster issue resolution, and increased overall efficiency.\n    \n*   Rapid application development: Compose caches the configuration used to create a container. When you restart a service that has not changed, Compose re-uses the existing containers. Re-using containers means that you can make changes to your environment very quickly.\n    \n*   Portability across environments: Compose supports variables in the Compose file. You can use these variables to customize your composition for different environments, or different users.\n    \n*   Extensive community and support: Docker Compose benefits from a vibrant and active community, which means abundant resources, tutorials, and support. This community-driven ecosystem contributes to the continuous improvement of Docker Compose and helps users troubleshoot issues effectively.\n    \n\nCompose can be used in many different ways. Some common use cases are outlined below.\n\n### [Development environments](#development-environments)\n\nWhen you're developing software, the ability to run an application in an isolated environment and interact with it is crucial. The Compose command line tool can be used to create the environment and interact with it.\n\nThe [Compose file](https://docs.docker.com/compose/compose-file/) provides a way to document and configure all of the application's service dependencies (databases, queues, caches, web service APIs, etc). Using the Compose command line tool you can create and start one or more containers for each dependency with a single command (`docker compose up`).\n\nTogether, these features provide a convenient way for you to get started on a project. Compose can reduce a multi-page \"developer getting started guide\" to a single machine-readable Compose file and a few commands.\n\n### [Automated testing environments](#automated-testing-environments)\n\nAn important part of any Continuous Deployment or Continuous Integration process is the automated test suite. Automated end-to-end testing requires an environment in which to run tests. Compose provides a convenient way to create and destroy isolated testing environments for your test suite. By defining the full environment in a [Compose file](https://docs.docker.com/compose/compose-file/), you can create and destroy these environments in just a few commands:\n\n### [Single host deployments](#single-host-deployments)\n\nCompose has traditionally been focused on development and testing workflows, but with each release we're making progress on more production-oriented features.\n\nFor details on using production-oriented features, see [Compose in production](https://docs.docker.com/compose/production/).\n\n*   [Learn about the history of Compose](https://docs.docker.com/compose/intro/history/)\n*   [Understand how Compose works](https://docs.docker.com/compose/compose-application-model/)\n*   [Quickstart](https://docs.docker.com/compose/gettingstarted/)",
  "title": "Why use Compose? | Docker Docs\n",
  "description": "Key benefits and use cases of Docker Compose",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/ci/github-actions/reproducible-builds/",
  "markdown": "# Reproducible builds with GitHub Actions\n\n`SOURCE_DATE_EPOCH` is a [standardized environment variable](https://reproducible-builds.org/docs/source-date-epoch/) for instructing build tools to produce a reproducible output. Setting the environment variable for a build makes the timestamps in the image index, config, and file metadata reflect the specified Unix time.\n\nTo set the environment variable in GitHub Actions, use the built-in `env` property on the build step.\n\nThe following example sets the `SOURCE_DATE_EPOCH` variable to 0, Unix epoch.\n\nThe following example sets `SOURCE_DATE_EPOCH` to the Git commit timestamp.\n\nFor more information about the `SOURCE_DATE_EPOCH` support in BuildKit, see [BuildKit documentation](https://github.com/moby/buildkit/blob/master/docs/build-repro.md#source_date_epoch).",
  "title": "Reproducible builds with GitHub Actions | Docker Docs\n",
  "description": "How to create reproducible builds in GitHub Actions using the SOURCE_EPOCH environment variable",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/release-notes/",
  "markdown": "# Build release notes | Docker Docs\n\nThis page contains information about the new features, improvements, and bug fixes in [Docker Buildx](https://github.com/docker/buildx).\n\n_2024-04-18_\n\nThe full release note for this release is available [on GitHub](https://github.com/docker/buildx/releases/tag/v0.14.0).\n\n### [Enhancements](#enhancements)\n\n*   Add support for `--print=lint` (experimental). [docker/buildx#2404](https://github.com/docker/buildx/pull/2404), [docker/buildx#2406](https://github.com/docker/buildx/pull/2406)\n*   Fix JSON formatting for custom implementations of print sub-requests in frontends. [docker/buildx#2374](https://github.com/docker/buildx/pull/2374)\n*   Provenance records are now set when building with `--metadata-file`. [docker/buildx#2280](https://github.com/docker/buildx/pull/2280)\n*   Add [Git authentication support](https://docs.docker.com/build/bake/remote-definition/#remote-definition-in-a-private-repository) for remote definitions. [docker/buildx#2363](https://github.com/docker/buildx/pull/2363)\n*   New `default-load` driver option for the `docker-container`, `remote`, and `kubernetes` drivers to load build results to the Docker Engine image store by default. [docker/buildx#2259](https://github.com/docker/buildx/pull/2259)\n*   Add `requests.ephemeral-storage`, `limits.ephemeral-storage` and `schedulername` options to the [`kubernetes` driver](https://docs.docker.com/build/drivers/kubernetes/). [docker/buildx#2370](https://github.com/docker/buildx/pull/2370), [docker/buildx#2415](https://github.com/docker/buildx/pull/2415)\n*   Add `indexof` function for `docker-bake.hcl` files. [docker/buildx#2384](https://github.com/docker/buildx/pull/2384)\n*   OpenTelemetry metrics for Buildx now measure durations of idle time, image exports, run operations, and image transfers for image source operations during build. [docker/buildx#2316](https://github.com/docker/buildx/pull/2316), [docker/buildx#2317](https://github.com/docker/buildx/pull/2317), [docker/buildx#2323](https://github.com/docker/buildx/pull/2323), [docker/buildx#2271](https://github.com/docker/buildx/pull/2271)\n*   Build progress metrics to the OpenTelemetry endpoint associated with the `desktop-linux` context no longer requires Buildx in experimental mode (`BUILDX_EXPERIMENTAL=1`). [docker/buildx#2344](https://github.com/docker/buildx/pull/2344)\n\n### [Bug fixes](#bug-fixes)\n\n*   Fix `--load` and `--push` incorrectly overriding outputs when used with multiple Bake file definitions. [docker/buildx#2336](https://github.com/docker/buildx/pull/2336)\n*   Fix build from stdin with experimental mode enabled. [docker/buildx#2394](https://github.com/docker/buildx/pull/2394)\n*   Fix an issue where delegated traces could be duplicated. [docker/buildx#2362](https://github.com/docker/buildx/pull/2362)\n\n### [Packaging updates](#packaging-updates)\n\n*   Compose support has been updated to [v2.26.1](https://github.com/docker/compose/releases/tag/v2.26.1) (via [`compose-go` v2.0.2](https://github.com/compose-spec/compose-go/releases/tag/v2.0.2)). [docker/buildx#2391](https://github.com/docker/buildx/pull/2391)\n\n_2024-03-13_\n\nThe full release note for this release is available [on GitHub](https://github.com/docker/buildx/releases/tag/v0.13.1).\n\n### [Bug fixes](#bug-fixes-1)\n\n*   Fix connecting to `docker-container://` and `kube-pod://` style URLs with remote driver. [docker/buildx#2327](https://github.com/docker/buildx/pull/2327)\n*   Fix handling of `--push` with Bake when a target has already defined a non-image output. [docker/buildx#2330](https://github.com/docker/buildx/pull/2330)\n\n_2024-03-06_\n\nThe full release note for this release is available [on GitHub](https://github.com/docker/buildx/releases/tag/v0.13.0).\n\n### [New](#new)\n\n*   New `docker buildx dial-stdio` command for directly contacting BuildKit daemon of the configured builder instance. [docker/buildx#2112](https://github.com/docker/buildx/pull/2112)\n*   Windows container builders can now be created using the `remote` driver and npipe connections. [docker/buildx#2287](https://github.com/docker/buildx/pull/2287)\n*   Npipe URL scheme is now supported on Windows. [docker/buildx#2250](https://github.com/docker/buildx/pull/2250)\n*   Experimental Buildx can now export OpenTelemetry metrics for build duration and transfer sizes. [docker/buildx#2235](https://github.com/docker/buildx/pull/2235), [docker/buildx#2258](https://github.com/docker/buildx/pull/2258) [docker/buildx#2225](https://github.com/docker/buildx/pull/2225) [docker/buildx#2224](https://github.com/docker/buildx/pull/2224) [docker/buildx#2155](https://github.com/docker/buildx/pull/2155)\n\n### [Enhancements](#enhancements-1)\n\n*   Bake command now supports defining `shm-size` and `ulimit` values. [docker/buildx#2279](https://github.com/docker/buildx/pull/2279), [docker/buildx#2242](https://github.com/docker/buildx/pull/2242)\n*   Better handling of connecting to unhealthy nodes with remote driver. [docker/buildx#2130](https://github.com/docker/buildx/pull/2130)\n*   Builders using the `docker-container` and `kubernetes` drivers now allow `network.host` entitlement by default (allowing access to the container's network). [docker/buildx#2266](https://github.com/docker/buildx/pull/2266)\n*   Builds can now use multiple outputs with a single command (requires BuildKit v0.13+). [docker/buildx#2290](https://github.com/docker/buildx/pull/2290), [docker/buildx#2302](https://github.com/docker/buildx/pull/2302)\n*   Default Git repository path is now found via configured tracking branch. [docker/buildx#2146](https://github.com/docker/buildx/pull/2146)\n*   Fix possible cache invalidation when using linked targets in Bake. [docker/buildx#2265](https://github.com/docker/buildx/pull/2265)\n*   Fixes for Git repository path sanitization in WSL. [docker/buildx#2167](https://github.com/docker/buildx/pull/2167)\n*   Multiple builders can now be removed with a single command. [docker/buildx#2140](https://github.com/docker/buildx/pull/2140)\n*   New cancellation signal handling via Unix socket. [docker/buildx#2184](https://github.com/docker/buildx/pull/2184) [docker/buildx#2289](https://github.com/docker/buildx/pull/2289)\n*   The Compose spec support has been updated to v2.0.0-rc.8. [docker/buildx#2205](https://github.com/docker/buildx/pull/2205)\n*   The `--config` flag for `docker buildx create` was renamed to `--buildkitd-config`. [docker/buildx#2268](https://github.com/docker/buildx/pull/2268)\n*   The `--metadata-file` flag for `docker buildx build` can now also return build reference that can be used for further build debugging, for example, in Docker Desktop. [docker/buildx#2263](https://github.com/docker/buildx/pull/2263)\n*   The `docker buildx bake` command now shares the same authentication provider for all targets for improved performance. [docker/buildx#2147](https://github.com/docker/buildx/pull/2147)\n*   The `docker buildx imagetools inspect` command now shows DSSE-signed SBOM and Provenance attestations. [docker/buildx#2194](https://github.com/docker/buildx/pull/2194)\n*   The `docker buildx ls` command now supports `--format` options for controlling the output. [docker/buildx#1787](https://github.com/docker/buildx/pull/1787)\n*   The `docker-container` driver now supports driver options for defining restart policy for BuildKit container. [docker/buildx#1271](https://github.com/docker/buildx/pull/1271)\n*   VCS attributes exported from Buildx now include the local directory sub-paths if they're relative to the current Git repository. [docker/buildx#2156](https://github.com/docker/buildx/pull/2156)\n*   `--add-host` flag now permits a `=` separator for IPv6 addresses. [docker/buildx#2121](https://github.com/docker/buildx/pull/2121)\n\n### [Bug fixes](#bug-fixes-2)\n\n*   Fix additional output when exporting progress with `--progress=rawjson` [docker/buildx#2252](https://github.com/docker/buildx/pull/2252)\n*   Fix possible console warnings on Windows. [docker/buildx#2238](https://github.com/docker/buildx/pull/2238)\n*   Fix possible inconsistent configuration merge order when using Bake with many configurations. [docker/buildx#2237](https://github.com/docker/buildx/pull/2237)\n*   Fix possible panic in the `docker buildx imagetools create` command. [docker/buildx#2230](https://github.com/docker/buildx/pull/2230)\n\n_2024-01-12_\n\nThe full release note for this release is available [on GitHub](https://github.com/docker/buildx/releases/tag/v0.12.1).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements)\n\n*   Fix incorrect validation of some `--driver-opt` values that could cause a panic and corrupt state to be stored. [docker/buildx#2176](https://github.com/docker/buildx/pull/2176)\n\n_2023-11-16_\n\nThe full release note for this release is available [on GitHub](https://github.com/docker/buildx/releases/tag/v0.12.0).\n\n### [New](#new-1)\n\n*   New `--annotation` flag for the `buildx build`, and an `annotations` key in the Bake file, that lets you add OCI Annotations to build results. [#2020](https://github.com/docker/buildx/pull/2020), [#2098](https://github.com/docker/buildx/pull/2098)\n*   New experimental debugging features, including a new `debug` command and an interactive debugging console. This feature currently requires setting `BUILDX_EXPERIMENTAL=1`. [#2006](https://github.com/docker/buildx/pull/2006), [#1896](https://github.com/docker/buildx/pull/1896), [#1970](https://github.com/docker/buildx/pull/1970), [#1914](https://github.com/docker/buildx/pull/1914), [#2026](https://github.com/docker/buildx/pull/2026), [#2086](https://github.com/docker/buildx/pull/2086)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-1)\n\n*   The special `host-gateway` IP mapping can now be used with the `--add-host` flag during build. [#1894](https://github.com/docker/buildx/pull/1894), [#2083](https://github.com/docker/buildx/pull/2083)\n*   Bake now allows adding local source files when building from remote definition. [#1838](https://github.com/docker/buildx/pull/1838)\n*   The status of uploading build results to Docker is now shown interactively on progress bar. [#1994](https://github.com/docker/buildx/pull/1994)\n*   Error handling has been improved when bootstrapping multi-node build clusters. [#1869](https://github.com/docker/buildx/pull/1869)\n*   The `buildx imagetools create` command now allows adding annotation when creating new images in the registry. [#1965](https://github.com/docker/buildx/pull/1965)\n*   OpenTelemetry build trace delegation from buildx is now possible with Docker and Remote driver. [#2034](https://github.com/docker/buildx/pull/2034)\n*   Bake command now shows all files where the build definition was loaded from on the progress bar. [#2076](https://github.com/docker/buildx/pull/2076)\n*   Bake files now allow the same attributes to be defined in multiple definition files. [#1062](https://github.com/docker/buildx/pull/1062)\n*   Using the Bake command with a remote definition now allows this definition to use local Dockerfiles. [#2015](https://github.com/docker/buildx/pull/2015)\n*   Docker container driver now explicitly sets BuildKit config path to make sure configurations are loaded from same location for both mainline and rootless images. [#2093](https://github.com/docker/buildx/pull/2093)\n*   Improve performance of detecting when BuildKit instance has completed booting. [#1934](https://github.com/docker/buildx/pull/1934)\n*   Container driver now accepts many new driver options for defining the resource limits for BuildKit container. [#2048](https://github.com/docker/buildx/pull/2048)\n*   Inspection commands formatting has been improved. [#2068](https://github.com/docker/buildx/pull/2068)\n*   Error messages about driver capabilities have been improved. [#1998](https://github.com/docker/buildx/pull/1998)\n*   Improve errors when invoking Bake command without targets. [#2100](https://github.com/docker/buildx/pull/2100)\n*   Allow enabling debug logs with environment variables when running in standalone mode. [#1821](https://github.com/docker/buildx/pull/1821)\n*   When using Docker driver the default image resolve mode has been updated to prefer local Docker images for backward compatibility. [#1886](https://github.com/docker/buildx/pull/1886)\n*   Kubernetes driver now allows setting custom annotations and labels to the BuildKit deployments and pods. [#1938](https://github.com/docker/buildx/pull/1938)\n*   Kubernetes driver now allows setting authentication token with endpoint configuration. [#1891](https://github.com/docker/buildx/pull/1891)\n*   Fix possible issue with chained targets in Bake that could result in build failing or local source for a target uploaded multiple times. [#2113](https://github.com/docker/buildx/pull/2113)\n*   Fix issue when accessing global target properties when using the matrix feature of the Bake command. [#2106](https://github.com/docker/buildx/pull/2106)\n*   Fixes for formatting validation of certain build flags [#2040](https://github.com/docker/buildx/pull/2040)\n*   Fixes to avoid locking certain commands unnecessarily while booting builder nodes. [#2066](https://github.com/docker/buildx/pull/2066)\n*   Fix cases where multiple builds try to bootstrap the same builder instance in parallel. [#2000](https://github.com/docker/buildx/pull/2000)\n*   Fix cases where errors on uploading build results to Docker could be dropped in some cases. [#1927](https://github.com/docker/buildx/pull/1927)\n*   Fix detecting capabilities for missing attestation support based on build output. [#1988](https://github.com/docker/buildx/pull/1988)\n*   Fix the build for loading in Bake remote definition to not show up in build history records. [#1961](https://github.com/docker/buildx/pull/1961), [#1954](https://github.com/docker/buildx/pull/1954)\n*   Fix errors when building Compose files using the that define profiles with Bake. [#1903](https://github.com/docker/buildx/pull/1903)\n*   Fix possible time correction errors on progress bar. [#1968](https://github.com/docker/buildx/pull/1968)\n*   Fix passing custom cgroup parent to builds that used the new controller interface. [#1913](https://github.com/docker/buildx/pull/1913)\n\n### [Packaging](#packaging)\n\n*   Compose support has been updated to 1.20, enabling \"include\" functionality when using the Bake command. [#1971](https://github.com/docker/buildx/pull/1971), [#2065](https://github.com/docker/buildx/pull/2065), [#2094](https://github.com/docker/buildx/pull/2094)\n\n_2023-07-18_\n\nThe full release note for this release is available [on GitHub](https://github.com/docker/buildx/releases/tag/v0.11.2).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-2)\n\n*   Fix a regression that caused buildx to not read the `KUBECONFIG` path from the instance store. [docker/buildx#1941](https://github.com/docker/buildx/pull/1941)\n*   Fix a regression with result handle builds showing up in the build history incorrectly. [docker/buildx#1954](https://github.com/docker/buildx/pull/1954)\n\n_2023-07-05_\n\nThe full release note for this release is available [on GitHub](https://github.com/docker/buildx/releases/tag/v0.11.1).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-3)\n\n*   Fix a regression for bake where services in profiles would not be loaded. [docker/buildx#1903](https://github.com/docker/buildx/pull/1903)\n*   Fix a regression where `--cgroup-parent` option had no effect during build. [docker/buildx#1913](https://github.com/docker/buildx/pull/1913)\n*   Fix a regression where valid docker contexts could fail buildx builder name validation. [docker/buildx#1879](https://github.com/docker/buildx/pull/1879)\n*   Fix a possible panic when terminal is resized during the build. [docker/buildx#1929](https://github.com/docker/buildx/pull/1929)\n\n_2023-06-13_\n\nThe full release note for this release is available [on GitHub](https://github.com/docker/buildx/releases/tag/v0.11.0).\n\n### [New](#new-2)\n\n*   Bake now supports [matrix builds](https://docs.docker.com/build/bake/reference/#targetmatrix). The new matrix field on `target` lets you create multiple similar targets to remove duplication in bake files. [docker/buildx#1690](https://github.com/docker/buildx/pull/1690)\n*   New experimental `--detach` flag for running builds in detached mode. [docker/buildx#1296](https://github.com/docker/buildx/pull/1296), [docker/buildx#1620](https://github.com/docker/buildx/pull/1620), [docker/buildx#1614](https://github.com/docker/buildx/pull/1614), [docker/buildx#1737](https://github.com/docker/buildx/pull/1737), [docker/buildx#1755](https://github.com/docker/buildx/pull/1755)\n*   New experimental [debug monitor mode](https://github.com/docker/buildx/blob/v0.11.0-rc1/docs/guides/debugging.md) that lets you start a debug session in your builds. [docker/buildx#1626](https://github.com/docker/buildx/pull/1626), [docker/buildx#1640](https://github.com/docker/buildx/pull/1640)\n*   New [`EXPERIMENTAL_BUILDKIT_SOURCE_POLICY` environment variable](https://docs.docker.com/build/building/variables/#experimental_buildkit_source_policy) for applying a BuildKit source policy file. [docker/buildx#1628](https://github.com/docker/buildx/pull/1628)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-4)\n\n*   `--load` now supports loading multi-platform images when the containerd image store is enabled. [docker/buildx#1813](https://github.com/docker/buildx/pull/1813)\n*   Build progress output now displays the name of the builder being used. [docker/buildx#1177](https://github.com/docker/buildx/pull/1177)\n*   Bake now supports detecting `compose.{yml,yaml}` files. [docker/buildx#1752](https://github.com/docker/buildx/pull/1752)\n*   Bake now supports new compose build keys `dockerfile_inline` and `additional_contexts`. [docker/buildx#1784](https://github.com/docker/buildx/pull/1784)\n*   Bake now supports replace HCL function. [docker/buildx#1720](https://github.com/docker/buildx/pull/1720)\n*   Bake now allows merging multiple similar attestation parameters into a single parameter to allow overriding with a single global value. [docker/buildx#1699](https://github.com/docker/buildx/pull/1699)\n*   Initial support for shell completion. [docker/buildx#1727](https://github.com/docker/buildx/pull/1727)\n*   BuildKit versions now correctly display in `buildx ls` and `buildx inspect` for builders using the `docker` driver. [docker/buildx#1552](https://github.com/docker/buildx/pull/1552)\n*   Display additional builder node details in buildx inspect view. [docker/buildx#1440](https://github.com/docker/buildx/pull/1440), [docker/buildx#1854](https://github.com/docker/buildx/pull/1874)\n*   Builders using the `remote` driver allow using TLS without proving its own key/cert (if BuildKit remote is configured to support it) [docker/buildx#1693](https://github.com/docker/buildx/pull/1693)\n*   Builders using the `kubernetes` driver support a new `serviceaccount` option, which sets the `serviceAccountName` of the Kubernetes pod. [docker/buildx#1597](https://github.com/docker/buildx/pull/1597)\n*   Builders using the `kubernetes` driver support the `proxy-url` option in the kubeconfig file. [docker/buildx#1780](https://github.com/docker/buildx/pull/1780)\n*   Builders using the `kubernetes` are now automatically assigned a node name if no name is explicitly provided. [docker/buildx#1673](https://github.com/docker/buildx/pull/1673)\n*   Fix invalid path when writing certificates for `docker-container` driver on Windows. [docker/buildx#1831](https://github.com/docker/buildx/pull/1831)\n*   Fix bake failure when remote bake file is accessed using SSH. [docker/buildx#1711](https://github.com/docker/buildx/pull/1711), [docker/buildx#1734](https://github.com/docker/buildx/pull/1734)\n*   Fix bake failure when remote bake context is incorrectly resolved. [docker/buildx#1783](https://github.com/docker/buildx/pull/1783)\n*   Fix path resolution of `BAKE_CMD_CONTEXT` and `cwd://` paths in bake contexts. [docker/buildx#1840](https://github.com/docker/buildx/pull/1840)\n*   Fix mixed OCI and Docker media types when creating images using `buildx imagetools create`. [docker/buildx#1797](https://github.com/docker/buildx/pull/1797)\n*   Fix mismatched image id between `--iidfile` and `-q`. [docker/buildx#1844](https://github.com/docker/buildx/pull/1844)\n*   Fix AWS authentication when mixing static creds and IAM profiles. [docker/buildx#1816](https://github.com/docker/buildx/pull/1816)\n\n_2023-03-06_\n\n> **Note**\n> \n> Buildx v0.10 enables support for a minimal [SLSA Provenance](https://slsa.dev/provenance/) attestation, which requires support for [OCI-compliant](https://github.com/opencontainers/image-spec) multi-platform images. This may introduce issues with registry and runtime support (e.g. [Google Cloud Run and AWS Lambda](https://github.com/docker/buildx/issues/1533)). You can optionally disable the default provenance attestation functionality using `--provenance=false`.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-5)\n\n*   Add `BUILDX_NO_DEFAULT_ATTESTATIONS` as alternative to `--provenance false`. [docker/buildx#1645](https://github.com/docker/buildx/issues/1645)\n*   Disable dirty Git checkout detection by default for performance. Can be enabled with `BUILDX_GIT_CHECK_DIRTY` opt-in. [docker/buildx#1650](https://github.com/docker/buildx/issues/1650)\n*   Strip credentials from VCS hint URL before sending to BuildKit. [docker/buildx#1664](https://github.com/docker/buildx/issues/1664)\n\n_2023-02-16_\n\n> **Note**\n> \n> Buildx v0.10 enables support for a minimal [SLSA Provenance](https://slsa.dev/provenance/) attestation, which requires support for [OCI-compliant](https://github.com/opencontainers/image-spec) multi-platform images. This may introduce issues with registry and runtime support (e.g. [Google Cloud Run and AWS Lambda](https://github.com/docker/buildx/issues/1533)). You can optionally disable the default provenance attestation functionality using `--provenance=false`.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-6)\n\n*   Fix reachable commit and warnings on collecting Git provenance info. [docker/buildx#1592](https://github.com/docker/buildx/issues/1592), [docker/buildx#1634](https://github.com/docker/buildx/issues/1634)\n*   Fix a regression where docker context was not being validated. [docker/buildx#1596](https://github.com/docker/buildx/issues/1596)\n*   Fix function resolution with JSON bake definition. [docker/buildx#1605](https://github.com/docker/buildx/issues/1605)\n*   Fix case where original HCL bake diagnostic is discarded. [docker/buildx#1607](https://github.com/docker/buildx/issues/1607)\n*   Fix labels not correctly set with bake and compose file. [docker/buildx#1631](https://github.com/docker/buildx/issues/1631)\n\n_2023-01-30_\n\n> **Note**\n> \n> Buildx v0.10 enables support for a minimal [SLSA Provenance](https://slsa.dev/provenance/) attestation, which requires support for [OCI-compliant](https://github.com/opencontainers/image-spec) multi-platform images. This may introduce issues with registry and runtime support (e.g. [Google Cloud Run and AWS Lambda](https://github.com/docker/buildx/issues/1533)). You can optionally disable the default provenance attestation functionality using `--provenance=false`.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-7)\n\n*   Fix preferred platforms order not taken into account in multi-node builds. [docker/buildx#1561](https://github.com/docker/buildx/issues/1561)\n*   Fix possible panic on handling `SOURCE_DATE_EPOCH` environment variable. [docker/buildx#1564](https://github.com/docker/buildx/issues/1564)\n*   Fix possible push error on multi-node manifest merge since BuildKit v0.11 on some registries. [docker/buildx#1566](https://github.com/docker/buildx/issues/1566)\n*   Improve warnings on collecting Git provenance info. [docker/buildx#1568](https://github.com/docker/buildx/issues/1568)\n\n_2023-01-27_\n\n> **Note**\n> \n> Buildx v0.10 enables support for a minimal [SLSA Provenance](https://slsa.dev/provenance/) attestation, which requires support for [OCI-compliant](https://github.com/opencontainers/image-spec) multi-platform images. This may introduce issues with registry and runtime support (e.g. [Google Cloud Run and AWS Lambda](https://github.com/docker/buildx/issues/1533)). You can optionally disable the default provenance attestation functionality using `--provenance=false`.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-8)\n\n*   Fix sending the correct origin URL as `vsc:source` metadata. [docker/buildx#1548](https://github.com/docker/buildx/issues/1548)\n*   Fix possible panic from data-race. [docker/buildx#1504](https://github.com/docker/buildx/issues/1504)\n*   Fix regression with `rm --all-inactive`. [docker/buildx#1547](https://github.com/docker/buildx/issues/1547)\n*   Improve attestation access in `imagetools inspect` by lazily loading data. [docker/buildx#1546](https://github.com/docker/buildx/issues/1546)\n*   Correctly mark capabilities request as internal. [docker/buildx#1538](https://github.com/docker/buildx/issues/1538)\n*   Detect invalid attestation configuration. [docker/buildx#1545](https://github.com/docker/buildx/issues/1545)\n*   Update containerd patches to fix possible push regression affecting `imagetools` commands. [docker/buildx#1559](https://github.com/docker/buildx/issues/1559)\n\n_2023-01-10_\n\n> **Note**\n> \n> Buildx v0.10 enables support for a minimal [SLSA Provenance](https://slsa.dev/provenance/) attestation, which requires support for [OCI-compliant](https://github.com/opencontainers/image-spec) multi-platform images. This may introduce issues with registry and runtime support (e.g. [Google Cloud Run and AWS Lambda](https://github.com/docker/buildx/issues/1533)). You can optionally disable the default provenance attestation functionality using `--provenance=false`.\n\n### [New](#new-3)\n\n*   The `buildx build` command supports new `--attest` flag, along with shorthands `--sbom` and `--provenance`, for adding attestations for your current build. [docker/buildx#1412](https://github.com/docker/buildx/issues/1412) [docker/buildx#1475](https://github.com/docker/buildx/issues/1475)\n    *   `--attest type=sbom` or `--sbom=true` adds [SBOM attestations](https://docs.docker.com/build/attestations/sbom/).\n    *   `--attest type=provenance` or `--provenance=true` adds [SLSA provenance attestation](https://docs.docker.com/build/attestations/slsa-provenance/).\n    *   When creating OCI images, a minimal provenance attestation is included with the image by default.\n*   When building with BuildKit that supports provenance attestations Buildx will automatically share the version control information of your build context, so it can be shown in provenance for later debugging. Previously this only happened when building from a Git URL directly. To opt-out of this behavior you can set `BUILDX_GIT_INFO=0`. Optionally you can also automatically define labels with VCS info by setting `BUILDX_GIT_LABELS=1`. [docker/buildx#1462](https://github.com/docker/buildx/issues/1462), [docker/buildx#1297](https://github.com/docker/buildx), [docker/buildx#1341](https://github.com/docker/buildx/issues/1341), [docker/buildx#1468](https://github.com/docker/buildx), [docker/buildx#1477](https://github.com/docker/buildx/issues/1477)\n*   Named contexts with `--build-context` now support `oci-layout://` protocol for initializing the context with a value of a local OCI layout directory. E.g. `--build-context stagename=oci-layout://path/to/dir`. This feature requires BuildKit v0.11.0+ and Dockerfile 1.5.0+. [docker/buildx#1456](https://github.com/docker/buildx/issues/1456)\n*   Bake now supports [resource interpolation](https://docs.docker.com/build/bake/inheritance/#reusing-single-attribute-from-targets) where you can reuse the values from other target definitions. [docker/buildx#1434](https://github.com/docker/buildx/issues/1434)\n*   Buildx will now automatically forward `SOURCE_DATE_EPOCH` environment variable if it is defined in your environment. This feature is meant to be used with updated [reproducible builds](https://github.com/moby/buildkit/blob/master/docs/build-repro.md) support in BuildKit v0.11.0+. [docker/buildx#1482](https://github.com/docker/buildx/issues/1482)\n*   Buildx now remembers the last activity for a builder for better organization of builder instances. [docker/buildx#1439](https://github.com/docker/buildx/issues/1439)\n*   Bake definition now supports null values for [variables](https://docs.docker.com/build/bake/reference/#variable) and [labels](https://docs.docker.com/build/bake/reference/#targetlabels) for build arguments and labels to use the defaults set in the Dockerfile. [docker/buildx#1449](https://github.com/docker/buildx/issues/1449)\n*   The [`buildx imagetools inspect` command](https://docs.docker.com/reference/cli/docker/buildx/imagetools/inspect/) now supports showing SBOM and Provenance data. [docker/buildx#1444](https://github.com/docker/buildx/issues/1444), [docker/buildx#1498](https://github.com/docker/buildx/issues/1498)\n*   Increase performance of `ls` command and inspect flows. [docker/buildx#1430](https://github.com/docker/buildx/issues/1430), [docker/buildx#1454](https://github.com/docker/buildx/issues/1454), [docker/buildx#1455](https://github.com/docker/buildx/issues/1455), [docker/buildx#1345](https://github.com/docker/buildx/issues/1345)\n*   Adding extra hosts with [Docker driver](https://docs.docker.com/build/drivers/docker/) now supports Docker-specific `host-gateway` special value. [docker/buildx#1446](https://github.com/docker/buildx/issues/1446)\n*   [OCI exporter](https://docs.docker.com/build/exporters/oci-docker/) now supports `tar=false` option for exporting OCI format directly in a directory. [docker/buildx#1420](https://github.com/docker/buildx/issues/1420)\n\n### [Upgrades](#upgrades)\n\n*   Updated the Compose Specification to 1.6.0. [docker/buildx#1387](https://github.com/docker/buildx/issues/1387)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-9)\n\n*   `--invoke` can now load default launch environment from the image metadata. [docker/buildx#1324](https://github.com/docker/buildx/issues/1324)\n*   Fix container driver behavior in regards to UserNS. [docker/buildx#1368](https://github.com/docker/buildx/issues/1368)\n*   Fix possible panic in Bake when using wrong variable value type. [docker/buildx#1442](https://github.com/docker/buildx/issues/1442)\n*   Fix possible panic in `imagetools inspect`. [docker/buildx#1441](https://github.com/docker/buildx/issues/1441) [docker/buildx#1406](https://github.com/docker/buildx/issues/1406)\n*   Fix sending empty `--add-host` value to BuildKit by default. [docker/buildx#1457](https://github.com/docker/buildx/issues/1457)\n*   Fix handling progress prefixes with progress groups. [docker/buildx#1305](https://github.com/docker/buildx/issues/1305)\n*   Fix recursively resolving groups in Bake. [docker/buildx#1313](https://github.com/docker/buildx/issues/1313)\n*   Fix possible wrong indentation on multi-node builder manifests. [docker/buildx#1396](https://github.com/docker/buildx/issues/1396)\n*   Fix possible panic from missing OpenTelemetry configuration. [docker/buildx#1383](https://github.com/docker/buildx/issues/1383)\n*   Fix `--progress=tty` behavior when TTY is not available. [docker/buildx#1371](https://github.com/docker/buildx/issues/1371)\n*   Fix connection error conditions in `prune` and `du` commands. [docker/buildx#1307](https://github.com/docker/buildx/issues/1307)\n\n_2022-08-18_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-10)\n\n*   The `inspect` command now displays the BuildKit version in use. [docker/buildx#1279](https://github.com/docker/buildx/issues/1279)\n*   Fixed a regression when building Compose files that contain services without a build block. [docker/buildx#1277](https://github.com/docker/buildx/issues/1277)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.9.1).\n\n_2022-08-17_\n\n### [New](#new-4)\n\n*   Support for a new [`remote` driver](https://docs.docker.com/build/drivers/remote/) that you can use to connect to any already running BuildKit instance. [docker/buildx#1078](https://github.com/docker/buildx/issues/1078), [docker/buildx#1093](https://github.com/docker/buildx/issues/1093), [docker/buildx#1094](https://github.com/docker/buildx/issues/1094), [docker/buildx#1103](https://github.com/docker/buildx/issues/1103), [docker/buildx#1134](https://github.com/docker/buildx/issues/1134), [docker/buildx#1204](https://github.com/docker/buildx/issues/1204)\n*   You can now load Dockerfile from standard input even when the build context is coming from external Git or HTTP URL. [docker/buildx#994](https://github.com/docker/buildx/issues/994)\n*   Build commands now support new the build context type `oci-layout://` for loading [build context from local OCI layout directories](https://docs.docker.com/reference/cli/docker/buildx/build/#source-oci-layout). Note that this feature depends on an unreleased BuildKit feature and builder instance from `moby/buildkit:master` needs to be used until BuildKit v0.11 is released. [docker/buildx#1173](https://github.com/docker/buildx/issues/1173)\n*   You can now use the new `--print` flag to run helper functions supported by the BuildKit frontend performing the build and print their results. You can use this feature in Dockerfile to show the build arguments and secrets that the current build supports with `--print=outline` and list all available Dockerfile stages with `--print=targets`. This feature is experimental for gathering early feedback and requires enabling `BUILDX_EXPERIMENTAL=1` environment variable. We plan to update/extend this feature in the future without keeping backward compatibility. [docker/buildx#1100](https://github.com/docker/buildx/issues/1100), [docker/buildx#1272](https://github.com/docker/buildx/issues/1272)\n*   You can now use the new `--invoke` flag to launch interactive containers from build results for an interactive debugging cycle. You can reload these containers with code changes or restore them to an initial state from the special monitor mode. This feature is experimental for gathering early feedback and requires enabling `BUILDX_EXPERIMENTAL=1` environment variable. We plan to update/extend this feature in the future without enabling backward compatibility. [docker/buildx#1168](https://github.com/docker/buildx/issues/1168), [docker/buildx#1257](https://github.com/docker/buildx), [docker/buildx#1259](https://github.com/docker/buildx/issues/1259)\n*   Buildx now understands environment variable `BUILDKIT_COLORS` and `NO_COLOR` to customize/disable the colors of interactive build progressbar. [docker/buildx#1230](https://github.com/docker/buildx/issues/1230), [docker/buildx#1226](https://github.com/docker/buildx/issues/1226)\n*   `buildx ls` command now shows the current BuildKit version of each builder instance. [docker/buildx#998](https://github.com/docker/buildx/issues/998)\n*   The `bake` command now loads `.env` file automatically when building Compose files for compatibility. [docker/buildx#1261](https://github.com/docker/buildx/issues/1261)\n*   Bake now supports Compose files with `cache_to` definition. [docker/buildx#1155](https://github.com/docker/buildx/issues/1155)\n*   Bake now supports new builtin function `timestamp()` to access current time. [docker/buildx#1214](https://github.com/docker/buildx/issues/1214)\n*   Bake now supports Compose build secrets definition. [docker/buildx#1069](https://github.com/docker/buildx/issues/1069)\n*   Additional build context configuration is now supported in Compose files via `x-bake`. [docker/buildx#1256](https://github.com/docker/buildx/issues/1256)\n*   Inspecting builder now shows current driver options configuration. [docker/buildx#1003](https://github.com/docker/buildx/issues/1003), [docker/buildx#1066](https://github.com/docker/buildx/issues/1066)\n\n### [Updates](#updates)\n\n*   Updated the Compose Specification to 1.4.0. [docker/buildx#1246](https://github.com/docker/buildx/issues/1246), [docker/buildx#1251](https://github.com/docker/buildx/issues/1251)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-11)\n\n*   The `buildx ls` command output has been updated with better access to errors from different builders. [docker/buildx#1109](https://github.com/docker/buildx/issues/1109)\n*   The `buildx create` command now performs additional validation of builder parameters to avoid creating a builder instance with invalid configuration. [docker/buildx#1206](https://github.com/docker/buildx/issues/1206)\n*   The `buildx imagetools create` command can now create new multi-platform images even if the source subimages are located on different repositories or registries. [docker/buildx#1137](https://github.com/docker/buildx/issues/1137)\n*   You can now set the default builder config that is used when creating builder instances without passing custom `--config` value. [docker/buildx#1111](https://github.com/docker/buildx/issues/1111)\n*   Docker driver can now detect if `dockerd` instance supports initially disabled Buildkit features like multi-platform images. [docker/buildx#1260](https://github.com/docker/buildx/issues/1260), [docker/buildx#1262](https://github.com/docker/buildx/issues/1262)\n*   Compose files using targets with `.` in the name are now converted to use `_` so the selector keys can still be used in such targets. [docker/buildx#1011](https://github.com/docker/buildx/issues/1011)\n*   Included an additional validation for checking valid driver configurations. [docker/buildx#1188](https://github.com/docker/buildx/issues/1188), [docker/buildx#1273](https://github.com/docker/buildx/issues/1273)\n*   The `remove` command now displays the removed builder and forbids removing context builders. [docker/buildx#1128](https://github.com/docker/buildx/issues/1128)\n*   Enable Azure authentication when using Kubernetes driver. [docker/buildx#974](https://github.com/docker/buildx/issues/974)\n*   Add tolerations handling for kubernetes driver. [docker/buildx#1045](https://github.com/docker/buildx/issues/1045) [docker/buildx#1053](https://github.com/docker/buildx/issues/1053)\n*   Replace deprecated seccomp annotations with `securityContext` in the `kubernetes` driver. [docker/buildx#1052](https://github.com/docker/buildx/issues/1052)\n*   Fix panic on handling manifests with nil platform. [docker/buildx#1144](https://github.com/docker/buildx/issues/1144)\n*   Fix using duration filter with `prune` command. [docker/buildx#1252](https://github.com/docker/buildx/issues/1252)\n*   Fix merging multiple JSON files on Bake definition. [docker/buildx#1025](https://github.com/docker/buildx/issues/1025)\n*   Fix issues with implicit builder created from Docker context had invalid configuration or dropped connection. [docker/buildx#1129](https://github.com/docker/buildx/issues/1129)\n*   Fix conditions for showing no-output warning when using named contexts. [docker/buildx#968](https://github.com/docker/buildx/issues/968)\n*   Fix duplicating builders when builder instance and docker context have the same name. [docker/buildx#1131](https://github.com/docker/buildx/issues/1131)\n*   Fix printing unnecessary SSH warning logs. [docker/buildx#1085](https://github.com/docker/buildx/issues/1085)\n*   Fix possible panic when using an empty variable block with Bake JSON definition. [docker/buildx#1080](https://github.com/docker/buildx/issues/1080)\n*   Fix image tools commands not handling `--builder` flag correctly. [docker/buildx#1067](https://github.com/docker/buildx/issues/1067)\n*   Fix using custom image together with rootless option. [docker/buildx#1063](https://github.com/docker/buildx/issues/1063)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.9.0).\n\n_2022-04-04_\n\n### [Updates](#updates-1)\n\n*   Update Compose spec used by `buildx bake` to v1.2.1 to fix parsing ports definition. [docker/buildx#1033](https://github.com/docker/buildx/issues/1033)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-12)\n\n*   Fix possible crash on handling progress streams from BuildKit v0.10. [docker/buildx#1042](https://github.com/docker/buildx/issues/1042)\n*   Fix parsing groups in `buildx bake` when already loaded by a parent group. [docker/buildx#1021](https://github.com/docker/buildx/issues/1021)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.8.2).\n\n_2022-03-21_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-13)\n\n*   Fix possible panic on handling build context scanning errors. [docker/buildx#1005](https://github.com/docker/buildx/issues/1005)\n*   Allow `.` on Compose target names in `buildx bake` for backward compatibility. [docker/buildx#1018](https://github.com/docker/buildx/issues/1018)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.8.1).\n\n_2022-03-09_\n\n### [New](#new-5)\n\n*   Build command now accepts `--build-context` flag to [define additional named build contexts](https://docs.docker.com/reference/cli/docker/buildx/build/#build-context) for your builds. [docker/buildx#904](https://github.com/docker/buildx/issues/904)\n*   Bake definitions now support [defining dependencies between targets](https://docs.docker.com/build/bake/contexts/) and using the result of one target in another build. [docker/buildx#928](https://github.com/docker/buildx/issues/928), [docker/buildx#965](https://github.com/docker/buildx/issues/965), [docker/buildx#963](https://github.com/docker/buildx/issues/963), [docker/buildx#962](https://github.com/docker/buildx/issues/962), [docker/buildx#981](https://github.com/docker/buildx/issues/981)\n*   `imagetools inspect` now accepts `--format` flag allowing access to config and buildinfo for specific images. [docker/buildx#854](https://github.com/docker/buildx/issues/854), [docker/buildx#972](https://github.com/docker/buildx/issues/972)\n*   New flag `--no-cache-filter` allows configuring build, so it ignores cache only for specified Dockerfile stages. [docker/buildx#860](https://github.com/docker/buildx/issues/860)\n*   Builds can now show a summary of warnings sets by the building frontend. [docker/buildx#892](https://github.com/docker/buildx/issues/892)\n*   The new build argument `BUILDKIT_INLINE_BUILDINFO_ATTRS` allows opting-in to embed building attributes to resulting image. [docker/buildx#908](https://github.com/docker/buildx/issues/908)\n*   The new flag `--keep-buildkitd` allows keeping BuildKit daemon running when removing a builder\n    *   [docker/buildx#852](https://github.com/docker/buildx/issues/852)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-14)\n\n*   `--metadata-file` output now supports embedded structure types. [docker/buildx#946](https://github.com/docker/buildx/issues/946)\n*   `buildx rm` now accepts new flag `--all-inactive` for removing all builders that are not currently running. [docker/buildx#885](https://github.com/docker/buildx/issues/885)\n*   Proxy config is now read from Docker configuration file and sent with build requests for backward compatibility. [docker/buildx#959](https://github.com/docker/buildx/issues/959)\n*   Support host networking in Compose. [docker/buildx#905](https://github.com/docker/buildx/issues/905), [docker/buildx#880](https://github.com/docker/buildx/issues/880)\n*   Bake files can now be read from stdin with `-f -`. [docker/buildx#864](https://github.com/docker/buildx/issues/864)\n*   `--iidfile` now always writes the image config digest independently of the driver being used (use `--metadata-file` for digest). [docker/buildx#980](https://github.com/docker/buildx/issues/980)\n*   Target names in Bake are now restricted to not use special characters. [docker/buildx#929](https://github.com/docker/buildx/issues/929)\n*   Image manifest digest can be read from metadata when pushed with `docker` driver. [docker/buildx#989](https://github.com/docker/buildx/issues/989)\n*   Fix environment file handling in Compose files. [docker/buildx#905](https://github.com/docker/buildx/issues/905)\n*   Show last access time in `du` command. [docker/buildx#867](https://github.com/docker/buildx/issues/867)\n*   Fix possible double output logs when multiple Bake targets run same build steps. [docker/buildx#977](https://github.com/docker/buildx/issues/977)\n*   Fix possible errors on multi-node builder building multiple targets with mixed platform. [docker/buildx#985](https://github.com/docker/buildx/issues/985)\n*   Fix some nested inheritance cases in Bake. [docker/buildx#914](https://github.com/docker/buildx/issues/914)\n*   Fix printing default group on Bake files. [docker/buildx#884](https://github.com/docker/buildx/issues/884)\n*   Fix `UsernsMode` when using rootless container. [docker/buildx#887](https://github.com/docker/buildx/issues/887)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.8.0).\n\n_2021-08-25_\n\n### [Fixes](#fixes)\n\n*   Fix issue with matching exclude rules in `.dockerignore`. [docker/buildx#858](https://github.com/docker/buildx/issues/858)\n*   Fix `bake --print` JSON output for current group. [docker/buildx#857](https://github.com/docker/buildx/issues/857)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.7.1).\n\n_2021-11-10_\n\n### [New features](#new-features)\n\n*   TLS certificates from BuildKit configuration are now transferred to build container with `docker-container` and `kubernetes` drivers. [docker/buildx#787](https://github.com/docker/buildx/issues/787)\n*   Builds support `--ulimit` flag for feature parity. [docker/buildx#800](https://github.com/docker/buildx/issues/800)\n*   Builds support `--shm-size` flag for feature parity. [docker/buildx#790](https://github.com/docker/buildx/issues/790)\n*   Builds support `--quiet` for feature parity. [docker/buildx#740](https://github.com/docker/buildx/issues/740)\n*   Builds support `--cgroup-parent` flag for feature parity. [docker/buildx#814](https://github.com/docker/buildx/issues/814)\n*   Bake supports builtin variable `BAKE_LOCAL_PLATFORM`. [docker/buildx#748](https://github.com/docker/buildx/issues/748)\n*   Bake supports `x-bake` extension field in Compose files. [docker/buildx#721](https://github.com/docker/buildx/issues/721)\n*   `kubernetes` driver now supports colon-separated `KUBECONFIG`. [docker/buildx#761](https://github.com/docker/buildx/issues/761)\n*   `kubernetes` driver now supports setting Buildkit config file with `--config`. [docker/buildx#682](https://github.com/docker/buildx/issues/682)\n*   `kubernetes` driver now supports installing QEMU emulators with driver-opt. [docker/buildx#682](https://github.com/docker/buildx/issues/682)\n\n### [Enhancements](#enhancements-2)\n\n*   Allow using custom registry configuration for multi-node pushes from the client. [docker/buildx#825](https://github.com/docker/buildx/issues/825)\n*   Allow using custom registry configuration for `buildx imagetools` command. [docker/buildx#825](https://github.com/docker/buildx/issues/825)\n*   Allow booting builder after creating with `buildx create --bootstrap`. [docker/buildx#692](https://github.com/docker/buildx/issues/692)\n*   Allow `registry:insecure` output option for multi-node pushes. [docker/buildx#825](https://github.com/docker/buildx/issues/825)\n*   BuildKit config and TLS files are now kept in Buildx state directory and reused if BuildKit instance needs to be recreated. [docker/buildx#824](https://github.com/docker/buildx/issues/824)\n*   Ensure different projects use separate destination directories for incremental context transfer for better performance. [docker/buildx#817](https://github.com/docker/buildx/issues/817)\n*   Build containers are now placed on separate cgroup by default. [docker/buildx#782](https://github.com/docker/buildx/issues/782)\n*   Bake now prints the default group with `--print`. [docker/buildx#720](https://github.com/docker/buildx/issues/720)\n*   `docker` driver now dials build session over HTTP for better performance. [docker/buildx#804](https://github.com/docker/buildx/issues/804)\n\n### [Fixes](#fixes-1)\n\n*   Fix using `--iidfile` together with a multi-node push. [docker/buildx#826](https://github.com/docker/buildx/issues/826)\n*   Using `--push` in Bake does not clear other image export options in the file. [docker/buildx#773](https://github.com/docker/buildx/issues/773)\n*   Fix Git URL detection for `buildx bake` when `https` protocol was used. [docker/buildx#822](https://github.com/docker/buildx/issues/822)\n*   Fix pushing image with multiple names on multi-node builds. [docker/buildx#815](https://github.com/docker/buildx/issues/815)\n*   Avoid showing `--builder` flags for commands that don't use it. [docker/buildx#818](https://github.com/docker/buildx/issues/818)\n*   Unsupported build flags now show a warning. [docker/buildx#810](https://github.com/docker/buildx/issues/810)\n*   Fix reporting error details in some OpenTelemetry traces. [docker/buildx#812](https://github.com/docker/buildx/issues/812)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.7.0).\n\n_2021-08-30_\n\n### [Fixes](#fixes-2)\n\n*   Fix BuildKit state volume location for Windows clients. [docker/buildx#751](https://github.com/docker/buildx/issues/751)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.6.3).\n\n_2021-08-21_\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.6.2).\n\n### [Fixes](#fixes-3)\n\n*   Fix connection error showing up in some SSH configurations. [docker/buildx#741](https://github.com/docker/buildx/issues/741)\n\n_2021-07-30_\n\n### [Enhancements](#enhancements-3)\n\n*   Set `ConfigFile` to parse compose files with Bake. [docker/buildx#704](https://github.com/docker/buildx/issues/704)\n\n### [Fixes](#fixes-4)\n\n*   Duplicate progress env var. [docker/buildx#693](https://github.com/docker/buildx/issues/693)\n*   Should ignore nil client. [docker/buildx#686](https://github.com/docker/buildx/issues/686)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.6.1).\n\n_2021-07-16_\n\n### [New features](#new-features-1)\n\n*   Support for OpenTelemetry traces and forwarding Buildx client traces to BuildKit. [docker/buildx#635](https://github.com/docker/buildx/issues/635)\n*   Experimental GitHub Actions remote cache backend with `--cache-to type=gha` and `--cache-from type=gha`. [docker/buildx#535](https://github.com/docker/buildx/issues/535)\n*   New `--metadata-file` flag has been added to build and Bake command that allows saving build result metadata in JSON format. [docker/buildx#605](https://github.com/docker/buildx/issues/605)\n*   This is the first release supporting Windows ARM64. [docker/buildx#654](https://github.com/docker/buildx/issues/654)\n*   This is the first release supporting Linux Risc-V. [docker/buildx#652](https://github.com/docker/buildx/issues/652)\n*   Bake now supports building from remote definition with local files or another remote source as context. [docker/buildx#671](https://github.com/docker/buildx/issues/671)\n*   Bake now allows variables to reference each other and using user functions in variables and vice-versa. [docker/buildx#575](https://github.com/docker/buildx/issues/575), [docker/buildx#539](https://github.com/docker/buildx/issues/539), [docker/buildx#532](https://github.com/docker/buildx/issues/532)\n*   Bake allows defining attributes in the global scope. [docker/buildx#541](https://github.com/docker/buildx/issues/541)\n*   Bake allows variables across multiple files. [docker/buildx#538](https://github.com/docker/buildx/issues/538)\n*   New quiet mode has been added to progress printer. [docker/buildx#558](https://github.com/docker/buildx/issues/558)\n*   `kubernetes` driver now supports defining resources/limits. [docker/buildx#618](https://github.com/docker/buildx/issues/618)\n*   Buildx binaries can now be accessed through [buildx-bin](https://hub.docker.com/r/docker/buildx-bin) Docker image. [docker/buildx#656](https://github.com/docker/buildx/issues/656)\n\n### [Enhancements](#enhancements-4)\n\n*   `docker-container` driver now keeps BuildKit state in volume. Enabling updates with keeping state. [docker/buildx#672](https://github.com/docker/buildx/issues/672)\n*   Compose parser is now based on new [compose-go parser](https://github.com/compose-spec/compose-go) fixing support for some newer syntax. [docker/buildx#669](https://github.com/docker/buildx/issues/669)\n*   SSH socket is now automatically forwarded when building an ssh-based git URL. [docker/buildx#581](https://github.com/docker/buildx/issues/581)\n*   Bake HCL parser has been rewritten. [docker/buildx#645](https://github.com/docker/buildx/issues/645)\n*   Extend HCL support with more functions. [docker/buildx#491](https://github.com/docker/buildx/issues/491) [docker/buildx#503](https://github.com/docker/buildx/issues/503)\n*   Allow secrets from environment variables. [docker/buildx#488](https://github.com/docker/buildx/issues/488)\n*   Builds with an unsupported multi-platform and load configuration now fail fast. [docker/buildx#582](https://github.com/docker/buildx/issues/582)\n*   Store Kubernetes config file to make buildx builder switchable. [docker/buildx#497](https://github.com/docker/buildx/issues/497)\n*   Kubernetes now lists all pods as nodes on inspection. [docker/buildx#477](https://github.com/docker/buildx/issues/477)\n*   Default Rootless image has been set to `moby/buildkit:buildx-stable-1-rootless`. [docker/buildx#480](https://github.com/docker/buildx/issues/480)\n\n### [Fixes](#fixes-5)\n\n*   `imagetools create` command now correctly merges JSON descriptor with old one. [docker/buildx#592](https://github.com/docker/buildx/issues/592)\n*   Fix building with `--network=none` not requiring extra security entitlements. [docker/buildx#531](https://github.com/docker/buildx/issues/531)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.6.0).\n\n_2020-12-15_\n\n### [Fixes](#fixes-6)\n\n*   Fix regression on setting `--platform` on `buildx create` outside `kubernetes` driver. [docker/buildx#475](https://github.com/docker/buildx/issues/475)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.5.1).\n\n_2020-12-15_\n\n### [New features](#new-features-2)\n\n*   The `docker` driver now supports the `--push` flag. [docker/buildx#442](https://github.com/docker/buildx/issues/442)\n*   Bake supports inline Dockerfiles. [docker/buildx#398](https://github.com/docker/buildx/issues/398)\n*   Bake supports building from remote URLs and Git repositories. [docker/buildx#398](https://github.com/docker/buildx/issues/398)\n*   `BUILDX_CONFIG` env var allow users to have separate buildx state from Docker config. [docker/buildx#385](https://github.com/docker/buildx/issues/385)\n*   `BUILDKIT_MULTI_PLATFORM` build arg allows to force building multi-platform return objects even if only one `--platform` specified. [docker/buildx#467](https://github.com/docker/buildx/issues/467)\n\n### [Enhancements](#enhancements-5)\n\n*   Allow `--append` to be used with `kubernetes` driver. [docker/buildx#370](https://github.com/docker/buildx/issues/370)\n*   Build errors show error location in source files and system stacktraces with `--debug`. [docker/buildx#389](https://github.com/docker/buildx/issues/389)\n*   Bake formats HCL errors with source definition. [docker/buildx#391](https://github.com/docker/buildx/issues/391)\n*   Bake allows empty string values in arrays that will be discarded. [docker/buildx#428](https://github.com/docker/buildx/issues/428)\n*   You can now use the Kubernetes cluster config with the `kubernetes` driver. [docker/buildx#368](https://github.com/docker/buildx/issues/368) [docker/buildx#460](https://github.com/docker/buildx/issues/460)\n*   Creates a temporary token for pulling images instead of sharing credentials when possible. [docker/buildx#469](https://github.com/docker/buildx/issues/469)\n*   Ensure credentials are passed when pulling BuildKit container image. [docker/buildx#441](https://github.com/docker/buildx/issues/441) [docker/buildx#433](https://github.com/docker/buildx/issues/433)\n*   Disable user namespace remapping in `docker-container` driver. [docker/buildx#462](https://github.com/docker/buildx/issues/462)\n*   Allow `--builder` flag to switch to default instance. [docker/buildx#425](https://github.com/docker/buildx/issues/425)\n*   Avoid warn on empty `BUILDX_NO_DEFAULT_LOAD` config value. [docker/buildx#390](https://github.com/docker/buildx/issues/390)\n*   Replace error generated by `quiet` option by a warning. [docker/buildx#403](https://github.com/docker/buildx/issues/403)\n*   CI has been switched to GitHub Actions. [docker/buildx#451](https://github.com/docker/buildx/issues/451), [docker/buildx#463](https://github.com/docker/buildx/issues/463), [docker/buildx#466](https://github.com/docker/buildx/issues/466), [docker/buildx#468](https://github.com/docker/buildx/issues/468), [docker/buildx#471](https://github.com/docker/buildx/issues/471)\n\n### [Fixes](#fixes-7)\n\n*   Handle lowercase Dockerfile name as a fallback for backward compatibility. [docker/buildx#444](https://github.com/docker/buildx/issues/444)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.5.0).\n\n_2020-08-22_\n\n### [New features](#new-features-3)\n\n*   Support `cacheonly` exporter. [docker/buildx#337](https://github.com/docker/buildx/issues/337)\n\n### [Enhancements](#enhancements-6)\n\n*   Update `go-cty` to pull in more `stdlib` functions. [docker/buildx#277](https://github.com/docker/buildx/issues/277)\n*   Improve error checking on load. [docker/buildx#281](https://github.com/docker/buildx/issues/281)\n\n### [Fixes](#fixes-8)\n\n*   Fix parsing json config with HCL. [docker/buildx#280](https://github.com/docker/buildx/issues/280)\n*   Ensure `--builder` is wired from root options. [docker/buildx#321](https://github.com/docker/buildx/issues/321)\n*   Remove warning for multi-platform iidfile. [docker/buildx#351](https://github.com/docker/buildx/issues/351)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.4.2).\n\n_2020-05-01_\n\n### [Fixes](#fixes-9)\n\n*   Fix regression on flag parsing. [docker/buildx#268](https://github.com/docker/buildx/issues/268)\n*   Fix using pull and no-cache keys in HCL targets. [docker/buildx#268](https://github.com/docker/buildx/issues/268)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.4.1).\n\n_2020-04-30_\n\n### [New features](#new-features-4)\n\n*   Add `kubernetes` driver. [docker/buildx#167](https://github.com/docker/buildx/issues/167)\n*   New global `--builder` flag to override builder instance for a single command. [docker/buildx#246](https://github.com/docker/buildx/issues/246)\n*   New `prune` and `du` commands for managing local builder cache. [docker/buildx#249](https://github.com/docker/buildx/issues/249)\n*   You can now set the new `pull` and `no-cache` options for HCL targets. [docker/buildx#165](https://github.com/docker/buildx/issues/165)\n\n### [Enhancements](#enhancements-7)\n\n*   Upgrade Bake to HCL2 with support for variables and functions. [docker/buildx#192](https://github.com/docker/buildx/issues/192)\n*   Bake now supports `--load` and `--push`. [docker/buildx#164](https://github.com/docker/buildx/issues/164)\n*   Bake now supports wildcard overrides for multiple targets. [docker/buildx#164](https://github.com/docker/buildx/issues/164)\n*   Container driver allows setting environment variables via `driver-opt`. [docker/buildx#170](https://github.com/docker/buildx/issues/170)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.4.0).\n\n_2019-09-27_\n\n### [Enhancements](#enhancements-8)\n\n*   Handle copying unix sockets instead of erroring. [docker/buildx#155](https://github.com/docker/buildx/issues/155) [moby/buildkit#1144](https://github.com/moby/buildkit/issues/1144)\n\n### [Fixes](#fixes-10)\n\n*   Running Bake with multiple Compose files now merges targets correctly. [docker/buildx#134](https://github.com/docker/buildx/issues/134)\n*   Fix bug when building a Dockerfile from stdin (`build -f -`). [docker/buildx#153](https://github.com/docker/buildx/issues/153)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.3.1).\n\n_2019-08-02_\n\n### [New features](#new-features-5)\n\n*   Custom `buildkitd` daemon flags. [docker/buildx#102](https://github.com/docker/buildx/issues/102)\n*   Driver-specific options on `create`. [docker/buildx#122](https://github.com/docker/buildx/issues/122)\n\n### [Enhancements](#enhancements-9)\n\n*   Environment variables are used in Compose files. [docker/buildx#117](https://github.com/docker/buildx/issues/117)\n*   Bake now honors `--no-cache` and `--pull`. [docker/buildx#118](https://github.com/docker/buildx/issues/118)\n*   Custom BuildKit config file. [docker/buildx#121](https://github.com/docker/buildx/issues/121)\n*   Entitlements support with `build --allow`. [docker/buildx#104](https://github.com/docker/buildx/issues/104)\n\n### [Fixes](#fixes-11)\n\n*   Fix bug where `--build-arg foo` would not read `foo` from environment. [docker/buildx#116](https://github.com/docker/buildx/issues/116)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.3.0).\n\n_2019-05-30_\n\n### [Enhancements](#enhancements-10)\n\n*   Change Compose file handling to require valid service specifications. [docker/buildx#87](https://github.com/docker/buildx/issues/87)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.2.2).\n\n_2019-05-25_\n\n### [New features](#new-features-6)\n\n*   Add `BUILDKIT_PROGRESS` env var. [docker/buildx#69](https://github.com/docker/buildx/issues/69)\n*   Add `local` platform. [docker/buildx#70](https://github.com/docker/buildx/issues/70)\n\n### [Enhancements](#enhancements-11)\n\n*   Keep arm variant if one is defined in the config. [docker/buildx#68](https://github.com/docker/buildx/issues/68)\n*   Make dockerfile relative to context. [docker/buildx#83](https://github.com/docker/buildx/issues/83)\n\n### [Fixes](#fixes-12)\n\n*   Fix parsing target from compose files. [docker/buildx#53](https://github.com/docker/buildx/issues/53)\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.2.1).\n\n_2019-04-25_\n\n### [New features](#new-features-7)\n\n*   First release\n\nFor more details, see the complete release notes in the [Buildx GitHub repository](https://github.com/docker/buildx/releases/tag/v0.2.0).",
  "title": "Build release notes | Docker Docs\n",
  "description": "Learn about the new features, bug fixes, and breaking changes for the newest Buildx release",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/intro/history/",
  "markdown": "# History and development of Docker Compose\n\nThis page provides:\n\n*   A brief history of the development of the Docker Compose CLI\n*   A clear explanation of the major versions and file formats that make up Compose V1 and Compose V2\n*   The main differences between Compose V1 and Compose V2\n\n![Image showing the main differences between Compose V1 and Compose V2](https://docs.docker.com/compose/images/v1-versus-v2.png)\n\nThe image above shows that the currently supported version of the Docker Compose CLI is Compose V2 which is defined by the [Compose Specification](https://docs.docker.com/compose/compose-file/).\n\nIt also provides a quick snapshot of the differences in file formats, command-line syntax, and top-level elements. This is covered in more detail in the following sections.\n\n### [Docker Compose CLI versioning](#docker-compose-cli-versioning)\n\nVersion one of the Docker Compose command-line binary was first released in 2014. It was written in Python, and is invoked with `docker-compose`. Typically, Compose V1 projects include a top-level `version` element in the `compose.yml` file, with values ranging from `2.0` to `3.8`, which refer to the specific [file formats](#compose-file-format-versioning).\n\nVersion two of the Docker Compose command-line binary was announced in 2020, is written in Go, and is invoked with `docker compose`. Compose V2 ignores the `version` top-level element in the `compose.yml` file.\n\n### [Compose file format versioning](#compose-file-format-versioning)\n\nThe Docker Compose CLIs are defined by specific file formats.\n\nThree major versions of the Compose file format for Compose V1 were released:\n\n*   Compose file format 1 with Compose 1.0.0 in 2014\n*   Compose file format 2.x with Compose 1.6.0 in 2016\n*   Compose file format 3.x with Compose 1.10.0 in 2017\n\nCompose file format 1 is substantially different to all the following formats as it lacks a top-level `services` key. Its usage is historical and files written in this format don't run with Compose V2.\n\nCompose file format 2.x and 3.x are very similar to each other, but the latter introduced many new options targeted at Swarm deployments.\n\nTo address confusion around Compose CLI versioning, Compose file format versioning, and feature parity depending on whether Swarm mode was in use, file format 2.x and 3.x were merged into the [Compose Specification](https://docs.docker.com/compose/compose-file/).\n\nCompose V2 uses the Compose Specification for project definition. Unlike the prior file formats, the Compose Specification is rolling and makes the `version` top-level element optional. Compose V2 also makes use of optional specifications - [Deploy](https://docs.docker.com/compose/compose-file/deploy/), [Develop](https://docs.docker.com/compose/compose-file/develop/) and [Build](https://docs.docker.com/compose/compose-file/build/).\n\nTo make [migration](https://docs.docker.com/compose/migrate/) easier, Compose V2 has backwards compatibility for certain elements that have been deprecated or changed between Compose file format 2.x/3.x and the Compose Specification.",
  "title": "History and development of Docker Compose | Docker Docs\n",
  "description": "History of Compose V1 and Compose YAML schema versioning",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/install/",
  "markdown": "# Overview of installing Docker Compose\n\nThis page contains summary information about the available options for installing Docker Compose.\n\n### [Scenario one: Install Docker Desktop](#scenario-one-install-docker-desktop)\n\nThe easiest and recommended way to get Docker Compose is to install Docker Desktop. Docker Desktop includes Docker Compose along with Docker Engine and Docker CLI which are Compose prerequisites.\n\nDocker Desktop is available on:\n\n*   [Linux](https://docs.docker.com/desktop/install/linux-install/)\n*   [Mac](https://docs.docker.com/desktop/install/mac-install/)\n*   [Windows](https://docs.docker.com/desktop/install/windows-install/)\n\nIf you have already installed Docker Desktop, you can check which version of Compose you have by selecting **About Docker Desktop** from the Docker menu ![whale menu](https://docs.docker.com/desktop/images/whale-x.svg) .\n\n### [Scenario two: Install the Compose plugin](#scenario-two-install-the-compose-plugin)\n\nIf you already have Docker Engine and Docker CLI installed, you can install the Compose plugin from the command line, by either:\n\n*   [Using Docker's repository](https://docs.docker.com/compose/install/linux/#install-using-the-repository)\n*   [Downloading and installing manually](https://docs.docker.com/compose/install/linux/#install-the-plugin-manually)\n\n> **Important**\n> \n> This is only available on Linux\n\n### [Scenario three: Install the Compose standalone](#scenario-three-install-the-compose-standalone)\n\nYou can [install the Compose standalone](https://docs.docker.com/compose/install/standalone/) on Linux or on Windows Server.\n\n> **Warning**\n> \n> This install scenario is not recommended and is only supported for backward compatibility purposes.",
  "title": "Overview of installing Docker Compose | Docker Docs\n",
  "description": "Learn how to install Docker Compose. Compose is available natively on Docker Desktop, as a Docker Engine plugin, and as a standalone tool.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/install/linux/",
  "markdown": "# Install the Compose plugin | Docker Docs\n\nOn this page you can find instructions on how to install the Compose plugin on Linux from the command line.\n\nTo install the Compose plugin on Linux, you can either:\n\n*   [Set up Docker's repository on your Linux system](#install-using-the-repository).\n*   [Install Compose manually](#install-the-plugin-manually).\n\n> **Note**\n> \n> These instructions assume you already have Docker Engine and Docker CLI installed and now want to install the Compose plugin.  \n> For Compose standalone, see [Install Compose Standalone](https://docs.docker.com/compose/install/standalone/).\n\n1.  Set up the repository. Find distro-specific instructions in:\n    \n    [Ubuntu](https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository) | [CentOS](https://docs.docker.com/engine/install/centos/#set-up-the-repository) | [Debian](https://docs.docker.com/engine/install/debian/#install-using-the-repository) | [Raspberry Pi OS](https://docs.docker.com/engine/install/raspberry-pi-os/#install-using-the-repository) | [Fedora](https://docs.docker.com/engine/install/fedora/#set-up-the-repository) | [RHEL](https://docs.docker.com/engine/install/rhel/#set-up-the-repository) | [SLES](https://docs.docker.com/engine/install/sles/#set-up-the-repository).\n    \n2.  Update the package index, and install the latest version of Docker Compose:\n    \n    *   For Ubuntu and Debian, run:\n        \n    *   For RPM-based distros, run:\n        \n3.  Verify that Docker Compose is installed correctly by checking the version.\n    \n    Expected output:\n    \n    Where `vN.N.N` is placeholder text standing in for the latest version.\n    \n\n### [Update Compose](#update-compose)\n\nTo update the Compose plugin, run the following commands:\n\n*   For Ubuntu and Debian, run:\n    \n*   For RPM-based distros, run:\n    \n\n> **Note**\n> \n> This option requires you to manage upgrades manually. We recommend setting up Docker's repository for easier maintenance.\n\n1.  To download and install the Compose CLI plugin, run:\n    \n    This command downloads the latest release of Docker Compose (from the Compose releases repository) and installs Compose for the active user under `$HOME` directory.\n    \n    To install:\n    \n    *   Docker Compose for _all users_ on your system, replace `~/.docker/cli-plugins` with `/usr/local/lib/docker/cli-plugins`.\n    *   A different version of Compose, substitute `v2.28.1` with the version of Compose you want to use.\n    \n    *   For a different architecture, substitute `x86_64` with the [architecture you want](https://github.com/docker/compose/releases).\n2.  Apply executable permissions to the binary:\n    \n    or, if you chose to install Compose for all users:\n    \n3.  Test the installation.",
  "title": "Install the Compose plugin | Docker Docs\n",
  "description": "Download and install Docker Compose on Linux with this step-by-step handbook. This plugin can be installed manually or by using a repository.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/install/standalone/",
  "markdown": "# Install Compose standalone | Docker Docs\n\nOn this page you can find instructions on how to install Compose standalone on Linux or Windows Server, from the command line.\n\n### [On Linux](#on-linux)\n\n> **Compose standalone**\n> \n> Note that Compose standalone uses the `-compose` syntax instead of the current standard syntax `compose`.  \n> For example type `docker-compose up` when using Compose standalone, instead of `docker compose up`.\n\n1.  To download and install Compose standalone, run:\n    \n2.  Apply executable permissions to the standalone binary in the target path for the installation.\n    \n3.  Test and execute compose commands using `docker-compose`.\n    \n    > **Tip**\n    > \n    > If the command `docker-compose` fails after installation, check your path. You can also create a symbolic link to `/usr/bin` or any other directory in your path. For example:\n    \n\n### [On Windows Server](#on-windows-server)\n\nFollow these instructions if you are running the Docker daemon and client directly on Microsoft Windows Server and want to install Docker Compose.\n\n1.  Run PowerShell as an administrator. When asked if you want to allow this app to make changes to your device, select **Yes** in order to proceed with the installation.\n    \n2.  GitHub now requires TLS1.2. In PowerShell, run the following:\n    \n3.  Run the following command to download the latest release of Compose (v2.28.1):\n    \n    > **Note**\n    > \n    > On Windows Server 2019 you can add the Compose executable to `$Env:ProgramFiles\\Docker`. Because this directory is registered in the system `PATH`, you can run the `docker-compose --version` command on the subsequent step with no additional configuration.\n    \n    > To install a different version of Compose, substitute `v2.28.1` with the version of Compose you want to use.\n    \n4.  Test the installation.",
  "title": "Install Compose standalone | Docker Docs\n",
  "description": "How to install Docker Compose - Other Scenarios",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/environment-variables/set-environment-variables/",
  "markdown": "# Set environment variables within your container's environment\n\nA container's environment is not set until there's an explicit entry in the service configuration to make this happen. With Compose, there are two ways you can set environment variables in your containers with your Compose file.\n\n> **Tip**\n> \n> Don't use environment variables to pass sensitive information, such as passwords, in to your containers. Use [secrets](https://docs.docker.com/compose/use-secrets/) instead.\n\nYou can set environment variables directly in your container's environment with the [`environment` attribute](https://docs.docker.com/compose/compose-file/05-services/#environment) in your `compose.yml`.\n\nIt supports both list and mapping syntax:\n\nis equivalent to\n\nSee [`environment` attribute](https://docs.docker.com/compose/compose-file/05-services/#environment) for more examples on how to use it.\n\n### [Additional information](#additional-information)\n\n*   You can choose not to set a value and pass the environment variables from your shell straight through to your containers. It works in the same way as `docker run -e VARIABLE ...`:\n\nThe value of the `DEBUG` variable in the container is taken from the value for the same variable in the shell in which Compose is run. Note that in this case no warning is issued if the `DEBUG` variable in the shell environment is not set.\n\n*   You can also take advantage of [interpolation](https://docs.docker.com/compose/environment-variables/variable-interpolation/#interpolation-syntax). In the following example, the result is similar to the one above but Compose gives you a warning if the `DEBUG` variable is not set in the shell environment or in an `.env` file in the project directory.\n    \n\nA container's environment can also be set using [`.env` files](https://docs.docker.com/compose/environment-variables/variable-interpolation/#env-file) along with the [`env_file` attribute](https://docs.docker.com/compose/compose-file/05-services/#env_file).\n\nUsing an `.env` file lets you to use the same file for use by a plain `docker run --env-file ...` command, or to share the same `.env` file within multiple services without the need to duplicate a long `environment` YAML block.\n\nIt can also help you keep your environment variables separate from your main configuration file, providing a more organized and secure way to manage sensitive information, as you do not need to place your `.env` file in the root of your project's directory.\n\nThe [`env_file` attribute](https://docs.docker.com/compose/compose-file/05-services/#env_file) also lets you use multiple `.env` files in your Compose application.\n\nThe paths to your `.env` file, specified in the `env_file` attribute, are relative to the location of your `compose.yml` file.\n\n> **Important**\n> \n> Interpolation in `.env` files is a Docker Compose CLI feature.\n> \n> It is not supported when running `docker run --env-file ...`.\n\n### [Additional information](#additional-information-1)\n\n*   If multiple files are specified, they are evaluated in order and can override values set in previous files.\n*   In addition, as the `.env` file supports [interpolation](https://docs.docker.com/compose/environment-variables/variable-interpolation/), it is possible to combine those with values set by `environment`.\n*   As of Docker Compose version 2.24.0, you can set your `.env` file, defined by the `env_file` attribute, to be optional by using the `required` field. When `required` is set to `false` and the `.env` file is missing, Compose silently ignores the entry.\n*   Values in your `.env` file can be overridden from the command line by using [`docker compose run -e`](#set-environment-variables-with-docker-compose-run---env).\n\nSimilar to `docker run --env`, you can set environment variables temporarily with `docker compose run --env` or its short form `docker compose run -e`:\n\n### [Additional information](#additional-information-2)\n\n*   You can also pass a variable from the shell by not giving it a value:\n    \n\nThe value of the `DEBUG` variable in the container is taken from the value for the same variable in the shell in which Compose is run.\n\n*   [Understand environment variable precedence](https://docs.docker.com/compose/environment-variables/envvars-precedence/).\n*   [Set or change predefined environment variables](https://docs.docker.com/compose/environment-variables/envvars/)\n*   [Explore best practices](https://docs.docker.com/compose/environment-variables/best-practices/)\n*   [Understand interpolation](https://docs.docker.com/compose/environment-variables/variable-interpolation/)",
  "title": "Set environment variables within your container's environment | Docker Docs\n",
  "description": "How to set, use, and manage environment variables with Compose",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/environment-variables/envvars/",
  "markdown": "# Set or change pre-defined environment variables in Docker Compose\n\nCompose already comes with pre-defined environment variables. It also inherits common Docker CLI environment variables, such as `DOCKER_HOST` and `DOCKER_CONTEXT`. See [Docker CLI environment variable reference](https://docs.docker.com/engine/reference/commandline/cli/#environment-variables) for details.\n\nThis page contains information on how you can set or change the following pre-defined environment variables if you need to:\n\n*   `COMPOSE_CONVERT_WINDOWS_PATHS`\n*   `COMPOSE_FILE`\n*   `COMPOSE_PROFILES`\n*   `COMPOSE_PROJECT_NAME`\n*   `DOCKER_CERT_PATH`\n*   `COMPOSE_PARALLEL_LIMIT`\n*   `COMPOSE_IGNORE_ORPHANS`\n*   `COMPOSE_REMOVE_ORPHANS`\n*   `COMPOSE_PATH_SEPARATOR`\n*   `COMPOSE_ANSI`\n*   `COMPOSE_STATUS_STDOUT`\n*   `COMPOSE_ENV_FILES`\n*   `COMPOSE_MENU`\n*   `COMPOSE_EXPERIMENTAL`\n\nYou can set or change the pre-defined environment variables:\n\n*   Within your Compose file using the [`environment` attribute](https://docs.docker.com/compose/environment-variables/set-environment-variables/#use-the-environment-attribute)\n*   With the `env-file` attribute and an [environment file](https://docs.docker.com/compose/environment-variables/set-environment-variables/#use-the-env_file-attribute)\n*   From the command line\n*   From your [shell](https://docs.docker.com/compose/environment-variables/variable-interpolation/#substitute-from-the-shell)\n\nWhen changing or setting any environment variables, be aware of [Environment variable precedence](https://docs.docker.com/compose/environment-variables/envvars-precedence/).\n\n### [COMPOSE\\_PROJECT\\_NAME](#compose_project_name)\n\nSets the project name. This value is prepended along with the service name to the container's name on startup.\n\nFor example, if your project name is `myapp` and it includes two services `db` and `web`, then Compose starts containers named `myapp-db-1` and `myapp-web-1` respectively.\n\nCompose can set the project name in different ways. The level of precedence (from highest to lowest) for each method is as follows:\n\n1.  The `-p` command line flag\n2.  `COMPOSE_PROJECT_NAME`\n3.  The top level `name:` variable from the config file (or the last `name:` from a series of config files specified using `-f`)\n4.  The `basename` of the project directory containing the config file (or containing the first config file specified using `-f`)\n5.  The `basename` of the current directory if no config file is specified\n\nProject names must contain only lowercase letters, decimal digits, dashes, and underscores, and must begin with a lowercase letter or decimal digit. If the `basename` of the project directory or current directory violates this constraint, you must use one of the other mechanisms.\n\nSee also the [command-line options overview](https://docs.docker.com/compose/reference/#command-options-overview-and-help) and [using `-p` to specify a project name](https://docs.docker.com/compose/reference/#use--p-to-specify-a-project-name).\n\n### [COMPOSE\\_FILE](#compose_file)\n\nSpecifies the path to a Compose file. Specifying multiple Compose files is supported.\n\n*   Default behavior: If not provided, Compose looks for a file named `compose.yaml` or `docker-compose.yaml` in the current directory and, if not found, then Compose searches each parent directory recursively until a file by that name is found.\n*   Default separator: When specifying multiple Compose files, the path separators are, by default, on:\n    *   Mac and Linux: `:` (colon),\n    *   Windows: `;` (semicolon).\n\nThe path separator can also be customized using `COMPOSE_PATH_SEPARATOR`.\n\nExample: `COMPOSE_FILE=docker-compose.yml:docker-compose.prod.yml`.\n\nSee also the [command-line options overview](https://docs.docker.com/compose/reference/#command-options-overview-and-help) and [using `-f` to specify name and path of one or more Compose files](https://docs.docker.com/compose/reference/#use--f-to-specify-name-and-path-of-one-or-more-compose-files).\n\n### [COMPOSE\\_PROFILES](#compose_profiles)\n\nSpecifies one or more profiles to be enabled on `compose up` execution. Services with matching profiles are started as well as any services for which no profile has been defined.\n\nFor example, calling `docker compose up`with `COMPOSE_PROFILES=frontend` selects services with the `frontend` profile as well as any services without a profile specified.\n\n*   Default separator: specify a list of profiles using a comma as separator.\n\nExample: `COMPOSE_PROFILES=frontend,debug`  \nThis example enables all services matching both the `frontend` and `debug` profiles and services without a profile.\n\nSee also [Using profiles with Compose](https://docs.docker.com/compose/profiles/) and the [`--profile` command-line option](https://docs.docker.com/compose/reference/#use---profile-to-specify-one-or-more-active-profiles).\n\n### [COMPOSE\\_CONVERT\\_WINDOWS\\_PATHS](#compose_convert_windows_paths)\n\nWhen enabled, Compose performs path conversion from Windows-style to Unix-style in volume definitions.\n\n*   Supported values:\n    *   `true` or `1`, to enable,\n    *   `false` or `0`, to disable.\n*   Defaults to: `0`.\n\n### [COMPOSE\\_PATH\\_SEPARATOR](#compose_path_separator)\n\nSpecifies a different path separator for items listed in `COMPOSE_FILE`.\n\n*   Defaults to:\n    *   On macOS and Linux to `:`,\n    *   On Windows to`;`.\n\n### [COMPOSE\\_IGNORE\\_ORPHANS](#compose_ignore_orphans)\n\nWhen enabled, Compose doesn't try to detect orphaned containers for the project.\n\n*   Supported values:\n    *   `true` or `1`, to enable,\n    *   `false` or `0`, to disable.\n*   Defaults to: `0`.\n\n### [COMPOSE\\_PARALLEL\\_LIMIT](#compose_parallel_limit)\n\nSpecifies the maximum level of parallelism for concurrent engine calls.\n\n### [COMPOSE\\_ANSI](#compose_ansi)\n\nSpecifies when to print ANSI control characters.\n\n*   Supported values:\n    *   `auto`, Compose detects if TTY mode can be used. Otherwise, use plain text mode.\n    *   `never`, use plain text mode.\n    *   `always` or `0`, use TTY mode.\n*   Defaults to: `auto`.\n\n### [COMPOSE\\_STATUS\\_STDOUT](#compose_status_stdout)\n\nWhen enabled, Compose writes its internal status and progress messages to `stdout` instead of `stderr`. The default value is false to clearly separate the output streams between Compose messages and your container's logs.\n\n*   Supported values:\n    *   `true` or `1`, to enable,\n    *   `false` or `0`, to disable.\n*   Defaults to: `0`.\n\n### [COMPOSE\\_ENV\\_FILES](#compose_env_files)\n\nLets you specify which environment files Compose should use if `--env-file` isn't used.\n\nWhen using multiple environment files, use a comma as a separator. For example,\n\nIf `COMPOSE_ENV_FILES` is not set, and you don't provide `--env-file` in the CLI, Docker Compose uses the default behavior, which is to look for an `.env` file in the project directory.\n\nWhen enabled, Compose displays a navigation menu where you can choose to open the Compose stack in Docker Desktop, switch on [`watch` mode](https://docs.docker.com/compose/file-watch/), or use [Docker Debug](https://docs.docker.com/reference/cli/docker/debug/).\n\n*   Supported values:\n    *   `true` or `1`, to enable,\n    *   `false` or `0`, to disable.\n*   Defaults to: `1` if you obtained Docker Compose through Docker Desktop, otherwise default is `0`.\n\n> **Note**\n> \n> Available in Docker Compose version 2.26.0 and later, and Docker Desktop version 4.29 and later\n\n### [COMPOSE\\_EXPERIMENTAL](#compose_experimental)\n\nThis is an opt-out variable. When turned off it deactivates the experimental features such as the navigation menu or [Synchronized file shares](https://docs.docker.com/desktop/synchronized-file-sharing/).\n\n*   Supported values:\n    *   `true` or `1`, to enable,\n    *   `false` or `0`, to disable.\n*   Defaults to: `1`.\n\n> **Note**\n> \n> Available in Docker Compose version 2.26.0 and later, and Docker Desktop version 4.29 and later\n\nThe following environment variables have no effect in Compose V2. For more information, see [Migrate to Compose V2](https://docs.docker.com/compose/migrate/).\n\n*   `COMPOSE_API_VERSION` By default the API version is negotiated with the server. Use `DOCKER_API_VERSION`.  \n    See the [Docker CLI environment variable reference](https://docs.docker.com/engine/reference/commandline/cli/#environment-variables) page.\n*   `COMPOSE_HTTP_TIMEOUT`\n*   `COMPOSE_TLS_VERSION`\n*   `COMPOSE_FORCE_WINDOWS_HOST`\n*   `COMPOSE_INTERACTIVE_NO_CLI`\n*   `COMPOSE_DOCKER_CLI_BUILD` Use `DOCKER_BUILDKIT` to select between BuildKit and the classic builder. If `DOCKER_BUILDKIT=0` then `docker compose build` uses the classic builder to build images.",
  "title": "Set or change pre-defined environment variables in Docker Compose | Docker Docs\n",
  "description": "Compose pre-defined environment variables",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/environment-variables/envvars-precedence/",
  "markdown": "# Environment variables precedence in Docker Compose\n\nWhen the same environment variable is set in multiple sources, Docker Compose follows a precedence rule to determine the value for that variable in your container's environment.\n\nThis page contains information on the level of precedence each method of setting environmental variables takes.\n\nThe order of precedence (highest to lowest) is as follows:\n\n1.  Set using [`docker compose run -e` in the CLI](https://docs.docker.com/compose/environment-variables/set-environment-variables/#set-environment-variables-with-docker-compose-run---env).\n2.  Set with either the `environment` or `env_file` attribute but with the value interpolated from your [shell](https://docs.docker.com/compose/environment-variables/variable-interpolation/#substitute-from-the-shell) or an environment file. (either your default [`.env` file](https://docs.docker.com/compose/environment-variables/variable-interpolation/#env-file), or with the [`--env-file` argument](https://docs.docker.com/compose/environment-variables/variable-interpolation/#substitute-with---env-file) in the CLI).\n3.  Set using just the [`environment` attribute](https://docs.docker.com/compose/environment-variables/set-environment-variables/#use-the-environment-attribute) in the Compose file.\n4.  Use of the [`env_file` attribute](https://docs.docker.com/compose/environment-variables/set-environment-variables/#use-the-env_file-attribute) in the Compose file.\n5.  Set in a container image in the [ENV directive](https://docs.docker.com/reference/dockerfile/#env). Having any `ARG` or `ENV` setting in a `Dockerfile` evaluates only if there is no Docker Compose entry for `environment`, `env_file` or `run --env`.\n\nIn the following example, a different value for the same environment variable in an `.env` file and with the `environment` attribute in the Compose file:\n\nThe environment variable defined with the `environment` attribute takes precedence.\n\nThe following table uses `VALUE`, an environment variable defining the version for an image, as an example.\n\n### [How the table works](#how-the-table-works)\n\nEach column represents a context from where you can set a value, or substitute in a value for `VALUE`.\n\nThe columns `Host OS environment` and `.env` file is listed only for illustration purposes. In reality, they don't result in a variable in the container by itself, but in conjunction with either the `environment` or `env_file` attribute.\n\nEach row represents a combination of contexts where `VALUE` is set, substituted, or both. The **Result** column indicates the final value for `VALUE` in each scenario.\n\n| #   | `docker compose run` | `environment` attribute | `env_file` attribute | Image `ENV` | `Host OS` environment | `.env` file |     | Result |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 1   | \\-  | \\-  | \\-  | \\-  | `VALUE=1.4` | `VALUE=1.3` |     | \\-  |\n| 2   | \\-  | \\-  | `VALUE=1.6` | `VALUE=1.5` | `VALUE=1.4` | \\-  |     | **`VALUE=1.6`** |\n| 3   | \\-  | `VALUE=1.7` | \\-  | `VALUE=1.5` | `VALUE=1.4` | \\-  |     | **`VALUE=1.7`** |\n| 4   | \\-  | \\-  | \\-  | `VALUE=1.5` | `VALUE=1.4` | `VALUE=1.3` |     | **`VALUE=1.5`** |\n| 5   | `--env VALUE=1.8` | \\-  | \\-  | `VALUE=1.5` | `VALUE=1.4` | `VALUE=1.3` |     | **`VALUE=1.8`** |\n| 6   | `--env VALUE` | \\-  | \\-  | `VALUE=1.5` | `VALUE=1.4` | `VALUE=1.3` |     | **`VALUE=1.4`** |\n| 7   | `--env VALUE` | \\-  | \\-  | `VALUE=1.5` | \\-  | `VALUE=1.3` |     | **`VALUE=1.3`** |\n| 8   | \\-  | \\-  | `VALUE` | `VALUE=1.5` | `VALUE=1.4` | `VALUE=1.3` |     | **`VALUE=1.4`** |\n| 9   | \\-  | \\-  | `VALUE` | `VALUE=1.5` | \\-  | `VALUE=1.3` |     | **`VALUE=1.3`** |\n| 10  | \\-  | `VALUE` | \\-  | `VALUE=1.5` | `VALUE=1.4` | `VALUE=1.3` |     | **`VALUE=1.4`** |\n| 11  | \\-  | `VALUE` | \\-  | `VALUE=1.5` | \\-  | `VALUE=1.3` |     | **`VALUE=1.3`** |\n| 12  | `--env VALUE` | `VALUE=1.7` | \\-  | `VALUE=1.5` | `VALUE=1.4` | `VALUE=1.3` |     | **`VALUE=1.4`** |\n| 13  | `--env VALUE=1.8` | `VALUE=1.7` | \\-  | `VALUE=1.5` | `VALUE=1.4` | `VALUE=1.3` |     | **`VALUE=1.8`** |\n| 14  | `--env VALUE=1.8` | \\-  | `VALUE=1.6` | `VALUE=1.5` | `VALUE=1.4` | `VALUE=1.3` |     | **`VALUE=1.8`** |\n| 15  | `--env VALUE=1.8` | `VALUE=1.7` | `VALUE=1.6` | `VALUE=1.5` | `VALUE=1.4` | `VALUE=1.3` |     | **`VALUE=1.8`** |\n\n### [Result explanation](#result-explanation)\n\nResult 1: The local environment takes precedence, but the Compose file is not set to replicate this inside the container, so no such variable is set.\n\nResult 2: The `env_file` attribute in the Compose file defines an explicit value for `VALUE` so the container environment is set accordingly.\n\nResult 3: The `environment` attribute in the Compose file defines an explicit value for `VALUE`, so the container environment is set accordingly/\n\nResult 4: The image's `ENV` directive declares the variable `VALUE`, and since the Compose file is not set to override this value, this variable is defined by image\n\nResult 5: The `docker compose run` command has the `--env` flag set which an explicit value, and overrides the value set by the image.\n\nResult 6: The `docker compose run` command has the `--env` flag set to replicate the value from the environment. Host OS value takes precedence and is replicated into the container's environment.\n\nResult 7: The `docker compose run` command has the `--env` flag set to replicate the value from the environment. Value from `.env` file is the selected to define the container's environment.\n\nResult 8: The `env_file` attribute in the Compose file is set to replicate `VALUE` from the local environment. Host OS value takes precedence and is replicated into the container's environment.\n\nResult 9: The `env_file` attribute in the Compose file is set to replicate `VALUE` from the local environment. Value from `.env` file is the selected to define the container's environment.\n\nResult 10: The `environment` attribute in the Compose file is set to replicate `VALUE` from the local environment. Host OS value takes precedence and is replicated into the container's environment.\n\nResult 11: The `environment` attribute in the Compose file is set to replicate `VALUE` from the local environment. Value from `.env` file is the selected to define the container's environment.\n\nResult 12: The `--env` flag has higher precedence than the `environment` and `env_file` attributes and is to set to replicate `VALUE` from the local environment. Host OS value takes precedence and is replicated into the container's environment.\n\nResults 13 to 15: The `--env` flag has higher precedence than the `environment` and `env_file` attributes and so sets the value.",
  "title": "Environment variables precedence in Docker Compose | Docker Docs\n",
  "description": "Scenario overview illustrating how environment variables are resolved in Compose",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/environment-variables/variable-interpolation/",
  "markdown": "# Set, use, and manage variables in a Compose file with interpolation\n\nA Compose file can use variables to offer more flexibility. If you want to quickly switch between image tags to test multiple versions, or want to adjust a volume source to your local environment, you don't need to edit the Compose file each time, you can just set variables that insert values into your Compose file at run time.\n\nInterpolation can also be used to insert values into your Compose file at run time, which is then used to pass variables into your container's environment\n\nBelow is a simple example:\n\nWhen you run `docker compose up`, the `web` service defined in the Compose file [interpolates](https://docs.docker.com/compose/environment-variables/variable-interpolation/) in the image `webapp:v1.5` which was set in the `.env` file. You can verify this with the [config command](https://docs.docker.com/reference/cli/docker/compose/config/), which prints your resolved application config to the terminal:\n\nInterpolation is applied for unquoted and double-quoted values. Both braced (`${VAR}`) and unbraced (`$VAR`) expressions are supported.\n\nFor braced expressions, the following formats are supported:\n\n*   Direct substitution\n    *   `${VAR}` -> value of `VAR`\n*   Default value\n    *   `${VAR:-default}` -> value of `VAR` if set and non-empty, otherwise `default`\n    *   `${VAR-default}` -> value of `VAR` if set, otherwise `default`\n*   Required value\n    *   `${VAR:?error}` -> value of `VAR` if set and non-empty, otherwise exit with error\n    *   `${VAR?error}` -> value of `VAR` if set, otherwise exit with error\n*   Alternative value\n    *   `${VAR:+replacement}` -> `replacement` if `VAR` is set and non-empty, otherwise empty\n    *   `${VAR+replacement}` -> `replacement` if `VAR` is set, otherwise empty\n\nFor more information, see [Interpolation](https://docs.docker.com/compose/compose-file/12-interpolation/) in the Compose Specification.\n\nDocker Compose can interpolate variables into your Compose file from multiple sources.\n\nNote that when the same variable is declared by multiple sources, precedence applies:\n\n1.  Variables from your shell environment\n2.  If `--env-file` is not set, variables set by an `.env` file in local working directory (`PWD`)\n3.  Variables from a file set by `--env-file` or an `.env` file in project directory\n\nYou can check variables and values used by Compose to interpolate the Compose model by running `docker compose config --environment`.\n\n### [`.env` file](#env-file)\n\nAn `.env` file in Docker Compose is a text file used to define variables that should be made available for interpolation when running `docker compose up`. This file typically contains key-value pairs of variables, and it lets you centralize and manage configuration in one place. The `.env` file is useful if you have multiple variables you need to store.\n\nThe `.env` file is the default method for setting variables. The `.env` file should be placed at the root of the project directory next to your `compose.yaml` file. For more information on formatting an environment file, see [Syntax for environment files](#env-file-syntax).\n\nBasic example:\n\n#### [Additional information](#additional-information)\n\n*   If you define a variable in your `.env` file, you can reference it directly in your `compose.yml` with the [`environment` attribute](https://docs.docker.com/compose/compose-file/05-services/#environment). For example, if your `.env` file contains the environment variable `DEBUG=1` and your `compose.yml` file looks like this:\n    \n    Docker Compose replaces `${DEBUG}` with the value from the `.env` file\n    \n    > **Important**\n    > \n    > Be aware of [Environment variables precedence](https://docs.docker.com/compose/environment-variables/envvars-precedence/) when using variables in an `.env` file that as environment variables in your container's environment.\n    \n*   You can place your `.env` file in a location other than the root of your project's directory, and then use the [`--env-file` option in the CLI](#substitute-with---env-file) so Compose can navigate to it.\n    \n*   Your `.env` file can be overridden by another `.env` if it is [substituted with `--env-file`](#substitute-with---env-file).\n    \n\n> **Important**\n> \n> Substitution from `.env` files is a Docker Compose CLI feature.\n> \n> It is not supported by Swarm when running `docker stack deploy`.\n\n#### [`.env` file syntax](#env-file-syntax)\n\nThe following syntax rules apply to environment files:\n\n*   Lines beginning with `#` are processed as comments and ignored.\n*   Blank lines are ignored.\n*   Unquoted and double-quoted (`\"`) values have interpolation applied.\n*   Each line represents a key-value pair. Values can optionally be quoted.\n    *   `VAR=VAL` -> `VAL`\n    *   `VAR=\"VAL\"` -> `VAL`\n    *   `VAR='VAL'` -> `VAL`\n*   Inline comments for unquoted values must be preceded with a space.\n    *   `VAR=VAL # comment` -> `VAL`\n    *   `VAR=VAL# not a comment` -> `VAL# not a comment`\n*   Inline comments for quoted values must follow the closing quote.\n    *   `VAR=\"VAL # not a comment\"` -> `VAL # not a comment`\n    *   `VAR=\"VAL\" # comment` -> `VAL`\n*   Single-quoted (`'`) values are used literally.\n    *   `VAR='$OTHER'` -> `$OTHER`\n    *   `VAR='${OTHER}'` -> `${OTHER}`\n*   Quotes can be escaped with `\\`.\n    *   `VAR='Let\\'s go!'` -> `Let's go!`\n    *   `VAR=\"{\\\"hello\\\": \\\"json\\\"}\"` -> `{\"hello\": \"json\"}`\n*   Common shell escape sequences including `\\n`, `\\r`, `\\t`, and `\\\\` are supported in double-quoted values.\n    *   `VAR=\"some\\tvalue\"` -> `some value`\n    *   `VAR='some\\tvalue'` -> `some\\tvalue`\n    *   `VAR=some\\tvalue` -> `some\\tvalue`\n\n### [Substitute with `--env-file`](#substitute-with---env-file)\n\nYou can set default values for multiple environment variables, in an `.env` file and then pass the file as an argument in the CLI.\n\nThe advantage of this method is that you can store the file anywhere and name it appropriately, for example, This file path is relative to the current working directory where the Docker Compose command is executed. Passing the file path is done using the `--env-file` option:\n\n#### [Additional information](#additional-information-1)\n\n*   This method is useful if you want to temporarily override an `.env` file that is already referenced in your `compose.yml` file. For example you may have different `.env` files for production ( `.env.prod`) and testing (`.env.test`). In the following example, there are two environment files, `.env` and `.env.dev`. Both have different values set for `TAG`.If the `--env-file` is not used in the command line, the `.env` file is loaded by default:Passing the `--env-file` argument overrides the default file path:When an invalid file path is being passed as an `--env-file` argument, Compose returns an error:\n*   You can use multiple `--env-file` options to specify multiple environment files, and Docker Compose reads them in order. Later files can override variables from earlier files.\n*   You can override specific environment variables from the command line when starting containers.\n\n### [local `.env` file versus `.env` file](#local-env-file-versus-project-directory-env-file)\n\nAn `.env` file can also be used to declare [pre-defined environment variables](https://docs.docker.com/compose/environment-variables/envvars/) used to control Compose behavior and files to be loaded.\n\nWhen executed without an explicit `--env-file` flag, Compose searches for an `.env` file in your working directory ( [PWD](https://www.gnu.org/software/bash/manual/html_node/Bash-Variables.html#index-PWD)) and loads values both for self-configuration and interpolation. If the values in this file define the `COMPOSE_FILE` pre-defined variable, which results in a project directory being set to another folder, Compose will load a second `.env` file, if present. This second `.env` file has a lower precedence.\n\nThis mechanism makes it possible to invoke an existing Compose project with a custom set of variables as overrides, without the need to pass environment variables by the command line.\n\n### [Substitute from the shell](#substitute-from-the-shell)\n\nYou can use existing environment variables from your host machine or from the shell environment where you execute `docker compose` commands. This lets you dynamically inject values into your Docker Compose configuration at runtime. For example, suppose the shell contains `POSTGRES_VERSION=9.3` and you supply the following configuration:\n\nWhen you run `docker compose up` with this configuration, Compose looks for the `POSTGRES_VERSION` environment variable in the shell and substitutes its value in. For this example, Compose resolves the image to `postgres:9.3` before running the configuration.\n\nIf an environment variable is not set, Compose substitutes with an empty string. In the previous example, if `POSTGRES_VERSION` is not set, the value for the image option is `postgres:`.\n\n> **Note**\n> \n> `postgres:` is not a valid image reference. Docker expects either a reference without a tag, like `postgres` which defaults to the latest image, or with a tag such as `postgres:15`.",
  "title": "Set, use, and manage variables in a Compose file with interpolation | Docker Docs\n",
  "description": "How to set, use, and manage variables in your Compose file with interpolation",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/environment-variables/best-practices/",
  "markdown": "# Best practices for working with environment variables in Docker Compose\n\n#### [Handle sensitive information securely](#handle-sensitive-information-securely)\n\nBe cautious about including sensitive data in environment variables. Consider using [Secrets](https://docs.docker.com/compose/use-secrets/) for managing sensitive information.\n\n#### [Understand environment variable precedence](#understand-environment-variable-precedence)\n\nBe aware of how Docker Compose handles the [precedence of environment variables](https://docs.docker.com/compose/environment-variables/envvars-precedence/) from different sources (`.env` files, shell variables, Dockerfiles).\n\n#### [Use specific environment files](#use-specific-environment-files)\n\nConsider how your application adapts to different environments. For example development, testing, production, and use different `.env` files as needed.\n\n#### [Know interpolation](#know-interpolation)\n\nUnderstand how [interpolation](https://docs.docker.com/compose/environment-variables/variable-interpolation/) works within compose files for dynamic configurations.\n\n#### [Command line overrides](#command-line-overrides)\n\nBe aware that you can [override environment variables](https://docs.docker.com/compose/environment-variables/set-environment-variables/#cli) from the command line when starting containers. This is useful for testing or when you have temporary changes.",
  "title": "Best practices for working with environment variables in Docker Compose | Docker Docs\n",
  "description": "Explainer on the best ways to set, use, and manage environment variables in Compose",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-application-model/",
  "markdown": "# How Compose works | Docker Docs\n\nWith Docker Compose you use a YAML configuration file, known as the [Compose file](#the-compose-file), to configure your applicationâ€™s services, and then you create and start all the services from your configuration with the [Compose CLI](#cli).\n\nThe Compose file, or `compose.yaml` file, follows the rules provided by the [Compose Specification](https://docs.docker.com/compose/compose-file/) in how to define multi-container applications. This is the Docker Compose implementation of the formal [Compose Specification](https://github.com/compose-spec/compose-spec).\n\nComputing components of an application are defined as [services](https://docs.docker.com/compose/compose-file/05-services/). A service is an abstract concept implemented on platforms by running the same container image, and configuration, one or more times.\n\nServices communicate with each other through [networks](https://docs.docker.com/compose/compose-file/06-networks/). In the Compose Specification, a network is a platform capability abstraction to establish an IP route between containers within services connected together.\n\nServices store and share persistent data into [volumes](https://docs.docker.com/compose/compose-file/07-volumes/). The Specification describes such a persistent data as a high-level filesystem mount with global options.\n\nSome services require configuration data that is dependent on the runtime or platform. For this, the Specification defines a dedicated [configs](https://docs.docker.com/compose/compose-file/08-configs/) concept. From a service container point of view, configs are comparable to volumes, in that they are files mounted into the container. But the actual definition involves distinct platform resources and services, which are abstracted by this type.\n\nA [secret](https://docs.docker.com/compose/compose-file/09-secrets/) is a specific flavor of configuration data for sensitive data that should not be exposed without security considerations. Secrets are made available to services as files mounted into their containers, but the platform-specific resources to provide sensitive data are specific enough to deserve a distinct concept and definition within the Compose specification.\n\n> **Note**\n> \n> With volumes, configs and secrets you can have a simple declaration at the top-level and then add more platform-specific information at the service level.\n\nA project is an individual deployment of an application specification on a platform. A project's name, set with the top-level [`name`](https://docs.docker.com/compose/compose-file/04-version-and-name/) attribute, is used to group resources together and isolate them from other applications or other installation of the same Compose-specified application with distinct parameters. If you are creating resources on a platform, you must prefix resource names by project and set the label `com.docker.compose.project`.\n\nCompose offers a way for you to set a custom project name and override this name, so that the same `compose.yaml` file can be deployed twice on the same infrastructure, without changes, by just passing a distinct name.\n\nThe default path for a Compose file is `compose.yaml` (preferred) or `compose.yml` that is placed in the working directory. Compose also supports `docker-compose.yaml` and `docker-compose.yml` for backwards compatibility of earlier versions. If both files exist, Compose prefers the canonical `compose.yaml`.\n\nYou can use [fragments](https://docs.docker.com/compose/compose-file/10-fragments/) and [extensions](https://docs.docker.com/compose/compose-file/11-extension/) to keep your Compose file efficient and easy to maintain.\n\nMultiple Compose files can be [merged](https://docs.docker.com/compose/compose-file/13-merge/) together to define the application model. The combination of YAML files is implemented by appending or overriding YAML elements based on the Compose file order you set. Simple attributes and maps get overridden by the highest order Compose file, lists get merged by appending. Relative paths are resolved based on the first Compose file's parent folder, whenever complimentary files being merged are hosted in other folders. As some Compose file elements can both be expressed as single strings or complex objects, merges apply to the expanded form. For more information, see [Working with multiple Compose files](https://docs.docker.com/compose/multiple-compose-files/)\n\nIf you want to reuse other Compose files, or factor out parts of your application model into separate Compose files, you can also use [`include`](https://docs.docker.com/compose/compose-file/14-include/). This is useful if your Compose application is dependent on another application which is managed by a different team, or needs to be shared with others.\n\nThe Docker CLI lets you to interact with your Docker Compose applications through the `docker compose` command, and its subcommands. Using the CLI, you can manage the lifecycle of your multi-container applications defined in the `compose.yaml` file. The CLI commands enable you to start, stop, and configure your applications effortlessly.\n\n### [Key commands](#key-commands)\n\nTo start all the services defined in your `compose.yaml` file:\n\nTo stop and remove the running services:\n\nIf you want to monitor the output of your running containers and debug issues, you can view the logs with:\n\nTo lists all the services along with their current status:\n\nFor a full list of all the Compose CLI commands, see the [reference documentation](https://docs.docker.com/reference/cli/docker/compose/).\n\nThe following example illustrates the Compose concepts outlined above. The example is non-normative.\n\nConsider an application split into a frontend web application and a backend service.\n\nThe frontend is configured at runtime with an HTTP configuration file managed by infrastructure, providing an external domain name, and an HTTPS server certificate injected by the platform's secured secret store.\n\nThe backend stores data in a persistent volume.\n\nBoth services communicate with each other on an isolated back-tier network, while the frontend is also connected to a front-tier network and exposes port 443 for external usage.\n\n![Compose application example](https://docs.docker.com/compose/images/compose-application.webp)\n\nThe example application is composed of the following parts:\n\n*   2 services, backed by Docker images: `webapp` and `database`\n*   1 secret (HTTPS certificate), injected into the frontend\n*   1 configuration (HTTP), injected into the frontend\n*   1 persistent volume, attached to the backend\n*   2 networks\n\nThe `docker compose up` command starts the `frontend` and `backend` services, create the necessary networks and volumes, and injects the configuration and secret into the frontend service.\n\n`docker compose ps` provides a snapshot of the current state of your services, making it easy to see which containers are running, their status, and the ports they are using:\n\n*   [Quickstart](https://docs.docker.com/compose/gettingstarted/)\n*   [Explore some sample applications](https://docs.docker.com/compose/samples-for-compose/)\n*   [Familiarize yourself with the Compose Specification](https://docs.docker.com/compose/compose-file/)",
  "title": "How Compose works | Docker Docs\n",
  "description": "Understand how Compose works and the Compose application model with an illustrative example",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/profiles/",
  "markdown": "# Using profiles with Compose | Docker Docs\n\nProfiles help you adjust your Compose application for different environments or use cases by selectively activating services. Services can be assigned to one or more profiles; unassigned services start by default, while assigned ones only start when their profile is active. This setup means specific services, like those for debugging or development, to be included in a single `compose.yml` file and activated only as needed.\n\nServices are associated with profiles through the [`profiles` attribute](https://docs.docker.com/compose/compose-file/05-services/#profiles) which takes an array of profile names:\n\nHere the services `frontend` and `phpmyadmin` are assigned to the profiles `frontend` and `debug` respectively and as such are only started when their respective profiles are enabled.\n\nServices without a `profiles` attribute are always enabled. In this case running `docker compose up` would only start `backend` and `db`.\n\nValid profiles names follow the regex format of `[a-zA-Z0-9][a-zA-Z0-9_.-]+`.\n\n> **Tip**\n> \n> The core services of your application shouldn't be assigned `profiles` so they are always enabled and automatically started.\n\nTo start a specific profile supply the `--profile` [command-line option](https://docs.docker.com/compose/reference/) or use the [`COMPOSE_PROFILES` environment variable](https://docs.docker.com/compose/environment-variables/envvars/#compose_profiles):\n\nThe above commands would both start your application with the `debug` profile enabled. In the example, `compose.yml` file above, this starts the services `backend`, `db` and `phpmyadmin`.\n\n### [Start multiple profiles](#start-multiple-profiles)\n\nYou can also enable multiple profiles, e.g. with `docker compose --profile frontend --profile debug up` the profiles `frontend` and `debug` will be enabled.\n\nMultiple profiles can be specified by passing multiple `--profile` flags or a comma-separated list for the `COMPOSE_PROFILES` environment variable:\n\nIf you want to enable all profiles at the same time, you can run `docker compose --profile \"*\"`.\n\nWhen a service with assigned `profiles` is explicitly targeted on the command line its profiles are started automatically so you don't need to start them manually. This can be used for one-off services and debugging tools. As an example consider the following configuration:\n\nBut keep in mind that `docker compose` only automatically starts the profiles of the services on the command line and not of any dependencies.\n\nThis means that any other services the targeted service `depends_on` should either:\n\n*   Share a common profile\n*   Always be started, by omitting `profiles` or having a matching profile started explicitly\n\nAlthough targeting `phpmyadmin` automatically starts the profiles `debug`, it doesn't automatically start the profiles required by `db` which is `dev`.\n\nTo fix this you either have to add the `debug` profile to the `db` service:\n\nor start the `dev` profile explicitly:\n\n[`profiles`](https://docs.docker.com/compose/compose-file/05-services/#profiles)",
  "title": "Using profiles with Compose | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/gettingstarted/",
  "markdown": "# Docker Compose Quickstart | Docker Docs\n\nThis tutorial aims to introduce fundamental concepts of Docker Compose by guiding you through the development of a basic Python web application.\n\nUsing the Flask framework, the application features a hit counter in Redis, providing a practical example of how Docker Compose can be applied in web development scenarios.\n\nThe concepts demonstrated here should be understandable even if you're not familiar with Python.\n\nThis is a non-normative example that just highlights the key things you can do with Compose.\n\nMake sure you have:\n\n*   Installed the latest version of Docker Compose\n*   A basic understanding of Docker concepts and how Docker works\n\n1.  Create a directory for the project:\n    \n2.  Create a file called `app.py` in your project directory and paste the following code in:\n    \n    In this example, `redis` is the hostname of the redis container on the application's network and the default port, `6379` is used.\n    \n    > **Note**\n    > \n    > Note the way the `get_hit_count` function is written. This basic retry loop attempts the request multiple times if the Redis service is not available. This is useful at startup while the application comes online, but also makes the application more resilient if the Redis service needs to be restarted anytime during the app's lifetime. In a cluster, this also helps handling momentary connection drops between nodes.\n    \n3.  Create another file called `requirements.txt` in your project directory and paste the following code in:\n    \n4.  Create a `Dockerfile` and paste the following code in:\n    \n    This tells Docker to:\n    \n    *   Build an image starting with the Python 3.10 image.\n    *   Set the working directory to `/code`.\n    *   Set environment variables used by the `flask` command.\n    *   Install gcc and other dependencies\n    *   Copy `requirements.txt` and install the Python dependencies.\n    *   Add metadata to the image to describe that the container is listening on port 5000\n    *   Copy the current directory `.` in the project to the workdir `.` in the image.\n    *   Set the default command for the container to `flask run --debug`.\n    \n    > **Important**\n    > \n    > Check that the `Dockerfile` has no file extension like `.txt`. Some editors may append this file extension automatically which results in an error when you run the application.\n    \n    For more information on how to write Dockerfiles, see the [Dockerfile reference](https://docs.docker.com/reference/dockerfile/).\n    \n\nCompose simplifies the control of your entire application stack, making it easy to manage services, networks, and volumes in a single, comprehensible YAML configuration file.\n\nCreate a file called `compose.yaml` in your project directory and paste the following:\n\nThis Compose file defines two services: `web` and `redis`.\n\nThe `web` service uses an image that's built from the `Dockerfile` in the current directory. It then binds the container and the host machine to the exposed port, `8000`. This example service uses the default port for the Flask web server, `5000`.\n\nThe `redis` service uses a public [Redis](https://registry.hub.docker.com/_/redis/) image pulled from the Docker Hub registry.\n\nFor more information on the `compose.yaml` file, see [How Compose works](https://docs.docker.com/compose/compose-application-model/).\n\nWith a single command, you create and start all the services from your configuration file.\n\n1.  From your project directory, start up your application by running `docker compose up`.\n    \n    Compose pulls a Redis image, builds an image for your code, and starts the services you defined. In this case, the code is statically copied into the image at build time.\n    \n2.  Enter `http://localhost:8000/` in a browser to see the application running.\n    \n    If this doesn't resolve, you can also try `http://127.0.0.1:8000`.\n    \n    You should see a message in your browser saying:\n    \n    ![hello world in browser](https://docs.docker.com/compose/images/quick-hello-world-1.png)\n    \n3.  Refresh the page.\n    \n    The number should increment.\n    \n    ![hello world in browser](https://docs.docker.com/compose/images/quick-hello-world-2.png)\n    \n4.  Switch to another terminal window, and type `docker image ls` to list local images.\n    \n    Listing images at this point should return `redis` and `web`.\n    \n    You can inspect images with `docker inspect <tag or id>`.\n    \n5.  Stop the application, either by running `docker compose down` from within your project directory in the second terminal, or by hitting `CTRL+C` in the original terminal where you started the app.\n    \n\nEdit the `compose.yaml` file in your project directory to use `watch` so you can preview your running Compose services which are automatically updated as you edit and save your code:\n\nWhenever a file is changed, Compose syncs the file to the corresponding location under `/code` inside the container. Once copied, the bundler updates the running application without a restart.\n\nFor more information on how Compose Watch works, see [Use Compose Watch](https://docs.docker.com/compose/file-watch/). Alternatively, see [Manage data in containers](https://docs.docker.com/storage/volumes/) for other options.\n\n> **Note**\n> \n> For this example to work, the `--debug` option is added to the `Dockerfile`. The `--debug` option in Flask enables automatic code reload, making it possible to work on the backend API without the need to restart or rebuild the container. After changing the `.py` file, subsequent API calls will use the new code, but the browser UI will not automatically refresh in this small example. Most frontend development servers include native live reload support that works with Compose.\n\nFrom your project directory, type `docker compose watch` or `docker compose up --watch` to build and launch the app and start the file watch mode.\n\nCheck the `Hello World` message in a web browser again, and refresh to see the count increment.\n\nTo see Compose Watch in action:\n\n1.  Change the greeting in `app.py` and save it. For example, change the `Hello World!` message to `Hello from Docker!`:\n    \n2.  Refresh the app in your browser. The greeting should be updated, and the counter should still be incrementing.\n    \n    ![hello world in browser](https://docs.docker.com/compose/images/quick-hello-world-3.png)\n    \n3.  Once you're done, run `docker compose down`.\n    \n\nUsing multiple Compose files lets you customize a Compose application for different environments or workflows. This is useful for large applications that may use dozens of containers, with ownership distributed across multiple teams.\n\n1.  In your project folder, create a new Compose file called `infra.yaml`.\n    \n2.  Cut the Redis service from your `compose.yaml` file and paste it into your new `infra.yaml` file. Make sure you add the `services` top-level attribute at the top of your file. Your `infra.yaml` file should now look like this:\n    \n3.  In your `compose.yaml` file, add the `include` top-level attribute along with the path to the `infra.yaml` file.\n    \n4.  Run `docker compose up` to build the app with the updated Compose files, and run it. You should see the `Hello world` message in your browser.\n    \n\nThis is a simplified example, but it demonstrates the basic principle of `include` and how it can make it easier to modularize complex applications into sub-Compose files. For more information on `include` and working with multiple Compose files, see [Working with multiple Compose files](https://docs.docker.com/compose/multiple-compose-files/).\n\n*   If you want to run your services in the background, you can pass the `-d` flag (for \"detached\" mode) to `docker compose up` and use `docker compose ps` to see what is currently running:\n    \n*   Run `docker compose --help` to see other available commands.\n    \n*   If you started Compose with `docker compose up -d`, stop your services once you've finished with them:\n    \n*   You can bring everything down, removing the containers entirely, with the `docker compose down` command.\n    \n\n*   Try the [Sample apps with Compose](https://github.com/docker/awesome-compose)\n*   [Explore the full list of Compose commands](https://docs.docker.com/compose/reference/)\n*   [Explore the Compose file reference](https://docs.docker.com/compose/compose-file/)\n*   [Check out the Learning Docker Compose video on LinkedIn Learning](https://www.linkedin.com/learning/learning-docker-compose/)",
  "title": "Docker Compose Quickstart | Docker Docs\n",
  "description": "Check out this tutorial on how to use Docker Compose from defining application dependencies to experimenting with commands.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/file-watch/",
  "markdown": "# Use Compose Watch | Docker Docs\n\nIntroduced in Docker Compose version [2.22.0](https://docs.docker.com/compose/release-notes/#2220)\n\nThe `watch` attribute automatically updates and previews your running Compose services as you edit and save your code. For many projects, this enables a hands-off development workflow once Compose is running, as services automatically update themselves when you save your work.\n\n`watch` adheres to the following file path rules:\n\n*   All paths are relative to the project directory\n*   Directories are watched recursively\n*   Glob patterns aren't supported\n*   Rules from `.dockerignore` apply\n    *   Use `ignore` option to define additional paths to be ignored (same syntax)\n    *   Temporary/backup files for common IDEs (Vim, Emacs, JetBrains, & more) are ignored automatically\n    *   `.git` directories are ignored automatically\n\nYou don't need to switch on `watch` for all services in a Compose project. In some instances, only part of the project, for example the Javascript frontend, might be suitable for automatic updates.\n\nCompose supports sharing a host directory inside service containers. Watch mode does not replace this functionality but exists as a companion specifically suited to developing in containers.\n\nMore importantly, `watch` allows for greater granularity than is practical with a bind mount. Watch rules let you ignore specific files or entire directories within the watched tree.\n\nFor example, in a JavaScript project, ignoring the `node_modules/` directory has two benefits:\n\n*   Performance. File trees with many small files can cause high I/O load in some configurations\n*   Multi-platform. Compiled artifacts cannot be shared if the host OS or architecture is different to the container\n\nFor example, in a Node.js project, it's not recommended to sync the `node_modules/` directory. Even though JavaScript is interpreted, `npm` packages can contain native code that is not portable across platforms.\n\nThe `watch` attribute defines a list of rules that control automatic service updates based on local file changes.\n\nEach rule requires, a `path` pattern and `action` to take when a modification is detected. There are two possible actions for `watch` and depending on the `action`, additional fields might be accepted or required.\n\nWatch mode can be used with many different languages and frameworks. The specific paths and rules will vary from project to project, but the concepts remain the same.\n\n### [Prerequisites](#prerequisites)\n\nIn order to work properly, `watch` relies on common executables. Make sure your service image contains the following binaries:\n\n*   stat\n*   mkdir\n*   rmdir\n\n`watch` also requires that the container's `USER` can write to the target path so it can update files. A common pattern is for initial content to be copied into the container using the `COPY` instruction in a Dockerfile. To ensure such files are owned by the configured user, use the `COPY --chown` flag:\n\n### [`action`](#action)\n\n#### [Sync](#sync)\n\nIf `action` is set to `sync`, Compose makes sure any changes made to files on your host automatically match with the corresponding files within the service container.\n\n`sync` is ideal for frameworks that support \"Hot Reload\" or equivalent functionality.\n\nMore generally, `sync` rules can be used in place of bind mounts for many development use cases.\n\n#### [Rebuild](#rebuild)\n\nIf `action` is set to `rebuild`, Compose automatically builds a new image with BuildKit and replaces the running service container.\n\nThe behavior is the same as running `docker compose up --build <svc>`.\n\nRebuild is ideal for compiled languages or as fallbacks for modifications to particular files that require a full image rebuild (e.g. `package.json`).\n\n#### [Sync + Restart](#sync--restart)\n\nIf `action` is set to `sync+restart`, Compose synchronizes your changes with the service containers and restarts it.\n\n`sync+restart` is ideal when config file changes, and you don't need to rebuild the image but just restart the main process of the service containers. It will work well when you update a database configuration or your `nginx.conf` file for example\n\n> **Tip**\n> \n> Optimize your `Dockerfile` for speedy incremental rebuilds with [image layer caching](https://docs.docker.com/build/cache) and [multi-stage builds](https://docs.docker.com/build/building/multi-stage/).\n\n### [`path` and `target`](#path-and-target)\n\nThe `target` field controls how the path is mapped into the container.\n\nFor `path: ./app/html` and a change to `./app/html/index.html`:\n\n*   `target: /app/html` -> `/app/html/index.html`\n*   `target: /app/static` -> `/app/static/index.html`\n*   `target: /assets` -> `/assets/index.html`\n\nThis minimal example targets a Node.js application with the following structure:\n\nIn this example, when running `docker compose up --watch`, a container for the `web` service is launched using an image built from the `Dockerfile` in the project's root. The `web` service runs `npm start` for its command, which then launches a development version of the application with Hot Module Reload enabled in the bundler (Webpack, Vite, Turbopack, etc).\n\nAfter the service is up, the watch mode starts monitoring the target directories and files. Then, whenever a source file in the `web/` directory is changed, Compose syncs the file to the corresponding location under `/src/web` inside the container. For example, `./web/App.jsx` is copied to `/src/web/App.jsx`.\n\nOnce copied, the bundler updates the running application without a restart.\n\nUnlike source code files, adding a new dependency canâ€™t be done on-the-fly, so whenever `package.json` is changed, Compose rebuilds the image and recreates the `web` service container.\n\nThis pattern can be followed for many languages and frameworks, such as Python with Flask: Python source files can be synced while a change to `requirements.txt` should trigger a rebuild.\n\nAdapting the previous example to demonstrate `sync+restart`:\n\nThis setup demonstrates how to use the `sync+restart` action in Docker Compose to efficiently develop and test a Node.js application with a frontend web server and backend service. The configuration ensures that changes to the application code and configuration files are quickly synchronized and applied, with the `web` service restarting as needed to reflect the changes.\n\n1.  Add `watch` sections to one or more services in `compose.yaml`.\n2.  Run `docker compose up --watch` to build and launch a Compose project and start the file watch mode.\n3.  Edit service source files using your preferred IDE or editor.\n\n> **Tip**\n> \n> Watch can also be used with the dedicated `docker compose watch` command if you don't want to get the application logs mixed with the (re)build logs and filesystem sync events.\n\n> **Looking for a sample project to test things out?**\n> \n> Check out [`dockersamples/avatars`](https://github.com/dockersamples/avatars), or [local setup for Docker docs](https://github.com/docker/docs/blob/main/CONTRIBUTING.md) for a demonstration of Compose `watch`.\n\nWe are actively looking for feedback on this feature. Give feedback or report any bugs you may find in the [Compose Specification repository](https://github.com/compose-spec/compose-spec/pull/253).\n\n*   [Compose Develop Specification](https://docs.docker.com/compose/compose-file/develop/)",
  "title": "Use Compose Watch | Docker Docs\n",
  "description": "Use File watch to automatically update running services as you work",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/project-name/",
  "markdown": "# Specify a project name | Docker Docs\n\nIn Compose, the default project name is derived from the base name of the project directory. However, you have the flexibility to set a custom project name.\n\nThis page offers examples of scenarios where custom project names can be helpful, outlines the various methods to set a project name, and provides the order of precedence for each approach.\n\n> **Note**\n> \n> The default project directory is the base directory of the Compose file. A custom value can also be set for it using the [`--project-directory` command line option](https://docs.docker.com/compose/reference/).\n\nCompose uses a project name to isolate environments from each other. There are multiple contexts where a project name is useful:\n\n*   On a development host: Create multiple copies of a single environment, useful for running stable copies for each feature branch of a project.\n*   On a CI server: Prevent interference between builds by setting the project name to a unique build number.\n*   On a shared or development host: Avoid interference between different projects that might share the same service names.\n\nProject names must contain only lowercase letters, decimal digits, dashes, and underscores, and must begin with a lowercase letter or decimal digit. If the base name of the project directory or current directory violates this constraint, alternative mechanisms are available.\n\nThe precedence order for each method, from highest to lowest, is as follows:\n\n1.  The `-p` command line flag.\n2.  The [COMPOSE\\_PROJECT\\_NAME environment variable](https://docs.docker.com/compose/environment-variables/envvars/).\n3.  The [top-level `name:` attribute](https://docs.docker.com/compose/compose-file/04-version-and-name/) in your Compose file. Or the last `name:` if you [specify multiple Compose files](https://docs.docker.com/compose/multiple-compose-files/merge/) in the command line with the `-f` flag.\n4.  The base name of the project directory containing your Compose file. Or the base name of the first Compose file if you [specify multiple Compose files](https://docs.docker.com/compose/multiple-compose-files/merge/) in the command line with the `-f` flag.\n5.  The base name of the current directory if no Compose file is specified.\n\n*   Read up on [working with multiple Compose files](https://docs.docker.com/compose/multiple-compose-files/).\n*   Explore some [sample apps](https://docs.docker.com/compose/samples-for-compose/).",
  "title": "Specify a project name | Docker Docs\n",
  "description": "Understand the different ways you can set a project name in Compose and what the precedence is.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/use-secrets/",
  "markdown": "# How to use secrets in Docker Compose\n\nA secret is any piece of data, such as a password, certificate, or API key, that shouldnâ€™t be transmitted over a network or stored unencrypted in a Dockerfile or in your applicationâ€™s source code.\n\nDocker Compose provides a way for you to use secrets without having to use environment variables to store information. If youâ€™re injecting passwords and API keys as environment variables, you risk unintentional information exposure. Services can only access secrets when explicitly granted by a `secrets` attribute within the `services` top-level element.\n\nEnvironment variables are often available to all processes, and it can be difficult to track access. They can also be printed in logs when debugging errors without your knowledge. Using secrets mitigates these risks.\n\nGetting a secret into a container is a two-step process. First, define the secret using the [top-level secrets element in your Compose file](https://docs.docker.com/compose/compose-file/09-secrets/). Next, update your service definitions to reference the secrets they require with the [secrets attribute](https://docs.docker.com/compose/compose-file/05-services/#secrets). Compose grants access to secrets on a per-service basis.\n\nUnlike the other methods, this permits granular access control within a service container via standard filesystem permissions.\n\n### [Simple](#simple)\n\nIn the following example, the frontend service is given access to the `my_secret` secret. In the container, `/run/secrets/my_secret` is set to the contents of the file `./my_secret.txt`.\n\n### [Advanced](#advanced)\n\nIn the advanced example above:\n\n*   The `secrets` attribute under each service defines the secrets you want to inject into the specific container.\n*   The top-level `secrets` section defines the variables `db_password` and `db_root_password` and provides the `file` that populates their values.\n*   The deployment of each container means Docker creates a temporary filesystem mount under `/run/secrets/<secret_name>` with their specific values.\n\n> **Note**\n> \n> The `_FILE` environment variables demonstrated here are a convention used by some images, including Docker Official Images like [mysql](https://hub.docker.com/_/mysql) and [postgres](https://hub.docker.com/_/postgres).\n\n*   [Secrets top-level element](https://docs.docker.com/compose/compose-file/09-secrets/)\n*   [Secrets attribute for services top-level element](https://docs.docker.com/compose/compose-file/05-services/#secrets)",
  "title": "How to use secrets in Docker Compose | Docker Docs\n",
  "description": "How to use secrets in Compose and their benefits",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/install/uninstall/",
  "markdown": "# Uninstall Docker Compose | Docker Docs\n\nUninstalling Docker Compose depends on the method you have used to install Docker Compose. On this page you can find specific instructions to uninstall Docker Compose.\n\nIf you want to uninstall Compose and you have installed Docker Desktop, see [Uninstall Docker Desktop](https://docs.docker.com/desktop/uninstall/).\n\n> **Note**\n> \n> Unless you have other Docker instances installed on that specific environment, you would be removing Docker altogether by uninstalling the Desktop.\n\nTo remove the Compose CLI plugin, run:\n\nUbuntu, Debian:\n\nRPM-based distros:\n\n### [Manually installed](#manually-installed)\n\nIf you used `curl` to install Compose CLI plugin, to uninstall it, run:\n\n### [Remove for all users](#remove-for-all-users)\n\nOr, if you have installed Compose for all users, run:\n\n> Got a **Permission denied** error?\n> \n> If you get a **Permission denied** error using either of the above methods, you do not have the permissions allowing you to remove `docker-compose`. To force the removal, prepend `sudo` to either of the above instructions and run it again.\n\n### [Inspect the location of the Compose CLI plugin](#inspect-the-location-of-the-compose-cli-plugin)\n\nTo check where Compose is installed, use:",
  "title": "Uninstall Docker Compose | Docker Docs\n",
  "description": "How to uninstall Docker Compose",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/production/",
  "markdown": "# Use Compose in production | Docker Docs\n\nWhen you define your app with Compose in development, you can use this definition to run your application in different environments such as CI, staging, and production.\n\nThe easiest way to deploy an application is to run it on a single server, similar to how you would run your development environment. If you want to scale up your application, you can run Compose apps on a Swarm cluster.\n\n### [Modify your Compose file for production](#modify-your-compose-file-for-production)\n\nYou may need to make changes to your app configuration to make it ready for production. These changes might include:\n\n*   Removing any volume bindings for application code, so that code stays inside the container and can't be changed from outside\n*   Binding to different ports on the host\n*   Setting environment variables differently, such as reducing the verbosity of logging, or to specify settings for external services such as an email server\n*   Specifying a restart policy like [`restart: always`](https://docs.docker.com/compose/compose-file/05-services/#restart)to avoid downtime\n*   Adding extra services such as a log aggregator\n\nFor this reason, consider defining an additional Compose file, for example `production.yml`, which specifies production-appropriate configuration. This configuration file only needs to include the changes you want to make from the original Compose file. The additional Compose file is then applied over the original `compose.yml` to create a new configuration.\n\nOnce you have a second configuration file, you can use it with the `-f` option:\n\nSee [Using multiple compose files](https://docs.docker.com/compose/multiple-compose-files/) for a more complete example, and other options.\n\n### [Deploying changes](#deploying-changes)\n\nWhen you make changes to your app code, remember to rebuild your image and recreate your app's containers. To redeploy a service called `web`, use:\n\nThis first command rebuilds the image for `web` and then stops, destroys, and recreates just the `web` service. The `--no-deps` flag prevents Compose from also recreating any services which `web` depends on.\n\n### [Running Compose on a single server](#running-compose-on-a-single-server)\n\nYou can use Compose to deploy an app to a remote Docker host by setting the `DOCKER_HOST`, `DOCKER_TLS_VERIFY`, and `DOCKER_CERT_PATH` environment variables appropriately. For more information, see [pre-defined environment variables](https://docs.docker.com/compose/environment-variables/envvars/).\n\nOnce you've set up your environment variables, all the normal `docker compose` commands work with no further configuration.",
  "title": "Use Compose in production | Docker Docs\n",
  "description": "Guide to using Docker Compose in production",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/multiple-compose-files/",
  "markdown": "# Overview | Docker Docs\n\nThis section contains information on the ways you can work with multiple Compose files.\n\nUsing multiple Compose files lets you customize a Compose application for different environments or workflows. This is useful for large applications that may use dozens of containers, with ownership distributed across multiple teams. For example, if your organization or team uses a monorepo, each team may have their own â€œlocalâ€ Compose file to run a subset of the application. They then need to rely on other teams to provide a reference Compose file that defines the expected way to run their own subset. Complexity moves from the code in to the infrastructure and the configuration file.\n\nThe quickest way to work with multiple Compose files is to [merge](https://docs.docker.com/compose/multiple-compose-files/merge/) Compose files using the `-f` flag in the command line to list out your desired Compose files. However, [merging rules](https://docs.docker.com/compose/multiple-compose-files/merge/#merging-rules) means this can soon get quite complicated.\n\nDocker Compose provides two other options to manage this complexity when working with multiple Compose files. Depending on your project's needs, you can:\n\n*   [Extend a Compose file](https://docs.docker.com/compose/multiple-compose-files/extends/) by referring to another Compose file and selecting the bits you want to use in your own application, with the ability to override some attributes.\n*   [Include other Compose files](https://docs.docker.com/compose/multiple-compose-files/include/) directly in your Compose file.",
  "title": "Overview | Docker Docs\n",
  "description": "General overview for the different ways you can work with multiple compose files in Docker Compose",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/multiple-compose-files/extends/",
  "markdown": "# Extend your Compose file | Docker Docs\n\nDocker Compose's [`extends` attribute](https://docs.docker.com/compose/compose-file/05-services/#extends) lets you share common configurations among different files, or even different projects entirely.\n\nExtending services is useful if you have several services that reuse a common set of configuration options. With `extends` you can define a common set of service options in one place and refer to it from anywhere. You can refer to another Compose file and select a service you want to also use in your own application, with the ability to override some attributes for your own needs.\n\n> **Important**\n> \n> When you use multiple Compose files, you must make sure all paths in the files are relative to the base Compose file (i.e. the Compose file in your main-project folder). This is required because extend files need not be valid Compose files. Extend files can contain small fragments of configuration. Tracking which fragment of a service is relative to which path is difficult and confusing, so to keep paths easier to understand, all paths must be defined relative to the base file.\n\n### [Extending services from another file](#extending-services-from-another-file)\n\nTake the following example:\n\nThis instructs Compose to re-use only the properties of the `webapp` service defined in the `common-services.yml` file. The `webapp` service itself is not part of the final project.\n\nIf `common-services.yml` looks like this:\n\nYou get exactly the same result as if you wrote `docker-compose.yml` with the same `build`, `ports`, and `volumes` configuration values defined directly under `web`.\n\nTo include the service `webapp` in the final project when extending services from another file, you need to explicitly include both services in your current Compose file. For example (note this is a non-normative example):\n\nAlternatively, you can use [include](https://docs.docker.com/compose/multiple-compose-files/include/).\n\n### [Extending services within the same file](#extending-services-within-the-same-file)\n\nIf you define services in the same Compose file and extend one service from another, both the original service and the extended service will be part of your final configuration. For example:\n\n### [Extending services within the same file and from another file](#extending-services-within-the-same-file-and-from-another-file)\n\nYou can go further and define, or re-define, configuration locally in `compose.yaml`:\n\nExtending an individual service is useful when you have multiple services that have a common configuration. The example below is a Compose app with two services, a web application and a queue worker. Both services use the same codebase and share many configuration options.\n\nThe `common.yaml` file defines the common configuration:\n\nThe `docker-compose.yaml` defines the concrete services which use the common configuration:\n\n`volumes_from` and `depends_on` are never shared between services using `extends`. These exceptions exist to avoid implicit dependencies; you always define `volumes_from` locally. This ensures dependencies between services are clearly visible when reading the current file. Defining these locally also ensures that changes to the referenced file don't break anything.\n\n`extends` is useful if you only need a single service to be shared and you are familiar with the file you're extending to, so you can tweak the configuration. But this isnâ€™t an acceptable solution when you want to re-use someone else's unfamiliar configurations and you donâ€™t know about its own dependencies.\n\nWhen using `extends` with a `file` attribute which points to another folder, relative paths declared by the service being extended are converted so they still point to the same file when used by the extending service. This is illustrated in the following example:\n\nBase Compose file:\n\nThe `commons/compose.yaml` file:\n\nThe resulting service refers to the original `container.env` file within the `commons` directory. This can be confirmed with `docker compose config` which inspects the actual model:\n\n*   [`extends`](https://docs.docker.com/compose/compose-file/05-services/#extends)",
  "title": "Extend your Compose file | Docker Docs\n",
  "description": "How to use Docker Compose's extends keyword to share configuration between files and projects",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/multiple-compose-files/merge/",
  "markdown": "# Merge Compose files | Docker Docs\n\nDocker Compose lets you merge and override a set of Compose files together to create a composite Compose file.\n\nBy default, Compose reads two files, a `compose.yml` and an optional `compose.override.yml` file. By convention, the `compose.yml` contains your base configuration. The override file can contain configuration overrides for existing services or entirely new services.\n\nIf a service is defined in both files, Compose merges the configurations using the rules described below and in the [Compose Specification](https://docs.docker.com/compose/compose-file/13-merge/).\n\nTo use multiple override files, or an override file with a different name, you can either use the pre-defined [COMPOSE\\_FILE](https://docs.docker.com/compose/environment-variables/envvars/#compose_file) environment variable, or use the `-f` option to specify the list of files.\n\nCompose merges files in the order they're specified on the command line. Subsequent files may merge, override, or add to their predecessors.\n\nFor example:\n\nThe `compose.yml` file might specify a `webapp` service.\n\nThe `compose.admin.yml` may also specify this same service:\n\nAny matching fields override the previous file. New values, add to the `webapp` service configuration:\n\n> **Important**\n> \n> When you use multiple Compose files, you must make sure all paths in the files are relative to the base Compose file (the first Compose file specified with `-f`). This is required because override files need not be valid Compose files. Override files can contain small fragments of configuration. Tracking which fragment of a service is relative to which path is difficult and confusing, so to keep paths easier to understand, all paths must be defined relative to the base file.\n\n### [Additional information](#additional-information)\n\n*   Using `-f` is optional. If not provided, Compose searches the working directory and its parent directories for a `compose.yml` and a `compose.override.yml` file. You must supply at least the `compose.yml` file. If both files exist on the same directory level, Compose combines them into a single configuration.\n    \n*   When you use multiple Compose files, all paths in the files are relative to the first configuration file specified with `-f`. You can use the `--project-directory` option to override this base path.\n    \n*   You can use a `-f` with `-` (dash) as the filename to read the configuration from `stdin`. For example:\n    \n    When `stdin` is used, all paths in the configuration are relative to the current working directory.\n    \n*   You can use the `-f` flag to specify a path to a Compose file that is not located in the current directory, either from the command line or by setting up a [COMPOSE\\_FILE environment variable](https://docs.docker.com/compose/environment-variables/envvars/#compose_file) in your shell or in an environment file.\n    \n    For example, if you are running the [Compose Rails sample](https://github.com/docker/awesome-compose/tree/master/official-documentation-samples/rails/README.md), and have a `compose.yml` file in a directory called `sandbox/rails`. You can use a command like [docker compose pull](https://docs.docker.com/reference/cli/docker/compose/pull/) to get the postgres image for the `db` service from anywhere by using the `-f` flag as follows: `docker compose -f ~/sandbox/rails/compose.yml pull db`\n    \n    Here's the full example:\n    \n\nCompose copies configurations from the original service over to the local one. If a configuration option is defined in both the original service and the local service, the local value replaces or extends the original value.\n\nFor single-value options like `image`, `command` or `mem_limit`, the new value replaces the old value.\n\noriginal service:\n\nlocal service:\n\nresult:\n\nFor the multi-value options `ports`, `expose`, `external_links`, `dns`, `dns_search`, and `tmpfs`, Compose concatenates both sets of values:\n\noriginal service:\n\nlocal service:\n\nresult:\n\nIn the case of `environment`, `labels`, `volumes`, and `devices`, Compose \"merges\" entries together with locally defined values taking precedence. For `environment` and `labels`, the environment variable or label name determines which value is used:\n\noriginal service:\n\nlocal service:\n\nresult:\n\nEntries for `volumes` and `devices` are merged using the mount path in the container:\n\noriginal service:\n\nlocal service:\n\nresult:\n\nFor more merging rules, see [Merge and override](https://docs.docker.com/compose/compose-file/13-merge/) in the Compose Specification.\n\nA common use case for multiple files is changing a development Compose app for a production-like environment (which may be production, staging or CI). To support these differences, you can split your Compose configuration into a few different files:\n\nStart with a base file that defines the canonical configuration for the services.\n\n`compose.yml`\n\nIn this example the development configuration exposes some ports to the host, mounts our code as a volume, and builds the web image.\n\n`compose.override.yml`\n\nWhen you run `docker compose up` it reads the overrides automatically.\n\nTo use this Compose app in a production environment, another override file is created, which might be stored in a different git repo or managed by a different team.\n\n`compose.prod.yml`\n\nTo deploy with this production Compose file you can run\n\nThis deploys all three services using the configuration in `compose.yml` and `compose.prod.yml` but not the dev configuration in `compose.override.yml`.\n\nFor more information, see [Using Compose in production](https://docs.docker.com/compose/production/).\n\nDocker Compose supports relative paths for the many resources to be included in the application model: build context for service images, location of file defining environment variables, path to a local directory used in a bind-mounted volume. With such a constraint, code organization in a monorepo can become hard as a natural choice would be to have dedicated folders per team or component, but then the Compose files relative paths become irrelevant.\n\n*   [Merge rules](https://docs.docker.com/compose/compose-file/13-merge/)",
  "title": "Merge Compose files | Docker Docs\n",
  "description": "How merging Compose files works",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/multiple-compose-files/include/",
  "markdown": "# Include | Docker Docs\n\nIntroduced in Docker Compose version [2.20.3](https://docs.docker.com/compose/release-notes/#2203)\n\nWith `include`, you can incorporate a separate `compose.yaml` file directly in your current `compose.yaml` file. This makes it easy to modularize complex applications into sub-Compose files, which in turn enables application configurations to be made simpler and more explicit.\n\nThe [`include` top-level element](https://docs.docker.com/compose/compose-file/14-include/) helps to reflect the engineering team responsible for the code directly in the config file's organization. It also solves the relative path problem that [`extends`](https://docs.docker.com/compose/multiple-compose-files/extends/) and [merge](https://docs.docker.com/compose/multiple-compose-files/merge/) present.\n\nEach path listed in the `include` section loads as an individual Compose application model, with its own project directory, in order to resolve relative paths.\n\nOnce the included Compose application loads, all resources are copied into the current Compose application model.\n\n> **Note**\n> \n> `include` applies recursively so an included Compose file which declares its own `include` section, results in those other files being included as well.\n\n`my-compose-include.yaml` manages `serviceB` which details some replicas, web UI to inspect data, isolated networks, volumes for data persistence, etc. The application relying on `serviceB` doesnâ€™t need to know about the infrastructure details, and consumes the Compose file as a building block it can rely on.\n\nThis means the team managing `serviceB` can refactor its own database component to introduce additional services without impacting any dependent teams. It also means that the dependent teams don't need to include additional flags on each Compose command they run.\n\nCompose reports an error if any resource from `include` conflicts with resources from the included Compose file. This rule prevents unexpected conflicts with resources defined by the included compose file author. However, there may be some circumstances where you might want to tweak the included model. This can be achieved by adding an override file to the include directive:\n\nThe main limitation with this approach is that you need to maintain a dedicated override file per include. For complex projects with multiple includes this would result into many Compose files.\n\nThe other option is to use a `compose.override.yaml` file. While conflicts will be rejected from the file using `include` when same resource is declared, a global Compose override file can override the resulting merged model, as demonstrated in following example:\n\nMain `compose.yaml` file:\n\nOverride `compose.override.yaml` file:\n\nCombined together, this allows you to benefit from third-party reusable components, and adjust the Compose model for your needs.\n\n[`include` top-level element](https://docs.docker.com/compose/compose-file/14-include/)",
  "title": "Include | Docker Docs\n",
  "description": "How to use Docker Compose's include top-level element",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/samples-for-compose/",
  "markdown": "# Sample apps with Compose | Docker Docs\n\nThe following samples show the various aspects of how to work with Docker Compose. As a prerequisite, be sure to [install Docker Compose](https://docs.docker.com/compose/install/) if you have not already done so.\n\nThe samples should help you to:\n\n*   Define services based on Docker images using [Compose files](https://docs.docker.com/compose/compose-file/): `compose.yml` and `docker-stack.yml`\n*   Understand the relationship between `compose.yml` and [Dockerfiles](https://docs.docker.com/reference/dockerfile/)\n*   Learn how to make calls to your application services from Compose files\n*   Learn how to deploy applications and services to a [swarm](https://docs.docker.com/engine/swarm/)\n\nThese samples focus specifically on Docker Compose:\n\n*   [Quickstart: Compose and ELK](https://github.com/docker/awesome-compose/tree/master/elasticsearch-logstash-kibana/README.md) - Shows how to use Docker Compose to set up and run ELK - Elasticsearch-Logstash-Kibana.\n    \n*   [Quickstart: Compose and Django](https://github.com/docker/awesome-compose/tree/master/official-documentation-samples/django/README.md) - Shows how to use Docker Compose to set up and run a simple Django/PostgreSQL app.\n    \n*   [Quickstart: Compose and Rails](https://github.com/docker/awesome-compose/tree/master/official-documentation-samples/rails/README.md) - Shows how to use Docker Compose to set up and run a Rails/PostgreSQL app.\n    \n*   [Quickstart: Compose and WordPress](https://github.com/docker/awesome-compose/tree/master/official-documentation-samples/wordpress/README.md) - Shows how to use Docker Compose to set up and run WordPress in an isolated environment with Docker containers.\n    \n\nThe Awesome Compose samples provide a starting point on how to integrate different frameworks and technologies using Docker Compose. All samples are available in the [Awesome-compose GitHub repo](https://github.com/docker/awesome-compose) and are ready to run with `docker compose up`.",
  "title": "Sample apps with Compose | Docker Docs\n",
  "description": "Summary of samples related to Compose",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/startup-order/",
  "markdown": "# Control startup and shutdown order in Compose\n\nYou can control the order of service startup and shutdown with the [depends\\_on](https://docs.docker.com/compose/compose-file/05-services/#depends_on) attribute. Compose always starts and stops containers in dependency order, where dependencies are determined by `depends_on`, `links`, `volumes_from`, and `network_mode: \"service:...\"`.\n\nA good example of when you might use this is an application which needs to access a database. If both services are started with `docker compose up`, there is a chance this will fail since the application service might start before the database service and won't find a database able to handle its SQL statements.\n\nOn startup, Compose does not wait until a container is \"ready\", only until it's running. This can cause issues if, for example, you have a relational database system that needs to start its own services before being able to handle incoming connections.\n\nThe solution for detecting the ready state of a service is to use the `condition` attribute with one of the following options:\n\n*   `service_started`\n*   `service_healthy`. This specifies that a dependency is expected to be â€œhealthyâ€, which is defined with `healthcheck`, before starting a dependent service.\n*   `service_completed_successfully`. This specifies that a dependency is expected to run to successful completion before starting a dependent service.\n\nCompose creates services in dependency order. `db` and `redis` are created before `web`.\n\nCompose waits for healthchecks to pass on dependencies marked with `service_healthy`. `db` is expected to be \"healthy\" (as indicated by `healthcheck`) before `web` is created.\n\nThe healthcheck for the `db` service uses the `pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}'` command to check if the PostgreSQL database is ready. The service is retried every 10 seconds, up to 5 times.\n\nCompose also removes services in dependency order. `web` is removed before `db` and `redis`.\n\n*   [`depends_on`](https://docs.docker.com/compose/compose-file/05-services/#depends_on)\n*   [`healthcheck`](https://docs.docker.com/compose/compose-file/05-services/#healthcheck)",
  "title": "Control startup and shutdown order in Compose | Docker Docs\n",
  "description": "How to control service startup and shutdown order in Docker Compose",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/networking/",
  "markdown": "# Networking in Compose | Docker Docs\n\n> **Important**\n> \n> Docker's documentation refers to and describes Compose V2 functionality.\n> \n> Effective July 2023, Compose V1 stopped receiving updates and is no longer in new Docker Desktop releases. Compose V2 has replaced it and is now integrated into all current Docker Desktop versions. For more information, see [Migrate to Compose V2](https://docs.docker.com/compose/migrate).\n\nBy default Compose sets up a single [network](https://docs.docker.com/reference/cli/docker/network/create/) for your app. Each container for a service joins the default network and is both reachable by other containers on that network, and discoverable by the service's name.\n\n> **Note**\n> \n> Your app's network is given a name based on the \"project name\", which is based on the name of the directory it lives in. You can override the project name with either the [`--project-name` flag](https://docs.docker.com/compose/reference/) or the [`COMPOSE_PROJECT_NAME` environment variable](https://docs.docker.com/compose/environment-variables/envvars/#compose_project_name).\n\nFor example, suppose your app is in a directory called `myapp`, and your `compose.yml` looks like this:\n\nWhen you run `docker compose up`, the following happens:\n\n1.  A network called `myapp_default` is created.\n2.  A container is created using `web`'s configuration. It joins the network `myapp_default` under the name `web`.\n3.  A container is created using `db`'s configuration. It joins the network `myapp_default` under the name `db`.\n\nEach container can now look up the service name `web` or `db` and get back the appropriate container's IP address. For example, `web`'s application code could connect to the URL `postgres://db:5432` and start using the Postgres database.\n\nIt is important to note the distinction between `HOST_PORT` and `CONTAINER_PORT`. In the above example, for `db`, the `HOST_PORT` is `8001` and the container port is `5432` (postgres default). Networked service-to-service communication uses the `CONTAINER_PORT`. When `HOST_PORT` is defined, the service is accessible outside the swarm as well.\n\nWithin the `web` container, your connection string to `db` would look like `postgres://db:5432`, and from the host machine, the connection string would look like `postgres://{DOCKER_IP}:8001` for example `postgres://localhost:8001` if your container is running locally.\n\nIf you make a configuration change to a service and run `docker compose up` to update it, the old container is removed and the new one joins the network under a different IP address but the same name. Running containers can look up that name and connect to the new address, but the old address stops working.\n\nIf any containers have connections open to the old container, they are closed. It is a container's responsibility to detect this condition, look up the name again and reconnect.\n\n> **Tip**\n> \n> Reference containers by name, not IP, whenever possible. Otherwise youâ€™ll need to constantly update the IP address you use.\n\nLinks allow you to define extra aliases by which a service is reachable from another service. They are not required to enable services to communicate. By default, any service can reach any other service at that service's name. In the following example, `db` is reachable from `web` at the hostnames `db` and `database`:\n\nSee the [links reference](https://docs.docker.com/compose/compose-file/05-services/#links) for more information.\n\nWhen deploying a Compose application on a Docker Engine with [Swarm mode enabled](https://docs.docker.com/engine/swarm/), you can make use of the built-in `overlay` driver to enable multi-host communication.\n\nOverlay networks are always created as `attachable`. You can optionally set the [`attachable`](https://docs.docker.com/compose/compose-file/06-networks/#attachable) property to `false`.\n\nConsult the [Swarm mode section](https://docs.docker.com/engine/swarm/), to see how to set up a Swarm cluster, and the [Getting started with multi-host networking](https://docs.docker.com/network/network-tutorial-overlay/) to learn about multi-host overlay networks.\n\nInstead of just using the default app network, you can specify your own networks with the top-level `networks` key. This lets you create more complex topologies and specify [custom network drivers](https://docs.docker.com/engine/extend/plugins_network/) and options. You can also use it to connect services to externally-created networks which aren't managed by Compose.\n\nEach service can specify what networks to connect to with the service-level `networks` key, which is a list of names referencing entries under the top-level `networks` key.\n\nThe following example shows a Compose file which defines two custom networks. The `proxy` service is isolated from the `db` service, because they do not share a network in common. Only `app` can talk to both.\n\nNetworks can be configured with static IP addresses by setting the [ipv4\\_address and/or ipv6\\_address](https://docs.docker.com/compose/compose-file/05-services/#ipv4_address-ipv6_address) for each attached network.\n\nNetworks can also be given a [custom name](https://docs.docker.com/compose/compose-file/06-networks/#name):\n\nInstead of, or as well as, specifying your own networks, you can also change the settings of the app-wide default network by defining an entry under `networks` named `default`:\n\nIf you want your containers to join a pre-existing network, use the [`external` option](https://docs.docker.com/compose/compose-file/06-networks/#external)\n\nInstead of attempting to create a network called `[projectname]_default`, Compose looks for a network called `my-pre-existing-network` and connects your app's containers to it.\n\nFor full details of the network configuration options available, see the following references:\n\n*   [Top-level `networks` element](https://docs.docker.com/compose/compose-file/06-networks/)\n*   [Service-level `networks` attribute](https://docs.docker.com/compose/compose-file/05-services/#networks)",
  "title": "Networking in Compose | Docker Docs\n",
  "description": "How Docker Compose sets up networking between containers",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/faq/",
  "markdown": "# Compose FAQs | Docker Docs\n\n### [What is the difference between `docker compose` and `docker-compose`](#what-is-the-difference-between-docker-compose-and-docker-compose)\n\nVersion one of the Docker Compose command-line binary was first released in 2014. It was written in Python, and is invoked with `docker-compose`. Typically, Compose V1 projects include a top-level version element in the compose.yml file, with values ranging from 2.0 to 3.8, which refer to the specific file formats.\n\nVersion two of the Docker Compose command-line binary was announced in 2020, is written in Go, and is invoked with `docker compose`. Compose V2 ignores the version top-level element in the compose.yml file.\n\nFor further information, see [History and development of Compose](https://docs.docker.com/compose/intro/history/).\n\n### [What's the difference between `up`, `run`, and `start`?](#whats-the-difference-between-up-run-and-start)\n\nTypically, you want `docker compose up`. Use `up` to start or restart all the services defined in a `compose.yml`. In the default \"attached\" mode, you see all the logs from all the containers. In \"detached\" mode (`-d`), Compose exits after starting the containers, but the containers continue to run in the background.\n\nThe `docker compose run` command is for running \"one-off\" or \"adhoc\" tasks. It requires the service name you want to run and only starts containers for services that the running service depends on. Use `run` to run tests or perform an administrative task such as removing or adding data to a data volume container. The `run` command acts like `docker run -ti` in that it opens an interactive terminal to the container and returns an exit status matching the exit status of the process in the container.\n\nThe `docker compose start` command is useful only to restart containers that were previously created but were stopped. It never creates new containers.\n\n### [Why do my services take 10 seconds to recreate or stop?](#why-do-my-services-take-10-seconds-to-recreate-or-stop)\n\nThe `docker compose stop` command attempts to stop a container by sending a `SIGTERM`. It then waits for a [default timeout of 10 seconds](https://docs.docker.com/reference/cli/docker/compose/stop/). After the timeout, a `SIGKILL` is sent to the container to forcefully kill it. If you are waiting for this timeout, it means that your containers aren't shutting down when they receive the `SIGTERM` signal.\n\nThere has already been a lot written about this problem of [processes handling signals](https://medium.com/@gchudnov/trapping-signals-in-docker-containers-7a57fdda7d86) in containers.\n\nTo fix this problem, try the following:\n\n*   Make sure you're using the exec form of `CMD` and `ENTRYPOINT` in your Dockerfile.\n    \n    For example use `[\"program\", \"arg1\", \"arg2\"]` not `\"program arg1 arg2\"`. Using the string form causes Docker to run your process using `bash` which doesn't handle signals properly. Compose always uses the JSON form, so don't worry if you override the command or entrypoint in your Compose file.\n    \n*   If you are able, modify the application that you're running to add an explicit signal handler for `SIGTERM`.\n    \n*   Set the `stop_signal` to a signal which the application knows how to handle:\n    \n*   If you can't modify the application, wrap the application in a lightweight init system (like [s6](https://skarnet.org/software/s6/)) or a signal proxy (like [dumb-init](https://github.com/Yelp/dumb-init) or [tini](https://github.com/krallin/tini)). Either of these wrappers takes care of handling `SIGTERM` properly.\n    \n\n### [How do I run multiple copies of a Compose file on the same host?](#how-do-i-run-multiple-copies-of-a-compose-file-on-the-same-host)\n\nCompose uses the project name to create unique identifiers for all of a project's containers and other resources. To run multiple copies of a project, set a custom project name using the [`-p` command line option](https://docs.docker.com/compose/reference/) or the [`COMPOSE_PROJECT_NAME` environment variable](https://docs.docker.com/compose/environment-variables/envvars/#compose_project_name).\n\n### [Can I use JSON instead of YAML for my Compose file?](#can-i-use-json-instead-of-yaml-for-my-compose-file)\n\nYes. [YAML is a superset of JSON](https://stackoverflow.com/a/1729545/444646) so any JSON file should be valid YAML. To use a JSON file with Compose, specify the filename to use, for example:\n\n### [Should I include my code with `COPY`/`ADD` or a volume?](#should-i-include-my-code-with-copyadd-or-a-volume)\n\nYou can add your code to the image using `COPY` or `ADD` directive in a `Dockerfile`. This is useful if you need to relocate your code along with the Docker image, for example when you're sending code to another environment (production, CI, etc).\n\nUse a `volume` if you want to make changes to your code and see them reflected immediately, for example when you're developing code and your server supports hot code reloading or live-reload.\n\nThere may be cases where you want to use both. You can have the image include the code using a `COPY`, and use a `volume` in your Compose file to include the code from the host during development. The volume overrides the directory contents of the image.",
  "title": "Compose FAQs | Docker Docs\n",
  "description": "Frequently asked questions for Docker Compose",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/migrate/",
  "markdown": "# Migrate to Compose V2 | Docker Docs\n\nFrom July 2023 Compose V1 stopped receiving updates. Itâ€™s also no longer available in new releases of Docker Desktop.\n\nCompose V2, which was first released in 2020, is included with all currently supported versions of Docker Desktop. It offers an improved CLI experience, improved build performance with BuildKit, and continued new-feature development.\n\nThe easiest and recommended way is to make sure you have the latest version of [Docker Desktop](https://docs.docker.com/desktop/release-notes/), which bundles the Docker Engine and Docker CLI platform including Compose V2.\n\nWith Docker Desktop, Compose V2 is always accessible as `docker compose`. Additionally, the **Use Compose V2** setting is turned on by default, which provides an alias from `docker-compose`.\n\nFor manual installs on Linux, you can get Compose V2 by either:\n\n*   [Using Docker's repository](https://docs.docker.com/compose/install/linux/#install-using-the-repository) (recommended)\n*   [Downloading and installing manually](https://docs.docker.com/compose/install/linux/#install-the-plugin-manually)\n\n### [`docker-compose` vs `docker compose`](#docker-compose-vs-docker-compose)\n\nUnlike Compose V1, Compose V2 integrates into the Docker CLI platform and the recommended command-line syntax is `docker compose`.\n\nThe Docker CLI platform provides a consistent and predictable set of options and flags, such as the `DOCKER_HOST` environment variable or the `--context` command-line flag.\n\nThis change lets you use all of the shared flags on the root `docker` command. For example, `docker --log-level=debug --tls compose up` enables debug logging from the Docker Engine as well as ensuring that TLS is used for the connection.\n\n> **Tip**\n> \n> Update scripts to use Compose V2 by replacing the hyphen (`-`) with a space, using `docker compose` instead of `docker-compose`.\n\n### [Service container names](#service-container-names)\n\nCompose generates container names based on the project name, service name, and scale/replica count.\n\nIn Compose V1, an underscore (`_`) was used as the word separator. In Compose V2, a hyphen (`-`) is used as the word separator.\n\nUnderscores aren't valid characters in DNS hostnames. By using a hyphen instead, Compose V2 ensures service containers can be accessed over the network via consistent, predictable hostnames.\n\nFor example, running the Compose command `-p myproject up --scale=1 svc` results in a container named `myproject_svc_1` with Compose V1 and a container named `myproject-svc-1` with Compose V2.\n\n> **Tip**\n> \n> In Compose V2, the global `--compatibility` flag or `COMPOSE_COMPATIBILITY` environment variable preserves the Compose V1 behavior to use underscores (`_`) as the word separator. As this option must be specified for every Compose V2 command run, it's recommended that you only use this as a temporary measure while transitioning to Compose V2.\n\n### [Command-line flags and subcommands](#command-line-flags-and-subcommands)\n\nCompose V2 supports almost all Compose V1 flags and subcommands, so in most cases, it can be used as a drop-in replacement in scripts.\n\n#### [Unsupported in V2](#unsupported-in-v2)\n\nThe following were deprecated in Compose V1 and aren't supported in Compose V2:\n\n*   `docker-compose scale`. Use `docker compose up --scale` instead.\n*   `docker-compose rm --all`\n\n#### [Different in V2](#different-in-v2)\n\nThe following behave differently between Compose V1 and V2:\n\n|     | Compose V1 | Compose V2 |\n| --- | --- | --- |\n| `--compatibility` | Deprecated. Migrates YAML fields based on legacy schema version. | Uses `_` as word separator for container names instead of `-` to match V1. |\n| `ps --filter KEY-VALUE` | Undocumented. Allows filtering by arbitrary service properties. | Only allows filtering by specific properties, e.g. `--filter=status=running`. |\n\n### [Environment variables](#environment-variables)\n\nEnvironment variable behavior in Compose V1 wasn't formally documented and behaved inconsistently in some edge cases.\n\nFor Compose V2, the [Environment variables](https://docs.docker.com/compose/environment-variables/) section covers both [precedence](https://docs.docker.com/compose/environment-variables/envvars-precedence) as well as [`.env` file interpolation](https://docs.docker.com/compose/environment-variables/variable-interpolation/) and includes many examples covering tricky situations such as escaping nested quotes.\n\nCheck if:\n\n*   Your project uses multiple levels of environment variable overrides, for example `.env` file and `--env` CLI flags.\n*   Any `.env` file values have escape sequences or nested quotes.\n*   Any `.env` file values contain literal `$` signs in them. This is common with PHP projects.\n*   Any variable values use advanced expansion syntax, for example `${VAR:?error}`.\n\n> **Tip**\n> \n> Run `docker compose config` on the project to preview the configuration after Compose V2 has performed interpolation to verify that values appear as expected.\n> \n> Maintaining backwards compatibility with Compose V1 is typically achievable by ensuring that literal values (no interpolation) are single-quoted and values that should have interpolation applied are double-quoted.\n\nFor most projects, switching to Compose V2 requires no changes to the Compose YAML or your development workflow.\n\nIt's recommended that you adapt to the new preferred way of running Compose V2, which is to use `docker compose` instead of `docker-compose`. This provides additional flexibility and removes the requirement for a `docker-compose` compatibility alias.\n\nHowever, Docker Desktop continues to support a `docker-compose` alias to redirect commands to `docker compose` for convenience and improved compatibility with third-party tools and scripts.\n\n### [Migrating running projects](#migrating-running-projects)\n\nIn both V1 and V2, running `up` on a Compose project recreates service containers as necessary to reach the desired state based on comparing the actual state in the Docker Engine to the resolved project configuration including Compose YAML, environment variables, and command-line flags.\n\nBecause Compose V1 and V2 [name service containers differently](#service-container-names), running `up` using V2 the first time on a project with running services originally launched by V1, results in service containers being recreated with updated names.\n\nNote that even if `--compatibility` flag is used to preserve the V1 naming style, Compose still needs to recreate service containers originally launched by V1 the first time `up` is run by V2 to migrate the internal state.\n\n### [Using Compose V2 with Docker-in-Docker](#using-compose-v2-with-docker-in-docker)\n\nCompose V2 is now included in the [Docker official image on Docker Hub](https://hub.docker.com/_/docker).\n\nAdditionally, a new [docker/compose-bin image on Docker Hub](https://hub.docker.com/r/docker/compose-bin) packages the latest version of Compose V2 for use in multi-stage builds.\n\nYes. You can still download and install Compose V1 packages, but you won't get support from Docker if anything breaks.\n\n> **Warning**\n> \n> The final Compose V1 release, version 1.29.2, was May 10, 2021. These packages haven't received any security updates since then. Use at your own risk.\n\n*   [docker-compose V1 on PyPI](https://pypi.org/project/docker-compose/1.29.2/)\n*   [docker/compose V1 on Docker Hub](https://hub.docker.com/r/docker/compose)\n*   [docker-compose V1 source on GitHub](https://github.com/docker/compose/releases/tag/1.29.2)",
  "title": "Migrate to Compose V2 | Docker Docs\n",
  "description": "How to migrate from Compose V1 to V2",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/feedback/",
  "markdown": "# Give feedback | Docker Docs\n\nThere are many ways you can provide feedback on Docker Compose.\n\n### [In-product feedback](#in-product-feedback)\n\nIf you have obtained Docker Compose through Docker Desktop, you can use the `docker feedback` command to submit feedback directly from the command line.\n\n### [Report bugs or problems on GitHub](#report-bugs-or-problems-on-github)\n\nTo report bugs or problems, visit [Docker Compose on GitHub](https://github.com/docker/compose/issues)\n\nYou can also provide feedback through the #docker-compose [Docker Community Slack](https://dockr.ly/comm-slack) channel.",
  "title": "Give feedback | Docker Docs\n",
  "description": "Find a way to provide feedback on Docker Compose that's right for you",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/api/",
  "markdown": "# Develop with Docker Engine API\n\nDocker provides an API for interacting with the Docker daemon (called the Docker Engine API), as well as SDKs for Go and Python. The SDKs allow you to efficiently build and scale Docker apps and solutions. If Go or Python don't work for you, you can use the Docker Engine API directly.\n\nFor information about Docker Engine SDKs, see [Develop with Docker Engine SDKs](https://docs.docker.com/engine/api/sdk/).\n\nThe Docker Engine API is a RESTful API accessed by an HTTP client such as `wget` or `curl`, or the HTTP library which is part of most modern programming languages.\n\nYou can [view the reference for the latest version of the API](https://docs.docker.com/engine/api/latest/) or [choose a specific version](https://docs.docker.com/engine/api/version-history/).\n\nThe version of the Docker Engine API you should use depends upon the version of your Docker daemon and Docker client.\n\nA given version of the Docker Engine SDK supports a specific version of the Docker Engine API, as well as all earlier versions. If breaking changes occur, they are documented prominently.\n\n> **Note**\n> \n> The Docker daemon and client don't necessarily need to be the same version at all times. However, keep the following in mind.\n> \n> *   If the daemon is newer than the client, the client doesn't know about new features or deprecated API endpoints in the daemon.\n>     \n> *   If the client is newer than the daemon, the client can request API endpoints that the daemon doesn't know about.\n>     \n\nA new version of the API is released when new features are added. The Docker API is backward-compatible, so you don't need to update code that uses the API unless you need to take advantage of new features.\n\nTo see the highest version of the API your Docker daemon and client support, use `docker version`:\n\nYou can specify the API version to use in any of the following ways:\n\n*   When using the SDK, use the latest version. At a minimum, use the version that incorporates the API version with the features you need.\n    \n*   When using `curl` directly, specify the version as the first part of the URL. For instance, if the endpoint is `/containers/` you can use `/v1.46/containers/`.\n    \n*   To force the Docker CLI or the Docker Engine SDKs to use an older version of the API than the version reported by `docker version`, set the environment variable `DOCKER_API_VERSION` to the correct version. This works on Linux, Windows, or macOS clients.\n    \n    While the environment variable is set, that version of the API is used, even if the Docker daemon supports a newer version. This environment variable disables API version negotiation, so you should only use it if you must use a specific version of the API, or for debugging purposes.\n    \n*   The Docker Go SDK allows you to enable API version negotiation, automatically selects an API version that's supported by both the client and the Docker Engine that's in use.\n    \n*   For the SDKs, you can also specify the API version programmatically as a parameter to the `client` object. See the [Go constructor](https://pkg.go.dev/github.com/docker/docker/client#NewClientWithOpts) or the [Python SDK documentation for `client`](https://docker-py.readthedocs.io/en/stable/client.html).\n    \n\n### [API version matrix](#api-version-matrix)\n\n| Docker version | Maximum API version | Change log |\n| --- | --- | --- |\n| 27.0 | [1.46](https://docs.docker.com/engine/api/v1.46/) | [changes](https://docs.docker.com/engine/api/version-history/#v146-api-changes) |\n| 26.1 | [1.45](https://docs.docker.com/engine/api/v1.45/) | [changes](https://docs.docker.com/engine/api/version-history/#v145-api-changes) |\n| 26.0 | [1.45](https://docs.docker.com/engine/api/v1.45/) | [changes](https://docs.docker.com/engine/api/version-history/#v145-api-changes) |\n| 25.0 | [1.44](https://docs.docker.com/engine/api/v1.44/) | [changes](https://docs.docker.com/engine/api/version-history/#v144-api-changes) |\n| 24.0 | [1.43](https://docs.docker.com/engine/api/v1.43/) | [changes](https://docs.docker.com/engine/api/version-history/#v143-api-changes) |\n| 23.0 | [1.42](https://docs.docker.com/engine/api/v1.42/) | [changes](https://docs.docker.com/engine/api/version-history/#v142-api-changes) |\n| 20.10 | [1.41](https://docs.docker.com/engine/api/v1.41/) | [changes](https://docs.docker.com/engine/api/version-history/#v141-api-changes) |\n| 19.03 | [1.40](https://docs.docker.com/engine/api/v1.40/) | [changes](https://docs.docker.com/engine/api/version-history/#v140-api-changes) |\n| 18.09 | [1.39](https://docs.docker.com/engine/api/v1.39/) | [changes](https://docs.docker.com/engine/api/version-history/#v139-api-changes) |\n| 18.06 | [1.38](https://docs.docker.com/engine/api/v1.38/) | [changes](https://docs.docker.com/engine/api/version-history/#v138-api-changes) |\n| 18.05 | [1.37](https://docs.docker.com/engine/api/v1.37/) | [changes](https://docs.docker.com/engine/api/version-history/#v137-api-changes) |\n| 18.04 | [1.37](https://docs.docker.com/engine/api/v1.37/) | [changes](https://docs.docker.com/engine/api/version-history/#v137-api-changes) |\n| 18.03 | [1.37](https://docs.docker.com/engine/api/v1.37/) | [changes](https://docs.docker.com/engine/api/version-history/#v137-api-changes) |\n| 18.02 | [1.36](https://docs.docker.com/engine/api/v1.36/) | [changes](https://docs.docker.com/engine/api/version-history/#v136-api-changes) |\n| 17.12 | [1.35](https://docs.docker.com/engine/api/v1.35/) | [changes](https://docs.docker.com/engine/api/version-history/#v135-api-changes) |\n| 17.11 | [1.34](https://docs.docker.com/engine/api/v1.34/) | [changes](https://docs.docker.com/engine/api/version-history/#v134-api-changes) |\n| 17.10 | [1.33](https://docs.docker.com/engine/api/v1.33/) | [changes](https://docs.docker.com/engine/api/version-history/#v133-api-changes) |\n| 17.09 | [1.32](https://docs.docker.com/engine/api/v1.32/) | [changes](https://docs.docker.com/engine/api/version-history/#v132-api-changes) |\n| 17.07 | [1.31](https://docs.docker.com/engine/api/v1.31/) | [changes](https://docs.docker.com/engine/api/version-history/#v131-api-changes) |\n| 17.06 | [1.30](https://docs.docker.com/engine/api/v1.30/) | [changes](https://docs.docker.com/engine/api/version-history/#v130-api-changes) |\n| 17.05 | [1.29](https://docs.docker.com/engine/api/v1.29/) | [changes](https://docs.docker.com/engine/api/version-history/#v129-api-changes) |\n| 17.04 | [1.28](https://docs.docker.com/engine/api/v1.28/) | [changes](https://docs.docker.com/engine/api/version-history/#v128-api-changes) |\n| 17.03.1 | [1.27](https://docs.docker.com/engine/api/v1.27/) | [changes](https://docs.docker.com/engine/api/version-history/#v127-api-changes) |\n| 17.03 | [1.26](https://docs.docker.com/engine/api/v1.27/) | [changes](https://docs.docker.com/engine/api/version-history/#v126-api-changes) |\n| 1.13.1 | [1.26](https://docs.docker.com/engine/api/v1.26/) | [changes](https://docs.docker.com/engine/api/version-history/#v126-api-changes) |\n| 1.13 | [1.25](https://docs.docker.com/engine/api/v1.26/) | [changes](https://docs.docker.com/engine/api/version-history/#v125-api-changes) |\n| 1.12 | [1.24](https://docs.docker.com/engine/api/v1.24/) | [changes](https://docs.docker.com/engine/api/version-history/#v124-api-changes) |\n\n### [Deprecated API versions](#deprecated-api-versions)\n\nAPI versions before v1.24 are [deprecated](https://docs.docker.com/engine/deprecated/#deprecate-legacy-api-versions). You can find archived documentation for deprecated versions of the API in the code repository on GitHub:\n\n*   [Documentation for API versions 1.23 and before](https://github.com/moby/moby/tree/v25.0.0/docs/api).\n*   [Documentation for API versions 1.17 and before](https://github.com/moby/moby/tree/v1.9.1/docs/reference/api).",
  "title": "Develop with Docker Engine API | Docker Docs\n",
  "description": "Learn how you can use Docker Engine API and SDKs in the language of your choice.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/gpu-support/",
  "markdown": "# Turn on GPU access with Docker Compose\n\nCompose services can define GPU device reservations if the Docker host contains such devices and the Docker Daemon is set accordingly. For this, make sure you install the [prerequisites](https://docs.docker.com/config/containers/resource_constraints/#gpu) if you haven't already done so.\n\nThe examples in the following sections focus specifically on providing service containers access to GPU devices with Docker Compose. You can use either `docker-compose` or `docker compose` commands. For more information, see [Migrate to Compose V2](https://docs.docker.com/compose/migrate/).\n\nGPUs are referenced in a `compose.yml` file using the [device](https://docs.docker.com/compose/compose-file/deploy/#devices) attribute from the Compose Deploy specification, within your services that need them.\n\nThis provides more granular control over a GPU reservation as custom values can be set for the following device properties:\n\n*   `capabilities`. This value specifies as a list of strings (eg. `capabilities: [gpu]`). You must set this field in the Compose file. Otherwise, it returns an error on service deployment.\n*   `count`. This value, specified as an integer or the value `all`, represents the number of GPU devices that should be reserved (providing the host holds that number of GPUs). If `count` is set to `all` or not specified, all GPUs available on the host are used by default.\n*   `device_ids`. This value, specified as a list of strings, represents GPU device IDs from the host. You can find the device ID in the output of `nvidia-smi` on the host. If no `device_ids` are set, all GPUs available on the host are used by default.\n*   `driver`. This value is specified as a string, for example `driver: 'nvidia'`\n*   `options`. Key-value pairs representing driver specific options.\n\n> **Important**\n> \n> You must set the `capabilities` field. Otherwise, it returns an error on service deployment.\n> \n> `count` and `device_ids` are mutually exclusive. You must only define one field at a time.\n\nFor more information on these properties, see the [Compose Deploy Specification](https://docs.docker.com/compose/compose-file/deploy/#devices).\n\n### [Example of a Compose file for running a service with access to 1 GPU device](#example-of-a-compose-file-for-running-a-service-with-access-to-1-gpu-device)\n\nRun with Docker Compose:\n\nOn machines hosting multiple GPUs, the `device_ids` field can be set to target specific GPU devices and `count` can be used to limit the number of GPU devices assigned to a service container.\n\nYou can use `count` or `device_ids` in each of your service definitions. An error is returned if you try to combine both, specify an invalid device ID, or use a value of count thatâ€™s higher than the number of GPUs in your system.\n\nTo allow access only to GPU-0 and GPU-3 devices:",
  "title": "Turn on GPU access with Docker Compose | Docker Docs\n",
  "description": "Understand GPU support in Docker Compose",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/release-notes/",
  "markdown": "# Docker Compose release notes | Docker Docs\n\nFor more detailed information, see the [release notes in the Compose repo](https://github.com/docker/compose/releases/).\n\n_2024-06-24_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements)\n\n*   Fixed progress display, broken in `v2.28.0`, when TTY mode available.\n\n_2024-06-21_\n\n### [Update](#update)\n\n*   Dependencies upgrade: bump compose-go to v2.1.3\n*   Dependencies upgrade: bump docker engine and cli to v27.0.1-rc.1\n\n_2024-06-21_\n\n### [Update](#update-1)\n\n*   Dependencies upgrade: bump buildx to 0.15.1\n*   Dependencies upgrade: bump buildkit to 0.14.1\n\n_2024-06-20_\n\n### [Update](#update-2)\n\n*   Dependencies upgrade: bump golang to 1.21.11\n*   Dependencies upgrade: bump docker engine and cli to v26.1.4\n*   Dependencies upgrade: bump buildx to 0.15.0\n*   Dependencies upgrade: bump buildkit to 0.14.0\n*   Dependencies upgrade: bump containerd to 1.7.18\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-1)\n\n*   Added an `--environment` flag to the `config` command\n*   Fixed a bug which caused the `watch` process to hang when used as flag with the `up` command\n*   Fixed usage of `COMPOSE_PROFILES` in `.env` file\n\n_2024-05-24_\n\n### [Update](#update-3)\n\n*   Dependencies upgrade: bump compose-go to v2.1.1\n*   Dependencies upgrade: bump docker engine and cli to v26.1.3\n*   Dependencies upgrade: bump buildx to 0.14.1\n*   Dependencies upgrade: bump containerd to 1.7.17\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-2)\n\n*   Added a navigation menu in the CLI where you can open your Compose file in Docker Desktop\n*   Added documentation for `--menu` flag in `docker compose up`\n*   Fixed a bug with `--resolve-image-digests` used with `--no-interpolate`\n*   You can now use a local `.env` file to override `COMPOSE_*` environment variables\n\n_2024-04-24_\n\n### [Update](#update-4)\n\n*   Dependencies upgrade: bump golang to 1.21.9\n*   Dependencies upgrade: bump compose-go to v2.1.0\n*   Dependencies upgrade: bump docker engine and cli to v26.1.0\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-3)\n\n*   Introduced `--abort-on-container-failure` flag\n*   Introduced `--all-resources` to not exclude resources not used by services\n*   Introduced support for `build.entitlements`\n*   Fixed a bug so Docker Compose now ignores missing containers when `docker compose down/stop -p` is run\n*   Fixed support for `--flag=value` syntax in compatibility mode\n\n_2024-03-29_\n\n### [Update](#update-5)\n\n*   Dependencies upgrade: opencontainers/image-spec v1.1.0\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-4)\n\n*   Added image pull failure reason in output\n*   Fixed crash when running up with `--no-build` and `--watch`\n*   Fixed crash when no TTY available and menu enabled\n*   Improved legibility of menu actions\n\n_2024-03-22_\n\n### [Update](#update-6)\n\n*   Dependencies upgrade: bump compose-go v2.0.2\n*   Dependencies upgrade: bump docker v26.0.0\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-5)\n\n*   Reduced timeout of the Otel tracing command\n*   Fixed `config --format json`\n*   Fixed documentation on default build image name\n*   Introduced Synchronized file shares for bind mounts in Compose\n*   Added support for `annotations`\n*   Introduced `config --variables` to list Compose model variables\n*   Added a navigation menu within `docker compose up`\n\n_2024-03-15_\n\n### [Update](#update-7)\n\n*   Dependencies upgrade: bump compose-go v2.0.0\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-6)\n\n*   Restored `config` behaviour until `--no-interpolate` is set\n*   Fixed service name shell completion\n*   Added `--watch` flag to `up` command\n\n_2024-03-06_\n\n### [Update](#update-8)\n\n*   Dependencies upgrade: bump golang to 1.21.8\n*   Dependencies upgrade: bump compose-go to 2.0.0-rc8\n*   Dependencies upgrade: bump docker to v24.0.4\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-7)\n\n*   Compose now ensures stable priority sort order for networks\n*   Fixed interpolation with curly braces (e.g. JSON) in default values\n*   Fixed validation for non-unique `container_name` values\n*   Fixed validation for `develop.watch`\n*   Fixed environment loading for `include`\n*   Fixed panic when merging labels/networks\n*   Added support for `--no-path-resolution` when using `include`\n*   Fixed missing project name errors\n*   Fixed `--no-interpolate` flag on `config`\n*   Added a workaround for file lock issues with Watch mode on Windows\n*   Fixed duplicate exit code status messages\n*   Compose now respects `COMPOSE_REMOVE_ORPHANS` on `up`\n\n_2024-02-15_\n\n### [Update](#update-9)\n\n*   Dependencies upgrade: bump cli to 25.0.3\n*   Dependencies upgrade: bump compose-go to 2.0.0-rc.7\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-8)\n\n*   Fixed issue of `.env` file loading when project file is set via `COMPOSE_FILE` variable\n*   Aligned `ps --status=exited` behaviour with the Docker CLI behaviour\n*   Fixed a deadlock when collecting large logs\n\n_2024-01-30_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-9)\n\n*   Fixed \"failed to solve: changes out of order\" errors when building images on Windows.\n\n_2024-01-29_\n\n### [Update](#update-10)\n\n*   Dependencies upgrade: bump cli to 25.0.1\n*   Dependencies upgrade: bump docker to 25.0.1\n*   Dependencies upgrade: bump compose-go to 2.0.0-rc.3\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-10)\n\n*   Fixed issue when checking external network existence when swarm is enabled.\n*   Added support for `storage_opt` attribute.\n\n_2024-01-24_\n\nThis release fixes a build issue with Docker Desktop for Windows introduced in Compose v2.24.0.\n\n### [Update](#update-11)\n\n*   Compose now uses a custom version of `fsutils` library.\n\n_2024-01-22_\n\n### [Update](#update-12)\n\n*   Dependencies upgrade: bump cli to 25.0.0 GA\n*   Dependencies upgrade: bump compose-go to 2.0.0-rc.2\n\n_2024-01-18_\n\n### [Update](#update-13)\n\n*   Dependencies upgrade: bump cli to 25.0.0-rc3\n*   Dependencies upgrade: bump docker to 25.0.0-rc3\n*   Dependencies upgrade: bump compose-go to 2.0.0-rc.1\n*   Dependencies upgrade: bump containerd to 1.7.12\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-11)\n\n*   Reworked the display of container status during `up`\n*   Fixed the engine version required to use `healthcheck.start_interval`\n*   Removed `watch` subcommand from the `alpha` command\n*   Fixed a bug when handling received signals\n\n_2024-01-11_\n\n### [Update](#update-14)\n\n*   Dependencies upgrade: bump cli to 25.0.0-beta.3\n*   Dependencies upgrade: bump compose-go to 2.0.0-beta.3\n*   Dependencies upgrade: bump golang to 1.21.6\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-12)\n\n*   Introduced `docker compose attach` to attach local standard input, output, and error streams to a service's running container.\n*   Introduced `docker compose stats` to display a live stream of container(s) resource usage statistics.\n*   Introduced `docker compose ps --orphans` to include/exclude services not declared.\n*   Introduced `docker compose logs --index` to select a replica container.\n*   Introduced `docker compose build --with-dependencies` to also build dependencies.\n*   Added source policies for build.\n*   Included disabled services for shell completion.\n*   Restored `Project` in ps JSON output.\n*   Added OCI 1.0 fallback support for AWS ECR.\n*   Build now does not require environment to be resolved.\n*   Compose now sends out a cancel event on SIGINT/SIGTERM signal for `compose up`.\n*   Fixed log by exposing services ports when `--verbose`.\n*   Fixed inlined and environment-defined configs to be mounted under /<id> until an explicit target is set.\n*   Fixed combination of `--pull always --no-build`.\n*   Fixed race condition in log printer.\n*   Fixed `docker compose up` teardown when command context is cancelled.\n\n_2023-11-22_\n\n### [Update](#update-15)\n\n*   Dependencies upgrade: bump buildx to v0.12.0\n\n_2023-11-21_\n\n### [Update](#update-16)\n\n*   Dependencies upgrade: bump buildkit 0.12.3\n*   Dependencies upgrade: bump docker 24.0.7\n*   Dependencies upgrade: bump cli 24.0.7\n*   Dependencies upgrade: bump 1.20.2\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-13)\n\n*   Compose now supports `builds.tags` with `push` command.\n*   Compose Watch now re-builds service images at startup.\n*   Now `--remove-orphans` doesn't manage disabled services as orphaned.\n*   Compose displays `Building` output log only if there is at least one service to build.\n\n_2023-11-16_\n\n### [Update](#update-17)\n\n*   Dependencies upgrade: bump compose-go to v1.20.1\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-14)\n\n*   Aligned Compose with OCI artifact best practices.\n*   Introduced `--resolve-image-digests` so users can seal service images by digest when publishing a Compose application.\n*   Improved Compose Watch configuration logging.\n*   Compose now rejects a Compose file using `secrets|configs.driver` or `template_driver`.\n*   Compose now fails to start if a dependency is missing.\n*   Fixed SIGTERM support to stop/kill stack.\n*   Fixed a `--hash` regression.\n*   Fixed \"Application failed to start after update\" when an external network is on a watched service.\n*   Fixed `--pull` documentation.\n*   Fixed display by adding newline in cmd/compose/build.go.\n*   Compose is rendered quiet after filtering applied.\n*   Stripped project prefix from docker-compose up output.\n\n_2023-10-18_\n\n### [Update](#update-18)\n\n*   Dependencies upgrade: bump compose-go to v1.20.0\n*   Dependencies upgrade: bump containerd to 1.7.7\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-15)\n\n*   Added dry-run support for publish command\n*   Added `COMPOSE_ENV_FILES` env variable to pass a list of env files\n*   Added `sync+restart` action to `compose watch`\n*   Aligned `compose ps` output with Docker CLI by default and introduced `--no-trunc` to keep the previous behaviour\n*   Fixed hashes inconsistency between `up` and `configure`\n*   Enabled profiles when `down` ran with explicit service names\n*   Fixed an issue when the pull policy provided was invalid\n\n_2023-09-21_\n\n> **Note**\n> \n> The `watch` command is now generally available (GA). You can directly use it from the root command `docker compose watch`. For more information, see [File watch](https://docs.docker.com/compose/file-watch/).\n\n### [Update](#update-19)\n\n*   Dependencies upgrade: bump golang to 1.21.1\n*   Dependencies upgrade: bump compose-go to v1.19.0\n*   Dependencies upgrade: bump buildkit to v0.12.2\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-16)\n\n*   Added experimental support for the `publish` command.\n*   The command `watch` now builds and launches the project during startup.\n*   Added `policy` option to the `--pull` flag.\n*   Fixed various race and deadlock conditions for `up` command on exit.\n*   Fixed multi-platform issues on build.\n*   Enabled services that are explicitly requested even when their `profiles` aren't activated.\n*   Fixed a `config` issue when the declared `env_file` is missing.\n*   Passed BuildOptions to `up` and `run` commands.\n\n_2023-08-30_\n\n> **Note**\n> \n> The format of `docker compose ps` and `docker compose ps --format=json` changed to better align with `docker ps` output. See [compose#10918](https://github.com/docker/compose/pull/10918).\n\n### [Update](#update-20)\n\n*   Dependencies upgrade: bump compose-go to v1.18.3\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-17)\n\n*   Changed `docker compose ps` and `docker compose ps --format=json` output to align with Docker CLI.\n*   Added support for multi-document YAML files.\n*   Added support for loading remote Compose files from Git repos with `include` (experimental).\n*   Fixed incorrect proxy variables during build.\n*   Fixed truncated container logs on container exit.\n*   Fixed \"no such service\" errors when using `include` with `--profile`.\n*   Fixed `.env` overrides when using `include`.\n\n_2023-08-11_\n\n### [Update](#update-21)\n\n*   Dependencies upgrade: bump golang to 1.21.0\n*   Dependencies upgrade: bump compose-go to v1.18.1\n*   Dependencies upgrade: bump buildkit to v0.12.1\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-18)\n\n*   Improved speed and reliability of `watch` sync.\n*   Added builder's name on the first build line.\n*   Improved shell completion for `--project-directory` and `--profile`.\n*   Fixed build issue with proxy configuration not passing to legacy builder.\n*   Removed unnecessary warning when an option dependency exists successfully.\n\n_2023-07-19_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-19)\n\n*   Added support for the `depends_on.required` attribute.\n*   Fixed an issue where build tries to push unnamed service images.\n*   Fixed a bug which meant the target secret path on Windows was not checked.\n*   Fixed a bug resolving build context path for services using `extends.file`.\n\n_2023-07-18_\n\n### [Update](#update-22)\n\n*   Dependencies upgrade: bump golang to 1.20.6\n*   Dependencies upgrade: bump buildx to v0.11.2\n*   Dependencies upgrade: bump buildkit to v0.12\n*   Dependencies upgrade: bump docker-cli to v24.0.5-dev\n\n_2023-07-11_\n\n### [Update](#update-23)\n\n*   Dependencies upgrade: bump docker/cli-docs-tools to v0.6.0\n*   Dependencies upgrade: bump docker to v24.0.4\n*   Dependencies upgrade: bump buildx to v0.11.1\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-20)\n\n*   Introduced the `wait` command.\n*   Added support of `--builder` and `BUILDX_BUILDER` to the `build` command.\n*   Added support for the `include` and `attach` attributes from the Compose Specification.\n*   Fixed a DryRun mode issue when initializing CLI client.\n*   Fixed a bug with random missing network when a service has more than one.\n*   Fixed the Secrets file permission value to comply with the Compose Specification.\n*   Fixed an issue about `no-deps` flag not being applied.\n*   Fixed some source code comments.\n*   Fixed a bug when `--index` is not set select.\n*   Fixed a process leak in the wait e2e test.\n*   Improved some test speeds.\n\n_2023-06-29_\n\n### [Update](#update-24)\n\n*   Dependencies upgrade: bump compose-go to v1.15.1\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-21)\n\n*   Fixed sporadic \"container not connected to network\" errors on `compose up`.\n*   Fixed \"please specify build context\" errors on `compose build`.\n*   Compose now warns if using a bind mount in a service `watch` configuration.\n\n_2023-06-21_\n\n### [Update](#update-25)\n\n*   Dependencies upgrade: bump compose-go to v1.15.0\n*   Dependencies upgrade: bump buildx to v0.11.0\n*   Dependencies upgrade: bump docker to v24.0.2\n*   Dependencies upgrade: bump golang to 1.20.5\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-22)\n\n*   Introduced the ability to select a single service to be stopped by `compose down`.\n*   Added `--progress` as top-level flag to configure progress UI style.\n*   Introduced `run --cap-add` to run maintenance commands using service image.\n*   Fixed a bug during detection of swarm mode.\n*   Fixed a bug when setting the project name via `COMPOSE_PROJECT_NAME` environment variable.\n*   Adjusted the display of the volumes flag with the help of `down` command.\n*   Fixed a bug in the `up` command which should not silently ignore missing `depends_on` services.\n*   Aligned forward signal to container behaviour with the `docker run` one.\n*   Compose now detects network name conflict.\n*   Fixed a typo in the warning message about an existing volume.\n*   Compose now detects new services started after `compose -p x logs -f` command.\n*   Fixed a bug when `compose` was used as project name.\n*   Fixed a bug in the `watch` command when a directory does not exist.\n*   Removed default timeout of 10 seconds when restarting or stopping services.\n*   Fixed a bug in `watch` which applied the \"rebuild\" strategy by default.\n*   Fixed a race condition, waiting for containers when one exit.\n*   Added a warning telling users that uid,gid,mode are not implemented for `build.secrets`.\n*   Fixed a bug in `watch` which was watching the whole build context instead of only configured paths.\n*   Compose now sorts containers by creation date to scale down the older ones first.\n*   Fixed a bug in the docs generation task for Windows environments.\n*   Updated the docs to reflect Dry Run mode is feature complete.\n*   Improved the diagnostic message on network label mismatch.\n*   Fixed a bug which was rendering `Building` section when there was no build involved.\n*   Fixed a bug in code coverage metrics.\n*   Added OTEL initialization.\n*   Added a GitHub action to trigger Docker Desktop e2e tests with Compose edge versions.\n*   Added more ignore rules to dependabot.\n\n_2023-05-17_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-23)\n\n*   Fixed \"Image not found\" errors when building images\n\n_2023-05-16_\n\n### [Update](#update-26)\n\n*   Dependencies upgrade: bump compose-go to v1.13.5\n*   Dependencies upgrade: bump buildkit to v0.11.6\n*   Dependencies upgrade: bump docker to v23.0.5\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-24)\n\n*   Added dry run support using `--dry-run`\n*   Added the first (alpha) implementation of the `viz` sub-command\n*   Introduced `--no-path-resolution` to skip relative path to be resolved\n*   Introduced `COMPOSE_ANSI` to define the `--ansi` default value\n*   Introduced `COMPOSE_STATUS_STDOUT` to get status messages sent to stdout\n*   Fixed the BuildKit progressui integration\n*   Fixed a bug to stop blocking the events loop collecting logs\n*   Restored support for `--memory`\n*   Fixed a bug which meant containers didn't stop after termination\n*   Compose now lets users declare the build secret target\n*   Fixed a bug which caused a container to be recreated when the config has not changed\n*   Fixed a race condition when `--parallel` is used with a large number of dependent services\n*   Compose now checks the local image matches the required platform\n*   Fixed local image removal when `compose down` is ran with `--project-name`\n*   Compose now detects the active endpoint trying to remove the network and skips with a warning\n*   Removed unnecessary \\[\\] output\n*   Compose detects that a Windows terminal is not a `console.File` to avoid a panic\n*   `--parallel` now has precedence over `COMPOSE_PARALLEL_LIMIT`\n*   Compose now reports that the external network is not found when Swarm is disabled\n\n_2023-03-26_\n\n### [Update](#update-27)\n\n*   Dependencies upgrade: bump compose-go to v1.13.2\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-25)\n\n*   Fixed invalid project name error for directories with uppercase characters or `.` in the name. Fixed [compose#10405](https://github.com/docker/compose/issues/10405)\n\n_2023-03-24_\n\n### [Update](#update-28)\n\n*   Dependencies upgrade: bump buildkit to v0.11.5\n*   Dependencies upgrade: bump compose-go to v1.13.1\n*   Dependencies upgrade: bump golang to 1.20.2\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-26)\n\n*   Fixed panic on `alpha watch` command. Pull Request [compose#10393](https://github.com/docker/compose/pull/10393)\n*   Prevented conflicts for services named `extensions`. Fixed [compose-go#247](https://github.com/compose-spec/compose-go/issues/247)\n*   Compose now validates project names more consistently. Fixed [compose-go#363](https://github.com/compose-spec/compose-go/issues/363)\n\n_2023-03-23_\n\n### [Upgrade notes](#upgrade-notes)\n\n*   Project name validation is more strictly enforced. Project names can only include letters, numbers, `_`, `-` and must be lowercase and start with a letter or number.\n*   Boolean fields in YAML must be either `true` or `false`. Deprecated YAML 1.1 values such as \"on\" or \"no\" are not supported.\n*   Duplicate YAML merge keys (`<<`) are rejected.\n\n### [Update](#update-29)\n\n*   Dependencies upgrade: bump buildkit to v0.11.4\n*   Dependencies upgrade: bump buildx to v0.10.4\n*   Dependencies upgrade: bump containerd to 1.6.18\n*   Dependencies upgrade: bump compose-go to v1.13.0\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-27)\n\n*   Introduced `--wait-timeout` on `up` command. Fixed [compose#10269](https://github.com/docker/compose/issues/10269)\n*   Made `compose service --hash` output sort by service name. Pull Request [compose#10278](https://github.com/docker/compose/pull/10278)\n*   Compose now renders a compact TUI progress report to monitor layers download. Pull Request [compose#10281](https://github.com/docker/compose/pull/10281)\n*   Introduced `restart` for `depends_on`. Fixed [compose#10284](https://github.com/docker/compose/issues/10284)\n*   Added support of `NO_COLOR` env var. Fixed [compose#10340](https://github.com/docker/compose/issues/10340)\n*   Progress writer now uses `dockercli.Err` stream. Fixed [compose#10366](https://github.com/docker/compose/issues/10366)\n*   Added support for `additional_contexts` in the `build` service configuration. Fixed [compose#9461](https://github.com/docker/compose/issues/9461) [compose#9961](https://github.com/docker/compose/issues/9961)\n*   Added file delete/rename handling in `watch` mode. Pull Request [compose#10386](https://github.com/docker/compose/pull/10386)\n*   Introduced an `ignore` attribute in `watch` mode. Pull Request [compose#10385](https://github.com/docker/compose/pull/10385)\n*   Compose now uses progress writer to show copies status. Pull Request [compose#10387](https://github.com/docker/compose/pull/10387)\n*   Updated reference documentation for `-p`/`--project-name` flag. Fixed [docs#16915](https://github.com/docker/docs/pull/16915), [compose-spec#311](https://github.com/compose-spec/compose-spec/issues/311)\n*   Introduced a `replace` label to track the relationship between old and new containers of a service. Fixed [compose#9600](https://github.com/docker/compose/issues/9600)\n*   Fixed a bug that meant dependent services were not restarted after a service was restarted. Fixed [compose#10263](https://github.com/docker/compose/issues/10263)\n*   Compose now ignores services without a build section in `watch` mode. Fixed [compose#10270](https://github.com/docker/compose/issues/10270)\n*   Compose now applies config options for pseudo-subcommands. Fixed [compose#10286](https://github.com/docker/compose/issues/10286)\n*   Compose manages only containers with config\\_hash labels (i.e, created by compose). Fixed [compose#10317](https://github.com/docker/compose/issues/10317)\n*   Compose triggers an error if the project name is empty after normalization. Fixed [compose#10313](https://github.com/docker/compose/issues/10313)\n*   Compose restarts only needed services by checking `depends_on` relations. Fixed [compose#10337](https://github.com/docker/compose/issues/10337)\n*   Fixed a display issue on small terminals. Fixed [compose#10322](https://github.com/docker/compose/issues/10322)\n*   Fixed an issue with building the built images IDs collection. Pull Request [compose#10372](https://github.com/docker/compose/issues/10372)\n*   Use configured name separator to define oneoff container name. Fixed [compose#10354](https://github.com/docker/compose/issues/10354)\n*   Fixed concurrent map read/write issue when recreating containers. Fixed [compose#10319](https://github.com/docker/compose/issues/10319)\n*   Compose now supports Dry Run mode for `stop` and `rm` commands. Pull Request [compose#10257](https://github.com/docker/compose/issues/10257)\n*   Compose now supports Dry Run mode for `pull` command. Pull Request [compose#10341](https://github.com/docker/compose/issues/10341)\n*   Compose now supports Dry Run mode for `push` command. Pull Request [compose#10355](https://github.com/docker/compose/issues/10355)\n*   Compose now supports Dry Run mode for `exec` command. Pull Request [compose#10252](https://github.com/docker/compose/issues/10252)\n*   Compose now supports Dry Run mode for `restart` command. Pull Request [compose#10339](https://github.com/docker/compose/issues/10339)\n\n_2023-02-08_\n\n### [Update](#update-30)\n\n*   Dependencies upgrade: bump docker to v23.0.0\n*   Dependencies upgrade: bump docker-cli to v23.0.0\n*   Dependencies upgrade: bump buildkit to v0.11.2\n*   Dependencies upgrade: bump buildx to v0.10.2\n*   Dependencies upgrade: bump containerd to 1.6.16\n*   Dependencies upgrade: bump golang to 1.20\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-28)\n\n*   Introduced `--remove-orphans` for the `compose create` command. Fixed [compose#9718](https://github.com/docker/compose/issues/9718)\n*   Shortened the TTY output when the terminal is too small. Fixed [compose#9962](https://github.com/docker/compose/issues/9962)\n*   Added `remove-orphans` functionality to run. Fixed [compose#9718](https://github.com/docker/compose/issues/9718#issuecomment-1209448445)\n*   Introduced the experimental `watch` command. Pull Request [compose#10163](https://github.com/docker/compose/pull/10163)\n*   Compose now allows TTY to be allocated with `-t`. Fixed [compose#10161](https://github.com/docker/compose/issues/10161)\n*   Introduced the experimental `dry-run` command. Pull Request [compose#10173](https://github.com/docker/compose/issues/10173)\n*   Updated the documentation to explain ways to configure parallelism. Pull Request [compose#10198](https://github.com/docker/compose/issues/10198)\n*   Aligned the `logs` command with docker CLI by aliasing `-n` for `--tail`. Fixed [compose#10199](https://github.com/docker/compose/issues/10199)\n*   Added support for `docker compose build --push`. Pull Request [compose#10148](https://github.com/docker/compose/issues/10148)\n*   Added `--scale` to the `compose create` command. Fixed [compose#10208](https://github.com/docker/compose/issues/10208)\n*   Renamed `convert` to `config` to align with the Compose V1 UX. Pull Request [compose#10214](https://github.com/docker/compose/issues/10214)\n*   Compose now passes the proxy config as build args. Fixed [compose#8797](https://github.com/docker/compose/issues/8797)\n*   Fixed parsing issue in `compose up` by ignoring containers not created by Compose. Fixed [compose#10162](https://github.com/docker/compose/issues/10162#issuecomment-1384989985)\n*   Fixed the goroutine leak in log formatter initialization. Fixed [compose#10157](https://github.com/docker/compose/issues/10157)\n*   Fixed an issue where compose logs don't exit when all running containers have been stopped. Pull Request [compose#10181](https://github.com/docker/compose/issues/10181)\n*   Fixed the documentation to reflect `docker compose ps` being aligned with `docker ps`. Pull Request [compose#10195](https://github.com/docker/compose/issues/10195)\n*   Fixed an issue where the remote Buildx driver was not found. Fixed [compose#9893](https://github.com/docker/compose/issues/9893)\n*   Improved logging when recreating a service container. Pull request [compose#10236](https://github.com/docker/compose/issues/10236)\n*   Fixed an issue so Compose now only waits for containers concerned by the wait condition. Fixed [compose#10200](https://github.com/docker/compose/issues/10200)\n*   Compose now prevents assignment to entry in nil map. Fixed [compose#10244](https://github.com/docker/compose/issues/10244)\n*   Added a dedicated GitHub Action workflow for Cucumber tests. Pull Request [compose#10165](https://github.com/docker/compose/issues/10165)\n*   Cleaned the TUI lines when switching in compact log mode. Fixed [compose#10201](https://github.com/docker/compose/issues/10201)\n*   Added Tilt watcher to detect code changes in watch mode. Pull Request [compose#10218](https://github.com/docker/compose/issues/10218)\n*   Compose now supports Dry Run mode for `kill` command. Fixed [compose#10210](https://github.com/docker/compose/issues/10210)\n*   Compose now supports Dry Run mode for `pause` command.Fixed [compose#10217](https://github.com/docker/compose/issues/10217)\n*   Compose now supports Dry Run mode for `cp` command.Fixed [compose#10235](https://github.com/docker/compose/issues/10235)\n\n_2023-01-09_\n\n### [Update](#update-31)\n\n*   Dependencies upgrade to fix Golan CVE-2022-27664 and CVE-2022-32149\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-29)\n\n*   Added support for UTS namespace. Fixed [compose#8408](https://github.com/docker/compose/issues/8408)\n*   Fixed filtering issue when no filter set. Fixed [roadmap#418](https://github.com/docker/roadmap/issues/418)\n*   Fixed concurrent map writes issue during build step. Pull Request [compose#10151](https://github.com/docker/compose/pull/10151)\n*   Fixed issue when stdin is not a terminal. Fixed [compose#9739](https://github.com/docker/compose/issues/9739)\n\n_2023-01-05_\n\n### [Update](#update-32)\n\n*   Dependencies upgrade: bump compose-go to v1.8.1\n*   Dependencies upgrade: bump cli-docs-tool to 0.5.1\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-30)\n\n*   Added support of the `privileged` attribute in the `service.build` section. Pull Request [compose#10112](https://github.com/docker/compose/pull/10112)\n*   Introduced `--ignore-buildable` to ignore buildable images on pull. Fixed [compose#8805](https://github.com/docker/compose/issues/8805)\n*   Introduceed `--no-attach` to ignore some service outputs. Fixed [compose#8546](https://github.com/docker/compose/issues/8546)\n*   Fixed issue with `logs` when `driver:none` is set. Fixed [compose#9030](https://github.com/docker/compose/issues/9030)\n*   Compose now relies on dockerCLI.streams. Pull Request [compose#10082](https://github.com/docker/compose/pull/10082)\n*   Fixed issue with service hash that MUST exclude replicas. Fixed [compose#10077](https://github.com/docker/compose/issues/10077)\n*   Compose now checks service names based on project, not running containers. Fixed [compose#9951](https://github.com/docker/compose/issues/9951)\n*   Fixed security opts support (seccomp and unconfined). Fixed [compose#9505](https://github.com/docker/compose/issues/9505)\n*   Fixed empty file when using compose config in case of smaller source files. Fixed [compose#10121](https://github.com/docker/compose/issues/10121)\n*   Fixed issue with `--pull` not applied on `compose up`. Fixed [compose#10125](https://github.com/docker/compose/issues/10125)\n*   Compose should ignore not only auto-removed containers but also \"removal in progress\" for orphan containers. Pull Request [compose#10136](https://github.com/docker/compose/pull/10136)\n*   Compose limits build concurrency according to `--parallel`. Fixed [compose#9091](https://github.com/docker/compose/issues/9091)\n\n_2022-12-20_\n\n### [Update](#update-33)\n\n*   Dependencies upgrade: bump containerd to 1.6.14\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-31)\n\n*   Compose now uses DOCKER\\_DEFAULT\\_PLATFORM to determine the platform when creating a container. Fixed [compose#10041](https://github.com/docker/compose/pull/10041)\n*   Compose now detects when dependency failed to start. Fixed [compose#9732](https://github.com/docker/compose/pull/9732)\n*   Fixed WCOW volume mounts. Fixed [compose#9577](https://github.com/docker/compose/pull/9577)\n*   List only running containers when using `--all=false`. Fixed [compose#10085](https://github.com/docker/compose/pull/10085)\n*   Fixed a regression when running pull `--ignore-pull-failures`. Fixed [compose#10089](https://github.com/docker/compose/pull/10089)\n*   Fixed CPU quota issue. Fixed [compose#10073](https://github.com/docker/compose/pull/10073)\n*   Fixed race condition on compose logs. Fixed [compose#8880](https://github.com/docker/compose/pull/8880)\n*   Updated projectOptions to be public by renaming it to ProjectOptions. Fixed [compose#100102](https://github.com/docker/compose/pull/100102)\n\n_2022-12-15_\n\n### [Updates](#updates)\n\n*   Dependencies upgrade: bump Go to 1.19.4\n*   Dependencies upgrade: bump containerd to 1.6.12\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-32)\n\n*   Added `--parallel` to limit concurrent engine calls. Pull Request [compose#10030](https://github.com/docker/compose/pull/10030)\n*   Distinguished stdout and stderr in `up` logs. Fixed [compose#8098](https://github.com/docker/compose/issues/8098)\n*   Aligned `compose ps` output with `docker ps`. Fixed [compose#6867](https://github.com/docker/compose/issues/6867)\n*   Added `--include-deps` to push command. Pull Request [compose#10044](https://github.com/docker/compose/pull/10044)\n*   Introduced `--timestamp` option on `compose up`. Fixed [compose#5730](https://github.com/docker/compose/issues/5730)\n*   Compose now applies uid/gid when creating a secret from the environment. Pull Request [compose#10084](https://github.com/docker/compose/pull/10084)\n*   Fixed deadlock when waiting for attached-dependencies. Fixed [compose#10021](https://github.com/docker/compose/pull/10021)\n*   Fixed race condition when collecting pulled images IDs. Fixed [compose#9897](https://github.com/docker/compose/pull/9897)\n*   Compose doesn't stop the `pull` command for images that can be built. Fixed [compose#8724](https://github.com/docker/compose/pull/8724)\n*   Fixed corner case when there's no container to attach to. Fixed [compose#8752](https://github.com/docker/compose/pull/8752)\n*   Compose containers' startup must run sequentially for engine to assign distinct ports within a configured range. Fixed [compose#8530](https://github.com/docker/compose/pull/8530)\n*   Fixed parsing of `repository:tag`. Fixed [compose#9208](https://github.com/docker/compose/pull/9208)\n*   Load project from files when explicitly set by user. Fixed [compose#9554](https://github.com/docker/compose/pull/9554)\n\n_2022-12-02_\n\n### [Updates](#updates-1)\n\n*   Dependencies upgrade: bump compose-go to [v1.8.0](https://github.com/compose-spec/compose-go/releases/tag/v1.8.0)\n*   Dependencies upgrade: bump Go to 1.19.3\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-33)\n\n*   Added `oom_score_adj` field to service definition. Pull Request [compose#10019](https://github.com/docker/compose/issues/10019)\n*   Added mode field for tmpfs mount permissions. Pull Request [compose#10031](https://github.com/docker/compose/issues/10031)\n*   Compose now only stops services started by `up` when interrupted. Fixed [compose#10028](https://github.com/docker/compose/issues/10028)\n*   Compose now loads implicit profiles for targeted services. Fixed [compose#10025](https://github.com/docker/compose/issues/10025)\n*   Compose does not require `service.build.platforms` to be set if `service.platform` is set. Fixed [compose#10017](https://github.com/docker/compose/issues/10017)\n*   Plain output is used during buildx image builds if `--ansi=never` is set. Fixed [compose#10020](https://github.com/docker/compose/issues/10020)\n*   `COMPOSE_IGNORE_ORPHANS` environment variable now behaves more consistently. Fixed [compose#10035](https://github.com/docker/compose/issues/10035)\n*   Compose now uses the correct image name separator in `convert`. Fixed [compose#9904](https://github.com/docker/compose/issues/9904)\n*   Fixed `run` for services using `network_mode: service:NAME`. Fixed [compose#10036](https://github.com/docker/compose/issues/10036)\n\n_2022-11-23_\n\n### [Updates](#updates-2)\n\n*   Dependencies upgrade: bump containerd to 1.6.10\n*   Dependencies upgrade: bump docker-credential-helpers to v0.7.0\n*   Update CI dependencies. Pull Request [compose#9982](https://github.com/docker/compose/pull/9982)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-34)\n\n*   Added a `no-consistency` option to `convert` command. Fixed [compose#9963](https://github.com/docker/compose/issues/9963)\n*   Added a `build` option to `run` command. Fixed [compose#10003](https://github.com/docker/compose/issues/10003)\n*   Fixed mapping `restart_policy.condition` to engine supported values. Fixed [compose#8756](https://github.com/docker/compose/issues/8756), [docs#15936](https://github.com/docker/docs/pull/15936)\n*   Fixed missing support of `deploy.reservation.memory`. Fixed [compose#9902](https://github.com/docker/compose/issues/9902)\n*   Fixed a bug to prevent usage of `COMPOSE_PROFILES` when `--profile` arg is used. Fixed [compose#9895](https://github.com/docker/compose/issues/9895)\n*   Fixed a bug to prevent pulling a service's image when depending on a service which will build this image. Fixed [compose#9983](https://github.com/docker/compose/issues/9983)\n*   Fixed parsing issue when a container number label is not found. Fixed [compose#10004](https://github.com/docker/compose/issues/10004)\n*   Compose now uses the platform value defined by `DOCKER_DEFAULT_PLATFORM` when no `service.platform` defined. Fixed [compose#9889](https://github.com/docker/compose/issues/9889)\n*   Removed usage of the deprecated dependency `gotest.tools` v2. Pull Request [compose#9935](https://github.com/docker/compose/pull/9935)\n*   Excluded issues labeled with `kind/feature` from stale bot process. Fixed [compose#9988](https://github.com/docker/compose/pull/9988)\n\n_2022-10-21_\n\n### [Updates](#updates-3)\n\n*   Updated Docker Engine API to restore compatibility with Golang 1.18 needed for Linux packaging. Pull Request [compose#9940](https://github.com/docker/compose/pull/9940)\n\nFor the full change log or additional information, check the [Compose repository 2.12.2 release page](https://github.com/docker/compose/releases/tag/v2.12.2).\n\n_2022-10-21_\n\n### [Security](#security)\n\n*   Updated Docker Engine API to apply fix of [CVE-2022-39253](https://nvd.nist.gov/vuln/detail/CVE-2022-39253). Pull Request [compose#9934](https://github.com/docker/compose/pull/9934)\n\nFor the full change log or additional information, check the [Compose repository 2.12.1 release page](https://github.com/docker/compose/releases/tag/v2.12.1).\n\n_2022-10-18_\n\n### [Updates](#updates-4)\n\n*   CI update to the documentation repository path\n    \n*   Upgraded to compose-go from [1.5.1 to 1.6.0](https://github.com/compose-spec/compose-go/releases/tag/v1.6.0)\n    \n*   Updated to go 1.19.2 to address CVE-2022-2879, CVE-2022-2880, CVE-2022-41715\n    \n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-35)\n\n*   Added a `quiet` option when pushing an image. Fixed [compose#9089](https://github.com/docker/compose/issues/9089)\n*   Fixed a misleading error message for `port` command. Pull Request [compose#9909](https://github.com/docker/compose/pull/9909)\n*   Fixed a bug to prevent failure when Compose tries to remove a non-existing container. Fixed by [compose#9896](https://github.com/docker/compose/pull/9896/)\n*   Switched GitHub issue template form\n\nFor the full change log or additional information, check the [Compose repository 2.12.0 release page](https://github.com/docker/compose/releases/tag/v2.12.0).\n\n_2022-09-27_\n\n> **Note**\n> \n> *   Updates on environment file syntax & interpolation: see [compose#9879](https://github.com/docker/compose/issues/9879)\n> *   Setting `DOCKER_HOST` via `.env` files is not supported in Compose v2\n\n### [Updates](#updates-5)\n\n*   Upgraded to compose-go from [1.5.1 to 1.6.0](https://github.com/compose-spec/compose-go/releases/tag/v1.6.0)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-36)\n\n*   Fixed a bug to prevent \"invalid template\" errors on valid environment variable values. Fixes [compose##9806](https://github.com/docker/compose/issues/9806), [compose##9746](https://github.com/docker/compose/issues/9746), [compose##9704](https://github.com/docker/compose/issues/9704), [compose##9294](https://github.com/docker/compose/issues/9294)\n*   Fixed a bug to ensure new images from `docker compose build` are used. Fixes [compose#9856](https://github.com/docker/compose/issues/9856)\n*   Fixed cross-architecture builds when `DOCKER_DEFAULT_PLATFORM` not set. Fixes [compose#9864](https://github.com/docker/compose/pull/9864)\n*   Fixed intermittent conflict errors when using `depends_on`. Fixes [compose#9014](https://github.com/docker/compose/issues/9014)\n*   Cleared service `CMD` when entry point is overridden. Fixes [compose#9622](https://github.com/docker/compose/issues/9622)\n*   Configured default builder export when no `build.platforms` defined. Fixes [compose#9856](https://github.com/docker/compose/issues/9856)\n*   Fixed a bug to keep the platform defined, in priority, via DOCKER\\_DEFAULT\\_PLATFORM or the `service.platform` attribut. Fixes [compose#9864](https://github.com/docker/compose/issues/9864)\n*   Removed support for `DOCKER_HOST` in `.env` files. Fixes [compose#9210](https://github.com/docker/compose/issues/9210)\n*   Fixed a bug to ensure clean service command if entry point is overridden in run command. Fixes [compose#9622](https://github.com/docker/compose/issues/9622)\n*   Deps: fixed race condition during graph traversal. Fixes [compose#9014](https://github.com/docker/compose/issues/9014)\n*   CI now runs on Windows & macOS including E2E tests via Docker Desktop\n*   Added more information when `service.platform` isn't part of `service.build.platforms`\n*   GitHub Workflows security hardening\n\nFor the full change log or additional information, check the [Compose repository 2.11.2 release page](https://github.com/docker/compose/releases/tag/v2.11.2).\n\n_2022-09-20_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-37)\n\n*   Fixed a bug to keep `depends_on` condition when service has `volumes_from`. Fixes [compose#9843](https://github.com/docker/compose/issues/9843)\n*   Fixed a bug to keep the platform defined at service level during build if no build platforms. Fixes [compose#9729](https://github.com/docker/compose/pull/9729#issuecomment-1246748144)\n*   Fixed a bug to keep the platform defined via DOCKER\\_DEFAULT\\_PLATFORM during build if no build platforms provided. Fixes [compose#9853](https://github.com/docker/compose/issues/9853)\n\nFor the full change log or additional information, check the [Compose repository 2.11.1 release page](https://github.com/docker/compose/releases/tag/v2.11.1).\n\n_2022-09-14_\n\n### [Updates](#updates-6)\n\n*   Dependencies upgrade: bump Golang to 1.19.1\n*   Dependencies upgrade: bump github.com/docker/go-units from 0.4.0 to 0.5.0\n*   Dependencies upgrade: bump github.com/cnabio/cnab-to-oci from 0.3.6 to 0.3.7\n*   Dependencies upgrade: bump go.opentelemetry.io/otel from 1.9.0 to 1.10.0\n*   Dependencies upgrade: bump github.com/AlecAivazis/survey/v2 from 2.3.5\n*   Dependencies upgrade: bump go.opentelemetry.io/otel from 1.4.1 to 1.9.0\n*   Dependencies upgrade: bump compose-go from [1.5.0 to 1.5.1](https://github.com/compose-spec/compose-go/releases/tag/v1.5.1)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-38)\n\n*   Added platforms build. Fixes [compose-spec#267](https://github.com/compose-spec/compose-spec/pull/267)\n*   Logs now filter to services from current Compose file. Fixes [compose#9801](https://github.com/docker/compose/issues/9801)\n*   Added an improved output warning when pulling images. Fixes [compose#9820](https://github.com/docker/compose/issues/9820)\n*   Fixed a bug to ensure correct capture of exit code when service has dependencies. Fixes [compose#9778](https://github.com/docker/compose/issues/9778)\n*   Fixed `down` with `--rmi`. Fixes [compose#9655](https://github.com/docker/compose/issues/9655)\n*   Fixed docker-compose convert that turns $ into $$ when using the --no-interpolate option. Fixes [compose#9160](https://github.com/docker/compose/issues/9160)\n*   Fixed `build.go` access custom labels directly cause panic. See [compose#9810](https://github.com/docker/compose/pull/9810)\n*   Applied newly loaded envvars to \"DockerCli\" and \"APIClient\". Fixes [compose#9210](https://github.com/docker/compose/issues/9210)\n*   Only attempt to start specified services on `compose start [services]`. Fixes [compose#9796](https://github.com/docker/compose/issues/9796) [compose#9807](https://github.com/docker/compose/issues/9807)\n*   Label built images for reliable cleanup on `down`. Fixes [compose#9655](https://github.com/docker/compose/issues/9655)\n\nFor the full change log or additional information, check the [Compose repository 2.11.0 release page](https://github.com/docker/compose/releases/tag/v2.11.0).\n\n_2022-08-26_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-39)\n\n*   Properly respect `DOCKER_TLS_VERIFY` and `DOCKER_CERT_PATH` environment variables. Fixes [compose#9789](https://github.com/docker/compose/issues/9789).\n*   Improved `Makefile` used in [docker/docker-ce-packaging#742](https://github.com/docker/docker-ce-packaging/pull/742).\n\nFor the full change log or additional information, check the [Compose repository 2.10.2 release page](https://github.com/docker/compose/releases/tag/v2.10.2).\n\n_2022-08-24_\n\n### [Updates](#updates-7)\n\n*   Dependencies update: Bumped github.com/moby/buildkit from [0.10.3 to 0.10.4](https://github.com/moby/buildkit/releases/tag/v0.10.4).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-40)\n\n*   Fixed image pulls being skipped when `pull_policy` was not set. Fixes [compose#9773](https://github.com/docker/compose/issues/9773).\n*   Restored `.sha256` checksum files in release artifacts. Fixes [compose#9772](https://github.com/docker/compose/issues/9772).\n*   Removed error message showing exit code when using --exit-code-from. Fixes [compose#9782](https://github.com/docker/compose/issues/9782).\n*   Fixed `compose pull` to pull images even when they existed locally if `tag=latest`.\n*   CI: Fixed checksums checking and brought back individual checksum files.\n\nFor the full change log or additional information, check the [Compose repository 2.10.1 release page](https://github.com/docker/compose/releases/tag/v2.10.1).\n\n_2022-08-19_\n\n### [New](#new)\n\n*   Applied newly loaded environment variables to `DockerCli` and `APIClient`. Fixes [compose#9210](https://github.com/docker/compose/issues/9210).\n*   Added support for windows/arm64 and linux/riscv64.\n\n### [Updates](#updates-8)\n\n*   Updated Dockerfile syntax to latest stable and renamed docs Dockerfile.\n*   Dependencies update: Upgraded BuildKit & docker/distribution.\n*   Dependencies update: Updated Docker CLI version used in CI to v20.10.17.\n*   Dependencies update: Bumped github.com/containerd/containerd from [1.6.6 to 1.6.7](https://github.com/containerd/containerd/releases/tag/v1.6.7).\n*   Dependencies update: Bump github.com/containerd/containerd from [1.6.7 to 1.6.8](https://github.com/containerd/containerd/releases/tag/v1.6.8).\n*   Dependencies update: Bumped to Go 1.18.5.\n*   Dependencies update: Bumped github.com/cnabio/cnab-to-oci from [0.3.5 to 0.3.6](https://github.com/cnabio/cnab-to-oci/releases/tag/v0.3.6).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-41)\n\n*   Reverted environment variables precedence to OS over `.env` file. Fixes [compose#9737](https://github.com/docker/compose/issues/9737).\n*   Updated usage strings for consistency.\n*   Resolved environment variables case-insensitively on Windows. Fixes [compose#9431](https://github.com/docker/compose/issues/9431).\n*   Fixed `compose up` so dependency containers aren't stopped when a stop signal is issued. This keeps parity with v1 behavior-wise.\n*   Fixes [compose#9696](https://github.com/docker/compose/issues/9696).\n*   Fixed commands that start/restart/pause/unpause so that, if ran from the Compose file, the Compose model is also applied. Fixes [compose#9705](https://github.com/docker/compose/issues/9705) and [compose#9705](https://github.com/docker/compose/issues/9671).\n*   Removed extra whitespaces in help text of some subcommands.\n*   Fixed `compose create` to not override service pull policy when the value from the command line is configured as the default. Fixes [compose#9717](https://github.com/docker/compose/issues/9717).\n*   Filtered out \"commandConn.Close- warning\" message. Fixes [compose#8544](https://github.com/docker/compose/issues/8544).\n*   Fixed up/start/run to not wait for disabled dependency. Fixes [compose#9591](https://github.com/docker/compose/issues/9591).\n*   Applied Compose model on `compose kill`, added `--remove-orphans` option. Fixes [compose#9742](https://github.com/docker/compose/issues/9742).\n*   Fixed `compose pull` to avoid pulling the same images multiple times. Fixes [compose#8768](https://github.com/docker/compose/issues/8768).\n*   Fixed version of golangci-lint to v1.47.3, issue with v1.48.0 for now.\n\nFor the full change log, check the [Compose repository 2.10.0 release page](https://github.com/docker/compose/releases/tag/v2.10.0).\n\n_2022-08-7_\n\n> **Important**\n> \n> Compose v2.9.0 contains changes to the environment variable's precedence that have since been reverted. We recommend using v2.10+ to avoid compatibility issues.\n\n> **Note**\n> \n> This release reverts the breaking changes introduced in [Compose v2.8.0](#280) by [`compose-go v1.3.0`](https://github.com/compose-spec/compose-go/releases/tag/v1.3.0).\n\n### [Updates](#updates-9)\n\n*   Updated [`compose-go` to v1.4.0](https://github.com/compose-spec/compose-go/releases/tag/v1.4.0) as previous version introduced breaking changes. Fixes [compose#9700](https://github.com/docker/compose/issues/9700).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-42)\n\n*   Overwritten parent commands PreRun code for `compose version`. Fixes [compose#9698](https://github.com/docker/compose/issues/9698).\n*   Fixed `LinkLocalIPs` in V2. Fixes [compose#9692](https://github.com/docker/compose/issues/9692).\n*   Linked to `BUILDING.md` for testing instructions. Fixes [compose#9439](https://github.com/docker/compose/issues/9439).\n\nFor the full change log or additional information, check the [Compose repository 2.9.0 release page](https://github.com/docker/compose/releases/tag/v2.9.0).\n\n_2022-07-29_\n\n> **Important**\n> \n> This release introduced a breaking change via `compose-go v1.3.0` and this [PR](https://github.com/compose-spec/compose-go/pull/294). In this release, Docker Compose recreates new resources (networks, volumes, secrets, configs, etc.) with new names, using a `-` (dash) instead an `_` (underscore) and tries to connect to or use these newly created resources instead of your existing ones!\n> \n> Please use Compose the v2.9.0 release instead.\n\n### [New](#new-1)\n\n*   Introduced `--pull` flag to allow the force pull of updated service images. Fixes [compose#9451](https://github.com/docker/compose/issues/9451).\n*   Increased code quality by adding `gocritic` to the linters.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-43)\n\n*   Fixed interpolation error message output. Fixes [compose-spec/compose-go#292](https://github.com/compose-spec/compose-go/pull/292).\n*   Defined precedence of the environment variables evaluation. Fixes [compose#9521](https://github.com/docker/compose/issues/9606), [compose#9638](https://github.com/docker/compose/issues/9638), [compose#9608](https://github.com/docker/compose/issues/9608), [compose#9578](https://github.com/docker/compose/issues/9578). [compose#9468](https://github.com/docker/compose/issues/9468), and [compose#9683](https://github.com/docker/compose/issues/9468).\n*   Docs CI: Fixed to use push-to-fork when creating a PR.\n*   Used environmental variable for golang's version and updates GitHub Actions from v2 to v3.\n*   Used [google/addlicense](https://github.com/google/addlicense) instead of [kunalkushwaha/ltag](https://github.com/kunalkushwaha/ltag).\n\nFor the full change log or additional information, check the [Compose repository 2.8.0 release page](https://github.com/docker/compose/releases/tag/v2.8.0).\n\n_2022-07-20_\n\n### [New](#new-2)\n\n*   Added support for environment secrets during build step. Fixes [compose#9606](https://github.com/docker/compose/issues/9606).\n\n### [Updates](#updates-10)\n\n*   Dependencies upgrade: bumped [go to 1.18.4](https://github.com/golang/go/compare/go1.18.3...go1.18.4).\n*   Dependencies upgrade: bumped [compose-go to v1.2.9](https://github.com/compose-spec/compose-go/releases/tag/v1.2.9).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-44)\n\n*   Networks: prevented issues due to duplicate names. Fixes [moby/moby#18864](https://github.com/moby/moby/issues/18864).\n*   Fixed issue with close networks name on `compose up` and `compose down` commands. Fixes [compose#9630](https://github.com/docker/compose/issues/9044).\n*   Used appropriate dependency condition for one-shot containers when running `compose up --wait`. Fixes [compose#9606](https://github.com/docker/compose/pull/9572).\n*   Fixed environment variable expansion.\n*   Validated depended-on services exist in consistency check. Fixes [compose#8910](https://github.com/docker/compose/issues/8910).\n*   Fixed hash usage in environment values. Fixes [compose#9509](https://github.com/docker/compose/issues/9509).\n*   Docker Build: added fix to respect dependency order for classic builder. Fixes [compose#8538](https://github.com/docker/compose/issues/8538).\n*   Fixed panic caused by empty string argument. Fixes [compose-switch#35](https://github.com/docker/compose-switch/issues/35).\n*   Fixed start/restart as to not impact one-off containers. Fixes [compose#9509](https://github.com/docker/compose/issues/9044).\n*   Fixed to keep the container reference when `volumes_from` targets a container and not a service. Fixes [compose#8874](https://github.com/docker/compose/issues/8874).\n*   build.go: added fix to initialize `CustomLabels` map if `nil`.\n*   Added new targets to build Compose binary before running e2e tests.\n*   CI: released workflow to open a PR on docs repo with latest changes.\n*   e2e: added test for `ps`.\n*   e2e: split out pause tests and add more cases.\n*   e2e: add more start/stop test cases.\n\nFor the full change log or additional information, check the [Compose repository 2.7.0 release page](https://github.com/docker/compose/releases/tag/v2.7.0).\n\n_2022-06-23_\n\n### [New](#new-3)\n\n*   Added support for setting secrets from environment variable. Fixes [compose-spec/compose-spec#251](https://github.com/compose-spec/compose-spec/issues/251).\n\n### [Updates](#updates-11)\n\n*   Upgrade: compose-go [v1.2.8](https://github.com/compose-spec/compose-go/releases/tag/v1.2.8).\n*   Upgrade: buildx [v0.8.2](https://github.com/docker/buildx/releases/tag/v0.8.2).\n*   Dependencies upgrade: bumped runc [to 1.1.2](https://github.com/opencontainers/runc/releases/tag/v1.1.2).\n*   Dependencies upgrade: bumped golang to [1.18.3](https://go.dev/doc/devel/release#go1.18.minor).\n*   Dependencies upgrade: bumped compose-go to [v1.2.8](https://github.com/compose-spec/compose-go/releases/tag/v1.2.8).\n*   Dependencies upgrade: bumped github.com/theupdateframework/notary from 0.6.1 to 0.7.0.\n*   Dependencies upgrade: bumped github.com/cnabio/cnab-to-oci from 0.3.1-beta1 to 0.3.3.\n*   Dependencies upgrade: bumped github.com/hashicorp/go-version from 1.3.0 to 1.5.0.\n*   Dependencies upgrade: bumped github.com/stretchr/testify from 1.7.0 to 1.7.2.\n*   Dependencies upgrade: bumped github.com/docker/buildx from 0.8.1 to 0.8.2.\n*   Dependencies upgrade: bumped github.com/AlecAivazis/survey/v2 from 2.3.2 to 2.3.5.\n*   Dependencies upgrade: bumped github.com/containerd/containerd from 1.6.2 to 1.6.6.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-45)\n\n*   Added links to container create request. Fixes [#9513](https://github.com/docker/compose/issues/9513).\n*   Fixed `compose run` to start only direct dependencies. Fixes [#9459](https://github.com/docker/compose/issues/9459).\n*   Fixed `compose up` 'service not found' errors when using `--no-deps` option. Fixes [#9427](https://github.com/docker/compose/issues/9427).\n*   Fixed `compose down` to respect `COMPOSE_REMOVE_ORPHANS` environment variable. Fixes [#9562](https://github.com/docker/compose/issues/9562).\n*   Fixed project-level bind mount volumes. Fixes [docker/for-mac#6317](https://github.com/docker/for-mac/issues/6317).\n*   Fixed parsing of properties `deploy.limits.cpus` and `deploy.limits.pids` to respect floating-point values. Fixes [#9542](https://github.com/docker/compose/issues/9542) and [#9501](https://github.com/docker/compose/issues/9501).\n*   Fixed `compose ps` output to list all exposed ports. Fixes [#9257](https://github.com/docker/compose/issues/9527).\n*   Fixed spelling mistakes in `compose ps` code.\n*   Fixed `docker compose` to honor `--no-ansi` even when deprecated option is requested.\n*   Fixed network name and network ID possible ambiguity.\n*   e2e: added test for `ps`.\n*   e2e: unmarshalled json into container summaries.\n*   e2e: fixed subtests and block parallel unsafe tests.\n*   e2e: isolated test command env from system env.\n*   e2e: fixed spurious `ps` failures.\n*   e2e: ensured all compose commands standalone compatible.\n*   e2e: improved test output on failures.\n\nFor the full change log or additional information, check the [Compose repository 2.6.1 release page](https://github.com/docker/compose/releases/tag/v2.6.1).\n\n_2022-05-30_\n\n### [New](#new-4)\n\n*   Added the tags property to the build section. In this property tags can be defined to be applied to the final image, in addition to the one defined in the image property.\n*   Added end-to-end tests to ensure there is no regression on environment variables precedence.\n*   Added ddev's end-to-end test.\n\n### [Updates](#updates-12)\n\n*   Dependencies update: bumping [compose-go to 1.2.6](https://github.com/compose-spec/compose-go/releases/tag/v1.2.6).\n*   Dependencies update: bumping [compose-go to 1.2.7](https://github.com/compose-spec/compose-go/releases/tag/v1.2.7).\n*   Dependencies update: bumping [golang to 1.18](https://go.dev/doc/devel/release#go1.18).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-46)\n\n*   Fixed `compose up` to attach only to services declared in project with enabled profiles. Fixes [#9286](https://github.com/docker/compose/issues/9286).\n*   Fixed flickering prompt when pulling same image from multiple services. Fixes [#9469](https://github.com/docker/compose/issues/9469).\n*   Fixed compose go to import .env file to OS environment to allow setting variables (such as DOCKER\\_BUILDKIT) through this file. Fixes [#9345](https://github.com/docker/compose/issues/9345).\n*   Fixed `TestLocalComposeUp` that failed locally.\n*   Fixed local run of make `e2e-compose-standalone`.\n\nFor the full change log or additional information, check the [Compose repository 2.6.0 release page](https://github.com/docker/compose/releases/tag/v2.6.0).\n\n_2022-05-17_\n\n### [Updates](#updates-13)\n\n*   Dependencies updates: bumping compose-go to 1.2.5.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-47)\n\n*   Fixed resolution of project's working directive absolute path when a relative path is declared using '--env-file'. Fixes [docker/for-mac#6229](https://github.com/docker/for-mac/issues/6229).\n*   Fixed `compose down`: now rejects all arguments in order to clarify usage. Fixes [#9151](https://github.com/docker/compose/issues/9151).\n*   Fixed `compose down`: now exits with status=0 if there is nothing to remove. Fixes [#9426](https://github.com/docker/compose/issues/9426).\n*   Fixed extra space printed in logs output lines with --no-log-prefix option. Fixes [#9464](https://github.com/docker/compose/issues/9464).\n*   Clarified what the default work dir is when multiple compose files are passed.\n*   cp command: copy to all containers of a service as default behavior.\n\nFor the full change log or additional information, check the [Compose repository 2.5.1 release page](https://github.com/docker/compose/releases/tag/v2.5.1).\n\n_2022-04-29_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-48)\n\n*   Fixed panic with `compose down` command when `-p` flag specified. Fixes [#9353](https://github.com/docker/compose/issues/9353).\n*   Passed newly created project as input to start services (`docker compose up`). Fixes [#9356](https://github.com/docker/compose/issues/9356).\n*   Included services declared under links in docker-compose file as implicit dependencies. Fixes [#9301](https://github.com/docker/compose/issues/9301).\n*   Added changes `docker compose pull` command to respect defined policy: 1) skip services configured as `pull_policy: never` and 2) ignore those with an existing image and `pull_policy: missing`. Fixes [#3660](https://github.com/docker/compose/issues/3660).\n*   Error building project from resources is no longer ignored in order to prevent `down` panic. Fixes [#9383](https://github.com/docker/compose/issues/9383).\n*   Enforced project name to be lowercase. Fixes [#9378](https://github.com/docker/compose/issues/9378).\n*   Added support to build-time secrets. Fixes [#6358](https://github.com/docker/compose/issues/6358).\n*   Changed `compose-go` to allow (re)building volume string to be used by engine `bind` API when mount can't be used. Fixes [#9380](https://github.com/docker/compose/issues/9380).\n*   Provided checksums.txt file and added `--binary` to allow verification in different OS. Fixes [#9388](https://github.com/docker/compose/issues/9388).\n*   Added changes so locally pulled image's ID is inspected and persisted to `com.docker.compose.image`. Fixes [#9357](https://github.com/docker/compose/issues/9357).\n*   Fixed issue regarding IPAM gateway setup. Fixes [#9330](https://github.com/docker/compose/issues/9330).\n*   Added support for ppc64le archictecture for docker compose binary.\n*   Fixed search/replace typo in `--no-TTY` documentation.\n\nFor the full change log or additional information, check the [Compose repository 2.5.0 release page](https://github.com/docker/compose/releases/tag/v2.5.0).\n\n_2022-04-04_\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-49)\n\n*   Passed the `--rm flag` value as is to the Docker CLI when running a container with this flag. Fixes [#9314](https://github.com/docker/compose/issues/9314).\n*   Added ssh config to the build options when building an image from a `docker compose up` command. Fixes [#9338](https://github.com/docker/compose/issues/9338).\n*   Added inspection to container checking if a TTY is required. Running services with `tty:true` specified now show console output. Fixes [#9288](https://github.com/docker/compose/issues/9288).\n\nFor the full change log or additional information, check the [Compose repository 2.4.1 release page](https://github.com/docker/compose/releases/tag/v2.4.1).\n\n_2022-04-1_\n\n### [Updates](#updates-14)\n\n*   Dependencies update: Bumped buildx to v0.8.1. to fix possible panic on handling build context scanning errors.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-50)\n\n*   Passed the interactive flag '-i' from the Compose CLI to the Docker one to run exec command. Fixes [#9315](https://github.com/docker/compose/issues/9315).\n*   Compose commands now take the value of `COMPOSE_PROJECT_NAME` environmental variable into consideration. Fixes [#9316](https://github.com/docker/compose/issues/9316).\n*   Fixed issue of `compose down` command that when executed in contexts without any services started or resources to be deleted was returning an error. Error was due to command trying to delete an inexistent default network. Fixes [#9333](https://github.com/docker/compose/issues/9333).\n*   Introduced support for `cache_from`, `cache_to`, `no_cache` and `pull` attributes in the build section. These attributes allow forcing a complete rebuild from sources and checking with registry for images used. These changes provide the basis for offering `--no-cache` and `--pull` options for compose build (or equivalent) command down the line.\n*   Introduced support of an `--ssh` flag for the `build` command from CLI and Compose file. Fixes [#7025](https://github.com/docker/compose/issues/7025).\n*   Fixed typo in `--ssh` flag description. Related to [#7025](https://github.com/docker/compose/issues/7025).\n*   Pinned Kubernetes dependencies to the same version as in buildx.\n*   Passed the interactive flag from the Compose CLI to the Docker one to run exec command.\n*   Fixed race condition on start-stop end-to-end tests running in parallel.\n*   Removed code regarding an obsolete warning.\n*   Vendor: github.com/containerd/containerd v1.6.2. Includes a fix for CVE-2022-24769 (doesn't affect our codebase).\n\nFor the full change log or additional information, check the [Compose repository 2.4.0 release page](https://github.com/docker/compose/releases/tag/v2.4.0).\n\n_2022-03-25_\n\n### [New](#new-5)\n\n*   Introduced changes to use RunExec and RunStart from docker/cli to handle all the interactive/tty/\\* terminal logic.\n\n### [Removed](#removed)\n\n*   Removed a container with no candidate now produces a warning instead of an error. Fixes [#9255](https://github.com/docker/compose/issues/9255).\n*   Removed the \"Deprecated\" mentions from -i and -t options to run and exec commands. These options are on by default and in use. Fixes [#9229](https://github.com/docker/compose/pull/9229#discussion_r819730788).\n*   Removed the \"Deprecated\" mention from the --filter flag, to keep consistency with other commands.\n*   Removed the need to get the original compose.yaml file to run 'docker compose kill'.\n\n### [Updates](#updates-15)\n\n*   Dependencies update: Bumped github.com/spf13/cobra from 1.3.0 to 1.4.0. Cobra library no longer requires Viper and all of its indirect dependencies [See cobra's release page](https://github.com/spf13/cobra/releases).\n*   Dependencies update: Bumped buildx from v0.7.1 to v0.8.0.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-51)\n\n*   Recovered behavior for 'compose up -d' of recreating containers of compose file images with refreshed content. Fixes [#9259](https://github.com/docker/compose/issues/9259).\n*   Docker compose --status, --filter and --format flags documentation updates.\n*   `docker compose down -v` now does not remove external volumes and networks as per the option's expected and documented behavior. Whenever project is specified it is also now used to enforce down to only remove resources listed in compose.yaml file. Fixes [#9172](https://github.com/docker/compose/issues/9172), [#9145](https://github.com/docker/compose/issues/9145).\n*   Changed Compose API reference docs automation to pick up diffs code vs. docs.\n\nFor the full change log or additional information, check the [Compose repository 2.3.4 release page](https://github.com/docker/compose/releases/tag/v2.3.4).\n\n(2022-03-8 to 2022-04-14)\n\nFor the releases later than 1.29.2 and earlier than 2.3.4, please check the [Compose repository release pages](https://github.com/docker/compose/releases).\n\n(2021-05-10)\n\n### [Miscellaneous](#miscellaneous)\n\n*   Removed the prompt to use `docker-compose` in the `up` command.\n    \n*   Bumped `py` to `1.10.0` in `requirements-indirect.txt`.\n    \n\n(2021-04-13)\n\n### [Bugs](#bugs)\n\n*   Fixed invalid handler warning on Windows builds.\n    \n*   Fixed config hash to trigger container re-creation on IPC mode updates.\n    \n*   Fixed conversion map for `placement.max_replicas_per_node`.\n    \n*   Removed extra scan suggestion on build.\n    \n\n(2021-04-06)\n\n### [Features](#features)\n\n*   Added profile filter to `docker-compose config`.\n    \n*   Added a `depends_on` condition to wait for successful service completion.\n    \n\n### [Miscellaneous](#miscellaneous-1)\n\n*   Added an image scan message on build.\n    \n*   Updated warning message for `--no-ansi` to mention `--ansi never` as alternative.\n    \n*   Bumped docker-py to 5.0.0.\n    \n*   Bumped PyYAML to 5.4.1.\n    \n*   Bumped python-dotenv to 0.17.0.\n    \n\n(2021-03-23)\n\n### [Bug fixes](#bug-fixes)\n\n*   Made `--env-file` relative to the current working directory. Environment file paths set with `--env-file` are now relative to the current working directory and override the default `.env` file located in the project directory.\n    \n*   Fixed missing service property `storage_opt` by updating the Compose schema.\n    \n*   Fixed build `extra_hosts` list format.\n    \n*   Removed additional error message on `exec`.\n    \n\n### [Miscellaneous](#miscellaneous-2)\n\n*   Added `compose.yml` and `compose.yaml` to the default filename list.\n\n(2021-02-26)\n\n### [Bugs](#bugs-1)\n\n*   Fixed the OpenSSL version mismatch error when shelling out to the SSH client (via bump to docker-py 4.4.4 which contains the fix).\n    \n*   Added missing build flags to the native builder: `platform`, `isolation` and `extra_hosts`.\n    \n*   Removed info message on native build.\n    \n*   Fixed the log fetching bug when service logging driver is set to 'none'.\n    \n\n(2021-02-18)\n\n### [Bug fixes](#bug-fixes-1)\n\n*   Fixed SSH port parsing by bumping docker-py to 4.4.3.\n\n### [Miscellaneous](#miscellaneous-3)\n\n*   Bumped Python to 3.7.10.\n\n(2021-02-17)\n\n### [Bug fixes](#bug-fixes-2)\n\n*   Fixed SSH hostname parsing when it contains a leading 's'/'h', and removed the quiet option that was hiding the error (via docker-py bump to 4.4.2).\n    \n*   Fixed key error for `--no-log-prefix` option.\n    \n*   Fixed incorrect CLI environment variable name for service profiles: `COMPOSE_PROFILES` instead of `COMPOSE_PROFILE`.\n    \n*   Fixed the fish completion.\n    \n\n### [Miscellaneous](#miscellaneous-4)\n\n*   Bumped cryptography to 3.3.2.\n    \n*   Removed the log driver filter.\n    \n\nFor a list of PRs and issues fixed in this release, see [Compose 1.28.3](https://github.com/docker/compose/milestone/53?closed=1).\n\n(2021-01-26)\n\n### [Bug fixes](#bug-fixes-3)\n\n*   Revert to Python 3.7 bump for Linux static builds\n    \n*   Add bash completion for `docker-compose logs|up --no-log-prefix`\n    \n\n### [Miscellaneous](#miscellaneous-5)\n\n*   CI setup update\n\n(2021-01-20)\n\n### [Features](#features-1)\n\n*   Added support for NVIDIA GPUs through device requests.\n    \n*   Added support for service profiles.\n    \n*   Changed the SSH connection approach to the Docker CLI by shelling out to the local SSH client. Set the `COMPOSE_PARAMIKO_SSH=1` environment variable to enable the old behavior.\n    \n*   Added a flag to disable log prefix.\n    \n*   Added a flag for ANSI output control.\n    \n*   Docker Compose now uses the native Docker CLI's `build` command when building images. Set the `COMPOSE_DOCKER_CLI_BUILD=0` environment variable to disable this feature.\n    \n\n### [Bug fixes](#bug-fixes-4)\n\n*   Made `parallel_pull=True` by default.\n    \n*   Restored the warning for configs in non-swarm mode.\n    \n*   Took `--file` into account when defining `project_dir`.\n    \n*   Fixed a service attach bug on `compose up`.\n    \n\n### [Miscellaneous](#miscellaneous-6)\n\n*   Added usage metrics.\n    \n*   Synced schema with COMPOSE specification.\n    \n*   Improved failure report for missing mandatory environment variables.\n    \n*   Bumped `attrs` to 20.3.0.\n    \n*   Bumped `more_itertools` to 8.6.0.\n    \n*   Bumped `cryptograhy` to 3.2.1.\n    \n*   Bumped `cffi` to 1.14.4.\n    \n*   Bumped `virtualenv` to 20.2.2.\n    \n*   Bumped `bcrypt` to 3.2.0.\n    \n*   Bumped GitPython to 3.1.11.\n    \n*   Bumped `docker-py` to 4.4.1.\n    \n*   Bumped Python to 3.9.\n    \n*   Linux: bumped Debian base image from stretch to buster (required for Python 3.9).\n    \n*   macOS: Bumped OpenSSL 1.1.1g to 1.1.1h, and Python 3.7.7 to 3.9.0.\n    \n*   Bumped PyInstaller to 4.1.\n    \n*   Relaxed the restriction on base images to latest minor.\n    \n*   Updated READMEs.\n    \n\n(2020-09-24)\n\n### [Bug fixes](#bug-fixes-5)\n\n*   Removed path checks for bind mounts.\n    \n*   Fixed port rendering to output long form syntax for non-v1.\n    \n*   Added protocol to the Docker socket address.\n    \n\n(2020-09-16)\n\n### [Bug fixes](#bug-fixes-6)\n\n*   Merged `max_replicas_per_node` on `docker-compose config`.\n    \n*   Fixed `depends_on` serialization on `docker-compose config`.\n    \n*   Fixed scaling when some containers are not running on `docker-compose up`.\n    \n*   Enabled relative paths for `driver_opts.device` for `local` driver.\n    \n*   Allowed strings for `cpus` fields.\n    \n\n(2020-09-10)\n\n### [Bug fixes](#bug-fixes-7)\n\n*   Fixed bug on `docker-compose run` container attach.\n\n(2020-09-10)\n\n### [Bug fixes](#bug-fixes-8)\n\n*   Fixed `docker-compose run` when `service.scale` is specified.\n    \n*   Allowed the `driver` property for external networks as a temporary workaround for the Swarm network propagation issue.\n    \n*   Pinned the new internal schema version to `3.9` as the default.\n    \n*   Preserved the version number configured in the Compose file.\n    \n\n(2020-09-07)\n\n### [Features](#features-2)\n\n*   Merged 2.x and 3.x Compose formats and aligned with `COMPOSE_SPEC` schema.\n    \n*   Implemented service mode for `ipc`.\n    \n*   Passed `COMPOSE_PROJECT_NAME` environment variable in container mode.\n    \n*   Made `run` behave in the same way as `up`.\n    \n*   Used `docker build` on `docker-compose run` when `COMPOSE_DOCKER_CLI_BUILD` environment variable is set.\n    \n*   Used the docker-py default API version for engine queries (`auto`).\n    \n*   Parsed `network_mode` on build.\n    \n\n### [Bug fixes](#bug-fixes-9)\n\n*   Ignored build context path validation when building is not required.\n    \n*   Fixed float to bytes conversion via docker-py bump to 4.3.1.\n    \n*   Fixed the scale bug when the deploy section is set.\n    \n*   Fixed `docker-py` bump in `setup.py`.\n    \n*   Fixed experimental build failure detection.\n    \n*   Fixed context propagation to the Docker CLI.\n    \n\n### [Miscellaneous](#miscellaneous-7)\n\n*   Bumped `docker-py` to 4.3.1.\n    \n*   Bumped `tox` to 3.19.0.\n    \n*   Bumped `virtualenv` to 20.0.30.\n    \n*   Added script for Docs synchronization.\n    \n\n(2020-07-02)\n\n### [Bug fixes](#bug-fixes-10)\n\n*   Enforced `docker-py` 4.2.2 as minimum version when installing with pip.\n\n(2020-06-30)\n\n### [Features](#features-3)\n\n*   Bumped `docker-py` from 4.2.1 to 4.2.2.\n\n### [Bug fixes](#bug-fixes-11)\n\n*   Enforced `docker-py` 4.2.1 as minimum version when installing with pip.\n    \n*   Fixed context load for non-docker endpoints.\n    \n\n(2020-06-03)\n\n### [Features](#features-4)\n\n*   Added `docker context` support.\n    \n*   Added missing test dependency `ddt` to `setup.py`.\n    \n*   Added `--attach-dependencies` to command `up` for attaching to dependencies.\n    \n*   Allowed compatibility option with `COMPOSE_COMPATIBILITY` environment variable.\n    \n*   Bumped `Pytest` to 5.3.4 and add refactor compatibility with the new version.\n    \n*   Bumped `OpenSSL` from 1.1.1f to 1.1.1g.\n    \n*   Bumped `certifi` from 2019.11.28 to 2020.4.5.1.\n    \n*   Bumped `docker-py` from 4.2.0 to 4.2.1.\n    \n\n### [Bug fixes](#bug-fixes-12)\n\n*   Properly escaped values coming from `env_files`.\n    \n*   Synchronized compose-schemas with upstream (docker/cli).\n    \n*   Removed `None` entries on exec command.\n    \n*   Added `distro` package to get distro information.\n    \n*   Added `python-dotenv` to delegate `.env` file processing.\n    \n*   Stopped adjusting output on terminal width when piped into another command.\n    \n*   Showed an error message when `version` attribute is malformed.\n    \n*   Fixed HTTPS connection when `DOCKER_HOST` is remote.\n    \n\n(2020-04-10)\n\n### [Features](#features-5)\n\n*   Bumped OpenSSL from 1.1.1d to 1.1.1f.\n    \n*   Added Compose version 3.8.\n    \n    *   Limited service scale to the size specified by the field `deploy.placement.max_replicas_per_node`.\n\n(2020-02-03)\n\n### [Bug fixes](#bug-fixes-13)\n\n*   Fixed the CI script to enforce the minimal MacOS version to 10.11.\n    \n*   Fixed docker-compose exec for keys with no value on environment files.\n    \n\n(2020-01-23)\n\n### [Bug fixes](#bug-fixes-14)\n\n*   Fixed the CI script to enforce the compilation with Python3.\n    \n*   Updated the binary's sha256 on the release page.\n    \n\n(2020-01-20)\n\n### [New features](#new-features)\n\n*   Docker Compose now allows the compatibility option with `COMPOSE_COMPATIBILITY` environment variable.\n\n### [Bug fixes](#bug-fixes-15)\n\n*   Fixed an issue that caused Docker Compose to crash when the `version` field was set to an invalid value. Docker Compose now displays an error message when invalid values are used in the version field.\n    \n*   Fixed an issue that caused Docker Compose to render messages incorrectly when running commands outside a terminal.\n    \n\n(2020-01-06)\n\n### [Bugfixes](#bugfixes)\n\n*   Decoded the `APIError` explanation to Unicode before using it to create and start a container.\n    \n*   Docker Compose discards `com.docker.compose.filepaths` labels that have `None` as value. This usually occurs when labels originate from stdin.\n    \n*   Added OS X binary as a directory to solve slow start up time issues caused by macOS Catalina binary scan.\n    \n*   Passed the `HOME` environment variable in container mode when running with `script/run/run.sh`.\n    \n*   Docker Compose now reports images that cannot be pulled, however, are required to be built.\n    \n\n(2019-11-18)\n\n### [New features](#new-features-1)\n\n*   Set no-colors to true by changing `CLICOLOR` env variable to `0`.\n    \n*   Added working directory, config files, and env file to service labels.\n    \n*   Added ARM build dependencies.\n    \n*   Added BuildKit support (use `DOCKER_BUILDKIT=1` and `COMPOSE_DOCKER_CLI_BUILD=1`).\n    \n*   Raised Paramiko to version 2.6.0.\n    \n*   Added the following tags: `docker-compose:latest`, `docker-compose:<version>-alpine`, and `docker-compose:<version>-debian`.\n    \n*   Raised `docker-py` to version 4.1.0.\n    \n*   Enhanced support for `requests`, up to version 2.22.0.\n    \n*   Removed empty tag on `build:cache_from`.\n    \n*   `Dockerfile` enhancement that provides for the generation of `libmusl` binaries for Alpine Linux.\n    \n*   Pulling only of images that cannot be built.\n    \n*   The `scale` attribute now accepts `0` as a value.\n    \n*   Added a `--quiet` option and a `--no-rm` option to the `docker-compose build` command.\n    \n*   Added a `--no-interpolate` option to the `docker-compose config` command.\n    \n*   Raised OpenSSL for MacOS build from `1.1.0` to `1.1.1c`.\n    \n*   Added support for the `docker-compose.yml` file's `credential_spec` configuration option.\n    \n*   Resolution of digests without having to pull the image.\n    \n*   Upgraded `pyyaml` to version `4.2b1`.\n    \n*   Lowered the severity to `warning` for instances in which `down` attempts to remove a non-existent image.\n    \n*   Mandated the use of improved API fields for project events, when possible.\n    \n*   Updated `setup.py` for modern `pypi/setuptools`, and removed `pandoc` dependencies.\n    \n*   Removed `Dockerfile.armhf`, which is no longer required.\n    \n\n### [Bug fixes](#bug-fixes-16)\n\n*   Made container service color deterministic, including the removal of the color red.\n    \n*   Fixed non-ASCII character errors (Python 2 only).\n    \n*   Changed image sizing to decimal format, to align with Docker CLI.\n    \n*   `tty` size acquired through Python POSIX support.\n    \n*   Fixed same file `extends` optimization.\n    \n*   Fixed `stdin_open`.\n    \n*   Fixed the issue of `--remove-orphans` being ignored encountered during use with `up --no-start` option.\n    \n*   Fixed `docker-compose ps --all` command.\n    \n*   Fixed the `depends_on` dependency recreation behavior.\n    \n*   Fixed bash completion for the `docker-compose build --memory` command.\n    \n*   Fixed the misleading environmental variables warning that occurs when the `docker-compose exec` command is performed.\n    \n*   Fixed the failure check in the `parallel_execute_watch function`.\n    \n*   Fixed the race condition that occurs following the pulling of an image.\n    \n*   Fixed error on duplicate mount points (a configuration error message now displays).\n    \n*   Fixed the merge on `networks` section.\n    \n*   Compose container is always connected to `stdin` by default.\n    \n*   Fixed the presentation of failed services on the `docker-compose start` command when containers are not available.\n    \n\n(2019-06-24)\n\nThis release contains minor improvements and bug fixes.\n\n(2019-03-28)\n\n### [Features](#features-6)\n\n*   Added support for connecting to the Docker Engine using the `ssh` protocol.\n    \n*   Added an `--all` flag to `docker-compose ps` to include stopped one-off containers in the command's output.\n    \n*   Added bash completion for `ps --all|-a`.\n    \n*   Added support for credential\\_spec.\n    \n*   Added `--parallel` to `docker build`'s options in `bash` and `zsh` completion.\n    \n\n### [Bug fixes](#bug-fixes-17)\n\n*   Fixed a bug where some valid credential helpers weren't properly handled by Compose when attempting to pull images from private registries.\n    \n*   Fixed an issue where the output of `docker-compose start` before containers were created was misleading.\n    \n*   Compose will no longer accept whitespace in variable names sourced from environment files. This matches the Docker CLI behavior.\n    \n*   Compose will now report a configuration error if a service attempts to declare duplicate mount points in the volumes section.\n    \n*   Fixed an issue with the containerized version of Compose that prevented users from writing to stdin during interactive sessions started by `run` or `exec`.\n    \n*   One-off containers started by `run` no longer adopt the restart policy of the service, and are instead set to never restart.\n    \n*   Fixed an issue that caused some container events to not appear in the output of the `docker-compose events` command.\n    \n*   Missing images will no longer stop the execution of `docker-compose down` commands. A warning is now displayed instead.\n    \n*   Force `virtualenv` version for macOS CI.\n    \n*   Fixed merging of Compose files when network has `None` config.\n    \n*   Fixed `CTRL+C` issues by enabling `bootloader_ignore_signals` in `pyinstaller`.\n    \n*   Bumped `docker-py` version to `3.7.2` to fix SSH and proxy configuration issues.\n    \n*   Fixed release script and some typos on release documentation.\n    \n\n(2018-11-28)\n\n### [Bug fixes](#bug-fixes-18)\n\n*   Reverted a 1.23.0 change that appended random strings to container names created by `docker-compose up`, causing addressability issues.\n    \n    > **Note**: Containers created by `docker-compose run` will continue to use randomly generated names to avoid collisions during parallel runs.\n    \n*   Fixed an issue where some `dockerfile` paths would fail unexpectedly when attempting to build on Windows.\n    \n*   Fixed a bug where build context URLs would fail to build on Windows.\n    \n*   Fixed a bug that caused `run` and `exec` commands to fail for some otherwise accepted values of the `--host` parameter.\n    \n*   Fixed an issue where overrides for the `storage_opt` and `isolation` keys in service definitions weren't properly applied.\n    \n*   Fixed a bug where some invalid Compose files would raise an uncaught exception during validation.\n    \n\n(2018-11-01)\n\n### [Bug fixes](#bug-fixes-19)\n\n*   Fixed a bug where working with containers created with a version of Compose earlier than `1.23.0` would cause unexpected crashes.\n    \n*   Fixed an issue where the behavior of the `--project-directory` flag would vary depending on which subcommand was used.\n    \n\n(2018-10-30)\n\n### [Important note](#important-note)\n\nThe default naming scheme for containers created by Compose in this version has changed from `<project>_<service>_<index>` to `<project>_<service>_<index>_<slug>`, where `<slug>` is a randomly-generated hexadecimal string. Please make sure to update scripts relying on the old naming scheme accordingly before upgrading.\n\n### [Features](#features-7)\n\n*   Logs for containers restarting after a crash will now appear in the output of the `up` and `logs` commands.\n    \n*   Added `--hash` option to the `docker-compose config` command, allowing users to print a hash string for each service's configuration to facilitate rolling updates.\n    \n*   Added `--parallel` flag to the `docker-compose build` command, allowing Compose to build up to 5 images simultaneously.\n    \n*   Output for the `pull` command now reports status / progress even when pulling multiple images in parallel.\n    \n*   For images with multiple names, Compose will now attempt to match the one present in the service configuration in the output of the `images` command.\n    \n\n### [Bug fixes](#bug-fixes-20)\n\n*   Fixed an issue where parallel `run` commands for the same service would fail due to name collisions.\n    \n*   Fixed an issue where paths longer than 260 characters on Windows clients would cause `docker-compose build` to fail.\n    \n*   Fixed a bug where attempting to mount `/var/run/docker.sock` with Docker Desktop for Windows would result in failure.\n    \n*   The `--project-directory` option is now used by Compose to determine where to look for the `.env` file.\n    \n*   `docker-compose build` no longer fails when attempting to pull an image with credentials provided by the _**gcloud credential helper**_.\n    \n*   Fixed the `--exit-code-from` option in `docker-compose up` to always report the actual exit code even when the watched container is not the cause of the exit.\n    \n*   Fixed an issue that would prevent recreating a service in some cases where a volume would be mapped to the same mountpoint as a volume declared within the Dockerfile for that image.\n    \n*   Fixed a bug that caused hash configuration with multiple networks to be inconsistent, causing some services to be unnecessarily restarted.\n    \n*   Fixed a bug that would cause failures with variable substitution for services with a name containing one or more dot characters.\n    \n*   Fixed a pipe handling issue when using the containerized version of Compose.\n    \n*   Fixed a bug causing `external: false` entries in the Compose file to be printed as `external: true` in the output of `docker-compose config`.\n    \n*   Fixed a bug where issuing a `docker-compose pull` command on services without a defined image key would cause Compose to crash.\n    \n*   Volumes and binds are now mounted in the order they are declared in the service definition.\n    \n\n### [Miscellaneous](#miscellaneous-8)\n\n*   The `zsh` completion script has been updated with new options, and no longer suggests container names where service names are expected.\n\n(2018-07-17)\n\n### [New features](#new-features-2)\n\n#### [Compose format version 3.7](#compose-format-version-37)\n\n*   Introduced version 3.7 of the `docker-compose.yml` specification. This version requires Docker Engine 18.06.0 or above.\n    \n*   Added support for `rollback_config` in the deploy configuration\n    \n*   Added support for the `init` parameter in service configurations\n    \n*   Added support for extension fields in service, network, volume, secret, and config configurations\n    \n\n#### [Compose format version 2.4](#compose-format-version-24)\n\n*   Added support for extension fields in service, network, and volume configurations\n\n### [Bug fixes](#bug-fixes-21)\n\n*   Fixed a bug that prevented deployment with some Compose files when `DOCKER_DEFAULT_PLATFORM` was set\n    \n*   Compose will no longer try to create containers or volumes with invalid starting characters\n    \n*   Fixed several bugs that prevented Compose commands from working properly with containers created with an older version of Compose\n    \n*   Fixed an issue with the output of `docker-compose config` with the `--compatibility-mode` flag enabled when the source file contains attachable networks\n    \n*   Fixed a bug that prevented the `gcloud` credential store from working properly when used with the Compose binary on UNIX\n    \n*   Fixed a bug that caused connection errors when trying to operate over a non-HTTPS TCP connection on Windows\n    \n*   Fixed a bug that caused builds to fail on Windows if the Dockerfile was located in a subdirectory of the build context\n    \n*   Fixed an issue that prevented proper parsing of UTF-8 BOM encoded Compose files on Windows\n    \n*   Fixed an issue with handling of the double-wildcard (`**`) pattern in `.dockerignore` files when using `docker-compose build`\n    \n*   Fixed a bug that caused auth values in legacy `.dockercfg` files to be ignored\n    \n*   `docker-compose build` will no longer attempt to create image names starting with an invalid character\n    \n\n(2018-05-03)\n\n### [Bug fixes](#bug-fixes-22)\n\n*   Fixed a bug where the ip\\_range attribute in IPAM configs was prevented from passing validation\n\n(2018-04-27)\n\n### [Bug fixes](#bug-fixes-23)\n\n*   In 1.21.0, we introduced a change to how project names are sanitized for internal use in resource names. This caused issues when manipulating an existing, deployed application whose name had changed as a result. This release properly detects resources using \"legacy\" naming conventions.\n    \n*   Fixed an issue where specifying an in-context Dockerfile using an absolute path would fail despite being valid.\n    \n*   Fixed a bug where IPAM option changes were incorrectly detected, preventing redeployments.\n    \n*   Validation of v2 files now properly checks the structure of IPAM configs.\n    \n*   Improved support for credentials stores on Windows to include binaries using extensions other than `.exe`. The list of valid extensions is determined by the contents of the `PATHEXT` environment variable.\n    \n*   Fixed a bug where Compose would generate invalid binds containing duplicate elements with some v3.2 files, triggering errors at the Engine level during deployment.\n    \n\n(2018-04-11)\n\n### [New features](#new-features-3)\n\n#### [Compose file version 2.4](#compose-file-version-24)\n\n*   Introduced version 2.4 of the `docker-compose.yml` specification. This version requires Docker Engine 17.12.0 or above.\n    \n*   Added support for the `platform` parameter in service definitions. If supplied, the parameter is also used when performing build for the service.\n    \n\n#### [Compose file version 2.2 and up](#compose-file-version-22-and-up)\n\n*   Added support for the `cpu_rt_period` and `cpu_rt_runtime` parameters in service definitions (2.x only).\n\n#### [Compose file version 2.1 and up](#compose-file-version-21-and-up)\n\n*   Added support for the `cpu_period` parameter in service definitions (2.x only).\n    \n*   Added support for the `isolation` parameter in service build configurations. Additionally, the `isolation` parameter in service definitions is used for builds as well if no `build.isolation` parameter is defined. (2.x only)\n    \n\n#### [All formats](#all-formats)\n\n*   Added support for the `--workdir` flag in `docker-compose exec`.\n    \n*   Added support for the `--compress` flag in `docker-compose build`.\n    \n*   `docker-compose pull` is now performed in parallel by default. You can opt out using the `--no-parallel` flag. The `--parallel` flag is now deprecated and will be removed in a future version.\n    \n*   Dashes and underscores in project names are no longer stripped out.\n    \n*   `docker-compose build` now supports the use of Dockerfile from outside the build context.\n    \n\n### [Bug fixes](#bug-fixes-24)\n\n*   Compose now checks that the volume's configuration matches the remote volume, and errors out if a mismatch is detected.\n    \n*   Fixed a bug that caused Compose to raise unexpected errors when attempting to create several one-off containers in parallel.\n    \n*   Fixed a bug with argument parsing when using `docker-machine config` to generate TLS flags for `exec` and `run` commands.\n    \n*   Fixed a bug where variable substitution with an empty default value (e.g. `${VAR:-}`) would print an incorrect warning.\n    \n*   Improved resilience when encoding of the Compose file doesn't match the system's. Users are encouraged to use UTF-8 when possible.\n    \n*   Fixed a bug where external overlay networks in Swarm would be incorrectly recognized as inexistent by Compose, interrupting otherwise valid operations.\n    \n\n(2018-03-20)\n\n### [New features](#new-features-4)\n\n#### [Compose file version 3.6](#compose-file-version-36)\n\n*   Introduced version 3.6 of the `docker-compose.yml` specification. This version must be used with Docker Engine 18.02.0 or above.\n    \n*   Added support for the `tmpfs.size` property in volume mappings\n    \n\n#### [Compose file version 3.2 and up](#compose-file-version-32-and-up)\n\n*   The `--build-arg` option can now be used without specifying a service in `docker-compose build`\n\n#### [Compose file version 2.3](#compose-file-version-23)\n\n*   Added support for `device_cgroup_rules` in service definitions\n    \n*   Added support for the `tmpfs.size` property in long-form volume mappings\n    \n*   The `--build-arg` option can now be used without specifying a service in `docker-compose build`\n    \n\n#### [All formats](#all-formats-1)\n\n*   Added a `--log-level` option to the top-level `docker-compose` command. Accepted values are `debug`, `info`, `warning`, `error`, `critical`. Default log level is `info`\n    \n*   `docker-compose run` now allows users to unset the container's entrypoint\n    \n*   Proxy configuration found in the `~/.docker/config.json` file now populates environment and build args for containers created by Compose\n    \n*   Added the `--use-aliases` flag to `docker-compose run`, indicating that network aliases declared in the service's config should be used for the running container\n    \n*   Added the `--include-deps` flag to `docker-compose pull`\n    \n*   `docker-compose run` now kills and removes the running container upon receiving `SIGHUP`\n    \n*   `docker-compose ps` now shows the containers' health status if available\n    \n*   Added the long-form `--detach` option to the `exec`, `run` and `up` commands\n    \n\n### [Bug fixes](#bug-fixes-25)\n\n*   Fixed `.dockerignore` handling, notably with regard to absolute paths and last-line precedence rules\n    \n*   Fixed an issue where Compose would make costly DNS lookups when connecting to the Engine when using Docker For Mac\n    \n*   Fixed a bug introduced in 1.19.0 which caused the default certificate path to not be honored by Compose\n    \n*   Fixed a bug where Compose would incorrectly check whether a symlink's destination was accessible when part of a build context\n    \n*   Fixed a bug where `.dockerignore` files containing lines of whitespace caused Compose to error out on Windows\n    \n*   Fixed a bug where `--tls*` and `--host` options wouldn't be properly honored for interactive `run` and `exec` commands\n    \n*   A `seccomp:<filepath>` entry in the `security_opt` config now correctly sends the contents of the file to the engine\n    \n*   ANSI output for `up` and `down` operations should no longer affect the wrong lines\n    \n*   Improved support for non-unicode locales\n    \n*   Fixed a crash occurring on Windows when the user's home directory name contained non-ASCII characters\n    \n*   Fixed a bug occurring during builds caused by files with a negative `mtime` values in the build context\n    \n*   Fixed an encoding bug when streaming build progress\n    \n\n(2018-02-07)\n\n### [Breaking changes](#breaking-changes)\n\n*   On UNIX platforms, interactive `run` and `exec` commands now require the `docker` CLI to be installed on the client by default. To revert to the previous behavior, users may set the `COMPOSE_INTERACTIVE_NO_CLI` environment variable.\n\n### [New features](#new-features-5)\n\n#### [Compose file version 3.x](#compose-file-version-3x)\n\n*   The output of the `config` command should now merge `deploy` options from several Compose files in a more accurate manner\n\n#### [Compose file version 2.3](#compose-file-version-23-1)\n\n*   Added support for the `runtime` option in service definitions\n\n#### [Compose file version 2.1 and up](#compose-file-version-21-and-up-1)\n\n*   Added support for the `${VAR:?err}` and `${VAR?err}` variable interpolation syntax to indicate mandatory variables\n\n#### [Compose file version 2.x](#compose-file-version-2x)\n\n*   Added `priority` key to service network mappings, allowing the user to define in which order the specified service will connect to each network\n\n#### [All formats](#all-formats-2)\n\n*   Added `--renew-anon-volumes` (shorthand `-V`) to the `up` command, preventing Compose from recovering volume data from previous containers for anonymous volumes\n    \n*   Added limit for number of simultaneous parallel operations, which should prevent accidental resource exhaustion of the server. Default is 64 and can be configured using the `COMPOSE_PARALLEL_LIMIT` environment variable\n    \n*   Added `--always-recreate-deps` flag to the `up` command to force recreating dependent services along with the dependency owner\n    \n*   Added `COMPOSE_IGNORE_ORPHANS` environment variable to forgo orphan container detection and suppress warnings\n    \n*   Added `COMPOSE_FORCE_WINDOWS_HOST` environment variable to force Compose to parse volume definitions as if the Docker host was a Windows system, even if Compose itself is currently running on UNIX\n    \n*   Bash completion should now be able to better differentiate between running, stopped and paused services\n    \n\n### [Bug fixes](#bug-fixes-26)\n\n*   Fixed a bug that would cause the `build` command to report a connection error when the build context contained unreadable files or FIFO objects. These file types will now be handled appropriately\n    \n*   Fixed various issues around interactive `run`/`exec` sessions.\n    \n*   Fixed a bug where setting TLS options with environment and CLI flags simultaneously would result in part of the configuration being ignored\n    \n*   Fixed a bug where the DOCKER\\_TLS\\_VERIFY environment variable was being ignored by Compose\n    \n*   Fixed a bug where the `-d` and `--timeout` flags in `up` were erroneously marked as incompatible\n    \n*   Fixed a bug where the recreation of a service would break if the image associated with the previous container had been removed\n    \n*   Fixed a bug where updating a mount's target would break Compose when trying to recreate the associated service\n    \n*   Fixed a bug where `tmpfs` volumes declared using the extended syntax in Compose files using version 3.2 would be erroneously created as anonymous volumes instead\n    \n*   Fixed a bug where type conversion errors would print a stacktrace instead of exiting gracefully\n    \n*   Fixed some errors related to unicode handling\n    \n*   Dependent services no longer get recreated along with the dependency owner if their configuration hasn't changed\n    \n*   Added better validation of `labels` fields in Compose files. Label values containing scalar types (number, boolean) now get automatically converted to strings\n    \n\n(2017-12-18)\n\n### [New features](#new-features-6)\n\n#### [Compose file version 3.5](#compose-file-version-35)\n\n*   Introduced version 3.5 of the `docker-compose.yml` specification. This version requires Docker Engine 17.06.0 or above\n    \n*   Added support for the `shm_size` parameter in build configurations\n    \n*   Added support for the `isolation` parameter in service definitions\n    \n*   Added support for custom names for network, secret and config definitions\n    \n\n#### [Compose file version 2.3](#compose-file-version-23-2)\n\n*   Added support for `extra_hosts` in build configuration\n    \n*   Added support for the [long syntax](https://docs.docker.com/compose/compose-file/legacy-versions/) for volume entries, as previously introduced in the 3.2 format. Using this syntax will create [mounts](https://docs.docker.com/storage/bind-mounts/) instead of volumes.\n    \n\n#### [Compose file version 2.1 and up](#compose-file-version-21-and-up-2)\n\n*   Added support for the `oom_kill_disable` parameter in service definitions (2.x only)\n    \n*   Added support for custom names for network definitions (2.x only)\n    \n\n#### [All formats](#all-formats-3)\n\n*   Values interpolated from the environment will now be converted to the proper type when used in non-string fields.\n    \n*   Added support for `--label` in `docker-compose run`\n    \n*   Added support for `--timeout` in `docker-compose down`\n    \n*   Added support for `--memory` in `docker-compose build`\n    \n*   Setting `stop_grace_period` in service definitions now also sets the container's `stop_timeout`\n    \n\n### [Bug fixes](#bug-fixes-27)\n\n*   Fixed an issue where Compose was still handling service hostname according to legacy engine behavior, causing hostnames containing dots to be cut up\n    \n*   Fixed a bug where the `X-Y:Z` syntax for ports was considered invalid by Compose\n    \n*   Fixed an issue with CLI logging causing duplicate messages and inelegant output to occur\n    \n*   Fixed an issue that caused `stop_grace_period` to be ignored when using multiple Compose files\n    \n*   Fixed a bug that caused `docker-compose images` to crash when using untagged images\n    \n*   Fixed a bug where the valid `${VAR:-}` syntax would cause Compose to error out\n    \n*   Fixed a bug where `env_file` entries using an UTF-8 BOM were being read incorrectly\n    \n*   Fixed a bug where missing secret files would generate an empty directory in their place\n    \n*   Fixed character encoding issues in the CLI's error handlers\n    \n*   Added validation for the `test` field in healthchecks\n    \n*   Added validation for the `subnet` field in IPAM configurations\n    \n*   Added validation for `volumes` properties when using the long syntax in service definitions\n    \n*   The CLI now explicit prevents using `-d` and `--timeout` together in `docker-compose up`\n    \n\n(2017-11-01)\n\n### [New features](#new-features-7)\n\n#### [Compose file version 3.4](#compose-file-version-34)\n\n*   Introduced version 3.4 of the `docker-compose.yml` specification. This version requires to be used with Docker Engine 17.06.0 or above.\n    \n*   Added support for `cache_from`, `network` and `target` options in build configurations\n    \n*   Added support for the `order` parameter in the `update_config` section\n    \n*   Added support for setting a custom name in volume definitions using the `name` parameter\n    \n\n#### [Compose file version 2.3](#compose-file-version-23-3)\n\n*   Added support for `shm_size` option in build configuration\n\n#### [Compose file version 2.x](#compose-file-version-2x-1)\n\n*   Added support for extension fields (`x-*`). Also available for v3.4 files\n\n#### [All formats](#all-formats-4)\n\n*   Added new `--no-start` to the `up` command, allowing users to create all resources (networks, volumes, containers) without starting services. The `create` command is deprecated in favor of this new option\n\n### [Bug fixes](#bug-fixes-28)\n\n*   Fixed a bug where `extra_hosts` values would be overridden by extension files instead of merging together\n    \n*   Fixed a bug where the validation for v3.2 files would prevent using the `consistency` field in service volume definitions\n    \n*   Fixed a bug that would cause a crash when configuration fields expecting unique items would contain duplicates\n    \n*   Fixed a bug where mount overrides with a different mode would create a duplicate entry instead of overriding the original entry\n    \n*   Fixed a bug where build labels declared as a list wouldn't be properly parsed\n    \n*   Fixed a bug where the output of `docker-compose config` would be invalid for some versions if the file contained custom-named external volumes\n    \n*   Improved error handling when issuing a build command on Windows using an unsupported file version\n    \n*   Fixed an issue where networks with identical names would sometimes be created when running `up` commands concurrently.\n    \n\n(2017-08-31)\n\n### [New features](#new-features-8)\n\n#### [Compose file version 2.3](#compose-file-version-23-4)\n\n*   Introduced version 2.3 of the `docker-compose.yml` specification. This version requires to be used with Docker Engine 17.06.0 or above.\n    \n*   Added support for the `target` parameter in build configurations\n    \n*   Added support for the `start_period` parameter in healthcheck configurations\n    \n\n#### [Compose file version 2.x](#compose-file-version-2x-2)\n\n*   Added support for the `blkio_config` parameter in service definitions\n    \n*   Added support for setting a custom name in volume definitions using the `name` parameter (not available for version 2.0)\n    \n\n#### [All formats](#all-formats-5)\n\n*   Added new CLI flag `--no-ansi` to suppress ANSI control characters in output\n\n### [Bug fixes](#bug-fixes-29)\n\n*   Fixed a bug where nested `extends` instructions weren't resolved properly, causing \"file not found\" errors\n    \n*   Fixed several issues with `.dockerignore` parsing\n    \n*   Fixed issues where logs of TTY-enabled services were being printed incorrectly and causing `MemoryError` exceptions\n    \n*   Fixed a bug where printing application logs would sometimes be interrupted by a `UnicodeEncodeError` exception on Python 3\n    \n*   The `$` character in the output of `docker-compose config` is now properly escaped\n    \n*   Fixed a bug where running `docker-compose top` would sometimes fail with an uncaught exception\n    \n*   Fixed a bug where `docker-compose pull` with the `--parallel` flag would return a `0` exit code when failing\n    \n*   Fixed an issue where keys in `deploy.resources` were not being validated\n    \n*   Fixed an issue where the `logging` options in the output of `docker-compose config` would be set to `null`, an invalid value\n    \n*   Fixed the output of the `docker-compose images` command when an image would come from a private repository using an explicit port number\n    \n*   Fixed the output of `docker-compose config` when a port definition used `0` as the value for the published port\n    \n\n(2017-07-26)\n\n### [New features](#new-features-9)\n\n#### [Compose file version 2.2](#compose-file-version-22)\n\n*   Added support for the `network` parameter in build configurations.\n\n#### [Compose file version 2.1 and up](#compose-file-version-21-and-up-3)\n\n*   The `pid` option in a service's definition now supports a `service:<name>` value.\n    \n*   Added support for the `storage_opt` parameter in service definitions. This option is not available for the v3 format\n    \n\n#### [All formats](#all-formats-6)\n\n*   Added `--quiet` flag to `docker-compose pull`, suppressing progress output\n    \n*   Some improvements to CLI output\n    \n\n### [Bug fixes](#bug-fixes-30)\n\n*   Volumes specified through the `--volume` flag of `docker-compose run` now complement volumes declared in the service's definition instead of replacing them\n    \n*   Fixed a bug where using multiple Compose files would unset the scale value defined inside the Compose file.\n    \n*   Fixed an issue where the `credHelpers` entries in the `config.json` file were not being honored by Compose\n    \n*   Fixed a bug where using multiple Compose files with port declarations would cause failures in Python 3 environments\n    \n*   Fixed a bug where some proxy-related options present in the user's environment would prevent Compose from running\n    \n*   Fixed an issue where the output of `docker-compose config` would be invalid if the original file used `Y` or `N` values\n    \n*   Fixed an issue preventing `up` operations on a previously created stack on Windows Engine.\n    \n\n(2017-06-19)\n\n### [New features](#new-features-10)\n\n#### [Compose file version 3.3](#compose-file-version-33)\n\n*   Introduced version 3.3 of the `docker-compose.yml` specification. This version requires to be used with Docker Engine 17.06.0 or above. Note: the `credential_spec` and `configs` keys only apply to Swarm services and will be ignored by Compose\n\n#### [Compose file version 2.2](#compose-file-version-22-1)\n\n*   Added the following parameters in service definitions: `cpu_count`, `cpu_percent`, `cpus`\n\n#### [Compose file version 2.1](#compose-file-version-21)\n\n*   Added support for build labels. This feature is also available in the 2.2 and 3.3 formats.\n\n#### [All formats](#all-formats-7)\n\n*   Added shorthand `-u` for `--user` flag in `docker-compose exec`\n    \n*   Differences in labels between the Compose file and remote network will now print a warning instead of preventing redeployment.\n    \n\n### [Bug fixes](#bug-fixes-31)\n\n*   Fixed a bug where service's dependencies were being rescaled to their default scale when running a `docker-compose run` command\n    \n*   Fixed a bug where `docker-compose rm` with the `--stop` flag was not behaving properly when provided with a list of services to remove\n    \n*   Fixed a bug where `cache_from` in the build section would be ignored when using more than one Compose file.\n    \n*   Fixed a bug that prevented binding the same port to different IPs when using more than one Compose file.\n    \n*   Fixed a bug where override files would not be picked up by Compose if they had the `.yaml` extension\n    \n*   Fixed a bug on Windows Engine where networks would be incorrectly flagged for recreation\n    \n*   Fixed a bug where services declaring ports would cause crashes on some versions of Python 3\n    \n*   Fixed a bug where the output of `docker-compose config` would sometimes contain invalid port definitions\n    \n\n(2017-05-02)\n\n### [Breaking changes](#breaking-changes-1)\n\n*   `docker-compose up` now resets a service's scaling to its default value. You can use the newly introduced `--scale` option to specify a custom scale value\n\n### [New features](#new-features-11)\n\n#### [Compose file version 2.2](#compose-file-version-22-2)\n\n*   Introduced version 2.2 of the `docker-compose.yml` specification. This version requires to be used with Docker Engine 1.13.0 or above\n    \n*   Added support for `init` in service definitions.\n    \n*   Added support for `scale` in service definitions. The configuration's value can be overridden using the `--scale` flag in `docker-compose up`. The `scale` command is disabled for this file format\n    \n\n#### [Compose file version 2.x](#compose-file-version-2x-3)\n\n*   Added support for `options` in the `ipam` section of network definitions\n\n### [Bug fixes](#bug-fixes-32)\n\n*   Fixed a bug where paths provided to compose via the `-f` option were not being resolved properly\n    \n*   Fixed a bug where the `ext_ip::target_port` notation in the ports section was incorrectly marked as invalid\n    \n*   Fixed an issue where the `exec` command would sometimes not return control to the terminal when using the `-d` flag\n    \n*   Fixed a bug where secrets were missing from the output of the `config` command for v3.2 files\n    \n*   Fixed an issue where `docker-compose` would hang if no internet connection was available\n    \n*   Fixed an issue where paths containing unicode characters passed via the `-f` flag were causing Compose to crash\n    \n*   Fixed an issue where the output of `docker-compose config` would be invalid if the Compose file contained external secrets\n    \n*   Fixed a bug where using `--exit-code-from` with `up` would fail if Compose was installed in a Python 3 environment\n    \n*   Fixed a bug where recreating containers using a combination of `tmpfs` and `volumes` would result in an invalid config state\n    \n\n(2017-04-04)\n\n### [New features](#new-features-12)\n\n#### [Compose file version 3.2](#compose-file-version-32)\n\n*   Introduced version 3.2 of the `docker-compose.yml` specification\n    \n*   Added support for `cache_from` in the `build` section of services\n    \n*   Added support for the new expanded ports syntax in service definitions\n    \n*   Added support for the new expanded volumes syntax in service definitions\n    \n\n#### [Compose file version 2.1](#compose-file-version-21-1)\n\n*   Added support for `pids_limit` in service definitions\n\n#### [Compose file version 2.0 and up](#compose-file-version-20-and-up)\n\n*   Added `--volumes` option to `docker-compose config` that lists named volumes declared for that project\n    \n*   Added support for `mem_reservation` in service definitions (2.x only)\n    \n*   Added support for `dns_opt` in service definitions (2.x only)\n    \n\n#### [All formats](#all-formats-8)\n\n*   Added a new `docker-compose images` command that lists images used by the current project's containers\n    \n*   Added a `--stop` (shorthand `-s`) option to `docker-compose rm` that stops the running containers before removing them\n    \n*   Added a `--resolve-image-digests` option to `docker-compose config` that pins the image version for each service to a permanent digest\n    \n*   Added a `--exit-code-from SERVICE` option to `docker-compose up`. When used, `docker-compose` will exit on any container's exit with the code corresponding to the specified service's exit code\n    \n*   Added a `--parallel` option to `docker-compose pull` that enables images for multiple services to be pulled simultaneously\n    \n*   Added a `--build-arg` option to `docker-compose build`\n    \n*   Added a `--volume <volume_mapping>` (shorthand `-v`) option to `docker-compose run` to declare runtime volumes to be mounted\n    \n*   Added a `--project-directory PATH` option to `docker-compose` that will affect path resolution for the project\n    \n*   When using `--abort-on-container-exit` in `docker-compose up`, the exit code for the container that caused the abort will be the exit code of the `docker-compose up` command\n    \n*   Users can now configure which path separator character they want to use to separate the `COMPOSE_FILE` environment value using the `COMPOSE_PATH_SEPARATOR` environment variable\n    \n*   Added support for port range to a single port in port mappings, such as `8000-8010:80`.\n    \n\n### [Bug fixes](#bug-fixes-33)\n\n*   `docker-compose run --rm` now removes anonymous volumes after execution, matching the behavior of `docker run --rm`.\n    \n*   Fixed a bug where override files containing port lists would cause a TypeError to be raised\n    \n*   Fixed a bug where the `deploy` key would be missing from the output of `docker-compose config`\n    \n*   Fixed a bug where scaling services up or down would sometimes re-use obsolete containers\n    \n*   Fixed a bug where the output of `docker-compose config` would be invalid if the project declared anonymous volumes\n    \n*   Variable interpolation now properly occurs in the `secrets` section of the Compose file\n    \n*   The `secrets` section now properly appears in the output of `docker-compose config`\n    \n*   Fixed a bug where changes to some networks properties would not be detected against previously created networks\n    \n*   Fixed a bug where `docker-compose` would crash when trying to write into a closed pipe\n    \n*   Fixed an issue where Compose would not pick up on the value of COMPOSE\\_TLS\\_VERSION when used in combination with command-line TLS flags\n    \n\n(2017-02-17)\n\n### [Bug fixes](#bug-fixes-34)\n\n*   Fixed a bug that was preventing secrets configuration from being loaded properly\n    \n*   Fixed a bug where the `docker-compose config` command would fail if the config file contained secrets definitions\n    \n*   Fixed an issue where Compose on some linux distributions would pick up and load an outdated version of the requests library\n    \n*   Fixed an issue where socket-type files inside a build folder would cause `docker-compose` to crash when trying to build that service\n    \n*   Fixed an issue where recursive wildcard patterns `**` were not being recognized in `.dockerignore` files.\n    \n\n(2017-02-09)\n\n### [Bug fixes](#bug-fixes-35)\n\n*   Fixed a bug where the 3.1 file format was not being recognized as valid by the Compose parser\n\n(2017-02-08)\n\n### [New Features](#new-features-13)\n\n#### [Compose file version 3.1](#compose-file-version-31)\n\n*   Introduced version 3.1 of the `docker-compose.yml` specification. This version requires Docker Engine 1.13.0 or above. It introduces support for secrets. See the documentation for more information\n\n#### [Compose file version 2.0 and up](#compose-file-version-20-and-up-1)\n\n*   Introduced the `docker-compose top` command that displays processes running for the different services managed by Compose.\n\n### [Bug fixes](#bug-fixes-36)\n\n*   Fixed a bug where extending a service defining a healthcheck dictionary would cause `docker-compose` to error out.\n    \n*   Fixed an issue where the `pid` entry in a service definition was being ignored when using multiple Compose files.\n    \n\n(2017-02-01)\n\n### [Bug fixes](#bug-fixes-37)\n\n*   Fixed an issue where the presence of older versions of the docker-py package would cause unexpected crashes while running Compose\n    \n*   Fixed an issue where healthcheck dependencies would be lost when using multiple compose files for a project\n    \n*   Fixed a few issues that made the output of the `config` command invalid\n    \n*   Fixed an issue where adding volume labels to v3 Compose files would result in an error\n    \n*   Fixed an issue on Windows where build context paths containing unicode characters were being improperly encoded\n    \n*   Fixed a bug where Compose would occasionally crash while streaming logs when containers would stop or restart\n    \n\n(2017-01-18)\n\n### [New Features](#new-features-14)\n\n#### [Compose file version 3.0](#compose-file-version-30)\n\n*   Introduced version 3.0 of the `docker-compose.yml` specification. This version requires to be used with Docker Engine 1.13 or above and is specifically designed to work with the `docker stack` commands.\n\n#### [Compose file version 2.1 and up](#compose-file-version-21-and-up-4)\n\n*   Healthcheck configuration can now be done in the service definition using the `healthcheck` parameter\n    \n*   Containers dependencies can now be set up to wait on positive healthchecks when declared using `depends_on`. See the documentation for the updated syntax. **Note**: This feature will not be ported to version 3 Compose files.\n    \n*   Added support for the `sysctls` parameter in service definitions\n    \n*   Added support for the `userns_mode` parameter in service definitions\n    \n*   Compose now adds identifying labels to networks and volumes it creates\n    \n\n#### [Compose file version 2.0 and up](#compose-file-version-20-and-up-2)\n\n*   Added support for the `stop_grace_period` option in service definitions.\n\n### [Bug fixes](#bug-fixes-38)\n\n*   Colored output now works properly on Windows.\n    \n*   Fixed a bug where docker-compose run would fail to set up link aliases in interactive mode on Windows.\n    \n*   Networks created by Compose are now always made attachable (Compose files v2.1 and up).\n    \n*   Fixed a bug where falsy values of `COMPOSE_CONVERT_WINDOWS_PATHS` (`0`, `false`, empty value) were being interpreted as true.\n    \n*   Fixed a bug where forward slashes in some .dockerignore patterns weren't being parsed correctly on Windows\n    \n\n(2016-11-16)\n\n**Breaking changes**\n\n*   When using Compose with Docker Toolbox/Machine on Windows, volume paths are no longer converted from `C:\\Users` to `/c/Users`\\-style by default. To re-enable this conversion so that your volumes keep working, set the environment variable `COMPOSE_CONVERT_WINDOWS_PATHS=1`. Users of Docker for Windows are not affected and do not need to set the variable.\n\n### [New Features](#new-features-15)\n\n*   Interactive mode for `docker-compose run` and `docker-compose exec` is now supported on Windows platforms. The `docker` binary is required to be present on the system for this feature to work.\n    \n*   Introduced version 2.1 of the `docker-compose.yml` specification. This version requires to be used with Docker Engine 1.12 or above.\n    \n    *   Added support for setting volume labels and network labels in `docker-compose.yml`.\n    *   Added support for the `isolation` parameter in service definitions.\n    *   Added support for link-local IPs in the service networks definitions.\n    *   Added support for shell-style inline defaults in variable interpolation. The supported forms are `${FOO-default}` (fall back if FOO is unset) and `${FOO:-default}` (fall back if FOO is unset or empty).\n*   Added support for the `group_add` and `oom_score_adj` parameters in service definitions.\n    \n*   Added support for the `internal` and `enable_ipv6` parameters in network definitions.\n    \n*   Compose now defaults to using the `npipe` protocol on Windows.\n    \n*   Overriding a `logging` configuration will now properly merge the `options` mappings if the `driver` values do not conflict.\n    \n\n### [Bug fixes](#bug-fixes-39)\n\n*   Fixed several bugs related to `npipe` protocol support on Windows.\n    \n*   Fixed an issue with Windows paths being incorrectly converted when using Docker on Windows Server.\n    \n*   Fixed a bug where an empty `restart` value would sometimes result in an exception being raised.\n    \n*   Fixed an issue where service logs containing unicode characters would sometimes cause an error to occur.\n    \n*   Fixed a bug where unicode values in environment variables would sometimes raise a unicode exception when retrieved.\n    \n*   Fixed an issue where Compose would incorrectly detect a configuration mismatch for overlay networks.\n    \n\n(2016-09-22)\n\n### [Bug fixes](#bug-fixes-40)\n\n*   Fixed a bug where users using a credentials store were not able to access their private images.\n    \n*   Fixed a bug where users using identity tokens to authenticate were not able to access their private images.\n    \n*   Fixed a bug where an `HttpHeaders` entry in the docker configuration file would cause Compose to crash when trying to build an image.\n    \n*   Fixed a few bugs related to the handling of Windows paths in volume binding declarations.\n    \n*   Fixed a bug where Compose would sometimes crash while trying to read a streaming response from the engine.\n    \n*   Fixed an issue where Compose would crash when encountering an API error while streaming container logs.\n    \n*   Fixed an issue where Compose would erroneously try to output logs from drivers not handled by the Engine's API.\n    \n*   Fixed a bug where options from the `docker-machine config` command would not be properly interpreted by Compose.\n    \n*   Fixed a bug where the connection to the Docker Engine would sometimes fail when running a large number of services simultaneously.\n    \n*   Fixed an issue where Compose would sometimes print a misleading suggestion message when running the `bundle` command.\n    \n*   Fixed a bug where connection errors would not be handled properly by Compose during the project initialization phase.\n    \n*   Fixed a bug where a misleading error would appear when encountering a connection timeout.\n    \n\n(2016-06-14)\n\n### [Breaking Changes](#breaking-changes-2)\n\n*   As announced in 1.7.0, `docker-compose rm` now removes containers created by `docker-compose run` by default.\n    \n*   Setting `entrypoint` on a service now empties out any default command that was set on the image (i.e. any `CMD` instruction in the Dockerfile used to build it). This makes it consistent with the `--entrypoint` flag to `docker run`.\n    \n\n### [New Features](#new-features-16)\n\n*   Added `docker-compose bundle`, a command that builds a bundle file to be consumed by the new _Docker Stack_ commands in Docker 1.12.\n    \n*   Added `docker-compose push`, a command that pushes service images to a registry.\n    \n*   Compose now supports specifying a custom TLS version for interaction with the Docker Engine using the `COMPOSE_TLS_VERSION` environment variable.\n    \n\n### [Bug fixes](#bug-fixes-41)\n\n*   Fixed a bug where Compose would erroneously try to read `.env` at the project's root when it is a directory.\n    \n*   `docker-compose run -e VAR` now passes `VAR` through from the shell to the container, as with `docker run -e VAR`.\n    \n*   Improved config merging when multiple compose files are involved for several service sub-keys.\n    \n*   Fixed a bug where volume mappings containing Windows drives would sometimes be parsed incorrectly.\n    \n*   Fixed a bug in Windows environment where volume mappings of the host's root directory would be parsed incorrectly.\n    \n*   Fixed a bug where `docker-compose config` would output an invalid Compose file if external networks were specified.\n    \n*   Fixed an issue where unset buildargs would be assigned a string containing `'None'` instead of the expected empty value.\n    \n*   Fixed a bug where yes/no prompts on Windows would not show before receiving input.\n    \n*   Fixed a bug where trying to `docker-compose exec` on Windows without the `-d` option would exit with a stacktrace. This will still fail for the time being, but should do so gracefully.\n    \n*   Fixed a bug where errors during `docker-compose up` would show an unrelated stacktrace at the end of the process.\n    \n*   `docker-compose create` and `docker-compose start` show more descriptive error messages when something goes wrong.\n    \n\n(2016-05-04)\n\n### [Bug fixes](#bug-fixes-42)\n\n*   Fixed a bug where the output of `docker-compose config` for v1 files would be an invalid configuration file.\n    \n*   Fixed a bug where `docker-compose config` would not check the validity of links.\n    \n*   Fixed an issue where `docker-compose help` would not output a list of available commands and generic options as expected.\n    \n*   Fixed an issue where filtering by service when using `docker-compose logs` would not apply for newly created services.\n    \n*   Fixed a bug where unchanged services would sometimes be recreated in in the up phase when using Compose with Python 3.\n    \n*   Fixed an issue where API errors encountered during the up phase would not be recognized as a failure state by Compose.\n    \n*   Fixed a bug where Compose would raise a NameError because of an undefined exception name on non-Windows platforms.\n    \n*   Fixed a bug where the wrong version of `docker-py` would sometimes be installed alongside Compose.\n    \n*   Fixed a bug where the host value output by `docker-machine config default` would not be recognized as valid options by the `docker-compose` command line.\n    \n*   Fixed an issue where Compose would sometimes exit unexpectedly while reading events broadcasted by a Swarm cluster.\n    \n*   Corrected a statement in the docs about the location of the `.env` file, which is indeed read from the current directory, instead of in the same location as the Compose file.\n    \n\n(2016-04-13)\n\n### [Breaking Changes](#breaking-changes-3)\n\n*   `docker-compose logs` no longer follows log output by default. It now matches the behavior of `docker logs` and exits after the current logs are printed. Use `-f` to get the old default behavior.\n    \n*   Booleans are no longer allows as values for mappings in the Compose file (for keys `environment`, `labels` and `extra_hosts`). Previously this was a warning. Boolean values should be quoted so they become string values.\n    \n\n### [New Features](#new-features-17)\n\n*   Compose now looks for a `.env` file in the directory where it's run and reads any environment variables defined inside, if they're not already set in the shell environment. This lets you easily set defaults for variables used in the Compose file, or for any of the `COMPOSE_*` or `DOCKER_*` variables.\n    \n*   Added a `--remove-orphans` flag to both `docker-compose up` and `docker-compose down` to remove containers for services that were removed from the Compose file.\n    \n*   Added a `--all` flag to `docker-compose rm` to include containers created by `docker-compose run`. This will become the default behavior in the next version of Compose.\n    \n*   Added support for all the same TLS configuration flags used by the `docker` client: `--tls`, `--tlscert`, `--tlskey`, etc.\n    \n*   Compose files now support the `tmpfs` and `shm_size` options.\n    \n*   Added the `--workdir` flag to `docker-compose run`\n    \n*   `docker-compose logs` now shows logs for new containers that are created after it starts.\n    \n*   The `COMPOSE_FILE` environment variable can now contain multiple files, separated by the host system's standard path separator (`:` on Mac/Linux, `;` on Windows).\n    \n*   You can now specify a static IP address when connecting a service to a network with the `ipv4_address` and `ipv6_address` options.\n    \n*   Added `--follow`, `--timestamp`, and `--tail` flags to the `docker-compose logs` command.\n    \n*   `docker-compose up`, and `docker-compose start` will now start containers in parallel where possible.\n    \n*   `docker-compose stop` now stops containers in reverse dependency order instead of all at once.\n    \n*   Added the `--build` flag to `docker-compose up` to force it to build a new image. It now shows a warning if an image is automatically built when the flag is not used.\n    \n*   Added the `docker-compose exec` command for executing a process in a running container.\n    \n\n### [Bug fixes](#bug-fixes-43)\n\n*   `docker-compose down` now removes containers created by `docker-compose run`.\n    \n*   A more appropriate error is shown when a timeout is hit during `up` when using a tty.\n    \n*   Fixed a bug in `docker-compose down` where it would abort if some resources had already been removed.\n    \n*   Fixed a bug where changes to network aliases would not trigger a service to be recreated.\n    \n*   Fix a bug where a log message was printed about creating a new volume when it already existed.\n    \n*   Fixed a bug where interrupting `up` would not always shut down containers.\n    \n*   Fixed a bug where `log_opt` and `log_driver` were not properly carried over when extending services in the v1 Compose file format.\n    \n*   Fixed a bug where empty values for build args would cause file validation to fail.\n    \n\n(2016-02-23)\n\n*   Fixed a bug where connecting to a TLS-enabled Docker Engine would fail with a certificate verification error.\n\n(2016-02-23)\n\n### [Bug fixes](#bug-fixes-44)\n\n*   Fixed a bug where recreating a container multiple times would cause the new container to be started without the previous volumes.\n    \n*   Fixed a bug where Compose would set the value of unset environment variables to an empty string, instead of a key without a value.\n    \n*   Provide a better error message when Compose requires a more recent version of the Docker API.\n    \n*   Add a missing config field `network.aliases` which allows setting a network scoped alias for a service.\n    \n*   Fixed a bug where `run` would not start services listed in `depends_on`.\n    \n*   Fixed a bug where `networks` and `network_mode` where not merged when using extends or multiple Compose files.\n    \n*   Fixed a bug with service aliases where the short container id alias was only contained 10 characters, instead of the 12 characters used in previous versions.\n    \n*   Added a missing log message when creating a new named volume.\n    \n*   Fixed a bug where `build.args` was not merged when using `extends` or multiple Compose files.\n    \n*   Fixed some bugs with config validation when null values or incorrect types were used instead of a mapping.\n    \n*   Fixed a bug where a `build` section without a `context` would show a stack trace instead of a helpful validation message.\n    \n*   Improved compatibility with swarm by only setting a container affinity to the previous instance of a services' container when the service uses an anonymous container volume. Previously the affinity was always set on all containers.\n    \n*   Fixed the validation of some `driver_opts` would cause an error if a number was used instead of a string.\n    \n*   Some improvements to the `run.sh` script used by the Compose container install option.\n    \n*   Fixed a bug with `up --abort-on-container-exit` where Compose would exit, but would not stop other containers.\n    \n*   Corrected the warning message that is printed when a boolean value is used as a value in a mapping.\n    \n\n(2016-01-15)\n\n### [Major Features](#major-features)\n\n*   Compose 1.6 introduces a new format for `docker-compose.yml` which lets you define networks and volumes in the Compose file as well as services. It also makes a few changes to the structure of some configuration options.\n    \n    You don't have to use it - your existing Compose files will run on Compose 1.6 exactly as they do today.\n    \n    Check the [upgrade guide](https://docs.docker.com/compose/compose-file/legacy-versions/) for full details.\n    \n*   Support for networking has exited experimental status and is the recommended way to enable communication between containers.\n    \n    If you use the new file format, your app will use networking. If you aren't ready yet, just leave your Compose file as it is and it'll continue to work just the same.\n    \n    By default, you don't have to configure any networks. In fact, using networking with Compose involves even less configuration than using links. Consult the [networking guide](https://docs.docker.com/compose/networking/) for how to use it.\n    \n    The experimental flags `--x-networking` and `--x-network-driver`, introduced in Compose 1.5, have been removed.\n    \n*   You can now pass arguments to a build if you're using the new file format:\n    \n    ```\n    build:\n      context: .\n      args:\n        buildno: 1\n    ```\n    \n*   You can now specify both a `build` and an `image` key if you're using the new file format. `docker-compose build` will build the image and tag it with the name you've specified, while `docker-compose pull` will attempt to pull it.\n    \n*   There's a new `events` command for monitoring container events from the application, much like `docker events`. This is a good primitive for building tools on top of Compose for performing actions when particular things happen, such as containers starting and stopping.\n    \n*   There's a new `depends_on` option for specifying dependencies between services. This enforces the order of startup, and ensures that when you run `docker-compose up SERVICE` on a service with dependencies, those are started as well.\n    \n\n### [New Features](#new-features-18)\n\n*   Added a new command `config` which validates and prints the Compose configuration after interpolating variables, resolving relative paths, and merging multiple files and `extends`.\n    \n*   Added a new command `create` for creating containers without starting them.\n    \n*   Added a new command `down` to stop and remove all the resources created by `up` in a single command.\n    \n*   Added support for the `cpu_quota` configuration option.\n    \n*   Added support for the `stop_signal` configuration option.\n    \n*   Commands `start`, `restart`, `pause`, and `unpause` now exit with an error status code if no containers were modified.\n    \n*   Added a new `--abort-on-container-exit` flag to `up` which causes `up` to stop all container and exit once the first container exits.\n    \n*   Removed support for `FIG_FILE`, `FIG_PROJECT_NAME`, and no longer reads `fig.yml` as a default Compose file location.\n    \n*   Removed the `migrate-to-labels` command.\n    \n*   Removed the `--allow-insecure-ssl` flag.\n    \n\n### [Bug fixes](#bug-fixes-45)\n\n*   Fixed a validation bug that prevented the use of a range of ports in the `expose` field.\n    \n*   Fixed a validation bug that prevented the use of arrays in the `entrypoint` field if they contained duplicate entries.\n    \n*   Fixed a bug that caused `ulimits` to be ignored when used with `extends`.\n    \n*   Fixed a bug that prevented ipv6 addresses in `extra_hosts`.\n    \n*   Fixed a bug that caused `extends` to be ignored when included from multiple Compose files.\n    \n*   Fixed an incorrect warning when a container volume was defined in the Compose file.\n    \n*   Fixed a bug that prevented the force shutdown behavior of `up` and `logs`.\n    \n*   Fixed a bug that caused `None` to be printed as the network driver name when the default network driver was used.\n    \n*   Fixed a bug where using the string form of `dns` or `dns_search` would cause an error.\n    \n*   Fixed a bug where a container would be reported as \"Up\" when it was in the restarting state.\n    \n*   Fixed a confusing error message when DOCKER\\_CERT\\_PATH was not set properly.\n    \n*   Fixed a bug where attaching to a container would fail if it was using a non-standard logging driver (or none at all).\n    \n\n(2015-12-03)\n\n*   Fixed a bug which broke the use of `environment` and `env_file` with `extends`, and caused environment keys without values to have a `None` value, instead of a value from the host environment.\n    \n*   Fixed a regression in 1.5.1 that caused a warning about volumes to be raised incorrectly when containers were recreated.\n    \n*   Fixed a bug which prevented building a `Dockerfile` that used `ADD <url>`\n    \n*   Fixed a bug with `docker-compose restart` which prevented it from starting stopped containers.\n    \n*   Fixed handling of SIGTERM and SIGINT to properly stop containers\n    \n*   Add support for using a url as the value of `build`\n    \n*   Improved the validation of the `expose` option\n    \n\n(2015-11-12)\n\n*   Add the `--force-rm` option to `build`.\n    \n*   Add the `ulimit` option for services in the Compose file.\n    \n*   Fixed a bug where `up` would error with \"service needs to be built\" if a service changed from using `image` to using `build`.\n    \n*   Fixed a bug that would cause incorrect output of parallel operations on some terminals.\n    \n*   Fixed a bug that prevented a container from being recreated when the mode of a `volumes_from` was changed.\n    \n*   Fixed a regression in 1.5.0 where non-utf-8 unicode characters would cause `up` or `logs` to crash.\n    \n*   Fixed a regression in 1.5.0 where Compose would use a success exit status code when a command fails due to an HTTP timeout communicating with the docker daemon.\n    \n*   Fixed a regression in 1.5.0 where `name` was being accepted as a valid service option which would override the actual name of the service.\n    \n*   When using `--x-networking` Compose no longer sets the hostname to the container name.\n    \n*   When using `--x-networking` Compose will only create the default network if at least one container is using the network.\n    \n*   When printings logs during `up` or `logs`, flush the output buffer after each line to prevent buffering issues from hiding logs.\n    \n*   Recreate a container if one of its dependencies is being created. Previously a container was only recreated if it's dependencies already existed, but were being recreated as well.\n    \n*   Add a warning when a `volume` in the Compose file is being ignored and masked by a container volume from a previous container.\n    \n*   Improve the output of `pull` when run without a tty.\n    \n*   When using multiple Compose files, validate each before attempting to merge them together. Previously invalid files would result in not helpful errors.\n    \n*   Allow dashes in keys in the `environment` service option.\n    \n*   Improve validation error messages by including the filename as part of the error message.\n    \n\n(2015-11-03)\n\n### [Breaking changes](#breaking-changes-4)\n\nWith the introduction of variable substitution support in the Compose file, any Compose file that uses an environment variable (`$VAR` or `${VAR}`) in the `command:` or `entrypoint:` field will break.\n\nPreviously these values were interpolated inside the container, with a value from the container environment. In Compose 1.5.0, the values will be interpolated on the host, with a value from the host environment.\n\nTo migrate a Compose file to 1.5.0, escape the variables with an extra `$` (ex: `$$VAR` or `$${VAR}`). See [https://github.com/docker/compose/blob/8cc8e61/docs/compose-file.md#variable-substitution](https://github.com/docker/compose/blob/8cc8e61/docs/compose-file.md#variable-substitution)\n\n### [Major features](#major-features-1)\n\n*   Compose is now available for Windows.\n    \n*   Environment variables can be used in the Compose file. See [https://github.com/docker/compose/blob/8cc8e61/docs/compose-file.md#variable-substitution](https://github.com/docker/compose/blob/8cc8e61/docs/compose-file.md#variable-substitution)\n    \n*   Multiple compose files can be specified, allowing you to override settings in the default Compose file. See [https://github.com/docker/compose/blob/8cc8e61/docs/reference/docker-compose.md](https://github.com/docker/compose/blob/8cc8e61/docs/reference/docker-compose.md) for more details.\n    \n*   Compose now produces better error messages when a file contains invalid configuration.\n    \n*   `up` now waits for all services to exit before shutting down, rather than shutting down as soon as one container exits.\n    \n*   Experimental support for the new docker networking system can be enabled with the `--x-networking` flag. Read more here: [https://github.com/docker/docker/blob/8fee1c20/docs/userguide/dockernetworks.md](https://github.com/docker/docker/blob/8fee1c20/docs/userguide/dockernetworks.md)\n    \n\n### [New features](#new-features-19)\n\n*   You can now optionally pass a mode to `volumes_from`. For example, `volumes_from: [\"servicename:ro\"]`.\n    \n*   Since Docker now lets you create volumes with names, you can refer to those volumes by name in `docker-compose.yml`. For example, `volumes: [\"mydatavolume:/data\"]` will mount the volume named `mydatavolume` at the path `/data` inside the container.\n    \n    If the first component of an entry in `volumes` starts with a `.`, `/` or `~`, it is treated as a path and expansion of relative paths is performed as necessary. Otherwise, it is treated as a volume name and passed straight through to Docker.\n    \n    Read more on named volumes and volume drivers here: [https://github.com/docker/docker/blob/244d9c33/docs/userguide/dockervolumes.md](https://github.com/docker/docker/blob/244d9c33/docs/userguide/dockervolumes.md)\n    \n*   `docker-compose build --pull` instructs Compose to pull the base image for each Dockerfile before building.\n    \n*   `docker-compose pull --ignore-pull-failures` instructs Compose to continue if it fails to pull a single service's image, rather than aborting.\n    \n*   You can now specify an IPC namespace in `docker-compose.yml` with the `ipc` option.\n    \n*   Containers created by `docker-compose run` can now be named with the `--name` flag.\n    \n*   If you install Compose with pip or use it as a library, it now works with Python 3.\n    \n*   `image` now supports image digests (in addition to ids and tags). For example, `image: \"busybox@sha256:38a203e1986cf79639cfb9b2e1d6e773de84002feea2d4eb006b52004ee8502d\"`\n    \n*   `ports` now supports ranges of ports. For example,\n    \n    ```\n    ports:\n      - \"3000-3005\"\n      - \"9000-9001:8000-8001\"\n    ```\n    \n*   `docker-compose run` now supports a `-p|--publish` parameter, much like `docker run -p`, for publishing specific ports to the host.\n    \n*   `docker-compose pause` and `docker-compose unpause` have been implemented, analogous to `docker pause` and `docker unpause`.\n    \n*   When using `extends` to copy configuration from another service in the same Compose file, you can omit the `file` option.\n    \n*   Compose can be installed and run as a Docker image. This is an experimental feature.\n    \n\n### [Bug fixes](#bug-fixes-46)\n\n*   All values for the `log_driver` option which are supported by the Docker daemon are now supported by Compose.\n    \n*   `docker-compose build` can now be run successfully against a Swarm cluster.\n    \n\n(2015-09-22)\n\n*   Fixed a regression in the 1.4.1 release that would cause `docker-compose up` without the `-d` option to exit immediately.\n\n(2015-09-10)\n\n### [Bug fixes](#bug-fixes-47)\n\n*   Some configuration changes (notably changes to `links`, `volumes_from`, and `net`) were not properly triggering a container recreate as part of `docker-compose up`.\n*   `docker-compose up <service>` was showing logs for all services instead of just the specified services.\n*   Containers with custom container names were showing up in logs as `service_number` instead of their custom container name.\n*   When scaling a service sometimes containers would be recreated even when the configuration had not changed.\n\n(2015-08-04)\n\n*   By default, `docker-compose up` now only recreates containers for services whose configuration has changed since they were created. This should result in a dramatic speed-up for many applications.\n    \n    The experimental `--x-smart-recreate` flag which introduced this feature in Compose 1.3.0 has been removed, and a `--force-recreate` flag has been added for when you want to recreate everything.\n    \n*   Several of Compose's commands - `scale`, `stop`, `kill` and `rm` - now perform actions on multiple containers in parallel, rather than in sequence, which will run much faster on larger applications.\n    \n*   You can now specify a custom name for a service's container with `container_name`. Because Docker container names must be unique, this means you can't scale the service beyond one container.\n    \n*   You no longer have to specify a `file` option when using `extends` - it will default to the current file.\n    \n*   Service names can now contain dots, dashes and underscores.\n    \n*   Compose can now read YAML configuration from standard input, rather than from a file, by specifying `-` as the filename. This makes it easier to generate configuration dynamically:\n    \n    ```\n    $ echo 'redis: {\"image\": \"redis\"}' | docker-compose --file - up\n    ```\n    \n*   There's a new `docker-compose version` command which prints extended information about Compose's bundled dependencies.\n    \n*   `docker-compose.yml` now supports `log_opt` as well as `log_driver`, allowing you to pass extra configuration to a service's logging driver.\n    \n*   `docker-compose.yml` now supports `memswap_limit`, similar to `docker run --memory-swap`.\n    \n*   When mounting volumes with the `volumes` option, you can now pass in any mode supported by the daemon, not just `:ro` or `:rw`. For example, SELinux users can pass `:z` or `:Z`.\n    \n*   You can now specify a custom volume driver with the `volume_driver` option in `docker-compose.yml`, much like `docker run --volume-driver`.\n    \n*   A bug has been fixed where Compose would fail to pull images from private registries serving plain (unsecured) HTTP. The `--allow-insecure-ssl` flag, which was previously used to work around this issue, has been deprecated and now has no effect.\n    \n*   A bug has been fixed where `docker-compose build` would fail if the build depended on a private Hub image or an image from a private registry.\n    \n*   A bug has been fixed where Compose would crash if there were containers which the Docker daemon had not finished removing.\n    \n*   Two bugs have been fixed where Compose would sometimes fail with a \"Duplicate bind mount\" error, or fail to attach volumes to a container, if there was a volume path specified in `docker-compose.yml` with a trailing slash.\n    \n\nThanks @mnowster, @dnephin, @ekristen, @funkyfuture, @jeffk and @lukemarsden!\n\n(2015-07-15)\n\n### [Regression fixes](#regression-fixes)\n\n*   When stopping containers gracefully, Compose was setting the timeout to 0, effectively forcing a SIGKILL every time.\n*   Compose would sometimes crash depending on the formatting of container data returned from the Docker API.\n\n(2015-07-14)\n\n### [Bug fixes](#bug-fixes-48)\n\n*   When there were one-off containers created by running `docker-compose run` on an older version of Compose, `docker-compose run` would fail with a name collision. Compose now shows an error if you have leftover containers of this type lying around, and tells you how to remove them.\n*   Compose was not reading Docker authentication config files created in the new location, `~/docker/config.json`, and authentication against private registries would therefore fail.\n*   When a container had a pseudo-TTY attached, its output in `docker-compose up` would be truncated.\n*   `docker-compose up --x-smart-recreate` would sometimes fail when an image tag was updated.\n*   `docker-compose up` would sometimes create two containers with the same numeric suffix.\n*   `docker-compose rm` and `docker-compose ps` would sometimes list services that aren't part of the current project (though no containers were erroneously removed).\n*   Some `docker-compose` commands would not show an error if invalid service names were passed in.\n\nThanks @dano, @josephpage, @kevinsimper, @lieryan, @phemmer, @soulrebel and @sschepens!\n\n(2015-06-21)\n\n### [Bug fixes](#bug-fixes-49)\n\n*   `docker-compose build` would always attempt to pull the base image before building.\n*   `docker-compose help migrate-to-labels` failed with an error.\n*   If no network mode was specified, Compose would set it to \"bridge\", rather than allowing the Docker daemon to use its configured default network mode.\n\n(2015-06-18)\n\n### [Important notes](#important-notes)\n\n*   **This release contains breaking changes, and you will need to either remove or migrate your existing containers before running your app** - see the [upgrading section of the install docs](https://github.com/docker/compose/blob/1.3.0rc1/docs/install.md#upgrading) for details.\n    \n*   Compose now requires Docker 1.6.0 or later.\n    \n\n### [Improvements](#improvements)\n\n*   Compose now uses container labels, rather than names, to keep track of containers. This makes Compose both faster and easier to integrate with your own tools.\n    \n*   Compose no longer uses \"intermediate containers\" when recreating containers for a service. This makes `docker-compose up` less complex and more resilient to failure.\n    \n\n### [New features](#new-features-20)\n\n*   `docker-compose up` has an **experimental** new behavior: it will only recreate containers for services whose configuration has changed in `docker-compose.yml`. This will eventually become the default, but for now you can take it for a spin:\n    \n    ```\n      $ docker-compose up --x-smart-recreate\n    ```\n    \n*   When invoked in a subdirectory of a project, `docker-compose` will now climb up through parent directories until it finds a `docker-compose.yml`.\n    \n\nSeveral new configuration keys have been added to `docker-compose.yml`:\n\n*   `dockerfile`, like `docker build --file`, lets you specify an alternate Dockerfile to use with `build`.\n*   `labels`, like `docker run --labels`, lets you add custom metadata to containers.\n*   `extra_hosts`, like `docker run --add-host`, lets you add entries to a container's `/etc/hosts` file.\n*   `pid: host`, like `docker run --pid=host`, lets you reuse the same PID namespace as the host machine.\n*   `cpuset`, like `docker run --cpuset-cpus`, lets you specify which CPUs to allow execution in.\n*   `read_only`, like `docker run --read-only`, lets you mount a container's filesystem as read-only.\n*   `security_opt`, like `docker run --security-opt`, lets you specify [security options](https://docs.docker.com/reference/cli/docker/container/run/#security-opt).\n*   `log_driver`, like `docker run --log-driver`, lets you specify a [log driver](https://docs.docker.com/reference/cli/docker/container/run/#log-driver).\n\n### [Bug fixes](#bug-fixes-50)\n\n*   The output of `docker-compose run` was sometimes truncated, especially when running under Jenkins.\n*   A service's volumes would sometimes not update after volume configuration was changed in `docker-compose.yml`.\n*   Authenticating against third-party registries would sometimes fail.\n*   `docker-compose run --rm` would fail to remove the container if the service had a `restart` policy in place.\n*   `docker-compose scale` would refuse to scale a service beyond 1 container if it exposed a specific port number on the host.\n*   Compose would refuse to create multiple volume entries with the same host path.\n\nThanks @ahromis, @albers, @aleksandr-vin, @antoineco, @ccverak, @chernjie, @dnephin, @edmorley, @fordhurley, @josephpage, @KyleJamesWalker, @lsowen, @mchasal, @noironetworks, @sdake, @sdurrheimer, @sherter, @stephenlawrence, @thaJeztah, @thieman, @turtlemonvh, @twhiteman, @vdemeester, @xuxinkun and @zwily!\n\n(2015-04-16)\n\n*   `docker-compose.yml` now supports an `extends` option, which enables a service to inherit configuration from another service in another configuration file. This is really good for sharing common configuration between apps, or for configuring the same app for different environments. Here's the [documentation](https://github.com/docker/compose/blob/master/docs/).\n    \n*   When using Compose with a Swarm cluster, containers that depend on one another will be co-scheduled on the same node. This means that most Compose apps will now work out of the box, as long as they don't use `build`.\n    \n*   Repeated invocations of `docker-compose up` when using Compose with a Swarm cluster now work reliably.\n    \n*   Directories passed to `build`, filenames passed to `env_file` and volume host paths passed to `volumes` are now treated as relative to the _directory of the configuration file_, not the directory that `docker-compose` is being run in. In the majority of cases, those are the same, but if you use the `-f|--file` argument to specify a configuration file in another directory, **this is a breaking change**.\n    \n*   A service can now share another service's network namespace with `net: container:<service>`.\n    \n*   `volumes_from` and `net: container:<service>` entries are taken into account when resolving dependencies, so `docker-compose up <service>` will correctly start all dependencies of `<service>`.\n    \n*   `docker-compose run` now accepts a `--user` argument to specify a user to run the command as, just like `docker run`.\n    \n*   The `up`, `stop` and `restart` commands now accept a `--timeout` (or `-t`) argument to specify how long to wait when attempting to gracefully stop containers, just like `docker stop`.\n    \n*   `docker-compose rm` now accepts `-f` as a shorthand for `--force`, just like `docker rm`.\n    \n\nThanks, @abesto, @albers, @alunduil, @dnephin, @funkyfuture, @gilclark, @IanVS, @KingsleyKelly, @knutwalker, @thaJeztah and @vmalloc!\n\n(2015-02-25)\n\nFig has been renamed to Docker Compose, or just Compose for short. This has several implications for you:\n\n*   The command you type is now `docker-compose`, not `fig`.\n*   You should rename your fig.yml to docker-compose.yml.\n*   If youâ€™re installing via PyPI, the package is now `docker-compose`, so install it with `pip install docker-compose`.\n\nBesides that, thereâ€™s a lot of new stuff in this release:\n\n*   Weâ€™ve made a few small changes to ensure that Compose will work with Swarm, Dockerâ€™s new clustering tool ( [https://github.com/docker/swarm)](https://github.com/docker/swarm%29). Eventually you'll be able to point Compose at a Swarm cluster instead of a standalone Docker host and itâ€™ll run your containers on the cluster with no extra work from you. As Swarm is still developing, integration is rough and lots of Compose features don't work yet.\n    \n*   `docker-compose run` now has a `--service-ports` flag for exposing ports on the given service. This is useful for running your webapp with an interactive debugger, for example.\n    \n*   You can now link to containers outside your app with the `external_links` option in docker-compose.yml.\n    \n*   You can now prevent `docker-compose up` from automatically building images with the `--no-build` option. This will make fewer API calls and run faster.\n    \n*   If you donâ€™t specify a tag when using the `image` key, Compose will default to the `latest` tag, rather than pulling all tags.\n    \n*   `docker-compose kill` now supports the `-s` flag, allowing you to specify the exact signal you want to send to a serviceâ€™s containers.\n    \n*   docker-compose.yml now has an `env_file` key, analogous to `docker run --env-file`, letting you specify multiple environment variables in a separate file. This is great if you have a lot of them, or if you want to keep sensitive information out of version control.\n    \n*   docker-compose.yml now supports the `dns_search`, `cap_add`, `cap_drop`, `cpu_shares` and `restart` options, analogous to `docker run`â€™s `--dns-search`, `--cap-add`, `--cap-drop`, `--cpu-shares` and `--restart` options.\n    \n*   Compose now ships with Bash tab completion - see the installation and usage docs at [https://github.com/docker/compose/blob/1.1.0/docs/completion.md](https://github.com/docker/compose/blob/1.1.0/docs/completion.md)\n    \n*   A number of bugs have been fixed - see the milestone for details: [https://github.com/docker/compose/issues?q=milestone%3A1.1.0+](https://github.com/docker/compose/issues?q=milestone%3A1.1.0+)\n    \n\nThanks @dnephin, @squebe, @jbalonso, @raulcd, @benlangfield, @albers, @ggtools, @bersace, @dtenenba, @petercv, @drewkett, @TFenby, @paulRbr, @Aigeruth and @salehe!\n\n(2014-11-04)\n\n*   Added an `--allow-insecure-ssl` option to allow `fig up`, `fig run` and `fig pull` to pull from insecure registries.\n*   Fixed `fig run` not showing output in Jenkins.\n*   Fixed a bug where Fig couldn't build Dockerfiles with ADD statements pointing at URLs.\n\n(2014-10-16)\n\nThe highlights:\n\n*   [Fig has joined Docker.](https://www.orchardup.com/blog/orchard-is-joining-docker) Fig will continue to be maintained, but we'll also be incorporating the best bits of Fig into Docker itself.\n    \n    This means the GitHub repository has moved to [https://github.com/docker/fig](https://github.com/docker/fig) and our IRC channel is now #docker-fig on Freenode.\n    \n*   Fig can be used with the [official Docker OS X installer](https://docs.docker.com/desktop/install/mac-install/). Boot2Docker will mount the home directory from your host machine so volumes work as expected.\n    \n*   Fig supports Docker 1.3.\n    \n*   It is now possible to connect to the Docker daemon using TLS by using the `DOCKER_CERT_PATH` and `DOCKER_TLS_VERIFY` environment variables.\n    \n*   There is a new `fig port` command which outputs the host port binding of a service, in a similar way to `docker port`.\n    \n*   There is a new `fig pull` command which pulls the latest images for a service.\n    \n*   There is a new `fig restart` command which restarts a service's containers.\n    \n*   Fig creates multiple containers in service by appending a number to the service name. For example, `db_1`, `db_2`. As a convenience, Fig will now give the first container an alias of the service name. For example, `db`.\n    \n    This link alias is also a valid hostname and added to `/etc/hosts` so you can connect to linked services using their hostname. For example, instead of resolving the environment variables `DB_PORT_5432_TCP_ADDR` and `DB_PORT_5432_TCP_PORT`, you could just use the hostname `db` and port `5432` directly.\n    \n*   Volume definitions now support `ro` mode, expanding `~` and expanding environment variables.\n    \n*   `.dockerignore` is supported when building.\n    \n*   The project name can be set with the `FIG_PROJECT_NAME` environment variable.\n    \n*   The `--env` and `--entrypoint` options have been added to `fig run`.\n    \n*   The Fig binary for Linux is now linked against an older version of glibc so it works on CentOS 6 and Debian Wheezy.\n    \n\nOther things:\n\n*   `fig ps` now works on Jenkins and makes fewer API calls to the Docker daemon.\n*   `--verbose` displays more useful debugging output.\n*   When starting a service where `volumes_from` points to a service without any containers running, that service will now be started.\n*   Lots of docs improvements. Notably, environment variables are documented and official repositories are used throughout.\n\nThanks @dnephin, @d11wtq, @marksteve, @rubbish, @jbalonso, @timfreund, @alunduil, @mieciu, @shuron, @moss, @suzaku and @chmouel! Whew.\n\n(2014-07-28)\n\n*   Added a `--no-cache` option to `fig build`, which bypasses the cache just like `docker build --no-cache`.\n*   Fixed the `dns:` fig.yml option, which was causing fig to error out.\n*   Fixed a bug where fig couldn't start under Python 2.6.\n*   Fixed a log-streaming bug that occasionally caused fig to exit.\n\nThanks @dnephin and @marksteve!\n\n(2014-07-11)\n\n*   If a service has a command defined, `fig run [service]` with no further arguments will run it.\n*   The project name now defaults to the directory containing fig.yml, not the current working directory (if they're different)\n*   `volumes_from` now works properly with containers as well as services\n*   Fixed a race condition when recreating containers in `fig up`\n\nThanks @ryanbrainard and @d11wtq!\n\n(2014-07-11)\n\n*   Fig now starts links when you run `fig run` or `fig up`.\n    \n    For example, if you have a `web` service which depends on a `db` service, `fig run web ...` will start the `db` service.\n    \n*   Environment variables can now be resolved from the environment that Fig is running in. Just specify it as a blank variable in your `fig.yml` and, if set, it'll be resolved:\n    \n*   `volumes_from` is now supported in `fig.yml`. All of the volumes from the specified services and containers will be mounted:\n    \n*   A host address can now be specified in `ports`:\n    \n*   The `net` and `workdir` options are now supported in `fig.yml`.\n    \n*   The `hostname` option now works in the same way as the Docker CLI, splitting out into a `domainname` option.\n    \n*   TTY behavior is far more robust, and resizes are supported correctly.\n    \n*   Load YAML files safely.\n    \n\nThanks to @d11wtq, @ryanbrainard, @rail44, @j0hnsmith, @binarin, @Elemecca, @mozz100 and @marksteve for their help with this release!\n\n(2014-06-18)\n\n*   Fix various encoding errors when using `fig run`, `fig up` and `fig build`.\n\n(2014-05-08)\n\n*   Add support for Docker 0.11.0. (Thanks @marksteve!)\n*   Make project name configurable. (Thanks @jefmathiot!)\n*   Return correct exit code from `fig run`.\n\n(2014-04-29)\n\n*   Support Docker 0.9 and 0.10\n*   Display progress bars correctly when pulling images (no more ski slopes)\n*   `fig up` now stops all services when any container exits\n*   Added support for the `privileged` config option in fig.yml (thanks @kvz!)\n*   Shortened and aligned log prefixes in `fig up` output\n*   Only containers started with `fig run` link back to their own service\n*   Handle UTF-8 correctly when streaming `fig build/run/up` output (thanks @mauvm and @shanejonas!)\n*   Error message improvements\n\n(2014-03-05)\n\n*   Added an `--rm` option to `fig run`. (Thanks @marksteve!)\n*   Added an `expose` option to `fig.yml`.\n\n(2014-03-04)\n\n*   Added contribution instructions. (Thanks @kvz!)\n*   Fixed `fig rm` throwing an error.\n*   Fixed a bug in `fig ps` on Docker 0.8.1 when there is a container with no command.\n\n(2014-03-03)\n\n*   We now ship binaries for OS X and Linux. No more having to install with Pip!\n*   Add `-f` flag to specify alternate `fig.yml` files\n*   Add support for custom link names\n*   Fix a bug where recreating would sometimes hang\n*   Update docker-py to support Docker 0.8.0.\n*   Various documentation improvements\n*   Various error message improvements\n\nThanks @marksteve, @Gazler and @teozkr!\n\n(2014-02-17)\n\n*   Resolve dependencies using Cormen/Tarjan topological sort\n*   Fix `fig up` not printing log output\n*   Stop containers in reverse order to starting\n*   Fix scale command not binding ports\n\nThanks to @barnybug and @dustinlacewell for their work on this release.\n\n(2014-02-04)\n\n*   General improvements to error reporting (#77, #79)\n\n(2014-01-31)\n\n*   Link services to themselves so run commands can access the running service. (#67)\n*   Much better documentation.\n*   Make service dependency resolution more reliable. (#48)\n*   Load Fig configurations with a `.yaml` extension. (#58)\n\nBig thanks to @cameronmaske, @mrchrisadams and @damianmoore for their help with this release.\n\n(2014-01-27)\n\n*   Add a link alias without the project name. This makes the environment variables a little shorter: `REDIS_1_PORT_6379_TCP_ADDR`. (#54)\n\n(2014-01-23)\n\n*   Fix ports sometimes being configured incorrectly. (#46)\n*   Fix log output sometimes not displaying. (#47)\n\n(2014-01-22)\n\n*   Add `-T` option to `fig run` to disable pseudo-TTY. (#34)\n*   Fix `fig up` requiring the ubuntu image to be pulled to recreate containers. (#33) Thanks @cameronmaske!\n*   Improve reliability, fix arrow keys and fix a race condition in `fig run`. (#34, #39, #40)\n\n(2014-01-17)\n\n*   Fix bug where ports were not exposed correctly (#29). Thanks @dustinlacewell!\n\n(2014-01-16)\n\n*   Containers are recreated on each `fig up`, ensuring config is up-to-date with `fig.yml` (#2)\n*   Add `fig scale` command (#9)\n*   Use `DOCKER_HOST` environment variable to find Docker daemon, for consistency with the official Docker client (was previously `DOCKER_URL`) (#19)\n*   Truncate long commands in `fig ps` (#18)\n*   Fill out CLI help banners for commands (#15, #16)\n*   Show a friendlier error when `fig.yml` is missing (#4)\n*   Fix bug with `fig build` logging (#3)\n*   Fix bug where builds would time out if a step took a long time without generating output (#6)\n*   Fix bug where streaming container output over the Unix socket raised an error (#7)\n\nBig thanks to @tomstuart, @EnTeQuAk, @schickling, @aronasorman and @GeoffreyPlitt.\n\n(2014-01-02)\n\n*   Improve documentation\n*   Try to connect to Docker on `tcp://localdocker:4243` and a UNIX socket in addition to `localhost`.\n*   Improve `fig up` behavior\n*   Add confirmation prompt to `fig rm`\n*   Add `fig build` command\n\n(2013-12-20)\n\nInitial release.",
  "title": "Docker Compose release notes | Docker Docs\n",
  "description": "Learn about the new features, bug fixes, and breaking changes for the newest Docker Compose release",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-file",
  "markdown": "# Overview | Docker Docs\n\n> **New to Docker Compose?**\n> \n> Find more information about the [key features and use cases of Docker Compose](https://docs.docker.com/compose/intro/features-uses/) or [try the quickstart guide](https://docs.docker.com/compose/gettingstarted/).\n\nThe Compose Specification is the latest and recommended version of the Compose file format. It helps you define a [Compose file](https://docs.docker.com/compose/compose-application-model/) which is used to configure your Docker applicationâ€™s services, networks, volumes, and more.\n\nLegacy versions 2.x and 3.x of the Compose file format were merged into the Compose Specification. It is implemented in versions 1.27.0 and above (also known as Compose V2) of the Docker Compose CLI.\n\nThe Compose Specification on Docker Docs is the Docker Compose implementation. If you wish to implement your own version of the Compose Specification, see the [Compose Specification repository](https://github.com/compose-spec/compose-spec).\n\nUse the following links to navigate key sections of the Compose Specification.",
  "title": "Overview | Docker Docs\n",
  "description": "Find the latest recommended version of the Docker Compose file format for defining multi-container applications.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/api/v1.31/",
  "markdown": "Docker Engine API v1.31 Reference",
  "title": "Docker Engine API v1.31 Reference",
  "description": "Reference documentation and Swagger (OpenAPI) specification for the v1.31 version of the API served by Docker Engine.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-file/legacy-versions/",
  "markdown": "# Legacy versions | Docker Docs\n\nThe legacy versions of the Compose file reference has moved to the [V1 branch of the Compose repository](https://github.com/docker/compose/tree/v1/docs). They are no longer being actively maintained.\n\nThe latest and recommended version of the Compose file format is defined by the [Compose Specification](https://docs.docker.com/compose/compose-file/). This format merges the 2.x and 3.x versions and is implemented by **Compose 1.27.0+**. For more information, see the [History and development of Docker Compose](https://docs.docker.com/compose/intro/history/).",
  "title": "Legacy versions | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-file/09-secrets/",
  "markdown": "# Secrets top-level elements | Docker Docs\n\nSecrets are a flavor of [Configs](https://docs.docker.com/compose/compose-file/08-configs/) focusing on sensitive data, with specific constraint for this usage.\n\nServices can only access secrets when explicitly granted by a [`secrets` attribute](https://docs.docker.com/compose/compose-file/05-services/#secrets) within the `services` top-level element.\n\nThe top-level `secrets` declaration defines or references sensitive data that is granted to the services in your Compose application. The source of the secret is either `file` or `environment`.\n\n*   `file`: The secret is created with the contents of the file at the specified path.\n*   `environment`: The secret is created with the value of an environment variable.\n\n`server-certificate` secret is created as `<project_name>_server-certificate` when the application is deployed, by registering content of the `server.cert` as a platform secret.\n\n`token` secret is created as `<project_name>_token` when the application is deployed, by registering the content of the `OAUTH_TOKEN` environment variable as a platform secret.\n\nFor more information, see [How to use secrets in Compose](https://docs.docker.com/compose/use-secrets/).",
  "title": "Secrets top-level elements | Docker Docs\n",
  "description": "Explore all the attributes the secrets top-level element can have.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/api/version-history/",
  "markdown": "# Engine API version history | Docker Docs\n\n[Docker Engine API v1.46](https://docs.docker.com/engine/api/v1.46/) documentation\n\n*   `GET /info` now includes a `Containerd` field containing information about the location of the containerd API socket and containerd namespaces used by the daemon to run containers and plugins.\n*   `POST /containers/create` field `NetworkingConfig.EndpointsConfig.DriverOpts`, and `POST /networks/{id}/connect` field `EndpointsConfig.DriverOpts`, now support label `com.docker.network.endpoint.sysctls` for setting per-interface sysctls. The value is a comma separated list of sysctl assignments, the interface name must be \"IFNAME\". For example, to set `net.ipv4.config.eth0.log_martians=1`, use `net.ipv4.config.IFNAME.log_martians=1`. In API versions up-to 1.46, top level `--sysctl` settings for `eth0` will be migrated to `DriverOpts` when possible. This automatic migration will be removed for API versions 1.47 and greater.\n*   `GET /containers/json` now returns the annotations of containers.\n*   `POST /images/{name}/push` now supports a `platform` parameter (JSON encoded OCI Platform type) that allows selecting a specific platform manifest from the multi-platform image.\n*   `POST /containers/create` now takes `Options` as part of `HostConfig.Mounts.TmpfsOptions` to set options for tmpfs mounts.\n*   `POST /services/create` now takes `Options` as part of `ContainerSpec.Mounts.TmpfsOptions`, to set options for tmpfs mounts.\n*   `GET /events` now supports image `create` event that is emitted when a new image is built regardless if it was tagged or not.\n\n### [Deprecated Config fields in `GET /images/{name}/json` response](#deprecated-config-fields-in-get-imagesnamejson-response)\n\nThe `Config` field returned by this endpoint (used for \"image inspect\") returns additional fields that are not part of the image's configuration and not part of the [Docker Image Spec](https://github.com/moby/docker-image-spec/blob/v1.3.1/specs-go/v1/image.go#L19-L32) and the [OCI Image Spec](https://github.com/opencontainers/image-spec/blob/v1.1.0/specs-go/v1/config.go#L24-L62).\n\nThese additional fields are included in the response, due to an implementation detail, where the [api/types.ImageInspec](https://github.com/moby/moby/blob/v26.1.4/api/types/types.go#L87-L104) type used for the response is using the [container.Config](https://github.com/moby/moby/blob/v26.1.4/api/types/container/config.go#L47-L82) type.\n\nThe [container.Config](https://github.com/moby/moby/blob/v26.1.4/api/types/container/config.go#L47-L82) type is a superset of the image config, and while the image's Config is used as a _template_ for containers created from the image, the additional fields are set at runtime (from options passed when creating the container) and not taken from the image Config.\n\nThese fields are never set (and always return the default value for the type), but are not omitted in the response when left empty. As these fields were not intended to be part of the image configuration response, they are deprecated, and will be removed from the API.\n\nThe following fields are currently included in the API response, but are not part of the underlying image's Config, and deprecated:\n\n*   `Hostname`\n*   `Domainname`\n*   `AttachStdin`\n*   `AttachStdout`\n*   `AttachStderr`\n*   `Tty`\n*   `OpenStdin`\n*   `StdinOnce`\n*   `Image`\n*   `NetworkDisabled` (already omitted unless set)\n*   `MacAddress` (already omitted unless set)\n*   `StopTimeout` (already omitted unless set)\n\n*   `POST /services/create` and `POST /services/{id}/update` now support OomScoreAdj\n\n[Docker Engine API v1.45](https://docs.docker.com/engine/api/v1.45/) documentation\n\n*   `POST /containers/create` now supports `VolumeOptions.Subpath` which allows a subpath of a named volume to be mounted.\n*   `POST /images/search` will always assume a `false` value for the `is-automated` field. Consequently, searching for `is-automated=true` will yield no results, while `is-automated=false` will be a no-op.\n*   `GET /images/{name}/json` no longer includes the `Container` and `ContainerConfig` fields. To access image configuration, use `Config` field instead.\n*   The `Aliases` field returned in calls to `GET /containers/{name:.*}/json` no longer contains the short container ID, but instead will reflect exactly the values originally submitted to the `POST /containers/create` endpoint. The newly introduced `DNSNames` should now be used instead when short container IDs are needed.\n\n[Docker Engine API v1.44](https://docs.docker.com/engine/api/v1.44/) documentation\n\n*   GET `/images/json` now accepts an `until` filter. This accepts a timestamp and lists all images created before it. The `<timestamp>` can be Unix timestamps, date formatted timestamps, or Go duration strings (e.g. `10m`, `1h30m`) computed relative to the daemon machineâ€™s time. This change is not versioned, and affects all API versions if the daemon has this patch.\n*   The `VirtualSize` field in the `GET /images/{name}/json`, `GET /images/json`, and `GET /system/df` responses is now omitted. Use the `Size` field instead, which contains the same information.\n*   Deprecated: The `is_automated` field in the `GET /images/search` response has been deprecated and will always be set to false in the future because Docker Hub is deprecating the `is_automated` field in its search API. The deprecation is not versioned, and applies to all API versions.\n*   Deprecated: The `is-automated` filter for the `GET /images/search` endpoint. The `is_automated` field has been deprecated by Docker Hub's search API. Consequently, searching for `is-automated=true` will yield no results. The deprecation is not versioned, and applies to all API versions.\n*   Read-only bind mounts are now made recursively read-only on kernel >= 5.12 with runtimes which support the feature. `POST /containers/create`, `GET /containers/{id}/json`, and `GET /containers/json` now supports `BindOptions.ReadOnlyNonRecursive` and `BindOptions.ReadOnlyForceRecursive` to customize the behavior.\n*   `POST /containers/create` now accepts a `HealthConfig.StartInterval` to set the interval for health checks during the start period.\n*   `GET /info` now includes a `CDISpecDirs` field indicating the configured CDI specifications directories. The use of the applied setting requires the daemon to have expermental enabled, and for non-experimental daemons an empty list is always returned.\n*   `POST /networks/create` now returns a 400 if the `IPAMConfig` has invalid values. Note that this change is _unversioned_ and applied to all API versions on daemon that support version 1.44.\n*   `POST /networks/create` with a duplicated name now fails systematically. As such, the `CheckDuplicate` field is now deprecated. Note that this change is _unversioned_ and applied to all API versions on daemon that support version 1.44.\n*   `POST /containers/create` now accepts multiple `EndpointSettings` in `NetworkingConfig.EndpointSettings`.\n*   `POST /containers/create` and `POST /networks/{id}/connect` will now catch validation errors that were previously only returned during `POST /containers/{id}/start`. These endpoints will also return the full set of validation errors they find, instead of returning only the first one. Note that this change is _unversioned_ and applies to all API versions.\n*   `POST /services/create` and `POST /services/{id}/update` now accept `Seccomp` and `AppArmor` fields in the `ContainerSpec.Privileges` object. This allows some configuration of Seccomp and AppArmor in Swarm services.\n*   A new endpoint-specific `MacAddress` field has been added to `NetworkSettings.EndpointSettings` on `POST /containers/create`, and to `EndpointConfig` on `POST /networks/{id}/connect`. The container-wide `MacAddress` field in `Config`, on `POST /containers/create`, is now deprecated.\n*   The field `Networks` in the `POST /services/create` and `POST /services/{id}/update` requests is now deprecated. You should instead use the field `TaskTemplate.Networks`.\n*   The `Container` and `ContainerConfig` fields in the `GET /images/{name}/json` response are deprecated and will no longer be included in API v1.45.\n*   `GET /info` now includes `status` properties in `Runtimes`.\n*   A new field named `DNSNames` and containing all non-fully qualified DNS names a container takes on a specific network has been added to `GET /containers/{name:.*}/json`.\n*   The `Aliases` field returned in calls to `GET /containers/{name:.*}/json` in v1.44 and older versions contains the short container ID. This will change in the next API version, v1.45. Starting with that API version, this specific value will be removed from the `Aliases` field such that this field will reflect exactly the values originally submitted to the `POST /containers/create` endpoint. The newly introduced `DNSNames` should now be used instead.\n*   The fields `HairpinMode`, `LinkLocalIPv6Address`, `LinkLocalIPv6PrefixLen`, `SecondaryIPAddresses`, `SecondaryIPv6Addresses` available in `NetworkSettings` when calling `GET /containers/{id}/json` are deprecated and will be removed in a future release. You should instead look for the default network in `NetworkSettings.Networks`.\n*   `GET /images/{id}/json` omits the `Created` field (previously it was `0001-01-01T00:00:00Z`) if the `Created` field is missing from the image config.\n\n[Docker Engine API v1.43](https://docs.docker.com/engine/api/v1.43/) documentation\n\n*   `POST /containers/create` now accepts `Annotations` as part of `HostConfig`. Can be used to attach arbitrary metadata to the container, which will also be passed to the runtime when the container is started.\n*   `GET /images/json` no longer includes hardcoded `<none>:<none>` and `<none>@<none>` in `RepoTags` and`RepoDigests` for untagged images. In such cases, empty arrays will be produced instead.\n*   The `VirtualSize` field in the `GET /images/{name}/json`, `GET /images/json`, and `GET /system/df` responses is deprecated and will no longer be included in API v1.44. Use the `Size` field instead, which contains the same information.\n*   `GET /info` now includes `no-new-privileges` in the `SecurityOptions` string list when this option is enabled globally. This change is not versioned, and affects all API versions if the daemon has this patch.\n\n[Docker Engine API v1.42](https://docs.docker.com/engine/api/v1.42/) documentation\n\n*   Removed the `BuilderSize` field on the `GET /system/df` endpoint. This field was introduced in API 1.31 as part of an experimental feature, and no longer used since API 1.40. Use field `BuildCache` instead to track storage used by the builder component.\n    \n*   `POST /containers/{id}/stop` and `POST /containers/{id}/restart` now accept a `signal` query parameter, which allows overriding the container's default stop- signal.\n    \n*   `GET /images/json` now accepts query parameter `shared-size`. When set `true`, images returned will include `SharedSize`, which provides the size on disk shared with other images present on the system.\n    \n*   `GET /system/df` now accepts query parameter `type`. When set, computes and returns data only for the specified object type. The parameter can be specified multiple times to select several object types. Supported values are: `container`, `image`, `volume`, `build-cache`.\n    \n*   `GET /system/df` can now be used concurrently. If a request is made while a previous request is still being processed, the request will receive the result of the already running calculation, once completed. Previously, an error (`a disk usage operation is already running`) would be returned in this situation. This change is not versioned, and affects all API versions if the daemon has this patch.\n    \n*   The `POST /images/create` now supports both the operating system and architecture that is passed through the `platform` query parameter when using the `fromSrc` option to import an image from an archive. Previously, only the operating system was used and the architecture was ignored. If no `platform` option is set, the host's operating system and architecture as used as default. This change is not versioned, and affects all API versions if the daemon has this patch.\n    \n*   The `POST /containers/{id}/wait` endpoint now returns a `400` status code if an invalid `condition` is provided (on API 1.30 and up).\n    \n*   Removed the `KernelMemory` field from the `POST /containers/create` and `POST /containers/{id}/update` endpoints, any value it is set to will be ignored on API version `v1.42` and up. Older API versions still accept this field, but may take no effect, depending on the kernel version and OCI runtime in use.\n    \n*   `GET /containers/{id}/json` now omits the `KernelMemory` and `KernelMemoryTCP` if they are not set.\n    \n*   `GET /info` now omits the `KernelMemory` and `KernelMemoryTCP` if they are not supported by the host or host's configuration (if cgroups v2 are in use).\n    \n*   `GET /_ping` and `HEAD /_ping` now return `Builder-Version` by default. This header contains the default builder to use, and is a recommendation as advertised by the daemon. However, it is up to the client to choose which builder to use.\n    \n    The default value on Linux is version \"2\" (BuildKit), but the daemon can be configured to recommend version \"1\" (classic Builder). Windows does not yet support BuildKit for native Windows images, and uses \"1\" (classic builder) as a default.\n    \n    This change is not versioned, and affects all API versions if the daemon has this patch.\n    \n*   `GET /_ping` and `HEAD /_ping` now return a `Swarm` header, which allows a client to detect if Swarm is enabled on the daemon, without having to call additional endpoints. This change is not versioned, and affects all API versions if the daemon has this patch. Clients must consider this header \"optional\", and fall back to using other endpoints to get this information if the header is not present.\n    \n    The `Swarm` header can contain one of the following values:\n    \n    *   \"inactive\"\n    *   \"pending\"\n    *   \"error\"\n    *   \"locked\"\n    *   \"active/worker\"\n    *   \"active/manager\"\n*   `POST /containers/create` for Windows containers now accepts a new syntax in `HostConfig.Resources.Devices.PathOnHost`. As well as the existing `class/<GUID>` syntax, `<IDType>://<ID>` is now recognised. Support for specific `<IDType>` values depends on the underlying implementation and Windows version. This change is not versioned, and affects all API versions if the daemon has this patch.\n    \n*   `GET /containers/{id}/attach`, `GET /exec/{id}/start`, `GET /containers/{id}/logs` `GET /services/{id}/logs` and `GET /tasks/{id}/logs` now set Content-Type header to `application/vnd.docker.multiplexed-stream` when a multiplexed stdout/stderr stream is sent to client, `application/vnd.docker.raw-stream` otherwise.\n    \n*   `POST /volumes/create` now accepts a new `ClusterVolumeSpec` to create a cluster volume (CNI). This option can only be used if the daemon is a Swarm manager. The Volume response on creation now also can contain a `ClusterVolume` field with information about the created volume.\n    \n*   The `BuildCache.Parent` field, as returned by `GET /system/df` is deprecated and is now omitted. API versions before v1.42 continue to include this field.\n    \n*   `GET /system/df` now includes a new `Parents` field, for \"build-cache\" records, which contains a list of parent IDs for the build-cache record.\n    \n*   Volume information returned by `GET /volumes/{name}`, `GET /volumes` and `GET /system/df` can now contain a `ClusterVolume` if the volume is a cluster volume (requires the daemon to be a Swarm manager).\n    \n*   The `Volume` type, as returned by `Added new` ClusterVolume\\` fields\n    \n*   Added a new `PUT /volumes{name}` endpoint to update cluster volumes (CNI). Cluster volumes are only supported if the daemon is a Swarm manager.\n    \n*   `GET /containers/{name}/attach/ws` endpoint now accepts `stdin`, `stdout` and `stderr` query parameters to only attach to configured streams.\n    \n    NOTE: These parameters were documented before in older API versions, but not actually supported. API versions before v1.42 continue to ignore these parameters and default to attaching to all streams. To preserve the pre-v1.42 behavior, set all three query parameters (`?stdin=1,stdout=1,stderr=1`).\n    \n*   `POST /containers/create` on Linux now respects the `HostConfig.ConsoleSize` property. Container is immediately created with the desired terminal size and clients no longer need to set the desired size on their own.\n    \n*   `POST /containers/create` allow to set `CreateMountpoint` for host path to be created if missing. This brings parity with `Binds`\n    \n*   `POST /containers/create` rejects request if BindOptions|VolumeOptions|TmpfsOptions is set with a non-matching mount Type.\n    \n*   `POST /containers/{id}/exec` now accepts an optional `ConsoleSize` parameter. It allows to set the console size of the executed process immediately when it's created.\n    \n*   `POST /volumes/prune` will now only prune \"anonymous\" volumes (volumes which were not given a name) by default. A new filter parameter `all` can be set to a truth-y value (`true`, `1`) to get the old behavior.\n    \n\n[Docker Engine API v1.41](https://docs.docker.com/engine/api/v1.41/) documentation\n\n*   `GET /events` now returns `prune` events after pruning resources have completed. Prune events are returned for `container`, `network`, `volume`, `image`, and `builder`, and have a `reclaimed` attribute, indicating the amount of space reclaimed (in bytes).\n    \n*   `GET /info` now returns a `CgroupVersion` field, containing the cgroup version.\n    \n*   `GET /info` now returns a `DefaultAddressPools` field, containing a list of custom default address pools for local networks, which can be specified in the `daemon.json` file or `--default-address-pool` dockerd option.\n    \n*   `POST /services/create` and `POST /services/{id}/update` now supports `BindOptions.NonRecursive`.\n    \n*   The `ClusterStore` and `ClusterAdvertise` fields in `GET /info` are deprecated and are now omitted if they contain an empty value. This change is not versioned, and affects all API versions if the daemon has this patch.\n    \n*   The `filter` (singular) query parameter, which was deprecated in favor of the `filters` option in Docker 1.13, has now been removed from the `GET /images/json` endpoint. The parameter remains available when using API version 1.40 or below.\n    \n*   `GET /services` now returns `CapAdd` and `CapDrop` as part of the `ContainerSpec`.\n    \n*   `GET /services/{id}` now returns `CapAdd` and `CapDrop` as part of the `ContainerSpec`.\n    \n*   `POST /services/create` now accepts `CapAdd` and `CapDrop` as part of the `ContainerSpec`.\n    \n*   `POST /services/{id}/update` now accepts `CapAdd` and `CapDrop` as part of the `ContainerSpec`.\n    \n*   `GET /tasks` now returns `CapAdd` and `CapDrop` as part of the `ContainerSpec`.\n    \n*   `GET /tasks/{id}` now returns `CapAdd` and `CapDrop` as part of the `ContainerSpec`.\n    \n*   `GET /services` now returns `Pids` in `TaskTemplate.Resources.Limits`.\n    \n*   `GET /services/{id}` now returns `Pids` in `TaskTemplate.Resources.Limits`.\n    \n*   `POST /services/create` now accepts `Pids` in `TaskTemplate.Resources.Limits`.\n    \n*   `POST /services/{id}/update` now accepts `Pids` in `TaskTemplate.Resources.Limits` to limit the maximum number of PIDs.\n    \n*   `GET /tasks` now returns `Pids` in `TaskTemplate.Resources.Limits`.\n    \n*   `GET /tasks/{id}` now returns `Pids` in `TaskTemplate.Resources.Limits`.\n    \n*   `POST /containers/create` now accepts a `platform` query parameter in the format `os[/arch[/variant]]`.\n    \n    When set, the daemon checks if the requested image is present in the local image cache with the given OS and Architecture, and otherwise returns a `404` status.\n    \n    If the option is _not_ set, the host's native OS and Architecture are used to look up the image in the image cache. However, if no platform is passed and the given image _does_ exist in the local image cache, but its OS or architecture do not match, the container is created with the available image, and a warning is added to the `Warnings` field in the response, for example;\n    \n    ```\n    WARNING: The requested image's platform (linux/arm64/v8) does not\n             match the detected host platform (linux/amd64) and no\n             specific platform was requested\n    ```\n    \n*   `POST /containers/create` on Linux now accepts the `HostConfig.CgroupnsMode` property. Set the property to `host` to create the container in the daemon's cgroup namespace, or `private` to create the container in its own private cgroup namespace. The per-daemon default is `host`, and can be changed by using the`CgroupNamespaceMode` daemon configuration parameter.\n    \n*   `GET /info` now returns an `OSVersion` field, containing the operating system's version. This change is not versioned, and affects all API versions if the daemon has this patch.\n    \n*   `GET /info` no longer returns the `SystemStatus` field if it does not have a value set. This change is not versioned, and affects all API versions if the daemon has this patch.\n    \n*   `GET /services` now accepts query parameter `status`. When set `true`, services returned will include `ServiceStatus`, which provides Desired, Running, and Completed task counts for the service.\n    \n*   `GET /services` may now include `ReplicatedJob` or `GlobalJob` as the `Mode` in a `ServiceSpec`.\n    \n*   `GET /services/{id}` may now include `ReplicatedJob` or `GlobalJob` as the `Mode` in a `ServiceSpec`.\n    \n*   `POST /services/create` now accepts `ReplicatedJob or` GlobalJob`as the`Mode`in the`ServiceSpec.\n    \n*   `POST /services/{id}/update` accepts updating the fields of the `ReplicatedJob` object in the `ServiceSpec.Mode`. The service mode still cannot be changed, however.\n    \n*   `GET /services` now includes `JobStatus` on Services with mode `ReplicatedJob` or `GlobalJob`.\n    \n*   `GET /services/{id}` now includes `JobStatus` on Services with mode `ReplicatedJob` or `GlobalJob`.\n    \n*   `GET /tasks` now includes `JobIteration` on Tasks spawned from a job-mode service.\n    \n*   `GET /tasks/{id}` now includes `JobIteration` on the task if spawned from a job-mode service.\n    \n*   `GET /containers/{id}/stats` now accepts a query param (`one-shot`) which, when used with `stream=false` fetches a single set of stats instead of waiting for two collection cycles to have 2 CPU stats over a 1 second period.\n    \n*   The `KernelMemory` field in `HostConfig.Resources` is now deprecated.\n    \n*   The `KernelMemory` field in `Info` is now deprecated.\n    \n*   `GET /services` now returns `Ulimits` as part of `ContainerSpec`.\n    \n*   `GET /services/{id}` now returns `Ulimits` as part of `ContainerSpec`.\n    \n*   `POST /services/create` now accepts `Ulimits` as part of `ContainerSpec`.\n    \n*   `POST /services/{id}/update` now accepts `Ulimits` as part of `ContainerSpec`.\n    \n\n[Docker Engine API v1.40](https://docs.docker.com/engine/api/v1.40/) documentation\n\n*   The `/_ping` endpoint can now be accessed both using `GET` or `HEAD` requests. when accessed using a `HEAD` request, all headers are returned, but the body is empty (`Content-Length: 0`). This change is not versioned, and affects all API versions if the daemon has this patch. Clients are recommended to try using `HEAD`, but fallback to `GET` if the `HEAD` requests fails.\n*   `GET /_ping` and `HEAD /_ping` now set `Cache-Control` and `Pragma` headers to prevent the result from being cached. This change is not versioned, and affects all API versions if the daemon has this patch.\n*   `GET /services` now returns `Sysctls` as part of the `ContainerSpec`.\n*   `GET /services/{id}` now returns `Sysctls` as part of the `ContainerSpec`.\n*   `POST /services/create` now accepts `Sysctls` as part of the `ContainerSpec`.\n*   `POST /services/{id}/update` now accepts `Sysctls` as part of the `ContainerSpec`.\n*   `POST /services/create` now accepts `Config` as part of `ContainerSpec.Privileges.CredentialSpec`.\n*   `POST /services/{id}/update` now accepts `Config` as part of `ContainerSpec.Privileges.CredentialSpec`.\n*   `POST /services/create` now includes `Runtime` as an option in `ContainerSpec.Configs`\n*   `POST /services/{id}/update` now includes `Runtime` as an option in `ContainerSpec.Configs`\n*   `GET /tasks` now returns `Sysctls` as part of the `ContainerSpec`.\n*   `GET /tasks/{id}` now returns `Sysctls` as part of the `ContainerSpec`.\n*   `GET /networks` now supports a `dangling` filter type. When set to `true` (or `1`), the endpoint returns all networks that are not in use by a container. When set to `false` (or `0`), only networks that are in use by one or more containers are returned.\n*   `GET /nodes` now supports a filter type `node.label` filter to filter nodes based on the node.label. The format of the label filter is `node.label=<key>`/`node.label=<key>=<value>` to return those with the specified labels, or `node.label!=<key>`/`node.label!=<key>=<value>` to return those without the specified labels.\n*   `POST /containers/create` now accepts a `fluentd-async` option in `HostConfig.LogConfig.Config` when using the Fluentd logging driver. This option deprecates the `fluentd-async-connect` option, which remains funtional, but will be removed in a future release. Users are encouraged to use the `fluentd-async` option going forward. This change is not versioned, and affects all API versions if the daemon has this patch.\n*   `POST /containers/create` now accepts a `fluentd-request-ack` option in `HostConfig.LogConfig.Config` when using the Fluentd logging driver. If enabled, the Fluentd logging driver sends the chunk option with a unique ID. The server will respond with an acknowledgement. This option improves the reliability of the message transmission. This change is not versioned, and affects all API versions if the daemon has this patch.\n*   `POST /containers/create`, `GET /containers/{id}/json`, and `GET /containers/json` now supports `BindOptions.NonRecursive`.\n*   `POST /swarm/init` now accepts a `DataPathPort` property to set data path port number.\n*   `GET /info` now returns information about `DataPathPort` that is currently used in swarm\n*   `GET /info` now returns `PidsLimit` boolean to indicate if the host kernel has PID limit support enabled.\n*   `GET /info` now includes `name=rootless` in `SecurityOptions` when the daemon is running in rootless mode. This change is not versioned, and affects all API versions if the daemon has this patch.\n*   `GET /info` now returns `none` as `CgroupDriver` when the daemon is running in rootless mode. This change is not versioned, and affects all API versions if the daemon has this patch.\n*   `POST /containers/create` now accepts `DeviceRequests` as part of `HostConfig`. Can be used to set Nvidia GPUs.\n*   `GET /swarm` endpoint now returns DataPathPort info\n*   `POST /containers/create` now takes `KernelMemoryTCP` field to set hard limit for kernel TCP buffer memory.\n*   `GET /service` now returns `MaxReplicas` as part of the `Placement`.\n*   `GET /service/{id}` now returns `MaxReplicas` as part of the `Placement`.\n*   `POST /service/create` and `POST /services/(id or name)/update` now take the field `MaxReplicas` as part of the service `Placement`, allowing to specify maximum replicas per node for the service.\n*   `POST /containers/create` on Linux now creates a container with `HostConfig.IpcMode=private` by default, if IpcMode is not explicitly specified. The per-daemon default can be changed back to `shareable` by using `DefaultIpcMode` daemon configuration parameter.\n*   `POST /containers/{id}/update` now accepts a `PidsLimit` field to tune a container's PID limit. Set `0` or `-1` for unlimited. Leave `null` to not change the current value.\n*   `POST /build` now accepts `outputs` key for configuring build outputs when using BuildKit mode.\n\n[Docker Engine API v1.39](https://docs.docker.com/engine/api/v1.39/) documentation\n\n*   `GET /info` now returns an empty string, instead of `<unknown>` for `KernelVersion` and `OperatingSystem` if the daemon was unable to obtain this information.\n*   `GET /info` now returns information about the product license, if a license has been applied to the daemon.\n*   `GET /info` now returns a `Warnings` field, containing warnings and informational messages about missing features, or issues related to the daemon configuration.\n*   `POST /swarm/init` now accepts a `DefaultAddrPool` property to set global scope default address pool\n*   `POST /swarm/init` now accepts a `SubnetSize` property to set global scope networks by giving the length of the subnet masks for every such network\n*   `POST /session` (added in [V1.31](#v131-api-changes) is no longer experimental. This endpoint can be used to run interactive long-running protocols between the client and the daemon.\n\n[Docker Engine API v1.38](https://docs.docker.com/engine/api/v1.38/) documentation\n\n*   `GET /tasks` and `GET /tasks/{id}` now return a `NetworkAttachmentSpec` field, containing the `ContainerID` for non-service containers connected to \"attachable\" swarm-scoped networks.\n\n[Docker Engine API v1.37](https://docs.docker.com/engine/api/v1.37/) documentation\n\n*   `POST /containers/create` and `POST /services/create` now supports exposing SCTP ports.\n*   `POST /configs/create` and `POST /configs/{id}/create` now accept a `Templating` driver.\n*   `GET /configs` and `GET /configs/{id}` now return the `Templating` driver of the config.\n*   `POST /secrets/create` and `POST /secrets/{id}/create` now accept a `Templating` driver.\n*   `GET /secrets` and `GET /secrets/{id}` now return the `Templating` driver of the secret.\n\n[Docker Engine API v1.36](https://docs.docker.com/engine/api/v1.36/) documentation\n\n*   `Get /events` now return `exec_die` event when an exec process terminates.\n\n[Docker Engine API v1.35](https://docs.docker.com/engine/api/v1.35/) documentation\n\n*   `POST /services/create` and `POST /services/(id)/update` now accepts an `Isolation` field on container spec to set the Isolation technology of the containers running the service (`default`, `process`, or `hyperv`). This configuration is only used for Windows containers.\n*   `GET /containers/(name)/logs` now supports an additional query parameter: `until`, which returns log lines that occurred before the specified timestamp.\n*   `POST /containers/{id}/exec` now accepts a `WorkingDir` property to set the work-dir for the exec process, independent of the container's work-dir.\n*   `Get /version` now returns a `Platform.Name` field, which can be used by products using Moby as a foundation to return information about the platform.\n*   `Get /version` now returns a `Components` field, which can be used to return information about the components used. Information about the engine itself is now included as a \"Component\" version, and contains all information from the top-level `Version`, `GitCommit`, `APIVersion`, `MinAPIVersion`, `GoVersion`, `Os`, `Arch`, `BuildTime`, `KernelVersion`, and `Experimental` fields. Going forward, the information from the `Components` section is preferred over their top-level counterparts.\n\n[Docker Engine API v1.34](https://docs.docker.com/engine/api/v1.34/) documentation\n\n*   `POST /containers/(name)/wait?condition=removed` now also also returns in case of container removal failure. A pointer to a structure named `Error` added to the response JSON in order to indicate a failure. If `Error` is `null`, container removal has succeeded, otherwise the test of an error message indicating why container removal has failed is available from `Error.Message` field.\n\n[Docker Engine API v1.33](https://docs.docker.com/engine/api/v1.33/) documentation\n\n*   `GET /events` now supports filtering 4 more kinds of events: `config`, `node`, `secret` and `service`.\n\n[Docker Engine API v1.32](https://docs.docker.com/engine/api/v1.32/) documentation\n\n*   `POST /images/create` now accepts a `platform` parameter in the form of `os[/arch[/variant]]`.\n*   `POST /containers/create` now accepts additional values for the `HostConfig.IpcMode` property. New values are `private`, `shareable`, and `none`.\n*   `DELETE /networks/{id or name}` fixed issue where a `name` equal to another network's name was able to mask that `id`. If both a network with the given _name_ exists, and a network with the given _id_, the network with the given _id_ is now deleted. This change is not versioned, and affects all API versions if the daemon has this patch.\n\n[Docker Engine API v1.31](https://docs.docker.com/engine/api/v1.31/) documentation\n\n*   `DELETE /secrets/(name)` now returns status code 404 instead of 500 when the secret does not exist.\n*   `POST /secrets/create` now returns status code 409 instead of 500 when creating an already existing secret.\n*   `POST /secrets/create` now accepts a `Driver` struct, allowing the `Name` and driver-specific `Options` to be passed to store a secrets in an external secrets store. The `Driver` property can be omitted if the default (internal) secrets store is used.\n*   `GET /secrets/(id)` and `GET /secrets` now return a `Driver` struct, containing the `Name` and driver-specific `Options` of the external secrets store used to store the secret. The `Driver` property is omitted if no external store is used.\n*   `POST /secrets/(name)/update` now returns status code 400 instead of 500 when updating a secret's content which is not the labels.\n*   `POST /nodes/(name)/update` now returns status code 400 instead of 500 when demoting last node fails.\n*   `GET /networks/(id or name)` now takes an optional query parameter `scope` that will filter the network based on the scope (`local`, `swarm`, or `global`).\n*   `POST /session` is a new endpoint that can be used for running interactive long-running protocols between client and the daemon. This endpoint is experimental and only available if the daemon is started with experimental features enabled.\n*   `GET /images/(name)/get` now includes an `ImageMetadata` field which contains image metadata that is local to the engine and not part of the image config.\n*   `POST /services/create` now accepts a `PluginSpec` when `TaskTemplate.Runtime` is set to `plugin`\n*   `GET /events` now supports config events `create`, `update` and `remove` that are emitted when users create, update or remove a config\n*   `GET /volumes/` and `GET /volumes/{name}` now return a `CreatedAt` field, containing the date/time the volume was created. This field is omitted if the creation date/time for the volume is unknown. For volumes with scope \"global\", this field represents the creation date/time of the local _instance_ of the volume, which may differ from instances of the same volume on different nodes.\n*   `GET /system/df` now returns a `CreatedAt` field for `Volumes`. Refer to the `/volumes/` endpoint for a description of this field.\n\n[Docker Engine API v1.30](https://docs.docker.com/engine/api/v1.30/) documentation\n\n*   `GET /info` now returns the list of supported logging drivers, including plugins.\n*   `GET /info` and `GET /swarm` now returns the cluster-wide swarm CA info if the node is in a swarm: the cluster root CA certificate, and the cluster TLS leaf certificate issuer's subject and public key. It also displays the desired CA signing certificate, if any was provided as part of the spec.\n*   `POST /build/` now (when not silent) produces an `Aux` message in the JSON output stream with payload `types.BuildResult` for each image produced. The final such message will reference the image resulting from the build.\n*   `GET /nodes` and `GET /nodes/{id}` now returns additional information about swarm TLS info if the node is part of a swarm: the trusted root CA, and the issuer's subject and public key.\n*   `GET /distribution/(name)/json` is a new endpoint that returns a JSON output stream with payload `types.DistributionInspect` for an image name. It includes a descriptor with the digest, and supported platforms retrieved from directly contacting the registry.\n*   `POST /swarm/update` now accepts 3 additional parameters as part of the swarm spec's CA configuration; the desired CA certificate for the swarm, the desired CA key for the swarm (if not using an external certificate), and an optional parameter to force swarm to generate and rotate to a new CA certificate/key pair.\n*   `POST /service/create` and `POST /services/(id or name)/update` now take the field `Platforms` as part of the service `Placement`, allowing to specify platforms supported by the service.\n*   `POST /containers/(name)/wait` now accepts a `condition` query parameter to indicate which state change condition to wait for. Also, response headers are now returned immediately to acknowledge that the server has registered a wait callback for the client.\n*   `POST /swarm/init` now accepts a `DataPathAddr` property to set the IP-address or network interface to use for data traffic\n*   `POST /swarm/join` now accepts a `DataPathAddr` property to set the IP-address or network interface to use for data traffic\n*   `GET /events` now supports service, node and secret events which are emitted when users create, update and remove service, node and secret\n*   `GET /events` now supports network remove event which is emitted when users remove a swarm scoped network\n*   `GET /events` now supports a filter type `scope` in which supported value could be swarm and local\n*   `PUT /containers/(name)/archive` now accepts a `copyUIDGID` parameter to allow copy UID/GID maps to dest file or dir.\n\n[Docker Engine API v1.29](https://docs.docker.com/engine/api/v1.29/) documentation\n\n*   `DELETE /networks/(name)` now allows to remove the ingress network, the one used to provide the routing-mesh.\n*   `POST /networks/create` now supports creating the ingress network, by specifying an `Ingress` boolean field. As of now this is supported only when using the overlay network driver.\n*   `GET /networks/(name)` now returns an `Ingress` field showing whether the network is the ingress one.\n*   `GET /networks/` now supports a `scope` filter to filter networks based on the network mode (`swarm`, `global`, or `local`).\n*   `POST /containers/create`, `POST /service/create` and `POST /services/(id or name)/update` now takes the field `StartPeriod` as a part of the `HealthConfig` allowing for specification of a period during which the container should not be considered unhealthy even if health checks do not pass.\n*   `GET /services/(id)` now accepts an `insertDefaults` query-parameter to merge default values into the service inspect output.\n*   `POST /containers/prune`, `POST /images/prune`, `POST /volumes/prune`, and `POST /networks/prune` now support a `label` filter to filter containers, images, volumes, or networks based on the label. The format of the label filter could be `label=<key>`/`label=<key>=<value>` to remove those with the specified labels, or `label!=<key>`/`label!=<key>=<value>` to remove those without the specified labels.\n*   `POST /services/create` now accepts `Privileges` as part of `ContainerSpec`. Privileges currently include `CredentialSpec` and `SELinuxContext`.\n\n[Docker Engine API v1.28](https://docs.docker.com/engine/api/v1.28/) documentation\n\n*   `POST /containers/create` now includes a `Consistency` field to specify the consistency level for each `Mount`, with possible values `default`, `consistent`, `cached`, or `delegated`.\n*   `GET /containers/create` now takes a `DeviceCgroupRules` field in `HostConfig` allowing to set custom device cgroup rules for the created container.\n*   Optional query parameter `verbose` for `GET /networks/(id or name)` will now list all services with all the tasks, including the non-local tasks on the given network.\n*   `GET /containers/(id or name)/attach/ws` now returns WebSocket in binary frame format for API version >= v1.28, and returns WebSocket in text frame format for API version< v1.28, for the purpose of backward-compatibility.\n*   `GET /networks` is optimised only to return list of all networks and network specific information. List of all containers attached to a specific network is removed from this API and is only available using the network specific `GET /networks/{network-id}`.\n*   `GET /containers/json` now supports `publish` and `expose` filters to filter containers that expose or publish certain ports.\n*   `POST /services/create` and `POST /services/(id or name)/update` now accept the `ReadOnly` parameter, which mounts the container's root filesystem as read only.\n*   `POST /build` now accepts `extrahosts` parameter to specify a host to ip mapping to use during the build.\n*   `POST /services/create` and `POST /services/(id or name)/update` now accept a `rollback` value for `FailureAction`.\n*   `POST /services/create` and `POST /services/(id or name)/update` now accept an optional `RollbackConfig` object which specifies rollback options.\n*   `GET /services` now supports a `mode` filter to filter services based on the service mode (either `global` or `replicated`).\n*   `POST /containers/(name)/update` now supports updating `NanoCpus` that represents CPU quota in units of 10\\-9 CPUs.\n*   `POST /plugins/{name}/disable` now accepts a `force` query-parameter to disable a plugin even if still in use.\n\n[Docker Engine API v1.27](https://docs.docker.com/engine/api/v1.27/) documentation\n\n*   `GET /containers/(id or name)/stats` now includes an `online_cpus` field in both `precpu_stats` and `cpu_stats`. If this field is `nil` then for compatibility with older daemons the length of the corresponding `cpu_usage.percpu_usage` array should be used.\n\n[Docker Engine API v1.26](https://docs.docker.com/engine/api/v1.26/) documentation\n\n*   `POST /plugins/(plugin name)/upgrade` upgrade a plugin.\n\n[Docker Engine API v1.25](https://docs.docker.com/engine/api/v1.25/) documentation\n\n*   The API version is now required in all API calls. Instead of just requesting, for example, the URL `/containers/json`, you must now request `/v1.25/containers/json`.\n*   `GET /version` now returns `MinAPIVersion`.\n*   `POST /build` accepts `networkmode` parameter to specify network used during build.\n*   `GET /images/(name)/json` now returns `OsVersion` if populated\n*   `GET /images/(name)/json` no longer contains the `RootFS.BaseLayer` field. This field was used for Windows images that used a base-image that was pre-installed on the host (`RootFS.Type` `layers+base`), which is no longer supported, and the `RootFS.BaseLayer` field has been removed.\n*   `GET /info` now returns `Isolation`.\n*   `POST /containers/create` now takes `AutoRemove` in HostConfig, to enable auto-removal of the container on daemon side when the container's process exits.\n*   `GET /containers/json` and `GET /containers/(id or name)/json` now return `\"removing\"` as a value for the `State.Status` field if the container is being removed. Previously, \"exited\" was returned as status.\n*   `GET /containers/json` now accepts `removing` as a valid value for the `status` filter.\n*   `GET /containers/json` now supports filtering containers by `health` status.\n*   `DELETE /volumes/(name)` now accepts a `force` query parameter to force removal of volumes that were already removed out of band by the volume driver plugin.\n*   `POST /containers/create/` and `POST /containers/(name)/update` now validates restart policies.\n*   `POST /containers/create` now validates IPAMConfig in NetworkingConfig, and returns error for invalid IPv4 and IPv6 addresses (`--ip` and `--ip6` in `docker create/run`).\n*   `POST /containers/create` now takes a `Mounts` field in `HostConfig` which replaces `Binds`, `Volumes`, and `Tmpfs`. _note_: `Binds`, `Volumes`, and `Tmpfs` are still available and can be combined with `Mounts`.\n*   `POST /build` now performs a preliminary validation of the `Dockerfile` before starting the build, and returns an error if the syntax is incorrect. Note that this change is _unversioned_ and applied to all API versions.\n*   `POST /build` accepts `cachefrom` parameter to specify images used for build cache.\n*   `GET /networks/` endpoint now correctly returns a list of _all_ networks, instead of the default network if a trailing slash is provided, but no `name` or `id`.\n*   `DELETE /containers/(name)` endpoint now returns an error of `removal of container name is already in progress` with status code of 400, when container name is in a state of removal in progress.\n*   `GET /containers/json` now supports a `is-task` filter to filter containers that are tasks (part of a service in swarm mode).\n*   `POST /containers/create` now takes `StopTimeout` field.\n*   `POST /services/create` and `POST /services/(id or name)/update` now accept `Monitor` and `MaxFailureRatio` parameters, which control the response to failures during service updates.\n*   `POST /services/(id or name)/update` now accepts a `ForceUpdate` parameter inside the `TaskTemplate`, which causes the service to be updated even if there are no changes which would ordinarily trigger an update.\n*   `POST /services/create` and `POST /services/(id or name)/update` now return a `Warnings` array.\n*   `GET /networks/(name)` now returns field `Created` in response to show network created time.\n*   `POST /containers/(id or name)/exec` now accepts an `Env` field, which holds a list of environment variables to be set in the context of the command execution.\n*   `GET /volumes`, `GET /volumes/(name)`, and `POST /volumes/create` now return the `Options` field which holds the driver specific options to use for when creating the volume.\n*   `GET /exec/(id)/json` now returns `Pid`, which is the system pid for the exec'd process.\n*   `POST /containers/prune` prunes stopped containers.\n*   `POST /images/prune` prunes unused images.\n*   `POST /volumes/prune` prunes unused volumes.\n*   `POST /networks/prune` prunes unused networks.\n*   Every API response now includes a `Docker-Experimental` header specifying if experimental features are enabled (value can be `true` or `false`).\n*   Every API response now includes a `API-Version` header specifying the default API version of the server.\n*   The `hostConfig` option now accepts the fields `CpuRealtimePeriod` and `CpuRtRuntime` to allocate cpu runtime to rt tasks when `CONFIG_RT_GROUP_SCHED` is enabled in the kernel.\n*   The `SecurityOptions` field within the `GET /info` response now includes `userns` if user namespaces are enabled in the daemon.\n*   `GET /nodes` and `GET /node/(id or name)` now return `Addr` as part of a node's `Status`, which is the address that that node connects to the manager from.\n*   The `HostConfig` field now includes `NanoCpus` that represents CPU quota in units of 10\\-9 CPUs.\n*   `GET /info` now returns more structured information about security options.\n*   The `HostConfig` field now includes `CpuCount` that represents the number of CPUs available for execution by the container. Windows daemon only.\n*   `POST /services/create` and `POST /services/(id or name)/update` now accept the `TTY` parameter, which allocate a pseudo-TTY in container.\n*   `POST /services/create` and `POST /services/(id or name)/update` now accept the `DNSConfig` parameter, which specifies DNS related configurations in resolver configuration file (resolv.conf) through `Nameservers`, `Search`, and `Options`.\n*   `POST /services/create` and `POST /services/(id or name)/update` now support `node.platform.arch` and `node.platform.os` constraints in the services `TaskSpec.Placement.Constraints` field.\n*   `GET /networks/(id or name)` now includes IP and name of all peers nodes for swarm mode overlay networks.\n*   `GET /plugins` list plugins.\n*   `POST /plugins/pull?name=<plugin name>` pulls a plugin.\n*   `GET /plugins/(plugin name)` inspect a plugin.\n*   `POST /plugins/(plugin name)/set` configure a plugin.\n*   `POST /plugins/(plugin name)/enable` enable a plugin.\n*   `POST /plugins/(plugin name)/disable` disable a plugin.\n*   `POST /plugins/(plugin name)/push` push a plugin.\n*   `POST /plugins/create?name=(plugin name)` create a plugin.\n*   `DELETE /plugins/(plugin name)` delete a plugin.\n*   `POST /node/(id or name)/update` now accepts both `id` or `name` to identify the node to update.\n*   `GET /images/json` now support a `reference` filter.\n*   `GET /secrets` returns information on the secrets.\n*   `POST /secrets/create` creates a secret.\n*   `DELETE /secrets/{id}` removes the secret `id`.\n*   `GET /secrets/{id}` returns information on the secret `id`.\n*   `POST /secrets/{id}/update` updates the secret `id`.\n*   `POST /services/(id or name)/update` now accepts service name or prefix of service id as a parameter.\n*   `POST /containers/create` added 2 built-in log-opts that work on all logging drivers, `mode` (`blocking`|`non-blocking`), and `max-buffer-size` (e.g. `2m`) which enables a non-blocking log buffer.\n*   `POST /containers/create` now takes `HostConfig.Init` field to run an init inside the container that forwards signals and reaps processes.\n\n[Docker Engine API v1.24](https://docs.docker.com/engine/api/v1.24/) documentation\n\n*   `POST /containers/create` now takes `StorageOpt` field.\n*   `GET /info` now returns `SecurityOptions` field, showing if `apparmor`, `seccomp`, or `selinux` is supported.\n*   `GET /info` no longer returns the `ExecutionDriver` property. This property was no longer used after integration with ContainerD in Docker 1.11.\n*   `GET /networks` now supports filtering by `label` and `driver`.\n*   `GET /containers/json` now supports filtering containers by `network` name or id.\n*   `POST /containers/create` now takes `IOMaximumBandwidth` and `IOMaximumIOps` fields. Windows daemon only.\n*   `POST /containers/create` now returns an HTTP 400 \"bad parameter\" message if no command is specified (instead of an HTTP 500 \"server error\")\n*   `GET /images/search` now takes a `filters` query parameter.\n*   `GET /events` now supports a `reload` event that is emitted when the daemon configuration is reloaded.\n*   `GET /events` now supports filtering by daemon name or ID.\n*   `GET /events` now supports a `detach` event that is emitted on detaching from container process.\n*   `GET /events` now supports an `exec_detach` event that is emitted on detaching from exec process.\n*   `GET /images/json` now supports filters `since` and `before`.\n*   `POST /containers/(id or name)/start` no longer accepts a `HostConfig`.\n*   `POST /images/(name)/tag` no longer has a `force` query parameter.\n*   `GET /images/search` now supports maximum returned search results `limit`.\n*   `POST /containers/{name:.*}/copy` is now removed and errors out starting from this API version.\n*   API errors are now returned as JSON instead of plain text.\n*   `POST /containers/create` and `POST /containers/(id)/start` allow you to configure kernel parameters (sysctls) for use in the container.\n*   `POST /containers/<container ID>/exec` and `POST /exec/<exec ID>/start` no longer expects a \"Container\" field to be present. This property was not used and is no longer sent by the docker client.\n*   `POST /containers/create/` now validates the hostname (should be a valid RFC 1123 hostname).\n*   `POST /containers/create/` `HostConfig.PidMode` field now accepts `container:<name|id>`, to have the container join the PID namespace of an existing container.\n\n*   `GET /containers/json` returns the state of the container, one of `created`, `restarting`, `running`, `paused`, `exited` or `dead`.\n*   `GET /containers/json` returns the mount points for the container.\n*   `GET /networks/(name)` now returns an `Internal` field showing whether the network is internal or not.\n*   `GET /networks/(name)` now returns an `EnableIPv6` field showing whether the network has ipv6 enabled or not.\n*   `POST /containers/(name)/update` now supports updating container's restart policy.\n*   `POST /networks/create` now supports enabling ipv6 on the network by setting the `EnableIPv6` field (doing this with a label will no longer work).\n*   `GET /info` now returns `CgroupDriver` field showing what cgroup driver the daemon is using; `cgroupfs` or `systemd`.\n*   `GET /info` now returns `KernelMemory` field, showing if \"kernel memory limit\" is supported.\n*   `POST /containers/create` now takes `PidsLimit` field, if the kernel is >= 4.3 and the pids cgroup is supported.\n*   `GET /containers/(id or name)/stats` now returns `pids_stats`, if the kernel is >= 4.3 and the pids cgroup is supported.\n*   `POST /containers/create` now allows you to override usernamespaces remapping and use privileged options for the container.\n*   `POST /containers/create` now allows specifying `nocopy` for named volumes, which disables automatic copying from the container path to the volume.\n*   `POST /auth` now returns an `IdentityToken` when supported by a registry.\n*   `POST /containers/create` with both `Hostname` and `Domainname` fields specified will result in the container's hostname being set to `Hostname`, rather than `Hostname.Domainname`.\n*   `GET /volumes` now supports more filters, new added filters are `name` and `driver`.\n*   `GET /containers/(id or name)/logs` now accepts a `details` query parameter to stream the extra attributes that were provided to the containers `LogOpts`, such as environment variables and labels, with the logs.\n*   `POST /images/load` now returns progress information as a JSON stream, and has a `quiet` query parameter to suppress progress details.\n\n*   The `HostConfig.LxcConf` field has been removed, and is no longer available on `POST /containers/create` and `GET /containers/(id)/json`.\n*   `POST /container/(name)/update` updates the resources of a container.\n*   `GET /containers/json` supports filter `isolation` on Windows.\n*   `GET /containers/json` now returns the list of networks of containers.\n*   `GET /info` Now returns `Architecture` and `OSType` fields, providing information about the host architecture and operating system type that the daemon runs on.\n*   `GET /networks/(name)` now returns a `Name` field for each container attached to the network.\n*   `GET /version` now returns the `BuildTime` field in RFC3339Nano format to make it consistent with other date/time values returned by the API.\n*   `AuthConfig` now supports a `registrytoken` for token based authentication\n*   `POST /containers/create` now has a 4M minimum value limit for `HostConfig.KernelMemory`\n*   Pushes initiated with `POST /images/(name)/push` and pulls initiated with `POST /images/create` will be cancelled if the HTTP connection making the API request is closed before the push or pull completes.\n*   `POST /containers/create` now allows you to set a read/write rate limit for a device (in bytes per second or IO per second).\n*   `GET /networks` now supports filtering by `name`, `id` and `type`.\n*   `POST /containers/create` now allows you to set the static IPv4 and/or IPv6 address for the container.\n*   `POST /networks/(id)/connect` now allows you to set the static IPv4 and/or IPv6 address for the container.\n*   `GET /info` now includes the number of containers running, stopped, and paused.\n*   `POST /networks/create` now supports restricting external access to the network by setting the `Internal` field.\n*   `POST /networks/(id)/disconnect` now includes a `Force` option to forcefully disconnect a container from network\n*   `GET /containers/(id)/json` now returns the `NetworkID` of containers.\n*   `POST /networks/create` Now supports an options field in the IPAM config that provides options for custom IPAM plugins.\n*   `GET /networks/{network-id}` Now returns IPAM config options for custom IPAM plugins if any are available.\n*   `GET /networks/<network-id>` now returns subnets info for user-defined networks.\n*   `GET /info` can now return a `SystemStatus` field useful for returning additional information about applications that are built on top of engine.\n\n*   `GET /volumes` lists volumes from all volume drivers.\n*   `POST /volumes/create` to create a volume.\n*   `GET /volumes/(name)` get low-level information about a volume.\n*   `DELETE /volumes/(name)` remove a volume with the specified name.\n*   `VolumeDriver` was moved from `config` to `HostConfig` to make the configuration portable.\n*   `GET /images/(name)/json` now returns information about an image's `RepoTags` and `RepoDigests`.\n*   The `config` option now accepts the field `StopSignal`, which specifies the signal to use to kill a container.\n*   `GET /containers/(id)/stats` will return networking information respectively for each interface.\n*   The `HostConfig` option now includes the `DnsOptions` field to configure the container's DNS options.\n*   `POST /build` now optionally takes a serialized map of build-time variables.\n*   `GET /events` now includes a `timenano` field, in addition to the existing `time` field.\n*   `GET /events` now supports filtering by image and container labels.\n*   `GET /info` now lists engine version information and return the information of `CPUShares` and `Cpuset`.\n*   `GET /containers/json` will return `ImageID` of the image used by container.\n*   `POST /exec/(name)/start` will now return an HTTP 409 when the container is either stopped or paused.\n*   `POST /containers/create` now takes `KernelMemory` in HostConfig to specify kernel memory limit.\n*   `GET /containers/(name)/json` now accepts a `size` parameter. Setting this parameter to '1' returns container size information in the `SizeRw` and `SizeRootFs` fields.\n*   `GET /containers/(name)/json` now returns a `NetworkSettings.Networks` field, detailing network settings per network. This field deprecates the `NetworkSettings.Gateway`, `NetworkSettings.IPAddress`, `NetworkSettings.IPPrefixLen`, and `NetworkSettings.MacAddress` fields, which are still returned for backward-compatibility, but will be removed in a future version.\n*   `GET /exec/(id)/json` now returns a `NetworkSettings.Networks` field, detailing networksettings per network. This field deprecates the `NetworkSettings.Gateway`, `NetworkSettings.IPAddress`, `NetworkSettings.IPPrefixLen`, and `NetworkSettings.MacAddress` fields, which are still returned for backward-compatibility, but will be removed in a future version.\n*   The `HostConfig` option now includes the `OomScoreAdj` field for adjusting the badness heuristic. This heuristic selects which processes the OOM killer kills under out-of-memory conditions.\n\n*   `GET /containers/(id)/archive` get an archive of filesystem content from a container.\n*   `PUT /containers/(id)/archive` upload an archive of content to be extracted to an existing directory inside a container's filesystem.\n*   `POST /containers/(id)/copy` is deprecated in favor of the above `archive` endpoint which can be used to download files and directories from a container.\n*   The `hostConfig` option now accepts the field `GroupAdd`, which specifies a list of additional groups that the container process will run as.\n\n*   When the daemon detects a version mismatch with the client, usually when the client is newer than the daemon, an HTTP 400 is now returned instead of a 404.\n*   `GET /containers/(id)/stats` now accepts `stream` bool to get only one set of stats and disconnect.\n*   `GET /containers/(id)/logs` now accepts a `since` timestamp parameter.\n*   `GET /info` The fields `Debug`, `IPv4Forwarding`, `MemoryLimit`, and `SwapLimit` are now returned as boolean instead of as an int. In addition, the end point now returns the new boolean fields `CpuCfsPeriod`, `CpuCfsQuota`, and `OomKillDisable`.\n*   The `hostConfig` option now accepts the fields `CpuPeriod` and `CpuQuota`\n*   `POST /build` accepts `cpuperiod` and `cpuquota` options\n\n*   `GET /version` now returns `Os`, `Arch` and `KernelVersion`.\n*   `POST /containers/create` and `POST /containers/(id)/start`allow you to set ulimit settings for use in the container.\n*   `GET /info` now returns `SystemTime`, `HttpProxy`,`HttpsProxy` and `NoProxy`.\n*   `GET /images/json` added a `RepoDigests` field to include image digest information.\n*   `POST /build` can now set resource constraints for all containers created for the build.\n*   `CgroupParent` can be passed in the host config to setup container cgroups under a specific cgroup.\n*   `POST /build` closing the HTTP request cancels the build\n*   `POST /containers/(id)/exec` includes `Warnings` field to response.",
  "title": "Engine API version history | Docker Docs\n",
  "description": "Documentation of changes that have been made to Engine API.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/userguide/networking/",
  "markdown": "# Networking overview | Docker Docs\n\nContainer networking refers to the ability for containers to connect to and communicate with each other, or to non-Docker workloads.\n\nContainers have networking enabled by default, and they can make outgoing connections. A container has no information about what kind of network it's attached to, or whether their peers are also Docker workloads or not. A container only sees a network interface with an IP address, a gateway, a routing table, DNS services, and other networking details. That is, unless the container uses the `none` network driver.\n\nThis page describes networking from the point of view of the container, and the concepts around container networking. This page doesn't describe OS-specific details about how Docker networks work. For information about how Docker manipulates `iptables` rules on Linux, see [Packet filtering and firewalls](https://docs.docker.com/network/packet-filtering-firewalls/).\n\nYou can create custom, user-defined networks, and connect multiple containers to the same network. Once connected to a user-defined network, containers can communicate with each other using container IP addresses or container names.\n\nThe following example creates a network using the `bridge` network driver and running a container in the created network:\n\n### [Drivers](#drivers)\n\nThe following network drivers are available by default, and provide core networking functionality:\n\n| Driver | Description |\n| --- | --- |\n| `bridge` | The default network driver. |\n| `host` | Remove network isolation between the container and the Docker host. |\n| `none` | Completely isolate a container from the host and other containers. |\n| `overlay` | Overlay networks connect multiple Docker daemons together. |\n| `ipvlan` | IPvlan networks provide full control over both IPv4 and IPv6 addressing. |\n| `macvlan` | Assign a MAC address to a container. |\n\nFor more information about the different drivers, see [Network drivers overview](https://docs.docker.com/network/drivers/).\n\nIn addition to user-defined networks, you can attach a container to another container's networking stack directly, using the `--network container:<name|id>` flag format.\n\nThe following flags aren't supported for containers using the `container:` networking mode:\n\n*   `--add-host`\n*   `--hostname`\n*   `--dns`\n*   `--dns-search`\n*   `--dns-option`\n*   `--mac-address`\n*   `--publish`\n*   `--publish-all`\n*   `--expose`\n\nThe following example runs a Redis container, with Redis binding to `localhost`, then running the `redis-cli` command and connecting to the Redis server over the `localhost` interface.\n\nBy default, when you create or run a container using `docker create` or `docker run`, containers on bridge networks don't expose any ports to the outside world. Use the `--publish` or `-p` flag to make a port available to services outside the bridge network. This creates a firewall rule in the host, mapping a container port to a port on the Docker host to the outside world. Here are some examples:\n\n| Flag value | Description |\n| --- | --- |\n| `-p 8080:80` | Map port `8080` on the Docker host to TCP port `80` in the container. |\n| `-p 192.168.1.100:8080:80` | Map port `8080` on the Docker host IP `192.168.1.100` to TCP port `80` in the container. |\n| `-p 8080:80/udp` | Map port `8080` on the Docker host to UDP port `80` in the container. |\n| `-p 8080:80/tcp -p 8080:80/udp` | Map TCP port `8080` on the Docker host to TCP port `80` in the container, and map UDP port `8080` on the Docker host to UDP port `80` in the container. |\n\n> **Important**\n> \n> Publishing container ports is insecure by default. Meaning, when you publish a container's ports it becomes available not only to the Docker host, but to the outside world as well.\n> \n> If you include the localhost IP address (`127.0.0.1`, or `::1`) with the publish flag, only the Docker host and its containers can access the published container port.\n> \n> > **Warning**\n> > \n> > Hosts within the same L2 segment (for example, hosts connected to the same network switch) can reach ports published to localhost. For more information, see [moby/moby#45610](https://github.com/moby/moby/issues/45610)\n\nIf you want to make a container accessible to other containers, it isn't necessary to publish the container's ports. You can enable inter-container communication by connecting the containers to the same network, usually a [bridge network](https://docs.docker.com/network/drivers/bridge/).\n\nPorts on the host's IPv6 addresses will map to the container's IPv4 address if no host IP is given in a port mapping, the bridge network is IPv4-only, and `--userland-proxy=true` (default).\n\nFor more information about port mapping, including how to disable it and use direct routing to containers, see [packet filtering and firewalls](https://docs.docker.com/network/packet-filtering-firewalls/).\n\nBy default, the container gets an IP address for every Docker network it attaches to. A container receives an IP address out of the IP subnet of the network. The Docker daemon performs dynamic subnetting and IP address allocation for containers. Each network also has a default subnet mask and gateway.\n\nYou can connect a running container to multiple networks, either by passing the `--network` flag multiple times when creating the container, or using the `docker network connect` command for already running containers. In both cases, you can use the `--ip` or `--ip6` flags to specify the container's IP address on that particular network.\n\nIn the same way, a container's hostname defaults to be the container's ID in Docker. You can override the hostname using `--hostname`. When connecting to an existing network using `docker network connect`, you can use the `--alias` flag to specify an additional network alias for the container on that network.\n\nContainers use the same DNS servers as the host by default, but you can override this with `--dns`.\n\nBy default, containers inherit the DNS settings as defined in the `/etc/resolv.conf` configuration file. Containers that attach to the default `bridge` network receive a copy of this file. Containers that attach to a [custom network](https://docs.docker.com/network/network-tutorial-standalone/#use-user-defined-bridge-networks) use Docker's embedded DNS server. The embedded DNS server forwards external DNS lookups to the DNS servers configured on the host.\n\nYou can configure DNS resolution on a per-container basis, using flags for the `docker run` or `docker create` command used to start the container. The following table describes the available `docker run` flags related to DNS configuration.\n\n| Flag | Description |\n| --- | --- |\n| `--dns` | The IP address of a DNS server. To specify multiple DNS servers, use multiple `--dns` flags. DNS requests will be forwarded from the container's network namespace so, for example, `--dns=127.0.0.1` refers to the container's own loopback address. |\n| `--dns-search` | A DNS search domain to search non-fully qualified hostnames. To specify multiple DNS search prefixes, use multiple `--dns-search` flags. |\n| `--dns-opt` | A key-value pair representing a DNS option and its value. See your operating system's documentation for `resolv.conf` for valid options. |\n| `--hostname` | The hostname a container uses for itself. Defaults to the container's ID if not specified. |\n\n### [Custom hosts](#custom-hosts)\n\nYour container will have lines in `/etc/hosts` which define the hostname of the container itself, as well as `localhost` and a few other common things. Custom hosts, defined in `/etc/hosts` on the host machine, aren't inherited by containers. To pass additional hosts into a container, refer to [add entries to container hosts file](https://docs.docker.com/reference/cli/docker/container/run/#add-host) in the `docker run` reference documentation.\n\nIf your container needs to use a proxy server, see [Use a proxy server](https://docs.docker.com/network/proxy/).",
  "title": "Networking overview | Docker Docs\n",
  "description": "Learn how networking works from the container's point of view",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-file/11-extension/",
  "markdown": "# Extensions | Docker Docs\n\nExtensions can be used to make your Compose file more efficient and easier to maintain.\n\nUse the prefix `x-` as a top-level element to modularize configurations that you want to reuse. Compose ignores any fields that start with `x-`, this is the sole exception where Compose silently ignores unrecognized fields.\n\nExtensions can also be used with [anchors and aliases](https://docs.docker.com/compose/compose-file/10-fragments/).\n\nThey also can be used within any structure in a Compose file where user-defined keys are not expected. Compose uses those to enable experimental features, the same way browsers add support for [custom CSS features](https://www.w3.org/TR/2011/REC-CSS2-20110607/syndata.html#vendor-keywords)\n\nIn this example, the environment variables do not belong to either of the services. Theyâ€™ve been lifted out completely into the `x-env` extension field. This defines a new node which contains the environment field. The `&env` YAML anchor is used so both services can reference the extension fieldâ€™s value as `*env`.\n\nThe `nodeinfo` and `echoit` services both include the `x-function` extension via the `&function` anchor, then set their specific image and environment.\n\nUsing [YAML merge](https://yaml.org/type/merge.html) it is also possible to use multiple extensions and share and override additional attributes for specific needs:\n\n> **Note**\n> \n> [YAML merge](https://yaml.org/type/merge.html) only applies to mappings, and can't be used with sequences.\n> \n> In the example above, the environment variables are declared using the `FOO: BAR` mapping syntax, while the sequence syntax `- FOO=BAR` is only valid when no fragments are involved.\n\nThis section is informative. At the time of writing, the following prefixes are known to exist:\n\n| Prefix | Vendor/Organization |\n| --- | --- |\n| docker | Docker |\n| kubernetes | Kubernetes |\n\nValues express a byte value as a string in `{amount}{byte unit}` format: The supported units are `b` (bytes), `k` or `kb` (kilo bytes), `m` or `mb` (mega bytes) and `g` or `gb` (giga bytes).\n\nValues express a duration as a string in the form of `{value}{unit}`. The supported units are `us` (microseconds), `ms` (milliseconds), `s` (seconds), `m` (minutes) and `h` (hours). Values can combine multiple values without separator.",
  "title": "Extensions | Docker Docs\n",
  "description": "Understand how to use extensions",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-file/10-fragments/",
  "markdown": "# Fragments | Docker Docs\n\nWith Compose, you can use built-in [YAML](https://www.yaml.org/spec/1.2/spec.html#id2765878) features to make your Compose file neater and more efficient. Anchors and aliases let you create re-usable blocks. This is useful if you start to find common configurations that span multiple services. Having re-usable blocks minimizes potential mistakes.\n\nAnchors are created using the `&` sign. The sign is followed by an alias name. You can use this alias with the `*` sign later to reference the value following the anchor. Make sure there is no space between the `&` and the `*` characters and the following alias name.\n\nYou can use more than one anchor and alias in a single Compose file.\n\nIn the example above, a `default-volume` anchor is created based on the `db-data` volume. It is later reused by the alias `*default-volume` to define the `metrics` volume.\n\nAnchor resolution takes place before [variables interpolation](https://docs.docker.com/compose/compose-file/12-interpolation/), so variables can't be used to set anchors or aliases.\n\nIf you have an anchor that you want to use in more than one service, use it in conjunction with an [extension](https://docs.docker.com/compose/compose-file/11-extension/) to make your Compose file easier to maintain.\n\nYou may want to partially override values. Compose follows the rule outlined by [YAML merge type](https://yaml.org/type/merge.html).\n\nIn the following example, `metrics` volume specification uses alias to avoid repetition but overrides `name` attribute:\n\nYou can also extend the anchor to add additional values.\n\n> **Note**\n> \n> [YAML merge](https://yaml.org/type/merge.html) only applies to mappings, and can't be used with sequences.\n\nIn example above, the environment variables must be declared using the `FOO: BAR` mapping syntax, while the sequence syntax `- FOO=BAR` is only valid when no fragments are involved.",
  "title": "Fragments | Docker Docs\n",
  "description": "Understand how to use fragments",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-file/deploy/",
  "markdown": "# Compose Deploy Specification | Docker Docs\n\nDeploy is an optional part of the Compose Specification. It provides a set of deployment specifications for managing the behavior of containers across different environments.\n\n### [endpoint\\_mode](#endpoint_mode)\n\n`endpoint_mode` specifies a service discovery method for external clients connecting to a service. The Compose Deploy Specification defines two canonical values:\n\n*   `endpoint_mode: vip`: Assigns the service a virtual IP (VIP) that acts as the front end for clients to reach the service on a network. Platform routes requests between the client and nodes running the service, without client knowledge of how many nodes are participating in the service or their IP addresses or ports.\n    \n*   `endpoint_mode: dnsrr`: Platform sets up DNS entries for the service such that a DNS query for the service name returns a list of IP addresses (DNS round-robin), and the client connects directly to one of these.\n    \n\n### [labels](#labels)\n\n`labels` specifies metadata for the service. These labels are only set on the service and not on any containers for the service. This assumes the platform has some native concept of \"service\" that can match the Compose application model.\n\n### [mode](#mode)\n\n`mode` defines the replication model used to run the service on the platform. Either `global`, exactly one container per physical node, or `replicated`, a specified number of containers. The default is `replicated`.\n\n### [placement](#placement)\n\n`placement` specifies constraints and preferences for the platform to select a physical node to run service containers.\n\n#### [constraints](#constraints)\n\n`constraints` defines a required property the platform's node must fulfill to run the service container. It can be set either by a list or a map with string values.\n\n#### [preferences](#preferences)\n\n`preferences` defines a property the platform's node should fulfill to run service container. It can be set either by a list or a map with string values.\n\n### [replicas](#replicas)\n\nIf the service is `replicated` (which is the default), `replicas` specifies the number of containers that should be running at any given time.\n\n### [resources](#resources)\n\n`resources` configures physical resource constraints for container to run on platform. Those constraints can be configured as:\n\n*   `limits`: The platform must prevent the container to allocate more.\n*   `reservations`: The platform must guarantee the container can allocate at least the configured amount.\n\n#### [cpus](#cpus)\n\n`cpus` configures a limit or reservation for how much of the available CPU resources, as number of cores, a container can use.\n\n#### [memory](#memory)\n\n`memory` configures a limit or reservation on the amount of memory a container can allocate, set as a string expressing a [byte value](https://docs.docker.com/compose/compose-file/11-extension/#specifying-byte-values).\n\n#### [pids](#pids)\n\n`pids` tunes a containerâ€™s PIDs limit, set as an integer.\n\n#### [devices](#devices)\n\n`devices` configures reservations of the devices a container can use. It contains a list of reservations, each set as an object with the following parameters: `capabilities`, `driver`, `count`, `device_ids` and `options`.\n\nDevices are reserved using a list of capabilities, making `capabilities` the only required field. A device must satisfy all the requested capabilities for a successful reservation.\n\n##### [capabilities](#capabilities)\n\n`capabilities` are set as a list of strings, expressing both generic and driver specific capabilities. The following generic capabilities are recognized today:\n\n*   `gpu`: Graphics accelerator\n*   `tpu`: AI accelerator\n\nTo avoid name clashes, driver specific capabilities must be prefixed with the driver name. For example, reserving an nVidia CUDA-enabled accelerator might look like this:\n\n##### [driver](#driver)\n\nA different driver for the reserved device(s) can be requested using `driver` field. The value is specified as a string.\n\n##### [count](#count)\n\nIf `count` is set to `all` or not specified, Compose reserves all devices that satisfy the requested capabilities. Otherwise, Compose reserves at least the number of devices specified. The value is specified as an integer.\n\n`count` and `device_ids` fields are exclusive. Compose returns an error if both are specified.\n\n##### [device\\_ids](#device_ids)\n\nIf `device_ids` is set, Compose reserves devices with the specified IDs provided they satisfy the requested capabilities. The value is specified as a list of strings.\n\n`count` and `device_ids` fields are exclusive. Compose returns an error if both are specified.\n\n##### [options](#options)\n\nDriver specific options can be set with `options` as key-value pairs.\n\n### [restart\\_policy](#restart_policy)\n\n`restart_policy` configures if and how to restart containers when they exit. If `restart_policy` is not set, Compose considers the `restart` field set by the service configuration.\n\n*   `condition`. When set to:\n    *   `none`, containers are not automatically restarted regardless of the exit status.\n    *   `on-failure`, the container is restarted if it exits due to an error, which manifests as a non-zero exit code.\n    *   `any` (default), containers are restarted regardless of the exit status.\n*   `delay`: How long to wait between restart attempts, specified as a [duration](https://docs.docker.com/compose/compose-file/11-extension/#specifying-durations). The default is 0, meaning restart attempts can occur immediately.\n*   `max_attempts`: How many times to attempt to restart a container before giving up (default: never give up). If the restart does not succeed within the configured `window`, this attempt doesn't count toward the configured `max_attempts` value. For example, if `max_attempts` is set to '2', and the restart fails on the first attempt, more than two restarts must be attempted.\n*   `window`: How long to wait before deciding if a restart has succeeded, specified as a [duration](#specifying-durations) (default: decide immediately).\n\n### [rollback\\_config](#rollback_config)\n\n`rollback_config` configures how the service should be rollbacked in case of a failing update.\n\n*   `parallelism`: The number of containers to rollback at a time. If set to 0, all containers rollback simultaneously.\n*   `delay`: The time to wait between each container group's rollback (default 0s).\n*   `failure_action`: What to do if a rollback fails. One of `continue` or `pause` (default `pause`)\n*   `monitor`: Duration after each task update to monitor for failure `(ns|us|ms|s|m|h)` (default 0s).\n*   `max_failure_ratio`: Failure rate to tolerate during a rollback (default 0).\n*   `order`: Order of operations during rollbacks. One of `stop-first` (old task is stopped before starting new one), or `start-first` (new task is started first, and the running tasks briefly overlap) (default `stop-first`).\n\n### [update\\_config](#update_config)\n\n`update_config` configures how the service should be updated. Useful for configuring rolling updates.\n\n*   `parallelism`: The number of containers to update at a time.\n*   `delay`: The time to wait between updating a group of containers.\n*   `failure_action`: What to do if an update fails. One of `continue`, `rollback`, or `pause` (default: `pause`).\n*   `monitor`: Duration after each task update to monitor for failure `(ns|us|ms|s|m|h)` (default 0s).\n*   `max_failure_ratio`: Failure rate to tolerate during an update.\n*   `order`: Order of operations during updates. One of `stop-first` (old task is stopped before starting new one), or `start-first` (new task is started first, and the running tasks briefly overlap) (default `stop-first`).",
  "title": "Compose Deploy Specification | Docker Docs\n",
  "description": "Learn about the Compose Deploy Specification",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-file/develop/",
  "markdown": "# Compose Develop Specification | Docker Docs\n\n> **Note:**\n> \n> Develop is an optional part of the Compose Specification. It is available with Docker Compose version 2.22.0 and later.\n\nThis page defines how Compose behaves to efficiently assist you and defines the development constraints and workflows set by Compose. Only a subset of Compose file services may require a `develop` subsection.\n\nThe `develop` subsection defines configuration options that are applied by Compose to assist you during development of a service with optimized workflows.\n\n### [watch](#watch)\n\nThe `watch` attribute defines a list of rules that control automatic service updates based on local file changes. `watch` is a sequence, each individual item in the sequence defines a rule to be applied by Compose to monitor source code for changes. For more information, see [Use Compose Watch](https://docs.docker.com/compose/file-watch/).\n\n#### [action](#action)\n\n`action` defines the action to take when changes are detected. If `action` is set to:\n\n*   `rebuild`, Compose rebuilds the service image based on the `build` section and recreates the service with the updated image.\n*   `sync`, Compose keeps the existing service container(s) running, but synchronizes source files with container content according to the `target` attribute.\n*   `sync+restart`, Compose synchronizes source files with container content according to the `target` attribute, and then restarts the container.\n\n> `sync+restart` attribute is available with Docker Compose version 2.23.0 and later.\n\n#### [ignore](#ignore)\n\nThe `ignore` attribute can be used to define a list of patterns for paths to be ignored. Any updated file that matches a pattern, or belongs to a folder that matches a pattern, won't trigger services to be re-created. The syntax is the same as `.dockerignore` file:\n\n*   `*` matches 0 or more characters in a file name.\n*   `?` matches a single character in file name.\n*   `*/*` matches two nested folders with arbitrary names\n*   `**` matches an arbitrary number of nested folders\n\nIf the build context includes a `.dockerignore` file, the patterns in this file is loaded as implicit content for the `ignores` file, and values set in the Compose model are appended.\n\n#### [path](#path)\n\n`path` attribute defines the path to source code (relative to the project directory) to monitor for changes. Updates to any file inside the path, which doesn't match any `ignore` rule, triggers the configured action.\n\n#### [target](#target)\n\n`target` attribute only applies when `action` is configured for `sync`. Files within `path` with changes are synchronized with container filesystem, so that the latter is always running with up-to-date content.",
  "title": "Compose Develop Specification | Docker Docs\n",
  "description": "Learn about the Compose Develop Specification",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/guide/",
  "markdown": "# Build with Docker | Docker Docs\n\nWelcome! This guide is an introduction and deep-dive into building software with Docker.\n\nWhether youâ€™re just getting started, or youâ€™re already an advanced Docker user, this guide aims to provide useful pointers into the possibilities and best practices of Docker's build features.\n\nTopics covered in this guide include:\n\n*   Introduction to build concepts\n*   Image size optimization\n*   Build speed performance improvements\n*   Building and exporting binaries\n*   Cache mounts and bind mounts\n*   Software testing\n*   Multi-platform builds\n\nThroughout this guide, an example application written in Go is used to illustrate how the build features work. You donâ€™t need to know the Go programming language to follow this guide.\n\nThe guide starts off with a simple Dockerfile example, and builds from there. Some of the later sections in this guide describe advanced concepts and workflows. You don't need to complete this entire guide from start to finish. Follow the sections that seem relevant to you, and save the advanced sections at the end for later, when you need them.",
  "title": "Build with Docker | Docker Docs\n",
  "description": "Explore the features of Docker Build in this step-by-step guide",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-file/build/",
  "markdown": "# Compose Build Specification | Docker Docs\n\nBuild is an optional part of the Compose Specification. It tells Compose how to (re)build an application from source and lets you define the build process within a Compose file in a portable way. `build` can be either specified as a single string defining a context path, or as a detailed build definition.\n\nIn the former case, the whole path is used as a Docker context to execute a Docker build, looking for a canonical `Dockerfile` at the root of the directory. The path can be absolute or relative. If it is relative, it is resolved from the directory containing your Compose file. If it is absolute, the path prevents the Compose file from being portable so Compose displays a warning.\n\nIn the latter case, build arguments can be specified, including an alternate `Dockerfile` location. The path can be absolute or relative. If it is relative, it is resolved from the directory containing your Compose file. If it is absolute, the path prevents the Compose file from being portable so Compose displays a warning.\n\nWhen Compose is confronted with both a `build` subsection for a service and an `image` attribute, it follows the rules defined by the [`pull_policy`](https://docs.docker.com/compose/compose-file/05-services/#pull_policy) attribute.\n\nIf `pull_policy` is missing from the service definition, Compose attempts to pull the image first and then builds from source if the image isn't found in the registry or platform cache.\n\nCompose with `build` support offers an option to push built images to a registry. When doing so, it doesn't try to push service images without an `image` attribute. Compose warns you about the missing `image` attribute which prevents images being pushed.\n\nThe following example illustrates Compose Build Specification concepts with a concrete sample application. The sample is non-normative.\n\nWhen used to build service images from source, the Compose file creates three Docker images:\n\n*   `example/webapp`: A Docker image is built using `webapp` sub-directory, within the Compose file's parent folder, as the Docker build context. Lack of a `Dockerfile` within this folder throws an error.\n*   `example/database`: A Docker image is built using `backend` sub-directory within the Compose file parent folder. `backend.Dockerfile` file is used to define build steps, this file is searched relative to the context path, which means `..` resolves to the Compose file's parent folder, so `backend.Dockerfile` is a sibling file.\n*   A Docker image is built using the `custom` directory with the user's HOME as the Docker context. Compose displays a warning about the non-portable path used to build image.\n\nOn push, both `example/webapp` and `example/database` Docker images are pushed to the default registry. The `custom` service image is skipped as no `image` attribute is set and Compose displays a warning about this missing attribute.\n\nThe `build` subsection defines configuration options that are applied by Compose to build Docker images from source. `build` can be specified either as a string containing a path to the build context or as a detailed structure:\n\nUsing the string syntax, only the build context can be configured as either:\n\n*   A relative path to the Compose file's parent folder. This path must be a directory and must contain a `Dockerfile`\n    \n*   A git repository URL. Git URLs accept context configuration in their fragment section, separated by a colon (`:`). The first part represents the reference that Git checks out, and can be either a branch, a tag, or a remote reference. The second part represents a subdirectory inside the repository that is used as a build context.\n    \n\nAlternatively `build` can be an object with fields defined as follows:\n\n### [context](#context)\n\n`context` defines either a path to a directory containing a Dockerfile, or a URL to a git repository.\n\nWhen the value supplied is a relative path, it is interpreted as relative to the location of the Compose file. Compose warns you about the absolute path used to define the build context as those prevent the Compose file from being portable.\n\nIf not set explicitly, `context` defaults to project directory (`.`).\n\n### [dockerfile](#dockerfile)\n\n`dockerfile` sets an alternate Dockerfile. A relative path is resolved from the build context. Compose warns you about the absolute path used to define the Dockerfile as it prevents Compose files from being portable.\n\nWhen set, `dockerfile_inline` attribute is not allowed and Compose rejects any Compose file having both set.\n\n### [dockerfile\\_inline](#dockerfile_inline)\n\nIntroduced in Docker Compose version [2.17.0](https://docs.docker.com/compose/release-notes/#2170)\n\n`dockerfile_inline` defines the Dockerfile content as an inlined string in a Compose file. When set, the `dockerfile` attribute is not allowed and Compose rejects any Compose file having both set.\n\nUse of YAML multi-line string syntax is recommended to define the Dockerfile content:\n\n### [args](#args)\n\n`args` define build arguments, i.e. Dockerfile `ARG` values.\n\nUsing the following Dockerfile as an example:\n\n`args` can be set in the Compose file under the `build` key to define `GIT_COMMIT`. `args` can be set as a mapping or a list:\n\nValues can be omitted when specifying a build argument, in which case its value at build time must be obtained by user interaction, otherwise the build arg won't be set when building the Docker image.\n\n### [ssh](#ssh)\n\n`ssh` defines SSH authentications that the image builder should use during image build (e.g., cloning private repository).\n\n`ssh` property syntax can be either:\n\n*   `default`: Let the builder connect to the ssh-agent.\n*   `ID=path`: A key/value definition of an ID and the associated path. It can be either a [PEM](https://en.wikipedia.org/wiki/Privacy-Enhanced_Mail) file, or path to ssh-agent socket.\n\nor\n\nUsing a custom id `myproject` with path to a local SSH key:\n\nThe image builder can then rely on this to mount the SSH key during build. For illustration, [BuildKit extended syntax](https://github.com/compose-spec/compose-spec/pull/234/%5Bmoby/buildkit@master/frontend/dockerfile/docs/syntax.md#run---mounttypessh%5D%28https://github.com/moby/buildkit/blob/master/frontend/dockerfile/docs/syntax.md#run---mounttypessh%29) can be used to mount the SSH key set by ID and access a secured resource:\n\n`RUN --mount=type=ssh,id=myproject git clone ...`\n\n### [cache\\_from](#cache_from)\n\n`cache_from` defines a list of sources the image builder should use for cache resolution.\n\nCache location syntax follows the global format `[NAME|type=TYPE[,KEY=VALUE]]`. Simple `NAME` is actually a shortcut notation for `type=registry,ref=NAME`.\n\nCompose Build implementations may support custom types, the Compose Specification defines canonical types which must be supported:\n\n*   `registry` to retrieve build cache from an OCI image set by key `ref`\n\nUnsupported caches are ignored and don't prevent you from building images.\n\n### [cache\\_to](#cache_to)\n\n`cache_to` defines a list of export locations to be used to share build cache with future builds.\n\nCache target is defined using the same `type=TYPE[,KEY=VALUE]` syntax defined by [`cache_from`](#cache_from).\n\nUnsupported caches are ignored and don't prevent you from building images.\n\n### [additional\\_contexts](#additional_contexts)\n\nIntroduced in Docker Compose version [2.17.0](https://docs.docker.com/compose/release-notes/#2170)\n\n`additional_contexts` defines a list of named contexts the image builder should use during image build.\n\n`additional_contexts` can be a mapping or a list:\n\nWhen used as a list, the syntax follows the `NAME=VALUE` format, where `VALUE` is a string. Validation beyond that is the responsibility of the image builder (and is builder specific). Compose supports at least absolute and relative paths to a directory AND Git repository URLs, like [context](#context) does. Other context flavours must be prefixed to avoid ambiguity with a `type://` prefix.\n\nCompose warns you if the image builder does not support additional contexts and may list the unused contexts.\n\nIllustrative examples of how this is used in Buildx can be found [here](https://github.com/docker/buildx/blob/master/docs/reference/buildx_build.md#-additional-build-contexts---build-context).\n\n`extra_hosts` adds hostname mappings at build-time. Use the same syntax as [extra\\_hosts](https://docs.docker.com/compose/compose-file/05-services/#extra_hosts).\n\nIPv6 addresses can be enclosed in square brackets, for example:\n\nThe separator `=` is preferred, but `:` can also be used. Introduced in Docker Compose version [2.24.1](https://docs.docker.com/compose/release-notes/#2241). For example:\n\nCompose creates matching entry with the IP address and hostname in the container's network configuration, which means for Linux `/etc/hosts` will get extra lines:\n\n### [isolation](#isolation)\n\n`isolation` specifies a buildâ€™s container isolation technology. Like [isolation](https://docs.docker.com/compose/compose-file/05-services/#isolation), supported values are platform specific.\n\n### [privileged](#privileged)\n\nIntroduced in Docker Compose version [2.15.0](https://docs.docker.com/compose/release-notes/#2)\n\n`privileged` configures the service image to build with elevated privileges. Support and actual impacts are platform specific.\n\n### [labels](#labels)\n\n`labels` add metadata to the resulting image. `labels` can be set either as an array or a map.\n\nIt's recommended that you use reverse-DNS notation to prevent your labels from conflicting with other software.\n\n### [no\\_cache](#no_cache)\n\n`no_cache` disables image builder cache and enforces a full rebuild from source for all image layers. This only applies to layers declared in the Dockerfile, referenced images COULD be retrieved from local image store whenever tag has been updated on registry (see [pull](#pull)).\n\n### [pull](#pull)\n\n`pull` requires the image builder to pull referenced images (`FROM` Dockerfile directive), even if those are already available in the local image store.\n\n### [network](#network)\n\nSet the network containers connect to for the `RUN` instructions during build.\n\nUse `none` to disable networking during build:\n\n### [shm\\_size](#shm_size)\n\n`shm_size` sets the size of the shared memory (`/dev/shm` partition on Linux) allocated for building Docker images. Specify as an integer value representing the number of bytes or as a string expressing a [byte value](https://docs.docker.com/compose/compose-file/11-extension/#specifying-byte-values).\n\n### [target](#target)\n\n`target` defines the stage to build as defined inside a multi-stage `Dockerfile`.\n\n### [secrets](#secrets)\n\n`secrets` grants access to sensitive data defined by [secrets](https://docs.docker.com/compose/compose-file/05-services/#secrets) on a per-service build basis. Two different syntax variants are supported: the short syntax and the long syntax.\n\nCompose reports an error if the secret isn't defined in the [`secrets`](https://docs.docker.com/compose/compose-file/09-secrets/) section of this Compose file.\n\n#### [Short syntax](#short-syntax)\n\nThe short syntax variant only specifies the secret name. This grants the container access to the secret and mounts it as read-only to `/run/secrets/<secret_name>` within the container. The source name and destination mountpoint are both set to the secret name.\n\nThe following example uses the short syntax to grant the build of the `frontend` service access to the `server-certificate` secret. The value of `server-certificate` is set to the contents of the file `./server.cert`.\n\n#### [Long syntax](#long-syntax)\n\nThe long syntax provides more granularity in how the secret is created within the service's containers.\n\n*   `source`: The name of the secret as it exists on the platform.\n*   `target`: The name of the file to be mounted in `/run/secrets/` in the service's task containers. Defaults to `source` if not specified.\n*   `uid` and `gid`: The numeric UID or GID that owns the file within `/run/secrets/` in the service's task containers. Default value is USER running container.\n*   `mode`: The [permissions](https://wintelguy.com/permissions-calc.pl) for the file to be mounted in `/run/secrets/` in the service's task containers, in octal notation. Default value is world-readable permissions (mode `0444`). The writable bit must be ignored if set. The executable bit may be set.\n\nThe following example sets the name of the `server-certificate` secret file to `server.crt` within the container, sets the mode to `0440` (group-readable) and sets the user and group to `103`. The value of `server-certificate` secret is provided by the platform through a lookup and the secret lifecycle not directly managed by Compose.\n\nService builds may be granted access to multiple secrets. Long and short syntax for secrets may be used in the same Compose file. Defining a secret in the top-level `secrets` must not imply granting any service build access to it. Such grant must be explicit within service specification as [secrets](https://docs.docker.com/compose/compose-file/05-services/#secrets) service element.\n\n### [tags](#tags)\n\n`tags` defines a list of tag mappings that must be associated to the build image. This list comes in addition to the `image` [property defined in the service section](https://docs.docker.com/compose/compose-file/05-services/#image)\n\n### [ulimits](#ulimits)\n\nIntroduced in Docker Compose version [2.23.1](https://docs.docker.com/compose/release-notes/#2231)\n\n`ulimits` overrides the default ulimits for a container. It's specified either as an integer for a single limit or as mapping for soft/hard limits.\n\n### [platforms](#platforms)\n\n`platforms` defines a list of target [platforms](https://docs.docker.com/compose/compose-file/05-services/#platform).\n\nWhen the `platforms` attribute is omitted, Compose includes the service's platform in the list of the default build target platforms.\n\nWhen the `platforms` attribute is defined, Compose includes the service's platform, otherwise users won't be able to run images they built.\n\nComposes reports an error in the following cases:\n\n*   When the list contains multiple platforms but the implementation is incapable of storing multi-platform images.\n    \n*   When the list contains an unsupported platform.\n    \n*   When the list is non-empty and does not contain the service's platform",
  "title": "Compose Build Specification | Docker Docs\n",
  "description": "Learn about the Compose Build Specification",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/reference/",
  "markdown": "# Overview of docker compose CLI\n\n```\nUsage:  docker compose [OPTIONS] COMMAND\n\nDefine and run multi-container applications with Docker.\n\nOptions:\n      --ansi string                Control when to print ANSI control characters (\"never\"|\"always\"|\"auto\") (default \"auto\")\n      --compatibility              Run compose in backward compatibility mode\n      --dry-run                    Execute command in dry run mode\n      --env-file stringArray       Specify an alternate environment file\n  -f, --file stringArray           Compose configuration files\n      --parallel int               Control max parallelism, -1 for unlimited (default -1)\n      --profile stringArray        Specify a profile to enable\n      --progress string            Set type of progress output (auto, tty, plain, quiet) (default \"auto\")\n      --project-directory string   Specify an alternate working directory\n                                   (default: the path of the, first specified, Compose file)\n  -p, --project-name string        Project name\n\nCommands:\n  attach      Attach local standard input, output, and error streams to a service's running container.\n  build       Build or rebuild services\n  config      Parse, resolve and render compose file in canonical format\n  cp          Copy files/folders between a service container and the local filesystem\n  create      Creates containers for a service.\n  down        Stop and remove containers, networks\n  events      Receive real time events from containers.\n  exec        Execute a command in a running container.\n  images      List images used by the created containers\n  kill        Force stop service containers.\n  logs        View output from containers\n  ls          List running compose projects\n  pause       Pause services\n  port        Print the public port for a port binding.\n  ps          List containers\n  pull        Pull service images\n  push        Push service images\n  restart     Restart service containers\n  rm          Removes stopped service containers\n  run         Run a one-off command on a service.\n  scale       Scale services\n  start       Start services\n  stats       Display a live stream of container(s) resource usage statistics\n  stop        Stop services\n  top         Display the running processes\n  unpause     Unpause services\n  up          Create and start containers\n  version     Show the Docker Compose version information\n  wait        Block until the first service container stops\n  watch       Watch build context for service and rebuild/refresh containers when files are updated\n\nRun 'docker compose COMMAND --help' for more information on a command.\n```",
  "title": "Overview of docker compose CLI | Docker Docs\n",
  "description": "Overview of the Docker Compose CLI",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-file/12-interpolation/",
  "markdown": "# Interpolation | Docker Docs\n\nValues in a Compose file can be set by variables and interpolated at runtime. Compose files use a Bash-like syntax `${VARIABLE}`. Both `$VARIABLE` and `${VARIABLE}` syntax is supported.\n\nFor braced expressions, the following formats are supported:\n\n*   Direct substitution\n    *   `${VAR}` -> value of `VAR`\n*   Default value\n    *   `${VAR:-default}` -> value of `VAR` if set and non-empty, otherwise `default`\n    *   `${VAR-default}` -> value of `VAR` if set, otherwise `default`\n*   Required value\n    *   `${VAR:?error}` -> value of `VAR` if set and non-empty, otherwise exit with error\n    *   `${VAR?error}` -> value of `VAR` if set, otherwise exit with error\n*   Alternative value\n    *   `${VAR:+replacement}` -> `replacement` if `VAR` is set and non-empty, otherwise empty\n    *   `${VAR+replacement}` -> `replacement` if `VAR` is set, otherwise empty\n\nInterpolation can also be nested:\n\n*   `${VARIABLE:-${FOO}}`\n*   `${VARIABLE?$FOO}`\n*   `${VARIABLE:-${FOO:-default}}`\n\nOther extended shell-style features, such as `${VARIABLE/foo/bar}`, are not supported by Compose.\n\nYou can use a `$$` (double-dollar sign) when your configuration needs a literal dollar sign. This also prevents Compose from interpolating a value, so a `$$` allows you to refer to environment variables that you don't want processed by Compose.\n\nIf Compose can't resolve a substituted variable and no default value is defined, it displays a warning and substitutes the variable with an empty string.\n\nAs any values in a Compose file can be interpolated with variable substitution, including compact string notation for complex elements, interpolation is applied before a merge on a per-file basis.\n\nInterpolation applies only to YAML values, not to keys. For the few places where keys are actually arbitrary user-defined strings, such as [labels](https://docs.docker.com/compose/compose-file/05-services/#labels) or [environment](https://docs.docker.com/compose/compose-file/05-services/#environment), an alternate equal sign syntax must be used for interpolation to apply. For example:",
  "title": "Interpolation | Docker Docs\n",
  "description": "Learn about interpolation",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-file/06-networks/",
  "markdown": "# Networks top-level elements | Docker Docs\n\nNetworks let services communicate with each other. By default Compose sets up a single network for your app. Each container for a service joins the default network and is both reachable by other containers on that network, and discoverable by the service's name. The top-level `networks` element lets you configure named networks that can be reused across multiple services.\n\nTo use a network across multiple services, you must explicitly grant each service access by using the [networks](https://docs.docker.com/compose/compose-file/05-services/) attribute within the `services` top-level element. The `networks` top-level element has additional syntax that provides more granular control.\n\n### [Basic example](#basic-example)\n\nIn the following example, at runtime, networks `front-tier` and `back-tier` are created and the `frontend` service is connected to `front-tier` and `back-tier` networks.\n\n### [Advanced example](#advanced-example)\n\nThe advanced example shows a Compose file which defines two custom networks. The `proxy` service is isolated from the `db` service, because they do not share a network in common. Only `app` can talk to both.\n\n### [driver](#driver)\n\n`driver` specifies which driver should be used for this network. Compose returns an error if the driver is not available on the platform.\n\nFor more information on drivers and available options, see [Network drivers](https://docs.docker.com/network/drivers/).\n\n### [driver\\_opts](#driver_opts)\n\n`driver_opts` specifies a list of options as key-value pairs to pass to the driver. These options are driver-dependent. Consult the driver's documentation for more information.\n\n### [attachable](#attachable)\n\nIf `attachable` is set to `true`, then standalone containers should be able to attach to this network, in addition to services. If a standalone container attaches to the network, it can communicate with services and other standalone containers that are also attached to the network.\n\n### [enable\\_ipv6](#enable_ipv6)\n\n`enable_ipv6` enables IPv6 networking. For an example, see step four of [Create an IPv6 network](https://docs.docker.com/config/daemon/ipv6/).\n\n### [external](#external)\n\nIf set to `true`:\n\n*   `external` specifies that this networkâ€™s lifecycle is maintained outside of that of the application. Compose doesn't attempt to create these networks, and returns an error if one doesn't exist.\n*   All other attributes apart from name are irrelevant. If Compose detects any other attribute, it rejects the Compose file as invalid.\n\nIn the example below, `proxy` is the gateway to the outside world. Instead of attempting to create a network, Compose queries the platform for an existing network simply called `outside` and connects the `proxy` service's containers to it.\n\n### [ipam](#ipam)\n\n`ipam` specifies a custom IPAM configuration. This is an object with several properties, each of which is optional:\n\n*   `driver`: Custom IPAM driver, instead of the default.\n*   `config`: A list with zero or more configuration elements, each containing a:\n    *   `subnet`: Subnet in CIDR format that represents a network segment\n    *   `ip_range`: Range of IPs from which to allocate container IPs\n    *   `gateway`: IPv4 or IPv6 gateway for the master subnet\n    *   `aux_addresses`: Auxiliary IPv4 or IPv6 addresses used by Network driver, as a mapping from hostname to IP\n*   `options`: Driver-specific options as a key-value mapping.\n\n### [internal](#internal)\n\nBy default, Compose provides external connectivity to networks. `internal`, when set to `true`, allows you to create an externally isolated network.\n\n### [labels](#labels)\n\nAdd metadata to containers using `labels`. You can use either an array or a dictionary.\n\nIt is recommended that you use reverse-DNS notation to prevent labels from conflicting with those used by other software.\n\nCompose sets `com.docker.compose.project` and `com.docker.compose.network` labels.\n\n### [name](#name)\n\n`name` sets a custom name for the network. The name field can be used to reference networks which contain special characters. The name is used as is and is not scoped with the project name.\n\nIt can also be used in conjunction with the `external` property to define the platform network that Compose should retrieve, typically by using a parameter so the Compose file doesn't need to hard-code runtime specific values:\n\nFor more examples, see [Networking in Compose](https://docs.docker.com/compose/networking/).",
  "title": "Networks top-level elements | Docker Docs\n",
  "description": "Explore all the attributes the networks top-level element can have.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-file/07-volumes/",
  "markdown": "# Volumes top-level element | Docker Docs\n\nVolumes are persistent data stores implemented by the container engine. Compose offers a neutral way for services to mount volumes, and configuration parameters to allocate them to infrastructure. The top-level `volumes` declaration lets you configure named volumes that can be reused across multiple services.\n\nTo use a volume across multiple services, you must explicitly grant each service access by using the [volumes](https://docs.docker.com/compose/compose-file/05-services/#volumes) attribute within the `services` top-level element. The `volumes` attribute has additional syntax that provides more granular control.\n\n> **Tip**\n> \n> Working with large repositories or monorepos, or with virtual file systems that are no longer scaling with your codebase? Compose now takes advantage of [Synchronized file shares](https://docs.docker.com/desktop/synchronized-file-sharing/) and automatically creates file shares for bind mounts. Ensure you're signed in to Docker with a paid subscription and have enabled both **Access experimental features** and **Manage Synchronized file shares with Compose** in Docker Desktop's settings.\n\nThe following example shows a two-service setup where a database's data directory is shared with another service as a volume, named `db-data`, so that it can be periodically backed up.\n\nThe `db-data` volume is mounted at the `/var/lib/backup/data` and `/etc/data` container paths for backup and backend respectively.\n\nRunning `docker compose up` creates the volume if it doesn't already exist. Otherwise, the existing volume is used and is recreated if it's manually deleted outside of Compose.\n\nAn entry under the top-level `volumes` section can be empty, in which case it uses the container engine's default configuration for creating a volume. Optionally, you can configure it with the following keys:\n\n### [driver](#driver)\n\nSpecifies which volume driver should be used. If the driver is not available, Compose returns an error and doesn't deploy the application.\n\n### [driver\\_opts](#driver_opts)\n\n`driver_opts` specifies a list of options as key-value pairs to pass to the driver for this volume. The options are driver-dependent.\n\n### [external](#external)\n\nIf set to `true`:\n\n*   `external` specifies that this volume already exists on the platform and its lifecycle is managed outside of that of the application. Compose then doesn't create the volume and returns an error if the volume doesn't exist.\n*   All other attributes apart from `name` are irrelevant. If Compose detects any other attribute, it rejects the Compose file as invalid.\n\nIn the example below, instead of attempting to create a volume called `{project_name}_db-data`, Compose looks for an existing volume simply called `db-data` and mounts it into the `backend` service's containers.\n\n### [labels](#labels)\n\n`labels` are used to add metadata to volumes. You can use either an array or a dictionary.\n\nIt's recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.\n\nCompose sets `com.docker.compose.project` and `com.docker.compose.volume` labels.\n\n### [name](#name)\n\n`name` sets a custom name for a volume. The name field can be used to reference volumes that contain special characters. The name is used as is and is not scoped with the stack name.\n\nThis makes it possible to make this lookup name a parameter of the Compose file, so that the model ID for the volume is hard-coded but the actual volume ID on the platform is set at runtime during deployment.\n\nFor example, if `DATABASE_VOLUME=my_volume_001` in your `.env` file:\n\nRunning `docker compose up` uses the volume called `my_volume_001`.\n\nIt can also be used in conjunction with the `external` property. This means the name used to look up the actual volume on the platform is set separately from the name used to refer to the volume within the Compose file:",
  "title": "Volumes top-level element | Docker Docs\n",
  "description": "Explore all the attributes the volumes top-level element can have.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-file/08-configs/",
  "markdown": "# Configs top-level elements | Docker Docs\n\nConfigs let services to adapt their behaviour without the need to rebuild a Docker image. As with volumes, configs are mounted as files into a container's filesystem. The location of the mount point within the container defaults to `/<config-name>` in Linux containers and `C:\\<config-name>` in Windows containers.\n\nServices can only access configs when explicitly granted by a [`configs`](https://docs.docker.com/compose/compose-file/05-services/#configs) attribute within the `services` top-level element.\n\nBy default, the config:\n\n*   Is owned by the user running the container command but can be overridden by service configuration.\n*   Has world-readable permissions (mode 0444), unless the service is configured to override this.\n\nThe top-level `configs` declaration defines or references configuration data that is granted to services in your Compose application. The source of the config is either `file` or `external`.\n\n*   `file`: The config is created with the contents of the file at the specified path.\n*   `environment`: The config content is created with the value of an environment variable. Introduced in Docker Compose version [2.23.1](https://docs.docker.com/compose/release-notes/#2231).\n*   `content`: The content is created with the inlined value. Introduced in Docker Compose version [2.23.1](https://docs.docker.com/compose/release-notes/#2231).\n*   `external`: If set to true, `external` specifies that this config has already been created. Compose does not attempt to create it, and if it does not exist, an error occurs.\n*   `name`: The name of the config object in the container engine to look up. This field can be used to reference configs that contain special characters. The name is used as is and will **not** be scoped with the project name.\n\n`<project_name>_http_config` is created when the application is deployed, by registering the content of the `httpd.conf` as the configuration data.\n\nAlternatively, `http_config` can be declared as external. Compose looks up `http_config` to expose the configuration data to relevant services.\n\n`<project_name>_app_config` is created when the application is deployed, by registering the inlined content as the configuration data. This means Compose infers variables when creating the config, which allows you to adjust content according to service configuration:\n\nExternal configs lookup can also use a distinct key by specifying a `name`.\n\nThe following example modifies the previous one to look up a config using the parameter `HTTP_CONFIG_KEY`. The actual lookup key is set at deployment time by the [interpolation](https://docs.docker.com/compose/compose-file/12-interpolation/) of variables, but exposed to containers as hard-coded ID `http_config`.\n\nIf `external` is set to `true`, all other attributes apart from `name` are irrelevant. If Compose detects any other attribute, it rejects the Compose file as invalid.",
  "title": "Configs top-level elements | Docker Docs\n",
  "description": "Explore all the attributes the configs top-level element can have.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-file/05-services/",
  "markdown": "# Services top-level elements | Docker Docs\n\nA service is an abstract definition of a computing resource within an application which can be scaled or replaced independently from other components. Services are backed by a set of containers, run by the platform according to replication requirements and placement constraints. As services are backed by containers, they are defined by a Docker image and set of runtime arguments. All containers within a service are identically created with these arguments.\n\nA Compose file must declare a `services` top-level element as a map whose keys are string representations of service names, and whose values are service definitions. A service definition contains the configuration that is applied to each service container.\n\nEach service may also include a `build` section, which defines how to create the Docker image for the service. Compose supports building docker images using this service definition. If not used, the `build` section is ignored and the Compose file is still considered valid. Build support is an optional aspect of the Compose Specification, and is described in detail in the [Compose Build Specification](https://docs.docker.com/compose/compose-file/build/) documentation.\n\nEach service defines runtime constraints and requirements to run its containers. The `deploy` section groups these constraints and allows the platform to adjust the deployment strategy to best match containers' needs with available resources. Deploy support is an optional aspect of the Compose Specification, and is described in detail in the [Compose Deploy Specification](https://docs.docker.com/compose/compose-file/deploy/) documentation. If not implemented the `deploy` section is ignored and the Compose file is still considered valid.\n\n### [Simple example](#simple-example)\n\nThe following example demonstrates how to define two simple services, set their images, map ports, and configure basic environment variables using Docker Compose.\n\n### [Advanced example](#advanced-example)\n\nIn the following example, the `proxy` service uses the Nginx image, mounts a local Nginx configuration file into the container, exposes port `80` and depends on the `backend` service.\n\nThe `backend` service builds an image from the Dockerfile located in the `backend` directory that is set to build at stage `builder`.\n\nFor more example Compose files, explore the [Awesome Compose samples](https://github.com/docker/awesome-compose).\n\n### [annotations](#annotations)\n\n`annotations` defines annotations for the container. `annotations` can use either an array or a map.\n\n### [attach](#attach)\n\nIntroduced in Docker Compose version [2.20.0](https://docs.docker.com/compose/release-notes/#2200)\n\nWhen `attach` is defined and set to `false` Compose does not collect service logs, until you explicitly request it to.\n\nThe default service configuration is `attach: true`.\n\n### [build](#build)\n\n`build` specifies the build configuration for creating a container image from source, as defined in the [Compose Build Specification](https://docs.docker.com/compose/compose-file/build/).\n\n### [blkio\\_config](#blkio_config)\n\n`blkio_config` defines a set of configuration options to set block IO limits for a service.\n\n#### [device\\_read\\_bps, device\\_write\\_bps](#device_read_bps-device_write_bps)\n\nSet a limit in bytes per second for read / write operations on a given device. Each item in the list must have two keys:\n\n*   `path`: Defines the symbolic path to the affected device.\n*   `rate`: Either as an integer value representing the number of bytes or as a string expressing a byte value.\n\n#### [device\\_read\\_iops, device\\_write\\_iops](#device_read_iops-device_write_iops)\n\nSet a limit in operations per second for read / write operations on a given device. Each item in the list must have two keys:\n\n*   `path`: Defines the symbolic path to the affected device.\n*   `rate`: As an integer value representing the permitted number of operations per second.\n\n#### [weight](#weight)\n\nModify the proportion of bandwidth allocated to a service relative to other services. Takes an integer value between 10 and 1000, with 500 being the default.\n\n#### [weight\\_device](#weight_device)\n\nFine-tune bandwidth allocation by device. Each item in the list must have two keys:\n\n*   `path`: Defines the symbolic path to the affected device.\n*   `weight`: An integer value between 10 and 1000.\n\n### [cpu\\_count](#cpu_count)\n\n`cpu_count` defines the number of usable CPUs for service container.\n\n### [cpu\\_percent](#cpu_percent)\n\n`cpu_percent` defines the usable percentage of the available CPUs.\n\n### [cpu\\_shares](#cpu_shares)\n\n`cpu_shares` defines, as integer value, a service container's relative CPU weight versus other containers.\n\n### [cpu\\_period](#cpu_period)\n\n`cpu_period` configures CPU CFS (Completely Fair Scheduler) period when a platform is based on Linux kernel.\n\n### [cpu\\_quota](#cpu_quota)\n\n`cpu_quota` configures CPU CFS (Completely Fair Scheduler) quota when a platform is based on Linux kernel.\n\n### [cpu\\_rt\\_runtime](#cpu_rt_runtime)\n\n`cpu_rt_runtime` configures CPU allocation parameters for platforms with support for realtime scheduler. It can be either an integer value using microseconds as unit or a [duration](https://docs.docker.com/compose/compose-file/11-extension/#specifying-durations).\n\n### [cpu\\_rt\\_period](#cpu_rt_period)\n\n`cpu_rt_period` configures CPU allocation parameters for platforms with support for realtime scheduler. It can be either an integer value using microseconds as unit or a [duration](https://docs.docker.com/compose/compose-file/11-extension/#specifying-durations).\n\n### [cpus](#cpus)\n\n`cpus` define the number of (potentially virtual) CPUs to allocate to service containers. This is a fractional number. `0.000` means no limit.\n\nWhen set, `cpus` must be consistent with the `cpus` attribute in the [Deploy Specification](https://docs.docker.com/compose/compose-file/deploy/#cpus).\n\n### [cpuset](#cpuset)\n\n`cpuset` defines the explicit CPUs in which to allow execution. Can be a range `0-3` or a list `0,1`\n\n### [cap\\_add](#cap_add)\n\n`cap_add` specifies additional container [capabilities](https://man7.org/linux/man-pages/man7/capabilities.7.html) as strings.\n\n### [cap\\_drop](#cap_drop)\n\n`cap_drop` specifies container [capabilities](https://man7.org/linux/man-pages/man7/capabilities.7.html) to drop as strings.\n\n### [cgroup](#cgroup)\n\nIntroduced in Docker Compose version [2.15.0](https://docs.docker.com/compose/release-notes/#2150)\n\n`cgroup` specifies the cgroup namespace to join. When unset, it is the container runtime's decision to select which cgroup namespace to use, if supported.\n\n*   `host`: Runs the container in the Container runtime cgroup namespace.\n*   `private`: Runs the container in its own private cgroup namespace.\n\n### [cgroup\\_parent](#cgroup_parent)\n\n`cgroup_parent` specifies an optional parent [cgroup](https://man7.org/linux/man-pages/man7/cgroups.7.html) for the container.\n\n### [command](#command)\n\n`command` overrides the default command declared by the container image, for example by Dockerfile's `CMD`.\n\nThe value can also be a list, in a manner similar to [Dockerfile](https://docs.docker.com/reference/dockerfile/#cmd):\n\nIf the value is `null`, the default command from the image is used.\n\nIf the value is `[]` (empty list) or `''` (empty string), the default command declared by the image is ignored, i.e. overridden to be empty.\n\n### [configs](#configs)\n\nConfigs allow services to adapt their behaviour without the need to rebuild a Docker image. Services can only access configs when explicitly granted by the `configs` attribute. Two different syntax variants are supported.\n\nCompose reports an error if `config` doesn't exist on the platform or isn't defined in the [`configs` top-level element](https://docs.docker.com/compose/compose-file/08-configs/) in the Compose file.\n\nThere are two syntaxes defined for configs: a short syntax and a long syntax.\n\nYou can grant a service access to multiple configs, and you can mix long and short syntax.\n\n#### [Short syntax](#short-syntax)\n\nThe short syntax variant only specifies the config name. This grants the container access to the config and mounts it as files into a serviceâ€™s containerâ€™s filesystem. The location of the mount point within the container defaults to `/<config_name>` in Linux containers, and `C:\\<config-name>` in Windows containers.\n\nThe following example uses the short syntax to grant the `redis` service access to the `my_config` and `my_other_config` configs. The value of `my_config` is set to the contents of the file `./my_config.txt`, and `my_other_config` is defined as an external resource, which means that it has already been defined in the platform. If the external config does not exist, the deployment fails.\n\n#### [Long syntax](#long-syntax)\n\nThe long syntax provides more granularity in how the config is created within the service's task containers.\n\n*   `source`: The name of the config as it exists in the platform.\n*   `target`: The path and name of the file to be mounted in the service's task containers. Defaults to `/<source>` if not specified.\n*   `uid` and `gid`: The numeric UID or GID that owns the mounted config file within the service's task containers. Default value when not specified is USER running container.\n*   `mode`: The [permissions](https://wintelguy.com/permissions-calc.pl) for the file that is mounted within the service's task containers, in octal notation. Default value is world-readable (`0444`). Writable bit must be ignored. The executable bit can be set.\n\nThe following example sets the name of `my_config` to `redis_config` within the container, sets the mode to `0440` (group-readable) and sets the user and group to `103`. The `redis` service does not have access to the `my_other_config` config.\n\n### [container\\_name](#container_name)\n\n`container_name` is a string that specifies a custom container name, rather than a name generated by default.\n\nCompose does not scale a service beyond one container if the Compose file specifies a `container_name`. Attempting to do so results in an error.\n\n`container_name` follows the regex format of `[a-zA-Z0-9][a-zA-Z0-9_.-]+`\n\n### [credential\\_spec](#credential_spec)\n\n`credential_spec` configures the credential spec for a managed service account.\n\nIf you have services that use Windows containers, you can use `file:` and `registry:` protocols for `credential_spec`. Compose also supports additional protocols for custom use-cases.\n\nThe `credential_spec` must be in the format `file://<filename>` or `registry://<value-name>`.\n\nWhen using `registry:`, the credential spec is read from the Windows registry on the daemon's host. A registry value with the given name must be located in:\n\n```\nHKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Virtualization\\Containers\\CredentialSpecs\n```\n\nThe following example loads the credential spec from a value named `my-credential-spec` in the registry:\n\n#### [Example gMSA configuration](#example-gmsa-configuration)\n\nWhen configuring a gMSA credential spec for a service, you only need to specify a credential spec with `config`, as shown in the following example:\n\n### [depends\\_on](#depends_on)\n\nWith the `depends_on` attribute, you can control the order of service startup and shutdown. It is useful if services are closely coupled, and the startup sequence impacts the application's functionality.\n\n#### [Short syntax](#short-syntax-1)\n\nThe short syntax variant only specifies service names of the dependencies. Service dependencies cause the following behaviors:\n\n*   Compose creates services in dependency order. In the following example, `db` and `redis` are created before `web`.\n    \n*   Compose removes services in dependency order. In the following example, `web` is removed before `db` and `redis`.\n    \n\nSimple example:\n\nCompose guarantees dependency services have been started before starting a dependent service. Compose waits for dependency services to be \"ready\" before starting a dependent service.\n\n#### [Long syntax](#long-syntax-1)\n\nThe long form syntax enables the configuration of additional fields that can't be expressed in the short form.\n\n*   `restart`: When set to `true` Compose restarts this service after it updates the dependency service. This applies to an explicit restart controlled by a Compose operation, and excludes automated restart by the container runtime after the container dies. Introduced in Docker Compose version [2.17.0](https://docs.docker.com/compose/release-notes/#2170).\n    \n*   `condition`: Sets the condition under which dependency is considered satisfied\n    \n    *   `service_started`: An equivalent of the short syntax described above\n    *   `service_healthy`: Specifies that a dependency is expected to be \"healthy\" (as indicated by [healthcheck](#healthcheck)) before starting a dependent service.\n    *   `service_completed_successfully`: Specifies that a dependency is expected to run to successful completion before starting a dependent service.\n*   `required`: When set to `false` Compose only warns you when the dependency service isn't started or available. If it's not defined the default value of `required` is `true`. Introduced in Docker Compose version [2.20.0](https://docs.docker.com/compose/release-notes/#2200).\n    \n\nService dependencies cause the following behaviors:\n\n*   Compose creates services in dependency order. In the following example, `db` and `redis` are created before `web`.\n    \n*   Compose waits for healthchecks to pass on dependencies marked with `service_healthy`. In the following example, `db` is expected to be \"healthy\" before `web` is created.\n    \n*   Compose removes services in dependency order. In the following example, `web` is removed before `db` and `redis`.\n    \n\nCompose guarantees dependency services are started before starting a dependent service. Compose guarantees dependency services marked with `service_healthy` are \"healthy\" before starting a dependent service.\n\n### [deploy](#deploy)\n\n`deploy` specifies the configuration for the deployment and lifecycle of services, as defined [in the Compose Deploy Specification](https://docs.docker.com/compose/compose-file/deploy/).\n\n### [develop](#develop)\n\nIntroduced in Docker Compose version [2.22.0](https://docs.docker.com/compose/release-notes/#2220)\n\n`develop` specifies the development configuration for maintaining a container in sync with source, as defined in the [Development Section](https://docs.docker.com/compose/compose-file/develop/).\n\n### [device\\_cgroup\\_rules](#device_cgroup_rules)\n\n`device_cgroup_rules` defines a list of device cgroup rules for this container. The format is the same format the Linux kernel specifies in the [Control Groups Device Whitelist Controller](https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v1/devices.html).\n\n### [devices](#devices)\n\n`devices` defines a list of device mappings for created containers in the form of `HOST_PATH:CONTAINER_PATH[:CGROUP_PERMISSIONS]`.\n\n### [dns](#dns)\n\n`dns` defines custom DNS servers to set on the container network interface configuration. It can be a single value or a list.\n\n### [dns\\_opt](#dns_opt)\n\n`dns_opt` list custom DNS options to be passed to the containerâ€™s DNS resolver (`/etc/resolv.conf` file on Linux).\n\n### [dns\\_search](#dns_search)\n\n`dns_search` defines custom DNS search domains to set on container network interface configuration. It can be a single value or a list.\n\n### [domainname](#domainname)\n\n`domainname` declares a custom domain name to use for the service container. It must be a valid RFC 1123 hostname.\n\n### [entrypoint](#entrypoint)\n\n`entrypoint` declares the default entrypoint for the service container. This overrides the `ENTRYPOINT` instruction from the service's Dockerfile.\n\nIf `entrypoint` is non-null, Compose ignores any default command from the image, for example the `CMD` instruction in the Dockerfile.\n\nSee also [`command`](#command) to set or override the default command to be executed by the entrypoint process.\n\nIn its short form, the value can be defined as a string:\n\nAlternatively, the value can also be a list, in a manner similar to the [Dockerfile](https://docs.docker.com/reference/dockerfile/#cmd):\n\nIf the value is `null`, the default entrypoint from the image is used.\n\nIf the value is `[]` (empty list) or `''` (empty string), the default entrypoint declared by the image is ignored, i.e. overridden to be empty.\n\n### [env\\_file](#env_file)\n\nThe `env_file` attribute is used to specify one or more files that contain environment variables to be passed to the containers.\n\n`env_file` can also be a list. The files in the list are processed from the top down. For the same variable specified in two env files, the value from the last file in the list stands.\n\nList elements can also be declared as a mapping, which then lets you set an additional attribute `required`. This defaults to `true`. When `required` is set to `false` and the `.env` file is missing, Compose silently ignores the entry.\n\n> `required` attribute is available with Docker Compose version 2.24.0 or later.\n\nRelative path are resolved from the Compose file's parent folder. As absolute paths prevent the Compose file from being portable, Compose warns you when such a path is used to set `env_file`.\n\nEnvironment variables declared in the [environment](#environment) section override these values. This holds true even if those values are empty or undefined.\n\n#### [Env\\_file format](#env_file-format)\n\nEach line in an `.env` file must be in `VAR[=[VAL]]` format. The following syntax rules apply:\n\n*   Lines beginning with `#` are processed as comments and ignored.\n*   Blank lines are ignored.\n*   Unquoted and double-quoted (`\"`) values have [Interpolation](https://docs.docker.com/compose/compose-file/12-interpolation/) applied.\n*   Each line represents a key-value pair. Values can optionally be quoted.\n    *   `VAR=VAL` -> `VAL`\n    *   `VAR=\"VAL\"` -> `VAL`\n    *   `VAR='VAL'` -> `VAL`\n*   Inline comments for unquoted values must be preceded with a space.\n    *   `VAR=VAL # comment` -> `VAL`\n    *   `VAR=VAL# not a comment` -> `VAL# not a comment`\n*   Inline comments for quoted values must follow the closing quote.\n    *   `VAR=\"VAL # not a comment\"` -> `VAL # not a comment`\n    *   `VAR=\"VAL\" # comment` -> `VAL`\n*   Single-quoted (`'`) values are used literally.\n    *   `VAR='$OTHER'` -> `$OTHER`\n    *   `VAR='${OTHER}'` -> `${OTHER}`\n*   Quotes can be escaped with `\\`.\n    *   `VAR='Let\\'s go!'` -> `Let's go!`\n    *   `VAR=\"{\\\"hello\\\": \\\"json\\\"}\"` -> `{\"hello\": \"json\"}`\n*   Common shell escape sequences including `\\n`, `\\r`, `\\t`, and `\\\\` are supported in double-quoted values.\n    *   `VAR=\"some\\tvalue\"` -> `some value`\n    *   `VAR='some\\tvalue'` -> `some\\tvalue`\n    *   `VAR=some\\tvalue` -> `some\\tvalue`\n\n`VAL` may be omitted, in such cases the variable value is an empty string. `=VAL` may be omitted, in such cases the variable is unset.\n\n### [environment](#environment)\n\nThe `environment` attribute defines environment variables set in the container. `environment` can use either an array or a map. Any boolean values; true, false, yes, no, should be enclosed in quotes to ensure they are not converted to True or False by the YAML parser.\n\nEnvironment variables can be declared by a single key (no value to equals sign). In this case Compose relies on you to resolve the value. If the value is not resolved, the variable is unset and is removed from the service container environment.\n\nMap syntax:\n\nArray syntax:\n\nWhen both `env_file` and `environment` are set for a service, values set by `environment` have precedence.\n\n### [expose](#expose)\n\n`expose` defines the (incoming) port or a range of ports that Compose exposes from the container. These ports must be accessible to linked services and should not be published to the host machine. Only the internal container ports can be specified.\n\nSyntax is `<portnum>/[<proto>]` or `<startport-endport>/[<proto>]` for a port range. When not explicitly set, `tcp` protocol is used.\n\n> **Note**\n> \n> If the Dockerfile for the image already exposes ports, it is visible to other containers on the network even if `expose` is not set in your Compose file.\n\n### [extends](#extends)\n\n`extends` lets you share common configurations among different files, or even different projects entirely. With `extends` you can define a common set of service options in one place and refer to it from anywhere. You can refer to another Compose file and select a service you want to also use in your own application, with the ability to override some attributes for your own needs.\n\nYou can use `extends` on any service together with other configuration keys. The `extends` value must be a mapping defined with a required `service` and an optional `file` key.\n\n*   `service`: Defines the name of the service being referenced as a base, for example `web` or `database`.\n*   `file`: The location of a Compose configuration file defining that service.\n\nWhen a service uses `extends`, it can also specify dependencies on other resources, an explicit `volumes` declaration for instance. However, it's important to note that `extends` does not automatically incorporate the target volume definition into the extending Compose file. Instead, you are responsible for ensuring that an equivalent resource exists for the service being extended to maintain consistency. Docker Compose verifies that a resource with the referenced ID is present within the Compose model.\n\nDependencies on other resources in an `extends` target can be:\n\n*   An explicit reference by `volumes`, `networks`, `configs`, `secrets`, `links`, `volumes_from` or `depends_on`\n*   A reference to another service using the `service:{name}` syntax in namespace declaration (`ipc`, `pid`, `network_mode`)\n\nCircular references with `extends` are not supported, Compose returns an error when one is detected.\n\n#### [Finding referenced service](#finding-referenced-service)\n\n`file` value can be:\n\n*   Not present. This indicates that another service within the same Compose file is being referenced.\n*   File path, which can be either:\n    *   Relative path. This path is considered as relative to the location of the main Compose file.\n    *   Absolute path.\n\nA service denoted by `service` must be present in the identified referenced Compose file. Compose returns an error if:\n\n*   The service denoted by `service` is not found.\n*   The Compose file denoted by `file` is not found.\n\n#### [Merging service definitions](#merging-service-definitions)\n\nTwo service definitions, the main one in the current Compose file and the referenced one specified by `extends`, are merged in the following way:\n\n*   Mappings: Keys in mappings of the main service definition override keys in mappings of the referenced service definition. Keys that aren't overridden are included as is.\n*   Sequences: Items are combined together into a new sequence. The order of elements is preserved with the referenced items coming first and main items after.\n*   Scalars: Keys in the main service definition take precedence over keys in the referenced one.\n\n##### [Mappings](#mappings)\n\nThe following keys should be treated as mappings: `annotations`, `build.args`, `build.labels`, `build.extra_hosts`, `deploy.labels`, `deploy.update_config`, `deploy.rollback_config`, `deploy.restart_policy`, `deploy.resources.limits`, `environment`, `healthcheck`, `labels`, `logging.options`, `sysctls`, `storage_opt`, `extra_hosts`, `ulimits`.\n\nOne exception that applies to `healthcheck` is that the main mapping cannot specify `disable: true` unless the referenced mapping also specifies `disable: true`. Compose returns an error in this case.\n\nFor example, the input below:\n\nProduces the following configuration for the `cli` service. The same output is produced if array syntax is used.\n\nItems under `blkio_config.device_read_bps`, `blkio_config.device_read_iops`, `blkio_config.device_write_bps`, `blkio_config.device_write_iops`, `devices` and `volumes` are also treated as mappings where key is the target path inside the container.\n\nFor example, the input below:\n\nProduces the following configuration for the `cli` service. Note that the mounted path now points to the new volume name and `ro` flag was applied.\n\nIf the referenced service definition contains `extends` mapping, the items under it are simply copied into the new merged definition. The merging process is then kicked off again until no `extends` keys are remaining.\n\nFor example, the input below:\n\nProduces the following configuration for the `cli` service. Here, `cli` services gets `user` key from `common` service, which in turn gets this key from `base` service.\n\n##### [Sequences](#sequences)\n\nThe following keys should be treated as sequences: `cap_add`, `cap_drop`, `configs`, `deploy.placement.constraints`, `deploy.placement.preferences`, `deploy.reservations.generic_resources`, `device_cgroup_rules`, `expose`, `external_links`, `ports`, `secrets`, `security_opt`. Any duplicates resulting from the merge are removed so that the sequence only contains unique elements.\n\nFor example, the input below:\n\nProduces the following configuration for the `cli` service.\n\nIn case list syntax is used, the following keys should also be treated as sequences: `dns`, `dns_search`, `env_file`, `tmpfs`. Unlike sequence fields mentioned above, duplicates resulting from the merge are not removed.\n\n##### [Scalars](#scalars)\n\nAny other allowed keys in the service definition should be treated as scalars.\n\n### [external\\_links](#external_links)\n\n`external_links` link service containers to services managed outside of your Compose application. `external_links` define the name of an existing service to retrieve using the platform lookup mechanism. An alias of the form `SERVICE:ALIAS` can be specified.\n\n`extra_hosts` adds hostname mappings to the container network interface configuration (`/etc/hosts` for Linux).\n\n#### [Short syntax](#short-syntax-2)\n\nShort syntax uses plain strings in a list. Values must set hostname and IP address for additional hosts in the form of `HOSTNAME=IP`.\n\nIPv6 addresses can be enclosed in square brackets, for example:\n\nThe separator `=` is preferred, but `:` can also be used. Introduced in Docker Compose version [2.24.1](https://docs.docker.com/compose/release-notes/#2241). For example:\n\n#### [Long syntax](#long-syntax-2)\n\nAlternatively, `extra_hosts` can be set as a mapping between hostname(s) and IP(s)\n\nCompose creates a matching entry with the IP address and hostname in the container's network configuration, which means for Linux `/etc/hosts` get extra lines:\n\n### [group\\_add](#group_add)\n\n`group_add` specifies additional groups, by name or number, which the user inside the container must be a member of.\n\nAn example of where this is useful is when multiple containers (running as different users) need to all read or write the same file on a shared volume. That file can be owned by a group shared by all the containers, and specified in `group_add`.\n\nRunning `id` inside the created container must show that the user belongs to the `mail` group, which would not have been the case if `group_add` were not declared.\n\n### [healthcheck](#healthcheck)\n\nThe `healthcheck` attribute declares a check that's run to determine whether or not the service containers are \"healthy\". It works in the same way, and has the same default values, as the HEALTHCHECK Dockerfile instruction set by the service's Docker image. Your Compose file can override the values set in the Dockerfile.\n\nFor more information on `HEALTHCHECK`, see the [Dockerfile reference](https://docs.docker.com/reference/dockerfile/#healthcheck).\n\n`interval`, `timeout`, `start_period`, and `start_interval` are [specified as durations](https://docs.docker.com/compose/compose-file/11-extension/#specifying-durations). Introduced in Docker Compose version [2.20.2](https://docs.docker.com/compose/release-notes/#2202)\n\n`test` defines the command Compose runs to check container health. It can be either a string or a list. If it's a list, the first item must be either `NONE`, `CMD` or `CMD-SHELL`. If it's a string, it's equivalent to specifying `CMD-SHELL` followed by that string.\n\nUsing `CMD-SHELL` runs the command configured as a string using the container's default shell (`/bin/sh` for Linux). Both forms below are equivalent:\n\n`NONE` disables the healthcheck, and is mostly useful to disable the Healthcheck Dockerfile instruction set by the service's Docker image. Alternatively, the healthcheck set by the image can be disabled by setting `disable: true`:\n\n### [hostname](#hostname)\n\n`hostname` declares a custom host name to use for the service container. It must be a valid RFC 1123 hostname.\n\n### [image](#image)\n\n`image` specifies the image to start the container from. `image` must follow the Open Container Specification [addressable image format](https://github.com/opencontainers/org/blob/master/docs/docs/introduction/digests.md), as `[<registry>/][<project>/]<image>[:<tag>|@<digest>]`.\n\nIf the image does not exist on the platform, Compose attempts to pull it based on the `pull_policy`. If you are also using the [Compose Build Specification](https://docs.docker.com/compose/compose-file/build/), there are alternative options for controlling the precedence of pull over building the image from source, however pulling the image is the default behavior.\n\n`image` may be omitted from a Compose file as long as a `build` section is declared. If you are not using the Compose Build Specification, Compose won't work if `image` is missing from the Compose file.\n\n### [init](#init)\n\n`init` runs an init process (PID 1) inside the container that forwards signals and reaps processes. Set this option to `true` to enable this feature for the service.\n\nThe init binary that is used is platform specific.\n\n### [ipc](#ipc)\n\n`ipc` configures the IPC isolation mode set by the service container.\n\n*   `shareable`: Gives the container its own private IPC namespace, with a possibility to share it with other containers.\n*   `service:{name}`: Makes the container join another container's (`shareable`) IPC namespace.\n\n### [isolation](#isolation)\n\n`isolation` specifies a containerâ€™s isolation technology. Supported values are platform specific.\n\n### [labels](#labels)\n\n`labels` add metadata to containers. You can use either an array or a map.\n\nIt's recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.\n\nCompose creates containers with canonical labels:\n\n*   `com.docker.compose.project` set on all resources created by Compose to the user project name\n*   `com.docker.compose.service` set on service containers with service name as defined in the Compose file\n\nThe `com.docker.compose` label prefix is reserved. Specifying labels with this prefix in the Compose file results in a runtime error.\n\n### [links](#links)\n\n`links` defines a network link to containers in another service. Either specify both the service name and a link alias (`SERVICE:ALIAS`), or just the service name.\n\nContainers for the linked service are reachable at a hostname identical to the alias, or the service name if no alias is specified.\n\nLinks are not required to enable services to communicate. When no specific network configuration is set, any service is able to reach any other service at that serviceâ€™s name on the `default` network. If services do declare networks they are attached to, `links` does not override the network configuration and services not attached to a shared network are not be able to communicate. Compose doesn't warn you about a configuration mismatch.\n\nLinks also express implicit dependency between services in the same way as [depends\\_on](#depends_on), so they determine the order of service startup.\n\n### [logging](#logging)\n\n`logging` defines the logging configuration for the service.\n\nThe `driver` name specifies a logging driver for the service's containers. The default and available values are platform specific. Driver specific options can be set with `options` as key-value pairs.\n\n### [mac\\_address](#mac_address)\n\n> Available with Docker Compose version 2.24.0 and later.\n\n`mac_address` sets a MAC address for the service container.\n\n> **Note** Container runtimes might reject this value (ie. Docker Engine >= v25.0). In that case, you should use [networks.mac\\_address](#mac_address) instead.\n\n### [mem\\_limit](#mem_limit)\n\n`mem_limit` configures a limit on the amount of memory a container can allocate, set as a string expressing a [byte value](https://docs.docker.com/compose/compose-file/11-extension/#specifying-byte-values).\n\nWhen set, `mem_limit` must be consistent with the `limits.memory` attribute in the [Deploy Specification](https://docs.docker.com/compose/compose-file/deploy/#memory).\n\n### [mem\\_reservation](#mem_reservation)\n\n`mem_reservation` configures a reservation on the amount of memory a container can allocate, set as a string expressing a [byte value](https://docs.docker.com/compose/compose-file/11-extension/#specifying-byte-values).\n\nWhen set, `mem_reservation` must be consistent with the `reservations.memory` attribute in the [Deploy Specification](https://docs.docker.com/compose/compose-file/deploy/#memory).\n\n### [mem\\_swappiness](#mem_swappiness)\n\n`mem_swappiness` defines as a percentage, a value between 0 and 100, for the host kernel to swap out anonymous memory pages used by a container.\n\n*   `0`: Turns off anonymous page swapping.\n*   `100`: Sets all anonymous pages as swappable.\n\nThe default value is platform specific.\n\n### [memswap\\_limit](#memswap_limit)\n\n`memswap_limit` defines the amount of memory the container is allowed to swap to disk. This is a modifier attribute that only has meaning if [`memory`](https://docs.docker.com/compose/compose-file/deploy/#memory) is also set. Using swap lets the container write excess memory requirements to disk when the container has exhausted all the memory that is available to it. There is a performance penalty for applications that swap memory to disk often.\n\n*   If `memswap_limit` is set to a positive integer, then both `memory` and `memswap_limit` must be set. `memswap_limit` represents the total amount of memory and swap that can be used, and `memory` controls the amount used by non-swap memory. So if `memory`\\=\"300m\" and `memswap_limit`\\=\"1g\", the container can use 300m of memory and 700m (1g - 300m) swap.\n*   If `memswap_limit` is set to 0, the setting is ignored, and the value is treated as unset.\n*   If `memswap_limit` is set to the same value as `memory`, and `memory` is set to a positive integer, the container does not have access to swap.\n*   If `memswap_limit` is unset, and `memory` is set, the container can use as much swap as the `memory` setting, if the host container has swap memory configured. For instance, if `memory`\\=\"300m\" and `memswap_limit` is not set, the container can use 600m in total of memory and swap.\n*   If `memswap_limit` is explicitly set to -1, the container is allowed to use unlimited swap, up to the amount available on the host system.\n\n### [network\\_mode](#network_mode)\n\n`network_mode` sets a service container's network mode.\n\n*   `none`: Turns off all container networking.\n*   `host`: Gives the container raw access to the host's network interface.\n*   `service:{name}`: Gives the containers access to the specified service only. For more information, see [Container networks](https://docs.docker.com/network/#container-networks).\n\nWhen set, the [`networks`](#networks) attribute is not allowed and Compose rejects any Compose file containing both attributes.\n\n### [networks](#networks)\n\nThe `networks` attribute defines the networks that service containers are attached to, referencing entries under the `networks` top-level element. The `networks` attribute helps manage the networking aspects of containers, providing control over how services are segmented and interact within the Docker environment. This is used to specify which networks the containers for that service should connect to. This is important for defining how containers communicate with each other and externally.\n\nFor more information about the `networks` top-level element, see [Networks](https://docs.docker.com/compose/compose-file/06-networks/).\n\n#### [aliases](#aliases)\n\n`aliases` declares alternative hostnames for the service on the network. Other containers on the same network can use either the service name or an alias to connect to one of the service's containers.\n\nSince `aliases` are network-scoped, the same service can have different aliases on different networks.\n\n> **Note** A network-wide alias can be shared by multiple containers, and even by multiple services. If it is, then exactly which container the name resolves to is not guaranteed.\n\nIn the following example, service `frontend` is able to reach the `backend` service at the hostname `backend` or `database` on the `back-tier` network. The service `monitoring` is able to reach same `backend` service at `backend` or `mysql` on the `admin` network.\n\n#### [ipv4\\_address, ipv6\\_address](#ipv4_address-ipv6_address)\n\nSpecify a static IP address for a service container when joining the network.\n\nThe corresponding network configuration in the [top-level networks section](https://docs.docker.com/compose/compose-file/06-networks/) must have an `ipam` attribute with subnet configurations covering each static address.\n\n#### [link\\_local\\_ips](#link_local_ips)\n\n`link_local_ips` specifies a list of link-local IPs. Link-local IPs are special IPs which belong to a well known subnet and are purely managed by the operator, usually dependent on the architecture where they are deployed.\n\nExample:\n\n#### [mac\\_address](#mac_address-1)\n\nIntroduced in Docker Compose version [2.23.2](https://docs.docker.com/compose/release-notes/#2232)\n\n`mac_address` sets the MAC address used by the service container when connecting to this particular network.\n\n#### [priority](#priority)\n\n`priority` indicates in which order Compose connects the serviceâ€™s containers to its networks. If unspecified, the default value is 0.\n\nIn the following example, the app service connects to `app_net_1` first as it has the highest priority. It then connects to `app_net_3`, then `app_net_2`, which uses the default priority value of 0.\n\n### [oom\\_kill\\_disable](#oom_kill_disable)\n\nIf `oom_kill_disable` is set, Compose configures the platform so it won't kill the container in case of memory starvation.\n\n### [oom\\_score\\_adj](#oom_score_adj)\n\n`oom_score_adj` tunes the preference for containers to be killed by platform in case of memory starvation. Value must be within -1000,1000 range.\n\n### [pid](#pid)\n\n`pid` sets the PID mode for container created by Compose. Supported values are platform specific.\n\n### [pids\\_limit](#pids_limit)\n\n`pids_limit` tunes a containerâ€™s PIDs limit. Set to -1 for unlimited PIDs.\n\nWhen set, `pids_limit` must be consistent with the `pids` attribute in the [Deploy Specification](https://docs.docker.com/compose/compose-file/deploy/#pids).\n\n### [platform](#platform)\n\n`platform` defines the target platform the containers for the service run on. It uses the `os[/arch[/variant]]` syntax.\n\nThe values of `os`, `arch`, and `variant` must conform to the convention used by the [OCI Image Spec](https://github.com/opencontainers/image-spec/blob/v1.0.2/image-index.md).\n\nCompose uses this attribute to determine which version of the image is pulled and/or on which platform the serviceâ€™s build is performed.\n\n### [ports](#ports)\n\nThe `ports` is used to define the port mappings between the host machine and the containers. This is crucial for allowing external access to services running inside containers. It can be defined using short syntax for simple port mapping or long syntax, which includes additional options like protocol type and network mode.\n\n> **Note**\n> \n> Port mapping must not be used with `network_mode: host` otherwise a runtime error occurs.\n\n#### [Short syntax](#short-syntax-3)\n\nThe short syntax is a colon-separated string to set the host IP, host port, and container port in the form:\n\n`[HOST:]CONTAINER[/PROTOCOL]` where:\n\n*   `HOST` is `[IP:](port | range)`\n*   `CONTAINER` is `port | range`\n*   `PROTOCOL` to restrict port to specified protocol. `tcp` and `udp` values are defined by the Specification, Compose offers support for platform-specific protocol names.\n\nIf host IP is not set, it binds to all network interfaces. Ports can be either a single value or a range. Host and container must use equivalent ranges.\n\nEither specify both ports (`HOST:CONTAINER`), or just the container port. In the latter case, the container runtime automatically allocates any unassigned port of the host.\n\n`HOST:CONTAINER` should always be specified as a (quoted) string, to avoid conflicts with [yaml base-60 float](https://yaml.org/type/float.html).\n\nExamples:\n\n> **Note**\n> \n> If Host IP mapping is not supported by a container engine, Compose rejects the Compose file and ignores the specified host IP.\n\n#### [Long syntax](#long-syntax-3)\n\nThe long form syntax allows the configuration of additional fields that can't be expressed in the short form.\n\n*   `target`: The container port\n*   `published`: The publicly exposed port. It is defined as a string and can be set as a range using syntax `start-end`. It means the actual port is assigned a remaining available port, within the set range.\n*   `host_ip`: The Host IP mapping, unspecified means all network interfaces (`0.0.0.0`).\n*   `protocol`: The port protocol (`tcp` or `udp`). Defaults to `tcp`.\n*   `app_protocol`: The application protocol (TCP/IP level 4 / OSI level 7) this port is used for. This is optional and can be used as a hint for Compose to offer richer behavior for protocols that it understands. Introduced in Docker Compose version [2.26.0](https://docs.docker.com/compose/release-notes/#2260).\n*   `mode`: `host`: For publishing a host port on each node, or `ingress` for a port to be load balanced. Defaults to `ingress`.\n*   `name`: A human-readable name for the port, used to document it's usage within the service.\n\n### [privileged](#privileged)\n\n`privileged` configures the service container to run with elevated privileges. Support and actual impacts are platform specific.\n\n### [profiles](#profiles)\n\n`profiles` defines a list of named profiles for the service to be enabled under. If unassigned, the service is always started but if assigned, it is only started if the profile is activated.\n\nIf present, `profiles` follow the regex format of `[a-zA-Z0-9][a-zA-Z0-9_.-]+`.\n\n### [pull\\_policy](#pull_policy)\n\n`pull_policy` defines the decisions Compose makes when it starts to pull images. Possible values are:\n\n*   `always`: Compose always pulls the image from the registry.\n*   `never`: Compose doesn't pull the image from a registry and relies on the platform cached image. If there is no cached image, a failure is reported.\n*   `missing`: Compose pulls the image only if it's not available in the platform cache. This is the default option if you are not also using the [Compose Build Specification](https://docs.docker.com/compose/compose-file/build/). `if_not_present` is considered an alias for this value for backward compatibility.\n*   `build`: Compose builds the image. Compose rebuilds the image if it's already present.\n\n### [read\\_only](#read_only)\n\n`read_only` configures the service container to be created with a read-only filesystem.\n\n### [restart](#restart)\n\n`restart` defines the policy that the platform applies on container termination.\n\n*   `no`: The default restart policy. It does not restart the container under any circumstances.\n*   `always`: The policy always restarts the container until its removal.\n*   `on-failure[:max-retries]`: The policy restarts the container if the exit code indicates an error. Optionally, limit the number of restart retries the Docker daemon attempts.\n*   `unless-stopped`: The policy restarts the container irrespective of the exit code but stops restarting when the service is stopped or removed.\n\nYou can find more detailed information on restart policies in the [Restart Policies (--restart)](https://docs.docker.com/reference/cli/docker/container/run/#restart) section of the Docker run reference page.\n\n### [runtime](#runtime)\n\n`runtime` specifies which runtime to use for the serviceâ€™s containers.\n\nFor example, `runtime` can be the name of [an implementation of OCI Runtime Spec](https://github.com/opencontainers/runtime-spec/blob/master/implementations.md), such as \"runc\".\n\nThe default is `runc`. To use a different runtime, see [Alternative runtimes](https://docs.docker.com/engine/alternative-runtimes/).\n\n### [scale](#scale)\n\n`scale` specifies the default number of containers to deploy for this service. When both are set, `scale` must be consistent with the `replicas` attribute in the [Deploy Specification](https://docs.docker.com/compose/compose-file/deploy/#replicas).\n\n### [secrets](#secrets)\n\nThe `secrets` attribute grants access to sensitive data defined by the secrets top-level element on a per-service basis. Services can be granted access to multiple secrets.\n\nTwo different syntax variants are supported; the short syntax and the long syntax. Long and short syntax for secrets may be used in the same Compose file.\n\nCompose reports an error if the secret doesn't exist on the platform or isn't defined in the [`secrets` top-level section](https://docs.docker.com/compose/compose-file/09-secrets/) of the Compose file.\n\nDefining a secret in the top-level `secrets` must not imply granting any service access to it. Such grant must be explicit within service specification as [secrets](https://docs.docker.com/compose/compose-file/09-secrets/) service element.\n\n#### [Short syntax](#short-syntax-4)\n\nThe short syntax variant only specifies the secret name. This grants the container access to the secret and mounts it as read-only to `/run/secrets/<secret_name>` within the container. The source name and destination mountpoint are both set to the secret name.\n\nThe following example uses the short syntax to grant the `frontend` service access to the `server-certificate` secret. The value of `server-certificate` is set to the contents of the file `./server.cert`.\n\n#### [Long syntax](#long-syntax-4)\n\nThe long syntax provides more granularity in how the secret is created within the service's containers.\n\n*   `source`: The name of the secret as it exists on the platform.\n*   `target`: The name of the file to be mounted in `/run/secrets/` in the service's task container, or absolute path of the file if an alternate location is required. Defaults to `source` if not specified.\n*   `uid` and `gid`: The numeric UID or GID that owns the file within `/run/secrets/` in the service's task containers. Default value is USER running container.\n*   `mode`: The [permissions](https://wintelguy.com/permissions-calc.pl) for the file to be mounted in `/run/secrets/` in the service's task containers, in octal notation. The default value is world-readable permissions (mode `0444`). The writable bit must be ignored if set. The executable bit may be set.\n\nThe following example sets the name of the `server-certificate` secret file to `server.cert` within the container, sets the mode to `0440` (group-readable), and sets the user and group to `103`. The value of `server-certificate` is set to the contents of the file `./server.cert`.\n\n### [security\\_opt](#security_opt)\n\n`security_opt` overrides the default labeling scheme for each container.\n\nFor further default labeling schemes you can override, see [Security configuration](https://docs.docker.com/reference/cli/docker/container/run/#security-opt).\n\n### [shm\\_size](#shm_size)\n\n`shm_size` configures the size of the shared memory (`/dev/shm` partition on Linux) allowed by the service container. It's specified as a [byte value](https://docs.docker.com/compose/compose-file/11-extension/#specifying-byte-values).\n\n### [stdin\\_open](#stdin_open)\n\n`stdin_open` configures a service's container to run with an allocated stdin. This is the same as running a container with the `-i` flag. For more information, see [Keep STDIN open](https://docs.docker.com/reference/cli/docker/container/run/#interactive).\n\nSupported values are `true` or `false`.\n\n### [stop\\_grace\\_period](#stop_grace_period)\n\n`stop_grace_period` specifies how long Compose must wait when attempting to stop a container if it doesn't handle SIGTERM (or whichever stop signal has been specified with [`stop_signal`](#stop_signal)), before sending SIGKILL. It's specified as a [duration](https://docs.docker.com/compose/compose-file/11-extension/#specifying-durations).\n\nDefault value is 10 seconds for the container to exit before sending SIGKILL.\n\n### [stop\\_signal](#stop_signal)\n\n`stop_signal` defines the signal that Compose uses to stop the service containers. If unset containers are stopped by Compose by sending `SIGTERM`.\n\n### [storage\\_opt](#storage_opt)\n\n`storage_opt` defines storage driver options for a service.\n\n### [sysctls](#sysctls)\n\n`sysctls` defines kernel parameters to set in the container. `sysctls` can use either an array or a map.\n\nYou can only use sysctls that are namespaced in the kernel. Docker does not support changing sysctls inside a container that also modify the host system. For an overview of supported sysctls, refer to [configure namespaced kernel parameters (sysctls) at runtime](https://docs.docker.com/reference/cli/docker/container/run/#sysctl).\n\n### [tmpfs](#tmpfs)\n\n`tmpfs` mounts a temporary file system inside the container. It can be a single value or a list.\n\n### [tty](#tty)\n\n`tty` configures a service's container to run with a TTY. This is the same as running a container with the `-t` or `--tty` flag. For more information, see [Allocate a pseudo-TTY](https://docs.docker.com/reference/cli/docker/container/run/#tty).\n\nSupported values are `true` or `false`.\n\n### [ulimits](#ulimits)\n\n`ulimits` overrides the default ulimits for a container. It's specified either as an integer for a single limit or as mapping for soft/hard limits.\n\n### [user](#user)\n\n`user` overrides the user used to run the container process. The default is set by the image (i.e. Dockerfile `USER`). If it's not set, then `root`.\n\n### [userns\\_mode](#userns_mode)\n\n`userns_mode` sets the user namespace for the service. Supported values are platform specific and may depend on platform configuration.\n\n### [uts](#uts)\n\nIntroduced in Docker Compose version [2.15.1](https://docs.docker.com/compose/release-notes/#2151)\n\n`uts` configures the UTS namespace mode set for the service container. When unspecified it is the runtime's decision to assign a UTS namespace, if supported. Available values are:\n\n*   `'host'`: Results in the container using the same UTS namespace as the host.\n\n### [volumes](#volumes)\n\nThe `volumes` attribute define mount host paths or named volumes that are accessible by service containers. You can use `volumes` to define multiple types of mounts; `volume`, `bind`, `tmpfs`, or `npipe`.\n\nIf the mount is a host path and is only used by a single service, it can be declared as part of the service definition. To reuse a volume across multiple services, a named volume must be declared in the `volumes` top-level element.\n\nThe following example shows a named volume (`db-data`) being used by the `backend` service, and a bind mount defined for a single service.\n\nFor more information about the `volumes` top-level element, see [Volumes](https://docs.docker.com/compose/compose-file/07-volumes/).\n\n#### [Short syntax](#short-syntax-5)\n\nThe short syntax uses a single string with colon-separated values to specify a volume mount (`VOLUME:CONTAINER_PATH`), or an access mode (`VOLUME:CONTAINER_PATH:ACCESS_MODE`).\n\n*   `VOLUME`: Can be either a host path on the platform hosting containers (bind mount) or a volume name.\n*   `CONTAINER_PATH`: The path in the container where the volume is mounted.\n*   `ACCESS_MODE`: A comma-separated `,` list of options:\n    *   `rw`: Read and write access. This is the default if none is specified.\n    *   `ro`: Read-only access.\n    *   `z`: SELinux option indicating that the bind mount host content is shared among multiple containers.\n    *   `Z`: SELinux option indicating that the bind mount host content is private and unshared for other containers.\n\n> **Note**\n> \n> The SELinux re-labeling bind mount option is ignored on platforms without SELinux.\n\n> **Note** Relative host paths are only supported by Compose that deploy to a local container runtime. This is because the relative path is resolved from the Compose fileâ€™s parent directory which is only applicable in the local case. When Compose deploys to a non-local platform it rejects Compose files which use relative host paths with an error. To avoid ambiguities with named volumes, relative paths should always begin with `.` or `..`.\n\n#### [Long syntax](#long-syntax-5)\n\nThe long form syntax allows the configuration of additional fields that can't be expressed in the short form.\n\n*   `type`: The mount type. Either `volume`, `bind`, `tmpfs`, `npipe`, or `cluster`\n*   `source`: The source of the mount, a path on the host for a bind mount, or the name of a volume defined in the [top-level `volumes` key](https://docs.docker.com/compose/compose-file/07-volumes/). Not applicable for a tmpfs mount.\n*   `target`: The path in the container where the volume is mounted.\n*   `read_only`: Flag to set the volume as read-only.\n*   `bind`: Used to configure additional bind options:\n    *   `propagation`: The propagation mode used for the bind.\n    *   `create_host_path`: Creates a directory at the source path on host if there is nothing present. Compose does nothing if there is something present at the path. This is automatically implied by short syntax for backward compatibility with `docker-compose` legacy.\n    *   `selinux`: The SELinux re-labeling option `z` (shared) or `Z` (private)\n*   `volume`: Configures additional volume options:\n    *   `nocopy`: Flag to disable copying of data from a container when a volume is created.\n    *   `subpath`: Path inside a volume to mount instead of the volume root.\n*   `tmpfs`: Configures additional tmpfs options:\n    *   `size`: The size for the tmpfs mount in bytes (either numeric or as bytes unit).\n    *   `mode`: The file mode for the tmpfs mount as Unix permission bits as an octal number. Introduced in Docker Compose version [2.14.0](https://docs.docker.com/compose/release-notes/#2260).\n*   `consistency`: The consistency requirements of the mount. Available values are platform specific.\n\n> **Tip**\n> \n> Working with large repositories or monorepos, or with virtual file systems that are no longer scaling with your codebase? Compose now takes advantage of [Synchronized file shares](https://docs.docker.com/desktop/synchronized-file-sharing/) and automatically creates file shares for bind mounts. Ensure you're signed in to Docker with a paid subscription and have enabled both **Access experimental features** and **Manage Synchronized file shares with Compose** in Docker Desktop's settings.\n\n### [volumes\\_from](#volumes_from)\n\n`volumes_from` mounts all of the volumes from another service or container. You can optionally specify read-only access `ro` or read-write `rw`. If no access level is specified, then read-write access is used.\n\nYou can also mount volumes from a container that is not managed by Compose by using the `container:` prefix.\n\n### [working\\_dir](#working_dir)\n\n`working_dir` overrides the container's working directory which is specified by the image, for example Dockerfile's `WORKDIR`.",
  "title": "Services top-level elements | Docker Docs\n",
  "description": "Explore all the attributes the services top-level element can have.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-file/04-version-and-name/",
  "markdown": "# Version and name top-level elements\n\nThe top-level `version` property is defined by the Compose Specification for backward compatibility. It is only informative and you'll receive a warning message that it is obsolete if used.\n\nCompose doesn't use `version` to select an exact schema to validate the Compose file, but prefers the most recent schema when it's implemented.\n\nCompose validates whether it can fully parse the Compose file. If some fields are unknown, typically because the Compose file was written with fields defined by a newer version of the Specification, you'll receive a warning message.\n\nThe top-level `name` property is defined by the Compose Specification as the project name to be used if you don't set one explicitly. Compose offers a way for you to override this name, and sets a default project name to be used if the top-level `name` element is not set.\n\nWhenever a project name is defined by top-level `name` or by some custom mechanism, it is exposed for [interpolation](https://docs.docker.com/compose/compose-file/12-interpolation/) and environment variable resolution as `COMPOSE_PROJECT_NAME`\n\nFor more information on other ways to name Compose projects, see [Specify a project name](https://docs.docker.com/compose/project-name/).",
  "title": "Version and name top-level elements | Docker Docs\n",
  "description": "Understand when and if to set the version and name top-level element",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-file/13-merge/",
  "markdown": "# Merge | Docker Docs\n\nCompose lets you define a Compose application model through multiple Compose files. When doing so, Compose follows certain rules to merge Compose files.\n\nThese rules are outlined below.\n\nA YAML `mapping` gets merged by adding missing entries and merging the conflicting ones.\n\nMerging the following example YAML trees:\n\nResults in a Compose application model equivalent to the YAML tree:\n\nA YAML `sequence` is merged by appending values from the overriding Compose file to the previous one.\n\nMerging the following example YAML trees:\n\nResults in a Compose application model equivalent to the YAML tree:\n\n### [Shell commands](#shell-commands)\n\nWhen merging Compose files that use the services attributes [command](https://docs.docker.com/compose/compose-file/05-services/#command), [entrypoint](https://docs.docker.com/compose/compose-file/05-services/#entrypoint) and [healthcheck: `test`](https://docs.docker.com/compose/compose-file/05-services/#healthcheck), the value is overridden by the latest Compose file, and not appended.\n\nMerging the following example YAML trees:\n\nResults in a Compose application model equivalent to the YAML tree:\n\n### [Unique resources](#unique-resources)\n\nApplies to the [ports](https://docs.docker.com/compose/compose-file/05-services/#ports), [volumes](https://docs.docker.com/compose/compose-file/05-services/#volumes), [secrets](https://docs.docker.com/compose/compose-file/05-services/#secrets) and [configs](https://docs.docker.com/compose/compose-file/05-services/#configs) services attributes. While these types are modeled in a Compose file as a sequence, they have special uniqueness requirements:\n\n| Attribute | Unique key |\n| --- | --- |\n| volumes | target |\n| secrets | source |\n| configs | source |\n| ports | {ip, target, published, protocol} |\n\nWhen merging Compose files, Compose appends new entries that do not violate a uniqueness constraint and merge entries that share a unique key.\n\nMerging the following example YAML trees:\n\nResults in a Compose application model equivalent to the YAML tree:\n\n### [Reset value](#reset-value)\n\nIn addition to the previously described mechanism, an override Compose file can also be used to remove elements from your application model. For this purpose, the custom [YAML tag](https://yaml.org/spec/1.2.2/#24-tags) `!reset` can be set to override a value set by the overriden Compose file. A valid value for attribute must be provided, but will be ignored and target attribute will be set with type's default value or `null`.\n\nFor readability, it is recommended to explicitly set the attribute value to the null (`null`) or empty array `[]` (with `!reset null` or `!reset []`) so that it is clear that resulting attribute will be cleared.\n\nA base `compose.yaml` file:\n\nAnd an `compose.override.yaml` file:\n\nResults in:\n\n### [Replace value](#replace-value)\n\nIntroduced in Docker Compose version [2.24.4](https://docs.docker.com/compose/release-notes/#2244)\n\nWhile `!reset` can be used to remove a declaration from a Compose file using an override file, `!override` allows you to fully replace an attribute, bypassing the standard merge rules. A typical example is to fully replace a resource definition, to rely on a distinct model but using the same name.\n\nA base `compose.yaml` file:\n\nTo remove the original port, but expose a new one, the following override file is used:\n\nThis results in:\n\nIf `!override` had not been used, both `8080:80` and `8443:443` would be exposed as per the [merging rules outlined above](#sequence).\n\nFor more information on how merge can be used to create a composite Compose file, see [Working with multiple Compose files](https://docs.docker.com/compose/multiple-compose-files/)",
  "title": "Merge | Docker Docs\n",
  "description": "Learn about merging rules",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-file/14-include/",
  "markdown": "# Include | Docker Docs\n\nIntroduced in Docker Compose version [2.20.0](https://docs.docker.com/compose/release-notes/#2200)\n\nA Compose application can declare dependency on another Compose application. This is useful if:\n\n*   You want to reuse other Compose files.\n*   You need to factor out parts of your application model into separate Compose files so they can be managed separately or shared with others.\n*   Teams need to keep a Compose file reasonably complicated for the limited amount of resources it has to declare for it's own sub-domain, within a larger deployment.\n\nThe `include` top-level section is used to define the dependency on another Compose application, or sub-domain. Each path listed in the `include` section is loaded as an individual Compose application model, with it's own project directory, in order to resolve relative paths.\n\nOnce the included Compose application is loaded, all resources definitions are copied into the current Compose application model. Compose displays a warning if resource names conflict and doesn't try to merge them. To enforce this, `include` is evaluated after the Compose file(s) selected to define the Compose application model have been parsed and merged, so that conflicts between Compose files are detected.\n\n`include` applies recursively so an included Compose file which declares its own `include` section, triggers those other files to be included as well.\n\nAny volumes, networks, or other resources pulled in from the included Compose file can be used by the current Compose application for cross-service references. For example:\n\nCompose also supports the use of interpolated variables with `include`. It's recommended that you [specify mandatory variables](https://docs.docker.com/compose/compose-file/12-interpolation/). For example:\n\nThe short syntax only defines paths to other Compose files. The file is loaded with the parent folder as the project directory, and an optional `.env` file that is loaded to define any variables' default values by interpolation. The local project's environment can override those values.\n\nIn the above example, both `../commons/compose.yaml` and `../another_domain/compose.yaml` are loaded as individual Compose projects. Relative paths in Compose files being referred by `include` are resolved relative to their own Compose file path, not based on the local project's directory. Variables are interpolated using values set in the optional `.env` file in same folder, and is overridden by the local project's environment.\n\nThe long syntax offers more control over the sub-project parsing:\n\n### [path](#path)\n\n`path` is required and defines the location of the Compose file(s) to be parsed and included into the local Compose model. `path` can be set either to a string when a single Compose file is involved, or to a list of strings when multiple Compose files need to be [merged together](https://docs.docker.com/compose/compose-file/13-merge/) to define the Compose model to be included in the local application.\n\n### [project\\_directory](#project_directory)\n\n`project_directory` defines a base path to resolve relative paths set in the Compose file. It defaults to the directory of the included Compose file.\n\n### [env\\_file](#env_file)\n\n`env_file` defines an environment file(s) to use to define default values when interpolating variables in the Compose file being parsed. It defaults to `.env` file in the `project_directory` for the Compose file being parsed.\n\n`env_file` can be set either to a string or a list of strings when multiple environment files need to be merged to define a project environment.\n\nThe local project's environment has precedence over the values set by the Compose file, so that the local project can override values for customization.\n\nFor more information on using `include`, see [Working with multiple Compose files](https://docs.docker.com/compose/multiple-compose-files/)",
  "title": "Include | Docker Docs\n",
  "description": "Learn about include",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/api/sdk/",
  "markdown": "# Develop with Docker Engine SDKs\n\nDocker provides an API for interacting with the Docker daemon (called the Docker Engine API), as well as SDKs for Go and Python. The SDKs allow you to efficiently build and scale Docker apps and solutions. If Go or Python don't work for you, you can use the Docker Engine API directly.\n\nThe Docker Engine API is a RESTful API accessed by an HTTP client such as `wget` or `curl`, or the HTTP library which is part of most modern programming languages.\n\nUse the following commands to install the Go or Python SDK. Both SDKs can be installed and coexist together.\n\n### [Go SDK](#go-sdk)\n\nThe client requires a recent version of Go. Run `go version` and ensure that you're running a currently supported version of Go.\n\nFor more information, see [Docker Engine Go SDK reference](https://godoc.org/github.com/docker/docker/client).\n\n### [Python SDK](#python-sdk)\n\n*   Recommended: Run `pip install docker`.\n    \n*   If you can't use `pip`:\n    \n    1.  [Download the package directly](https://pypi.python.org/pypi/docker/).\n    2.  Extract it and change to the extracted directory.\n    3.  Run `python setup.py install`.\n\nFor more information, see [Docker Engine Python SDK reference](https://docker-py.readthedocs.io/).\n\nYou can [view the reference for the latest version of the API](https://docs.docker.com/engine/api/latest/) or [choose a specific version](https://docs.docker.com/engine/api/version-history/).\n\nThe version of the Docker Engine API you should use depends on the version of your Docker daemon and Docker client. See the [versioned API and SDK](https://docs.docker.com/engine/api/#versioned-api-and-sdk) section in the API documentation for details.\n\nUse the following guidelines to choose the SDK or API version to use in your code:\n\n*   If you're starting a new project, use the [latest version](https://docs.docker.com/engine/api/latest/), but use API version negotiation or specify the version you are using. This helps prevent surprises.\n*   If you need a new feature, update your code to use at least the minimum version that supports the feature, and prefer the latest version you can use.\n*   Otherwise, continue to use the version that your code is already using.\n\nAs an example, the `docker run` command can be implemented using the Docker API directly, or using the Python or Go SDK.\n\n* * *\n\nWhen using cURL to connect over a Unix socket, the hostname is not important. The previous examples use `localhost`, but any hostname would work.\n\n> **Important**\n> \n> The previous examples assume you're using cURL 7.50.0 or above. Older versions of cURL used a [non-standard URL notation](https://github.com/moby/moby/issues/17960) when using a socket connection.\n> \n> If you're' using an older version of cURL, use `http:/<API version>/` instead, for example: `http:/v1.46/containers/1c6594faf5/start`.\n\n* * *\n\nFor more examples, take a look at the [SDK examples](https://docs.docker.com/engine/api/sdk/examples/).\n\nThere are a number of community supported libraries available for other languages. They haven't been tested by Docker, so if you run into any issues, file them with the library maintainers.\n\n| Language | Library |\n| --- | --- |\n| C   | [libdocker](https://github.com/danielsuo/libdocker) |\n| C#  | [Docker.DotNet](https://github.com/ahmetalpbalkan/Docker.DotNet) |\n| C++ | [lasote/docker\\_client](https://github.com/lasote/docker_client) |\n| Clojure | [clj-docker-client](https://github.com/into-docker/clj-docker-client) |\n| Clojure | [contajners](https://github.com/lispyclouds/contajners) |\n| Dart | [bwu\\_docker](https://github.com/bwu-dart/bwu_docker) |\n| Erlang | [erldocker](https://github.com/proger/erldocker) |\n| Gradle | [gradle-docker-plugin](https://github.com/gesellix/gradle-docker-plugin) |\n| Groovy | [docker-client](https://github.com/gesellix/docker-client) |\n| Haskell | [docker-hs](https://github.com/denibertovic/docker-hs) |\n| Java | [docker-client](https://github.com/spotify/docker-client) |\n| Java | [docker-java](https://github.com/docker-java/docker-java) |\n| Java | [docker-java-api](https://github.com/amihaiemil/docker-java-api) |\n| Java | [jocker](https://github.com/ndeloof/jocker) |\n| NodeJS | [dockerode](https://github.com/apocas/dockerode) |\n| NodeJS | [harbor-master](https://github.com/arhea/harbor-master) |\n| Perl | [Eixo::Docker](https://github.com/alambike/eixo-docker) |\n| PHP | [Docker-PHP](https://github.com/docker-php/docker-php) |\n| Ruby | [docker-api](https://github.com/swipely/docker-api) |\n| Rust | [bollard](https://github.com/fussybeaver/bollard) |\n| Rust | [docker-rust](https://github.com/abh1nav/docker-rust) |\n| Rust | [shiplift](https://github.com/softprops/shiplift) |\n| Scala | [tugboat](https://github.com/softprops/tugboat) |\n| Scala | [reactive-docker](https://github.com/almoehi/reactive-docker) |\n| Swift | [docker-client-swift](https://github.com/valeriomazzeo/docker-client-swift) |",
  "title": "Develop with Docker Engine SDKs | Docker Docs\n",
  "description": "Learn how to use Docker Engine SDKs to automate Docker tasks in your language of choice",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/api/latest/",
  "markdown": "# index | Docker Docs\n\nRedirecting to the latest version of the Docker Engine API reference.",
  "title": "index | Docker Docs\n",
  "description": "",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/api/sdk/examples/",
  "markdown": "# Examples using the Docker Engine SDKs and Docker API\n\nAfter you [install Docker](https://docs.docker.com/get-docker/), you can [install the Go or Python SDK](https://docs.docker.com/engine/api/sdk/#install-the-sdks) and also try out the Docker Engine API.\n\nEach of these examples show how to perform a given Docker operation using the Go and Python SDKs and the HTTP API using `curl`.\n\nThis first example shows how to run a container using the Docker API. On the command line, you would use the `docker run` command, but this is just as easy to do from your own apps too.\n\nThis is the equivalent of typing `docker run alpine echo hello world` at the command prompt:\n\n* * *\n\nWhen using cURL to connect over a Unix socket, the hostname isn't important. The previous examples use `localhost`, but any hostname would work.\n\n> **Important**\n> \n> The previous examples assume you're using cURL 7.50.0 or above. Older versions of cURL used a [non-standard URL notation](https://github.com/moby/moby/issues/17960) when using a socket connection.\n> \n> If you're' using an older version of cURL, use `http:/<API version>/` instead, for example: `http:/v1.46/containers/1c6594faf5/start`.\n\n* * *\n\nYou can also run containers in the background, the equivalent of typing `docker run -d bfirsh/reticulate-splines`:\n\nYou can use the API to list containers that are running, just like using `docker ps`:\n\nNow that you know what containers exist, you can perform operations on them. This example stops all running containers.\n\n> **Note**\n> \n> Don't run this on a production server. Also, if you're' using swarm services, the containers stop, but Docker creates new ones to keep the service running in its configured state.\n\nYou can also perform actions on individual containers. This example prints the logs of a container given its ID. You need to modify the code before running it to change the hard-coded ID of the container to print the logs for.\n\nList the images on your Engine, similar to `docker image ls`:\n\nPull an image, like `docker pull`:\n\nPull an image, like `docker pull`, with authentication:\n\n> **Note**\n> \n> Credentials are sent in the clear. Docker's official registries use HTTPS. Private registries should also be configured to use HTTPS.\n\n* * *\n\nThe Python SDK retrieves authentication information from the [credentials store](https://docs.docker.com/reference/cli/docker/login/#credentials-store) file and integrates with [credential helpers](https://github.com/docker/docker-credential-helpers). It's possible to override these credentials, but that's out of scope for this example guide. After using `docker login`, the Python SDK uses these credentials automatically.\n\nThis example leaves the credentials in your shell's history, so consider this a naive implementation. The credentials are passed as a Base-64-encoded JSON structure.\n\n* * *\n\nCommit a container to create an image from its contents:",
  "title": "Examples using the Docker Engine SDKs and Docker API | Docker Docs\n",
  "description": "Examples on how to perform a given Docker operation using the Go and Python SDKs and the HTTP API using curl.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/guide/intro/",
  "markdown": "# Introduction | Docker Docs\n\nThe starting resources for this guide include a simple Go project and a Dockerfile. From this starting point, the guide illustrates various ways that you can improve how you build the application with Docker.\n\nTo follow this guide:\n\n1.  Install [Docker Desktop or Docker Engine](https://docs.docker.com/get-docker/)\n2.  Clone or create a new repository from the [application example on GitHub](https://github.com/dockersamples/buildme)\n\nThe example project for this guide is a client-server application for translating messages to a fictional language.\n\nHereâ€™s an overview of the files included in the project:\n\nThe `cmd/` directory contains the code for the two application components: client and server. The client is a user interface for writing, sending, and receiving messages. The server receives messages from clients, translates them, and sends them back to the client.\n\nA Dockerfile is a text document in which you define the build steps for your application. You write the Dockerfile in a domain-specific language, called the Dockerfile syntax.\n\nHere's the Dockerfile used as the starting point for this guide:\n\nHereâ€™s what this Dockerfile does:\n\n1.  `# syntax=docker/dockerfile:1`\n    \n    This comment is a [Dockerfile parser directive](https://docs.docker.com/reference/dockerfile/#parser-directives). It specifies which version of the Dockerfile syntax to use. This file uses the `dockerfile:1` syntax which is best practice: it ensures that you have access to the latest Docker build features.\n    \n2.  `FROM golang:1.21-alpine`\n    \n    The `FROM` instruction uses version `1.21-alpine` of the `golang` official image.\n    \n3.  `WORKDIR /src`\n    \n    Creates the `/src` working directory inside the container.\n    \n4.  `COPY . .`\n    \n    Copies the files in the build context to the working directory in the container.\n    \n5.  `RUN go mod download`\n    \n    Downloads the necessary Go modules to the container. Go modules is the dependency management tool for the Go programming language, similar to `npm install` for JavaScript, or `pip install` for Python.\n    \n6.  `RUN go build -o /bin/client ./cmd/client`\n    \n    Builds the `client` binary, which is used to send messages to be translated, into the `/bin` directory.\n    \n7.  `RUN go build -o /bin/server ./cmd/server`\n    \n    Builds the `server` binary, which listens for client translation requests, into the `/bin` directory.\n    \n8.  `ENTRYPOINT [ \"/bin/server\" ]`\n    \n    Specifies a command to run when the container starts. Starts the server process.\n    \n\nTo build an image using a Dockerfile, you use the `docker` command-line tool. The command for building an image is `docker build`.\n\nRun the following command to build the image.\n\nThis creates an image with the tag `buildme`. An image tag is the name of the image.\n\nThe image you just built contains two binaries, one for the server and one for the client. To see the translation service in action, run a container that hosts the server component, and then run another container that invokes the client.\n\nTo run a container, you use the `docker run` command.\n\n1.  Run a container from the image in detached mode.\n    \n    This starts a container named `buildme`.\n    \n2.  Run a new command in the `buildme` container that invokes the client binary.\n    \n\nThe `docker exec` command opens a terminal user interface where you can submit messages for the backend (server) process to translate.\n\nWhen you're done testing, you can stop the container:\n\nThis section gave you an overview of the example application used in this guide, an introduction to Dockerfiles and building. You've successfully built a container image and created a container from it.\n\nRelated information:\n\n*   [Dockerfile reference](https://docs.docker.com/reference/dockerfile/)\n*   [`docker build` CLI reference](https://docs.docker.com/reference/cli/docker/image/build/)\n*   [`docker run` CLI reference](https://docs.docker.com/reference/cli/docker/container/run/)\n\nThe next section explores how you can use layer cache to improve build speed.",
  "title": "Introduction | Docker Docs\n",
  "description": "An introduction to the Docker Build guide",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/guide/layers/",
  "markdown": "# Layers | Docker Docs\n\nThe order of Dockerfile instructions matters. A Docker build consists of a series of ordered build instructions. Each instruction in a Dockerfile roughly translates to an image layer. The following diagram illustrates how a Dockerfile translates into a stack of layers in a container image.\n\n![From Dockerfile to layers](https://docs.docker.com/build/guide/images/layers.png)\n\nWhen you run a build, the builder attempts to reuse layers from earlier builds. If a layer of an image is unchanged, then the builder picks it up from the build cache. If a layer has changed since the last build, that layer, and all layers that follow, must be rebuilt.\n\nThe Dockerfile from the previous section copies all project files to the container (`COPY . .`) and then downloads application dependencies in the following step (`RUN go mod download`). If you were to change any of the project files, then that would invalidate the cache for the `COPY` layer. It also invalidates the cache for all of the layers that follow.\n\n![Layer cache is bust](https://docs.docker.com/build/guide/images/cache-bust.png)\n\nBecause of the current order of the Dockerfile instructions, the builder must download the Go modules again, despite none of the packages having changed since the last time.\n\nYou can avoid this redundancy by reordering the instructions in the Dockerfile. Change the order of the instructions so that downloading and installing dependencies occur before the source code is copied over to the container. In that way, the builder can reuse the \"dependencies\" layer from the cache, even when you make changes to your source code.\n\nGo uses two files, called `go.mod` and `go.sum`, to track dependencies for a project. These files are to Go, what `package.json` and `package-lock.json` are to JavaScript. For Go to know which dependencies to download, you need to copy the `go.mod` and `go.sum` files to the container. Add another `COPY` instruction before `RUN go mod download`, this time copying only the `go.mod` and `go.sum` files.\n\nNow if you edit your source code, building the image won't cause the builder to download the dependencies each time. The `COPY . .` instruction appears after the package management instructions, so the builder can reuse the `RUN go mod download` layer.\n\n![Reordered](https://docs.docker.com/build/guide/images/reordered-layers.png)\n\nOrdering your Dockerfile instructions appropriately helps you avoid unnecessary work at build time.\n\nRelated information:\n\n*   [Docker build cache](https://docs.docker.com/build/cache/)\n*   [Dockerfile best practices](https://docs.docker.com/build/building/best-practices/)\n\nThe next section shows how you can make the build run faster, and make the resulting output smaller, using multi-stage builds.",
  "title": "Layers | Docker Docs\n",
  "description": "Improving the initial Dockerfile using layers",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/compose/compose-file/15-profiles/",
  "markdown": "# Profiles | Docker Docs\n\nWith profiles you can define a set of active profiles so your Compose application model is adjusted for various usages and environments.\n\nThe [services](https://docs.docker.com/compose/compose-file/05-services/) top-level element supports a `profiles` attribute to define a list of named profiles. Services without a `profiles` attribute are always enabled.\n\nA service is ignored by Compose when none of the listed `profiles` match the active ones, unless the service is explicitly targeted by a command. In that case its profile is added to the set of active profiles.\n\n> **Note**\n> \n> All other top-level elements are not affected by `profiles` and are always active.\n\nReferences to other services (by `links`, `extends` or shared resource syntax `service:xxx`) do not automatically enable a component that would otherwise have been ignored by active profiles. Instead Compose returns an error.\n\nIn the above example:\n\n*   If the Compose application model is parsed with no profile enabled, it only contains the `web` service.\n*   If the profile `test` is enabled, the model contains the services `test_lib` and `coverage_lib`, and service `web`, which is always enabled.\n*   If the profile `debug` is enabled, the model contains both `web` and `debug_lib` services, but not `test_lib` and `coverage_lib`, and as such the model is invalid regarding the `depends_on` constraint of `debug_lib`.\n*   If the profiles `debug` and `test` are enabled, the model contains all services; `web`, `test_lib`, `coverage_lib` and `debug_lib`.\n*   If Compose is executed with `test_lib` as the explicit service to run, `test_lib` and the `test` profile are active even if `test` profile is not enabled.\n*   If Compose is executed with `coverage_lib` as the explicit service to run, the service `coverage_lib` and the profile `test` are active and `test_lib` is pulled in by the `depends_on` constraint.\n*   If Compose is executed with `debug_lib` as the explicit service to run, again the model is invalid regarding the `depends_on` constraint of `debug_lib`, since `debug_lib` and `test_lib` have no common `profiles` listed.\n*   If Compose is executed with `debug_lib` as the explicit service to run and profile `test` is enabled, profile `debug` is automatically enabled and service `test_lib` is pulled in as a dependency starting both services `debug_lib` and `test_lib`.\n\nSee how you can use `profiles` in [Docker Compose](https://docs.docker.com/compose/profiles/).",
  "title": "Profiles | Docker Docs\n",
  "description": "Learn about profiles",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/guide/mounts/",
  "markdown": "# Mounts | Docker Docs\n\nThis section describes how to use cache mounts and bind mounts with Docker builds.\n\nCache mounts let you specify a persistent package cache to be used during builds. The persistent cache helps speed up build steps, especially steps that involve installing packages using a package manager. Having a persistent cache for packages means that even if you rebuild a layer, you only download new or changed packages.\n\nCache mounts are created using the `--mount` flag together with the `RUN` instruction in the Dockerfile. To use a cache mount, the format for the flag is `--mount=type=cache,target=<path>`, where `<path>` is the location of the cache directory that you wish to mount into the container.\n\nThe target path to use for the cache mount depends on the package manager youâ€™re using. The application example in this guide uses Go modules. That means that the target directory for the cache mount is the directory where the Go module cache gets written to. According to the [Go modules reference](https://go.dev/ref/mod#module-cache), the default location for the module cache is `$GOPATH/pkg/mod`, and the default value for `$GOPATH` is `/go`.\n\nUpdate the build steps for downloading packages and compiling the program to mount the `/go/pkg/mod` directory as a cache mount:\n\nThe `-x` flag added to the `go mod download` command prints the download executions that take place. Adding this flag lets you see how the cache mount is being used in the next step.\n\nBefore you rebuild the image, clear your build cache. This ensures that you're starting from a clean slate, making it easier to see exactly what the build is doing.\n\nNow itâ€™s time to rebuild the image. Invoke the build command, this time together with the `--progress=plain` flag, while also redirecting the output to a log file.\n\nWhen the build has finished, inspect the `log1.txt` file. The logs show how the Go modules were downloaded as part of the build.\n\nNow, in order to see that the cache mount is being used, change the version of one of the Go modules that your program imports. By changing the module version, you're forcing Go to download the new version of the dependency the next time you build. If you werenâ€™t using cache mounts, your system would re-download all modules. But because you've added a cache mount, Go can reuse most of the modules and only download the package versions that doesn't already exist in the `/go/pkg/mod` directory.\n\nUpdate the version of the `chi` package that the server component of the application uses:\n\nNow, run another build, and again redirect the build logs to a log file:\n\nNow if you inspect the `log2.txt` file, youâ€™ll find that only the `chi` package that was changed has been downloaded:\n\nThere are a few more small optimizations that you can implement to improve the Dockerfile. Currently, it's using the `COPY` instruction to pull in the `go.mod` and `go.sum` files before downloading modules. Instead of copying those files over to the containerâ€™s filesystem, you can use a bind mount. A bind mount makes the files available to the container directly from the host. This change removes the need for the additional `COPY` instruction (and layer) entirely.\n\nSimilarly, you can use the same technique to remove the need for the second `COPY` instruction as well. Specify bind mounts in the `build-client` and `build-server` stages for mounting the current working directory.\n\nThis section has shown how you can improve your build speed using cache and bind mounts.\n\nRelated information:\n\n*   [Dockerfile reference](https://docs.docker.com/reference/dockerfile/#run---mount)\n*   [Bind mounts](https://docs.docker.com/storage/bind-mounts/)\n\nThe next section of this guide is an introduction to making your builds configurable, using build arguments.",
  "title": "Mounts | Docker Docs\n",
  "description": "Introduction to cache mounts and bind mounts in builds",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/guide/build-args/",
  "markdown": "# Build arguments | Docker Docs\n\nBuild arguments is a great way to add flexibility to your builds. You can pass build arguments at build-time, and you can set a default value that the builder uses as a fallback.\n\nA practical use case for build arguments is to specify runtime versions for build stages. Your image uses the `golang:1.21-alpine` image as a base image. But what if someone wanted to use a different version of Go for building the application? They could update the version number inside the Dockerfile, but thatâ€™s inconvenient, it makes switching between versions more tedious than it has to be. Build arguments make life easier:\n\nThe `ARG` keyword is interpolated in the image name in the `FROM` instruction. The default value of the `GO_VERSION` build argument is set to `1.21`. If the build doesn't receive a `GO_VERSION` build argument, the `FROM` instruction resolves to `golang:1.21-alpine`.\n\nTry setting a different version of Go to use for building, using the `--build-arg` flag for the build command:\n\nRunning this command results in a build using the `golang:1.19-alpine` image.\n\nYou can also make use of build arguments to modify values in the source code of your program, at build time. This is useful for dynamically injecting information, avoiding hard-coded values. With Go, consuming external values at build time is done using linker flags, or `-ldflags`.\n\nThe server part of the application contains a conditional statement to print the app version, if a version is specified:\n\nYou could declare the version string value directly in the code. But, updating the version to line up with the release version of the application would require updating the code ahead of every release. That would be both tedious and error-prone. A better solution is to pass the version string as a build argument, and inject the build argument into the code.\n\nThe following example adds an `APP_VERSION` build argument to the `build-server` stage. The Go compiler uses the value of the build argument to set the value of a variable in the code.\n\nNow the version of the server is injected when building the binary, without having to update the source code. To verify this, you can build the `server` target and start a container with `docker run`. The server outputs `v0.0.1` as the version on startup.\n\nThis section showed how you can use build arguments to make builds more configurable, and inject values at build-time.\n\nRelated information:\n\n*   [`ARG` Dockerfile reference](https://docs.docker.com/reference/dockerfile/#arg)\n\nThe next section of this guide shows how you can use Docker builds to create not only container images, but executable binaries as well.",
  "title": "Build arguments | Docker Docs\n",
  "description": "Introduction to configurable builds, using build args",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/api/v1.24/",
  "markdown": "# Engine API v1.24 | Docker Docs\n\n*   The daemon listens on `unix:///var/run/docker.sock` but you can [Bind Docker to another host/port or a Unix socket](https://docs.docker.com/engine/reference/commandline/dockerd/#bind-docker-to-another-host-port-or-a-unix-socket).\n*   The API tends to be REST. However, for some complex commands, like `attach` or `pull`, the HTTP connection is hijacked to transport `stdout`, `stdin` and `stderr`.\n*   A `Content-Length` header should be present in `POST` requests to endpoints that expect a body.\n*   To lock to a specific version of the API, you prefix the URL with the version of the API to use. For example, `/v1.18/info`. If no version is included in the URL, the maximum supported API version is used.\n*   If the API version specified in the URL is not supported by the daemon, a HTTP `400 Bad Request` error message is returned.\n\nThe Engine API uses standard HTTP status codes to indicate the success or failure of the API call. The body of the response will be JSON in the following format:\n\n```\n{\n    \"message\": \"page not found\"\n}\n```\n\nThe status codes that are returned for each endpoint are specified in the endpoint documentation below.\n\n### [3.1 Containers](#31-containers)\n\n#### [List containers](#list-containers)\n\n`GET /containers/json`\n\nList containers\n\n**Example request**:\n\n```\nGET /v1.24/containers/json?all=1&before=8dfafdbc3a40&size=1 HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n[\n     {\n             \"Id\": \"8dfafdbc3a40\",\n             \"Names\":[\"/boring_feynman\"],\n             \"Image\": \"ubuntu:latest\",\n             \"ImageID\": \"d74508fb6632491cea586a1fd7d748dfc5274cd6fdfedee309ecdcbc2bf5cb82\",\n             \"Command\": \"echo 1\",\n             \"Created\": 1367854155,\n             \"State\": \"exited\",\n             \"Status\": \"Exit 0\",\n             \"Ports\": [{\"PrivatePort\": 2222, \"PublicPort\": 3333, \"Type\": \"tcp\"}],\n             \"Labels\": {\n                     \"com.example.vendor\": \"Acme\",\n                     \"com.example.license\": \"GPL\",\n                     \"com.example.version\": \"1.0\"\n             },\n             \"SizeRw\": 12288,\n             \"SizeRootFs\": 0,\n             \"HostConfig\": {\n                     \"NetworkMode\": \"default\"\n             },\n             \"NetworkSettings\": {\n                     \"Networks\": {\n                             \"bridge\": {\n                                      \"IPAMConfig\": null,\n                                      \"Links\": null,\n                                      \"Aliases\": null,\n                                      \"NetworkID\": \"7ea29fc1412292a2d7bba362f9253545fecdfa8ce9a6e37dd10ba8bee7129812\",\n                                      \"EndpointID\": \"2cdc4edb1ded3631c81f57966563e5c8525b81121bb3706a9a9a3ae102711f3f\",\n                                      \"Gateway\": \"172.17.0.1\",\n                                      \"IPAddress\": \"172.17.0.2\",\n                                      \"IPPrefixLen\": 16,\n                                      \"IPv6Gateway\": \"\",\n                                      \"GlobalIPv6Address\": \"\",\n                                      \"GlobalIPv6PrefixLen\": 0,\n                                      \"MacAddress\": \"02:42:ac:11:00:02\"\n                              }\n                     }\n             },\n             \"Mounts\": [\n                     {\n                              \"Name\": \"fac362...80535\",\n                              \"Source\": \"/data\",\n                              \"Destination\": \"/data\",\n                              \"Driver\": \"local\",\n                              \"Mode\": \"ro,Z\",\n                              \"RW\": false,\n                              \"Propagation\": \"\"\n                     }\n             ]\n     },\n     {\n             \"Id\": \"9cd87474be90\",\n             \"Names\":[\"/coolName\"],\n             \"Image\": \"ubuntu:latest\",\n             \"ImageID\": \"d74508fb6632491cea586a1fd7d748dfc5274cd6fdfedee309ecdcbc2bf5cb82\",\n             \"Command\": \"echo 222222\",\n             \"Created\": 1367854155,\n             \"State\": \"exited\",\n             \"Status\": \"Exit 0\",\n             \"Ports\": [],\n             \"Labels\": {},\n             \"SizeRw\": 12288,\n             \"SizeRootFs\": 0,\n             \"HostConfig\": {\n                     \"NetworkMode\": \"default\"\n             },\n             \"NetworkSettings\": {\n                     \"Networks\": {\n                             \"bridge\": {\n                                      \"IPAMConfig\": null,\n                                      \"Links\": null,\n                                      \"Aliases\": null,\n                                      \"NetworkID\": \"7ea29fc1412292a2d7bba362f9253545fecdfa8ce9a6e37dd10ba8bee7129812\",\n                                      \"EndpointID\": \"88eaed7b37b38c2a3f0c4bc796494fdf51b270c2d22656412a2ca5d559a64d7a\",\n                                      \"Gateway\": \"172.17.0.1\",\n                                      \"IPAddress\": \"172.17.0.8\",\n                                      \"IPPrefixLen\": 16,\n                                      \"IPv6Gateway\": \"\",\n                                      \"GlobalIPv6Address\": \"\",\n                                      \"GlobalIPv6PrefixLen\": 0,\n                                      \"MacAddress\": \"02:42:ac:11:00:08\"\n                              }\n                     }\n             },\n             \"Mounts\": []\n     },\n     {\n             \"Id\": \"3176a2479c92\",\n             \"Names\":[\"/sleepy_dog\"],\n             \"Image\": \"ubuntu:latest\",\n             \"ImageID\": \"d74508fb6632491cea586a1fd7d748dfc5274cd6fdfedee309ecdcbc2bf5cb82\",\n             \"Command\": \"echo 3333333333333333\",\n             \"Created\": 1367854154,\n             \"State\": \"exited\",\n             \"Status\": \"Exit 0\",\n             \"Ports\":[],\n             \"Labels\": {},\n             \"SizeRw\":12288,\n             \"SizeRootFs\":0,\n             \"HostConfig\": {\n                     \"NetworkMode\": \"default\"\n             },\n             \"NetworkSettings\": {\n                     \"Networks\": {\n                             \"bridge\": {\n                                      \"IPAMConfig\": null,\n                                      \"Links\": null,\n                                      \"Aliases\": null,\n                                      \"NetworkID\": \"7ea29fc1412292a2d7bba362f9253545fecdfa8ce9a6e37dd10ba8bee7129812\",\n                                      \"EndpointID\": \"8b27c041c30326d59cd6e6f510d4f8d1d570a228466f956edf7815508f78e30d\",\n                                      \"Gateway\": \"172.17.0.1\",\n                                      \"IPAddress\": \"172.17.0.6\",\n                                      \"IPPrefixLen\": 16,\n                                      \"IPv6Gateway\": \"\",\n                                      \"GlobalIPv6Address\": \"\",\n                                      \"GlobalIPv6PrefixLen\": 0,\n                                      \"MacAddress\": \"02:42:ac:11:00:06\"\n                              }\n                     }\n             },\n             \"Mounts\": []\n     },\n     {\n             \"Id\": \"4cb07b47f9fb\",\n             \"Names\":[\"/running_cat\"],\n             \"Image\": \"ubuntu:latest\",\n             \"ImageID\": \"d74508fb6632491cea586a1fd7d748dfc5274cd6fdfedee309ecdcbc2bf5cb82\",\n             \"Command\": \"echo 444444444444444444444444444444444\",\n             \"Created\": 1367854152,\n             \"State\": \"exited\",\n             \"Status\": \"Exit 0\",\n             \"Ports\": [],\n             \"Labels\": {},\n             \"SizeRw\": 12288,\n             \"SizeRootFs\": 0,\n             \"HostConfig\": {\n                     \"NetworkMode\": \"default\"\n             },\n             \"NetworkSettings\": {\n                     \"Networks\": {\n                             \"bridge\": {\n                                      \"IPAMConfig\": null,\n                                      \"Links\": null,\n                                      \"Aliases\": null,\n                                      \"NetworkID\": \"7ea29fc1412292a2d7bba362f9253545fecdfa8ce9a6e37dd10ba8bee7129812\",\n                                      \"EndpointID\": \"d91c7b2f0644403d7ef3095985ea0e2370325cd2332ff3a3225c4247328e66e9\",\n                                      \"Gateway\": \"172.17.0.1\",\n                                      \"IPAddress\": \"172.17.0.5\",\n                                      \"IPPrefixLen\": 16,\n                                      \"IPv6Gateway\": \"\",\n                                      \"GlobalIPv6Address\": \"\",\n                                      \"GlobalIPv6PrefixLen\": 0,\n                                      \"MacAddress\": \"02:42:ac:11:00:05\"\n                              }\n                     }\n             },\n             \"Mounts\": []\n     }\n]\n```\n\n**Query parameters**:\n\n*   **all** â€“ 1/True/true or 0/False/false, Show all containers. Only running containers are shown by default (i.e., this defaults to false)\n*   **limit** â€“ Show `limit` last created containers, include non-running ones.\n*   **since** â€“ Show only containers created since Id, include non-running ones.\n*   **before** â€“ Show only containers created before Id, include non-running ones.\n*   **size** â€“ 1/True/true or 0/False/false, Show the containers sizes\n*   **filters** - a JSON encoded value of the filters (a `map[string][]string`) to process on the containers list. Available filters:\n*   `exited=<int>`; -- containers with exit code of `<int>` ;\n*   `status=`(`created`|`restarting`|`running`|`paused`|`exited`|`dead`)\n*   `label=key` or `label=\"key=value\"` of a container label\n*   `isolation=`(`default`|`process`|`hyperv`) (Windows daemon only)\n*   `ancestor`\\=(`<image-name>[:<tag>]`, `<image id>` or `<image@digest>`)\n*   `before`\\=(`<container id>` or `<container name>`)\n*   `since`\\=(`<container id>` or `<container name>`)\n*   `volume`\\=(`<volume name>` or `<mount point destination>`)\n*   `network`\\=(`<network id>` or `<network name>`)\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **400** â€“ bad parameter\n*   **500** â€“ server error\n\n#### [Create a container](#create-a-container)\n\n`POST /containers/create`\n\nCreate a container\n\n**Example request**:\n\n```\nPOST /v1.24/containers/create HTTP/1.1\nContent-Type: application/json\nContent-Length: 12345\n\n{\n       \"Hostname\": \"\",\n       \"Domainname\": \"\",\n       \"User\": \"\",\n       \"AttachStdin\": false,\n       \"AttachStdout\": true,\n       \"AttachStderr\": true,\n       \"Tty\": false,\n       \"OpenStdin\": false,\n       \"StdinOnce\": false,\n       \"Env\": [\n               \"FOO=bar\",\n               \"BAZ=quux\"\n       ],\n       \"Cmd\": [\n               \"date\"\n       ],\n       \"Entrypoint\": \"\",\n       \"Image\": \"ubuntu\",\n       \"Labels\": {\n               \"com.example.vendor\": \"Acme\",\n               \"com.example.license\": \"GPL\",\n               \"com.example.version\": \"1.0\"\n       },\n       \"Volumes\": {\n         \"/volumes/data\": {}\n       },\n       \"Healthcheck\":{\n          \"Test\": [\"CMD-SHELL\", \"curl localhost:3000\"],\n          \"Interval\": 1000000000,\n          \"Timeout\": 10000000000,\n          \"Retries\": 10,\n          \"StartPeriod\": 60000000000\n       },\n       \"WorkingDir\": \"\",\n       \"NetworkDisabled\": false,\n       \"MacAddress\": \"12:34:56:78:9a:bc\",\n       \"ExposedPorts\": {\n               \"22/tcp\": {}\n       },\n       \"StopSignal\": \"SIGTERM\",\n       \"HostConfig\": {\n         \"Binds\": [\"/tmp:/tmp\"],\n         \"Tmpfs\": { \"/run\": \"rw,noexec,nosuid,size=65536k\" },\n         \"Links\": [\"redis3:redis\"],\n         \"Memory\": 0,\n         \"MemorySwap\": 0,\n         \"MemoryReservation\": 0,\n         \"KernelMemory\": 0,\n         \"CpuPercent\": 80,\n         \"CpuShares\": 512,\n         \"CpuPeriod\": 100000,\n         \"CpuQuota\": 50000,\n         \"CpusetCpus\": \"0,1\",\n         \"CpusetMems\": \"0,1\",\n         \"IOMaximumBandwidth\": 0,\n         \"IOMaximumIOps\": 0,\n         \"BlkioWeight\": 300,\n         \"BlkioWeightDevice\": [{}],\n         \"BlkioDeviceReadBps\": [{}],\n         \"BlkioDeviceReadIOps\": [{}],\n         \"BlkioDeviceWriteBps\": [{}],\n         \"BlkioDeviceWriteIOps\": [{}],\n         \"MemorySwappiness\": 60,\n         \"OomKillDisable\": false,\n         \"OomScoreAdj\": 500,\n         \"PidMode\": \"\",\n         \"PidsLimit\": -1,\n         \"PortBindings\": { \"22/tcp\": [{ \"HostPort\": \"11022\" }] },\n         \"PublishAllPorts\": false,\n         \"Privileged\": false,\n         \"ReadonlyRootfs\": false,\n         \"Dns\": [\"8.8.8.8\"],\n         \"DnsOptions\": [\"\"],\n         \"DnsSearch\": [\"\"],\n         \"ExtraHosts\": null,\n         \"VolumesFrom\": [\"parent\", \"other:ro\"],\n         \"CapAdd\": [\"NET_ADMIN\"],\n         \"CapDrop\": [\"MKNOD\"],\n         \"GroupAdd\": [\"newgroup\"],\n         \"RestartPolicy\": { \"Name\": \"\", \"MaximumRetryCount\": 0 },\n         \"NetworkMode\": \"bridge\",\n         \"Devices\": [],\n         \"Sysctls\": { \"net.ipv4.ip_forward\": \"1\" },\n         \"Ulimits\": [{}],\n         \"LogConfig\": { \"Type\": \"json-file\", \"Config\": {} },\n         \"SecurityOpt\": [],\n         \"StorageOpt\": {},\n         \"CgroupParent\": \"\",\n         \"VolumeDriver\": \"\",\n         \"ShmSize\": 67108864\n      },\n      \"NetworkingConfig\": {\n          \"EndpointsConfig\": {\n              \"isolated_nw\" : {\n                  \"IPAMConfig\": {\n                      \"IPv4Address\":\"172.20.30.33\",\n                      \"IPv6Address\":\"2001:db8:abcd::3033\",\n                      \"LinkLocalIPs\":[\"169.254.34.68\", \"fe80::3468\"]\n                  },\n                  \"Links\":[\"container_1\", \"container_2\"],\n                  \"Aliases\":[\"server_x\", \"server_y\"]\n              }\n          }\n      }\n  }\n```\n\n**Example response**:\n\n```\n  HTTP/1.1 201 Created\n  Content-Type: application/json\n\n  {\n       \"Id\":\"e90e34656806\",\n       \"Warnings\":[]\n  }\n```\n\n**JSON parameters**:\n\n*   **Hostname** - A string value containing the hostname to use for the container. This must be a valid RFC 1123 hostname.\n*   **Domainname** - A string value containing the domain name to use for the container.\n*   **User** - A string value specifying the user inside the container.\n*   **AttachStdin** - Boolean value, attaches to `stdin`.\n*   **AttachStdout** - Boolean value, attaches to `stdout`.\n*   **AttachStderr** - Boolean value, attaches to `stderr`.\n*   **Tty** - Boolean value, Attach standard streams to a `tty`, including `stdin` if it is not closed.\n*   **OpenStdin** - Boolean value, opens `stdin`,\n*   **StdinOnce** - Boolean value, close `stdin` after the 1 attached client disconnects.\n*   **Env** - A list of environment variables in the form of `[\"VAR=value\", ...]`\n*   **Labels** - Adds a map of labels to a container. To specify a map: `{\"key\":\"value\", ... }`\n*   **Cmd** - Command to run specified as a string or an array of strings.\n*   **Entrypoint** - Set the entry point for the container as a string or an array of strings.\n*   **Image** - A string specifying the image name to use for the container.\n*   **Volumes** - An object mapping mount point paths (strings) inside the container to empty objects.\n*   **Healthcheck** - A test to perform to check that the container is healthy.\n    *   ```\n        **Test** - The test to perform. Possible values are:\n            + `{}` inherit healthcheck from image or parent image\n            + `{\"NONE\"}` disable healthcheck\n            + `{\"CMD\", args...}` exec arguments directly\n            + `{\"CMD-SHELL\", command}` run command with system's default shell\n        ```\n        \n    *   ```\n        **Interval** - The time to wait between checks in nanoseconds. It should be 0 or at least 1000000 (1 ms). 0 means inherit.\n        ```\n        \n    *   ```\n        **Timeout** - The time to wait before considering the check to have hung. It should be 0 or at least 1000000 (1 ms). 0 means inherit.\n        ```\n        \n    *   ```\n        **Retries** - The number of consecutive failures needed to consider a container as unhealthy. 0 means inherit.\n        ```\n        \n    *   ```\n        **StartPeriod** - The time to wait for container initialization before starting health-retries countdown in nanoseconds. It should be 0 or at least 1000000 (1 ms). 0 means inherit.\n        ```\n        \n*   **WorkingDir** - A string specifying the working directory for commands to run in.\n*   **NetworkDisabled** - Boolean value, when true disables networking for the container\n*   **ExposedPorts** - An object mapping ports to an empty object in the form of: `\"ExposedPorts\": { \"<port>/<tcp|udp>: {}\" }`\n*   **StopSignal** - Signal to stop a container as a string or unsigned integer. `SIGTERM` by default.\n*   **HostConfig**\n    *   **Binds** â€“ A list of volume bindings for this container. Each volume binding is a string in one of these forms:\n        \n        *   `host-src:container-dest` to bind-mount a host path into the container. Both `host-src`, and `container-dest` must be an _absolute_ path.\n        *   `host-src:container-dest:ro` to make the bind mount read-only inside the container. Both `host-src`, and `container-dest` must be an _absolute_ path.\n        *   `volume-name:container-dest` to bind-mount a volume managed by a volume driver into the container. `container-dest` must be an _absolute_ path.\n        *   `volume-name:container-dest:ro` to mount the volume read-only inside the container. `container-dest` must be an _absolute_ path.\n    *   **Tmpfs** â€“ A map of container directories which should be replaced by tmpfs mounts, and their corresponding mount options. A JSON object in the form `{ \"/run\": \"rw,noexec,nosuid,size=65536k\" }`.\n        \n    *   **Links** - A list of links for the container. Each link entry should be in the form of `container_name:alias`.\n        \n    *   **Memory** - Memory limit in bytes.\n        \n    *   **MemorySwap** - Total memory limit (memory + swap); set `-1` to enable unlimited swap. You must use this with `memory` and make the swap value larger than `memory`.\n        \n    *   **MemoryReservation** - Memory soft limit in bytes.\n        \n    *   **KernelMemory** - Kernel memory limit in bytes.\n        \n    *   **CpuPercent** - An integer value containing the usable percentage of the available CPUs. (Windows daemon only)\n        \n    *   **CpuShares** - An integer value containing the container's CPU Shares (ie. the relative weight vs other containers).\n        \n    *   **CpuPeriod** - The length of a CPU period in microseconds.\n        \n    *   **CpuQuota** - Microseconds of CPU time that the container can get in a CPU period.\n        \n    *   **CpusetCpus** - String value containing the `cgroups CpusetCpus` to use.\n        \n    *   **CpusetMems** - Memory nodes (MEMs) in which to allow execution (0-3, 0,1). Only effective on NUMA systems.\n        \n    *   **IOMaximumBandwidth** - Maximum IO absolute rate in terms of IOps.\n        \n    *   **IOMaximumIOps** - Maximum IO absolute rate in terms of bytes per second.\n        \n    *   **BlkioWeight** - Block IO weight (relative weight) accepts a weight value between 10 and 1000.\n        \n    *   **BlkioWeightDevice** - Block IO weight (relative device weight) in the form of: `\"BlkioWeightDevice\": [{\"Path\": \"device_path\", \"Weight\": weight}]`\n        \n    *   **BlkioDeviceReadBps** - Limit read rate (bytes per second) from a device in the form of: `\"BlkioDeviceReadBps\": [{\"Path\": \"device_path\", \"Rate\": rate}]`, for example: `\"BlkioDeviceReadBps\": [{\"Path\": \"/dev/sda\", \"Rate\": \"1024\"}]\"`\n        \n    *   **BlkioDeviceWriteBps** - Limit write rate (bytes per second) to a device in the form of: `\"BlkioDeviceWriteBps\": [{\"Path\": \"device_path\", \"Rate\": rate}]`, for example: `\"BlkioDeviceWriteBps\": [{\"Path\": \"/dev/sda\", \"Rate\": \"1024\"}]\"`\n        \n    *   **BlkioDeviceReadIOps** - Limit read rate (IO per second) from a device in the form of: `\"BlkioDeviceReadIOps\": [{\"Path\": \"device_path\", \"Rate\": rate}]`, for example: `\"BlkioDeviceReadIOps\": [{\"Path\": \"/dev/sda\", \"Rate\": \"1000\"}]`\n        \n    *   **BlkioDeviceWriteIOps** - Limit write rate (IO per second) to a device in the form of: `\"BlkioDeviceWriteIOps\": [{\"Path\": \"device_path\", \"Rate\": rate}]`, for example: `\"BlkioDeviceWriteIOps\": [{\"Path\": \"/dev/sda\", \"Rate\": \"1000\"}]`\n        \n    *   **MemorySwappiness** - Tune a container's memory swappiness behavior. Accepts an integer between 0 and 100.\n        \n    *   **OomKillDisable** - Boolean value, whether to disable OOM Killer for the container or not.\n        \n    *   **OomScoreAdj** - An integer value containing the score given to the container in order to tune OOM killer preferences.\n        \n    *   **PidMode** - Set the PID (Process) Namespace mode for the container; `\"container:<name|id>\"`: joins another container's PID namespace `\"host\"`: use the host's PID namespace inside the container\n        \n    *   **PidsLimit** - Tune a container's pids limit. Set -1 for unlimited.\n        \n    *   **PortBindings** - A map of exposed container ports and the host port they should map to. A JSON object in the form `{ <port>/<protocol>: [{ \"HostPort\": \"<port>\" }] }` Take note that `port` is specified as a string and not an integer value.\n        \n    *   **PublishAllPorts** - Allocates an ephemeral host port for all of a container's exposed ports. Specified as a boolean value.\n        \n        Ports are de-allocated when the container stops and allocated when the container starts. The allocated port might be changed when restarting the container.\n        \n        The port is selected from the ephemeral port range that depends on the kernel. For example, on Linux the range is defined by `/proc/sys/net/ipv4/ip_local_port_range`.\n        \n    *   **Privileged** - Gives the container full access to the host. Specified as a boolean value.\n        \n    *   **ReadonlyRootfs** - Mount the container's root filesystem as read only. Specified as a boolean value.\n        \n    *   **Dns** - A list of DNS servers for the container to use.\n        \n    *   **DnsOptions** - A list of DNS options\n        \n    *   **DnsSearch** - A list of DNS search domains\n        \n    *   **ExtraHosts** - A list of hostnames/IP mappings to add to the container's `/etc/hosts` file. Specified in the form `[\"hostname:IP\"]`.\n        \n    *   **VolumesFrom** - A list of volumes to inherit from another container. Specified in the form `<container name>[:<ro|rw>]`\n        \n    *   **CapAdd** - A list of kernel capabilities to add to the container.\n        \n    *   **Capdrop** - A list of kernel capabilities to drop from the container.\n        \n    *   **GroupAdd** - A list of additional groups that the container process will run as\n        \n    *   **RestartPolicy** â€“ The behavior to apply when the container exits. The value is an object with a `Name` property of either `\"always\"` to always restart, `\"unless-stopped\"` to restart always except when user has manually stopped the container or `\"on-failure\"` to restart only when the container exit code is non-zero. If `on-failure` is used, `MaximumRetryCount` controls the number of times to retry before giving up. The default is not to restart. (optional) An ever increasing delay (double the previous delay, starting at 100mS) is added before each restart to prevent flooding the server.\n        \n    *   **UsernsMode** - Sets the usernamespace mode for the container when usernamespace remapping option is enabled. supported values are: `host`.\n        \n    *   **NetworkMode** - Sets the networking mode for the container. Supported standard values are: `bridge`, `host`, `none`, and `container:<name|id>`. Any other value is taken as a custom network's name to which this container should connect to.\n        \n    *   **Devices** - A list of devices to add to the container specified as a JSON object in the form `{ \"PathOnHost\": \"/dev/deviceName\", \"PathInContainer\": \"/dev/deviceName\", \"CgroupPermissions\": \"mrw\"}`\n        \n    *   **Ulimits** - A list of ulimits to set in the container, specified as `{ \"Name\": <name>, \"Soft\": <soft limit>, \"Hard\": <hard limit> }`, for example: `Ulimits: { \"Name\": \"nofile\", \"Soft\": 1024, \"Hard\": 2048 }`\n        \n    *   **Sysctls** - A list of kernel parameters (sysctls) to set in the container, specified as `{ <name>: <Value> }`, for example: `{ \"net.ipv4.ip_forward\": \"1\" }`\n        \n    *   **SecurityOpt**: A list of string values to customize labels for MLS systems, such as SELinux.\n        \n    *   **StorageOpt**: Storage driver options per container. Options can be passed in the form `{\"size\":\"120G\"}`\n        \n    *   **LogConfig** - Log configuration for the container, specified as a JSON object in the form `{ \"Type\": \"<driver_name>\", \"Config\": {\"key1\": \"val1\"}}`. Available types: `json-file`, `syslog`, `journald`, `gelf`, `fluentd`, `awslogs`, `splunk`, `etwlogs`, `none`. `json-file` logging driver.\n        \n    *   **CgroupParent** - Path to `cgroups` under which the container's `cgroup` is created. If the path is not absolute, the path is considered to be relative to the `cgroups` path of the init process. Cgroups are created if they do not already exist.\n        \n    *   **VolumeDriver** - Driver that this container users to mount volumes.\n        \n    *   **ShmSize** - Size of `/dev/shm` in bytes. The size must be greater than 0. If omitted the system uses 64MB.\n        \n\n**Query parameters**:\n\n*   **name** â€“ Assign the specified name to the container. Must match `/?[a-zA-Z0-9_-]+`.\n\n**Status codes**:\n\n*   **201** â€“ no error\n*   **400** â€“ bad parameter\n*   **404** â€“ no such image\n*   **406** â€“ impossible to attach (container not running)\n*   **409** â€“ conflict\n*   **500** â€“ server error\n\n#### [Inspect a container](#inspect-a-container)\n\n`GET /containers/(id or name)/json`\n\nReturn low-level information on the container `id`\n\n**Example request**:\n\n```\n  GET /v1.24/containers/4fa6e0f0c678/json HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n{\n\t\"AppArmorProfile\": \"\",\n\t\"Args\": [\n\t\t\"-c\",\n\t\t\"exit 9\"\n\t],\n\t\"Config\": {\n\t\t\"AttachStderr\": true,\n\t\t\"AttachStdin\": false,\n\t\t\"AttachStdout\": true,\n\t\t\"Cmd\": [\n\t\t\t\"/bin/sh\",\n\t\t\t\"-c\",\n\t\t\t\"exit 9\"\n\t\t],\n\t\t\"Domainname\": \"\",\n\t\t\"Entrypoint\": null,\n\t\t\"Env\": [\n\t\t\t\"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n\t\t],\n\t\t\"ExposedPorts\": null,\n\t\t\"Hostname\": \"ba033ac44011\",\n\t\t\"Image\": \"ubuntu\",\n\t\t\"Labels\": {\n\t\t\t\"com.example.vendor\": \"Acme\",\n\t\t\t\"com.example.license\": \"GPL\",\n\t\t\t\"com.example.version\": \"1.0\"\n\t\t},\n\t\t\"MacAddress\": \"\",\n\t\t\"NetworkDisabled\": false,\n\t\t\"OnBuild\": null,\n\t\t\"OpenStdin\": false,\n\t\t\"StdinOnce\": false,\n\t\t\"Tty\": false,\n\t\t\"User\": \"\",\n\t\t\"Volumes\": {\n\t\t\t\"/volumes/data\": {}\n\t\t},\n\t\t\"WorkingDir\": \"\",\n\t\t\"StopSignal\": \"SIGTERM\"\n\t},\n\t\"Created\": \"2015-01-06T15:47:31.485331387Z\",\n\t\"Driver\": \"overlay2\",\n\t\"ExecIDs\": null,\n\t\"HostConfig\": {\n\t\t\"Binds\": null,\n\t\t\"IOMaximumBandwidth\": 0,\n\t\t\"IOMaximumIOps\": 0,\n\t\t\"BlkioWeight\": 0,\n\t\t\"BlkioWeightDevice\": [{}],\n\t\t\"BlkioDeviceReadBps\": [{}],\n\t\t\"BlkioDeviceWriteBps\": [{}],\n\t\t\"BlkioDeviceReadIOps\": [{}],\n\t\t\"BlkioDeviceWriteIOps\": [{}],\n\t\t\"CapAdd\": null,\n\t\t\"CapDrop\": null,\n\t\t\"ContainerIDFile\": \"\",\n\t\t\"CpusetCpus\": \"\",\n\t\t\"CpusetMems\": \"\",\n\t\t\"CpuPercent\": 80,\n\t\t\"CpuShares\": 0,\n\t\t\"CpuPeriod\": 100000,\n\t\t\"Devices\": [],\n\t\t\"Dns\": null,\n\t\t\"DnsOptions\": null,\n\t\t\"DnsSearch\": null,\n\t\t\"ExtraHosts\": null,\n\t\t\"IpcMode\": \"\",\n\t\t\"Links\": null,\n\t\t\"Memory\": 0,\n\t\t\"MemorySwap\": 0,\n\t\t\"MemoryReservation\": 0,\n\t\t\"KernelMemory\": 0,\n\t\t\"OomKillDisable\": false,\n\t\t\"OomScoreAdj\": 500,\n\t\t\"NetworkMode\": \"bridge\",\n\t\t\"PidMode\": \"\",\n\t\t\"PortBindings\": {},\n\t\t\"Privileged\": false,\n\t\t\"ReadonlyRootfs\": false,\n\t\t\"PublishAllPorts\": false,\n\t\t\"RestartPolicy\": {\n\t\t\t\"MaximumRetryCount\": 2,\n\t\t\t\"Name\": \"on-failure\"\n\t\t},\n\t\t\"LogConfig\": {\n\t\t\t\"Config\": null,\n\t\t\t\"Type\": \"json-file\"\n\t\t},\n\t\t\"SecurityOpt\": null,\n\t\t\"Sysctls\": {\n\t\t        \"net.ipv4.ip_forward\": \"1\"\n\t\t},\n\t\t\"StorageOpt\": null,\n\t\t\"VolumesFrom\": null,\n\t\t\"Ulimits\": [{}],\n\t\t\"VolumeDriver\": \"\",\n\t\t\"ShmSize\": 67108864\n\t},\n\t\"HostnamePath\": \"/var/lib/docker/containers/ba033ac4401106a3b513bc9d639eee123ad78ca3616b921167cd74b20e25ed39/hostname\",\n\t\"HostsPath\": \"/var/lib/docker/containers/ba033ac4401106a3b513bc9d639eee123ad78ca3616b921167cd74b20e25ed39/hosts\",\n\t\"LogPath\": \"/var/lib/docker/containers/1eb5fabf5a03807136561b3c00adcd2992b535d624d5e18b6cdc6a6844d9767b/1eb5fabf5a03807136561b3c00adcd2992b535d624d5e18b6cdc6a6844d9767b-json.log\",\n\t\"Id\": \"ba033ac4401106a3b513bc9d639eee123ad78ca3616b921167cd74b20e25ed39\",\n\t\"Image\": \"04c5d3b7b0656168630d3ba35d8889bd0e9caafcaeb3004d2bfbc47e7c5d35d2\",\n\t\"MountLabel\": \"\",\n\t\"Name\": \"/boring_euclid\",\n\t\"NetworkSettings\": {\n\t\t\"Bridge\": \"\",\n\t\t\"SandboxID\": \"\",\n\t\t\"HairpinMode\": false,\n\t\t\"LinkLocalIPv6Address\": \"\",\n\t\t\"LinkLocalIPv6PrefixLen\": 0,\n\t\t\"Ports\": null,\n\t\t\"SandboxKey\": \"\",\n\t\t\"SecondaryIPAddresses\": null,\n\t\t\"SecondaryIPv6Addresses\": null,\n\t\t\"EndpointID\": \"\",\n\t\t\"Gateway\": \"\",\n\t\t\"GlobalIPv6Address\": \"\",\n\t\t\"GlobalIPv6PrefixLen\": 0,\n\t\t\"IPAddress\": \"\",\n\t\t\"IPPrefixLen\": 0,\n\t\t\"IPv6Gateway\": \"\",\n\t\t\"MacAddress\": \"\",\n\t\t\"Networks\": {\n\t\t\t\"bridge\": {\n\t\t\t\t\"NetworkID\": \"7ea29fc1412292a2d7bba362f9253545fecdfa8ce9a6e37dd10ba8bee7129812\",\n\t\t\t\t\"EndpointID\": \"7587b82f0dada3656fda26588aee72630c6fab1536d36e394b2bfbcf898c971d\",\n\t\t\t\t\"Gateway\": \"172.17.0.1\",\n\t\t\t\t\"IPAddress\": \"172.17.0.2\",\n\t\t\t\t\"IPPrefixLen\": 16,\n\t\t\t\t\"IPv6Gateway\": \"\",\n\t\t\t\t\"GlobalIPv6Address\": \"\",\n\t\t\t\t\"GlobalIPv6PrefixLen\": 0,\n\t\t\t\t\"MacAddress\": \"02:42:ac:12:00:02\"\n\t\t\t}\n\t\t}\n\t},\n\t\"Path\": \"/bin/sh\",\n\t\"ProcessLabel\": \"\",\n\t\"ResolvConfPath\": \"/var/lib/docker/containers/ba033ac4401106a3b513bc9d639eee123ad78ca3616b921167cd74b20e25ed39/resolv.conf\",\n\t\"RestartCount\": 1,\n\t\"State\": {\n\t\t\"Error\": \"\",\n\t\t\"ExitCode\": 9,\n\t\t\"FinishedAt\": \"2015-01-06T15:47:32.080254511Z\",\n\t\t\"OOMKilled\": false,\n\t\t\"Dead\": false,\n\t\t\"Paused\": false,\n\t\t\"Pid\": 0,\n\t\t\"Restarting\": false,\n\t\t\"Running\": true,\n\t\t\"StartedAt\": \"2015-01-06T15:47:32.072697474Z\",\n\t\t\"Status\": \"running\"\n\t},\n\t\"Mounts\": [\n\t\t{\n\t\t\t\"Name\": \"fac362...80535\",\n\t\t\t\"Source\": \"/data\",\n\t\t\t\"Destination\": \"/data\",\n\t\t\t\"Driver\": \"local\",\n\t\t\t\"Mode\": \"ro,Z\",\n\t\t\t\"RW\": false,\n\t\t\t\"Propagation\": \"\"\n\t\t}\n\t]\n}\n```\n\n**Example request, with size information**:\n\n```\nGET /v1.24/containers/4fa6e0f0c678/json?size=1 HTTP/1.1\n```\n\n**Example response, with size information**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n{\n....\n\"SizeRw\": 0,\n\"SizeRootFs\": 972,\n....\n}\n```\n\n**Query parameters**:\n\n*   **size** â€“ 1/True/true or 0/False/false, return container size information. Default is `false`.\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such container\n*   **500** â€“ server error\n\n#### [List processes running inside a container](#list-processes-running-inside-a-container)\n\n`GET /containers/(id or name)/top`\n\nList processes running inside the container `id`. On Unix systems this is done by running the `ps` command. This endpoint is not supported on Windows.\n\n**Example request**:\n\n```\nGET /v1.24/containers/4fa6e0f0c678/top HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n{\n   \"Titles\" : [\n     \"UID\", \"PID\", \"PPID\", \"C\", \"STIME\", \"TTY\", \"TIME\", \"CMD\"\n   ],\n   \"Processes\" : [\n     [\n       \"root\", \"13642\", \"882\", \"0\", \"17:03\", \"pts/0\", \"00:00:00\", \"/bin/bash\"\n     ],\n     [\n       \"root\", \"13735\", \"13642\", \"0\", \"17:06\", \"pts/0\", \"00:00:00\", \"sleep 10\"\n     ]\n   ]\n}\n```\n\n**Example request**:\n\n```\nGET /v1.24/containers/4fa6e0f0c678/top?ps_args=aux HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n{\n  \"Titles\" : [\n    \"USER\",\"PID\",\"%CPU\",\"%MEM\",\"VSZ\",\"RSS\",\"TTY\",\"STAT\",\"START\",\"TIME\",\"COMMAND\"\n  ]\n  \"Processes\" : [\n    [\n      \"root\",\"13642\",\"0.0\",\"0.1\",\"18172\",\"3184\",\"pts/0\",\"Ss\",\"17:03\",\"0:00\",\"/bin/bash\"\n    ],\n    [\n      \"root\",\"13895\",\"0.0\",\"0.0\",\"4348\",\"692\",\"pts/0\",\"S+\",\"17:15\",\"0:00\",\"sleep 10\"\n    ]\n  ],\n}\n```\n\n**Query parameters**:\n\n*   **ps\\_args** â€“ `ps` arguments to use (e.g., `aux`), defaults to `-ef`\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such container\n*   **500** â€“ server error\n\n#### [Get container logs](#get-container-logs)\n\n`GET /containers/(id or name)/logs`\n\nGet `stdout` and `stderr` logs from the container `id`\n\n> **Note**: This endpoint works only for containers with the `json-file` or `journald` logging drivers.\n\n**Example request**:\n\n```\n GET /v1.24/containers/4fa6e0f0c678/logs?stderr=1&stdout=1&timestamps=1&follow=1&tail=10&since=1428990821 HTTP/1.1\n```\n\n**Example response**:\n\n```\n HTTP/1.1 101 UPGRADED\n Content-Type: application/vnd.docker.raw-stream\n Connection: Upgrade\n Upgrade: tcp\n\n {% raw %}\n {{ STREAM }}\n {% endraw %}\n```\n\n**Query parameters**:\n\n*   **details** - 1/True/true or 0/False/false, Show extra details provided to logs. Default `false`.\n*   **follow** â€“ 1/True/true or 0/False/false, return stream. Default `false`.\n*   **stdout** â€“ 1/True/true or 0/False/false, show `stdout` log. Default `false`.\n*   **stderr** â€“ 1/True/true or 0/False/false, show `stderr` log. Default `false`.\n*   **since** â€“ UNIX timestamp (integer) to filter logs. Specifying a timestamp will only output log-entries since that timestamp. Default: 0 (unfiltered)\n*   **timestamps** â€“ 1/True/true or 0/False/false, print timestamps for every log line. Default `false`.\n*   **tail** â€“ Output specified number of lines at the end of logs: `all` or `<number>`. Default all.\n\n**Status codes**:\n\n*   **101** â€“ no error, hints proxy about hijacking\n*   **200** â€“ no error, no upgrade header found\n*   **404** â€“ no such container\n*   **500** â€“ server error\n\n#### [Inspect changes on a container's filesystem](#inspect-changes-on-a-containers-filesystem)\n\n`GET /containers/(id or name)/changes`\n\nInspect changes on container `id`'s filesystem\n\n**Example request**:\n\n```\nGET /v1.24/containers/4fa6e0f0c678/changes HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n[\n     {\n             \"Path\": \"/dev\",\n             \"Kind\": 0\n     },\n     {\n             \"Path\": \"/dev/kmsg\",\n             \"Kind\": 1\n     },\n     {\n             \"Path\": \"/test\",\n             \"Kind\": 1\n     }\n]\n```\n\nValues for `Kind`:\n\n*   `0`: Modify\n*   `1`: Add\n*   `2`: Delete\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such container\n*   **500** â€“ server error\n\n#### [Export a container](#export-a-container)\n\n`GET /containers/(id or name)/export`\n\nExport the contents of container `id`\n\n**Example request**:\n\n```\nGET /v1.24/containers/4fa6e0f0c678/export HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/octet-stream\n\n{% raw %}\n{{ TAR STREAM }}\n{% endraw %}\n```\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such container\n*   **500** â€“ server error\n\n#### [Get container stats based on resource usage](#get-container-stats-based-on-resource-usage)\n\n`GET /containers/(id or name)/stats`\n\nThis endpoint returns a live stream of a container's resource usage statistics.\n\n**Example request**:\n\n```\nGET /v1.24/containers/redis1/stats HTTP/1.1\n```\n\n**Example response**:\n\n```\n  HTTP/1.1 200 OK\n  Content-Type: application/json\n\n  {\n     \"read\" : \"2015-01-08T22:57:31.547920715Z\",\n     \"pids_stats\": {\n        \"current\": 3\n     },\n     \"networks\": {\n             \"eth0\": {\n                 \"rx_bytes\": 5338,\n                 \"rx_dropped\": 0,\n                 \"rx_errors\": 0,\n                 \"rx_packets\": 36,\n                 \"tx_bytes\": 648,\n                 \"tx_dropped\": 0,\n                 \"tx_errors\": 0,\n                 \"tx_packets\": 8\n             },\n             \"eth5\": {\n                 \"rx_bytes\": 4641,\n                 \"rx_dropped\": 0,\n                 \"rx_errors\": 0,\n                 \"rx_packets\": 26,\n                 \"tx_bytes\": 690,\n                 \"tx_dropped\": 0,\n                 \"tx_errors\": 0,\n                 \"tx_packets\": 9\n             }\n     },\n     \"memory_stats\" : {\n        \"stats\" : {\n           \"total_pgmajfault\" : 0,\n           \"cache\" : 0,\n           \"mapped_file\" : 0,\n           \"total_inactive_file\" : 0,\n           \"pgpgout\" : 414,\n           \"rss\" : 6537216,\n           \"total_mapped_file\" : 0,\n           \"writeback\" : 0,\n           \"unevictable\" : 0,\n           \"pgpgin\" : 477,\n           \"total_unevictable\" : 0,\n           \"pgmajfault\" : 0,\n           \"total_rss\" : 6537216,\n           \"total_rss_huge\" : 6291456,\n           \"total_writeback\" : 0,\n           \"total_inactive_anon\" : 0,\n           \"rss_huge\" : 6291456,\n           \"hierarchical_memory_limit\" : 67108864,\n           \"total_pgfault\" : 964,\n           \"total_active_file\" : 0,\n           \"active_anon\" : 6537216,\n           \"total_active_anon\" : 6537216,\n           \"total_pgpgout\" : 414,\n           \"total_cache\" : 0,\n           \"inactive_anon\" : 0,\n           \"active_file\" : 0,\n           \"pgfault\" : 964,\n           \"inactive_file\" : 0,\n           \"total_pgpgin\" : 477\n        },\n        \"max_usage\" : 6651904,\n        \"usage\" : 6537216,\n        \"failcnt\" : 0,\n        \"limit\" : 67108864\n     },\n     \"blkio_stats\" : {},\n     \"cpu_stats\" : {\n        \"cpu_usage\" : {\n           \"percpu_usage\" : [\n              8646879,\n              24472255,\n              36438778,\n              30657443\n           ],\n           \"usage_in_usermode\" : 50000000,\n           \"total_usage\" : 100215355,\n           \"usage_in_kernelmode\" : 30000000\n        },\n        \"system_cpu_usage\" : 739306590000000,\n        \"throttling_data\" : {\"periods\":0,\"throttled_periods\":0,\"throttled_time\":0}\n     },\n     \"precpu_stats\" : {\n        \"cpu_usage\" : {\n           \"percpu_usage\" : [\n              8646879,\n              24350896,\n              36438778,\n              30657443\n           ],\n           \"usage_in_usermode\" : 50000000,\n           \"total_usage\" : 100093996,\n           \"usage_in_kernelmode\" : 30000000\n        },\n        \"system_cpu_usage\" : 9492140000000,\n        \"throttling_data\" : {\"periods\":0,\"throttled_periods\":0,\"throttled_time\":0}\n     }\n  }\n```\n\nThe `precpu_stats` is the cpu statistic of _previous_ read, which is used for calculating the cpu usage percent. It is not the exact copy of the `cpu_stats` field.\n\n**Query parameters**:\n\n*   **stream** â€“ 1/True/true or 0/False/false, pull stats once then disconnect. Default `true`.\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such container\n*   **500** â€“ server error\n\n#### [Resize a container TTY](#resize-a-container-tty)\n\n`POST /containers/(id or name)/resize`\n\nResize the TTY for container with `id`. The unit is number of characters. You must restart the container for the resize to take effect.\n\n**Example request**:\n\n```\n  POST /v1.24/containers/4fa6e0f0c678/resize?h=40&w=80 HTTP/1.1\n```\n\n**Example response**:\n\n```\n  HTTP/1.1 200 OK\n  Content-Length: 0\n  Content-Type: text/plain; charset=utf-8\n```\n\n**Query parameters**:\n\n*   **h** â€“ height of `tty` session\n*   **w** â€“ width\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ No such container\n*   **500** â€“ Cannot resize container\n\n#### [Start a container](#start-a-container)\n\n`POST /containers/(id or name)/start`\n\nStart the container `id`\n\n**Example request**:\n\n```\nPOST /v1.24/containers/e90e34656806/start HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 204 No Content\n```\n\n**Query parameters**:\n\n*   **detachKeys** â€“ Override the key sequence for detaching a container. Format is a single character `[a-Z]` or `ctrl-<value>` where `<value>` is one of: `a-z`, `@`, `^`, `[`, `,` or `_`.\n\n**Status codes**:\n\n*   **204** â€“ no error\n*   **304** â€“ container already started\n*   **404** â€“ no such container\n*   **500** â€“ server error\n\n#### [Stop a container](#stop-a-container)\n\n`POST /containers/(id or name)/stop`\n\nStop the container `id`\n\n**Example request**:\n\n```\nPOST /v1.24/containers/e90e34656806/stop?t=5 HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 204 No Content\n```\n\n**Query parameters**:\n\n*   **t** â€“ number of seconds to wait before killing the container\n\n**Status codes**:\n\n*   **204** â€“ no error\n*   **304** â€“ container already stopped\n*   **404** â€“ no such container\n*   **500** â€“ server error\n\n#### [Restart a container](#restart-a-container)\n\n`POST /containers/(id or name)/restart`\n\nRestart the container `id`\n\n**Example request**:\n\n```\nPOST /v1.24/containers/e90e34656806/restart?t=5 HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 204 No Content\n```\n\n**Query parameters**:\n\n*   **t** â€“ number of seconds to wait before killing the container\n\n**Status codes**:\n\n*   **204** â€“ no error\n*   **404** â€“ no such container\n*   **500** â€“ server error\n\n#### [Kill a container](#kill-a-container)\n\n`POST /containers/(id or name)/kill`\n\nKill the container `id`\n\n**Example request**:\n\n```\nPOST /v1.24/containers/e90e34656806/kill HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 204 No Content\n```\n\n**Query parameters**:\n\n*   **signal** - Signal to send to the container: integer or string like `SIGINT`. When not set, `SIGKILL` is assumed and the call waits for the container to exit.\n\n**Status codes**:\n\n*   **204** â€“ no error\n*   **404** â€“ no such container\n*   **500** â€“ server error\n\n#### [Update a container](#update-a-container)\n\n`POST /containers/(id or name)/update`\n\nUpdate configuration of one or more containers.\n\n**Example request**:\n\n```\n   POST /v1.24/containers/e90e34656806/update HTTP/1.1\n   Content-Type: application/json\n   Content-Length: 12345\n\n   {\n     \"BlkioWeight\": 300,\n     \"CpuShares\": 512,\n     \"CpuPeriod\": 100000,\n     \"CpuQuota\": 50000,\n     \"CpusetCpus\": \"0,1\",\n     \"CpusetMems\": \"0\",\n     \"Memory\": 314572800,\n     \"MemorySwap\": 514288000,\n     \"MemoryReservation\": 209715200,\n     \"KernelMemory\": 52428800,\n     \"RestartPolicy\": {\n       \"MaximumRetryCount\": 4,\n       \"Name\": \"on-failure\"\n     }\n   }\n```\n\n**Example response**:\n\n```\n   HTTP/1.1 200 OK\n   Content-Type: application/json\n\n   {\n       \"Warnings\": []\n   }\n```\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **400** â€“ bad parameter\n*   **404** â€“ no such container\n*   **500** â€“ server error\n\n#### [Rename a container](#rename-a-container)\n\n`POST /containers/(id or name)/rename`\n\nRename the container `id` to a `new_name`\n\n**Example request**:\n\n```\nPOST /v1.24/containers/e90e34656806/rename?name=new_name HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 204 No Content\n```\n\n**Query parameters**:\n\n*   **name** â€“ new name for the container\n\n**Status codes**:\n\n*   **204** â€“ no error\n*   **404** â€“ no such container\n*   **409** - conflict name already assigned\n*   **500** â€“ server error\n\n#### [Pause a container](#pause-a-container)\n\n`POST /containers/(id or name)/pause`\n\nPause the container `id`\n\n**Example request**:\n\n```\nPOST /v1.24/containers/e90e34656806/pause HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 204 No Content\n```\n\n**Status codes**:\n\n*   **204** â€“ no error\n*   **404** â€“ no such container\n*   **500** â€“ server error\n\n#### [Unpause a container](#unpause-a-container)\n\n`POST /containers/(id or name)/unpause`\n\nUnpause the container `id`\n\n**Example request**:\n\n```\nPOST /v1.24/containers/e90e34656806/unpause HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 204 No Content\n```\n\n**Status codes**:\n\n*   **204** â€“ no error\n*   **404** â€“ no such container\n*   **500** â€“ server error\n\n#### [Attach to a container](#attach-to-a-container)\n\n`POST /containers/(id or name)/attach`\n\nAttach to the container `id`\n\n**Example request**:\n\n```\nPOST /v1.24/containers/16253994b7c4/attach?logs=1&stream=0&stdout=1 HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 101 UPGRADED\nContent-Type: application/vnd.docker.raw-stream\nConnection: Upgrade\nUpgrade: tcp\n\n{% raw %}\n{{ STREAM }}\n{% endraw %}\n```\n\n**Query parameters**:\n\n*   **detachKeys** â€“ Override the key sequence for detaching a container. Format is a single character `[a-Z]` or `ctrl-<value>` where `<value>` is one of: `a-z`, `@`, `^`, `[`, `,` or `_`.\n*   **logs** â€“ 1/True/true or 0/False/false, return logs. Default `false`.\n*   **stream** â€“ 1/True/true or 0/False/false, return stream. Default `false`.\n*   **stdin** â€“ 1/True/true or 0/False/false, if `stream=true`, attach to `stdin`. Default `false`.\n*   **stdout** â€“ 1/True/true or 0/False/false, if `logs=true`, return `stdout` log, if `stream=true`, attach to `stdout`. Default `false`.\n*   **stderr** â€“ 1/True/true or 0/False/false, if `logs=true`, return `stderr` log, if `stream=true`, attach to `stderr`. Default `false`.\n\n**Status codes**:\n\n*   **101** â€“ no error, hints proxy about hijacking\n*   **200** â€“ no error, no upgrade header found\n*   **400** â€“ bad parameter\n*   **404** â€“ no such container\n*   **409** - container is paused\n*   **500** â€“ server error\n\n**Stream details**:\n\nWhen using the TTY setting is enabled in [`POST /containers/create`](#create-a-container) , the stream is the raw data from the process PTY and client's `stdin`. When the TTY is disabled, then the stream is multiplexed to separate `stdout` and `stderr`.\n\nThe format is a **Header** and a **Payload** (frame).\n\n**HEADER**\n\nThe header contains the information which the stream writes (`stdout` or `stderr`). It also contains the size of the associated frame encoded in the last four bytes (`uint32`).\n\nIt is encoded on the first eight bytes like this:\n\n```\nheader := [8]byte{STREAM_TYPE, 0, 0, 0, SIZE1, SIZE2, SIZE3, SIZE4}\n```\n\n`STREAM_TYPE` can be:\n\n*   0: `stdin` (is written on `stdout`)\n*   1: `stdout`\n*   2: `stderr`\n\n`SIZE1, SIZE2, SIZE3, SIZE4` are the four bytes of the `uint32` size encoded as big endian.\n\n**PAYLOAD**\n\nThe payload is the raw stream.\n\n**IMPLEMENTATION**\n\nThe simplest way to implement the Attach protocol is the following:\n\n```\n1.  Read eight bytes.\n2.  Choose `stdout` or `stderr` depending on the first byte.\n3.  Extract the frame size from the last four bytes.\n4.  Read the extracted size and output it on the correct output.\n5.  Goto 1.\n```\n\n#### [Attach to a container (websocket)](#attach-to-a-container-websocket)\n\n`GET /containers/(id or name)/attach/ws`\n\nAttach to the container `id` via websocket\n\nImplements websocket protocol handshake according to [RFC 6455](http://tools.ietf.org/html/rfc6455)\n\n**Example request**\n\n```\nGET /v1.24/containers/e90e34656806/attach/ws?logs=0&stream=1&stdin=1&stdout=1&stderr=1 HTTP/1.1\n```\n\n**Example response**\n\n```\n{% raw %}\n{{ STREAM }}\n{% endraw %}\n```\n\n**Query parameters**:\n\n*   **detachKeys** â€“ Override the key sequence for detaching a container. Format is a single character `[a-Z]` or `ctrl-<value>` where `<value>` is one of: `a-z`, `@`, `^`, `[`, `,` or `_`.\n*   **logs** â€“ 1/True/true or 0/False/false, return logs. Default `false`.\n*   **stream** â€“ 1/True/true or 0/False/false, return stream. Default `false`.\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **400** â€“ bad parameter\n*   **404** â€“ no such container\n*   **500** â€“ server error\n\n#### [Wait a container](#wait-a-container)\n\n`POST /containers/(id or name)/wait`\n\nBlock until container `id` stops, then returns the exit code\n\n**Example request**:\n\n```\nPOST /v1.24/containers/16253994b7c4/wait HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n{\"StatusCode\": 0}\n```\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such container\n*   **500** â€“ server error\n\n#### [Remove a container](#remove-a-container)\n\n`DELETE /containers/(id or name)`\n\nRemove the container `id` from the filesystem\n\n**Example request**:\n\n```\nDELETE /v1.24/containers/16253994b7c4?v=1 HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 204 No Content\n```\n\n**Query parameters**:\n\n*   **v** â€“ 1/True/true or 0/False/false, Remove the volumes associated to the container. Default `false`.\n*   **force** - 1/True/true or 0/False/false, Kill then remove the container. Default `false`.\n*   **link** - 1/True/true or 0/False/false, Remove the specified link associated to the container. Default `false`.\n\n**Status codes**:\n\n*   **204** â€“ no error\n*   **400** â€“ bad parameter\n*   **404** â€“ no such container\n*   **409** â€“ conflict\n*   **500** â€“ server error\n\n#### [Retrieving information about files and folders in a container](#retrieving-information-about-files-and-folders-in-a-container)\n\n`HEAD /containers/(id or name)/archive`\n\nSee the description of the `X-Docker-Container-Path-Stat` header in the following section.\n\n#### [Get an archive of a filesystem resource in a container](#get-an-archive-of-a-filesystem-resource-in-a-container)\n\n`GET /containers/(id or name)/archive`\n\nGet a tar archive of a resource in the filesystem of container `id`.\n\n**Query parameters**:\n\n*   **path** - resource in the container's filesystem to archive. Required.\n    \n    If not an absolute path, it is relative to the container's root directory. The resource specified by **path** must exist. To assert that the resource is expected to be a directory, **path** should end in `/` or `/.` (assuming a path separator of `/`). If **path** ends in `/.` then this indicates that only the contents of the **path** directory should be copied. A symlink is always resolved to its target.\n    \n    > **Note**: It is not possible to copy certain system files such as resources under `/proc`, `/sys`, `/dev`, and mounts created by the user in the container.\n    \n\n**Example request**:\n\n```\nGET /v1.24/containers/8cce319429b2/archive?path=/root HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/x-tar\nX-Docker-Container-Path-Stat: eyJuYW1lIjoicm9vdCIsInNpemUiOjQwOTYsIm1vZGUiOjIxNDc0ODQwOTYsIm10aW1lIjoiMjAxNC0wMi0yN1QyMDo1MToyM1oiLCJsaW5rVGFyZ2V0IjoiIn0=\n\n{% raw %}\n{{ TAR STREAM }}\n{% endraw %}\n```\n\nOn success, a response header `X-Docker-Container-Path-Stat` will be set to a base64-encoded JSON object containing some filesystem header information about the archived resource. The above example value would decode to the following JSON object (whitespace added for readability):\n\nA `HEAD` request can also be made to this endpoint if only this information is desired.\n\n**Status codes**:\n\n*   **200** - success, returns archive of copied resource\n*   **400** - client error, bad parameter, details in JSON response body, one of:\n    *   must specify path parameter (**path** cannot be empty)\n    *   not a directory (**path** was asserted to be a directory but exists as a file)\n*   **404** - client error, resource not found, one of: â€“ no such container (container `id` does not exist)\n    *   no such file or directory (**path** does not exist)\n*   **500** - server error\n\n`PUT /containers/(id or name)/archive`\n\nUpload a tar archive to be extracted to a path in the filesystem of container `id`.\n\n**Query parameters**:\n\n*   **path** - path to a directory in the container to extract the archive's contents into. Required.\n    \n    If not an absolute path, it is relative to the container's root directory. The **path** resource must exist.\n    \n*   **noOverwriteDirNonDir** - If \"1\", \"true\", or \"True\" then it will be an error if unpacking the given content would cause an existing directory to be replaced with a non-directory and vice versa.\n    \n\n**Example request**:\n\n```\nPUT /v1.24/containers/8cce319429b2/archive?path=/vol1 HTTP/1.1\nContent-Type: application/x-tar\n\n{% raw %}\n{{ TAR STREAM }}\n{% endraw %}\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\n```\n\n**Status codes**:\n\n*   **200** â€“ the content was extracted successfully\n*   **400** - client error, bad parameter, details in JSON response body, one of:\n    *   must specify path parameter (**path** cannot be empty)\n    *   not a directory (**path** should be a directory but exists as a file)\n    *   unable to overwrite existing directory with non-directory (if **noOverwriteDirNonDir**)\n    *   unable to overwrite existing non-directory with directory (if **noOverwriteDirNonDir**)\n*   **403** - client error, permission denied, the volume or container rootfs is marked as read-only.\n*   **404** - client error, resource not found, one of: â€“ no such container (container `id` does not exist)\n    *   no such file or directory (**path** resource does not exist)\n*   **500** â€“ server error\n\n### [3.2 Images](#32-images)\n\n#### [List Images](#list-images)\n\n`GET /images/json`\n\n**Example request**:\n\n```\nGET /v1.24/images/json?all=0 HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n[\n  {\n     \"RepoTags\": [\n       \"ubuntu:12.04\",\n       \"ubuntu:precise\",\n       \"ubuntu:latest\"\n     ],\n     \"Id\": \"8dbd9e392a964056420e5d58ca5cc376ef18e2de93b5cc90e868a1bbc8318c1c\",\n     \"Created\": 1365714795,\n     \"Size\": 131506275,\n     \"VirtualSize\": 131506275,\n     \"Labels\": {}\n  },\n  {\n     \"RepoTags\": [\n       \"ubuntu:12.10\",\n       \"ubuntu:quantal\"\n     ],\n     \"ParentId\": \"27cf784147099545\",\n     \"Id\": \"b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc\",\n     \"Created\": 1364102658,\n     \"Size\": 24653,\n     \"VirtualSize\": 180116135,\n     \"Labels\": {\n        \"com.example.version\": \"v1\"\n     }\n  }\n]\n```\n\n**Example request, with digest information**:\n\n```\nGET /v1.24/images/json?digests=1 HTTP/1.1\n```\n\n**Example response, with digest information**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n[\n  {\n    \"Created\": 1420064636,\n    \"Id\": \"4986bf8c15363d1c5d15512d5266f8777bfba4974ac56e3270e7760f6f0a8125\",\n    \"ParentId\": \"ea13149945cb6b1e746bf28032f02e9b5a793523481a0a18645fc77ad53c4ea2\",\n    \"RepoDigests\": [\n      \"localhost:5000/test/busybox@sha256:cbbf2f9a99b47fc460d422812b6a5adff7dfee951d8fa2e4a98caa0382cfbdbf\"\n    ],\n    \"RepoTags\": [\n      \"localhost:5000/test/busybox:latest\",\n      \"playdate:latest\"\n    ],\n    \"Size\": 0,\n    \"VirtualSize\": 2429728,\n    \"Labels\": {}\n  }\n]\n```\n\nThe response shows a single image `Id` associated with two repositories (`RepoTags`): `localhost:5000/test/busybox`: and `playdate`. A caller can use either of the `RepoTags` values `localhost:5000/test/busybox:latest` or `playdate:latest` to reference the image.\n\nYou can also use `RepoDigests` values to reference an image. In this response, the array has only one reference and that is to the `localhost:5000/test/busybox` repository; the `playdate` repository has no digest. You can reference this digest using the value: `localhost:5000/test/busybox@sha256:cbbf2f9a99b47fc460d...`\n\nSee the `docker run` and `docker build` commands for examples of digest and tag references on the command line.\n\n**Query parameters**:\n\n*   **all** â€“ 1/True/true or 0/False/false, default false\n*   **filters** â€“ a JSON encoded value of the filters (a map\\[string\\]\\[\\]string) to process on the images list. Available filters:\n*   `dangling=true`\n*   `label=key` or `label=\"key=value\"` of an image label\n*   `before`\\=(`<image-name>[:<tag>]`, `<image id>` or `<image@digest>`)\n*   `since`\\=(`<image-name>[:<tag>]`, `<image id>` or `<image@digest>`)\n*   **filter** - only return images with the specified name\n\n#### [Build image from a Dockerfile](#build-image-from-a-dockerfile)\n\n`POST /build`\n\nBuild an image from a Dockerfile\n\n**Example request**:\n\n```\nPOST /v1.24/build HTTP/1.1\nContent-Type: application/x-tar\n\n{% raw %}\n{{ TAR STREAM }}\n{% endraw %}\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n{\"stream\": \"Step 1/5...\"}\n{\"stream\": \"...\"}\n{\"error\": \"Error...\", \"errorDetail\": {\"code\": 123, \"message\": \"Error...\"}}\n```\n\nThe input stream must be a `tar` archive compressed with one of the following algorithms: `identity` (no compression), `gzip`, `bzip2`, `xz`.\n\nThe archive must include a build instructions file, typically called `Dockerfile` at the archive's root. The `dockerfile` parameter may be used to specify a different build instructions file. To do this, its value must be the path to the alternate build instructions file to use.\n\nThe archive may include any number of other files, which are accessible in the build context (See the [_ADD build command_](https://docs.docker.com/engine/reference/builder/#add)).\n\nThe Docker daemon performs a preliminary validation of the `Dockerfile` before starting the build, and returns an error if the syntax is incorrect. After that, each instruction is run one-by-one until the ID of the new image is output.\n\nThe build is canceled if the client drops the connection by quitting or being killed.\n\n**Query parameters**:\n\n*   **dockerfile** - Path within the build context to the `Dockerfile`. This is ignored if `remote` is specified and points to an external `Dockerfile`.\n*   **t** â€“ A name and optional tag to apply to the image in the `name:tag` format. If you omit the `tag` the default `latest` value is assumed. You can provide one or more `t` parameters.\n*   **remote** â€“ A Git repository URI or HTTP/HTTPS context URI. If the URI points to a single text file, the file's contents are placed into a file called `Dockerfile` and the image is built from that file. If the URI points to a tarball, the file is downloaded by the daemon and the contents therein used as the context for the build. If the URI points to a tarball and the `dockerfile` parameter is also specified, there must be a file with the corresponding path inside the tarball.\n*   **q** â€“ Suppress verbose build output.\n*   **nocache** â€“ Do not use the cache when building the image.\n*   **pull** - Attempt to pull the image even if an older image exists locally.\n*   **rm** - Remove intermediate containers after a successful build (default behavior).\n*   **forcerm** - Always remove intermediate containers (includes `rm`).\n*   **memory** - Set memory limit for build.\n*   **memswap** - Total memory (memory + swap), `-1` to enable unlimited swap.\n*   **cpushares** - CPU shares (relative weight).\n*   **cpusetcpus** - CPUs in which to allow execution (e.g., `0-3`, `0,1`).\n*   **cpuperiod** - The length of a CPU period in microseconds.\n*   **cpuquota** - Microseconds of CPU time that the container can get in a CPU period.\n*   **buildargs** â€“ JSON map of string pairs for build-time variables. Users pass these values at build-time. Docker uses the `buildargs` as the environment context for command(s) run via the Dockerfile's `RUN` instruction or for variable expansion in other Dockerfile instructions. This is not meant for passing secret values. [Read more about the buildargs instruction](https://docs.docker.com/engine/reference/builder/#arg)\n*   **shmsize** - Size of `/dev/shm` in bytes. The size must be greater than 0. If omitted the system uses 64MB.\n*   **labels** â€“ JSON map of string pairs for labels to set on the image.\n\n**Request Headers**:\n\n*   **Content-type** â€“ Set to `\"application/x-tar\"`.\n    \n*   **X-Registry-Config** â€“ A base64-url-safe-encoded Registry Auth Config JSON object with the following structure:\n    \n    ```\n        {\n            \"docker.example.com\": {\n                \"username\": \"janedoe\",\n                \"password\": \"hunter2\"\n            },\n            \"https://index.docker.io/v1/\": {\n                \"username\": \"mobydock\",\n                \"password\": \"conta1n3rize14\"\n            }\n        }\n    ```\n    \n    This object maps the hostname of a registry to an object containing the \"username\" and \"password\" for that registry. Multiple registries may be specified as the build may be based on an image requiring authentication to pull from any arbitrary registry. Only the registry domain name (and port if not the default \"443\") are required. However (for legacy reasons) the \"official\" Docker, Inc. hosted registry must be specified with both a \"https://\" prefix and a \"/v1/\" suffix even though Docker will prefer to use the v2 registry API.\n    \n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **500** â€“ server error\n\n#### [Create an image](#create-an-image)\n\n`POST /images/create`\n\nCreate an image either by pulling it from the registry or by importing it\n\n**Example request**:\n\n```\nPOST /v1.24/images/create?fromImage=busybox&tag=latest HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n{\"status\": \"Pulling...\"}\n{\"status\": \"Pulling\", \"progress\": \"1 B/ 100 B\", \"progressDetail\": {\"current\": 1, \"total\": 100}}\n{\"error\": \"Invalid...\"}\n...\n```\n\nWhen using this endpoint to pull an image from the registry, the `X-Registry-Auth` header can be used to include a base64-encoded AuthConfig object.\n\n**Query parameters**:\n\n*   **fromImage** â€“ Name of the image to pull. The name may include a tag or digest. This parameter may only be used when pulling an image. The pull is cancelled if the HTTP connection is closed.\n*   **fromSrc** â€“ Source to import. The value may be a URL from which the image can be retrieved or `-` to read the image from the request body. This parameter may only be used when importing an image.\n*   **repo** â€“ Repository name given to an image when it is imported. The repo may include a tag. This parameter may only be used when importing an image.\n*   **tag** â€“ Tag or digest. If empty when pulling an image, this causes all tags for the given image to be pulled.\n\n**Request Headers**:\n\n*   **X-Registry-Auth** â€“ base64-encoded AuthConfig object, containing either login information, or a token\n    \n    *   Credential based login:\n        \n    \n    { \"username\": \"jdoe\", \"password\": \"secret\", \"email\": \"jdoe@acme.com\" } \\`\\`\\`\n    \n    *   Token based login:\n        \n    \n    { \"identitytoken\": \"9cbaf023786cd7...\" } \\`\\`\\`\n    \n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** - repository does not exist or no read access\n*   **500** â€“ server error\n\n#### [Inspect an image](#inspect-an-image)\n\n`GET /images/(name)/json`\n\nReturn low-level information on the image `name`\n\n**Example request**:\n\n```\nGET /v1.24/images/example/json HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n{\n   \"Id\" : \"sha256:85f05633ddc1c50679be2b16a0479ab6f7637f8884e0cfe0f4d20e1ebb3d6e7c\",\n   \"Container\" : \"cb91e48a60d01f1e27028b4fc6819f4f290b3cf12496c8176ec714d0d390984a\",\n   \"Comment\" : \"\",\n   \"Os\" : \"linux\",\n   \"Architecture\" : \"amd64\",\n   \"Parent\" : \"sha256:91e54dfb11794fad694460162bf0cb0a4fa710cfa3f60979c177d920813e267c\",\n   \"ContainerConfig\" : {\n      \"Tty\" : false,\n      \"Hostname\" : \"e611e15f9c9d\",\n      \"Volumes\" : null,\n      \"Domainname\" : \"\",\n      \"AttachStdout\" : false,\n      \"PublishService\" : \"\",\n      \"AttachStdin\" : false,\n      \"OpenStdin\" : false,\n      \"StdinOnce\" : false,\n      \"NetworkDisabled\" : false,\n      \"OnBuild\" : [],\n      \"Image\" : \"91e54dfb11794fad694460162bf0cb0a4fa710cfa3f60979c177d920813e267c\",\n      \"User\" : \"\",\n      \"WorkingDir\" : \"\",\n      \"Entrypoint\" : null,\n      \"MacAddress\" : \"\",\n      \"AttachStderr\" : false,\n      \"Labels\" : {\n         \"com.example.license\" : \"GPL\",\n         \"com.example.version\" : \"1.0\",\n         \"com.example.vendor\" : \"Acme\"\n      },\n      \"Env\" : [\n         \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n      ],\n      \"ExposedPorts\" : null,\n      \"Cmd\" : [\n         \"/bin/sh\",\n         \"-c\",\n         \"#(nop) LABEL com.example.vendor=Acme com.example.license=GPL com.example.version=1.0\"\n      ]\n   },\n   \"DockerVersion\" : \"1.9.0-dev\",\n   \"VirtualSize\" : 188359297,\n   \"Size\" : 0,\n   \"Author\" : \"\",\n   \"Created\" : \"2015-09-10T08:30:53.26995814Z\",\n   \"GraphDriver\" : {\n      \"Name\" : \"aufs\",\n      \"Data\" : null\n   },\n   \"RepoDigests\" : [\n      \"localhost:5000/test/busybox/example@sha256:cbbf2f9a99b47fc460d422812b6a5adff7dfee951d8fa2e4a98caa0382cfbdbf\"\n   ],\n   \"RepoTags\" : [\n      \"example:1.0\",\n      \"example:latest\",\n      \"example:stable\"\n   ],\n   \"Config\" : {\n      \"Image\" : \"91e54dfb11794fad694460162bf0cb0a4fa710cfa3f60979c177d920813e267c\",\n      \"NetworkDisabled\" : false,\n      \"OnBuild\" : [],\n      \"StdinOnce\" : false,\n      \"PublishService\" : \"\",\n      \"AttachStdin\" : false,\n      \"OpenStdin\" : false,\n      \"Domainname\" : \"\",\n      \"AttachStdout\" : false,\n      \"Tty\" : false,\n      \"Hostname\" : \"e611e15f9c9d\",\n      \"Volumes\" : null,\n      \"Cmd\" : [\n         \"/bin/bash\"\n      ],\n      \"ExposedPorts\" : null,\n      \"Env\" : [\n         \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n      ],\n      \"Labels\" : {\n         \"com.example.vendor\" : \"Acme\",\n         \"com.example.version\" : \"1.0\",\n         \"com.example.license\" : \"GPL\"\n      },\n      \"Entrypoint\" : null,\n      \"MacAddress\" : \"\",\n      \"AttachStderr\" : false,\n      \"WorkingDir\" : \"\",\n      \"User\" : \"\"\n   },\n   \"RootFS\": {\n       \"Type\": \"layers\",\n       \"Layers\": [\n           \"sha256:1834950e52ce4d5a88a1bbd131c537f4d0e56d10ff0dd69e66be3b7dfa9df7e6\",\n           \"sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef\"\n       ]\n   }\n}\n```\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such image\n*   **500** â€“ server error\n\n#### [Get the history of an image](#get-the-history-of-an-image)\n\n`GET /images/(name)/history`\n\nReturn the history of the image `name`\n\n**Example request**:\n\n```\nGET /v1.24/images/ubuntu/history HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n[\n    {\n        \"Id\": \"3db9c44f45209632d6050b35958829c3a2aa256d81b9a7be45b362ff85c54710\",\n        \"Created\": 1398108230,\n        \"CreatedBy\": \"/bin/sh -c #(nop) ADD file:eb15dbd63394e063b805a3c32ca7bf0266ef64676d5a6fab4801f2e81e2a5148 in /\",\n        \"Tags\": [\n            \"ubuntu:lucid\",\n            \"ubuntu:10.04\"\n        ],\n        \"Size\": 182964289,\n        \"Comment\": \"\"\n    },\n    {\n        \"Id\": \"6cfa4d1f33fb861d4d114f43b25abd0ac737509268065cdfd69d544a59c85ab8\",\n        \"Created\": 1398108222,\n        \"CreatedBy\": \"/bin/sh -c #(nop) MAINTAINER Tianon Gravi <admwiggin@gmail.com> - mkimage-debootstrap.sh -i iproute,iputils-ping,ubuntu-minimal -t lucid.tar.xz lucid http://archive.ubuntu.com/ubuntu/\",\n        \"Tags\": null,\n        \"Size\": 0,\n        \"Comment\": \"\"\n    },\n    {\n        \"Id\": \"511136ea3c5a64f264b78b5433614aec563103b4d4702f3ba7d4d2698e22c158\",\n        \"Created\": 1371157430,\n        \"CreatedBy\": \"\",\n        \"Tags\": [\n            \"scratch12:latest\",\n            \"scratch:latest\"\n        ],\n        \"Size\": 0,\n        \"Comment\": \"Imported from -\"\n    }\n]\n```\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such image\n*   **500** â€“ server error\n\n#### [Push an image on the registry](#push-an-image-on-the-registry)\n\n`POST /images/(name)/push`\n\nPush the image `name` on the registry\n\n**Example request**:\n\n```\nPOST /v1.24/images/test/push HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n{\"status\": \"Pushing...\"}\n{\"status\": \"Pushing\", \"progress\": \"1/? (n/a)\", \"progressDetail\": {\"current\": 1}}}\n{\"error\": \"Invalid...\"}\n...\n```\n\nIf you wish to push an image on to a private registry, that image must already have a tag into a repository which references that registry `hostname` and `port`. This repository name should then be used in the URL. This duplicates the command line's flow.\n\nThe push is cancelled if the HTTP connection is closed.\n\n**Example request**:\n\n```\nPOST /v1.24/images/registry.acme.com:5000/test/push HTTP/1.1\n```\n\n**Query parameters**:\n\n*   **tag** â€“ The tag to associate with the image on the registry. This is optional.\n\n**Request Headers**:\n\n*   **X-Registry-Auth** â€“ base64-encoded AuthConfig object, containing either login information, or a token\n    \n    *   Credential based login:\n        \n    \n    { \"username\": \"jdoe\", \"password\": \"secret\", \"email\": \"jdoe@acme.com\", } \\`\\`\\`\n    \n    *   Identity token based login:\n        \n    \n    { \"identitytoken\": \"9cbaf023786cd7...\" } \\`\\`\\`\n    \n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such image\n*   **500** â€“ server error\n\n#### [Tag an image into a repository](#tag-an-image-into-a-repository)\n\n`POST /images/(name)/tag`\n\nTag the image `name` into a repository\n\n**Example request**:\n\n```\nPOST /v1.24/images/test/tag?repo=myrepo&tag=v42 HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 201 Created\n```\n\n**Query parameters**:\n\n*   **repo** â€“ The repository to tag in\n*   **tag** - The new tag name\n\n**Status codes**:\n\n*   **201** â€“ no error\n*   **400** â€“ bad parameter\n*   **404** â€“ no such image\n*   **409** â€“ conflict\n*   **500** â€“ server error\n\n#### [Remove an image](#remove-an-image)\n\n`DELETE /images/(name)`\n\nRemove the image `name` from the filesystem\n\n**Example request**:\n\n```\nDELETE /v1.24/images/test HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-type: application/json\n\n[\n {\"Untagged\": \"3e2f21a89f\"},\n {\"Deleted\": \"3e2f21a89f\"},\n {\"Deleted\": \"53b4f83ac9\"}\n]\n```\n\n**Query parameters**:\n\n*   **force** â€“ 1/True/true or 0/False/false, default false\n*   **noprune** â€“ 1/True/true or 0/False/false, default false\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such image\n*   **409** â€“ conflict\n*   **500** â€“ server error\n\n#### [Search images](#search-images)\n\n`GET /images/search`\n\nSearch for an image on [Docker Hub](https://hub.docker.com/).\n\n> **Note**: The response keys have changed from API v1.6 to reflect the JSON sent by the registry server to the docker daemon's request.\n\n**Example request**:\n\n```\nGET /v1.24/images/search?term=sshd HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n[\n        {\n            \"description\": \"\",\n            \"is_official\": false,\n            \"is_automated\": false,\n            \"name\": \"wma55/u1210sshd\",\n            \"star_count\": 0\n        },\n        {\n            \"description\": \"\",\n            \"is_official\": false,\n            \"is_automated\": false,\n            \"name\": \"jdswinbank/sshd\",\n            \"star_count\": 0\n        },\n        {\n            \"description\": \"\",\n            \"is_official\": false,\n            \"is_automated\": false,\n            \"name\": \"vgauthier/sshd\",\n            \"star_count\": 0\n        }\n...\n]\n```\n\n**Query parameters**:\n\n*   **term** â€“ term to search\n*   **limit** â€“ maximum returned search results\n*   **filters** â€“ a JSON encoded value of the filters (a map\\[string\\]\\[\\]string) to process on the images list. Available filters:\n*   `stars=<number>`\n*   `is-automated=(true|false)`\n*   `is-official=(true|false)`\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **500** â€“ server error\n\n### [3.3 Misc](#33-misc)\n\n#### [Check auth configuration](#check-auth-configuration)\n\n`POST /auth`\n\nValidate credentials for a registry and get identity token, if available, for accessing the registry without password.\n\n**Example request**:\n\n```\nPOST /v1.24/auth HTTP/1.1\nContent-Type: application/json\nContent-Length: 12345\n\n{\n     \"username\": \"hannibal\",\n     \"password\": \"xxxx\",\n     \"serveraddress\": \"https://index.docker.io/v1/\"\n}\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\n\n{\n     \"Status\": \"Login Succeeded\",\n     \"IdentityToken\": \"9cbaf023786cd7...\"\n}\n```\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **204** â€“ no error\n*   **500** â€“ server error\n\n#### [Display system-wide information](#display-system-wide-information)\n\n`GET /info`\n\nDisplay system-wide information\n\n**Example request**:\n\n```\nGET /v1.24/info HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n{\n    \"Architecture\": \"x86_64\",\n    \"ClusterStore\": \"etcd://localhost:2379\",\n    \"CgroupDriver\": \"cgroupfs\",\n    \"Containers\": 11,\n    \"ContainersRunning\": 7,\n    \"ContainersStopped\": 3,\n    \"ContainersPaused\": 1,\n    \"CpuCfsPeriod\": true,\n    \"CpuCfsQuota\": true,\n    \"Debug\": false,\n    \"DockerRootDir\": \"/var/lib/docker\",\n    \"Driver\": \"btrfs\",\n    \"DriverStatus\": [[\"\"]],\n    \"ExperimentalBuild\": false,\n    \"HttpProxy\": \"http://test:test@localhost:8080\",\n    \"HttpsProxy\": \"https://test:test@localhost:8080\",\n    \"ID\": \"7TRN:IPZB:QYBB:VPBQ:UMPP:KARE:6ZNR:XE6T:7EWV:PKF4:ZOJD:TPYS\",\n    \"IPv4Forwarding\": true,\n    \"Images\": 16,\n    \"IndexServerAddress\": \"https://index.docker.io/v1/\",\n    \"InitPath\": \"/usr/bin/docker\",\n    \"InitSha1\": \"\",\n    \"KernelMemory\": true,\n    \"KernelVersion\": \"3.12.0-1-amd64\",\n    \"Labels\": [\n        \"storage=ssd\"\n    ],\n    \"MemTotal\": 2099236864,\n    \"MemoryLimit\": true,\n    \"NCPU\": 1,\n    \"NEventsListener\": 0,\n    \"NFd\": 11,\n    \"NGoroutines\": 21,\n    \"Name\": \"prod-server-42\",\n    \"NoProxy\": \"9.81.1.160\",\n    \"OomKillDisable\": true,\n    \"OSType\": \"linux\",\n    \"OperatingSystem\": \"Boot2Docker\",\n    \"Plugins\": {\n        \"Volume\": [\n            \"local\"\n        ],\n        \"Network\": [\n            \"null\",\n            \"host\",\n            \"bridge\"\n        ]\n    },\n    \"RegistryConfig\": {\n        \"IndexConfigs\": {\n            \"docker.io\": {\n                \"Mirrors\": null,\n                \"Name\": \"docker.io\",\n                \"Official\": true,\n                \"Secure\": true\n            }\n        },\n        \"InsecureRegistryCIDRs\": [\n            \"127.0.0.0/8\"\n        ]\n    },\n    \"SecurityOptions\": [\n        \"apparmor\",\n        \"seccomp\",\n        \"selinux\"\n    ],\n    \"ServerVersion\": \"1.9.0\",\n    \"SwapLimit\": false,\n    \"SystemStatus\": [[\"State\", \"Healthy\"]],\n    \"SystemTime\": \"2015-03-10T11:11:23.730591467-07:00\"\n}\n```\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **500** â€“ server error\n\n#### [Show the docker version information](#show-the-docker-version-information)\n\n`GET /version`\n\nShow the docker version information\n\n**Example request**:\n\n```\nGET /v1.24/version HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n{\n     \"Version\": \"1.12.0\",\n     \"Os\": \"linux\",\n     \"KernelVersion\": \"3.19.0-23-generic\",\n     \"GoVersion\": \"go1.6.3\",\n     \"GitCommit\": \"deadbee\",\n     \"Arch\": \"amd64\",\n     \"ApiVersion\": \"1.24\",\n     \"BuildTime\": \"2016-06-14T07:09:13.444803460+00:00\",\n     \"Experimental\": true\n}\n```\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **500** â€“ server error\n\n#### [Ping the docker server](#ping-the-docker-server)\n\n`GET /_ping`\n\nPing the docker server\n\n**Example request**:\n\n```\nGET /v1.24/_ping HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: text/plain\n\nOK\n```\n\n**Status codes**:\n\n*   **200** - no error\n*   **500** - server error\n\n#### [Create a new image from a container's changes](#create-a-new-image-from-a-containers-changes)\n\n`POST /commit`\n\nCreate a new image from a container's changes\n\n**Example request**:\n\n```\nPOST /v1.24/commit?container=44c004db4b17&comment=message&repo=myrepo HTTP/1.1\nContent-Type: application/json\nContent-Length: 12345\n\n{\n     \"Hostname\": \"\",\n     \"Domainname\": \"\",\n     \"User\": \"\",\n     \"AttachStdin\": false,\n     \"AttachStdout\": true,\n     \"AttachStderr\": true,\n     \"Tty\": false,\n     \"OpenStdin\": false,\n     \"StdinOnce\": false,\n     \"Env\": null,\n     \"Cmd\": [\n             \"date\"\n     ],\n     \"Mounts\": [\n       {\n         \"Source\": \"/data\",\n         \"Destination\": \"/data\",\n         \"Mode\": \"ro,Z\",\n         \"RW\": false\n       }\n     ],\n     \"Labels\": {\n             \"key1\": \"value1\",\n             \"key2\": \"value2\"\n      },\n     \"WorkingDir\": \"\",\n     \"NetworkDisabled\": false,\n     \"ExposedPorts\": {\n             \"22/tcp\": {}\n     }\n}\n```\n\n**Example response**:\n\n```\nHTTP/1.1 201 Created\nContent-Type: application/json\n\n{\"Id\": \"596069db4bf5\"}\n```\n\n**JSON parameters**:\n\n*   **config** - the container's configuration\n\n**Query parameters**:\n\n*   **container** â€“ source container\n*   **repo** â€“ repository\n*   **tag** â€“ tag\n*   **comment** â€“ commit message\n*   **author** â€“ author (e.g., \"John Hannibal Smith < hannibal@a-team.com\\>\")\n*   **pause** â€“ 1/True/true or 0/False/false, whether to pause the container before committing\n*   **changes** â€“ Dockerfile instructions to apply while committing\n\n**Status codes**:\n\n*   **201** â€“ no error\n*   **404** â€“ no such container\n*   **500** â€“ server error\n\n#### [Monitor Docker's events](#monitor-dockers-events)\n\n`GET /events`\n\nGet container events from docker, in real time via streaming.\n\nDocker containers report the following events:\n\n```\nattach, commit, copy, create, destroy, detach, die, exec_create, exec_detach, exec_start, export, health_status, kill, oom, pause, rename, resize, restart, start, stop, top, unpause, update\n```\n\nDocker images report the following events:\n\n```\ndelete, import, load, pull, push, save, tag, untag\n```\n\nDocker volumes report the following events:\n\n```\ncreate, mount, unmount, destroy\n```\n\nDocker networks report the following events:\n\n```\ncreate, connect, disconnect, destroy\n```\n\nDocker daemon report the following event:\n\n```\nreload\n```\n\n**Example request**:\n\n```\nGET /v1.24/events?since=1374067924\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\nServer: Docker/1.12.0 (linux)\nDate: Fri, 29 Apr 2016 15:18:06 GMT\nTransfer-Encoding: chunked\n\n{\n  \"status\": \"pull\",\n  \"id\": \"alpine:latest\",\n  \"Type\": \"image\",\n  \"Action\": \"pull\",\n  \"Actor\": {\n    \"ID\": \"alpine:latest\",\n    \"Attributes\": {\n      \"name\": \"alpine\"\n    }\n  },\n  \"time\": 1461943101,\n  \"timeNano\": 1461943101301854122\n}\n{\n  \"status\": \"create\",\n  \"id\": \"ede54ee1afda366ab42f824e8a5ffd195155d853ceaec74a927f249ea270c743\",\n  \"from\": \"alpine\",\n  \"Type\": \"container\",\n  \"Action\": \"create\",\n  \"Actor\": {\n    \"ID\": \"ede54ee1afda366ab42f824e8a5ffd195155d853ceaec74a927f249ea270c743\",\n    \"Attributes\": {\n      \"com.example.some-label\": \"some-label-value\",\n      \"image\": \"alpine\",\n      \"name\": \"my-container\"\n    }\n  },\n  \"time\": 1461943101,\n  \"timeNano\": 1461943101381709551\n}\n{\n  \"status\": \"attach\",\n  \"id\": \"ede54ee1afda366ab42f824e8a5ffd195155d853ceaec74a927f249ea270c743\",\n  \"from\": \"alpine\",\n  \"Type\": \"container\",\n  \"Action\": \"attach\",\n  \"Actor\": {\n    \"ID\": \"ede54ee1afda366ab42f824e8a5ffd195155d853ceaec74a927f249ea270c743\",\n    \"Attributes\": {\n      \"com.example.some-label\": \"some-label-value\",\n      \"image\": \"alpine\",\n      \"name\": \"my-container\"\n    }\n  },\n  \"time\": 1461943101,\n  \"timeNano\": 1461943101383858412\n}\n{\n  \"Type\": \"network\",\n  \"Action\": \"connect\",\n  \"Actor\": {\n    \"ID\": \"7dc8ac97d5d29ef6c31b6052f3938c1e8f2749abbd17d1bd1febf2608db1b474\",\n    \"Attributes\": {\n      \"container\": \"ede54ee1afda366ab42f824e8a5ffd195155d853ceaec74a927f249ea270c743\",\n      \"name\": \"bridge\",\n      \"type\": \"bridge\"\n    }\n  },\n  \"time\": 1461943101,\n  \"timeNano\": 1461943101394865557\n}\n{\n  \"status\": \"start\",\n  \"id\": \"ede54ee1afda366ab42f824e8a5ffd195155d853ceaec74a927f249ea270c743\",\n  \"from\": \"alpine\",\n  \"Type\": \"container\",\n  \"Action\": \"start\",\n  \"Actor\": {\n    \"ID\": \"ede54ee1afda366ab42f824e8a5ffd195155d853ceaec74a927f249ea270c743\",\n    \"Attributes\": {\n      \"com.example.some-label\": \"some-label-value\",\n      \"image\": \"alpine\",\n      \"name\": \"my-container\"\n    }\n  },\n  \"time\": 1461943101,\n  \"timeNano\": 1461943101607533796\n}\n{\n  \"status\": \"resize\",\n  \"id\": \"ede54ee1afda366ab42f824e8a5ffd195155d853ceaec74a927f249ea270c743\",\n  \"from\": \"alpine\",\n  \"Type\": \"container\",\n  \"Action\": \"resize\",\n  \"Actor\": {\n    \"ID\": \"ede54ee1afda366ab42f824e8a5ffd195155d853ceaec74a927f249ea270c743\",\n    \"Attributes\": {\n      \"com.example.some-label\": \"some-label-value\",\n      \"height\": \"46\",\n      \"image\": \"alpine\",\n      \"name\": \"my-container\",\n      \"width\": \"204\"\n    }\n  },\n  \"time\": 1461943101,\n  \"timeNano\": 1461943101610269268\n}\n{\n  \"status\": \"die\",\n  \"id\": \"ede54ee1afda366ab42f824e8a5ffd195155d853ceaec74a927f249ea270c743\",\n  \"from\": \"alpine\",\n  \"Type\": \"container\",\n  \"Action\": \"die\",\n  \"Actor\": {\n    \"ID\": \"ede54ee1afda366ab42f824e8a5ffd195155d853ceaec74a927f249ea270c743\",\n    \"Attributes\": {\n      \"com.example.some-label\": \"some-label-value\",\n      \"exitCode\": \"0\",\n      \"image\": \"alpine\",\n      \"name\": \"my-container\"\n    }\n  },\n  \"time\": 1461943105,\n  \"timeNano\": 1461943105079144137\n}\n{\n  \"Type\": \"network\",\n  \"Action\": \"disconnect\",\n  \"Actor\": {\n    \"ID\": \"7dc8ac97d5d29ef6c31b6052f3938c1e8f2749abbd17d1bd1febf2608db1b474\",\n    \"Attributes\": {\n      \"container\": \"ede54ee1afda366ab42f824e8a5ffd195155d853ceaec74a927f249ea270c743\",\n      \"name\": \"bridge\",\n      \"type\": \"bridge\"\n    }\n  },\n  \"time\": 1461943105,\n  \"timeNano\": 1461943105230860245\n}\n{\n  \"status\": \"destroy\",\n  \"id\": \"ede54ee1afda366ab42f824e8a5ffd195155d853ceaec74a927f249ea270c743\",\n  \"from\": \"alpine\",\n  \"Type\": \"container\",\n  \"Action\": \"destroy\",\n  \"Actor\": {\n    \"ID\": \"ede54ee1afda366ab42f824e8a5ffd195155d853ceaec74a927f249ea270c743\",\n    \"Attributes\": {\n      \"com.example.some-label\": \"some-label-value\",\n      \"image\": \"alpine\",\n      \"name\": \"my-container\"\n    }\n  },\n  \"time\": 1461943105,\n  \"timeNano\": 1461943105338056026\n}\n```\n\n**Query parameters**:\n\n*   **since** â€“ Timestamp. Show all events created since timestamp and then stream\n*   **until** â€“ Timestamp. Show events created until given timestamp and stop streaming\n*   **filters** â€“ A json encoded value of the filters (a map\\[string\\]\\[\\]string) to process on the event list. Available filters:\n*   `container=<string>`; -- container to filter\n*   `event=<string>`; -- event to filter\n*   `image=<string>`; -- image to filter\n*   `label=<string>`; -- image and container label to filter\n*   `type=<string>`; -- either `container` or `image` or `volume` or `network` or `daemon`\n*   `volume=<string>`; -- volume to filter\n*   `network=<string>`; -- network to filter\n*   `daemon=<string>`; -- daemon name or id to filter\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **400** - bad parameter\n*   **500** â€“ server error\n\n#### [Get a tarball containing all images in a repository](#get-a-tarball-containing-all-images-in-a-repository)\n\n`GET /images/(name)/get`\n\nGet a tarball containing all images and metadata for the repository specified by `name`.\n\nIf `name` is a specific name and tag (e.g. ubuntu:latest), then only that image (and its parents) are returned. If `name` is an image ID, similarly only that image (and its parents) are returned, but with the exclusion of the 'repositories' file in the tarball, as there were no image names referenced.\n\nSee the [image tarball format](#image-tarball-format) for more details.\n\n**Example request**\n\n```\nGET /v1.24/images/ubuntu/get\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/x-tar\n\nBinary data stream\n```\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **500** â€“ server error\n\n#### [Get a tarball containing all images](#get-a-tarball-containing-all-images)\n\n`GET /images/get`\n\nGet a tarball containing all images and metadata for one or more repositories.\n\nFor each value of the `names` parameter: if it is a specific name and tag (e.g. `ubuntu:latest`), then only that image (and its parents) are returned; if it is an image ID, similarly only that image (and its parents) are returned and there would be no names referenced in the 'repositories' file for this image ID.\n\nSee the [image tarball format](#image-tarball-format) for more details.\n\n**Example request**\n\n```\nGET /v1.24/images/get?names=myname%2Fmyapp%3Alatest&names=busybox\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/x-tar\n\nBinary data stream\n```\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **500** â€“ server error\n\n#### [Load a tarball with a set of images and tags into docker](#load-a-tarball-with-a-set-of-images-and-tags-into-docker)\n\n`POST /images/load`\n\nLoad a set of images and tags into a Docker repository. See the [image tarball format](#image-tarball-format) for more details.\n\n**Example request**\n\n```\nPOST /v1.24/images/load\nContent-Type: application/x-tar\nContent-Length: 12345\n\nTarball in body\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\nTransfer-Encoding: chunked\n\n{\"status\":\"Loading layer\",\"progressDetail\":{\"current\":32768,\"total\":1292800},\"progress\":\"[=                                                 ] 32.77 kB/1.293 MB\",\"id\":\"8ac8bfaff55a\"}\n{\"status\":\"Loading layer\",\"progressDetail\":{\"current\":65536,\"total\":1292800},\"progress\":\"[==                                                ] 65.54 kB/1.293 MB\",\"id\":\"8ac8bfaff55a\"}\n{\"status\":\"Loading layer\",\"progressDetail\":{\"current\":98304,\"total\":1292800},\"progress\":\"[===                                               ]  98.3 kB/1.293 MB\",\"id\":\"8ac8bfaff55a\"}\n{\"status\":\"Loading layer\",\"progressDetail\":{\"current\":131072,\"total\":1292800},\"progress\":\"[=====                                             ] 131.1 kB/1.293 MB\",\"id\":\"8ac8bfaff55a\"}\n...\n{\"stream\":\"Loaded image: busybox:latest\\n\"}\n```\n\n**Example response**:\n\nIf the \"quiet\" query parameter is set to `true` / `1` (`?quiet=1`), progress details are suppressed, and only a confirmation message is returned once the action completes.\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\nTransfer-Encoding: chunked\n\n{\"stream\":\"Loaded image: busybox:latest\\n\"}\n```\n\n**Query parameters**:\n\n*   **quiet** â€“ Boolean value, suppress progress details during load. Defaults to `0` / `false` if omitted.\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **500** â€“ server error\n\n#### [Image tarball format](#image-tarball-format)\n\nAn image tarball contains one directory per image layer (named using its long ID), each containing these files:\n\n*   `VERSION`: currently `1.0` - the file format version\n*   `json`: detailed layer information, similar to `docker inspect layer_id`\n*   `layer.tar`: A tarfile containing the filesystem changes in this layer\n\nThe `layer.tar` file contains `aufs` style `.wh..wh.aufs` files and directories for storing attribute changes and deletions.\n\nIf the tarball defines a repository, the tarball should also include a `repositories` file at the root that contains a list of repository and tag names mapped to layer IDs.\n\n#### [Exec Create](#exec-create)\n\n`POST /containers/(id or name)/exec`\n\nSets up an exec instance in a running container `id`\n\n**Example request**:\n\n```\nPOST /v1.24/containers/e90e34656806/exec HTTP/1.1\nContent-Type: application/json\nContent-Length: 12345\n\n{\n  \"AttachStdin\": true,\n  \"AttachStdout\": true,\n  \"AttachStderr\": true,\n  \"Cmd\": [\"sh\"],\n  \"DetachKeys\": \"ctrl-p,ctrl-q\",\n  \"Privileged\": true,\n  \"Tty\": true,\n  \"User\": \"123:456\"\n}\n```\n\n**Example response**:\n\n```\nHTTP/1.1 201 Created\nContent-Type: application/json\n\n{\n     \"Id\": \"f90e34656806\",\n     \"Warnings\":[]\n}\n```\n\n**JSON parameters**:\n\n*   **AttachStdin** - Boolean value, attaches to `stdin` of the `exec` command.\n*   **AttachStdout** - Boolean value, attaches to `stdout` of the `exec` command.\n*   **AttachStderr** - Boolean value, attaches to `stderr` of the `exec` command.\n*   **DetachKeys** â€“ Override the key sequence for detaching a container. Format is a single character `[a-Z]` or `ctrl-<value>` where `<value>` is one of: `a-z`, `@`, `^`, `[`, `,` or `_`.\n*   **Tty** - Boolean value to allocate a pseudo-TTY.\n*   **Cmd** - Command to run specified as a string or an array of strings.\n*   **Privileged** - Boolean value, runs the exec process with extended privileges.\n*   **User** - A string value specifying the user, and optionally, group to run the exec process inside the container. Format is one of: `\"user\"`, `\"user:group\"`, `\"uid\"`, or `\"uid:gid\"`.\n\n**Status codes**:\n\n*   **201** â€“ no error\n*   **404** â€“ no such container\n*   **409** - container is paused\n*   **500** - server error\n\n#### [Exec Start](#exec-start)\n\n`POST /exec/(id)/start`\n\nStarts a previously set up `exec` instance `id`. If `detach` is true, this API returns after starting the `exec` command. Otherwise, this API sets up an interactive session with the `exec` command.\n\n**Example request**:\n\n```\nPOST /v1.24/exec/e90e34656806/start HTTP/1.1\nContent-Type: application/json\nContent-Length: 12345\n\n{\n \"Detach\": false,\n \"Tty\": false\n}\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/vnd.docker.raw-stream\n\n{% raw %}\n{{ STREAM }}\n{% endraw %}\n```\n\n**JSON parameters**:\n\n*   **Detach** - Detach from the `exec` command.\n*   **Tty** - Boolean value to allocate a pseudo-TTY.\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such exec instance\n*   **409** - container is paused\n\n**Stream details**:\n\nSimilar to the stream behavior of `POST /containers/(id or name)/attach` API\n\n#### [Exec Resize](#exec-resize)\n\n`POST /exec/(id)/resize`\n\nResizes the `tty` session used by the `exec` command `id`. The unit is number of characters. This API is valid only if `tty` was specified as part of creating and starting the `exec` command.\n\n**Example request**:\n\n```\nPOST /v1.24/exec/e90e34656806/resize?h=40&w=80 HTTP/1.1\nContent-Type: text/plain\n```\n\n**Example response**:\n\n```\nHTTP/1.1 201 Created\nContent-Type: text/plain\n```\n\n**Query parameters**:\n\n*   **h** â€“ height of `tty` session\n*   **w** â€“ width\n\n**Status codes**:\n\n*   **201** â€“ no error\n*   **404** â€“ no such exec instance\n\n#### [Exec Inspect](#exec-inspect)\n\n`GET /exec/(id)/json`\n\nReturn low-level information about the `exec` command `id`.\n\n**Example request**:\n\n```\nGET /v1.24/exec/11fb006128e8ceb3942e7c58d77750f24210e35f879dd204ac975c184b820b39/json HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n{\n  \"CanRemove\": false,\n  \"ContainerID\": \"b53ee82b53a40c7dca428523e34f741f3abc51d9f297a14ff874bf761b995126\",\n  \"DetachKeys\": \"\",\n  \"ExitCode\": 2,\n  \"ID\": \"f33bbfb39f5b142420f4759b2348913bd4a8d1a6d7fd56499cb41a1bb91d7b3b\",\n  \"OpenStderr\": true,\n  \"OpenStdin\": true,\n  \"OpenStdout\": true,\n  \"ProcessConfig\": {\n    \"arguments\": [\n      \"-c\",\n      \"exit 2\"\n    ],\n    \"entrypoint\": \"sh\",\n    \"privileged\": false,\n    \"tty\": true,\n    \"user\": \"1000\"\n  },\n  \"Running\": false\n}\n```\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such exec instance\n*   **500** - server error\n\n### [3.4 Volumes](#34-volumes)\n\n#### [List volumes](#list-volumes)\n\n`GET /volumes`\n\n**Example request**:\n\n```\nGET /v1.24/volumes HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n{\n  \"Volumes\": [\n    {\n      \"Name\": \"tardis\",\n      \"Driver\": \"local\",\n      \"Mountpoint\": \"/var/lib/docker/volumes/tardis\",\n      \"Labels\": null,\n      \"Scope\": \"local\"\n    }\n  ],\n  \"Warnings\": []\n}\n```\n\n**Query parameters**:\n\n*   **filters** - JSON encoded value of the filters (a `map[string][]string`) to process on the volumes list. Available filters:\n    *   `name=<volume-name>` Matches all or part of a volume name.\n    *   `dangling=<boolean>` When set to `true` (or `1`), returns all volumes that are \"dangling\" (not in use by a container). When set to `false` (or `0`), only volumes that are in use by one or more containers are returned.\n    *   `driver=<volume-driver-name>` Matches all or part of a volume driver name.\n\n**Status codes**:\n\n*   **200** - no error\n*   **500** - server error\n\n#### [Create a volume](#create-a-volume)\n\n`POST /volumes/create`\n\nCreate a volume\n\n**Example request**:\n\n```\nPOST /v1.24/volumes/create HTTP/1.1\nContent-Type: application/json\nContent-Length: 12345\n\n{\n  \"Name\": \"tardis\",\n  \"Labels\": {\n    \"com.example.some-label\": \"some-value\",\n    \"com.example.some-other-label\": \"some-other-value\"\n  },\n  \"Driver\": \"custom\"\n}\n```\n\n**Example response**:\n\n```\nHTTP/1.1 201 Created\nContent-Type: application/json\n\n{\n  \"Name\": \"tardis\",\n  \"Driver\": \"custom\",\n  \"Mountpoint\": \"/var/lib/docker/volumes/tardis\",\n  \"Status\": {\n    \"hello\": \"world\"\n  },\n  \"Labels\": {\n    \"com.example.some-label\": \"some-value\",\n    \"com.example.some-other-label\": \"some-other-value\"\n  },\n  \"Scope\": \"local\"\n}\n```\n\n**Status codes**:\n\n*   **201** - no error\n*   **500** - server error\n\n**JSON parameters**:\n\n*   **Name** - The new volume's name. If not specified, Docker generates a name.\n*   **Driver** - Name of the volume driver to use. Defaults to `local` for the name.\n*   **DriverOpts** - A mapping of driver options and values. These options are passed directly to the driver and are driver specific.\n*   **Labels** - Labels to set on the volume, specified as a map: `{\"key\":\"value\",\"key2\":\"value2\"}`\n\n**JSON fields in response**:\n\nRefer to the [inspect a volume](#inspect-a-volume) section or details about the JSON fields returned in the response.\n\n#### [Inspect a volume](#inspect-a-volume)\n\n`GET /volumes/(name)`\n\nReturn low-level information on the volume `name`\n\n**Example request**:\n\n```\nGET /v1.24/volumes/tardis\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n{\n  \"Name\": \"tardis\",\n  \"Driver\": \"custom\",\n  \"Mountpoint\": \"/var/lib/docker/volumes/tardis/_data\",\n  \"Status\": {\n    \"hello\": \"world\"\n  },\n  \"Labels\": {\n      \"com.example.some-label\": \"some-value\",\n      \"com.example.some-other-label\": \"some-other-value\"\n  },\n  \"Scope\": \"local\"\n}\n```\n\n**Status codes**:\n\n*   **200** - no error\n*   **404** - no such volume\n*   **500** - server error\n\n**JSON fields in response**:\n\nThe following fields can be returned in the API response. Empty fields, or fields that are not supported by the volume's driver may be omitted in the response.\n\n*   **Name** - Name of the volume.\n*   **Driver** - Name of the volume driver used by the volume.\n*   **Mountpoint** - Mount path of the volume on the host.\n*   **Status** - Low-level details about the volume, provided by the volume driver. Details are returned as a map with key/value pairs: `{\"key\":\"value\",\"key2\":\"value2\"}`. The `Status` field is optional, and is omitted if the volume driver does not support this feature.\n*   **Labels** - Labels set on the volume, specified as a map: `{\"key\":\"value\",\"key2\":\"value2\"}`.\n*   **Scope** - Scope describes the level at which the volume exists, can be one of `global` for cluster-wide or `local` for machine level. The default is `local`.\n\n#### [Remove a volume](#remove-a-volume)\n\n`DELETE /volumes/(name)`\n\nInstruct the driver to remove the volume (`name`).\n\n**Example request**:\n\n```\nDELETE /v1.24/volumes/tardis HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 204 No Content\n```\n\n**Status codes**:\n\n*   **204** - no error\n*   **404** - no such volume or volume driver\n*   **409** - volume is in use and cannot be removed\n*   **500** - server error\n\n### [3.5 Networks](#35-networks)\n\n#### [List networks](#list-networks)\n\n`GET /networks`\n\n**Example request**:\n\n```\nGET /v1.24/networks?filters={\"type\":{\"custom\":true}} HTTP/1.1\n```\n\n**Example response**:\n\n**Query parameters**:\n\n*   **filters** - JSON encoded network list filter. The filter value is one of:\n    *   `driver=<driver-name>` Matches a network's driver.\n    *   `id=<network-id>` Matches all or part of a network id.\n    *   `label=<key>` or `label=<key>=<value>` of a network label.\n    *   `name=<network-name>` Matches all or part of a network name.\n    *   `type=[\"custom\"|\"builtin\"]` Filters networks by type. The `custom` keyword returns all user-defined networks.\n\n**Status codes**:\n\n*   **200** - no error\n*   **500** - server error\n\n#### [Inspect network](#inspect-network)\n\n`GET /networks/(id or name)`\n\nReturn low-level information on the network `id`\n\n**Example request**:\n\n```\nGET /v1.24/networks/7d86d31b1478e7cca9ebed7e73aa0fdeec46c5ca29497431d3007d2d9e15ed99 HTTP/1.1\n```\n\n**Example response**:\n\n**Status codes**:\n\n*   **200** - no error\n*   **404** - network not found\n*   **500** - server error\n\n#### [Create a network](#create-a-network)\n\n`POST /networks/create`\n\nCreate a network\n\n**Example request**:\n\n**Example response**:\n\n**Status codes**:\n\n*   **201** - no error\n*   **403** - operation not supported for pre-defined networks\n*   **404** - plugin not found\n*   **500** - server error\n\n**JSON parameters**:\n\n*   **Name** - The new network's name. this is a mandatory field\n*   **CheckDuplicate** - Requests daemon to check for networks with same name. Defaults to `false`. Since Network is primarily keyed based on a random ID and not on the name, and network name is strictly a user-friendly alias to the network which is uniquely identified using ID, there is no guaranteed way to check for duplicates. This parameter CheckDuplicate is there to provide a best effort checking of any networks which has the same name but it is not guaranteed to catch all name collisions.\n*   **Driver** - Name of the network driver plugin to use. Defaults to `bridge` driver\n*   **Internal** - Restrict external access to the network\n*   **IPAM** - Optional custom IP scheme for the network\n    *   **Driver** - Name of the IPAM driver to use. Defaults to `default` driver\n    *   **Config** - List of IPAM configuration options, specified as a map: `{\"Subnet\": <CIDR>, \"IPRange\": <CIDR>, \"Gateway\": <IP address>, \"AuxAddress\": <device_name:IP address>}`\n    *   **Options** - Driver-specific options, specified as a map: `{\"option\":\"value\" [,\"option2\":\"value2\"]}`\n*   **EnableIPv6** - Enable IPv6 on the network\n*   **Options** - Network specific options to be used by the drivers\n*   **Labels** - Labels to set on the network, specified as a map: `{\"key\":\"value\" [,\"key2\":\"value2\"]}`\n\n#### [Connect a container to a network](#connect-a-container-to-a-network)\n\n`POST /networks/(id or name)/connect`\n\nConnect a container to a network\n\n**Example request**:\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\n```\n\n**Status codes**:\n\n*   **200** - no error\n*   **403** - operation not supported for swarm scoped networks\n*   **404** - network or container is not found\n*   **500** - Internal Server Error\n\n**JSON parameters**:\n\n*   **container** - container-id/name to be connected to the network\n\n#### [Disconnect a container from a network](#disconnect-a-container-from-a-network)\n\n`POST /networks/(id or name)/disconnect`\n\nDisconnect a container from a network\n\n**Example request**:\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\n```\n\n**Status codes**:\n\n*   **200** - no error\n*   **403** - operation not supported for swarm scoped networks\n*   **404** - network or container not found\n*   **500** - Internal Server Error\n\n**JSON parameters**:\n\n*   **Container** - container-id/name to be disconnected from a network\n*   **Force** - Force the container to disconnect from a network\n\n#### [Remove a network](#remove-a-network)\n\n`DELETE /networks/(id or name)`\n\nInstruct the driver to remove the network (`id`).\n\n**Example request**:\n\n```\nDELETE /v1.24/networks/22be93d5babb089c5aab8dbc369042fad48ff791584ca2da2100db837a1c7c30 HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 204 No Content\n```\n\n**Status codes**:\n\n*   **204** - no error\n*   **403** - operation not supported for pre-defined networks\n*   **404** - no such network\n*   **500** - server error\n\n### [3.6 Plugins (experimental)](#36-plugins-experimental)\n\n#### [List plugins](#list-plugins)\n\n`GET /plugins`\n\nReturns information about installed plugins.\n\n**Example request**:\n\n```\nGET /v1.24/plugins HTTP/1.1\n```\n\n**Example response**:\n\n**Status codes**:\n\n*   **200** - no error\n*   **500** - server error\n\n#### [Install a plugin](#install-a-plugin)\n\n`POST /plugins/pull?name=<plugin name>`\n\nPulls and installs a plugin. After the plugin is installed, it can be enabled using the [`POST /plugins/(plugin name)/enable` endpoint](#enable-a-plugin).\n\n**Example request**:\n\nThe `:latest` tag is optional, and is used as default if omitted. When using this endpoint to pull a plugin from the registry, the `X-Registry-Auth` header can be used to include a base64-encoded AuthConfig object. Refer to the [create an image](#create-an-image) section for more details.\n\n**Example response**:\n\n**Query parameters**:\n\n*   **name** - Name of the plugin to pull. The name may include a tag or digest. This parameter is required.\n\n**Status codes**:\n\n*   **200** - no error\n*   **500** - error parsing reference / not a valid repository/tag: repository name must have at least one component\n*   **500** - plugin already exists\n\n#### [Inspect a plugin](#inspect-a-plugin)\n\n`GET /plugins/(plugin name)`\n\nReturns detailed information about an installed plugin.\n\n**Example request**:\n\nThe `:latest` tag is optional, and is used as default if omitted.\n\n**Example response**:\n\n**Status codes**:\n\n*   **200** - no error\n*   **404** - plugin not installed\n\n#### [Enable a plugin](#enable-a-plugin)\n\n`POST /plugins/(plugin name)/enable`\n\nEnables a plugin\n\n**Example request**:\n\nThe `:latest` tag is optional, and is used as default if omitted.\n\n**Example response**:\n\n**Status codes**:\n\n*   **200** - no error\n*   **404** - plugin not installed\n*   **500** - plugin is already enabled\n\n#### [Disable a plugin](#disable-a-plugin)\n\n`POST /plugins/(plugin name)/disable`\n\nDisables a plugin\n\n**Example request**:\n\nThe `:latest` tag is optional, and is used as default if omitted.\n\n**Example response**:\n\n**Status codes**:\n\n*   **200** - no error\n*   **404** - plugin not installed\n*   **500** - plugin is already disabled\n\n#### [Remove a plugin](#remove-a-plugin)\n\n`DELETE /plugins/(plugin name)`\n\nRemoves a plugin\n\n**Example request**:\n\nThe `:latest` tag is optional, and is used as default if omitted.\n\n**Example response**:\n\n**Status codes**:\n\n*   **200** - no error\n*   **404** - plugin not installed\n*   **500** - plugin is active\n\n### [3.7 Nodes](#37-nodes)\n\n**Note**: Node operations require the engine to be part of a swarm.\n\n#### [List nodes](#list-nodes)\n\n`GET /nodes`\n\nList nodes\n\n**Example request**:\n\n```\nGET /v1.24/nodes HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n[\n  {\n    \"ID\": \"24ifsmvkjbyhk\",\n    \"Version\": {\n      \"Index\": 8\n    },\n    \"CreatedAt\": \"2016-06-07T20:31:11.853781916Z\",\n    \"UpdatedAt\": \"2016-06-07T20:31:11.999868824Z\",\n    \"Spec\": {\n      \"Name\": \"my-node\",\n      \"Role\": \"manager\",\n      \"Availability\": \"active\"\n      \"Labels\": {\n          \"foo\": \"bar\"\n      }\n    },\n    \"Description\": {\n      \"Hostname\": \"bf3067039e47\",\n      \"Platform\": {\n        \"Architecture\": \"x86_64\",\n        \"OS\": \"linux\"\n      },\n      \"Resources\": {\n        \"NanoCPUs\": 4000000000,\n        \"MemoryBytes\": 8272408576\n      },\n      \"Engine\": {\n        \"EngineVersion\": \"1.12.0\",\n        \"Labels\": {\n            \"foo\": \"bar\",\n        }\n        \"Plugins\": [\n          {\n            \"Type\": \"Volume\",\n            \"Name\": \"local\"\n          },\n          {\n            \"Type\": \"Network\",\n            \"Name\": \"bridge\"\n          }\n          {\n            \"Type\": \"Network\",\n            \"Name\": \"null\"\n          }\n          {\n            \"Type\": \"Network\",\n            \"Name\": \"overlay\"\n          }\n        ]\n      }\n    },\n    \"Status\": {\n      \"State\": \"ready\"\n    },\n    \"ManagerStatus\": {\n      \"Leader\": true,\n      \"Reachability\": \"reachable\",\n      \"Addr\": \"172.17.0.2:2377\"\"\n    }\n  }\n]\n```\n\n**Query parameters**:\n\n*   **filters** â€“ a JSON encoded value of the filters (a `map[string][]string`) to process on the nodes list. Available filters:\n    *   `id=<node id>`\n    *   `label=<engine label>`\n    *   `membership=`(`accepted`|`pending`)\\`\n    *   `name=<node name>`\n    *   `role=`(`manager`|`worker`)\\`\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **406** - node is not part of a swarm\n*   **500** â€“ server error\n\n#### [Inspect a node](#inspect-a-node)\n\n`GET /nodes/(id or name)`\n\nReturn low-level information on the node `id`\n\n**Example request**:\n\n```\n  GET /v1.24/nodes/24ifsmvkjbyhk HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n{\n  \"ID\": \"24ifsmvkjbyhk\",\n  \"Version\": {\n    \"Index\": 8\n  },\n  \"CreatedAt\": \"2016-06-07T20:31:11.853781916Z\",\n  \"UpdatedAt\": \"2016-06-07T20:31:11.999868824Z\",\n  \"Spec\": {\n    \"Name\": \"my-node\",\n    \"Role\": \"manager\",\n    \"Availability\": \"active\"\n    \"Labels\": {\n        \"foo\": \"bar\"\n    }\n  },\n  \"Description\": {\n    \"Hostname\": \"bf3067039e47\",\n    \"Platform\": {\n      \"Architecture\": \"x86_64\",\n      \"OS\": \"linux\"\n    },\n    \"Resources\": {\n      \"NanoCPUs\": 4000000000,\n      \"MemoryBytes\": 8272408576\n    },\n    \"Engine\": {\n      \"EngineVersion\": \"1.12.0\",\n      \"Labels\": {\n          \"foo\": \"bar\",\n      }\n      \"Plugins\": [\n        {\n          \"Type\": \"Volume\",\n          \"Name\": \"local\"\n        },\n        {\n          \"Type\": \"Network\",\n          \"Name\": \"bridge\"\n        }\n        {\n          \"Type\": \"Network\",\n          \"Name\": \"null\"\n        }\n        {\n          \"Type\": \"Network\",\n          \"Name\": \"overlay\"\n        }\n      ]\n    }\n  },\n  \"Status\": {\n    \"State\": \"ready\"\n  },\n  \"ManagerStatus\": {\n    \"Leader\": true,\n    \"Reachability\": \"reachable\",\n    \"Addr\": \"172.17.0.2:2377\"\"\n  }\n}\n```\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such node\n*   **406** â€“ node is not part of a swarm\n*   **500** â€“ server error\n\n#### [Remove a node](#remove-a-node)\n\n`DELETE /nodes/(id or name)`\n\nRemove a node from the swarm.\n\n**Example request**:\n\n```\nDELETE /v1.24/nodes/24ifsmvkjbyhk HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Length: 0\nContent-Type: text/plain; charset=utf-8\n```\n\n**Query parameters**:\n\n*   **force** - 1/True/true or 0/False/false, Force remove a node from the swarm. Default `false`.\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such node\n*   **406** â€“ node is not part of a swarm\n*   **500** â€“ server error\n\n#### [Update a node](#update-a-node)\n\n`POST /nodes/(id)/update`\n\nUpdate a node.\n\nThe payload of the `POST` request is the new `NodeSpec` and overrides the current `NodeSpec` for the specified node.\n\nIf `Availability` or `Role` are omitted, this returns an error. Any other field omitted resets the current value to either an empty value or the default cluster-wide value.\n\n**Example Request**\n\n```\nPOST /v1.24/nodes/24ifsmvkjbyhk/update?version=8 HTTP/1.1\nContent-Type: application/json\nContent-Length: 12345\n\n{\n  \"Availability\": \"active\",\n  \"Name\": \"node-name\",\n  \"Role\": \"manager\",\n  \"Labels\": {\n    \"foo\": \"bar\"\n  }\n}\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Length: 0\nContent-Type: text/plain; charset=utf-8\n```\n\n**Query parameters**:\n\n*   **version** â€“ The version number of the node object being updated. This is required to avoid conflicting writes.\n\nJSON Parameters:\n\n*   **Annotations** â€“ Optional medata to associate with the node.\n    *   **Name** â€“ User-defined name for the node.\n    *   **Labels** â€“ A map of labels to associate with the node (e.g., `{\"key\":\"value\", \"key2\":\"value2\"}`).\n*   **Role** - Role of the node (worker|manager).\n*   **Availability** - Availability of the node (active|pause|drain).\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such node\n*   **406** â€“ node is not part of a swarm\n*   **500** â€“ server error\n\n### [3.8 Swarm](#38-swarm)\n\n#### [Inspect swarm](#inspect-swarm)\n\n`GET /swarm`\n\nInspect swarm\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n{\n  \"CreatedAt\" : \"2016-08-15T16:00:20.349727406Z\",\n  \"Spec\" : {\n    \"Dispatcher\" : {\n      \"HeartbeatPeriod\" : 5000000000\n    },\n    \"Orchestration\" : {\n     \"TaskHistoryRetentionLimit\" : 10\n    },\n    \"CAConfig\" : {\n      \"NodeCertExpiry\" : 7776000000000000\n    },\n    \"Raft\" : {\n      \"LogEntriesForSlowFollowers\" : 500,\n      \"HeartbeatTick\" : 1,\n      \"SnapshotInterval\" : 10000,\n      \"ElectionTick\" : 3\n    },\n    \"TaskDefaults\" : {},\n    \"Name\" : \"default\"\n  },\n \"JoinTokens\" : {\n    \"Worker\" : \"SWMTKN-1-1h8aps2yszaiqmz2l3oc5392pgk8e49qhx2aj3nyv0ui0hez2a-6qmn92w6bu3jdvnglku58u11a\",\n    \"Manager\" : \"SWMTKN-1-1h8aps2yszaiqmz2l3oc5392pgk8e49qhx2aj3nyv0ui0hez2a-8llk83c4wm9lwioey2s316r9l\"\n },\n \"ID\" : \"70ilmkj2f6sp2137c753w2nmt\",\n \"UpdatedAt\" : \"2016-08-15T16:32:09.623207604Z\",\n \"Version\" : {\n   \"Index\" : 51\n}\n```\n\n}\n\n**Status codes**:\n\n*   **200** - no error\n*   **406** â€“ node is not part of a swarm\n*   **500** - sever error\n\n#### [Initialize a new swarm](#initialize-a-new-swarm)\n\n`POST /swarm/init`\n\nInitialize a new swarm. The body of the HTTP response includes the node ID.\n\n**Example request**:\n\n```\nPOST /v1.24/swarm/init HTTP/1.1\nContent-Type: application/json\nContent-Length: 12345\n\n{\n  \"ListenAddr\": \"0.0.0.0:2377\",\n  \"AdvertiseAddr\": \"192.168.1.1:2377\",\n  \"ForceNewCluster\": false,\n  \"Spec\": {\n    \"Orchestration\": {},\n    \"Raft\": {},\n    \"Dispatcher\": {},\n    \"CAConfig\": {}\n  }\n}\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Length: 28\nContent-Type: application/json\nDate: Thu, 01 Sep 2016 21:49:13 GMT\nServer: Docker/1.12.0 (linux)\n\n\"7v2t30z9blmxuhnyo6s4cpenp\"\n```\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **400** â€“ bad parameter\n*   **406** â€“ node is already part of a swarm\n*   **500** - server error\n\nJSON Parameters:\n\n*   **ListenAddr** â€“ Listen address used for inter-manager communication, as well as determining the networking interface used for the VXLAN Tunnel Endpoint (VTEP). This can either be an address/port combination in the form `192.168.1.1:4567`, or an interface followed by a port number, like `eth0:4567`. If the port number is omitted, the default swarm listening port is used.\n*   **AdvertiseAddr** â€“ Externally reachable address advertised to other nodes. This can either be an address/port combination in the form `192.168.1.1:4567`, or an interface followed by a port number, like `eth0:4567`. If the port number is omitted, the port number from the listen address is used. If `AdvertiseAddr` is not specified, it will be automatically detected when possible.\n*   **ForceNewCluster** â€“ Force creation of a new swarm.\n*   **Spec** â€“ Configuration settings for the new swarm.\n    *   **Orchestration** â€“ Configuration settings for the orchestration aspects of the swarm.\n        *   **TaskHistoryRetentionLimit** â€“ Maximum number of tasks history stored.\n    *   **Raft** â€“ Raft related configuration.\n        *   **SnapshotInterval** â€“ Number of logs entries between snapshot.\n        *   **KeepOldSnapshots** â€“ Number of snapshots to keep beyond the current snapshot.\n        *   **LogEntriesForSlowFollowers** â€“ Number of log entries to keep around to sync up slow followers after a snapshot is created.\n        *   **HeartbeatTick** â€“ Amount of ticks (in seconds) between each heartbeat.\n        *   **ElectionTick** â€“ Amount of ticks (in seconds) needed without a leader to trigger a new election.\n    *   **Dispatcher** â€“ Configuration settings for the task dispatcher.\n        *   **HeartbeatPeriod** â€“ The delay for an agent to send a heartbeat to the dispatcher.\n    *   **CAConfig** â€“ Certificate authority configuration.\n        *   **NodeCertExpiry** â€“ Automatic expiry for nodes certificates.\n        *   **ExternalCA** - Configuration for forwarding signing requests to an external certificate authority.\n            *   **Protocol** - Protocol for communication with the external CA (currently only \"cfssl\" is supported).\n            *   **URL** - URL where certificate signing requests should be sent.\n            *   **Options** - An object with key/value pairs that are interpreted as protocol-specific options for the external CA driver.\n\n#### [Join an existing swarm](#join-an-existing-swarm)\n\n`POST /swarm/join`\n\nJoin an existing swarm\n\n**Example request**:\n\n```\nPOST /v1.24/swarm/join HTTP/1.1\nContent-Type: application/json\n\n{\n  \"ListenAddr\": \"0.0.0.0:2377\",\n  \"AdvertiseAddr\": \"192.168.1.1:2377\",\n  \"RemoteAddrs\": [\"node1:2377\"],\n  \"JoinToken\": \"SWMTKN-1-3pu6hszjas19xyp7ghgosyx9k8atbfcr8p2is99znpy26u2lkl-7p73s1dx5in4tatdymyhg9hu2\"\n}\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Length: 0\nContent-Type: text/plain; charset=utf-8\n```\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **400** â€“ bad parameter\n*   **406** â€“ node is already part of a swarm\n*   **500** - server error\n\nJSON Parameters:\n\n*   **ListenAddr** â€“ Listen address used for inter-manager communication if the node gets promoted to manager, as well as determining the networking interface used for the VXLAN Tunnel Endpoint (VTEP).\n*   **AdvertiseAddr** â€“ Externally reachable address advertised to other nodes. This can either be an address/port combination in the form `192.168.1.1:4567`, or an interface followed by a port number, like `eth0:4567`. If the port number is omitted, the port number from the listen address is used. If `AdvertiseAddr` is not specified, it will be automatically detected when possible.\n*   **RemoteAddr** â€“ Address of any manager node already participating in the swarm.\n*   **JoinToken** â€“ Secret token for joining this swarm.\n\n#### [Leave a swarm](#leave-a-swarm)\n\n`POST /swarm/leave`\n\nLeave a swarm\n\n**Example request**:\n\n```\nPOST /v1.24/swarm/leave HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Length: 0\nContent-Type: text/plain; charset=utf-8\n```\n\n**Query parameters**:\n\n*   **force** - Boolean (0/1, false/true). Force leave swarm, even if this is the last manager or that it will break the cluster.\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **406** â€“ node is not part of a swarm\n*   **500** - server error\n\n#### [Update a swarm](#update-a-swarm)\n\n`POST /swarm/update`\n\nUpdate a swarm\n\n**Example request**:\n\n```\nPOST /v1.24/swarm/update HTTP/1.1\nContent-Length: 12345\n\n{\n  \"Name\": \"default\",\n  \"Orchestration\": {\n    \"TaskHistoryRetentionLimit\": 10\n  },\n  \"Raft\": {\n    \"SnapshotInterval\": 10000,\n    \"LogEntriesForSlowFollowers\": 500,\n    \"HeartbeatTick\": 1,\n    \"ElectionTick\": 3\n  },\n  \"Dispatcher\": {\n    \"HeartbeatPeriod\": 5000000000\n  },\n  \"CAConfig\": {\n    \"NodeCertExpiry\": 7776000000000000\n  },\n  \"JoinTokens\": {\n    \"Worker\": \"SWMTKN-1-3pu6hszjas19xyp7ghgosyx9k8atbfcr8p2is99znpy26u2lkl-1awxwuwd3z9j1z3puu7rcgdbx\",\n    \"Manager\": \"SWMTKN-1-3pu6hszjas19xyp7ghgosyx9k8atbfcr8p2is99znpy26u2lkl-7p73s1dx5in4tatdymyhg9hu2\"\n  }\n}\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Length: 0\nContent-Type: text/plain; charset=utf-8\n```\n\n**Query parameters**:\n\n*   **version** â€“ The version number of the swarm object being updated. This is required to avoid conflicting writes.\n*   **rotateWorkerToken** - Set to `true` (or `1`) to rotate the worker join token.\n*   **rotateManagerToken** - Set to `true` (or `1`) to rotate the manager join token.\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **400** â€“ bad parameter\n*   **406** â€“ node is not part of a swarm\n*   **500** - server error\n\nJSON Parameters:\n\n*   **Orchestration** â€“ Configuration settings for the orchestration aspects of the swarm.\n    *   **TaskHistoryRetentionLimit** â€“ Maximum number of tasks history stored.\n*   **Raft** â€“ Raft related configuration.\n    *   **SnapshotInterval** â€“ Number of logs entries between snapshot.\n    *   **KeepOldSnapshots** â€“ Number of snapshots to keep beyond the current snapshot.\n    *   **LogEntriesForSlowFollowers** â€“ Number of log entries to keep around to sync up slow followers after a snapshot is created.\n    *   **HeartbeatTick** â€“ Amount of ticks (in seconds) between each heartbeat.\n    *   **ElectionTick** â€“ Amount of ticks (in seconds) needed without a leader to trigger a new election.\n*   **Dispatcher** â€“ Configuration settings for the task dispatcher.\n    *   **HeartbeatPeriod** â€“ The delay for an agent to send a heartbeat to the dispatcher.\n*   **CAConfig** â€“ CA configuration.\n    *   **NodeCertExpiry** â€“ Automatic expiry for nodes certificates.\n    *   **ExternalCA** - Configuration for forwarding signing requests to an external certificate authority.\n        *   **Protocol** - Protocol for communication with the external CA (currently only \"cfssl\" is supported).\n        *   **URL** - URL where certificate signing requests should be sent.\n        *   **Options** - An object with key/value pairs that are interpreted as protocol-specific options for the external CA driver.\n*   **JoinTokens** - Tokens that can be used by other nodes to join the swarm.\n    *   **Worker** - Token to use for joining as a worker.\n    *   **Manager** - Token to use for joining as a manager.\n\n### [3.9 Services](#39-services)\n\n**Note**: Service operations require to first be part of a swarm.\n\n#### [List services](#list-services)\n\n`GET /services`\n\nList services\n\n**Example request**:\n\n```\nGET /v1.24/services HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n[\n  {\n    \"ID\": \"9mnpnzenvg8p8tdbtq4wvbkcz\",\n    \"Version\": {\n      \"Index\": 19\n    },\n    \"CreatedAt\": \"2016-06-07T21:05:51.880065305Z\",\n    \"UpdatedAt\": \"2016-06-07T21:07:29.962229872Z\",\n    \"Spec\": {\n      \"Name\": \"hopeful_cori\",\n      \"TaskTemplate\": {\n        \"ContainerSpec\": {\n          \"Image\": \"redis\"\n        },\n        \"Resources\": {\n          \"Limits\": {},\n          \"Reservations\": {}\n        },\n        \"RestartPolicy\": {\n          \"Condition\": \"any\",\n          \"MaxAttempts\": 0\n        },\n        \"Placement\": {\n          \"Constraints\": [\n            \"node.role == worker\"\n          ]\n        }\n      },\n      \"Mode\": {\n        \"Replicated\": {\n          \"Replicas\": 1\n        }\n      },\n      \"UpdateConfig\": {\n        \"Parallelism\": 1,\n        \"FailureAction\": \"pause\"\n      },\n      \"EndpointSpec\": {\n        \"Mode\": \"vip\",\n        \"Ports\": [\n          {\n            \"Protocol\": \"tcp\",\n            \"TargetPort\": 6379,\n            \"PublishedPort\": 30001\n          }\n        ]\n      }\n    },\n    \"Endpoint\": {\n      \"Spec\": {\n        \"Mode\": \"vip\",\n        \"Ports\": [\n          {\n            \"Protocol\": \"tcp\",\n            \"TargetPort\": 6379,\n            \"PublishedPort\": 30001\n          }\n        ]\n      },\n      \"Ports\": [\n        {\n          \"Protocol\": \"tcp\",\n          \"TargetPort\": 6379,\n          \"PublishedPort\": 30001\n        }\n      ],\n      \"VirtualIPs\": [\n        {\n          \"NetworkID\": \"4qvuz4ko70xaltuqbt8956gd1\",\n          \"Addr\": \"10.255.0.2/16\"\n        },\n        {\n          \"NetworkID\": \"4qvuz4ko70xaltuqbt8956gd1\",\n          \"Addr\": \"10.255.0.3/16\"\n        }\n      ]\n    }\n  }\n]\n```\n\n**Query parameters**:\n\n*   **filters** â€“ a JSON encoded value of the filters (a `map[string][]string`) to process on the services list. Available filters:\n    *   `id=<service id>`\n    *   `label=<service label>`\n    *   `name=<service name>`\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **406** â€“ node is not part of a swarm\n*   **500** â€“ server error\n\n#### [Create a service](#create-a-service)\n\n`POST /services/create`\n\nCreate a service. When using this endpoint to create a service using a private repository from the registry, the `X-Registry-Auth` header must be used to include a base64-encoded AuthConfig object. Refer to the [create an image](#create-an-image) section for more details.\n\n**Example request**:\n\n```\nPOST /v1.24/services/create HTTP/1.1\nContent-Type: application/json\nContent-Length: 12345\n\n{\n  \"Name\": \"web\",\n  \"TaskTemplate\": {\n    \"ContainerSpec\": {\n      \"Image\": \"nginx:alpine\",\n      \"Mounts\": [\n        {\n          \"ReadOnly\": true,\n          \"Source\": \"web-data\",\n          \"Target\": \"/usr/share/nginx/html\",\n          \"Type\": \"volume\",\n          \"VolumeOptions\": {\n            \"DriverConfig\": {\n            },\n            \"Labels\": {\n              \"com.example.something\": \"something-value\"\n            }\n          }\n        }\n      ],\n      \"User\": \"33\"\n    },\n    \"Networks\": [\n        {\n          \"Target\": \"overlay1\"\n        }\n    ],\n    \"LogDriver\": {\n      \"Name\": \"json-file\",\n      \"Options\": {\n        \"max-file\": \"3\",\n        \"max-size\": \"10M\"\n      }\n    },\n    \"Placement\": {\n      \"Constraints\": [\n        \"node.role == worker\"\n      ]\n    },\n    \"Resources\": {\n      \"Limits\": {\n        \"MemoryBytes\": 104857600\n      },\n      \"Reservations\": {\n      }\n    },\n    \"RestartPolicy\": {\n      \"Condition\": \"on-failure\",\n      \"Delay\": 10000000000,\n      \"MaxAttempts\": 10\n    }\n  },\n  \"Mode\": {\n    \"Replicated\": {\n      \"Replicas\": 4\n    }\n  },\n  \"UpdateConfig\": {\n    \"Delay\": 30000000000,\n    \"Parallelism\": 2,\n    \"FailureAction\": \"pause\"\n  },\n  \"EndpointSpec\": {\n    \"Ports\": [\n      {\n        \"Protocol\": \"tcp\",\n        \"PublishedPort\": 8080,\n        \"TargetPort\": 80\n      }\n    ]\n  },\n  \"Labels\": {\n    \"foo\": \"bar\"\n  }\n}\n```\n\n**Example response**:\n\n```\nHTTP/1.1 201 Created\nContent-Type: application/json\n\n{\n  \"ID\":\"ak7w3gjqoa3kuz8xcpnyy0pvl\"\n}\n```\n\n**Status codes**:\n\n*   **201** â€“ no error\n*   **403** - network is not eligible for services\n*   **406** â€“ node is not part of a swarm\n*   **409** â€“ name conflicts with an existing object\n*   **500** - server error\n\n**JSON Parameters**:\n\n*   **Name** â€“ User-defined name for the service.\n*   **Labels** â€“ A map of labels to associate with the service (e.g., `{\"key\":\"value\", \"key2\":\"value2\"}`).\n*   **TaskTemplate** â€“ Specification of the tasks to start as part of the new service.\n    *   **ContainerSpec** - Container settings for containers started as part of this task.\n        *   **Image** â€“ A string specifying the image name to use for the container.\n        *   **Command** â€“ The command to be run in the image.\n        *   **Args** â€“ Arguments to the command.\n        *   **Env** â€“ A list of environment variables in the form of `[\"VAR=value\"[,\"VAR2=value2\"]]`.\n        *   **Dir** â€“ A string specifying the working directory for commands to run in.\n        *   **User** â€“ A string value specifying the user inside the container.\n        *   **Labels** â€“ A map of labels to associate with the service (e.g., `{\"key\":\"value\", \"key2\":\"value2\"}`).\n        *   **Mounts** â€“ Specification for mounts to be added to containers created as part of the service.\n            *   **Target** â€“ Container path.\n            *   **Source** â€“ Mount source (e.g. a volume name, a host path).\n            *   **Type** â€“ The mount type (`bind`, or `volume`).\n            *   **ReadOnly** â€“ A boolean indicating whether the mount should be read-only.\n            *   **BindOptions** - Optional configuration for the `bind` type.\n                *   **Propagation** â€“ A propagation mode with the value `[r]private`, `[r]shared`, or `[r]slave`.\n            *   **VolumeOptions** â€“ Optional configuration for the `volume` type.\n                *   **NoCopy** â€“ A boolean indicating if volume should be populated with the data from the target. (Default false)\n                *   **Labels** â€“ User-defined name and labels for the volume.\n                *   **DriverConfig** â€“ Map of driver-specific options.\n                    *   **Name** - Name of the driver to use to create the volume.\n                    *   **Options** - key/value map of driver specific options.\n        *   **StopGracePeriod** â€“ Amount of time to wait for the container to terminate before forcefully killing it.\n    *   **LogDriver** - Log configuration for containers created as part of the service.\n        *   **Name** - Name of the logging driver to use (`json-file`, `syslog`, `journald`, `gelf`, `fluentd`, `awslogs`, `splunk`, `etwlogs`, `none`).\n        *   **Options** - Driver-specific options.\n    *   **Resources** â€“ Resource requirements which apply to each individual container created as part of the service.\n        *   **Limits** â€“ Define resources limits.\n            *   **NanoCPUs** â€“ CPU limit in units of 10\\-9 CPU shares.\n            *   **MemoryBytes** â€“ Memory limit in Bytes.\n        *   **Reservation** â€“ Define resources reservation.\n            *   **NanoCPUs** â€“ CPU reservation in units of 10\\-9 CPU shares.\n            *   **MemoryBytes** â€“ Memory reservation in Bytes.\n    *   **RestartPolicy** â€“ Specification for the restart policy which applies to containers created as part of this service.\n        *   **Condition** â€“ Condition for restart (`none`, `on-failure`, or `any`).\n        *   **Delay** â€“ Delay between restart attempts.\n        *   **MaxAttempts** â€“ Maximum attempts to restart a given container before giving up (default value is 0, which is ignored).\n        *   **Window** â€“ Windows is the time window used to evaluate the restart policy (default value is 0, which is unbounded).\n    *   **Placement** â€“ Restrictions on where a service can run.\n        *   **Constraints** â€“ An array of constraints, e.g. `[ \"node.role == manager\" ]`.\n*   **Mode** â€“ Scheduling mode for the service (`replicated` or `global`, defaults to `replicated`).\n*   **UpdateConfig** â€“ Specification for the update strategy of the service.\n    *   **Parallelism** â€“ Maximum number of tasks to be updated in one iteration (0 means unlimited parallelism).\n    *   **Delay** â€“ Amount of time between updates.\n    *   **FailureAction** - Action to take if an updated task fails to run, or stops running during the update. Values are `continue` and `pause`.\n*   **Networks** â€“ Array of network names or IDs to attach the service to.\n*   **EndpointSpec** â€“ Properties that can be configured to access and load balance a service.\n    *   **Mode** â€“ The mode of resolution to use for internal load balancing between tasks (`vip` or `dnsrr`). Defaults to `vip` if not provided.\n    *   **Ports** â€“ List of exposed ports that this service is accessible on from the outside, in the form of: `{\"Protocol\": <\"tcp\"|\"udp\">, \"PublishedPort\": <port>, \"TargetPort\": <port>}`. Ports can only be provided if `vip` resolution mode is used.\n\n**Request Headers**:\n\n*   **Content-type** â€“ Set to `\"application/json\"`.\n*   **X-Registry-Auth** â€“ base64-encoded AuthConfig object, containing either login information, or a token. Refer to the [create an image](#create-an-image) section for more details.\n\n#### [Remove a service](#remove-a-service)\n\n`DELETE /services/(id or name)`\n\nStop and remove the service `id`\n\n**Example request**:\n\n```\nDELETE /v1.24/services/16253994b7c4 HTTP/1.1\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Length: 0\nContent-Type: text/plain; charset=utf-8\n```\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such service\n*   **406** - node is not part of a swarm\n*   **500** â€“ server error\n\n#### [Inspect one or more services](#inspect-one-or-more-services)\n\n`GET /services/(id or name)`\n\nReturn information on the service `id`.\n\n**Example request**:\n\n```\nGET /v1.24/services/1cb4dnqcyx6m66g2t538x3rxha HTTP/1.1\n```\n\n**Example response**:\n\n```\n{\n  \"ID\": \"ak7w3gjqoa3kuz8xcpnyy0pvl\",\n  \"Version\": {\n    \"Index\": 95\n  },\n  \"CreatedAt\": \"2016-06-07T21:10:20.269723157Z\",\n  \"UpdatedAt\": \"2016-06-07T21:10:20.276301259Z\",\n  \"Spec\": {\n    \"Name\": \"redis\",\n    \"TaskTemplate\": {\n      \"ContainerSpec\": {\n        \"Image\": \"redis\"\n      },\n      \"Resources\": {\n        \"Limits\": {},\n        \"Reservations\": {}\n      },\n      \"RestartPolicy\": {\n        \"Condition\": \"any\",\n        \"MaxAttempts\": 0\n      },\n      \"Placement\": {}\n    },\n    \"Mode\": {\n      \"Replicated\": {\n        \"Replicas\": 1\n      }\n    },\n    \"UpdateConfig\": {\n      \"Parallelism\": 1,\n      \"FailureAction\": \"pause\"\n    },\n    \"EndpointSpec\": {\n      \"Mode\": \"vip\",\n      \"Ports\": [\n        {\n          \"Protocol\": \"tcp\",\n          \"TargetPort\": 6379,\n          \"PublishedPort\": 30001\n        }\n      ]\n    }\n  },\n  \"Endpoint\": {\n    \"Spec\": {\n      \"Mode\": \"vip\",\n      \"Ports\": [\n        {\n          \"Protocol\": \"tcp\",\n          \"TargetPort\": 6379,\n          \"PublishedPort\": 30001\n        }\n      ]\n    },\n    \"Ports\": [\n      {\n        \"Protocol\": \"tcp\",\n        \"TargetPort\": 6379,\n        \"PublishedPort\": 30001\n      }\n    ],\n    \"VirtualIPs\": [\n      {\n        \"NetworkID\": \"4qvuz4ko70xaltuqbt8956gd1\",\n        \"Addr\": \"10.255.0.4/16\"\n      }\n    ]\n  }\n}\n```\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such service\n*   **406** - node is not part of a swarm\n*   **500** â€“ server error\n\n#### [Update a service](#update-a-service)\n\n`POST /services/(id)/update`\n\nUpdate a service. When using this endpoint to create a service using a private repository from the registry, the `X-Registry-Auth` header can be used to update the authentication information for that is stored for the service. The header contains a base64-encoded AuthConfig object. Refer to the [create an image](#create-an-image) section for more details.\n\n**Example request**:\n\n```\nPOST /v1.24/services/1cb4dnqcyx6m66g2t538x3rxha/update?version=23 HTTP/1.1\nContent-Type: application/json\nContent-Length: 12345\n\n{\n  \"Name\": \"top\",\n  \"TaskTemplate\": {\n    \"ContainerSpec\": {\n      \"Image\": \"busybox\",\n      \"Args\": [\n        \"top\"\n      ]\n    },\n    \"Resources\": {\n      \"Limits\": {},\n      \"Reservations\": {}\n    },\n    \"RestartPolicy\": {\n      \"Condition\": \"any\",\n      \"MaxAttempts\": 0\n    },\n    \"Placement\": {}\n  },\n  \"Mode\": {\n    \"Replicated\": {\n      \"Replicas\": 1\n    }\n  },\n  \"UpdateConfig\": {\n    \"Parallelism\": 1\n  },\n  \"EndpointSpec\": {\n    \"Mode\": \"vip\"\n  }\n}\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\nContent-Length: 0\nContent-Type: text/plain; charset=utf-8\n```\n\n**JSON Parameters**:\n\n*   **Name** â€“ User-defined name for the service. Note that renaming services is not supported.\n*   **Labels** â€“ A map of labels to associate with the service (e.g., `{\"key\":\"value\", \"key2\":\"value2\"}`).\n*   **TaskTemplate** â€“ Specification of the tasks to start as part of the new service.\n    *   **ContainerSpec** - Container settings for containers started as part of this task.\n        *   **Image** â€“ A string specifying the image name to use for the container.\n        *   **Command** â€“ The command to be run in the image.\n        *   **Args** â€“ Arguments to the command.\n        *   **Env** â€“ A list of environment variables in the form of `[\"VAR=value\"[,\"VAR2=value2\"]]`.\n        *   **Dir** â€“ A string specifying the working directory for commands to run in.\n        *   **User** â€“ A string value specifying the user inside the container.\n        *   **Labels** â€“ A map of labels to associate with the service (e.g., `{\"key\":\"value\", \"key2\":\"value2\"}`).\n        *   **Mounts** â€“ Specification for mounts to be added to containers created as part of the new service.\n            *   **Target** â€“ Container path.\n            *   **Source** â€“ Mount source (e.g. a volume name, a host path).\n            *   **Type** â€“ The mount type (`bind`, or `volume`).\n            *   **ReadOnly** â€“ A boolean indicating whether the mount should be read-only.\n            *   **BindOptions** - Optional configuration for the `bind` type\n                *   **Propagation** â€“ A propagation mode with the value `[r]private`, `[r]shared`, or `[r]slave`.\n            *   **VolumeOptions** â€“ Optional configuration for the `volume` type.\n                *   **NoCopy** â€“ A boolean indicating if volume should be populated with the data from the target. (Default false)\n                *   **Labels** â€“ User-defined name and labels for the volume.\n                *   **DriverConfig** â€“ Map of driver-specific options.\n                    *   **Name** - Name of the driver to use to create the volume\n                    *   **Options** - key/value map of driver specific options\n        *   **StopGracePeriod** â€“ Amount of time to wait for the container to terminate before forcefully killing it.\n    *   **Resources** â€“ Resource requirements which apply to each individual container created as part of the service.\n        *   **Limits** â€“ Define resources limits.\n            *   **CPU** â€“ CPU limit\n            *   **Memory** â€“ Memory limit\n        *   **Reservation** â€“ Define resources reservation.\n            *   **CPU** â€“ CPU reservation\n            *   **Memory** â€“ Memory reservation\n    *   **RestartPolicy** â€“ Specification for the restart policy which applies to containers created as part of this service.\n        *   **Condition** â€“ Condition for restart (`none`, `on-failure`, or `any`).\n        *   **Delay** â€“ Delay between restart attempts.\n        *   **MaxAttempts** â€“ Maximum attempts to restart a given container before giving up (default value is 0, which is ignored).\n        *   **Window** â€“ Windows is the time window used to evaluate the restart policy (default value is 0, which is unbounded).\n    *   **Placement** â€“ Restrictions on where a service can run.\n        *   **Constraints** â€“ An array of constraints, e.g. `[ \"node.role == manager\" ]`.\n*   **Mode** â€“ Scheduling mode for the service (`replicated` or `global`, defaults to `replicated`).\n*   **UpdateConfig** â€“ Specification for the update strategy of the service.\n    *   **Parallelism** â€“ Maximum number of tasks to be updated in one iteration (0 means unlimited parallelism).\n    *   **Delay** â€“ Amount of time between updates.\n*   **Networks** â€“ Array of network names or IDs to attach the service to.\n*   **EndpointSpec** â€“ Properties that can be configured to access and load balance a service.\n    *   **Mode** â€“ The mode of resolution to use for internal load balancing between tasks (`vip` or `dnsrr`). Defaults to `vip` if not provided.\n    *   **Ports** â€“ List of exposed ports that this service is accessible on from the outside, in the form of: `{\"Protocol\": <\"tcp\"|\"udp\">, \"PublishedPort\": <port>, \"TargetPort\": <port>}`. Ports can only be provided if `vip` resolution mode is used.\n\n**Query parameters**:\n\n*   **version** â€“ The version number of the service object being updated. This is required to avoid conflicting writes.\n\n**Request Headers**:\n\n*   **Content-type** â€“ Set to `\"application/json\"`.\n*   **X-Registry-Auth** â€“ base64-encoded AuthConfig object, containing either login information, or a token. Refer to the [create an image](#create-an-image) section for more details.\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ no such service\n*   **406** - node is not part of a swarm\n*   **500** â€“ server error\n\n### [3.10 Tasks](#310-tasks)\n\n**Note**: Task operations require the engine to be part of a swarm.\n\n#### [List tasks](#list-tasks)\n\n`GET /tasks`\n\nList tasks\n\n**Example request**:\n\n```\nGET /v1.24/tasks HTTP/1.1\n```\n\n**Example response**:\n\n```\n[\n  {\n    \"ID\": \"0kzzo1i0y4jz6027t0k7aezc7\",\n    \"Version\": {\n      \"Index\": 71\n    },\n    \"CreatedAt\": \"2016-06-07T21:07:31.171892745Z\",\n    \"UpdatedAt\": \"2016-06-07T21:07:31.376370513Z\",\n    \"Spec\": {\n      \"ContainerSpec\": {\n        \"Image\": \"redis\"\n      },\n      \"Resources\": {\n        \"Limits\": {},\n        \"Reservations\": {}\n      },\n      \"RestartPolicy\": {\n        \"Condition\": \"any\",\n        \"MaxAttempts\": 0\n      },\n      \"Placement\": {}\n    },\n    \"ServiceID\": \"9mnpnzenvg8p8tdbtq4wvbkcz\",\n    \"Slot\": 1,\n    \"NodeID\": \"60gvrl6tm78dmak4yl7srz94v\",\n    \"Status\": {\n      \"Timestamp\": \"2016-06-07T21:07:31.290032978Z\",\n      \"State\": \"running\",\n      \"Message\": \"started\",\n      \"ContainerStatus\": {\n        \"ContainerID\": \"e5d62702a1b48d01c3e02ca1e0212a250801fa8d67caca0b6f35919ebc12f035\",\n        \"PID\": 677\n      }\n    },\n    \"DesiredState\": \"running\",\n    \"NetworksAttachments\": [\n      {\n        \"Network\": {\n          \"ID\": \"4qvuz4ko70xaltuqbt8956gd1\",\n          \"Version\": {\n            \"Index\": 18\n          },\n          \"CreatedAt\": \"2016-06-07T20:31:11.912919752Z\",\n          \"UpdatedAt\": \"2016-06-07T21:07:29.955277358Z\",\n          \"Spec\": {\n            \"Name\": \"ingress\",\n            \"Labels\": {\n              \"com.docker.swarm.internal\": \"true\"\n            },\n            \"DriverConfiguration\": {},\n            \"IPAMOptions\": {\n              \"Driver\": {},\n              \"Configs\": [\n                {\n                  \"Subnet\": \"10.255.0.0/16\",\n                  \"Gateway\": \"10.255.0.1\"\n                }\n              ]\n            }\n          },\n          \"DriverState\": {\n            \"Name\": \"overlay\",\n            \"Options\": {\n              \"com.docker.network.driver.overlay.vxlanid_list\": \"256\"\n            }\n          },\n          \"IPAMOptions\": {\n            \"Driver\": {\n              \"Name\": \"default\"\n            },\n            \"Configs\": [\n              {\n                \"Subnet\": \"10.255.0.0/16\",\n                \"Gateway\": \"10.255.0.1\"\n              }\n            ]\n          }\n        },\n        \"Addresses\": [\n          \"10.255.0.10/16\"\n        ]\n      }\n    ],\n  },\n  {\n    \"ID\": \"1yljwbmlr8er2waf8orvqpwms\",\n    \"Version\": {\n      \"Index\": 30\n    },\n    \"CreatedAt\": \"2016-06-07T21:07:30.019104782Z\",\n    \"UpdatedAt\": \"2016-06-07T21:07:30.231958098Z\",\n    \"Name\": \"hopeful_cori\",\n    \"Spec\": {\n      \"ContainerSpec\": {\n        \"Image\": \"redis\"\n      },\n      \"Resources\": {\n        \"Limits\": {},\n        \"Reservations\": {}\n      },\n      \"RestartPolicy\": {\n        \"Condition\": \"any\",\n        \"MaxAttempts\": 0\n      },\n      \"Placement\": {}\n    },\n    \"ServiceID\": \"9mnpnzenvg8p8tdbtq4wvbkcz\",\n    \"Slot\": 1,\n    \"NodeID\": \"60gvrl6tm78dmak4yl7srz94v\",\n    \"Status\": {\n      \"Timestamp\": \"2016-06-07T21:07:30.202183143Z\",\n      \"State\": \"shutdown\",\n      \"Message\": \"shutdown\",\n      \"ContainerStatus\": {\n        \"ContainerID\": \"1cf8d63d18e79668b0004a4be4c6ee58cddfad2dae29506d8781581d0688a213\"\n      }\n    },\n    \"DesiredState\": \"shutdown\",\n    \"NetworksAttachments\": [\n      {\n        \"Network\": {\n          \"ID\": \"4qvuz4ko70xaltuqbt8956gd1\",\n          \"Version\": {\n            \"Index\": 18\n          },\n          \"CreatedAt\": \"2016-06-07T20:31:11.912919752Z\",\n          \"UpdatedAt\": \"2016-06-07T21:07:29.955277358Z\",\n          \"Spec\": {\n            \"Name\": \"ingress\",\n            \"Labels\": {\n              \"com.docker.swarm.internal\": \"true\"\n            },\n            \"DriverConfiguration\": {},\n            \"IPAMOptions\": {\n              \"Driver\": {},\n              \"Configs\": [\n                {\n                  \"Subnet\": \"10.255.0.0/16\",\n                  \"Gateway\": \"10.255.0.1\"\n                }\n              ]\n            }\n          },\n          \"DriverState\": {\n            \"Name\": \"overlay\",\n            \"Options\": {\n              \"com.docker.network.driver.overlay.vxlanid_list\": \"256\"\n            }\n          },\n          \"IPAMOptions\": {\n            \"Driver\": {\n              \"Name\": \"default\"\n            },\n            \"Configs\": [\n              {\n                \"Subnet\": \"10.255.0.0/16\",\n                \"Gateway\": \"10.255.0.1\"\n              }\n            ]\n          }\n        },\n        \"Addresses\": [\n          \"10.255.0.5/16\"\n        ]\n      }\n    ]\n  }\n]\n```\n\n**Query parameters**:\n\n*   **filters** â€“ a JSON encoded value of the filters (a `map[string][]string`) to process on the services list. Available filters:\n    *   `id=<task id>`\n    *   `name=<task name>`\n    *   `service=<service name>`\n    *   `node=<node id or name>`\n    *   `label=key` or `label=\"key=value\"`\n    *   `desired-state=(running | shutdown | accepted)`\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **406** - node is not part of a swarm\n*   **500** â€“ server error\n\n#### [Inspect a task](#inspect-a-task)\n\n`GET /tasks/(id)`\n\nGet details on the task `id`\n\n**Example request**:\n\n```\nGET /v1.24/tasks/0kzzo1i0y4jz6027t0k7aezc7 HTTP/1.1\n```\n\n**Example response**:\n\n```\n{\n  \"ID\": \"0kzzo1i0y4jz6027t0k7aezc7\",\n  \"Version\": {\n    \"Index\": 71\n  },\n  \"CreatedAt\": \"2016-06-07T21:07:31.171892745Z\",\n  \"UpdatedAt\": \"2016-06-07T21:07:31.376370513Z\",\n  \"Spec\": {\n    \"ContainerSpec\": {\n      \"Image\": \"redis\"\n    },\n    \"Resources\": {\n      \"Limits\": {},\n      \"Reservations\": {}\n    },\n    \"RestartPolicy\": {\n      \"Condition\": \"any\",\n      \"MaxAttempts\": 0\n    },\n    \"Placement\": {}\n  },\n  \"ServiceID\": \"9mnpnzenvg8p8tdbtq4wvbkcz\",\n  \"Slot\": 1,\n  \"NodeID\": \"60gvrl6tm78dmak4yl7srz94v\",\n  \"Status\": {\n    \"Timestamp\": \"2016-06-07T21:07:31.290032978Z\",\n    \"State\": \"running\",\n    \"Message\": \"started\",\n    \"ContainerStatus\": {\n      \"ContainerID\": \"e5d62702a1b48d01c3e02ca1e0212a250801fa8d67caca0b6f35919ebc12f035\",\n      \"PID\": 677\n    }\n  },\n  \"DesiredState\": \"running\",\n  \"NetworksAttachments\": [\n    {\n      \"Network\": {\n        \"ID\": \"4qvuz4ko70xaltuqbt8956gd1\",\n        \"Version\": {\n          \"Index\": 18\n        },\n        \"CreatedAt\": \"2016-06-07T20:31:11.912919752Z\",\n        \"UpdatedAt\": \"2016-06-07T21:07:29.955277358Z\",\n        \"Spec\": {\n          \"Name\": \"ingress\",\n          \"Labels\": {\n            \"com.docker.swarm.internal\": \"true\"\n          },\n          \"DriverConfiguration\": {},\n          \"IPAMOptions\": {\n            \"Driver\": {},\n            \"Configs\": [\n              {\n                \"Subnet\": \"10.255.0.0/16\",\n                \"Gateway\": \"10.255.0.1\"\n              }\n            ]\n          }\n        },\n        \"DriverState\": {\n          \"Name\": \"overlay\",\n          \"Options\": {\n            \"com.docker.network.driver.overlay.vxlanid_list\": \"256\"\n          }\n        },\n        \"IPAMOptions\": {\n          \"Driver\": {\n            \"Name\": \"default\"\n          },\n          \"Configs\": [\n            {\n              \"Subnet\": \"10.255.0.0/16\",\n              \"Gateway\": \"10.255.0.1\"\n            }\n          ]\n        }\n      },\n      \"Addresses\": [\n        \"10.255.0.10/16\"\n      ]\n    }\n  ]\n}\n```\n\n**Status codes**:\n\n*   **200** â€“ no error\n*   **404** â€“ unknown task\n*   **406** - node is not part of a swarm\n*   **500** â€“ server error\n\n### [4.1 Inside `docker run`](#41-inside-docker-run)\n\nAs an example, the `docker run` command line makes the following API calls:\n\n*   Create the container\n    \n*   If the status code is 404, it means the image doesn't exist:\n    \n    *   Try to pull it.\n    *   Then, retry to create the container.\n*   Start the container.\n    \n*   If you are not in detached mode:\n    \n*   Attach to the container, using `logs=1` (to have `stdout` and `stderr` from the container's start) and `stream=1`\n    \n*   If in detached mode or only `stdin` is attached, display the container's id.\n    \n\n### [4.2 Hijacking](#42-hijacking)\n\nIn this version of the API, `/attach`, uses hijacking to transport `stdin`, `stdout`, and `stderr` on the same socket.\n\nTo hint potential proxies about connection hijacking, Docker client sends connection upgrade headers similarly to websocket.\n\n```\nUpgrade: tcp\nConnection: Upgrade\n```\n\nWhen Docker daemon detects the `Upgrade` header, it switches its status code from **200 OK** to **101 UPGRADED** and resends the same headers.\n\n### [4.3 CORS Requests](#43-cors-requests)\n\nTo set cross origin requests to the Engine API please give values to `--api-cors-header` when running Docker in daemon mode. Set \\* (asterisk) allows all, default or blank means CORS disabled\n\n```\n$ dockerd -H=\"192.168.1.9:2375\" --api-cors-header=\"http://foo.bar\"\n```",
  "title": "Engine API v1.24 | Docker Docs\n",
  "description": "API Documentation for Docker",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/guide/multi-stage/",
  "markdown": "# Multi-stage | Docker Docs\n\nThis section explores multi-stage builds. There are two main reasons for why youâ€™d want to use multi-stage builds:\n\n*   They allow you to run build steps in parallel, making your build pipeline faster and more efficient.\n*   They allow you to create a final image with a smaller footprint, containing only what's needed to run your program.\n\nIn a Dockerfile, a build stage is represented by a `FROM` instruction. The Dockerfile from the previous section doesnâ€™t leverage multi-stage builds. Itâ€™s all one build stage. That means that the final image is bloated with resources used to compile the program.\n\nThe program compiles to executable binaries, so you donâ€™t need Go language utilities to exist in the final image.\n\nUsing multi-stage builds, you can choose to use different base images for your build and runtime environments. You can copy build artifacts from the build stage over to the runtime stage.\n\nModify the Dockerfile as follows. This change creates another stage using a minimal `scratch` image as a base. In the final `scratch` stage, the binaries built in the previous stage are copied over to the filesystem of the new stage.\n\nNow if you build the image and inspect it, you should see a significantly smaller number:\n\nThe image went from 150MB to only just 8.45MB in size. Thatâ€™s because the resulting image only contains the binaries, and nothing else.\n\nYou've reduced the footprint of the image. The following step shows how you can improve build speed with multi-stage builds, using parallelism. The build currently produces the binaries one after the other. There is no reason why you need to build the client before building the server, or vice versa.\n\nYou can split the binary-building steps into separate stages. In the final `scratch` stage, copy the binaries from each corresponding build stage. By segmenting these builds into separate stages, Docker can run them in parallel.\n\nThe stages for building each binary both require the Go compilation tools and application dependencies. Define these common steps as a reusable base stage. You can do that by assigning a name to the stage using the pattern `FROM image AS stage_name`. This allows you to reference the stage name in a `FROM` instruction of another stage (`FROM stage_name`).\n\nYou can also assign a name to the binary-building stages, and reference the stage name in the `COPY --from=stage_name` instruction when copying the binaries to the final `scratch` image.\n\nNow, instead of first building the binaries one after the other, the `build-client` and `build-server` stages are executed simultaneously.\n\n![Stages executing in parallel](https://docs.docker.com/build/guide/images/parallelism.gif)\n\nThe final image is now small, and youâ€™re building it efficiently using parallelism. But this image is slightly strange, in that it contains both the client and the server binary in the same image. Shouldnâ€™t these be two different images?\n\nItâ€™s possible to create multiple different images using a single Dockerfile. You can specify a target stage of a build using the `--target` flag. Replace the unnamed `FROM scratch` stage with two separate stages named `client` and `server`.\n\nAnd now you can build the client and server programs as separate Docker images (tags):\n\nThe images are now even smaller, about 4 MB each.\n\nThis change also avoids having to build both binaries each time. When selecting to build the `client` target, Docker only builds the stages leading up to that target. The `build-server` and `server` stages are skipped if theyâ€™re not needed. Likewise, building the `server` target skips the `build-client` and `client` stages.\n\nMulti-stage builds are useful for creating images with less bloat and a smaller footprint, and also helps to make builds run faster.\n\nRelated information:\n\n*   [Multi-stage builds](https://docs.docker.com/build/building/multi-stage/)\n*   [Base images](https://docs.docker.com/build/building/base-images/)\n\nThe next section describes how you can use file mounts to further improve build speeds.",
  "title": "Multi-stage | Docker Docs\n",
  "description": "Faster and smaller builds with multi-stage builds",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/guide/export/",
  "markdown": "# Export binaries | Docker Docs\n\nDid you know that you can use Docker to build your application to standalone binaries? Sometimes, you donâ€™t want to package and distribute your application as a Docker image. Use Docker to build your application, and use exporters to save the output to disk.\n\nThe default output format for `docker build` is a container image. That image is automatically loaded to your local image store, where you can run a container from that image, or push it to a registry. Under the hood, this uses the default exporter, called the `docker` exporter.\n\nTo export your build results as files instead, you can use the `local` exporter. The `local` exporter saves the filesystem of the build container to the specified directory on the host machine.\n\nTo use the `local` exporter, pass the `--output` option to the `docker build` command. The `--output` flag takes one argument: the destination on the host machine where you want to save the files.\n\nThe following commands exports the files from of the `server` target to the current working directory on the host filesystem:\n\nRunning this command creates a binary at `./bin/server`. Itâ€™s created under the `bin/` directory because thatâ€™s where the file was located inside the build container.\n\nIf you want to create a build that exports both binaries, you can create another build stage in the Dockerfile that copies both of the binaries from each build stage:\n\nNow you can build the `binaries` target using the `--output` option to export both the client and server binaries.\n\nThis section has demonstrated how you can use Docker to build and export standalone binaries. These binaries can be distributed freely, and donâ€™t require a container runtime like the Docker daemon.\n\nThe binaries you've generated so far are Linux binaries. That's because the build environment is Linux. If your host OS is Linux, you can run these files. Building binaries that work on Mac or Windows machines requires cross-compilation. This is explored later on in this guide.\n\nRelated information:\n\n*   [`docker build --output` CLI reference](https://docs.docker.com/reference/cli/docker/image/build/#output)\n*   [Build exporters](https://docs.docker.com/build/exporters/)\n\nThe next topic of this guide is testing: how you can use Docker to run application tests.",
  "title": "Export binaries | Docker Docs\n",
  "description": "Using Docker builds to create and export executable binaries",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/guide/multi-platform/",
  "markdown": "# Multi-platform | Docker Docs\n\nUp until this point in the guide, you've built Linux binaries. This section describes how you can support other operating systems, and architectures, using multi-platform builds via emulation and cross-compilation.\n\nThe easiest way to get started with building for multiple platforms is using emulation. With emulation, you can build your app to multiple architectures without having to make any changes to your Dockerfile. All you need to do is to pass the `--platform` flag to the build command, specifying the OS and architecture you want to build for.\n\nThe following command builds the server image for the `linux/arm/v7` platform:\n\nYou can also use emulation to produce outputs for multiple platforms at once. However, the default image store in Docker Engine doesn't support building and loading multi-platform images. You need to enable the containerd image store which supports concurrent multi-platform builds.\n\n* * *\n\nTo enable the containerd image store in Docker Desktop, go to **Settings** and select **Use containerd for pulling and storing images** in the **General** tab.\n\nNote that changing the image store means you'll temporarily lose access to images and containers in the classic image store. Those resources still exist, but to view them, you'll need to disable the containerd image store.\n\nIf you're not using Docker Desktop, enable the containerd image store by adding the following feature configuration to your `/etc/docker/daemon.json` configuration file.\n\nRestart the daemon after updating the configuration file.\n\n* * *\n\nTo run multi-platform builds, invoke the `docker build` command, and pass it the same arguments as you did before. Only this time, also add a `--platform` flag specifying multiple architectures.\n\nThis command uses emulation to run the same build three times, once for each platform. The build results are exported to a `bin` directory.\n\nWhen you build for multiple platforms concurrently, BuildKit runs all of the build steps under emulation for each platform that you specify. Effectively forking the build into multiple concurrent processes.\n\n![Build pipelines using emulation](https://docs.docker.com/build/guide/images/emulation.png)\n\nThere are, however, a few downsides to running multi-platform builds using emulation:\n\n*   If you tried running the command above, you may have noticed that it took a long time to finish. Emulation can be much slower than native execution for CPU-intensive tasks.\n*   Emulation only works when the architecture is supported by the base image youâ€™re using. The example in this guide uses the Alpine Linux version of the `golang` image, which means you can only build Linux images this way, for a limited set of CPU architectures, without having to change the base image.\n\nAs an alternative to emulation, the next step explores cross-compilation. Cross-compiling makes multi-platform builds much faster and versatile.\n\nUsing cross-compilation means leveraging the capabilities of a compiler to build for multiple platforms, without the need for emulation.\n\nThe first thing you'll need to do is pinning the builder to use the nodeâ€™s native architecture as the build platform. This is to prevent emulation. Then, from the node's native architecture, the builder cross-compiles the application to a number of other target platforms.\n\n### [Platform build arguments](#platform-build-arguments)\n\nThis approach involves using a few pre-defined build arguments that you have access to in your Docker builds: `BUILDPLATFORM` and `TARGETPLATFORM` (and derivatives, like `TARGETOS`). These build arguments reflect the values you pass to the `--platform` flag.\n\nFor example, if you invoke a build with `--platform=linux/amd64`, then the build arguments resolve to:\n\n*   `TARGETPLATFORM=linux/amd64`\n*   `TARGETOS=linux`\n*   `TARGETARCH=amd64`\n\nWhen you pass more than one value to the platform flag, build stages that use the pre-defined platform arguments are forked automatically for each platform. This is in contrast to builds running under emulation, where the entire build pipeline runs per platform.\n\n![Build pipelines using cross-compilation](https://docs.docker.com/build/guide/images/cross-compilation.png)\n\n### [Update the Dockerfile](#update-the-dockerfile)\n\nTo build the app using the cross-compilation technique, update the Dockerfile as follows:\n\n*   Add `--platform=$BUILDPLATFORM` to the `FROM` instruction for the initial `base` stage, pinning the platform of the `golang` image to match the architecture of the host machine.\n*   Add `ARG` instructions for the Go compilation stages, making the `TARGETOS` and `TARGETARCH` build arguments available to the commands in this stage.\n*   Set the `GOOS` and `GOARCH` environment variables to the values of `TARGETOS` and `TARGETARCH`. The Go compiler uses these variables to do cross-compilation.\n\nThe only thing left to do now is to run the actual build. To run a multi-platform build, set the `--platform` option, and specify a CSV string of the OS and architectures that you want to build for. The following command illustrates how to build, and export, binaries for Mac (ARM64), Windows, and Linux:\n\nWhen the build finishes, youâ€™ll find client and server binaries for all of the selected platforms in the `bin` directory:\n\nThis section has demonstrated how you can get started with multi-platform builds using emulation and cross-compilation.\n\nRelated information:\n\n*   [Multi-platfom images](https://docs.docker.com/build/building/multi-platform/)\n*   [containerd image store (Docker Desktop)](https://docs.docker.com/desktop/containerd/)\n*   [containerd image store (Docker Engine)](https://docs.docker.com/storage/containerd/)\n\nYou may also want to consider checking out [xx - Dockerfile cross-compilation helpers](https://github.com/tonistiigi/xx). `xx` is a Docker image containing utility scripts that make cross-compiling with Docker builds easier.\n\nThis section is the final part of the Build with Docker guide. The following page contains some pointers for where to go next.",
  "title": "Multi-platform | Docker Docs\n",
  "description": "Building for multiple operating systems and architectures",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/guide/test/",
  "markdown": "# Test | Docker Docs\n\nThis section focuses on testing. The example in this section focuses on linting, but the same principles apply for other kinds of tests as well, such as unit tests. Code linting is a static analysis of code that helps you detect errors, style violations, and anti-patterns.\n\nThe exact steps for how to test your code can vary a lot depending on the programming language or framework that you use. The example application used in this guide is written in Go. You will add a build step that uses `golangci-lint`, a popular linters runner for Go.\n\nThe `golangci-lint` tool is available as an image on Docker Hub. Before you add the lint step to the Dockerfile, you can try it out using a `docker run` command.\n\nYou will notice that `golangci-lint` works: it finds an issue in the code where there's a missing error check.\n\nNow you can add this as a step to the Dockerfile.\n\nThe added `lint` stage uses the `golangci/golangci-lint` image from Docker Hub to invoke the `golangci-lint run` command with a bind-mount for the build context.\n\nThe lint stage is independent of any of the other stages in the Dockerfile. Therefore, running a regular build wonâ€™t cause the lint step to run. To lint the code, you must specify the `lint` stage:\n\nIn addition to running tests, it's sometimes useful to be able to export the results of a test to a test report.\n\nExporting test results is no different to exporting binaries, as shown in the previous section of this guide:\n\n1.  Save the test results to a file.\n2.  Create a new stage in your Dockerfile using the `scratch` base image.\n3.  Export that stage using the `local` exporter.\n\nThe exact steps on how to do this is left as a reader's exercise :-)\n\nThis section has shown an example on how you can use Docker builds to run tests (or as shown in this section, linters).\n\nThe next topic in this guide is multi-platform builds, using emulation and cross-compilation.",
  "title": "Test | Docker Docs\n",
  "description": "Running tests with Docker Build",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/build/guide/next-steps/",
  "markdown": "# Next steps | Docker Docs\n\nThis guide has demonstrated some of the build features and capabilities that Docker provides.\n\nIf you would like to continue learning about Docker build, consider exploring the following resources:\n\n*   [BuildKit](https://docs.docker.com/build/buildkit/): deep-dive into the open source build engine that powers your Docker builds\n*   [Drivers](https://docs.docker.com/build/drivers/): configure for how and where your Docker builds run\n*   [Exporters](https://docs.docker.com/build/exporters/): save your build results to different output formats\n*   [Bake](https://docs.docker.com/build/bake/): orchestrate your build workflows\n*   [Attestations](https://docs.docker.com/build/attestations/): annotate your build artifacts with metadata\n*   [Continuous integration](https://docs.docker.com/build/ci/): run Docker builds in CI\n\nIf you have suggestions for improving the content of this guide, you can use the feedback widget to submit your feedback.\n\nIf you don't see the feedback widget, try turning off your content filtering extension or ad blocker, if you use one.\n\nYou can also submit an issue on [the docs GitHub repository](https://github.com/docker/docs/issues/new), if you prefer.",
  "title": "Next steps | Docker Docs\n",
  "description": "Next steps following the Docker Build guide",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/reference/commandline/dockerd/",
  "markdown": "# dockerd | Docker Docs\n\nOptions with \\[\\] may be specified multiple times.\n\n`dockerd` is the persistent process that manages containers. Docker uses different binaries for the daemon and client. To run the daemon you type `dockerd`.\n\nTo run the daemon with debug output, use `dockerd --debug` or add `\"debug\": true` to [the `daemon.json` file](#daemon-configuration-file).\n\n> **Enabling experimental features**\n> \n> Enable experimental features by starting `dockerd` with the `--experimental` flag or adding `\"experimental\": true` to the `daemon.json` file.\n\n### [Environment variables](#environment-variables)\n\nThe following list of environment variables are supported by the `dockerd` daemon. Some of these environment variables are supported both by the Docker Daemon and the `docker` CLI. Refer to [Environment variables](https://docs.docker.com/engine/reference/commandline/cli/#environment-variables) in the CLI section to learn about environment variables supported by the `docker` CLI.\n\n| Variable | Description |\n| --- | --- |\n| `DOCKER_CERT_PATH` | Location of your authentication keys. This variable is used both by the [`docker` CLI](https://docs.docker.com/engine/reference/commandline/cli/) and the `dockerd` daemon. |\n| `DOCKER_DRIVER` | The storage driver to use. |\n| `DOCKER_RAMDISK` | If set this disables `pivot_root`. |\n| `DOCKER_TLS_VERIFY` | When set Docker uses TLS and verifies the remote. This variable is used both by the [`docker` CLI](https://docs.docker.com/engine/reference/commandline/cli/) and the `dockerd` daemon. |\n| `DOCKER_TMPDIR` | Location for temporary files created by the daemon. |\n| `HTTP_PROXY` | Proxy URL for HTTP requests unless overridden by NoProxy. See the [Go specification](https://pkg.go.dev/golang.org/x/net/http/httpproxy#Config) for details. |\n| `HTTPS_PROXY` | Proxy URL for HTTPS requests unless overridden by NoProxy. See the [Go specification](https://pkg.go.dev/golang.org/x/net/http/httpproxy#Config) for details. |\n| `MOBY_DISABLE_PIGZ` | Disables the use of [`unpigz`](https://linux.die.net/man/1/pigz) to decompress layers in parallel when pulling images, even if it is installed. |\n| `NO_PROXY` | Comma-separated values specifying hosts that should be excluded from proxying. See the [Go specification](https://pkg.go.dev/golang.org/x/net/http/httpproxy#Config) for details. |\n\n### [Proxy configuration](#proxy-configuration)\n\n> **Note**\n> \n> Refer to the [Docker Desktop manual](https://docs.docker.com/desktop/networking/#httphttps-proxy-support) if you are running [Docker Desktop](https://docs.docker.com/desktop/).\n\nIf you are behind an HTTP proxy server, for example in corporate settings, you may have to configure the Docker daemon to use the proxy server for operations such as pulling and pushing images. The daemon can be configured in three ways:\n\n1.  Using environment variables (`HTTP_PROXY`, `HTTPS_PROXY`, and `NO_PROXY`).\n2.  Using the `http-proxy`, `https-proxy`, and `no-proxy` fields in the [daemon configuration file](#daemon-configuration-file) (Docker Engine version 23.0 or later).\n3.  Using the `--http-proxy`, `--https-proxy`, and `--no-proxy` command-line options. (Docker Engine version 23.0 or later).\n\nThe command-line and configuration file options take precedence over environment variables. Refer to [control and configure Docker with systemd](https://docs.docker.com/config/daemon/systemd/#httphttps-proxy) to set these environment variables on a host using `systemd`.\n\n### [Daemon socket option](#daemon-socket-option)\n\nThe Docker daemon can listen for [Docker Engine API](https://docs.docker.com/engine/api/) requests via three different types of Socket: `unix`, `tcp`, and `fd`.\n\nBy default, a `unix` domain socket (or IPC socket) is created at `/var/run/docker.sock`, requiring either `root` permission, or `docker` group membership.\n\nIf you need to access the Docker daemon remotely, you need to enable the tcp Socket. When using a TCP socket, the Docker daemon provides un-encrypted and un-authenticated direct access to the Docker daemon by default. You should secure the daemon either using the [built in HTTPS encrypted socket](https://docs.docker.com/engine/security/protect-access/), or by putting a secure web proxy in front of it. You can listen on port `2375` on all network interfaces with `-H tcp://0.0.0.0:2375`, or on a particular network interface using its IP address: `-H tcp://192.168.59.103:2375`. It is conventional to use port `2375` for un-encrypted, and port `2376` for encrypted communication with the daemon.\n\n> **Note**\n> \n> If you're using an HTTPS encrypted socket, keep in mind that only TLS version 1.0 and higher is supported. Protocols SSLv3 and below are not supported for security reasons.\n\nOn systemd based systems, you can communicate with the daemon via [systemd socket activation](https://0pointer.de/blog/projects/socket-activation.html), with `dockerd -H fd://`. Using `fd://` works for most setups, but you can also specify individual sockets: `dockerd -H fd://3`. If the specified socket activated files aren't found, the daemon exits. You can find examples of using systemd socket activation with Docker and systemd in the [Docker source tree](https://github.com/docker/docker/tree/master/contrib/init/systemd/).\n\nYou can configure the Docker daemon to listen to multiple sockets at the same time using multiple `-H` options:\n\nThe example below runs the daemon listening on the default Unix socket, and on 2 specific IP addresses on this host:\n\nThe Docker client honors the `DOCKER_HOST` environment variable to set the `-H` flag for the client. Use **one** of the following commands:\n\nSetting the `DOCKER_TLS_VERIFY` environment variable to any value other than the empty string is equivalent to setting the `--tlsverify` flag. The following are equivalent:\n\nThe Docker client honors the `HTTP_PROXY`, `HTTPS_PROXY`, and `NO_PROXY` environment variables (or the lowercase versions thereof). `HTTPS_PROXY` takes precedence over `HTTP_PROXY`.\n\nThe Docker client supports connecting to a remote daemon via SSH:\n\nTo use SSH connection, you need to set up `ssh` so that it can reach the remote host with public key authentication. Password authentication is not supported. If your key is protected with passphrase, you need to set up `ssh-agent`.\n\n#### [Bind Docker to another host/port or a Unix socket](#bind-docker-to-another-hostport-or-a-unix-socket)\n\n> **Warning**\n> \n> Changing the default `docker` daemon binding to a TCP port or Unix `docker` user group introduces security risks, as it may allow non-root users to gain root access on the host. Make sure you control access to `docker`. If you are binding to a TCP port, anyone with access to that port has full Docker access; so it's not advisable on an open network.\n\nWith `-H` it's possible to make the Docker daemon to listen on a specific IP and port. By default, it listens on `unix:///var/run/docker.sock` to allow only local connections by the root user. You could set it to `0.0.0.0:2375` or a specific host IP to give access to everybody, but that isn't recommended because someone could gain root access to the host where the daemon is running.\n\nSimilarly, the Docker client can use `-H` to connect to a custom port. The Docker client defaults to connecting to `unix:///var/run/docker.sock` on Linux, and `tcp://127.0.0.1:2376` on Windows.\n\n`-H` accepts host and port assignment in the following format:\n\nFor example:\n\n*   `tcp://` -> TCP connection to `127.0.0.1` on either port `2376` when TLS encryption is on, or port `2375` when communication is in plain text.\n*   `tcp://host:2375` -> TCP connection on host:2375\n*   `tcp://host:2375/path` -> TCP connection on host:2375 and prepend path to all requests\n*   `unix://path/to/socket` -> Unix socket located at `path/to/socket`\n\n`-H`, when empty, defaults to the same value as when no `-H` was passed in.\n\n`-H` also accepts short form for TCP bindings: `host:` or `host:port` or `:port`\n\nRun Docker in daemon mode:\n\nDownload an `ubuntu` image:\n\nYou can use multiple `-H`, for example, if you want to listen on both TCP and a Unix socket\n\n### [Daemon storage-driver](#daemon-storage-driver)\n\nOn Linux, the Docker daemon has support for several different image layer storage drivers: `overlay2`, `fuse-overlayfs`, `btrfs`, and `zfs`.\n\n`overlay2` is the preferred storage driver for all currently supported Linux distributions, and is selected by default. Unless users have a strong reason to prefer another storage driver, `overlay2` should be used.\n\nYou can find out more about storage drivers and how to select one in [Select a storage driver](https://docs.docker.com/storage/storagedriver/select-storage-driver/).\n\nOn Windows, the Docker daemon only supports the `windowsfilter` storage driver.\n\n### [Options per storage driver](#options-per-storage-driver)\n\nParticular storage-driver can be configured with options specified with `--storage-opt` flags. Options for `zfs` start with `zfs`, and options for `btrfs` start with `btrfs`.\n\n#### [ZFS options](#zfs-options)\n\n##### [`zfs.fsname`](#zfsfsname)\n\nSpecifies the ZFS filesystem that the daemon should use to create its datasets. By default, the ZFS filesystem in `/var/lib/docker` is used.\n\n###### [Example](#example)\n\n#### [Btrfs options](#btrfs-options)\n\n##### [`btrfs.min_space`](#btrfsmin_space)\n\nSpecifies the minimum size to use when creating the subvolume which is used for containers. If user uses disk quota for btrfs when creating or running a container with **\\--storage-opt size** option, Docker should ensure the **size** can't be smaller than **btrfs.min\\_space**.\n\n###### [Example](#example-1)\n\n#### [Overlay2 options](#overlay2-options)\n\n##### [`overlay2.size`](#overlay2size)\n\nSets the default max size of the container. It is supported only when the backing filesystem is `xfs` and mounted with `pquota` mount option. Under these conditions the user can pass any size less than the backing filesystem size.\n\n###### [Example](#example-2)\n\n#### [Windowsfilter options](#windowsfilter-options)\n\n##### [`size`](#size)\n\nSpecifies the size to use when creating the sandbox which is used for containers. Defaults to 20G.\n\n###### [Example](#example-3)\n\n### [Runtime options](#runtime-options)\n\nThe Docker daemon relies on a [OCI](https://github.com/opencontainers/runtime-spec) compliant runtime (invoked via the `containerd` daemon) as its interface to the Linux kernel `namespaces`, `cgroups`, and `SELinux`.\n\n#### [Configure container runtimes](#configure-container-runtimes)\n\nBy default, the Docker daemon uses runc as a container runtime. You can configure the daemon to add additional runtimes.\n\ncontainerd shims installed on `PATH` can be used directly, without the need to edit the daemon's configuration. For example, if you install the Kata Containers shim (`containerd-shim-kata-v2`) on `PATH`, then you can select that runtime with `docker run` without having to edit the daemon's configuration:\n\nContainer runtimes that don't implement containerd shims, or containerd shims installed outside of `PATH`, must be registered with the daemon, either via the configuration file or using the `--add-runtime` command line flag.\n\nFor examples on how to use other container runtimes, see [Alternative container runtimes](https://docs.docker.com/engine/alternative-runtimes/)\n\n##### [Configure runtimes using `daemon.json`](#configure-runtimes-using-daemonjson)\n\nTo register and configure container runtimes using the daemon's configuration file, add the runtimes as entries under `runtimes`:\n\nThe key of the entry (`<runtime>` in the previous example) represents the name of the runtime. This is the name that you reference when you run a container, using `docker run --runtime <runtime>`.\n\nThe runtime entry contains an object specifying the configuration for your runtime. The properties of the object depends on what kind of runtime you're looking to register:\n\n*   If the runtime implements its own containerd shim, the object shall contain a `runtimeType` field and an optional `options` field.\n    \n    See [Configure shims](#configure-containerd-shims).\n    \n*   If the runtime is designed to be a drop-in replacement for runc, the object contains a `path` field, and an optional `runtimeArgs` field.\n    \n    See [Configure runc drop-in replacements](#configure-runc-drop-in-replacements).\n    \n\nAfter changing the runtimes configuration in the configuration file, you must reload or restart the daemon for changes to take effect:\n\n##### [Configure containerd shims](#configure-containerd-shims)\n\nIf the runtime that you want to register implements a containerd shim, or if you want to register a runtime which uses the runc shim, use the following format for the runtime entry:\n\n`runtimeType` refers to either:\n\n*   A fully qualified name of a containerd shim.\n    \n    The fully qualified name of a shim is the same as the `runtime_type` used to register the runtime in containerd's CRI configuration. For example, `io.containerd.runsc.v1`.\n    \n*   The path of a containerd shim binary.\n    \n    This option is useful if you installed the containerd shim binary outside of `PATH`.\n    \n\n`options` is optional. It lets you specify the runtime configuration that you want to use for the shim. The configuration parameters that you can specify in `options` depends on the runtime you're registering. For most shims, the supported configuration options are `TypeUrl` and `ConfigPath`. For example:\n\nYou can configure multiple runtimes using the same runtimeType. For example:\n\nThe `options` field takes a special set of configuration parameters when used with `\"runtimeType\": \"io.containerd.runc.v2\"`. For more information about runc parameters, refer to the runc configuration section in [CRI Plugin Config Guide](https://github.com/containerd/containerd/blob/v1.7.2/docs/cri/config.md#full-configuration).\n\n##### [Configure runc drop-in replacements](#configure-runc-drop-in-replacements)\n\nIf the runtime that you want to register can act as a drop-in replacement for runc, you can register the runtime either using the daemon configuration file, or using the `--add-runtime` flag for the `dockerd` cli.\n\nWhen you use the configuration file, the entry uses the following format:\n\nWhere `path` is either the absolute path to the runtime executable, or the name of an executable installed on `PATH`:\n\nAnd `runtimeArgs` lets you optionally pass additional arguments to the runtime. Entries with this format use the containerd runc shim to invoke a custom runtime binary.\n\nWhen you use the `--add-runtime` CLI flag, use the following format:\n\nDefining runtime arguments via the command line is not supported.\n\nFor an example configuration for a runc drop-in replacment, see [Alternative container runtimes > youki](https://docs.docker.com/engine/alternative-runtimes/#youki)\n\n##### [Configure the default container runtime](#configure-the-default-container-runtime)\n\nYou can specify either the name of a fully qualified containerd runtime shim, or the name of a registered runtime. You can specify the default runtime either using the daemon configuration file, or using the `--default-runtime` flag for the `dockerd` cli.\n\nWhen you use the configuration file, the entry uses the following format:\n\nWhen you use the `--default-runtime` CLI flag, use the following format:\n\n#### [Run containerd standalone](#run-containerd-standalone)\n\nBy default, the Docker daemon automatically starts `containerd`. If you want to control `containerd` startup, manually start `containerd` and pass the path to the `containerd` socket using the `--containerd` flag. For example:\n\n#### [Configure cgroup driver](#configure-cgroup-driver)\n\nYou can configure how the runtime should manage container cgroups, using the `--exec-opt native.cgroupdriver` CLI flag.\n\nYou can only specify `cgroupfs` or `systemd`. If you specify `systemd` and it is not available, the system errors out. If you omit the `native.cgroupdriver` option, `cgroupfs` is used on cgroup v1 hosts, `systemd` is used on cgroup v2 hosts with systemd available.\n\nThis example sets the `cgroupdriver` to `systemd`:\n\nSetting this option applies to all containers the daemon launches.\n\n#### [Configure container isolation technology (Windows)](#configure-container-isolation-technology-windows)\n\nFor Windows containers, you can specify the default container isolation technology to use, using the `--exec-opt isolation` flag.\n\nThe following example makes `hyperv` the default isolation technology:\n\nIf no isolation value is specified on daemon start, on Windows client, the default is `hyperv`, and on Windows server, the default is `process`.\n\n### [Daemon DNS options](#daemon-dns-options)\n\nTo set the DNS server for all Docker containers, use:\n\nTo set the DNS search domain for all Docker containers, use:\n\n### [Allow push of non-distributable artifacts](#allow-push-of-non-distributable-artifacts)\n\nSome images (e.g., Windows base images) contain artifacts whose distribution is restricted by license. When these images are pushed to a registry, restricted artifacts are not included.\n\nTo override this behavior for specific registries, use the `--allow-nondistributable-artifacts` option in one of the following forms:\n\n*   `--allow-nondistributable-artifacts myregistry:5000` tells the Docker daemon to push non-distributable artifacts to myregistry:5000.\n*   `--allow-nondistributable-artifacts 10.1.0.0/16` tells the Docker daemon to push non-distributable artifacts to all registries whose resolved IP address is within the subnet described by the CIDR syntax.\n\nThis option can be used multiple times.\n\nThis option is useful when pushing images containing non-distributable artifacts to a registry on an air-gapped network so hosts on that network can pull the images without connecting to another server.\n\n> **Warning**\n> \n> Non-distributable artifacts typically have restrictions on how and where they can be distributed and shared. Only use this feature to push artifacts to private registries and ensure that you are in compliance with any terms that cover redistributing non-distributable artifacts.\n\n### [Insecure registries](#insecure-registries)\n\nIn this section, \"registry\" refers to a private registry, and `myregistry:5000` is a placeholder example of a private registry.\n\nDocker considers a private registry either secure or insecure. A secure registry uses TLS and a copy of its CA certificate is placed on the Docker host at `/etc/docker/certs.d/myregistry:5000/ca.crt`. An insecure registry is either not using TLS (i.e., listening on plain text HTTP), or is using TLS with a CA certificate not known by the Docker daemon. The latter can happen when the certificate wasn't found under `/etc/docker/certs.d/myregistry:5000/`, or if the certificate verification failed (i.e., wrong CA).\n\nBy default, Docker assumes all registries to be secure, except for local registries. Communicating with an insecure registry isn't possible if Docker assumes that registry is secure. In order to communicate with an insecure registry, the Docker daemon requires `--insecure-registry` in one of the following two forms:\n\n*   `--insecure-registry myregistry:5000` tells the Docker daemon that myregistry:5000 should be considered insecure.\n*   `--insecure-registry 10.1.0.0/16` tells the Docker daemon that all registries whose domain resolve to an IP address is part of the subnet described by the CIDR syntax, should be considered insecure.\n\nThe flag can be used multiple times to allow multiple registries to be marked as insecure.\n\nIf an insecure registry isn't marked as insecure, `docker pull`, `docker push`, and `docker search` result in error messages, prompting the user to either secure or pass the `--insecure-registry` flag to the Docker daemon as described above.\n\nLocal registries, whose IP address falls in the 127.0.0.0/8 range, are automatically marked as insecure as of Docker 1.3.2. It isn't recommended to rely on this, as it may change in the future.\n\nEnabling `--insecure-registry`, i.e., allowing un-encrypted and/or untrusted communication, can be useful when running a local registry. However, because its use creates security vulnerabilities it should only be enabled for testing purposes. For increased security, users should add their CA to their system's list of trusted CAs instead of enabling `--insecure-registry`.\n\n#### [Legacy Registries](#legacy-registries)\n\nOperations against registries supporting only the legacy v1 protocol are no longer supported. Specifically, the daemon doesn't attempt to push, pull or sign in to v1 registries. The exception to this is `search` which can still be performed on v1 registries.\n\n### [Running a Docker daemon behind an HTTPS\\_PROXY](#running-a-docker-daemon-behind-an-https_proxy)\n\nWhen running inside a LAN that uses an `HTTPS` proxy, the proxy's certificates replace Docker Hub's certificates. These certificates must be added to your Docker host's configuration:\n\n1.  Install the `ca-certificates` package for your distribution\n2.  Ask your network admin for the proxy's CA certificate and append them to `/etc/pki/tls/certs/ca-bundle.crt`\n3.  Then start your Docker daemon with `HTTPS_PROXY=http://username:password@proxy:port/ dockerd`. The `username:` and `password@` are optional - and are only needed if your proxy is set up to require authentication.\n\nThis only adds the proxy and authentication to the Docker daemon's requests. To use the proxy when building images and running containers, see [Configure Docker to use a proxy server](https://docs.docker.com/network/proxy/)\n\n### [Default `ulimit` settings](#default-ulimit-settings)\n\nThe `--default-ulimit` flag lets you set the default `ulimit` options to use for all containers. It takes the same options as `--ulimit` for `docker run`. If these defaults aren't set, `ulimit` settings are inherited from the Docker daemon. Any `--ulimit` options passed to `docker run` override the daemon defaults.\n\nBe careful setting `nproc` with the `ulimit` flag, as `nproc` is designed by Linux to set the maximum number of processes available to a user, not to a container. For details, see [`docker run` reference](https://docs.docker.com/reference/cli/docker/container/run/#ulimit).\n\nDocker's access authorization can be extended by authorization plugins that your organization can purchase or build themselves. You can install one or more authorization plugins when you start the Docker `daemon` using the `--authorization-plugin=PLUGIN_ID` option.\n\nThe `PLUGIN_ID` value is either the plugin's name or a path to its specification file. The plugin's implementation determines whether you can specify a name or path. Consult with your Docker administrator to get information about the plugins available to you.\n\nOnce a plugin is installed, requests made to the `daemon` through the command line or Docker's Engine API are allowed or denied by the plugin. If you have multiple plugins installed, each plugin, in order, must allow the request for it to complete.\n\nFor information about how to create an authorization plugin, refer to the [authorization plugin](https://docs.docker.com/engine/extend/plugins_authorization/) section.\n\n### [Daemon user namespace options](#daemon-user-namespace-options)\n\nThe Linux kernel [user namespace support](https://man7.org/linux/man-pages/man7/user_namespaces.7.html) provides additional security by enabling a process, and therefore a container, to have a unique range of user and group IDs which are outside the traditional user and group range utilized by the host system. One of the most important security improvements is that, by default, container processes running as the `root` user have expected administrative privileges it expects (with some restrictions) inside the container, but are effectively mapped to an unprivileged `uid` on the host.\n\nFor details about how to use this feature, as well as limitations, see [Isolate containers with a user namespace](https://docs.docker.com/engine/security/userns-remap/).\n\n### [Configure host gateway IP](#configure-host-gateway-ip)\n\nThe Docker daemon supports a special `host-gateway` value for the `--add-host` flag for the `docker run` and `docker build` commands. This value resolves to the host's gateway IP and lets containers connect to services running on the host.\n\nBy default, `host-gateway` resolves to the IP address of the default bridge. You can configure this to resolve to a different IP using the `--host-gateway-ip` flag for the dockerd command line interface, or the `host-gateway-ip` key in the daemon configuration file.\n\n### [Enable CDI devices](#enable-cdi-devices)\n\n> **Note**\n> \n> This is experimental feature and as such doesn't represent a stable API.\n> \n> This feature isn't enabled by default. To this feature, set `features.cdi` to `true` in the `daemon.json` configuration file.\n\nContainer Device Interface (CDI) is a [standardized](https://github.com/cncf-tags/container-device-interface/blob/main/SPEC.md) mechanism for container runtimes to create containers which are able to interact with third party devices.\n\nThe Docker daemon supports running containers with CDI devices if the requested device specifications are available on the filesystem of the daemon.\n\nThe default specification directors are:\n\n*   `/etc/cdi/` for static CDI Specs\n*   `/var/run/cdi` for generated CDI Specs\n\nAlternatively, you can set custom locations for CDI specifications using the `cdi-spec-dirs` option in the `daemon.json` configuration file, or the `--cdi-spec-dir` flag for the `dockerd` CLI.\n\nWhen CDI is enabled for a daemon, you can view the configured CDI specification directories using the `docker info` command.\n\n### [Miscellaneous options](#miscellaneous-options)\n\nIP masquerading uses address translation to allow containers without a public IP to talk to other machines on the internet. This may interfere with some network topologies, and can be disabled with `--ip-masq=false`.\n\nDocker supports soft links for the Docker data directory (`/var/lib/docker`) and for `/var/lib/docker/tmp`. The `DOCKER_TMPDIR` and the data directory can be set like this:\n\n#### [Default cgroup parent](#default-cgroup-parent)\n\nThe `--cgroup-parent` option lets you set the default cgroup parent for containers. If this option isn't set, it defaults to `/docker` for the cgroupfs driver, and `system.slice` for the systemd cgroup driver.\n\nIf the cgroup has a leading forward slash (`/`), the cgroup is created under the root cgroup, otherwise the cgroup is created under the daemon cgroup.\n\nAssuming the daemon is running in cgroup `daemoncgroup`, `--cgroup-parent=/foobar` creates a cgroup in `/sys/fs/cgroup/memory/foobar`, whereas using `--cgroup-parent=foobar` creates the cgroup in `/sys/fs/cgroup/memory/daemoncgroup/foobar`\n\nThe systemd cgroup driver has different rules for `--cgroup-parent`. systemd represents hierarchy by slice and the name of the slice encodes the location in the tree. So `--cgroup-parent` for systemd cgroups should be a slice name. A name can consist of a dash-separated series of names, which describes the path to the slice from the root slice. For example, `--cgroup-parent=user-a-b.slice` means the memory cgroup for the container is created in `/sys/fs/cgroup/memory/user.slice/user-a.slice/user-a-b.slice/docker-<id>.scope`.\n\nThis setting can also be set per container, using the `--cgroup-parent` option on `docker create` and `docker run`, and takes precedence over the `--cgroup-parent` option on the daemon.\n\n#### [Daemon metrics](#daemon-metrics)\n\nThe `--metrics-addr` option takes a TCP address to serve the metrics API. This feature is still experimental, therefore, the daemon must be running in experimental mode for this feature to work.\n\nTo serve the metrics API on `localhost:9323` you would specify `--metrics-addr 127.0.0.1:9323`, allowing you to make requests on the API at `127.0.0.1:9323/metrics` to receive metrics in the [prometheus](https://prometheus.io/docs/instrumenting/exposition_formats/) format.\n\nPort `9323` is the [default port associated with Docker metrics](https://github.com/prometheus/prometheus/wiki/Default-port-allocations) to avoid collisions with other Prometheus exporters and services.\n\nIf you are running a Prometheus server you can add this address to your scrape configs to have Prometheus collect metrics on Docker. For more information, see [Collect Docker metrics with Prometheus](https://docs.docker.com/config/daemon/prometheus/).\n\n#### [Node generic resources](#node-generic-resources)\n\nThe `--node-generic-resources` option takes a list of key-value pair (`key=value`) that allows you to advertise user defined resources in a Swarm cluster.\n\nThe current expected use case is to advertise NVIDIA GPUs so that services requesting `NVIDIA-GPU=[0-16]` can land on a node that has enough GPUs for the task to run.\n\nExample of usage:\n\n### [Daemon configuration file](#daemon-configuration-file)\n\nThe `--config-file` option allows you to set any configuration option for the daemon in a JSON format. This file uses the same flag names as keys, except for flags that allow several entries, where it uses the plural of the flag name, e.g., `labels` for the `label` flag.\n\nThe options set in the configuration file must not conflict with options set using flags. The Docker daemon fails to start if an option is duplicated between the file and the flags, regardless of their value. This is intentional, and avoids silently ignore changes introduced in configuration reloads. For example, the daemon fails to start if you set daemon labels in the configuration file and also set daemon labels via the `--label` flag. Options that are not present in the file are ignored when the daemon starts.\n\nThe `--validate` option allows to validate a configuration file without starting the Docker daemon. A non-zero exit code is returned for invalid configuration files.\n\n##### [On Linux](#on-linux)\n\nThe default location of the configuration file on Linux is `/etc/docker/daemon.json`. Use the `--config-file` flag to specify a non-default location.\n\nThe following is a full example of the allowed configuration options on Linux:\n\n> **Note**\n> \n> You can't set options in `daemon.json` that have already been set on daemon startup as a flag. On systems that use systemd to start the Docker daemon, `-H` is already set, so you can't use the `hosts` key in `daemon.json` to add listening addresses. See [custom Docker daemon options](https://docs.docker.com/config/daemon/systemd/#custom-docker-daemon-options) for an example on how to configure the daemon using systemd drop-in files.\n\n##### [On Windows](#on-windows)\n\nThe default location of the configuration file on Windows is `%programdata%\\docker\\config\\daemon.json`. Use the `--config-file` flag to specify a non-default location.\n\nThe following is a full example of the allowed configuration options on Windows:\n\nThe `default-runtime` option is by default unset, in which case dockerd automatically detects the runtime. This detection is based on if the `containerd` flag is set.\n\nAccepted values:\n\n*   `com.docker.hcsshim.v1` - This is the built-in runtime that Docker has used since Windows supported was first added and uses the v1 HCS API's in Windows.\n*   `io.containerd.runhcs.v1` - This is uses the containerd `runhcs` shim to run the container and uses the v2 HCS API's in Windows.\n\n#### [Feature options](#feature-options)\n\nThe optional field `features` in `daemon.json` lets you enable or disable specific daemon features.\n\nThe list of feature options include:\n\n*   `containerd-snapshotter`: when set to `true`, the daemon uses containerd snapshotters instead of the classic storage drivers for storing image and container data. For more information, see [containerd storage](https://docs.docker.com/storage/containerd/).\n    \n*   `windows-dns-proxy`: when set to `true`, the daemon's internal DNS resolver will forward requests to external servers. Without this, most applications running in the container will still be able to use secondary DNS servers configured in the container itself, but `nslookup` won't be able to resolve external names. The current default is `false`, it will change to `true` in a future release. This option is only allowed on Windows.\n    \n    > **Warning** The `windows-dns-proxy` feature flag will be removed in a future release.\n    \n\n#### [Configuration reload behavior](#configuration-reload-behavior)\n\nSome options can be reconfigured when the daemon is running without requiring to restart the process. The daemon uses the `SIGHUP` signal in Linux to reload, and a global event in Windows with the key `Global\\docker-daemon-config-$PID`. You can modify the options in the configuration file, but the daemon still checks for conflicting settings with the specified CLI flags. The daemon fails to reconfigure itself if there are conflicts, but it won't stop execution.\n\nThe list of currently supported options that can be reconfigured is this:\n\n| Option | Description |\n| --- | --- |\n| `debug` | Toggles debug mode of the daemon. |\n| `labels` | Replaces the daemon labels with a new set of labels. |\n| `live-restore` | Toggles [live restore](https://docs.docker.com/config/containers/live-restore/). |\n| `max-concurrent-downloads` | Configures the max concurrent downloads for each pull. |\n| `max-concurrent-uploads` | Configures the max concurrent uploads for each push. |\n| `max-download-attempts` | Configures the max download attempts for each pull. |\n| `default-runtime` | Configures the runtime to be used if not is specified at container creation. |\n| `runtimes` | Configures the list of available OCI runtimes that can be used to run containers. |\n| `authorization-plugin` | Specifies the authorization plugins to use. |\n| `allow-nondistributable-artifacts` | Specifies a list of registries to which the daemon will push non-distributable artifacts. |\n| `insecure-registries` | Specifies a list of registries that the daemon should consider insecure. |\n| `registry-mirrors` | Specifies a list of registry mirrors. |\n| `shutdown-timeout` | Configures the daemon's existing configuration timeout with a new timeout for shutting down all containers. |\n| `features` | Enables or disables specific features. |\n\n### [Run multiple daemons](#run-multiple-daemons)\n\n> **Note**\n> \n> Running multiple daemons on a single host is considered experimental. You may encounter unsolved problems, and things may not work as expected in some cases.\n\nThis section describes how to run multiple Docker daemons on a single host. To run multiple daemons, you must configure each daemon so that it doesn't conflict with other daemons on the same host. You can set these options either by providing them as flags, or by using a [daemon configuration file](#daemon-configuration-file).\n\nThe following daemon options must be configured for each daemon:\n\nWhen your daemons use different values for these flags, you can run them on the same host without any problems. It is important that you understand the meaning of these options and to use them correctly.\n\n*   The `-b, --bridge=` flag is set to `docker0` as default bridge network. It is created automatically when you install Docker. If you aren't using the default, you must create and configure the bridge manually, or set it to 'none': `--bridge=none`\n*   `--exec-root` is the path where the container state is stored. The default value is `/var/run/docker`. Specify the path for your running daemon here.\n*   `--data-root` is the path where persisted data such as images, volumes, and cluster state are stored. The default value is `/var/lib/docker`. To avoid any conflict with other daemons, set this parameter separately for each daemon.\n*   `-p, --pidfile=/var/run/docker.pid` is the path where the process ID of the daemon is stored. Specify the path for your PID file here.\n*   `--host=[]` specifies where the Docker daemon listens for client connections. If unspecified, it defaults to `/var/run/docker.sock`.\n*   `--iptables=false` prevents the Docker daemon from adding iptables rules. If multiple daemons manage iptables rules, they may overwrite rules set by another daemon. Be aware that disabling this option requires you to manually add iptables rules to expose container ports. If you prevent Docker from adding iptables rules, Docker also doesn't add IP masquerading rules, even if you set `--ip-masq` to `true`. Without IP masquerading rules, Docker containers can't connect to external hosts or the internet when using network other than default bridge.\n*   `--config-file=/etc/docker/daemon.json` is the path where configuration file is stored. You can use it instead of daemon flags. Specify the path for each daemon.\n*   `--tls*` Docker daemon supports `--tlsverify` mode that enforces encrypted and authenticated remote connections. The `--tls*` options enable use of specific certificates for individual daemons.\n\nExample script for a separate â€œbootstrapâ€ instance of the Docker daemon without network:\n\n### [Default network options](#default-network-options)\n\nThe `default-network-opts` key in the `daemon.json` configuration file, and the equivalent `--default-network-opt` CLI flag, let you specify default values for driver network driver options for new networks.\n\nThe following example shows how to configure options for the `bridge` driver using the `daemon.json` file.\n\nThis example uses the `bridge` network driver. Refer to the [bridge network driver page](https://docs.docker.com/network/drivers/bridge/#options) for an overview of available driver options.\n\nAfter changing the configuration and restarting the daemon, new networks that you create use these option configurations as defaults.\n\nNote that changing this daemon configuration doesn't affect pre-existing networks.\n\nUsing the `--default-network-opt` CLI flag is useful for testing and debugging purposes, but you should prefer using the `daemon.json` file for persistent daemon configuration. The CLI flag expects a value with the following format: `driver=opt=value`, for example:",
  "title": "dockerd | Docker Docs\n",
  "description": "The daemon command description and usage",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/reference/builder/",
  "markdown": "# Dockerfile reference | Docker Docs\n\nDocker can build images automatically by reading the instructions from a Dockerfile. A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. This page describes the commands you can use in a Dockerfile.\n\nThe Dockerfile supports the following instructions:\n\n| Instruction | Description |\n| --- | --- |\n| [`ADD`](#add) | Add local or remote files and directories. |\n| [`ARG`](#arg) | Use build-time variables. |\n| [`CMD`](#cmd) | Specify default commands. |\n| [`COPY`](#copy) | Copy files and directories. |\n| [`ENTRYPOINT`](#entrypoint) | Specify default executable. |\n| [`ENV`](#env) | Set environment variables. |\n| [`EXPOSE`](#expose) | Describe which ports your application is listening on. |\n| [`FROM`](#from) | Create a new build stage from a base image. |\n| [`HEALTHCHECK`](#healthcheck) | Check a container's health on startup. |\n| [`LABEL`](#label) | Add metadata to an image. |\n| [`MAINTAINER`](#maintainer-deprecated) | Specify the author of an image. |\n| [`ONBUILD`](#onbuild) | Specify instructions for when the image is used in a build. |\n| [`RUN`](#run) | Execute build commands. |\n| [`SHELL`](#shell) | Set the default shell of an image. |\n| [`STOPSIGNAL`](#stopsignal) | Specify the system call signal for exiting a container. |\n| [`USER`](#user) | Set user and group ID. |\n| [`VOLUME`](#volume) | Create volume mounts. |\n| [`WORKDIR`](#workdir) | Change working directory. |\n\nHere is the format of the Dockerfile:\n\nThe instruction is not case-sensitive. However, convention is for them to be UPPERCASE to distinguish them from arguments more easily.\n\nDocker runs instructions in a Dockerfile in order. A Dockerfile **must begin with a `FROM` instruction**. This may be after [parser directives](#parser-directives), [comments](#format), and globally scoped [ARGs](#arg). The `FROM` instruction specifies the [parent image](https://docs.docker.com/glossary/#parent-image) from which you are building. `FROM` may only be preceded by one or more `ARG` instructions, which declare arguments that are used in `FROM` lines in the Dockerfile.\n\nBuildKit treats lines that begin with `#` as a comment, unless the line is a valid [parser directive](#parser-directives). A `#` marker anywhere else in a line is treated as an argument. This allows statements like:\n\nComment lines are removed before the Dockerfile instructions are executed. The comment in the following example is removed before the shell executes the `echo` command.\n\nThe following examples is equivalent.\n\nComments don't support line continuation characters.\n\n> **Note on whitespace**\n> \n> For backward compatibility, leading whitespace before comments (`#`) and instructions (such as `RUN`) are ignored, but discouraged. Leading whitespace is not preserved in these cases, and the following examples are therefore equivalent:\n> \n> Whitespace in instruction arguments, however, isn't ignored. The following example prints `hello world` with leading whitespace as specified:\n\nParser directives are optional, and affect the way in which subsequent lines in a Dockerfile are handled. Parser directives don't add layers to the build, and don't show up as build steps. Parser directives are written as a special type of comment in the form `# directive=value`. A single directive may only be used once.\n\nOnce a comment, empty line or builder instruction has been processed, BuildKit no longer looks for parser directives. Instead it treats anything formatted as a parser directive as a comment and doesn't attempt to validate if it might be a parser directive. Therefore, all parser directives must be at the top of a Dockerfile.\n\nParser directives aren't case-sensitive, but they're lowercase by convention. It's also conventional to include a blank line following any parser directives. Line continuation characters aren't supported in parser directives.\n\nDue to these rules, the following examples are all invalid:\n\nInvalid due to line continuation:\n\nInvalid due to appearing twice:\n\nTreated as a comment because it appears after a builder instruction:\n\nTreated as a comment because it appears after a comment that isn't a parser directive:\n\nThe following `unknowndirective` is treated as a comment because it isn't recognized. The known `syntax` directive is treated as a comment because it appears after a comment that isn't a parser directive.\n\nNon line-breaking whitespace is permitted in a parser directive. Hence, the following lines are all treated identically:\n\nThe following parser directives are supported:\n\n*   `syntax`\n*   `escape`\n\n### [syntax](#syntax)\n\nUse the `syntax` parser directive to declare the Dockerfile syntax version to use for the build. If unspecified, BuildKit uses a bundled version of the Dockerfile frontend. Declaring a syntax version lets you automatically use the latest Dockerfile version without having to upgrade BuildKit or Docker Engine, or even use a custom Dockerfile implementation.\n\nMost users will want to set this parser directive to `docker/dockerfile:1`, which causes BuildKit to pull the latest stable version of the Dockerfile syntax before the build.\n\nFor more information about how the parser directive works, see [Custom Dockerfile syntax](https://docs.docker.com/build/buildkit/dockerfile-frontend/).\n\n### [escape](#escape)\n\nOr\n\nThe `escape` directive sets the character used to escape characters in a Dockerfile. If not specified, the default escape character is `\\`.\n\nThe escape character is used both to escape characters in a line, and to escape a newline. This allows a Dockerfile instruction to span multiple lines. Note that regardless of whether the `escape` parser directive is included in a Dockerfile, escaping is not performed in a `RUN` command, except at the end of a line.\n\nSetting the escape character to `` ` `` is especially useful on `Windows`, where `\\` is the directory path separator. `` ` `` is consistent with [Windows PowerShell](https://technet.microsoft.com/en-us/library/hh847755.aspx).\n\nConsider the following example which would fail in a non-obvious way on Windows. The second `\\` at the end of the second line would be interpreted as an escape for the newline, instead of a target of the escape from the first `\\`. Similarly, the `\\` at the end of the third line would, assuming it was actually handled as an instruction, cause it be treated as a line continuation. The result of this Dockerfile is that second and third lines are considered a single instruction:\n\nResults in:\n\nOne solution to the above would be to use `/` as the target of both the `COPY` instruction, and `dir`. However, this syntax is, at best, confusing as it is not natural for paths on Windows, and at worst, error prone as not all commands on Windows support `/` as the path separator.\n\nBy adding the `escape` parser directive, the following Dockerfile succeeds as expected with the use of natural platform semantics for file paths on Windows:\n\nResults in:\n\nEnvironment variables (declared with [the `ENV` statement](#env)) can also be used in certain instructions as variables to be interpreted by the Dockerfile. Escapes are also handled for including variable-like syntax into a statement literally.\n\nEnvironment variables are notated in the Dockerfile either with `$variable_name` or `${variable_name}`. They are treated equivalently and the brace syntax is typically used to address issues with variable names with no whitespace, like `${foo}_bar`.\n\nThe `${variable_name}` syntax also supports a few of the standard `bash` modifiers as specified below:\n\n*   `${variable:-word}` indicates that if `variable` is set then the result will be that value. If `variable` is not set then `word` will be the result.\n*   `${variable:+word}` indicates that if `variable` is set then `word` will be the result, otherwise the result is the empty string.\n\nThe following variable replacements are supported in a pre-release version of Dockerfile syntax, when using the `# syntax=docker/dockerfile-upstream:master` syntax directive in your Dockerfile:\n\n*   `${variable#pattern}` removes the shortest match of `pattern` from `variable`, seeking from the start of the string.\n    \n*   `${variable##pattern}` removes the longest match of `pattern` from `variable`, seeking from the start of the string.\n    \n*   `${variable%pattern}` removes the shortest match of `pattern` from `variable`, seeking backwards from the end of the string.\n    \n*   `${variable%%pattern}` removes the longest match of `pattern` from `variable`, seeking backwards from the end of the string.\n    \n*   `${variable/pattern/replacement}` replace the first occurrence of `pattern` in `variable` with `replacement`\n    \n*   `${variable//pattern/replacement}` replaces all occurrences of `pattern` in `variable` with `replacement`\n    \n\nIn all cases, `word` can be any string, including additional environment variables.\n\n`pattern` is a glob pattern where `?` matches any single character and `*` any number of characters (including zero). To match literal `?` and `*`, use a backslash escape: `\\?` and `\\*`.\n\nYou can escape whole variable names by adding a `\\` before the variable: `\\$foo` or `\\${foo}`, for example, will translate to `$foo` and `${foo}` literals respectively.\n\nExample (parsed representation is displayed after the `#`):\n\nEnvironment variables are supported by the following list of instructions in the Dockerfile:\n\n*   `ADD`\n*   `COPY`\n*   `ENV`\n*   `EXPOSE`\n*   `FROM`\n*   `LABEL`\n*   `STOPSIGNAL`\n*   `USER`\n*   `VOLUME`\n*   `WORKDIR`\n*   `ONBUILD` (when combined with one of the supported instructions above)\n\nYou can also use environment variables with `RUN`, `CMD`, and `ENTRYPOINT` instructions, but in those cases the variable substitution is handled by the command shell, not the builder. Note that instructions using the exec form don't invoke a command shell automatically. See [Variable substitution](#variable-substitution).\n\nEnvironment variable substitution use the same value for each variable throughout the entire instruction. Changing the value of a variable only takes effect in subsequent instructions. Consider the following example:\n\n*   The value of `def` becomes `hello`\n*   The value of `ghi` becomes `bye`\n\nYou can use `.dockerignore` file to exclude files and directories from the build context. For more information, see [.dockerignore file](https://docs.docker.com/build/building/context/#dockerignore-files).\n\nThe `RUN`, `CMD`, and `ENTRYPOINT` instructions all have two possible forms:\n\n*   `INSTRUCTION [\"executable\",\"param1\",\"param2\"]` (exec form)\n*   `INSTRUCTION command param1 param2` (shell form)\n\nThe exec form makes it possible to avoid shell string munging, and to invoke commands using a specific command shell, or any other executable. It uses a JSON array syntax, where each element in the array is a command, flag, or argument.\n\nThe shell form is more relaxed, and emphasizes ease of use, flexibility, and readability. The shell form automatically uses a command shell, whereas the exec form does not.\n\n### [Exec form](#exec-form)\n\nThe exec form is parsed as a JSON array, which means that you must use double-quotes (\") around words, not single-quotes (').\n\nThe exec form is best used to specify an `ENTRYPOINT` instruction, combined with `CMD` for setting default arguments that can be overridden at runtime. For more information, see [ENTRYPOINT](#entrypoint).\n\n#### [Variable substitution](#variable-substitution)\n\nUsing the exec form doesn't automatically invoke a command shell. This means that normal shell processing, such as variable substitution, doesn't happen. For example, `RUN [ \"echo\", \"$HOME\" ]` won't handle variable substitution for `$HOME`.\n\nIf you want shell processing then either use the shell form or execute a shell directly with the exec form, for example: `RUN [ \"sh\", \"-c\", \"echo $HOME\" ]`. When using the exec form and executing a shell directly, as in the case for the shell form, it's the shell that's doing the environment variable substitution, not the builder.\n\n#### [Backslashes](#backslashes)\n\nIn exec form, you must escape backslashes. This is particularly relevant on Windows where the backslash is the path separator. The following line would otherwise be treated as shell form due to not being valid JSON, and fail in an unexpected way:\n\nThe correct syntax for this example is:\n\n### [Shell form](#shell-form)\n\nUnlike the exec form, instructions using the shell form always use a command shell. The shell form doesn't use the JSON array format, instead it's a regular string. The shell form string lets you escape newlines using the [escape character](#escape) (backslash by default) to continue a single instruction onto the next line. This makes it easier to use with longer commands, because it lets you split them up into multiple lines. For example, consider these two lines:\n\nThey're equivalent to the following line:\n\nYou can also use heredocs with the shell form to break up a command:\n\nFor more information about heredocs, see [Here-documents](#here-documents).\n\n### [Use a different shell](#use-a-different-shell)\n\nYou can change the default shell using the `SHELL` command. For example:\n\nFor more information, see [SHELL](#shell).\n\nOr\n\nOr\n\nThe `FROM` instruction initializes a new build stage and sets the [base image](https://docs.docker.com/glossary/#base-image) for subsequent instructions. As such, a valid Dockerfile must start with a `FROM` instruction. The image can be any valid image.\n\n*   `ARG` is the only instruction that may precede `FROM` in the Dockerfile. See [Understand how ARG and FROM interact](#understand-how-arg-and-from-interact).\n*   `FROM` can appear multiple times within a single Dockerfile to create multiple images or use one build stage as a dependency for another. Simply make a note of the last image ID output by the commit before each new `FROM` instruction. Each `FROM` instruction clears any state created by previous instructions.\n*   Optionally a name can be given to a new build stage by adding `AS name` to the `FROM` instruction. The name can be used in subsequent `FROM <name>`, [`COPY --from=<name>`](#copy---from), and [`RUN --mount=type=bind,from=<name>`](#run---mounttypebind) instructions to refer to the image built in this stage.\n*   The `tag` or `digest` values are optional. If you omit either of them, the builder assumes a `latest` tag by default. The builder returns an error if it can't find the `tag` value.\n\nThe optional `--platform` flag can be used to specify the platform of the image in case `FROM` references a multi-platform image. For example, `linux/amd64`, `linux/arm64`, or `windows/amd64`. By default, the target platform of the build request is used. Global build arguments can be used in the value of this flag, for example [automatic platform ARGs](#automatic-platform-args-in-the-global-scope) allow you to force a stage to native build platform (`--platform=$BUILDPLATFORM`), and use it to cross-compile to the target platform inside the stage.\n\n### [Understand how ARG and FROM interact](#understand-how-arg-and-from-interact)\n\n`FROM` instructions support variables that are declared by any `ARG` instructions that occur before the first `FROM`.\n\nAn `ARG` declared before a `FROM` is outside of a build stage, so it can't be used in any instruction after a `FROM`. To use the default value of an `ARG` declared before the first `FROM` use an `ARG` instruction without a value inside of a build stage:\n\nThe `RUN` instruction will execute any commands to create a new layer on top of the current image. The added layer is used in the next step in the Dockerfile. `RUN` has two forms:\n\nFor more information about the differences between these two forms, see [shell or exec forms](#shell-and-exec-form).\n\nThe shell form is most commonly used, and lets you break up longer instructions into multiple lines, either using newline [escapes](#escape), or with [heredocs](#here-documents):\n\nThe available `[OPTIONS]` for the `RUN` instruction are:\n\n*   [`--mount`](#run---mount)\n*   [`--network`](#run---network)\n*   [`--security`](#run---security)\n\n### [Cache invalidation for RUN instructions](#cache-invalidation-for-run-instructions)\n\nThe cache for `RUN` instructions isn't invalidated automatically during the next build. The cache for an instruction like `RUN apt-get dist-upgrade -y` will be reused during the next build. The cache for `RUN` instructions can be invalidated by using the `--no-cache` flag, for example `docker build --no-cache`.\n\nSee the [Dockerfile Best Practices guide](https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/) for more information.\n\nThe cache for `RUN` instructions can be invalidated by [`ADD`](#add) and [`COPY`](#copy) instructions.\n\n### [RUN --mount](#run---mount)\n\n`RUN --mount` allows you to create filesystem mounts that the build can access. This can be used to:\n\n*   Create bind mount to the host filesystem or other build stages\n*   Access build secrets or ssh-agent sockets\n*   Use a persistent package management cache to speed up your build\n\nThe supported mount types are:\n\n| Type | Description |\n| --- | --- |\n| [`bind`](#run---mounttypebind) (default) | Bind-mount context directories (read-only). |\n| [`cache`](#run---mounttypecache) | Mount a temporary directory to cache directories for compilers and package managers. |\n| [`tmpfs`](#run---mounttypetmpfs) | Mount a `tmpfs` in the build container. |\n| [`secret`](#run---mounttypesecret) | Allow the build container to access secure files such as private keys without baking them into the image. |\n| [`ssh`](#run---mounttypessh) | Allow the build container to access SSH keys via SSH agents, with support for passphrases. |\n\n### [RUN --mount=type=bind](#run---mounttypebind)\n\nThis mount type allows binding files or directories to the build container. A bind mount is read-only by default.\n\n| Option | Description |\n| --- | --- |\n| `target`[1](#fn:1) | Mount path. |\n| `source` | Source path in the `from`. Defaults to the root of the `from`. |\n| `from` | Build stage or image name for the root of the source. Defaults to the build context. |\n| `rw`,`readwrite` | Allow writes on the mount. Written data will be discarded. |\n\n### [RUN --mount=type=cache](#run---mounttypecache)\n\nThis mount type allows the build container to cache directories for compilers and package managers.\n\n| Option | Description |\n| --- | --- |\n| `id` | Optional ID to identify separate/different caches. Defaults to value of `target`. |\n| `target`[1](#fn:1) | Mount path. |\n| `ro`,`readonly` | Read-only if set. |\n| `sharing` | One of `shared`, `private`, or `locked`. Defaults to `shared`. A `shared` cache mount can be used concurrently by multiple writers. `private` creates a new mount if there are multiple writers. `locked` pauses the second writer until the first one releases the mount. |\n| `from` | Build stage to use as a base of the cache mount. Defaults to empty directory. |\n| `source` | Subpath in the `from` to mount. Defaults to the root of the `from`. |\n| `mode` | File mode for new cache directory in octal. Default `0755`. |\n| `uid` | User ID for new cache directory. Default `0`. |\n| `gid` | Group ID for new cache directory. Default `0`. |\n\nContents of the cache directories persists between builder invocations without invalidating the instruction cache. Cache mounts should only be used for better performance. Your build should work with any contents of the cache directory as another build may overwrite the files or GC may clean it if more storage space is needed.\n\n#### [Example: cache Go packages](#example-cache-go-packages)\n\n#### [Example: cache apt packages](#example-cache-apt-packages)\n\nApt needs exclusive access to its data, so the caches use the option `sharing=locked`, which will make sure multiple parallel builds using the same cache mount will wait for each other and not access the same cache files at the same time. You could also use `sharing=private` if you prefer to have each build create another cache directory in this case.\n\n### [RUN --mount=type=tmpfs](#run---mounttypetmpfs)\n\nThis mount type allows mounting `tmpfs` in the build container.\n\n| Option | Description |\n| --- | --- |\n| `target`[1](#fn:1) | Mount path. |\n| `size` | Specify an upper limit on the size of the filesystem. |\n\n### [RUN --mount=type=secret](#run---mounttypesecret)\n\nThis mount type allows the build container to access secure files such as private keys without baking them into the image.\n\n| Option | Description |\n| --- | --- |\n| `id` | ID of the secret. Defaults to basename of the target path. |\n| `target` | Mount path. Defaults to `/run/secrets/` + `id`. |\n| `required` | If set to `true`, the instruction errors out when the secret is unavailable. Defaults to `false`. |\n| `mode` | File mode for secret file in octal. Default `0400`. |\n| `uid` | User ID for secret file. Default `0`. |\n| `gid` | Group ID for secret file. Default `0`. |\n\n#### [Example: access to S3](#example-access-to-s3)\n\n### [RUN --mount=type=ssh](#run---mounttypessh)\n\nThis mount type allows the build container to access SSH keys via SSH agents, with support for passphrases.\n\n| Option | Description |\n| --- | --- |\n| `id` | ID of SSH agent socket or key. Defaults to \"default\". |\n| `target` | SSH agent socket path. Defaults to `/run/buildkit/ssh_agent.${N}`. |\n| `required` | If set to `true`, the instruction errors out when the key is unavailable. Defaults to `false`. |\n| `mode` | File mode for socket in octal. Default `0600`. |\n| `uid` | User ID for socket. Default `0`. |\n| `gid` | Group ID for socket. Default `0`. |\n\n#### [Example: access to GitLab](#example-access-to-gitlab)\n\nYou can also specify a path to `*.pem` file on the host directly instead of `$SSH_AUTH_SOCK`. However, pem files with passphrases are not supported.\n\n### [RUN --network](#run---network)\n\n`RUN --network` allows control over which networking environment the command is run in.\n\nThe supported network types are:\n\n| Type | Description |\n| --- | --- |\n| [`default`](#run---networkdefault) (default) | Run in the default network. |\n| [`none`](#run---networknone) | Run with no network access. |\n| [`host`](#run---networkhost) | Run in the host's network environment. |\n\n### [RUN --network=default](#run---networkdefault)\n\nEquivalent to not supplying a flag at all, the command is run in the default network for the build.\n\n### [RUN --network=none](#run---networknone)\n\nThe command is run with no network access (`lo` is still available, but is isolated to this process)\n\n#### [Example: isolating external effects](#example-isolating-external-effects)\n\n`pip` will only be able to install the packages provided in the tarfile, which can be controlled by an earlier build stage.\n\n### [RUN --network=host](#run---networkhost)\n\nThe command is run in the host's network environment (similar to `docker build --network=host`, but on a per-instruction basis)\n\n> **Warning**\n> \n> The use of `--network=host` is protected by the `network.host` entitlement, which needs to be enabled when starting the buildkitd daemon with `--allow-insecure-entitlement network.host` flag or in [buildkitd config](https://github.com/moby/buildkit/blob/master/docs/buildkitd.toml.md), and for a build request with [`--allow network.host` flag](https://docs.docker.com/engine/reference/commandline/buildx_build/#allow).\n\n### [RUN --security](#run---security)\n\n> **Note**\n> \n> Not yet available in stable syntax, use [`docker/dockerfile:1-labs`](#syntax) version.\n\nThe default security mode is `sandbox`. With `--security=insecure`, the builder runs the command without sandbox in insecure mode, which allows to run flows requiring elevated privileges (e.g. containerd). This is equivalent to running `docker run --privileged`.\n\n> **Warning**\n> \n> In order to access this feature, entitlement `security.insecure` should be enabled when starting the buildkitd daemon with `--allow-insecure-entitlement security.insecure` flag or in [buildkitd config](https://github.com/moby/buildkit/blob/master/docs/buildkitd.toml.md), and for a build request with [`--allow security.insecure` flag](https://docs.docker.com/engine/reference/commandline/buildx_build/#allow).\n\nDefault sandbox mode can be activated via `--security=sandbox`, but that is no-op.\n\n#### [Example: check entitlements](#example-check-entitlements)\n\nThe `CMD` instruction sets the command to be executed when running a container from an image.\n\nYou can specify `CMD` instructions using [shell or exec forms](#shell-and-exec-form):\n\n*   `CMD [\"executable\",\"param1\",\"param2\"]` (exec form)\n*   `CMD [\"param1\",\"param2\"]` (exec form, as default parameters to `ENTRYPOINT`)\n*   `CMD command param1 param2` (shell form)\n\nThere can only be one `CMD` instruction in a Dockerfile. If you list more than one `CMD`, only the last one takes effect.\n\nThe purpose of a `CMD` is to provide defaults for an executing container. These defaults can include an executable, or they can omit the executable, in which case you must specify an `ENTRYPOINT` instruction as well.\n\nIf you would like your container to run the same executable every time, then you should consider using `ENTRYPOINT` in combination with `CMD`. See [`ENTRYPOINT`](#entrypoint). If the user specifies arguments to `docker run` then they will override the default specified in `CMD`, but still use the default `ENTRYPOINT`.\n\nIf `CMD` is used to provide default arguments for the `ENTRYPOINT` instruction, both the `CMD` and `ENTRYPOINT` instructions should be specified in the [exec form](#exec-form).\n\n> **Note**\n> \n> Don't confuse `RUN` with `CMD`. `RUN` actually runs a command and commits the result; `CMD` doesn't execute anything at build time, but specifies the intended command for the image.\n\nThe `LABEL` instruction adds metadata to an image. A `LABEL` is a key-value pair. To include spaces within a `LABEL` value, use quotes and backslashes as you would in command-line parsing. A few usage examples:\n\nAn image can have more than one label. You can specify multiple labels on a single line. Prior to Docker 1.10, this decreased the size of the final image, but this is no longer the case. You may still choose to specify multiple labels in a single instruction, in one of the following two ways:\n\n> **Note**\n> \n> Be sure to use double quotes and not single quotes. Particularly when you are using string interpolation (e.g. `LABEL example=\"foo-$ENV_VAR\"`), single quotes will take the string as is without unpacking the variable's value.\n\nLabels included in base or parent images (images in the `FROM` line) are inherited by your image. If a label already exists but with a different value, the most-recently-applied value overrides any previously-set value.\n\nTo view an image's labels, use the `docker image inspect` command. You can use the `--format` option to show just the labels;\n\n## [MAINTAINER (deprecated)](#maintainer-deprecated)\n\nThe `MAINTAINER` instruction sets the _Author_ field of the generated images. The `LABEL` instruction is a much more flexible version of this and you should use it instead, as it enables setting any metadata you require, and can be viewed easily, for example with `docker inspect`. To set a label corresponding to the `MAINTAINER` field you could use:\n\nThis will then be visible from `docker inspect` with the other labels.\n\nThe `EXPOSE` instruction informs Docker that the container listens on the specified network ports at runtime. You can specify whether the port listens on TCP or UDP, and the default is TCP if you don't specify a protocol.\n\nThe `EXPOSE` instruction doesn't actually publish the port. It functions as a type of documentation between the person who builds the image and the person who runs the container, about which ports are intended to be published. To publish the port when running the container, use the `-p` flag on `docker run` to publish and map one or more ports, or the `-P` flag to publish all exposed ports and map them to high-order ports.\n\nBy default, `EXPOSE` assumes TCP. You can also specify UDP:\n\nTo expose on both TCP and UDP, include two lines:\n\nIn this case, if you use `-P` with `docker run`, the port will be exposed once for TCP and once for UDP. Remember that `-P` uses an ephemeral high-ordered host port on the host, so TCP and UDP doesn't use the same port.\n\nRegardless of the `EXPOSE` settings, you can override them at runtime by using the `-p` flag. For example\n\nTo set up port redirection on the host system, see [using the -P flag](https://docs.docker.com/engine/reference/run/#expose-incoming-ports). The `docker network` command supports creating networks for communication among containers without the need to expose or publish specific ports, because the containers connected to the network can communicate with each other over any port. For detailed information, see the [overview of this feature](https://docs.docker.com/engine/userguide/networking/).\n\nThe `ENV` instruction sets the environment variable `<key>` to the value `<value>`. This value will be in the environment for all subsequent instructions in the build stage and can be [replaced inline](#environment-replacement) in many as well. The value will be interpreted for other environment variables, so quote characters will be removed if they are not escaped. Like command line parsing, quotes and backslashes can be used to include spaces within values.\n\nExample:\n\nThe `ENV` instruction allows for multiple `<key>=<value> ...` variables to be set at one time, and the example below will yield the same net results in the final image:\n\nThe environment variables set using `ENV` will persist when a container is run from the resulting image. You can view the values using `docker inspect`, and change them using `docker run --env <key>=<value>`.\n\nA stage inherits any environment variables that were set using `ENV` by its parent stage or any ancestor. Refer [here](https://docs.docker.com/build/building/multi-stage/) for more on multi-staged builds.\n\nEnvironment variable persistence can cause unexpected side effects. For example, setting `ENV DEBIAN_FRONTEND=noninteractive` changes the behavior of `apt-get`, and may confuse users of your image.\n\nIf an environment variable is only needed during build, and not in the final image, consider setting a value for a single command instead:\n\nOr using [`ARG`](#arg), which is not persisted in the final image:\n\n> **Alternative syntax**\n> \n> The `ENV` instruction also allows an alternative syntax `ENV <key> <value>`, omitting the `=`. For example:\n> \n> This syntax does not allow for multiple environment-variables to be set in a single `ENV` instruction, and can be confusing. For example, the following sets a single environment variable (`ONE`) with value `\"TWO= THREE=world\"`:\n> \n> The alternative syntax is supported for backward compatibility, but discouraged for the reasons outlined above, and may be removed in a future release.\n\nADD has two forms. The latter form is required for paths containing whitespace.\n\nThe available `[OPTIONS]` are:\n\n*   [`--keep-git-dir`](#add---keep-git-dir)\n*   [`--checksum`](#add---checksum)\n*   [`--chown`](#add---chown---chmod)\n*   [`--chmod`](#add---chown---chmod)\n*   [`--link`](#add---link)\n*   [`--exclude`](#add---exclude)\n\nThe `ADD` instruction copies new files, directories or remote file URLs from `<src>` and adds them to the filesystem of the image at the path `<dest>`.\n\nMultiple `<src>` resources may be specified but if they are files or directories, their paths are interpreted as relative to the source of the context of the build.\n\nEach `<src>` may contain wildcards and matching will be done using Go's [filepath.Match](https://golang.org/pkg/path/filepath#Match) rules. For example:\n\nTo add all files in the root of the build context starting with \"hom\":\n\nIn the following example, `?` is a single-character wildcard, matching e.g. \"home.txt\".\n\nThe `<dest>` is an absolute path, or a path relative to `WORKDIR`, into which the source will be copied inside the destination container.\n\nThe example below uses a relative path, and adds \"test.txt\" to `<WORKDIR>/relativeDir/`:\n\nWhereas this example uses an absolute path, and adds \"test.txt\" to `/absoluteDir/`\n\nWhen adding files or directories that contain special characters (such as `[` and `]`), you need to escape those paths following the Golang rules to prevent them from being treated as a matching pattern. For example, to add a file named `arr[0].txt`, use the following;\n\nIn the case where `<src>` is a remote file URL, the destination will have permissions of 600. If the remote file being retrieved has an HTTP `Last-Modified` header, the timestamp from that header will be used to set the `mtime` on the destination file. However, like any other file processed during an `ADD`, `mtime` isn't included in the determination of whether or not the file has changed and the cache should be updated.\n\n> **Note**\n> \n> If you build by passing a Dockerfile through STDIN (`docker build - < somefile`), there is no build context, so the Dockerfile can only contain a URL based `ADD` instruction. You can also pass a compressed archive through STDIN: (`docker build - < archive.tar.gz`), the Dockerfile at the root of the archive and the rest of the archive will be used as the context of the build.\n\nIf your URL files are protected using authentication, you need to use `RUN wget`, `RUN curl` or use another tool from within the container as the `ADD` instruction doesn't support authentication.\n\n> **Note**\n> \n> The first encountered `ADD` instruction will invalidate the cache for all following instructions from the Dockerfile if the contents of `<src>` have changed. This includes invalidating the cache for `RUN` instructions. See the [Dockerfile Best Practices guide â€“ Leverage build cache](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#leverage-build-cache) for more information.\n\n`ADD` obeys the following rules:\n\n*   The `<src>` path must be inside the build context; you can't use `ADD ../something /something`, because the builder can only access files from the context, and `../something` specifies a parent file or directory of the build context root.\n    \n*   If `<src>` is a URL and `<dest>` does end with a trailing slash, then the filename is inferred from the URL and the file is downloaded to `<dest>/<filename>`. For instance, `ADD http://example.com/foobar /` would create the file `/foobar`. The URL must have a nontrivial path so that an appropriate filename can be discovered in this case (`http://example.com` doesn't work).\n    \n*   If `<src>` is a directory, the entire contents of the directory are copied, including filesystem metadata.\n    \n    > **Note**\n    > \n    > The directory itself isn't copied, only its contents.\n    \n*   If `<src>` is a local `tar` archive in a recognized compression format (`identity`, `gzip`, `bzip2` or `xz`) then it's unpacked as a directory. Resources from remote URLs aren't decompressed. When a directory is copied or unpacked, it has the same behavior as `tar -x`. The result is the union of:\n    \n    1.  Whatever existed at the destination path and\n    2.  The contents of the source tree, with conflicts resolved in favor of \"2.\" on a file-by-file basis.\n    \n    > **Note**\n    > \n    > Whether a file is identified as a recognized compression format or not is done solely based on the contents of the file, not the name of the file. For example, if an empty file happens to end with `.tar.gz` this isn't recognized as a compressed file and doesn't generate any kind of decompression error message, rather the file will simply be copied to the destination.\n    \n*   If `<src>` is any other kind of file, it's copied individually along with its metadata. In this case, if `<dest>` ends with a trailing slash `/`, it will be considered a directory and the contents of `<src>` will be written at `<dest>/base(<src>)`.\n    \n*   If multiple `<src>` resources are specified, either directly or due to the use of a wildcard, then `<dest>` must be a directory, and it must end with a slash `/`.\n    \n*   If `<src>` is a file, and `<dest>` doesn't end with a trailing slash, the contents of `<src>` will be written as filename `<dest>`.\n    \n*   If `<dest>` doesn't exist, it's created, along with all missing directories in its path.\n    \n\n### [Adding private Git repositories](#adding-private-git-repositories)\n\nTo add a private repository via SSH, create a Dockerfile with the following form:\n\nThis Dockerfile can be built with `docker build --ssh` or `buildctl build --ssh`, e.g.,\n\n### [ADD --keep-git-dir](#add---keep-git-dir)\n\nWhen `<src>` is the HTTP or SSH address of a remote Git repository, BuildKit adds the contents of the Git repository to the image excluding the `.git` directory by default.\n\nThe `--keep-git-dir=true` flag lets you preserve the `.git` directory.\n\n### [ADD --checksum](#add---checksum)\n\nThe `--checksum` flag lets you verify the checksum of a remote resource:\n\nThe `--checksum` flag only supports HTTP sources currently.\n\n### [ADD --chown --chmod](#add---chown---chmod)\n\nSee [`COPY --chown --chmod`](#copy---chown---chmod).\n\n### [ADD --link](#add---link)\n\nSee [`COPY --link`](#copy---link).\n\n### [ADD --exclude](#add---exclude)\n\nSee [`COPY --exclude`](#copy---exclude).\n\nCOPY has two forms. The latter form is required for paths containing whitespace.\n\nThe available `[OPTIONS]` are:\n\n*   [`--from`](#copy---from)\n*   [`--chown`](#copy---chown---chmod)\n*   [`--chmod`](#copy---chown---chmod)\n*   [`--link`](#copy---link)\n*   [`--parents`](#copy---parents)\n*   [`--exclude`](#copy---exclude)\n\nThe `COPY` instruction copies new files or directories from `<src>` and adds them to the filesystem of the container at the path `<dest>`.\n\nMultiple `<src>` resources may be specified but the paths of files and directories will be interpreted as relative to the source of the context of the build.\n\nEach `<src>` may contain wildcards and matching will be done using Go's [filepath.Match](https://golang.org/pkg/path/filepath#Match) rules. For example:\n\nTo add all files in the root of the build context starting with \"hom\":\n\nIn the following example, `?` is a single-character wildcard, matching e.g. \"home.txt\".\n\nThe `<dest>` is an absolute path, or a path relative to `WORKDIR`, into which the source will be copied inside the destination container.\n\nThe example below uses a relative path, and adds \"test.txt\" to `<WORKDIR>/relativeDir/`:\n\nWhereas this example uses an absolute path, and adds \"test.txt\" to `/absoluteDir/`\n\nWhen copying files or directories that contain special characters (such as `[` and `]`), you need to escape those paths following the Golang rules to prevent them from being treated as a matching pattern. For example, to copy a file named `arr[0].txt`, use the following;\n\n> **Note**\n> \n> If you build using STDIN (`docker build - < somefile`), there is no build context, so `COPY` can't be used.\n\nOptionally `COPY` accepts a flag `--from=<name>` that can be used to set the source location to a previous build stage (created with `FROM .. AS <name>`) that will be used instead of a build context sent by the user. In case a build stage with a specified name can't be found an image with the same name is attempted to be used instead.\n\n`COPY` obeys the following rules:\n\n*   The `<src>` path is resolved relative to the build context. If you specify a relative path leading outside of the build context, such as `COPY ../something /something`, parent directory paths are stripped out automatically. The effective source path in this example becomes `COPY something /something`\n    \n*   If `<src>` is a directory, the entire contents of the directory are copied, including filesystem metadata.\n    \n    > **Note**\n    > \n    > The directory itself isn't copied, only its contents.\n    \n*   If `<src>` is any other kind of file, it's copied individually along with its metadata. In this case, if `<dest>` ends with a trailing slash `/`, it will be considered a directory and the contents of `<src>` will be written at `<dest>/base(<src>)`.\n    \n*   If multiple `<src>` resources are specified, either directly or due to the use of a wildcard, then `<dest>` must be a directory, and it must end with a slash `/`.\n    \n*   If `<src>` is a file, and `<dest>` doesn't end with a trailing slash, the contents of `<src>` will be written as filename `<dest>`.\n    \n*   If `<dest>` doesn't exist, it's created, along with all missing directories in its path.\n    \n\n> **Note**\n> \n> The first encountered `COPY` instruction will invalidate the cache for all following instructions from the Dockerfile if the contents of `<src>` have changed. This includes invalidating the cache for `RUN` instructions. See the [Dockerfile Best Practices guide â€“ Leverage build cache](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#leverage-build-cache) for more information.\n\n### [COPY --from](#copy---from)\n\nBy default, the `COPY` instruction copies files from the build context. The `COPY --from` flag lets you copy files from an image, a build stage, or a named context instead.\n\nTo copy from a build stage in a [multi-stage build](https://docs.docker.com/build/building/multi-stage/), specify the name of the stage you want to copy from. You specify stage names using the `AS` keyword with the `FROM` instruction.\n\nYou can also copy files directly from other images. The following example copies an `nginx.conf` file from the official Nginx image.\n\nThe source path of `COPY --from` is always resolved from filesystem root of the image or stage that you specify.\n\n### [COPY --chown --chmod](#copy---chown---chmod)\n\n> **Note**\n> \n> Only octal notation is currently supported. Non-octal support is tracked in [moby/buildkit#1951](https://github.com/moby/buildkit/issues/1951).\n\nThe `--chown` and `--chmod` features are only supported on Dockerfiles used to build Linux containers, and doesn't work on Windows containers. Since user and group ownership concepts do not translate between Linux and Windows, the use of `/etc/passwd` and `/etc/group` for translating user and group names to IDs restricts this feature to only be viable for Linux OS-based containers.\n\nAll files and directories copied from the build context are created with a UID and GID of `0` unless the optional `--chown` flag specifies a given username, groupname, or UID/GID combination to request specific ownership of the copied content. The format of the `--chown` flag allows for either username and groupname strings or direct integer UID and GID in any combination. Providing a username without groupname or a UID without GID will use the same numeric UID as the GID. If a username or groupname is provided, the container's root filesystem `/etc/passwd` and `/etc/group` files will be used to perform the translation from name to integer UID or GID respectively. The following examples show valid definitions for the `--chown` flag:\n\nIf the container root filesystem doesn't contain either `/etc/passwd` or `/etc/group` files and either user or group names are used in the `--chown` flag, the build will fail on the `COPY` operation. Using numeric IDs requires no lookup and does not depend on container root filesystem content.\n\n### [COPY --link](#copy---link)\n\nEnabling this flag in `COPY` or `ADD` commands allows you to copy files with enhanced semantics where your files remain independent on their own layer and don't get invalidated when commands on previous layers are changed.\n\nWhen `--link` is used your source files are copied into an empty destination directory. That directory is turned into a layer that is linked on top of your previous state.\n\nIs equivalent of doing two builds:\n\nand\n\nand merging all the layers of both images together.\n\n#### [Benefits of using `--link`](#benefits-of-using---link)\n\nUse `--link` to reuse already built layers in subsequent builds with `--cache-from` even if the previous layers have changed. This is especially important for multi-stage builds where a `COPY --from` statement would previously get invalidated if any previous commands in the same stage changed, causing the need to rebuild the intermediate stages again. With `--link` the layer the previous build generated is reused and merged on top of the new layers. This also means you can easily rebase your images when the base images receive updates, without having to execute the whole build again. In backends that support it, BuildKit can do this rebase action without the need to push or pull any layers between the client and the registry. BuildKit will detect this case and only create new image manifest that contains the new layers and old layers in correct order.\n\nThe same behavior where BuildKit can avoid pulling down the base image can also happen when using `--link` and no other commands that would require access to the files in the base image. In that case BuildKit will only build the layers for the `COPY` commands and push them to the registry directly on top of the layers of the base image.\n\n#### [Incompatibilities with `--link=false`](#incompatibilities-with---linkfalse)\n\nWhen using `--link` the `COPY/ADD` commands are not allowed to read any files from the previous state. This means that if in previous state the destination directory was a path that contained a symlink, `COPY/ADD` can not follow it. In the final image the destination path created with `--link` will always be a path containing only directories.\n\nIf you don't rely on the behavior of following symlinks in the destination path, using `--link` is always recommended. The performance of `--link` is equivalent or better than the default behavior and, it creates much better conditions for cache reuse.\n\n### [COPY --parents](#copy---parents)\n\n> **Note**\n> \n> Not yet available in stable syntax, use [`docker/dockerfile:1.7-labs`](#syntax) version.\n\nThe `--parents` flag preserves parent directories for `src` entries. This flag defaults to `false`.\n\nThis behavior is similar to the [Linux `cp` utility's](https://www.man7.org/linux/man-pages/man1/cp.1.html) `--parents` or [`rsync`](https://man7.org/linux/man-pages/man1/rsync.1.html) `--relative` flag.\n\nAs with Rsync, it is possible to limit which parent directories are preserved by inserting a dot and a slash (`./`) into the source path. If such point exists, only parent directories after it will be preserved. This may be especially useful copies between stages with `--from` where the source paths need to be absolute.\n\nNote that, without the `--parents` flag specified, any filename collision will fail the Linux `cp` operation with an explicit error message (`cp: will not overwrite just-created './x/a.txt' with './y/a.txt'`), where the Buildkit will silently overwrite the target file at the destination.\n\nWhile it is possible to preserve the directory structure for `COPY` instructions consisting of only one `src` entry, usually it is more beneficial to keep the layer count in the resulting image as low as possible. Therefore, with the `--parents` flag, the Buildkit is capable of packing multiple `COPY` instructions together, keeping the directory structure intact.\n\n### [COPY --exclude](#copy---exclude)\n\n> **Note**\n> \n> Not yet available in stable syntax, use [`docker/dockerfile:1.7-labs`](#syntax) version.\n\nThe `--exclude` flag lets you specify a path expression for files to be excluded.\n\nThe path expression follows the same format as `<src>`, supporting wildcards and matching using Go's [filepath.Match](https://golang.org/pkg/path/filepath#Match) rules. For example, to add all files starting with \"hom\", excluding files with a `.txt` extension:\n\nYou can specify the `--exclude` option multiple times for a `COPY` instruction. Multiple `--excludes` are files matching its patterns not to be copied, even if the files paths match the pattern specified in `<src>`. To add all files starting with \"hom\", excluding files with either `.txt` or `.md` extensions:\n\n## [ENTRYPOINT](#entrypoint)\n\nAn `ENTRYPOINT` allows you to configure a container that will run as an executable.\n\n`ENTRYPOINT` has two possible forms:\n\n*   The exec form, which is the preferred form:\n    \n*   The shell form:\n    \n\nFor more information about the different forms, see [Shell and exec form](#shell-and-exec-form).\n\nThe following command starts a container from the `nginx` with its default content, listening on port 80:\n\nCommand line arguments to `docker run <image>` will be appended after all elements in an exec form `ENTRYPOINT`, and will override all elements specified using `CMD`.\n\nThis allows arguments to be passed to the entry point, i.e., `docker run <image> -d` will pass the `-d` argument to the entry point. You can override the `ENTRYPOINT` instruction using the `docker run --entrypoint` flag.\n\nThe shell form of `ENTRYPOINT` prevents any `CMD` command line arguments from being used. It also starts your `ENTRYPOINT` as a subcommand of `/bin/sh -c`, which does not pass signals. This means that the executable will not be the container's `PID 1`, and will not receive Unix signals. In this case, your executable doesn't receive a `SIGTERM` from `docker stop <container>`.\n\nOnly the last `ENTRYPOINT` instruction in the Dockerfile will have an effect.\n\n### [Exec form ENTRYPOINT example](#exec-form-entrypoint-example)\n\nYou can use the exec form of `ENTRYPOINT` to set fairly stable default commands and arguments and then use either form of `CMD` to set additional defaults that are more likely to be changed.\n\nWhen you run the container, you can see that `top` is the only process:\n\nTo examine the result further, you can use `docker exec`:\n\nAnd you can gracefully request `top` to shut down using `docker stop test`.\n\nThe following Dockerfile shows using the `ENTRYPOINT` to run Apache in the foreground (i.e., as `PID 1`):\n\nIf you need to write a starter script for a single executable, you can ensure that the final executable receives the Unix signals by using `exec` and `gosu` commands:\n\nLastly, if you need to do some extra cleanup (or communicate with other containers) on shutdown, or are co-ordinating more than one executable, you may need to ensure that the `ENTRYPOINT` script receives the Unix signals, passes them on, and then does some more work:\n\nIf you run this image with `docker run -it --rm -p 80:80 --name test apache`, you can then examine the container's processes with `docker exec`, or `docker top`, and then ask the script to stop Apache:\n\n> **Note**\n> \n> You can override the `ENTRYPOINT` setting using `--entrypoint`, but this can only set the binary to exec (no `sh -c` will be used).\n\n### [Shell form ENTRYPOINT example](#shell-form-entrypoint-example)\n\nYou can specify a plain string for the `ENTRYPOINT` and it will execute in `/bin/sh -c`. This form will use shell processing to substitute shell environment variables, and will ignore any `CMD` or `docker run` command line arguments. To ensure that `docker stop` will signal any long running `ENTRYPOINT` executable correctly, you need to remember to start it with `exec`:\n\nWhen you run this image, you'll see the single `PID 1` process:\n\nWhich exits cleanly on `docker stop`:\n\nIf you forget to add `exec` to the beginning of your `ENTRYPOINT`:\n\nYou can then run it (giving it a name for the next step):\n\nYou can see from the output of `top` that the specified `ENTRYPOINT` is not `PID 1`.\n\nIf you then run `docker stop test`, the container will not exit cleanly - the `stop` command will be forced to send a `SIGKILL` after the timeout:\n\n### [Understand how CMD and ENTRYPOINT interact](#understand-how-cmd-and-entrypoint-interact)\n\nBoth `CMD` and `ENTRYPOINT` instructions define what command gets executed when running a container. There are few rules that describe their co-operation.\n\n1.  Dockerfile should specify at least one of `CMD` or `ENTRYPOINT` commands.\n    \n2.  `ENTRYPOINT` should be defined when using the container as an executable.\n    \n3.  `CMD` should be used as a way of defining default arguments for an `ENTRYPOINT` command or for executing an ad-hoc command in a container.\n    \n4.  `CMD` will be overridden when running the container with alternative arguments.\n    \n\nThe table below shows what command is executed for different `ENTRYPOINT` / `CMD` combinations:\n\n|     | No ENTRYPOINT | ENTRYPOINT exec\\_entry p1\\_entry | ENTRYPOINT \\[\"exec\\_entry\", \"p1\\_entry\"\\] |\n| --- | --- | --- | --- |\n| **No CMD** | error, not allowed | /bin/sh -c exec\\_entry p1\\_entry | exec\\_entry p1\\_entry |\n| **CMD \\[\"exec\\_cmd\", \"p1\\_cmd\"\\]** | exec\\_cmd p1\\_cmd | /bin/sh -c exec\\_entry p1\\_entry | exec\\_entry p1\\_entry exec\\_cmd p1\\_cmd |\n| **CMD exec\\_cmd p1\\_cmd** | /bin/sh -c exec\\_cmd p1\\_cmd | /bin/sh -c exec\\_entry p1\\_entry | exec\\_entry p1\\_entry /bin/sh -c exec\\_cmd p1\\_cmd |\n\n> **Note**\n> \n> If `CMD` is defined from the base image, setting `ENTRYPOINT` will reset `CMD` to an empty value. In this scenario, `CMD` must be defined in the current image to have a value.\n\nThe `VOLUME` instruction creates a mount point with the specified name and marks it as holding externally mounted volumes from native host or other containers. The value can be a JSON array, `VOLUME [\"/var/log/\"]`, or a plain string with multiple arguments, such as `VOLUME /var/log` or `VOLUME /var/log /var/db`. For more information/examples and mounting instructions via the Docker client, refer to [_Share Directories via Volumes_](https://docs.docker.com/storage/volumes/) documentation.\n\nThe `docker run` command initializes the newly created volume with any data that exists at the specified location within the base image. For example, consider the following Dockerfile snippet:\n\nThis Dockerfile results in an image that causes `docker run` to create a new mount point at `/myvol` and copy the `greeting` file into the newly created volume.\n\n### [Notes about specifying volumes](#notes-about-specifying-volumes)\n\nKeep the following things in mind about volumes in the Dockerfile.\n\n*   **Volumes on Windows-based containers**: When using Windows-based containers, the destination of a volume inside the container must be one of:\n    \n    *   a non-existing or empty directory\n    *   a drive other than `C:`\n*   **Changing the volume from within the Dockerfile**: If any build steps change the data within the volume after it has been declared, those changes will be discarded.\n    \n*   **JSON formatting**: The list is parsed as a JSON array. You must enclose words with double quotes (`\"`) rather than single quotes (`'`).\n    \n*   **The host directory is declared at container run-time**: The host directory (the mountpoint) is, by its nature, host-dependent. This is to preserve image portability, since a given host directory can't be guaranteed to be available on all hosts. For this reason, you can't mount a host directory from within the Dockerfile. The `VOLUME` instruction does not support specifying a `host-dir` parameter. You must specify the mountpoint when you create or run the container.\n    \n\nor\n\nThe `USER` instruction sets the user name (or UID) and optionally the user group (or GID) to use as the default user and group for the remainder of the current stage. The specified user is used for `RUN` instructions and at runtime, runs the relevant `ENTRYPOINT` and `CMD` commands.\n\n> Note that when specifying a group for the user, the user will have _only_ the specified group membership. Any other configured group memberships will be ignored.\n\n> **Warning**\n> \n> When the user doesn't have a primary group then the image (or the next instructions) will be run with the `root` group.\n> \n> On Windows, the user must be created first if it's not a built-in account. This can be done with the `net user` command called as part of a Dockerfile.\n\nThe `WORKDIR` instruction sets the working directory for any `RUN`, `CMD`, `ENTRYPOINT`, `COPY` and `ADD` instructions that follow it in the Dockerfile. If the `WORKDIR` doesn't exist, it will be created even if it's not used in any subsequent Dockerfile instruction.\n\nThe `WORKDIR` instruction can be used multiple times in a Dockerfile. If a relative path is provided, it will be relative to the path of the previous `WORKDIR` instruction. For example:\n\nThe output of the final `pwd` command in this Dockerfile would be `/a/b/c`.\n\nThe `WORKDIR` instruction can resolve environment variables previously set using `ENV`. You can only use environment variables explicitly set in the Dockerfile. For example:\n\nThe output of the final `pwd` command in this Dockerfile would be `/path/$DIRNAME`\n\nIf not specified, the default working directory is `/`. In practice, if you aren't building a Dockerfile from scratch (`FROM scratch`), the `WORKDIR` may likely be set by the base image you're using.\n\nTherefore, to avoid unintended operations in unknown directories, it's best practice to set your `WORKDIR` explicitly.\n\nThe `ARG` instruction defines a variable that users can pass at build-time to the builder with the `docker build` command using the `--build-arg <varname>=<value>` flag.\n\n> **Warning**\n> \n> It isn't recommended to use build arguments for passing secrets such as user credentials, API tokens, etc. Build arguments are visible in the `docker history` command and in `max` mode provenance attestations, which are attached to the image by default if you use the Buildx GitHub Actions and your GitHub repository is public.\n> \n> Refer to the [`RUN --mount=type=secret`](#run---mounttypesecret) section to learn about secure ways to use secrets when building images.\n\nA Dockerfile may include one or more `ARG` instructions. For example, the following is a valid Dockerfile:\n\n### [Default values](#default-values)\n\nAn `ARG` instruction can optionally include a default value:\n\nIf an `ARG` instruction has a default value and if there is no value passed at build-time, the builder uses the default.\n\n### [Scope](#scope)\n\nAn `ARG` variable definition comes into effect from the line on which it is defined in the Dockerfile not from the argument's use on the command-line or elsewhere. For example, consider this Dockerfile:\n\nA user builds this file by calling:\n\nThe `USER` at line 2 evaluates to `some_user` as the `username` variable is defined on the subsequent line 3. The `USER` at line 4 evaluates to `what_user`, as the `username` argument is defined and the `what_user` value was passed on the command line. Prior to its definition by an `ARG` instruction, any use of a variable results in an empty string.\n\nAn `ARG` instruction goes out of scope at the end of the build stage where it was defined. To use an argument in multiple stages, each stage must include the `ARG` instruction.\n\n### [Using ARG variables](#using-arg-variables)\n\nYou can use an `ARG` or an `ENV` instruction to specify variables that are available to the `RUN` instruction. Environment variables defined using the `ENV` instruction always override an `ARG` instruction of the same name. Consider this Dockerfile with an `ENV` and `ARG` instruction.\n\nThen, assume this image is built with this command:\n\nIn this case, the `RUN` instruction uses `v1.0.0` instead of the `ARG` setting passed by the user:`v2.0.1` This behavior is similar to a shell script where a locally scoped variable overrides the variables passed as arguments or inherited from environment, from its point of definition.\n\nUsing the example above but a different `ENV` specification you can create more useful interactions between `ARG` and `ENV` instructions:\n\nUnlike an `ARG` instruction, `ENV` values are always persisted in the built image. Consider a docker build without the `--build-arg` flag:\n\nUsing this Dockerfile example, `CONT_IMG_VER` is still persisted in the image but its value would be `v1.0.0` as it is the default set in line 3 by the `ENV` instruction.\n\nThe variable expansion technique in this example allows you to pass arguments from the command line and persist them in the final image by leveraging the `ENV` instruction. Variable expansion is only supported for [a limited set of Dockerfile instructions.](#environment-replacement)\n\n### [Predefined ARGs](#predefined-args)\n\nDocker has a set of predefined `ARG` variables that you can use without a corresponding `ARG` instruction in the Dockerfile.\n\n*   `HTTP_PROXY`\n*   `http_proxy`\n*   `HTTPS_PROXY`\n*   `https_proxy`\n*   `FTP_PROXY`\n*   `ftp_proxy`\n*   `NO_PROXY`\n*   `no_proxy`\n*   `ALL_PROXY`\n*   `all_proxy`\n\nTo use these, pass them on the command line using the `--build-arg` flag, for example:\n\nBy default, these pre-defined variables are excluded from the output of `docker history`. Excluding them reduces the risk of accidentally leaking sensitive authentication information in an `HTTP_PROXY` variable.\n\nFor example, consider building the following Dockerfile using `--build-arg HTTP_PROXY=http://user:pass@proxy.lon.example.com`\n\nIn this case, the value of the `HTTP_PROXY` variable is not available in the `docker history` and is not cached. If you were to change location, and your proxy server changed to `http://user:pass@proxy.sfo.example.com`, a subsequent build does not result in a cache miss.\n\nIf you need to override this behaviour then you may do so by adding an `ARG` statement in the Dockerfile as follows:\n\nWhen building this Dockerfile, the `HTTP_PROXY` is preserved in the `docker history`, and changing its value invalidates the build cache.\n\n### [Automatic platform ARGs in the global scope](#automatic-platform-args-in-the-global-scope)\n\nThis feature is only available when using the [BuildKit](https://docs.docker.com/build/buildkit/) backend.\n\nBuildKit supports a predefined set of `ARG` variables with information on the platform of the node performing the build (build platform) and on the platform of the resulting image (target platform). The target platform can be specified with the `--platform` flag on `docker build`.\n\nThe following `ARG` variables are set automatically:\n\n*   `TARGETPLATFORM` - platform of the build result. Eg `linux/amd64`, `linux/arm/v7`, `windows/amd64`.\n*   `TARGETOS` - OS component of TARGETPLATFORM\n*   `TARGETARCH` - architecture component of TARGETPLATFORM\n*   `TARGETVARIANT` - variant component of TARGETPLATFORM\n*   `BUILDPLATFORM` - platform of the node performing the build.\n*   `BUILDOS` - OS component of BUILDPLATFORM\n*   `BUILDARCH` - architecture component of BUILDPLATFORM\n*   `BUILDVARIANT` - variant component of BUILDPLATFORM\n\nThese arguments are defined in the global scope so are not automatically available inside build stages or for your `RUN` commands. To expose one of these arguments inside the build stage redefine it without value.\n\nFor example:\n\n### [BuildKit built-in build args](#buildkit-built-in-build-args)\n\n| Arg | Type | Description |\n| --- | --- | --- |\n| `BUILDKIT_CACHE_MOUNT_NS` | String | Set optional cache ID namespace. |\n| `BUILDKIT_CONTEXT_KEEP_GIT_DIR` | Bool | Trigger Git context to keep the `.git` directory. |\n| `BUILDKIT_INLINE_CACHE`[2](#fn:2) | Bool | Inline cache metadata to image config or not. |\n| `BUILDKIT_MULTI_PLATFORM` | Bool | Opt into deterministic output regardless of multi-platform output or not. |\n| `BUILDKIT_SANDBOX_HOSTNAME` | String | Set the hostname (default `buildkitsandbox`) |\n| `BUILDKIT_SYNTAX` | String | Set frontend image |\n| `SOURCE_DATE_EPOCH` | Int | Set the Unix timestamp for created image and layers. More info from [reproducible builds](https://reproducible-builds.org/docs/source-date-epoch/). Supported since Dockerfile 1.5, BuildKit 0.11 |\n\n#### [Example: keep `.git` dir](#example-keep-git-dir)\n\nWhen using a Git context, `.git` dir is not kept on checkouts. It can be useful to keep it around if you want to retrieve git information during your build:\n\n### [Impact on build caching](#impact-on-build-caching)\n\n`ARG` variables are not persisted into the built image as `ENV` variables are. However, `ARG` variables do impact the build cache in similar ways. If a Dockerfile defines an `ARG` variable whose value is different from a previous build, then a \"cache miss\" occurs upon its first usage, not its definition. In particular, all `RUN` instructions following an `ARG` instruction use the `ARG` variable implicitly (as an environment variable), thus can cause a cache miss. All predefined `ARG` variables are exempt from caching unless there is a matching `ARG` statement in the Dockerfile.\n\nFor example, consider these two Dockerfile:\n\nIf you specify `--build-arg CONT_IMG_VER=<value>` on the command line, in both cases, the specification on line 2 doesn't cause a cache miss; line 3 does cause a cache miss. `ARG CONT_IMG_VER` causes the `RUN` line to be identified as the same as running `CONT_IMG_VER=<value> echo hello`, so if the `<value>` changes, you get a cache miss.\n\nConsider another example under the same command line:\n\nIn this example, the cache miss occurs on line 3. The miss happens because the variable's value in the `ENV` references the `ARG` variable and that variable is changed through the command line. In this example, the `ENV` command causes the image to include the value.\n\nIf an `ENV` instruction overrides an `ARG` instruction of the same name, like this Dockerfile:\n\nLine 3 doesn't cause a cache miss because the value of `CONT_IMG_VER` is a constant (`hello`). As a result, the environment variables and values used on the `RUN` (line 4) doesn't change between builds.\n\nThe `ONBUILD` instruction adds to the image a trigger instruction to be executed at a later time, when the image is used as the base for another build. The trigger will be executed in the context of the downstream build, as if it had been inserted immediately after the `FROM` instruction in the downstream Dockerfile.\n\nAny build instruction can be registered as a trigger.\n\nThis is useful if you are building an image which will be used as a base to build other images, for example an application build environment or a daemon which may be customized with user-specific configuration.\n\nFor example, if your image is a reusable Python application builder, it will require application source code to be added in a particular directory, and it might require a build script to be called after that. You can't just call `ADD` and `RUN` now, because you don't yet have access to the application source code, and it will be different for each application build. You could simply provide application developers with a boilerplate Dockerfile to copy-paste into their application, but that's inefficient, error-prone and difficult to update because it mixes with application-specific code.\n\nThe solution is to use `ONBUILD` to register advance instructions to run later, during the next build stage.\n\nHere's how it works:\n\n1.  When it encounters an `ONBUILD` instruction, the builder adds a trigger to the metadata of the image being built. The instruction doesn't otherwise affect the current build.\n2.  At the end of the build, a list of all triggers is stored in the image manifest, under the key `OnBuild`. They can be inspected with the `docker inspect` command.\n3.  Later the image may be used as a base for a new build, using the `FROM` instruction. As part of processing the `FROM` instruction, the downstream builder looks for `ONBUILD` triggers, and executes them in the same order they were registered. If any of the triggers fail, the `FROM` instruction is aborted which in turn causes the build to fail. If all triggers succeed, the `FROM` instruction completes and the build continues as usual.\n4.  Triggers are cleared from the final image after being executed. In other words they aren't inherited by \"grand-children\" builds.\n\nFor example you might add something like this:\n\n### [ONBUILD limitations](#onbuild-limitations)\n\n*   Chaining `ONBUILD` instructions using `ONBUILD ONBUILD` isn't allowed.\n*   The `ONBUILD` instruction may not trigger `FROM` or `MAINTAINER` instructions.\n*   `ONBUILD COPY --from` is [not supported](https://github.com/moby/buildkit/issues/816).\n\nThe `STOPSIGNAL` instruction sets the system call signal that will be sent to the container to exit. This signal can be a signal name in the format `SIG<NAME>`, for instance `SIGKILL`, or an unsigned number that matches a position in the kernel's syscall table, for instance `9`. The default is `SIGTERM` if not defined.\n\nThe image's default stopsignal can be overridden per container, using the `--stop-signal` flag on `docker run` and `docker create`.\n\nThe `HEALTHCHECK` instruction has two forms:\n\n*   `HEALTHCHECK [OPTIONS] CMD command` (check container health by running a command inside the container)\n*   `HEALTHCHECK NONE` (disable any healthcheck inherited from the base image)\n\nThe `HEALTHCHECK` instruction tells Docker how to test a container to check that it's still working. This can detect cases such as a web server stuck in an infinite loop and unable to handle new connections, even though the server process is still running.\n\nWhen a container has a healthcheck specified, it has a health status in addition to its normal status. This status is initially `starting`. Whenever a health check passes, it becomes `healthy` (whatever state it was previously in). After a certain number of consecutive failures, it becomes `unhealthy`.\n\nThe options that can appear before `CMD` are:\n\n*   `--interval=DURATION` (default: `30s`)\n*   `--timeout=DURATION` (default: `30s`)\n*   `--start-period=DURATION` (default: `0s`)\n*   `--start-interval=DURATION` (default: `5s`)\n*   `--retries=N` (default: `3`)\n\nThe health check will first run **interval** seconds after the container is started, and then again **interval** seconds after each previous check completes.\n\nIf a single run of the check takes longer than **timeout** seconds then the check is considered to have failed.\n\nIt takes **retries** consecutive failures of the health check for the container to be considered `unhealthy`.\n\n**start period** provides initialization time for containers that need time to bootstrap. Probe failure during that period will not be counted towards the maximum number of retries. However, if a health check succeeds during the start period, the container is considered started and all consecutive failures will be counted towards the maximum number of retries.\n\n**start interval** is the time between health checks during the start period. This option requires Docker Engine version 25.0 or later.\n\nThere can only be one `HEALTHCHECK` instruction in a Dockerfile. If you list more than one then only the last `HEALTHCHECK` will take effect.\n\nThe command after the `CMD` keyword can be either a shell command (e.g. `HEALTHCHECK CMD /bin/check-running`) or an exec array (as with other Dockerfile commands; see e.g. `ENTRYPOINT` for details).\n\nThe command's exit status indicates the health status of the container. The possible values are:\n\n*   0: success - the container is healthy and ready for use\n*   1: unhealthy - the container isn't working correctly\n*   2: reserved - don't use this exit code\n\nFor example, to check every five minutes or so that a web-server is able to serve the site's main page within three seconds:\n\nTo help debug failing probes, any output text (UTF-8 encoded) that the command writes on stdout or stderr will be stored in the health status and can be queried with `docker inspect`. Such output should be kept short (only the first 4096 bytes are stored currently).\n\nWhen the health status of a container changes, a `health_status` event is generated with the new status.\n\nThe `SHELL` instruction allows the default shell used for the shell form of commands to be overridden. The default shell on Linux is `[\"/bin/sh\", \"-c\"]`, and on Windows is `[\"cmd\", \"/S\", \"/C\"]`. The `SHELL` instruction must be written in JSON form in a Dockerfile.\n\nThe `SHELL` instruction is particularly useful on Windows where there are two commonly used and quite different native shells: `cmd` and `powershell`, as well as alternate shells available including `sh`.\n\nThe `SHELL` instruction can appear multiple times. Each `SHELL` instruction overrides all previous `SHELL` instructions, and affects all subsequent instructions. For example:\n\nThe following instructions can be affected by the `SHELL` instruction when the shell form of them is used in a Dockerfile: `RUN`, `CMD` and `ENTRYPOINT`.\n\nThe following example is a common pattern found on Windows which can be streamlined by using the `SHELL` instruction:\n\nThe command invoked by the builder will be:\n\nThis is inefficient for two reasons. First, there is an unnecessary `cmd.exe` command processor (aka shell) being invoked. Second, each `RUN` instruction in the shell form requires an extra `powershell -command` prefixing the command.\n\nTo make this more efficient, one of two mechanisms can be employed. One is to use the JSON form of the `RUN` command such as:\n\nWhile the JSON form is unambiguous and does not use the unnecessary `cmd.exe`, it does require more verbosity through double-quoting and escaping. The alternate mechanism is to use the `SHELL` instruction and the shell form, making a more natural syntax for Windows users, especially when combined with the `escape` parser directive:\n\nResulting in:\n\nThe `SHELL` instruction could also be used to modify the way in which a shell operates. For example, using `SHELL cmd /S /C /V:ON|OFF` on Windows, delayed environment variable expansion semantics could be modified.\n\nThe `SHELL` instruction can also be used on Linux should an alternate shell be required such as `zsh`, `csh`, `tcsh` and others.\n\nHere-documents allow redirection of subsequent Dockerfile lines to the input of `RUN` or `COPY` commands. If such command contains a [here-document](https://pubs.opengroup.org/onlinepubs/9699919799/utilities/V3_chap02.html#tag_18_07_04) the Dockerfile considers the next lines until the line only containing a here-doc delimiter as part of the same command.\n\n### [Example: Running a multi-line script](#example-running-a-multi-line-script)\n\nIf the command only contains a here-document, its contents is evaluated with the default shell.\n\nAlternatively, shebang header can be used to define an interpreter.\n\nMore complex examples may use multiple here-documents.\n\n### [Example: Creating inline files](#example-creating-inline-files)\n\nWith `COPY` instructions, you can replace the source parameter with a here-doc indicator to write the contents of the here-document directly to a file. The following example creates a `greeting.txt` file containing `hello world` using a `COPY` instruction.\n\nRegular here-doc [variable expansion and tab stripping rules](https://pubs.opengroup.org/onlinepubs/9699919799/utilities/V3_chap02.html#tag_18_07_04) apply. The following example shows a small Dockerfile that creates a `hello.sh` script file using a `COPY` instruction with a here-document.\n\nIn this case, file script prints \"hello bar\", because the variable is expanded when the `COPY` instruction gets executed.\n\nIf instead you were to quote any part of the here-document word `EOT`, the variable would not be expanded at build-time.\n\nNote that `ARG FOO=bar` is excessive here, and can be removed. The variable gets interpreted at runtime, when the script is invoked:\n\nFor examples of Dockerfiles, refer to:\n\n*   The [\"build images\" section](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/)\n*   The [\"get started\" tutorial](https://docs.docker.com/get-started/)\n*   The [language-specific getting started guides](https://docs.docker.com/language/)\n*   The [build guide](https://docs.docker.com/build/guide/)",
  "title": "Dockerfile reference | Docker Docs\n",
  "description": "Find all the available commands you can use in a Dockerfile and learn how to use them, including COPY, ARG, ENTRYPOINT, and more.",
  "languageCode": "en"
},
{
  "url": "https://docs.docker.com/engine/reference/commandline/buildx_build/",
  "markdown": "# docker buildx build | Docker Docs\n\n|     |     |\n| --- | --- |\n| Description | Start a build |\n| Usage | `docker buildx build [OPTIONS] PATH \\| URL \\| -` |\n| Aliases<br><br>An alias is a short or memorable alternative for a longer command. | `docker buildx b` |\n\nThe `buildx build` command starts a build using BuildKit. This command is similar to the UI of `docker build` command and takes the same flags and arguments.\n\nFor documentation on most of these flags, refer to the [`docker build` documentation](https://docs.docker.com/reference/cli/docker/image/build/). This page describes a subset of the new flags.\n\n| Option | Default | Description |\n| --- | --- | --- |\n| [`--add-host`](https://docs.docker.com/reference/cli/docker/image/build/#add-host) |     | Add a custom host-to-IP mapping (format: `host:ip`) |\n| [`--allow`](#allow) |     | Allow extra privileged entitlement (e.g., `network.host`, `security.insecure`) |\n| [`--annotation`](#annotation) |     | Add annotation to the image |\n| [`--attest`](#attest) |     | Attestation parameters (format: `type=sbom,generator=image`) |\n| [`--build-arg`](#build-arg) |     | Set build-time variables |\n| [`--build-context`](#build-context) |     | Additional build contexts (e.g., name=path) |\n| [`--cache-from`](#cache-from) |     | External cache sources (e.g., `user/app:cache`, `type=local,src=path/to/dir`) |\n| [`--cache-to`](#cache-to) |     | Cache export destinations (e.g., `user/app:cache`, `type=local,dest=path/to/dir`) |\n| `--call` | `build` | Set method for evaluating build (`check`, `outline`, `targets`) |\n| [`--cgroup-parent`](https://docs.docker.com/reference/cli/docker/image/build/#cgroup-parent) |     | Set the parent cgroup for the `RUN` instructions during build |\n| `--check` |     | Shorthand for `--call=check` |\n| `--detach` |     | experimental (CLI) Detach buildx server (supported only on linux) |\n| [`-f, --file`](https://docs.docker.com/reference/cli/docker/image/build/#file) |     | Name of the Dockerfile (default: `PATH/Dockerfile`) |\n| `--iidfile` |     | Write the image ID to a file |\n| `--label` |     | Set metadata for an image |\n| [`--load`](#load) |     | Shorthand for `--output=type=docker` |\n| [`--metadata-file`](#metadata-file) |     | Write build result metadata to a file |\n| `--network` |     | Set the networking mode for the `RUN` instructions during build |\n| `--no-cache` |     | Do not use cache when building the image |\n| [`--no-cache-filter`](#no-cache-filter) |     | Do not cache specified stages |\n| [`-o, --output`](#output) |     | Output destination (format: `type=local,dest=path`) |\n| [`--platform`](#platform) |     | Set target platform for build |\n| [`--progress`](#progress) | `auto` | Set type of progress output (`auto`, `plain`, `tty`, `rawjson`). Use plain to show container output |\n| [`--provenance`](#provenance) |     | Shorthand for `--attest=type=provenance` |\n| `--pull` |     | Always attempt to pull all referenced images |\n| [`--push`](#push) |     | Shorthand for `--output=type=registry` |\n| `-q, --quiet` |     | Suppress the build output and print image ID on success |\n| `--root` |     | experimental (CLI) Specify root directory of server to connect |\n| [`--sbom`](#sbom) |     | Shorthand for `--attest=type=sbom` |\n| [`--secret`](#secret) |     | Secret to expose to the build (format: `id=mysecret[,src=/local/secret]`) |\n| `--server-config` |     | experimental (CLI) Specify buildx server config file (used only when launching new server) |\n| [`--shm-size`](#shm-size) |     | Shared memory size for build containers |\n| [`--ssh`](#ssh) |     | SSH agent socket or keys to expose to the build (format: `default\\|<id>[=<socket>\\|<key>[,<key>]]`) |\n| [`-t, --tag`](https://docs.docker.com/reference/cli/docker/image/build/#tag) |     | Name and optionally a tag (format: `name:tag`) |\n| [`--target`](https://docs.docker.com/reference/cli/docker/image/build/#target) |     | Set the target build stage to build |\n| [`--ulimit`](#ulimit) |     | Ulimit options |\n\n### [Create annotations (--annotation)](#annotation)\n\nAdd OCI annotations to the image index, manifest, or descriptor. The following example adds the `foo=bar` annotation to the image manifests:\n\nYou can optionally add a type prefix to specify the level of the annotation. By default, the image manifest is annotated. The following example adds the `foo=bar` annotation the image index instead of the manifests:\n\nYou can specify multiple types, separated by a comma (,) to add the annotation to multiple image components. The following example adds the `foo=bar` annotation to image index, descriptors, manifests:\n\nYou can also specify a platform qualifier in square brackets (`[os/arch]`) in the type prefix, to apply the annotation to a subset of manifests with the matching platform. The following example adds the `foo=bar` annotation only to the manifest with the `linux/amd64` platform:\n\nWildcards are not supported in the platform qualifier; you can't specify a type prefix like `manifest[linux/*]` to add annotations only to manifests which has `linux` as the OS platform.\n\nFor more information about annotations, see [Annotations](https://docs.docker.com/build/building/annotations/).\n\n### [Create attestations (--attest)](#attest)\n\nCreate [image attestations](https://docs.docker.com/build/attestations/). BuildKit currently supports:\n\n*   `sbom` - Software Bill of Materials.\n    \n    Use `--attest=type=sbom` to generate an SBOM for an image at build-time. Alternatively, you can use the [`--sbom` shorthand](#sbom).\n    \n    For more information, see [here](https://docs.docker.com/build/attestations/sbom/).\n    \n*   `provenance` - SLSA Provenance\n    \n    Use `--attest=type=provenance` to generate provenance for an image at build-time. Alternatively, you can use the [`--provenance` shorthand](#provenance).\n    \n    By default, a minimal provenance attestation will be created for the build result, which will only be attached for images pushed to registries.\n    \n    For more information, see [here](https://docs.docker.com/build/attestations/slsa-provenance/).\n    \n\n### [Allow extra privileged entitlement (--allow)](#allow)\n\nAllow extra privileged entitlement. List of entitlements:\n\n*   `network.host` - Allows executions with host networking.\n*   `security.insecure` - Allows executions without sandbox. See [related Dockerfile extensions](https://docs.docker.com/reference/dockerfile/#run---security).\n\nFor entitlements to be enabled, the BuildKit daemon also needs to allow them with `--allow-insecure-entitlement` (see [`create --buildkitd-flags`](https://docs.docker.com/reference/cli/docker/buildx/create/#buildkitd-flags)).\n\n### [Set build-time variables (--build-arg)](#build-arg)\n\nSame as [`docker build` command](https://docs.docker.com/reference/cli/docker/image/build/#build-arg).\n\nThere are also useful built-in build arguments, such as:\n\n*   `BUILDKIT_CONTEXT_KEEP_GIT_DIR=<bool>`: trigger git context to keep the `.git` directory\n*   `BUILDKIT_INLINE_CACHE=<bool>`: inline cache metadata to image config or not\n*   `BUILDKIT_MULTI_PLATFORM=<bool>`: opt into deterministic output regardless of multi-platform output or not\n\nLearn more about the built-in build arguments in the [Dockerfile reference docs](https://docs.docker.com/reference/dockerfile/#buildkit-built-in-build-args).\n\n### [Additional build contexts (--build-context)](#build-context)\n\nDefine additional build context with specified contents. In Dockerfile the context can be accessed when `FROM name` or `--from=name` is used. When Dockerfile defines a stage with the same name it is overwritten.\n\nThe value can be a local source directory, [local OCI layout compliant directory](https://github.com/opencontainers/image-spec/blob/main/image-layout.md), container image (with docker-image:// prefix), Git or HTTP URL.\n\nReplace `alpine:latest` with a pinned one:\n\nExpose a secondary local source directory:\n\n#### [Use an OCI layout directory as build context](#source-oci-layout)\n\nSource an image from a local [OCI layout compliant directory](https://github.com/opencontainers/image-spec/blob/main/image-layout.md), either by tag, or by digest:\n\nThe OCI layout directory must be compliant with the [OCI layout specification](https://github.com/opencontainers/image-spec/blob/main/image-layout.md). You can reference an image in the layout using either tags, or the exact digest.\n\n### [Override the configured builder instance (--builder)](#builder)\n\nSame as [`buildx --builder`](https://docs.docker.com/reference/cli/docker/buildx/#builder).\n\n### [Use an external cache source for a build (--cache-from)](#cache-from)\n\nUse an external cache source for a build. Supported types are `registry`, `local`, `gha` and `s3`.\n\n*   [`registry` source](https://github.com/moby/buildkit#registry-push-image-and-cache-separately) can import cache from a cache manifest or (special) image configuration on the registry.\n*   [`local` source](https://github.com/moby/buildkit#local-directory-1) can import cache from local files previously exported with `--cache-to`.\n*   [`gha` source](https://github.com/moby/buildkit#github-actions-cache-experimental) can import cache from a previously exported cache with `--cache-to` in your GitHub repository\n*   [`s3` source](https://github.com/moby/buildkit#s3-cache-experimental) can import cache from a previously exported cache with `--cache-to` in your S3 bucket\n\nIf no type is specified, `registry` exporter is used with a specified reference.\n\n`docker` driver currently only supports importing build cache from the registry.\n\nMore info about cache exporters and available attributes: [https://github.com/moby/buildkit#export-cache](https://github.com/moby/buildkit#export-cache)\n\n### [Export build cache to an external cache destination (--cache-to)](#cache-to)\n\nExport build cache to an external cache destination. Supported types are `registry`, `local`, `inline`, `gha` and `s3`.\n\n*   [`registry` type](https://github.com/moby/buildkit#registry-push-image-and-cache-separately) exports build cache to a cache manifest in the registry.\n*   [`local` type](https://github.com/moby/buildkit#local-directory-1) exports cache to a local directory on the client.\n*   [`inline` type](https://github.com/moby/buildkit#inline-push-image-and-cache-together) writes the cache metadata into the image configuration.\n*   [`gha` type](https://github.com/moby/buildkit#github-actions-cache-experimental) exports cache through the [GitHub Actions Cache service API](https://github.com/tonistiigi/go-actions-cache/blob/master/api.md#authentication).\n*   [`s3` type](https://github.com/moby/buildkit#s3-cache-experimental) exports cache to a S3 bucket.\n\nThe `docker` driver only supports cache exports using the `inline` and `local` cache backends.\n\nAttribute key:\n\n*   `mode` - Specifies how many layers are exported with the cache. `min` on only exports layers already in the final build stage, `max` exports layers for all stages. Metadata is always exported for the whole build.\n\nMore info about cache exporters and available attributes: [https://github.com/moby/buildkit#export-cache](https://github.com/moby/buildkit#export-cache)\n\n### [Load the single-platform build result to `docker images` (--load)](#load)\n\nShorthand for [`--output=type=docker`](#docker). Will automatically load the single-platform build result to `docker images`.\n\n### [Write build result metadata to a file (--metadata-file)](#metadata-file)\n\nTo output build metadata such as the image digest, pass the `--metadata-file` flag. The metadata will be written as a JSON object to the specified file. The directory of the specified file must already exist and be writable.\n\n> **Note**\n> \n> Build record [provenance](https://docs.docker.com/build/attestations/slsa-provenance/#provenance-attestation-example) (`buildx.build.provenance`) includes minimal provenance by default. Set the `BUILDX_METADATA_PROVENANCE` environment variable to customize this behavior:\n> \n> *   `min` sets minimal provenance (default).\n> *   `max` sets full provenance.\n> *   `disabled`, `false` or `0` does not set any provenance.\n\n### [Ignore build cache for specific stages (--no-cache-filter)](#no-cache-filter)\n\nThe `--no-cache-filter` lets you specify one or more stages of a multi-stage Dockerfile for which build cache should be ignored. To specify multiple stages, use a comma-separated syntax:\n\nFor example, the following Dockerfile contains four stages:\n\n*   `base`\n*   `install`\n*   `test`\n*   `release`\n\nTo ignore the cache for the `install` stage:\n\nTo ignore the cache the `install` and `release` stages:\n\nThe arguments for the `--no-cache-filter` flag must be names of stages.\n\n### [Set the export action for the build result (-o, --output)](#output)\n\nSets the export action for the build result. In `docker build` all builds finish by creating a container image and exporting it to `docker images`. `buildx` makes this step configurable allowing results to be exported directly to the client, OCI image tarballs, registry etc.\n\nBuildx with `docker` driver currently only supports local, tarball exporter and image exporter. `docker-container` driver supports all the exporters.\n\nIf just the path is specified as a value, `buildx` will use the local exporter with this path as the destination. If the value is \"-\", `buildx` will use `tar` exporter and write to `stdout`.\n\n> \\*\\*Note \\*\\*\n> \n> Since BuildKit v0.13.0 multiple outputs can be specified by repeating the flag.\n\nSupported exported types are:\n\n#### [`local`](#local)\n\nThe `local` export type writes all result files to a directory on the client. The new files will be owned by the current user. On multi-platform builds, all results will be put in subdirectories by their platform.\n\nAttribute key:\n\n*   `dest` - destination directory where files will be written\n\n#### [`tar`](#tar)\n\nThe `tar` export type writes all result files as a single tarball on the client. On multi-platform builds all results will be put in subdirectories by their platform.\n\nAttribute key:\n\n*   `dest` - destination path where tarball will be written. â€œ-â€ writes to stdout.\n\n#### [`oci`](#oci)\n\nThe `oci` export type writes the result image or manifest list as an [OCI image layout](https://github.com/opencontainers/image-spec/blob/v1.0.1/image-layout.md) tarball on the client.\n\nAttribute key:\n\n*   `dest` - destination path where tarball will be written. â€œ-â€ writes to stdout.\n\n#### [`docker`](#docker)\n\nThe `docker` export type writes the single-platform result image as a [Docker image specification](https://github.com/docker/docker/blob/v20.10.2/image/spec/v1.2.md) tarball on the client. Tarballs created by this exporter are also OCI compatible.\n\nThe default image store in Docker Engine doesn't support loading multi-platform images. You can enable the containerd image store, or push multi-platform images is to directly push to a registry, see [`registry`](#registry).\n\nAttribute keys:\n\n*   `dest` - destination path where tarball will be written. If not specified, the tar will be loaded automatically to the local image store.\n*   `context` - name for the Docker context where to import the result\n\n#### [`image`](#image)\n\nThe `image` exporter writes the build result as an image or a manifest list. When using `docker` driver the image will appear in `docker images`. Optionally, image can be automatically pushed to a registry by specifying attributes.\n\nAttribute keys:\n\n*   `name` - name (references) for the new image.\n*   `push` - Boolean to automatically push the image.\n\n#### [`registry`](#registry)\n\nThe `registry` exporter is a shortcut for `type=image,push=true`.\n\n### [Set the target platforms for the build (--platform)](#platform)\n\nSet the target platform for the build. All `FROM` commands inside the Dockerfile without their own `--platform` flag will pull base images for this platform and this value will also be the platform of the resulting image.\n\nThe default value is the platform of the BuildKit daemon where the build runs. The value takes the form of `os/arch` or `os/arch/variant`. For example, `linux/amd64` or `linux/arm/v7`. Additionally, the `--platform` flag also supports a special `local` value, which tells BuildKit to use the platform of the BuildKit client that invokes the build.\n\nWhen using `docker-container` driver with `buildx`, this flag can accept multiple values as an input separated by a comma. With multiple values the result will be built for all of the specified platforms and joined together into a single manifest list.\n\nIf the `Dockerfile` needs to invoke the `RUN` command, the builder needs runtime support for the specified platform. In a clean setup, you can only execute `RUN` commands for your system architecture. If your kernel supports [`binfmt_misc`](https://en.wikipedia.org/wiki/Binfmt_misc) launchers for secondary architectures, buildx will pick them up automatically. Docker desktop releases come with `binfmt_misc` automatically configured for `arm64` and `arm` architectures. You can see what runtime platforms your current builder instance supports by running `docker buildx inspect --bootstrap`.\n\nInside a `Dockerfile`, you can access the current platform value through `TARGETPLATFORM` build argument. Refer to the [`docker build` documentation](https://docs.docker.com/reference/dockerfile/#automatic-platform-args-in-the-global-scope) for the full description of automatic platform argument variants .\n\nYou can find the formatting definition for the platform specifier in the [containerd source code](https://github.com/containerd/containerd/blob/v1.4.3/platforms/platforms.go#L63).\n\n### [Set type of progress output (--progress)](#progress)\n\nSet type of progress output (`auto`, `plain`, `tty`, `rawjson`). Use `plain` to show container output (default `auto`).\n\n> **Note**\n> \n> You can also use the `BUILDKIT_PROGRESS` environment variable to set its value.\n\nThe following example uses `plain` output during the build:\n\n> **Note**\n> \n> Check also the [`BUILDKIT_COLORS`](https://docs.docker.com/build/building/variables/#buildkit_colors) environment variable for modifying the colors of the terminal output.\n\nThe `rawjson` output marshals the solve status events from BuildKit to JSON lines. This mode is designed to be read by an external program.\n\n### [Create provenance attestations (--provenance)](#provenance)\n\nShorthand for [`--attest=type=provenance`](#attest), used to configure provenance attestations for the build result. For example, `--provenance=mode=max` can be used as an abbreviation for `--attest=type=provenance,mode=max`.\n\nAdditionally, `--provenance` can be used with Boolean values to enable or disable provenance attestations. For example, `--provenance=false` disables all provenance attestations, while `--provenance=true` enables all provenance attestations.\n\nBy default, a minimal provenance attestation will be created for the build result. Note that the default image store in Docker Engine doesn't support attestations. Provenance attestations only persist for images pushed directly to a registry if you use the default image store. Alternatively, you can switch to using the containerd image store.\n\nFor more information about provenance attestations, see [here](https://docs.docker.com/build/attestations/slsa-provenance/).\n\n### [Push the build result to a registry (--push)](#push)\n\nShorthand for [`--output=type=registry`](#registry). Will automatically push the build result to registry.\n\n### [Create SBOM attestations (--sbom)](#sbom)\n\nShorthand for [`--attest=type=sbom`](#attest), used to configure SBOM attestations for the build result. For example, `--sbom=generator=<user>/<generator-image>` can be used as an abbreviation for `--attest=type=sbom,generator=<user>/<generator-image>`.\n\nAdditionally, `--sbom` can be used with Boolean values to enable or disable SBOM attestations. For example, `--sbom=false` disables all SBOM attestations.\n\nNote that the default image store in Docker Engine doesn't support attestations. Provenance attestations only persist for images pushed directly to a registry if you use the default image store. Alternatively, you can switch to using the containerd image store.\n\nFor more information, see [here](https://docs.docker.com/build/attestations/sbom/).\n\n### [Secret to expose to the build (--secret)](#secret)\n\nExposes secrets (authentication credentials, tokens) to the build. A secret can be mounted into the build using a `RUN --mount=type=secret` mount in the [Dockerfile](https://docs.docker.com/reference/dockerfile/#run---mounttypesecret). For more information about how to use build secrets, see [Build secrets](https://docs.docker.com/build/building/secrets/).\n\nSupported types are:\n\n*   [`file`](#file)\n*   [`env`](#env)\n\nBuildx attempts to detect the `type` automatically if unset.\n\n#### [`file`](#file)\n\nAttribute keys:\n\n*   `id` - ID of the secret. Defaults to base name of the `src` path.\n*   `src`, `source` - Secret filename. `id` used if unset.\n\n#### [`env`](#env)\n\nAttribute keys:\n\n*   `id` - ID of the secret. Defaults to `env` name.\n*   `env` - Secret environment variable. `id` used if unset, otherwise will look for `src`, `source` if `id` unset.\n\n### [Shared memory size for build containers (--shm-size)](#shm-size)\n\nSets the size of the shared memory allocated for build containers when using `RUN` instructions.\n\nThe format is `<number><unit>`. `number` must be greater than `0`. Unit is optional and can be `b` (bytes), `k` (kilobytes), `m` (megabytes), or `g` (gigabytes). If you omit the unit, the system uses bytes.\n\n> **Note**\n> \n> In most cases, it is recommended to let the builder automatically determine the appropriate configurations. Manual adjustments should only be considered when specific performance tuning is required for complex build scenarios.\n\n### [SSH agent socket or keys to expose to the build (--ssh)](#ssh)\n\nThis can be useful when some commands in your Dockerfile need specific SSH authentication (e.g., cloning a private repository).\n\n`--ssh` exposes SSH agent socket or keys to the build and can be used with the [`RUN --mount=type=ssh` mount](https://docs.docker.com/reference/dockerfile/#run---mounttypessh).\n\nExample to access Gitlab using an SSH agent socket:\n\n### [Set ulimits (--ulimit)](#ulimit)\n\n`--ulimit` overrides the default ulimits of build's containers when using `RUN` instructions and are specified with a soft and hard limit as such: `<type>=<soft limit>[:<hard limit>]`, for example:\n\n> **Note**\n> \n> If you don't provide a `hard limit`, the `soft limit` is used for both values. If no `ulimits` are set, they're inherited from the default `ulimits` set on the daemon.\n\n> **Note**\n> \n> In most cases, it is recommended to let the builder automatically determine the appropriate configurations. Manual adjustments should only be considered when specific performance tuning is required for complex build scenarios.",
  "title": "docker buildx build | Docker Docs\n",
  "description": "",
  "languageCode": "en"
}]