[
  {
    "url": "https://www.rudderstack.com/docs/profiles/permissions/",
    "markdown": "# Warehouse Permissions | RudderStack Docs\n\nGrant RudderStack the required permissions on your data warehouse.\n\n* * *\n\n*     7 minute read  \n    \n\nRudderStack supports **Snowflake**, **Redshift**, **Databricks**, and **BigQuery** for creating unified user profiles.\n\nTo read and write data to the warehouse, RudderStack requires specific warehouse permissions as explained in the following sections.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Keeping separate schemas for projects running via CLI and web is recommended. This way projects run from the CLI will never risk overwriting your production data.\n\n## Snowflake\n\nSnowflake uses a combination of DAC and RBAC models for [access control](https://docs.snowflake.com/en/user-guide/security-access-control-overview.html). However, RudderStack chooses an RBAC-based access control mechanism as multiple users can launch the [Profile Builder CLI](https://www.rudderstack.com/docs/profiles/get-started/profile-builder/).\n\nAlso, it is not ideal to tie the result of an individual user run with that user. Hence, it is recommended to create a generic role (for example, `PROFILES_ROLE`) with the following privileges:\n\n*   Read access to all the inputs to the model (can be shared in case of multiple schemas/tables).\n*   Write access to the schemas and common tables as the PB project creates material (output) tables.\n\nIf you want to access any material created from the project run, the role (`PROFILES_ROLE`) must also have read access to all of those schemas.\n\nBelow are some sample commands which grant the required privileges to the role (`PROFILES_ROLE`) in a Snowflake warehouse:\n\n```\n-- Create role\nCREATE ROLE PROFILES_ROLE;\nSHOW ROLES; -- To validate\n```\n\n```\n-- Create user\nCREATE USER PROFILES_TEST_USER PASSWORD='<StrongPassword>' DEFAULT_ROLE='PROFILES_ROLE';\nSHOW USERS; -- To validate\n```\n\n```\n-- Grant role to user and database\nGRANT ROLE PROFILES_ROLE TO USER PROFILES_TEST_USER;\nGRANT USAGE ON DATABASE YOUR_RUDDERSTACK_DB TO ROLE PROFILES_ROLE;\n```\n\n```\n-- Create separate schema for Profiles and grant privileges to role\nCREATE SCHEMA YOUR_RUDDERSTACK_DB.RS_PROFILES;\nGRANT ALL PRIVILEGES ON SCHEMA YOUR_RUDDERSTACK_DB.RS_PROFILES TO ROLE PROFILES_ROLE;\nGRANT USAGE ON WAREHOUSE RUDDER_WAREHOUSE TO ROLE PROFILES_ROLE;\nGRANT USAGE ON SCHEMA YOUR_RUDDERSTACK_DB.EVENTSSCHEMA TO ROLE PROFILES_ROLE;\n```\n\nFor accessing input sources, you can individually grant select on tables/views, or give blanket grant to all in a schema.\n\n```\n-- Assuming we want read access to tables/views in schema EVENTSSCHEMA\nGRANT SELECT ON ALL TABLES IN SCHEMA YOUR_RUDDERSTACK_DB.RS_PROFILES TO PROFILES_ROLE;\nGRANT SELECT ON FUTURE TABLES IN SCHEMA YOUR_RUDDERSTACK_DB.RS_PROFILES TO PROFILES_ROLE;\nGRANT SELECT ON ALL VIEWS IN SCHEMA YOUR_RUDDERSTACK_DB.RS_PROFILES TO PROFILES_ROLE;\nGRANT SELECT ON FUTURE VIEWS IN SCHEMA YOUR_RUDDERSTACK_DB.RS_PROFILES TO PROFILES_ROLE;\n```\n\n```\n-- Assuming we want read access to tracks and identifies tables in schema EVENTSSCHEMA\nGRANT SELECT ON TABLE YOUR_RUDDERSTACK_DB.RS_PROFILES.TRACKS TO PROFILES_ROLE;\nGRANT SELECT ON TABLE YOUR_RUDDERSTACK_DB.RS_PROFILES.IDENTIFIES TO PROFILES_ROLE;\n```\n\n## Redshift\n\nSuppose the inputs/edge sources are in a single schema `website_eventstream` and the name of the newly created Profiles user is `rudderstack_admin`. In this case, the requirements are as follows:\n\n*   A separate schema `rs_profiles` (to store all the common and output tables).\n*   The `rudderstack_admin` user should have all the privileges on the above schema and the associated tables.\n*   The `rudderstack_admin` user should have `USAGE` privilege on schemas that have the edge sources and input tables (`website_eventstream`) and read (`SELECT`) privileges on specific tables as well. This privilege can extend to the migration schema and other schemas from where data from warehouses comes in.\n*   The `rudderstack_admin` user should have privileges to use `plpythonu` to create some UDFs.\n\nThe sample commands are as follows:\n\n```\nCREATE USER rudderstack_admin WITH PASSWORD '<strong_unique_password>';\nCREATE SCHEMA rs_profiles;\nGRANT ALL ON SCHEMA \"rs_profiles\" TO rudderstack_admin;\nGRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA \"rs_profiles\" TO rudderstack_admin;\nGRANT USAGE ON SCHEMA \"website_eventstream\" TO rudderstack_admin;\nGRANT USAGE ON LANGUAGE plpythonu TO rudderstack_admin;\n```\n\n```\nGRANT SELECT ON ALL TABLES IN SCHEMA \"website_eventstream\" TO rudderstack_admin;\n```\n\nTo give access to only specific input tables/views referred in your Profiles project, use the below command:\n\n```\nGRANT SELECT ON TABLE \"<YOUR_SCHEMA>\".\"<YOUR_TABLE>\" TO rudderstack_admin;\n```\n\n### Supported inputs\n\nRudderStack supports the following input types for Redshift warehouse/serverless:\n\n*   Redshift cluster with DC2 type nodes with following types as inputs:\n    *   Redshift internal tables\n    *   External schema and tables only for inputs (not supported as output)\n    *   CSV files stored on S3 as inputs\n*   Redshift cluster with RA3 type nodes with following types as inputs:\n    *   Redshift internal tables\n    *   External schema and tables only for inputs (not supported as output)\n    *   CSV files stored on S3 as inputs\n    *   Cross DB input tables\n*   Redshift serverless with following types as inputs:\n    *   Redshift internal tables\n    *   External schema and tables (not supported as output)\n    *   CSV files stored on S3 as inputs\n    *   Cross DB input tables RudderStack also supports various authentication mechanisms to authenticate the user running the Profiles project. Refer [Redshift warehouse connection](https://www.rudderstack.com/docs/profiles/get-started/profile-builder/#2-create-warehouse-connection) for more information.\n\n## Databricks\n\n1.  Open the Databricks UI.\n2.  Create a new user.\n3.  Reuse an existing catalog or create a new one by clicking **Create Catalog**.\n4.  Grant `USE SCHEMA` privilege on the catalog.\n5.  Create a separate schema to write objects created by RudderStack Profiles.\n6.  Grant all privileges on this schema.\n7.  Grant privileges to access relevant schemas for the input tables. For example, if an input schema is in a schema named `website_eventstream`, then you can run the following commands to assign a blanket grant to all schemas or only specific tables/views referred in your Profiles project:\n\n```\nCREATE USER rudderstack_admin WITH PASSWORD <strong_unique_password>;\nGRANT USE SCHEMA ON CATALOG <catalog name> TO rudderstack_admin;\nCREATE SCHEMA RS_PROFILES;\nGRANT ALL PRIVILEGES ON SCHEMA RS_PROFILES TO rudderstack_admin;\nGRANT SELECT ON SCHEMA website_eventstream TO rudderstack_admin;\n```\n\n```\nGRANT SELECT ON ALL TABLES IN SCHEMA \"website_eventstream\" TO rudderstack_admin;\n```\n\nTo give access to only specific input tables/views referred in your Profiles project, use the below command:\n\n```\nGRANT SELECT ON TABLE public.input_table TO rudderstack_admin; \n```\n\n## BigQuery\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> For BigQuery, RudderStack recommends you to use a view instead of table for streaming data sets.\n\nYou must first assign the `BigQuery Job User` role to your service account. To do so:\n\n1.  Open the [BigQuery UI](https://console.cloud.google.com/) (Google Cloud Console).\n2.  Select **IAM & Admin** > **IAM** from the left sidebar.\n3.  Click **GRANT ACCESS** to grant permissions to your service account.\n4.  Enter your service account email in the **New principals** field.\n5.  In the **Assign roles** section, select `BigQuery Job User` role from the role list.\n6.  Click **Save**.\n\nAlternatively, you can add the following **IAM Policy Binding**:\n\n```\n{\n  \"bindings\": [\n    {\n      \"role\": \"roles/bigquery.jobUser\",\n      \"members\": [\n        \"serviceAccount:your-service-account@your-project.iam.gserviceaccount.com\"\n      ]\n    }\n  ]\n}\n```\n\nFurther, assign the dataset or project level roles to your service account:\n\n1.  Open the [BigQuery UI](https://console.cloud.google.com/) (Google Cloud Console).\n2.  Select **BigQuery** from the sidebar.\n3.  Select the dataset from your schema to which you want to grant access.\n4.  In the **Dataset info** window, click **SHARING** > **Permissions**.\n5.  Click **Add Principal**.\n6.  Enter the service account email in the **New principals** field.\n7.  In the **Assign roles** section, select the following roles from the role list:\n    *   **BigQuery Data Viewer**: Allows read access to the dataset.\n    *   **BigQuery Data Editor**: Allows read and write access to the dataset.\n\nAlternatively, you can add the following **IAM Policy Binding**:\n\n```\n{\n  \"bindings\": [\n    {\n      \"role\": \"roles/bigquery.dataViewer\",\n      \"members\": [\n        \"serviceAccount:your-service-account@your-project.iam.gserviceaccount.com\"\n      ],\n      \"condition\": {\n        \"title\": \"Access to dataset1\",\n        \"description\": \"Allow data viewing access to dataset1\",\n        \"expression\": \"resource.name.startsWith('projects/your-project-id/datasets/dataset1')\"\n      }\n    },\n    {\n      \"role\": \"roles/bigquery.dataEditor\",\n      \"members\": [\n        \"serviceAccount:your-service-account@your-project.iam.gserviceaccount.com\"\n      ],\n      \"condition\": {\n        \"title\": \"Access to dataset2\",\n        \"description\": \"Allow data editing access to dataset2\",\n        \"expression\": \"resource.name.startsWith('projects/your-project-id/datasets/dataset2')\"\n      }\n    }\n  ]\n}\n```\n\nIf you have input relations in many datasets from a single project, you can assign the required privileges for the complete Google Cloud project. This allows your service account to access the relation from all the datasets of the project.\n\n1.  Open the [BigQuery UI](https://console.cloud.google.com/) (Google Cloud Console).\n2.  Select **IAM & Admin** > **IAM** from the left sidebar.\n3.  Click **GRANT ACCESS** to grant permissions to your service account.\n4.  Enter the service account email in the **New principals** field.\n5.  In the **Assign roles** section, select the following roles from the role list:\n    *   **BigQuery Data Viewer**: Allows read access to the dataset.\n    *   **BigQuery Data Editor**: Allows read and write access to the dataset.\n\nAlternatively, you can add the following **IAM Policy Binding**:\n\n```\n{\n  \"bindings\": [\n    {\n      \"role\": \"roles/bigquery.dataViewer\",\n      \"members\": [\n        \"serviceAccount:your-service-account@your-project.iam.gserviceaccount.com\"\n      ]\n    },\n    {\n      \"role\": \"roles/bigquery.dataEditor\",\n      \"members\": [\n        \"serviceAccount:your-service-account@your-project.iam.gserviceaccount.com\"\n      ]\n    }\n  ]\n}\n```\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Warehouse Permissions | RudderStack Docs",
    "description": "Grant RudderStack the required permissions on your data warehouse.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/core-concepts/identity-stitching/",
    "markdown": "# Identity Stitching | RudderStack Docs\n\nStitch multiple identifiers together to create a unified and comprehensive profile.\n\n* * *\n\n*     4 minute read  \n    \n\nIdentity stitching combines unique identifiers across your digital touchpoints to identify users and create a unified, omnichannel view of your customers. Using this feature, you can:\n\n*   **Understand user behavior**: Consolidate and connect customer data from various sources to better understand customers’ preferences, behaviors, and interactions across multiple touchpoints.\n*   **Provide personalized support**: Deliver personalized marketing messages and experiences to your customers. Ensures that the right message reaches the right person at the right time, increasing the effectiveness of marketing campaigns.\n*   **Enrich user profile with features**: Enhance user profiles with additional data points and features. These features can include demographic information, preferences, purchase history, browsing behavior, or any other static or computed data points.\n\n## Problem of multiple identities\n\nCompanies gather user data across digital touchpoints like websites, mobile apps, enterprise systems like CRMs, marketing platforms, etc. During this process, a single user is identified with multiple identifiers across their product journey, like their email ID, phone number, device ID, anonymous ID, and more. Also, the user information is spread across dozens of devices, accounts, or products as they often change their devices and use work and personal emails together.\n\nThe user data stored in the warehouse contains unstructured objects that represent one or more user (or entity) identities. Competitive businesses need to clarify this mess of data points into an accurate model of customer behavior and build personalized relationships.\n\nTo create a unified user profile, it is essential to correlate all of the different user identifiers into one canonical identifier so that all the data related to a particular user or entity can be associated with that user or entity.\n\nThis unification step, called **Identity Stitching**, ties all the user data from these tables into a unified view, giving you a 360-degree view of the user.\n\n## Perform identity stitching\n\nYou can use the RudderStack’s [identity stitching model](https://www.rudderstack.com/docs/profiles/example/id-stitcher/) to define the identifiers you want to combine together. You can also define the input sources, like [Event Stream](https://www.rudderstack.com/docs/sources/event-streams/), [Cloud Extract](https://www.rudderstack.com/docs/sources/extract/) sources, which automatically produce an identity graph because all the schemas and unique identifiers are known.\n\n## Unify identities across all platforms and devices\n\nIdentity stitching is the process of matching different identifiers across multiple devices, digital touchpoints, and other data (like offline point-of-sale interactions) to build a comprehensive identity graph. This identity graph includes nodes (identifiers) and their relationships (edges), and it is generated as a transparent table in the warehouse.\n\nRudderStack performs identity stitching by mapping all the unique identifiers into a single canonical ID (for example, `rudder_id`), then uses that ID to make user feature development easier (for example, summing the payment events against a single `rudder_id`).\n\n[![single identity created from different identities](https://www.rudderstack.com/docs/images/profiles/id-stitching.webp)](https://www.rudderstack.com/docs/images/profiles/id-stitching.webp)\n\n## Identity graph\n\nIdentity stitching starts with the creation of an identity graph. The identity graph is a database housing the entity identifiers where you can identify and connect details related to your customer journeys. Further, it stitches them together in one customer profile representing their whole identity.\n\nThe most fundamental data in an identity graph is the ID tag associated with a device, account, network, session, transaction, or any other anonymous identifier that can engage with your company. Once you’ve collected this data and associated it with a single customer identity (wherever possible), your customer data becomes more reliable, and you can move on to achieve higher goals.\n\nAn identity graph incorporates models that help it in ingesting new information. As you add a new data point with whatever connections are immediately known, the graph database determines if it fits into any existing customer identifier. If there is a clear link - such as a matching device ID or conclusive biographical data like a credit card number - the graph incorporates the data into a relevant user node.\n\n[![identity graph](https://www.rudderstack.com/docs/images/profiles/identity-graph.webp)](https://www.rudderstack.com/docs/images/profiles/identity-graph.webp)\n\n## Notable features\n\n*   Use different input sources like RudderStack’s [Event Stream](https://www.rudderstack.com/docs/sources/event-streams/), [Cloud Extract](https://www.rudderstack.com/docs/sources/extract/) sources, or any existing tables in the warehouse.\n*   Merge identities for entities like a user, customer, product, business account, etc.\n*   Stitch identities from all the required channels like web, mobile, marketing platforms, etc.\n*   Use identity stitching results to develop user features and deliver personalized campaigns.\n\n#### See also\n\n*   [Sample identity stitching project](https://www.rudderstack.com/docs/profiles/example/id-stitcher/)\n*   [Problem of Identity resolution](https://www.rudderstack.com/blog/the-tale-of-identity-graph-and-identity-resolution/)\n*   [How to achieve ID mapping in a data warehouse](https://www.rudderstack.com/blog/identity-graph-and-identity-resolution-in-sql/)\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Identity Stitching | RudderStack Docs",
    "description": "Stitch multiple identifiers together to create a unified and comprehensive profile.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/get-started/sample-data/",
    "markdown": "# Snowflake Sample Data | RudderStack Docs\n\nSample data for Snowflake\n\n* * *\n\n*     2 minute read  \n    \n\nRudderStack provides a sample data set for the Snowflake warehouse, available in the [Snowflake marketplace](https://app.snowflake.com/marketplace/listing/GZT0Z856CMJ/rudderstack-inc-rudderstack-event-data-for-quickstart). You can use this data to run the Profiles project and [Predictive features](https://www.rudderstack.com/docs/profiles/predictions/) through the UI or the CLI.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The number of columns in this data set are intentionally limited to make the data set easily understandable. Also, all email addresses are generated randomly and no PII is used in the generation of this data set.\n\nThe following tables, properties, and user information is included in the data set:\n\n## Tables\n\nThis data set includes below-mentioned RudderStack event data tables:\n\n*   `PAGES` - Page view events from anonymous and known users.\n*   `TRACKS` - Summarized tracked user actions (like `login`, `signup`, `order_completed`, etc.).\n*   `IDENTIFIES` - Identify calls run when a user provides a unique identifier (i.e., upon `signup`).\n*   `ORDER_COMPLETED` - Detailed payloads from tracked `order_completed` events.\n\nAs of January 2023, here are the approximate number of rows in each table:\n\n*   `PAGES`: ~43k\n*   `TRACKS`: ~14k\n*   `IDENTIFIES`: ~4.8k\n*   `ORDER_COMPLETED`: ~2.2k\n\nThese volumes follow the pattern of a normal eCommerce conversion funnel (pageview, signup, order). Specifically, here’s a rough breakdown of the user journey by volume:\n\n*   30% - Never sign in\n*   10% - Sign in but never add an item to cart\n*   40% - Add to cart and abandon\n*   20% - Make purchases\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Note that this data includes _future_ data until Apr 2024, and starts in June 2023. This is to ensure that future users can still run the project with ‘current’ data. RudderStack team will refresh the data periodically throughout the year.\n\n## Properties\n\nThis data set includes a _subset_ of the standard properties found in the [Warehouse schema spec](https://www.rudderstack.com/docs/destinations/warehouse-destinations/warehouse-schema/) for each table. The required columns for running Profiles and Predictions projects are also present.\n\n### User information\n\nThe user data includes a subset of our standard properties for `identify` calls.\n\nThis data set contains a total of ~10k unique users by `anonymousId`. About half of these unique users (~4.8k) are known users (with an associated `identify` call).\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Snowflake Sample Data | RudderStack Docs",
    "description": "Sample data for Snowflake",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/cli-user-guide/structure/",
    "markdown": "# Project Structure | RudderStack Docs\n\nKnow the specifications of a site configuration file, PB project structure, configuration files, and their parameters.\n\n* * *\n\n*     11 minute read  \n    \n\nOnce you complete the [Profile Builder CLI](https://www.rudderstack.com/docs/profiles/get-started/profile-builder/) steps, you will be able to see the Profiles project on your machine.\n\n## Site configuration file\n\nRudderStack creates a site configuration file (`~/.pb/siteconfig.yaml`) while [creating a warehouse connection](https://www.rudderstack.com/docs/profiles/get-started/profile-builder/#2-create-warehouse-connection). It contains the following details including secrets (if any):\n\n*   Warehouse connection details and its credentials.\n*   Git repository connection credentials (if any). See [Associate SSH Key to Git Project](https://www.rudderstack.com/docs/profiles/example/packages/#associate-ssh-key-to-git-project) for more information.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> If you have multiple Profiles projects and they use different warehouse connections, you can store the details for multiple connections in the same site configuration file.\n\nA sample site configuration file containing multiple warehouse connection details is shown below:\n\n```\nconnections:\n  prod-db-profile:\n      target: dev\n      outputs:\n          dev:\n              account: inb828.us-west-3\n              dbname: MAT_STORE\n              password: password\n              role: PROFILES_ROLE\n              schema: AB_SCHEMA\n              type: snowflake\n              user: rik\n              warehouse: PROD_WAREHOUSE\n  test-db-profile:\n      target: test\n      outputs:\n          db:\n              access_token: dabasihasdho\n              catalog: rs_dev\n              host: adb-98.18.azuredatabricks.net\n              http_endpoint: /sql/1.0/warehouses/919uasdn92h\n              port: 443\n              schema: rs_profiles\n              type: databricks\n              user: johndoe@abc.onmicrosoft.com\n          dev:\n              account: uk12.us-west-1\n              dbname: RUDDERSTACK_DB\n              password: password\n              role: RS_ROLE\n              schema: RS_PROFILES\n              type: snowflake\n              user: johndoe\n              warehouse: RS_WAREHOUSE\n          snowflake-keypair: # example of an unencrypted Snowflake key-pair\n              type: snowflake\n              account: vb8.us-east-1\n              dbname: PROD_DB\n              role: PROFILES_ROLE\n              warehouse: RUDDER\n              schema: RS_PROFILES\n              user: PROFILES_USER_UNC\n              useKeyPairAuth: true\n              privateKey: -----BEGIN PRIVATE KEY----- ..keyvalue.. -----END PRIVATE KEY-----\n          snowflake-encrypted-keypair: # example of an encrypted Snowflake key-pair\n              type: snowflake\n              account: vb8.us-east-1\n              dbname: PROD_DB\n              role: PROFILES_ROLE\n              warehouse: RUDDER\n              schema: RS_PROFILES\n              user: PROFILES_USER_EC\n              useKeyPairAuth: true\n              privateKey: -----BEGIN ENCRYPTED PRIVATE KEY----- ..keyvalue.. -----END ENCRYPTED PRIVATE KEY-----\n              privateKeyPassphrase: valuegoeshere!\n          redshift_v1:\n              dbname: warehouse_rs\n              host: warehouse.abc.us-east-3.redshift.amazonaws.com\n              password: password\n              port: 5419\n              schema: rs_profiles\n              type: redshift\n              user: redshift_user\n          redshift_v2:\n              workgroup_name: warehouse_workgroup\n              region: us-east-1\n              driver: v2\n              sslmode: require\n              dbname: warehouse_rs\n              schema: rs_profiles\n              type: redshift\n              access_key_id: ******************\n              secret_access_key: ******************************\n           big:\n              credentials:\n                auth_provider_x509_cert_url: https://www.googleapis.com/oauth2/v1/certs\n                auth_uri: https://accounts.google.com/o/oauth2/auth\n                client_email: johndoe@big-query-integration-poc.iam.gserviceaccount.com\n                client_id: \"123345678909872\"\n                client_x509_cert_url: https://www.googleapis.com/robot/v1/metadata/x509/johndoe%40big-query-integration-poc.iam.gserviceaccount.com\n                private_key: |\n                    -----BEGIN PRIVATE KEY-----                    \n                   ## private key\n                    -----END PRIVATE KEY-----\n                private_key_id: 5271368bhjbd72y278222e233w23e231e\n              project_id: big-query-integration-poc\n                token_uri: https://oauth2.googleapis.com/token\n                type: service_account\n                project_id: rs_profiles\n              schema: rs_profiles\n              type: bigquery\n              user: johndoe@big-query-integration-poc.iam.gserviceaccount.com\ngitcreds:\n - reporegex: \"git@github.com:REPO_OWNER/*\" # in case of ssh url\n   key: |\n       -----BEGIN OPENSSH PRIVATE KEY-----\n       **********************************************************************\n       **********************************************************************\n       **********************************************************************\n       **********************************************************************\n       ****************************************************************\n       -----END OPENSSH PRIVATE KEY-----       \n - reporegex: \"https://github.com/rudderlabs/*\" # https url\n   basic_auth:\n     username: oauth2\n     password: ... # your personal access token with read permission\npy_models:\n    enabled: true # in case you are using Python models in your project, else set it to false\n    python_path: /opt/anaconda3/bin/python # the path where Python is installed (run `which python` to get the full path). If `py_models` is not enabled, set it to `\"\"`. For Windows, you may pass the path value as: python.exe\n    credentials_presets: null\n    allowed_git_urls_regex: \"\"\ncache_dir: /Users/YOURNAME/.pb/WhtGitCache/ # For Windows, the directory path will have forward slash (\\)\nfilepath: /Users/YOURNAME/.pb/siteconfig.yaml # For Windows, the file path will have forward slash (\\)\n```\n\n## Profiles project structure\n\nThe following image shows the folder structure of the project:\n\n[![Project structure](https://www.rudderstack.com/docs/images/profiles/project-structure.webp)](https://www.rudderstack.com/docs/images/profiles/project-structure.webp)\n\n### `pb_project.yaml`\n\nThe `pb_project.yaml` file contains the project details like the name, schema version, warehouse connection, [entityEntity refers to a digital representation of a class of real world distinct objects for which you can create a profile.](https://www.rudderstack.com/docs/resources/glossary/#entity) names along with ID types, etc.\n\nA sample `pb_project.yaml` file with entity type as `user`:\n\n```\n# Project name\nname: sample_attribution\n\n# Project's yaml schema version\nschema_version: 69\n\n# WH Connection to use\nconnection: test\n\n# Model folders to use\nmodel_folders:\n  - models\n\n# Entities in the project and their ids\nentities:\n  - name: user\n    # Change the following to set a custom ID stitcher(optional).\n    # id_stitcher: models/user_id_stitcher\n    id_types:\n      - main_id\n      - user_id\n      - anonymous_id\n      - email\n    # Feature views - to get all features/traits of an entity into a single view (optional)\n    feature_views: \n      using_ids: \n        - id: user_id \n          name: with_user_id\n          \n# lib packages can be imported to signify that this project's properties are inherited\npackages:\n  - name: corelib\n    url: \"https://github.com/rudderlabs/rudderstack-profiles-corelib/tag/schema_{{best_schema_version}}\"\n\n# Profiles can also use certain model types defined in Python.\n# Examples include ML models. Those dependencies are specified here.\npython_requirements:\n  - profiles-pycorelib==0.1.0\n```\n\nThe following table explains the fields used in the above file:\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `name` | String | Name of the project. |\n| `schema_version` | Integer | Project’s YAML version. Each new schema version comes with improvements and added functionalities. |\n| `connection` | String | Connection name from [`siteconfig.yaml`](https://www.rudderstack.com/docs/profiles/cli-user-guide/structure/) used for connecting to the warehouse. |\n| `model_folders` | String | Names of folders where model files are stored. |\n| [`entities`](#entities) | List | Lists all the entities used in the project for which you can define models. Each entry for an entity here is a JSON object specifying entity’s name and attributes. |\n| [`packages`](#packages) | List | List of packages with their name and URL. Optionally, you can also extend ID types filters for including or excluding certain values from this list. |\n\n##### `entities`\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `name` | String | Name of the entity used in the project. |\n| `id_stitcher` | String | (Optional) Reference path of the [custom ID stitcher model](https://www.rudderstack.com/docs/profiles/example/id-stitcher/#sample-project-for-custom-id-stitcher) (for example, `models/name_of_id_stitcher`). |\n| [`id_types`](https://www.rudderstack.com/docs/profiles/example/packages/#modify-existing-id-types) | List | List of all identifier types associated with the current entity. |\n| `feature_views` | List | (Optional) Lists all the view names along with their ID’s being served for [feature views model](https://www.rudderstack.com/docs/profiles/example/feature-views/). |\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> The identifiers listed in `id_types` may have a many-to-one relationship with an entity but each ID must belong to a single entity.\n> \n> For example, a `user` entity might have `id_types` as the `salesforce_id`, `anonymous_id`, `email`, and `session_id` (a user may have many session IDs over time). However, it should not include something like `ip_address`, as a single IP can be used by different users at different times and it is not considered as a user identifier.\n\n##### `packages`\n\nYou can import library packages in a project signifying where the project inherits its properties from.\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `name` | String | Specify a name. |\n| `url` | String | HTTPS URL of the lib package, with a tag for the best schema version. |\n\n### `inputs.yaml`\n\nThe `inputs.yaml` file lists all the input sources which should be used to run [models](#models) and eventually create outputs. You can also define specific constraints on the input sources using the [`contract`](https://www.rudderstack.com/docs/profiles/example/packages/#model-contracts) key.\n\nRudderStack supports the following input sources:\n\n*   **Table**: Specify the table’s name in the `table` key.\n*   **View**: Specify the view’s name in the `view` key.\n*   **S3 bucket**: Specify the path of the CSV file in your bucket in the `s3` key. See [Use Amazon S3 bucket as input](https://www.rudderstack.com/docs/profiles/example/packages/#use-amazon-s3-bucket-as-input) for more information.\n*   **Local CSV file**: Specify the file path in the `csv` key. See [Use CSV file as input](https://www.rudderstack.com/docs/profiles/example/packages/#use-csv-file-as-input) for more information.\n\nYou can also specify the table/view along with the column name and SQL expression for retrieving values. The input specification may also include metadata and the constraints on those columns.\n\nA sample `inputs.yaml` file:\n\n```\ninputs:\n  - name: salesforceTasks\n    contract:\n      is_optional: false\n      is_event_stream: true\n      with_entity_ids:\n        - user\n      with_columns:\n        - name: activitydate\n        - name: whoid\n    app_defaults:\n      table: salesforce.task\n      # For BigQuery, it is recommended to use view (view: _views_<view_name>) instead of table for event streaming data sets.\n      occurred_at_col: activitydate\n      row_identifier:\n        - activitydate\n        - whoid\n      ids:\n        # column name or sql expression\n        - select: \"whoid\" \n          type: salesforce_id\n          entity: user\n          to_default_stitcher: true\n  - name: salesforceContact\n    contract:\n      is_optional: false\n      is_event_stream: true\n      with_entity_ids:\n        - user\n      with_columns:\n        - name: createddate\n        - name: id\n        - name: email\n    app_defaults:\n      table: salesforce.contact\n      # For BigQuery, it is recommended to use view (view: _views_<view_name>) instead of table for event streaming data sets.\n      occurred_at_col: createddate\n      ids:\n        - select: \"id\"\n          type: salesforce_id\n          entity: user\n          to_default_stitcher: true\n        - select: \"case when lower(email) like any ('%gmail%', '%yahoo%') then lower(email)  else split_part(lower(email),'@',2) end\"\n          type: email\n          entity: user\n          to_default_stitcher: true\n  - name: websitePageVisits\n    contract:\n      is_optional: false\n      is_event_stream: true\n      with_entity_ids:\n        - user\n      with_columns:\n        - name: timestamp\n        - name: anonymous_id\n        - name: context_traits_email\n        - name: user_id\n    app_defaults:\n      table: autotrack.pages\n      # For BigQuery, it is recommended to use view (view: _views_<view_name>) instead of table for event streaming data sets.\n      occurred_at_col: timestamp\n      ids:\n        - select: \"anonymous_id\"\n          type: rudder_anon_id\n          entity: user\n          to_default_stitcher: true\n        # below sql expression check the email type, if it is gmail and yahoo return email otherwise spilt email return domain of email.  \n        - select: \"case when lower(coalesce(context_traits_email, user_id)) like any ('%gmail%', '%yahoo%') then lower(coalesce(context_traits_email, user_id))  \\\n              else split_part(lower(coalesce(context_traits_email, user_id)),'@',2) end\"\n          type: email\n          entity: user\n          to_default_stitcher: true\n```\n\nThe following table explains the fields used in the above file:\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `name` | String | Name of the input model. |\n| `contract` | Dictionary | A model contract provides essential information about the model like the necessary columns and entity IDs that it should contain. This is crucial for other models that depend on it, as it helps find errors early and closer to the point of their origin. |\n| `app_defaults` | Dictionary | Values that input defaults to when you run the project directly. For library projects, you can remap the inputs and override the app defaults while importing the library projects. |\n\n##### `contract`\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `is_optional` | Boolean | Whether the model’s existence in the warehouse is mandatory. |\n| `is_event_stream` | Boolean | Whether the table/view is a series/stream of events. A model that has a `timestamp` column is an event stream model. |\n| `with_entity_ids` | List | List of all entities with which the model is related. A model M1 is considered related to model M2 if there is an ID of model M2 in M1’s output columns. |\n| `with_columns` | List | List of all ID columns that this contract is applicable for. |\n\n##### `app_defaults`\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `table`/`view` | String | Name of the warehouse table/view containing the data. You can prefix the table/view with an external schema or database in the same warehouse, if applicable. Note that you can specify either a table or view but not both. |\n| `s3` | String | Name of the CSV file in your Amazon S3 bucket containing the data. |\n| `csv` | String | Name of the CSV file in your local storage containing the data. The file path should be relative to the project folder. |\n| `occurred_at_col` | String | Name of the column in table/view containing the timestamp. |\n| `row_identifier` | String | (Optional) List of all the identifiers whose combination acts as a primary key. If the unique row exists already during the run process while creating a copy of the input table, it is not copied again. |\n| [`ids`](#ids) | List | Specifies the list of all IDs present in the source table along with their column names (or column SQL expressions).<br><br>**Note**: Some input columns may contain IDs of associated entities. By their presence, such ID columns associate the row with the entity of the ID. The ID Stitcher may use these declarations to automatically discover ID-to-ID edges. |\n\n##### `ids`\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `select` | String | Specifies the column name to be used as the identifier. You can also specify a SQL expression if some transformation is required.<br><br>**Note**: You can also refer table from another Database/Schema in the same data warehouse. For example, `table: <database_name>.<schema_name>.<table_name>`. |\n| `type` | String | Type of identifier. All the ID types of a project are declared in [`pb_project.yaml`](#project-details). You can specify additional filters on the column expression.<br><br>**Note**: Each ID type is linked only with a single entity. |\n| `entity` | String | Entity name defined in the [`pb_project.yaml`](#project-details) file to which the ID belongs. |\n| `to_default_stitcher` | Boolean | Set this **optional** field to `false` for the ID to be excluded from the default ID stitcher. |\n\n### `profiles.yaml`\n\nThe `profiles.yaml` file lists `entity_vars`/`input_vars` used to create the output tables under `var_groups`.\n\nThe following `profiles.yaml` file defines a group of vars named `vars_list`. It also defines two models namely `user_profile`, and `user_python_model`:\n\n```\nvar_groups:\n  name: vars_list\n  entity_key: user # This is the name defined in project file. If we change that, we need to change the name here too.\n  vars:\n    - entity_var:\n        name: is_mql\n        select: max(case when salesForceLeadsTable.mql__c == 'True' then 1 else 0 end)\n        from: inputs/salesForceLeadsTable\n        description: Whether a domain is mql or not\n    - entity_var:\n        name: blacklistFlag\n        select: max(case when exclude_reason is not null then 1 else 0 end)\n        from: inputs/blacklistDomains\n        where: (context_sources_job_run_id = (select top 1 context_sources_job_run_id from blacklistDomains order by timestamp desc))\n        is_feature: false\n    - entity_var:\n        name: ignore_domain\n        select: case when {{user.Var(\"blacklistFlag\")}} = 1 or {{user.Var(\"domainSummary_account_type\")}} like '%free%' then 1 else 0 end\n        description: Whether a domain should be ignored for the analysis\n    - entity_var:\n        name: salesEvents\n        select: json_agg(activitydate, case when (type='Email' or tasksubtype = 'Email') then case when lower(subject) like '%[in]%' then 'sf_inbound_email' \\\n              else 'sf_outbound_email' end when macro(call_conversion) then 'sf_call' else null end as event)\n        from: inputs/salesforceTasks\n        description: Salesforce touches are converted to one of following events - sf_inbound_email, sf_outbound_email, sf_call, null\n        is_feature: false\n    - entity_var:\n        name: webhookFormSubmit\n        select:  min(timestamp)\n        from: inputs/webhookSource\n        where: variable_1 is null and timestamp < sales_conversion_timestamp and timestamp > var('start_date')\nmodels:\n  - name: user_profile\n    model_type: feature_table_model\n    model_spec:\n      validity_time: 24h # 1 day\n      entity_key: user\n```\n\n##### `var_groups`\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `name` | String | A unique name for the var\\_group. |\n| `entity_key` | String | The entity to which the var\\_group belongs to. |\n| `vars` | Object | This section is used to specify variables, with the help of `entity_var` and `input_var`. Aggregation on stitched ID type is done by default and is implicit. |\n\nOptionally, you can create models using the above vars. The following fields are common for all the model types:\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `name` | String | Name of the model. Note that a table with the same name is created in the data warehouse. For example, if you define the name as `user_table`, the output table will be named something like `Material_user_table_<rest-of-generated-hash>_<timestamp-number>`. |\n| `model_type` | String | Defines the type of model. Possible values are: `id_stitcher`, `feature_table_model`, `sql_template`, `entity_cohort`, `id_collator`, `python_model`, `feature_views`, etc. |\n| `model_spec` | Object | Creates a detailed configuration specification for the target model. Different schema is applicable for different model types as explained in each section below. |\n\nRudderStack supports the following model types:\n\n*   [Feature Views](https://www.rudderstack.com/docs/profiles/example/feature-views/)\n*   [Feature Table (legacy)](https://www.rudderstack.com/docs/profiles/example/feature-table/)\n*   [SQL Template](https://www.rudderstack.com/docs/profiles/example/sql-model/)\n*   [ID Stitcher](https://www.rudderstack.com/docs/profiles/example/id-stitcher/)\n*   [ID Collator](https://www.rudderstack.com/docs/profiles/example/id-collator/)\n*   [Python model](https://www.rudderstack.com/docs/profiles/predictions/#python-model)\n*   [Packages](https://www.rudderstack.com/docs/profiles/example/packages/)\n\n### `README.md`\n\nThe `README.md` file provides a quick overview on how to use PB along with SQL queries for data analysis.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Project Structure | RudderStack Docs",
    "description": "Know the specifications of a site configuration file, PB project structure, configuration files, and their parameters.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/cli-user-guide/commands/",
    "markdown": "# Commands | RudderStack Docs\n\nLearn about the Profiles commands and how to use them.\n\n* * *\n\n*     12 minute read  \n    \n\nThe Profile Builder tool supports specific commands, making executing the usual operations easier. The basic syntax of executing a command is:\n\n```\n$ pb <command> <subcommand> [parameters]\n```\n\n## Supported commands\n\nYou can use the following Profile Builder commands:\n\n### cleanup\n\nDisplays and removes materials, older than the retention time period specified by the user (default value is 180 days).\n\n```\npb cleanup materials -r <number of days>\n```\n\n**Optional Parameter**\n\n| Parameter | Description |\n| --- | --- |\n| `-r` | Retention time in number of days.<br><br>**Example**: If you pass 1, then all the materials created prior to one day (24 hours) are listed. This is followed by prompts asking you for confirmation, after which you can view the material names and delete them. |\n\n### compile\n\nGenerates SQL queries from models.\n\nIt creates SQL queries from the `models/profiles.yaml` file, storing the generated results in the **Output** subfolder in the project’s folder. With each run, a new folder is created inside it. You can manually execute these SQL files on the warehouse.\n\n**Optional parameters**\n\n| Parameter | Description |\n| --- | --- |\n| `clean_output` | Empties the output folder(s) before executing the command. |\n| `-c` | Uses a site configuration file other than the one in `.pb` directory.<br><br>**Example**: `$ pb compile -c MyOtherConnection/siteconfig.yaml` |\n| `-t` | Defines target name (mentioned in `siteconfig.yaml`) or timestamp in building the model.<br><br>**Example**: If your `siteconfig.yaml` has two targets, `dev` and `test`, and you want to use the `test` instance: `$ pb compile -t test` |\n| `--begin_time` | Timestamp to be used as a start time in building model. |\n| `--end_time` | Timestamp to be used as an end time in building model. |\n| `--migrate_on_load` | Whether to automatically migrate the project and packages to the latest version. Defaults to false. |\n| `--migrated_folder_path` | Folder location of the migrated project. Defaults to sub-directory of the project folder. |\n| `-p` | *   Uses a project file (`pb_project.yaml`) other than the one in current directory.  <br>    **Example**: `$ pb compile -p MyOtherProject`.<br>  <br>*   Fetches project from a URL such as GitHub.  <br>    **Example**:`$ pb compile -p git@github.com:<orgname>/<repo>`. You can also fetch a specific tag, like `$ pb compile -p git@github.com:<orgname>/<repo>/tag/<tag_version>/<folderpath>` |\n| `--rebase_incremental` | Rebases any incremental models (build afresh from their inputs) instead of starting from a previous run. You can do this every once in a while to address the stale data or migration/cleanup of an input table. |\n\n### discover\n\nDiscovers elements in the warehouse, such as models, entities, features and sources.\n\nIt allows you to discover all the registered elements in the warehouse.\n\n**Subcommands**\n\nDiscover all the `models`, `entities`, `features`, `sources`, and `materials` in the warehouse.\n\n```\n$ pb discover models\n$ pb discover entities\n$ pb discover features\n$ pb discover sources\n$ pb discover materials\n```\n\n**Optional parameters**\n\n| Parameter | Description |\n| --- | --- |\n| `-e` | Discovers specific entities with their name.<br><br>**Example**: `$ pb discover -e 'Name'` |\n| `-m` | Discovers a specific model.<br><br>**Example**: `$ pb discover -m 'MY_DATABASE.PROD_SCHEMA.CREATED_MODEL'` |\n| `-c` | Uses a site config other than the default one.<br><br>**Example**: `$ pb discover -c siteconfig.yaml` |\n| `-s` | Discovers entities in a specified schema. |\n| `-s \"*\"` | Discovers entities across all schemas (case-sensitive). |\n| `-u` | Discovers entities having the specified source URL’s.<br><br>**Example**: To discover all the entities coming from GitHub: `$ pb discover -u %github%` |\n| `-t` | Selects target (mentioned in `siteconfig.yaml`). |\n| `-p` | Uses project folder other than the one in current directory.<br><br>**Example**: `$ pb discover -p ThisFolder/ThatSubFolder/SomeOtherProject/` |\n| `-f` | Specifies a file path to dump the discovery output into a csv file.<br><br>**Example**: `$ pb discover -f path/to/csv_file.csv` |\n| `-k` | Restricts discovery of the specified model keys.<br><br>**Example**: `$ pb discover -k entity_key:mode_type:model_name` |\n| `--csv_file` | Specify this flag with a file path to dump the discovery output into a csv file. |\n\n**Examples**\n\n```\n# Discover all the models\n$ pb discover models\n\n# Discover a model with specific name\n$ pb discover -m 'RUDDER_WEB_EVENTS.PROD_SCHEMA.feature_profile'\n\n# Discover all features having 'max' in their name\n$ pb discover features -u %max%\n\n# Discover all the entities for a specific profile\n$ pb discover entities -c siteconfig.yaml\n\n# Discover all materials for target dev\n$ pb discover materials -t dev\n\n# Export output of discover command to a CSV file in output folder\n$ pb discover -f my-custom-name.csv\n\n# Export all sources to a CSV file in output folder\n$ pb discover sources -f my-custom-name.csv\n```\n\n### help\n\nProvides list information for any command.\n\n**Subcommand**\n\nGet usage information for a specific command, with subcommands, and optional parameters.\n\n### init\n\nCreates connection and initializes projects.\n\n**Subcommands**\n\nInputs values for a warehouse connection and then stores it in the `siteconfig.yaml` file.\n\nGenerates files in a folder named **HelloPbProject** with sample data. You can change it as per project information, models, etc.\n\n**Optional parameters**\n\n| Parameter | Description |\n| --- | --- |\n| `pb-project -o` | Creates a Profile Builder project with a different name by specifying it as an additional parameter.<br><br>**Example**: To create a Profile Builder project with the name **SomeOtherProject**: `$ pb init pb-project -o SomeOtherProject` |\n| `connection -c` | Creates `siteconfig.yaml` at a location other than `.pb` inside home directory.<br><br>**Example**: To create `myconfig.yaml` in the current folder: `$ pb init connection -c myconfig.yaml`. |\n\n### insert\n\nAllows you to store the test dataset in your (Snowflake) warehouse . It creates the tables `sample_rs_demo_identifies` and `sample_rs_demo_tracks` in your warehouse schema specified in the `test` connection.\n\n```\n# Select the first connection named test having target and output as dev, of type Snowflake.\n$ pb insert\n# By default it'll pick up connection named test. To use connection named red:\n$ pb insert -n red\n# To pick up connection named red, with target test .\n$ pb insert -n red -t test\n```\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> This command is supported only for Snowflake currently.\n\n### migrate\n\nMigrate your project to the latest schema.\n\n**Subcommands**\n\nBased on the current schema version of your project, it enlists all the steps needed to migrate it to the latest one.\n\nAutomatically migrate from one version to another.\n\nTo migrate your models:\n\n**Schema 44 onwards**\n\nNavigate to the folder where your project files are stored. Then execute one of the following:\n\n*   `pb migrate auto --inplace`: Replaces contents of existing folder with the migrated folder.\n*   `pb migrate auto -d <MigratedFolder>`: Keeps the original project intact and stores the migrated project in another folder.\n\n**Schema 43 -> 44:**\n\nUse `{{entity-name.Var(var-name)}}` to refer to an `entity-var` or an `input-var`.\n\nFor example, for entity\\_var `user_lifespan` in your HelloPbProject, change `select: last_seen - first_seen` to `select: '{{user.Var(\"last_seen\")}} - {{user.Var(\"first_seen\")}}'`.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Note that:\n> \n> *   You must use two curly brackets.\n> *   Anything contained within double curly brackets must be written in double quotes (`\" \"`). If you use single quotes within double quotes, then use the escape character (`\\`) that comes when using macros.\n\nFurther, navigate to the folder where your project files are stored. Then execute one of the following:\n\n*   `pb migrate auto --inplace`: Replaces contents of existing folder with the migrated folder.\n*   `pb migrate auto -d <MigratedFolder>`: Keeps the original project intact and stores the migrated project in another folder.\n\n**Linear dependency**\n\nSpecify this parameter when entity as vars migration is not done (till version 43). After the migration is done, it’s not necessary to mention this parameter and can be removed.\n\n```\n  compatibility_mode:\n    linear_dependency_of_vars: true\n```\n\n**Optional parameters**\n\n| Parameter | Description |\n| --- | --- |\n| `-p` | Uses a project file other than the one in current directory. |\n| `-c` | Uses a `siteconfig.yaml` file other than the one in your home directory. |\n| `-t` | Target name (defaults to the one specified in `siteconfig.yaml` file). |\n| `-v` | Version to which the project needs to be migrated (defaults to the latest version). |\n| `-d` | Destination folder to store the migrated project files.<br><br>**Example**: `pb migrate auto -d FolderName` |\n| `--force` | Ignores warnings (if any) and migrates the project. |\n| `--inplace` | Overwrites the source folder and stores migrated project files in place of original.<br><br>**Example**: `pb migrate auto --inplace` |\n| `-p` | Uses a project folder other than the one in current directory.<br><br>**Example**: `$ pb discover -p ThisFolder/ThatSubFolder/SomeOtherProject/` |\n| `-f` | Specifies a file path to dump the discovery output into a csv file.<br><br>**Example**: `$ pb discover -f path/to/csv_file.csv` |\n| `-k` | Restricts discovery of the specified model keys.<br><br>**Example**: `$ pb discover -k entity_key:mode_type:model_name` |\n\n### run\n\nCreates identity stitcher or feature table model in the Warehouse.\n\nIt generates the SQL files from models and executes them in the warehouse. Once executed, you can see the output table names, which are accessible from the warehouse.\n\n**Optional parameters**\n\nThe `run` command shares the same parameters as the [`compile`](#compile) command, in addition to the following ones:\n\n| Parameter | Description |\n| --- | --- |\n| `--force` | Does a force run even if the material already exists. |\n| `-- write_output_csv` | Writes all the generated tables to CSV files in the specified directory.<br><br>**Example**: `$ pb run -- WriteOutputHere.csv` |\n| `--model_args` | Customizes behavior of an individual model by passing configuration params to it.<br><br>The only argument type supported currently is `breakpoint` for feature table models.<br><br>The `breakpoint` parameter lets you generate and run SQL only till a specific feature/tablevar. You can specify it in the format `modelName:argType:argName` where argName is the name of feature/tablevar.<br><br>**Example**: `$ pb run --model_args domain_profile:breakpoint:salesforceEvents` |\n| `--model_refs` | Restricts the operation to a specified model. You can specify model references like `pb run --model_refs models/<model-name> --seq_no latest` |\n| `--seq_no` | Sequence number for the run, for example, 0, 1, 2,…, latest/new. The default value is `new`. You can check run logs or use discover commands to know about existing sequence numbers. |\n| `--ignore_model_errors` | Allows the project to continue to run in case of an erroneous model. The execution will not stop due to one bad model. |\n| `--grep_var_dependencies` | Uses regex pattern matching over fields from vars to find references to other vars and set dependencies. By default, it is set to `true`. |\n| `--concurrency` | (_Experimental_) Lets you run the models concurrently in a warehouse (wherever possible) based on the dependency graph. In CLI, you can specify the concurrency level for running models in a project via `pb run --concurrency <int>` (default int value is 1). Currently, this is supported only for Snowflake warehouse. It is recommended to use this option judiciously as applying a large value may not be supported by your warehouse. The concurrency limit for Snowflake is 20. To increase the limit, see [Snowflake docs](https://community.snowflake.com/s/question/0D50Z00008VjQDkSAN/how-to-handle-thenumberofwaitersexceedsthe20statementslimit-error). |\n| `--begin_time` | Timestamp to be used as a start time in building model. |\n| `--end_time` | Timestamp to be used as an end time in building model. |\n| `--migrate_on_load` | Whether to automatically migrate the project and packages to the latest version. Defaults to false. |\n| `--migrated_folder_path` | Folder location of the migrated project. Defaults to sub-directory of the project folder. |\n| `--include_untimed` | Whether to include data without timestamps when running models. Defaults to true. |\n\n### show\n\nObtains a comprehensive overview of models, id\\_clusters, packages, and more in a project. Its capacity to provide detailed information makes it particularly useful when searching for specific details, like all the models in your project.\n\n**Subcommands**\n\n1.  `pb show models`\n\nThis command lets you view information about the models in your project. The output includes the following information about each model:\n\n*   **Warehouse name**: Name of the table/view to be created in the warehouse.\n*   **Model type**: Whether its an identity stitching, feature table, SQL model etc.\n*   **Output type**: Whether the output type is `ephemeral`, `table`, or `view`.\n*   **Run type**: Whether the model’s run type is `discrete` or `incremental`.\n*   **SQL type**: Whether the SQL type of the model is `single_sql` or `multi_sql`.\n\n2.  `pb show models --json`\n\nThis subcommand saves all model details in a JSON file.\n\n3.  `pb show dependencies`\n\nThis subcommand generates a graph file (`dependencies.png`) highlighting the dependencies of all models in your project.\n\n4.  `pb show dataflow`\n\nThis subcommand generates a graph file (`dataflow.png`) highlighting the data flow of all models in your project.\n\n5.  `pb show idstitcher-report --id_stitcher_model models/<ModelName> --migrate_on_load`\n\nThis subcommand creates a detailed report about the identity stitching model runs. To know the exact modelRef to be used, you can execute `pb show models`. By default, it picks up the last run, which can be changed using flag `-l`. The output consists of:\n\n*   **ModelRef**: The model reference name.\n*   **Seq No**: Sequence number of the run for which you are creating the report.\n*   **Material Name**: Output name as created in warehouse.\n*   **Creation Time**: Time when the material object was created.\n*   **Model Converged**: Indicates a successful run if `true`.\n*   **Pre Stitched IDs before run**: Count of all the IDs before stitching.\n*   **Post Stitched IDs after run**: Count of unique IDs after stitching.\n\nProfile Builder also generates a HTML report with relevant results and graphics including largest cluster, ID graph, etc. It is saved in `output` folder and the exact path is shown on screen when you execute the command.\n\n6.  `pb show entity-lookup -v '<trait value>'`\n\nThis subcommand lists all the features associated with an entity using any of the traits (flag `-v`) as ID types (email, user id, etc. that you are trying to discover).\n\n**Optional parameters**\n\n| Parameter | Description |\n| --- | --- |\n| `--entity string` | (Optional) Passes the entity value. (default `user`). |\n| `-h` | Displays help information for the command. |\n| `-p` | Specifies the project path to list the models. If not specified, it uses the project in the current directory. |\n| `-c` | File location of the `siteconfig.yaml` (defaults to the one in your home directory). |\n| `-t` | Target name (defaults to the target specified in `siteconfig.yaml` file). |\n| `--include_disabled` | Lets the disabled models be a part of the generated graph image (applicable to [`dataflow` and `dependencies`](#show)). |\n| `--seq_no` | Specifies a particular run for an ID stitcher model (applicable for [`idstitcher-report`](#show)). |\n\n### query\n\nExecutes SQL query on the warehouse and prints the output on screen (10 rows by default).\n\nFor example, if you want to print the output of a specific table/view named `user_id_stitcher`, run the following query:\n\n```\npb query \"select * from user_id_stitcher\"\n```\n\nTo reference a model with the name `user_default_id_stitcher` for a previous run with seq\\_no 26, you can execute:\n\n```\npb query \"select * from {{this.DeRef('path/to/user_default_id_stitcher')}} limit 10\" --seq_no=26\n```\n\n**Optional parameters**:\n\n| Parameter | Description |\n| --- | --- |\n| `-f` | Exports output to a CSV file. |\n| `-max_rows` | Maximum number of rows to be printed (default is 10). |\n| `-seq_no` | Sequence number for the run. |\n\n### validate\n\nValidates aspects of the project and configuration.\n\nIt allows you to run various tests on the project-related configurations and validate those. This includes but is not limited to validating the project configuration, privileges associated with the role specified in the site configuration of the project’s connection, etc.\n\n**Subcommands**\n\nRuns tests on the role specified in the site configuration file and validates if the role has privileges to access all the related objects in the warehouse. It throws an error if the role does not have required privileges to access the input tables or does not have the permissions to write the material output in the output schema.\n\n### version\n\nShows the Profile Builder’s current version along with its GitHash and native schema version.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Commands | RudderStack Docs",
    "description": "Learn about the Profiles commands and how to use them.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/changelog/",
    "markdown": "# Changelog | RudderStack Docs\n\nChangelog for all the Profiles versions.\n\n* * *\n\n*     48 minute read  \n    \n\n## Version 0.15.0\n\n_10 July 2024_\n\n**What’s New**\n\n*   Support for key-pair authentication in Snowflake for enhanced security.\n*   Schema has been updated from 67 to 69.\n\n**Improvements**\n\n*   Replaced `ROW_NUMBER() OVER(ORDER BY 1)` with `ROW_NUMBER() OVER()` for Redshift and BigQuery. This eliminates an unnecessary `ORDER BY` first column.\n\n**Known Issues**\n\n*   When using the CLI: You will have to manually make changes in the [`siteconfig.yaml` file](https://www.rudderstack.com/docs/profiles/cli-user-guide/structure/#site-configuration-file) to add a Snowflake connection with key-pair authentication.\n*   RudderStack does not support accessing input sources in a different project for the BigQuery warehouse.\n*   Linux users might see this warning for all command runs - you can ignore it: `WARN[0000]log.go:228 gosnowflake.(*defaultLogger).Warn DBUS_SESSION_BUS_ADDRESS envvar looks to be not set, this can lead to runaway dbus-daemon processes. To avoid this, set envvar DBUS_SESSION_BUS_ADDRESS=$XDG_RUNTIME_DIR/bus (if it exists) or DBUS_SESSION_BUS_ADDRESS=/dev/null`.\n*   Redshift: If two different users create material objects on the same schema, RudderStack gives an error during cleanup when trying to drop views created by the other user, like `user_var_table`.\n*   `pb validate access` command does not work for BigQuery.\n*   `pb insert` does not work for Redshift, Databricks, and BigQuery.\n*   Cross database references can fail on Redshift for a few clusters.\n*   If you are referring a public package in the project and get `ssh: handshake failed error`, then you’ll have to manually remove the entire folder from _WhtGitCache_ to make it work.\n*   The code for `validity_time` is redundant and should be removed.\n*   Timegrains is an experimental feature. There might be some undiscovered issues.\n*   While creating Activations, validation for Redshift does not work correctly in the RudderStack dashboard.\n\n## Version 0.14.2\n\n_28 June 2024_\n\n**Bug Fixes**\n\n*   Resolved “authentication token has expired” issue on Snowflake.\n\n## Version 0.14.1\n\n_26 June 2024_\n\n**Bug Fixes**\n\n*   Resolved few migration issues.\n*   Fixed BigQuery issues where the project name had special characters.\n\n## Version 0.14.0\n\n_19 June 2024_\n\n**What’s New**\n\n*   You can now refer to `entity_vars` defined on cohorts using the `<cohort_name>.Var(\"<var_name>\")` syntax along with the original `entity.Var(\"v1\")` syntax.\n*   Vars from ancestor vars are now inherited in derived cohorts. If a derived cohort has vars with the same name as ancestors, they are overridden.\n*   You can also specify `timegrains` on a specific `entity_var` and not only on the entire `var_group`.\n*   If a column is specified as mandatory in a model contract, it must be present in the warehouse. Otherwise, the project will fail. Also, contract validation is now enabled for SQL models and Python models.\n*   `pb show models` command now displays additional information such as the `enable_status` of models, warehouse name, namespace, and timegrains.\n*   In materialization status, the flag `not_needed` has been renamed to `only_if_necessary`.\n*   Some experimental features are added to optimize performance by partitioning var tables.\n*   A new key `row_identifier` _(experimental)_ has been added under `app_defaults` in the `inputs.yaml` file.\n*   Schema has been updated from 63 -> 67 in the `pb_project.yaml` file.\n\n**Improvements**\n\n*   Few optimizations in the RudderStack dashboard to make it leaner and faster.\n\n**Bug Fixes**\n\n*   Fixed the issue where features list wasn’t getting added to input models build specification.\n*   Resolved a bug where <`entity`\\>`/feature_views` model wasn’t getting created, in case the `feature_views` key didn’t have any value.\n*   Resolved the error where some BigQuery projects were failing with the message `Dataset <> not found in location`.\n*   Fixed the symlink issue where the `pb run`/`pb compile` commands were failing when the relative path of the project is passed.\n*   Resolved the bug where input models were getting enabled if they did not exist earlier, even if their status wasn’t set.\n*   Error is now being thrown in case all the inputs of a model are disabled but they are mandatory.\n*   Fixed the error `nil pointer dereference` when `other_id` is not defined in the feature views.\n*   Resolved the issue where different cohorts with same feature names were throwing an error.\n*   Fixed the bug where a derived cohort was not able to refer other cohort’s vars.\n*   Fixed `column name is ambiguous` error in feature views when there are vars with the same name in different timegrains.\n*   Resolved the issue where some projects with concurrency were failing with error `concurrent map read and map write`.\n*   Fixed the issue with force runs on models with begin time.\n\n**Known Issues**\n\n*   RudderStack does not support accessing input sources in a different project for the BigQuery warehouse.\n*   Linux users might see this warning for all command runs - you can ignore it: `WARN[0000]log.go:228 gosnowflake.(*defaultLogger).Warn DBUS_SESSION_BUS_ADDRESS envvar looks to be not set, this can lead to runaway dbus-daemon processes. To avoid this, set envvar DBUS_SESSION_BUS_ADDRESS=$XDG_RUNTIME_DIR/bus (if it exists) or DBUS_SESSION_BUS_ADDRESS=/dev/null`.\n*   Redshift: If two different users create material objects on the same schema, RudderStack gives an error during cleanup when trying to drop views created by the other user, like `user_var_table`.\n*   `pb validate access` command does not work for BigQuery.\n*   `pb insert` does not work for Redshift, Databricks, and BigQuery.\n*   Cross database references can fail on Redshift for a few clusters.\n*   If you are referring a public package in the project and get `ssh: handshake failed error`, then you’ll have to manually remove the entire folder from _WhtGitCache_ to make it work.\n*   The code for `validity_time` is redundant and should be removed.\n*   In some cases, you may need to install the `profiles-rudderstack` and `profiles-rudderstack-bin` pip packages separately.\n*   You may have to execute the compile command once before executing validate access. Otherwise, you will get a `seq_no` error.\n*   Timegrains is an experimental feature. There might be some undiscovered issues.\n*   Activations does not work with Redshift warehouse.\n\n## Version 0.13.2\n\n_11 June 2024_\n\n**Bug Fixes**\n\n*   Fixed issues with auto-migrate on Windows.\n*   Resolved insufficient memory error encountered while adding `main_id` to `input_var` tables in Redshift.\n\n## Version 0.13.1\n\n_23 May 2024_\n\n**Bug Fixes**\n\n*   Resolved the issue with remapped models in entity projects in the RudderStack dashboard.\n*   Fixed timestamp casting issues on BigQuery.\n\n**Known Issues**\n\n*   RudderStack does not support accessing input sources in a different project for the BigQuery warehouse.\n*   Linux users might see this warning for all command runs - you can ignore it: `WARN[0000]log.go:228 gosnowflake.(*defaultLogger).Warn DBUS_SESSION_BUS_ADDRESS envvar looks to be not set, this can lead to runaway dbus-daemon processes. To avoid this, set envvar DBUS_SESSION_BUS_ADDRESS=$XDG_RUNTIME_DIR/bus (if it exists) or DBUS_SESSION_BUS_ADDRESS=/dev/null`.\n*   Redshift: If two different users create material objects on the same schema, RudderStack gives an error during cleanup when trying to drop views created by the other user, like `user_var_table`.\n*   `pb validate access` command does not work for BigQuery.\n*   `pb insert` does not work for Redshift, Databricks, and BigQuery.\n*   Cross database references can fail on Redshift for a few clusters.\n*   If you are referring a public package in the project and get `ssh: handshake failed error`, then you’ll have to manually remove the entire folder from _WhtGitCache_ to make it work.\n*   The code for `validity_time` is redundant and should be removed.\n*   In some cases, you may need to install the `profiles-rudderstack` and `profiles-rudderstack-bin` pip packages separately.\n*   You may have to execute the compile command once before executing validate access. Otherwise, you will get a `seq_no` error.\n*   Cohort features do not inherit the parent’s features.\n*   RudderStack dashboard lists a cohort only if it has features.\n*   Timegrains is an experimental feature. There might be some undiscovered issues.\n*   Activations does not work with Redshift warehouse.\n\n## Version 0.13\n\n_16 May 2024_\n\n**What’s New**\n\n*   Timegrains feature _(experimental)_ lets you reuse the output material of a model within the specified time period, preventing unnecessary recalculations⁠. You can define its value as a day, week, month etc. to compute features at the end of that particular period.\n*   Cohorts feature _(experimental)_ lets you define core customer segments within an entity based on some characteristics.\n*   Removed support for `rebase_incremental` in project\\_spec. However, you can specify it using the command-line tool.\n*   The `output` folder now generates artifacts for `run` and `compile` commands in separate subfolders with the same name.\n*   `pb init pb-project` now comes with a sample SQL model.\n*   `ReadFile` support introduced in YAML which lets you highlight syntax. In a SQL model, you can use `{{this.ReadFile(\"models/sql_file.sql\")}}` to refer SQL content from a file.\n*   Material registry is now at v5. It includes two new columns - `model_ref` and `registry_version`. The registry will be automatically migrated once you execute `pb run` command.\n\n**Improvements**\n\n*   Improved performance in compilation and ID stitching processes, resulting in faster operations.\n*   Improved error handling at some places.\n*   Few internal refactorings for enhanced working.\n\n**Bug Fixes**\n\n*   Removed `include_untimed` key from the `pb_project.yaml` file as it was redundant.\n*   Fixed sporadic lengthening of project runs in RudderStack dashboard.\n\n**Known Issues**\n\n*   Linux users might see this warning for all command runs - you can ignore it: `WARN[0000]log.go:228 gosnowflake.(*defaultLogger).Warn DBUS_SESSION_BUS_ADDRESS envvar looks to be not set, this can lead to runaway dbus-daemon processes. To avoid this, set envvar DBUS_SESSION_BUS_ADDRESS=$XDG_RUNTIME_DIR/bus (if it exists) or DBUS_SESSION_BUS_ADDRESS=/dev/null`.\n*   Redshift: If two different users create material objects on the same schema, RudderStack will throw error during cleanup when trying to drop views created by the other user, such as `user_var_table`.\n*   `pb validate access` command does not work for BigQuery.\n*   Some commands such as `pb insert` does not work for Redshift, Databricks, and BigQuery.\n*   For a few clusters, cross database references can fail on Redshift.\n*   If you are referring a public package in the project and get `ssh: handshake failed error`, then you’ll have to manually clear _WhtGitCache_ folder to make it work.\n*   The code for `validity_time` is redundant and should be removed.\n*   In some cases, you may need to install the `profiles-rudderstack` and `profiles-rudderstack-bin` pip packages separately.\n*   You may have to execute the compile command once before executing validate access. Otherwise, you will get a `seq_no` error.\n*   Cohort features do not inherit parent’s features.\n*   RudderStack dashboard lists a cohort only if it has features.\n*   Timegrains is an experimental feature. There might be some undiscovered issues.\n*   Activations does not work with Redshift warehouse.\n\n## Version 0.12.1\n\n_2 May 2024_\n\n**Improvements**\n\n*   If all the inputs of a model are disabled, the model is disabled by default.\n\n**Bug Fixes**\n\n*   Resolved bug where some projects were failing in case nested columns were missing.\n*   Updated the migration logic to preserve old view names. The reason being that some existing Activation API projects were failing due to the renaming of `serve_traits` to `feature_views`.\n\n**Known Issues**\n\n*   Linux users might see this warning for all command runs - you can ignore it: `WARN[0000]log.go:228 gosnowflake.(*defaultLogger).Warn DBUS_SESSION_BUS_ADDRESS envvar looks to be not set, this can lead to runaway dbus-daemon processes. To avoid this, set envvar DBUS_SESSION_BUS_ADDRESS=$XDG_RUNTIME_DIR/bus (if it exists) or DBUS_SESSION_BUS_ADDRESS=/dev/null`.\n*   Redshift: If two different users create material objects on the same schema, RudderStack will throw error during cleanup when trying to drop views created by the other user, such as `user_var_table`.\n*   `pb validate access` command does not work for BigQuery.\n*   Some commands such as `pb insert` does not work for Redshift, Databricks, and BigQuery.\n*   For a few clusters, cross database references can fail on Redshift.\n*   If you are referring a public package in the project and get `ssh: handshake failed error`, then you’ll have to manually clear _WhtGitCache_ folder to make it work.\n*   The code for `validity_time` is redundant and should be removed.\n*   In some cases, you may need to install the `profiles-rudderstack` and `profiles-rudderstack-bin` pip packages separately.\n*   You may have to execute the compile command once before executing validate access. Otherwise, you will get a `seq_no` error.\n\n## Version 0.12.0\n\n_25 April 2024_\n\n**What’s New**\n\n*   Support for external tables on Redshift Serverless.\n    \n*   Redshift users can now also connect via SSH Tunnel.\n    \n*   Support to specify the version on which you want to run your Profiles project. It is also backported to v0.10.8 and v0.11.5 onwards.\n    \n*   Feature views path refs look like below:\n    \n    *   user/all/feature\\_view _\\# By default, the id served is user `main_id`._\n    *   user/all/feature\\_view/using\\_email _\\# For non default IDs, the path ref has using\\_<idname>_\n    *   user/all/feature\\_view/salesforce\\_id\\_stitched\\_features _\\# The names can still be overridden._\n*   Ability to add description (optional) to feature tags in the project file.\n    \n    ```\n    available_tags:\n        - name: demographics\n          description: all tags related to user demographics\n        - name: billing\n    ```\n    \n*   Reorganized the overall flow when defining a Redshift connection. You can specify the region while using Redshift.\n    \n*   Creating a new project using `pb init pb-project` now comes with sample data in CSV format, in a folder named `csvs`. These are referenced in the input file.\n    \n*   Renamed `Entity Traits 360` model to `Feature Views`. Also, in the `pb_project.yaml` file, a Feature Views model is included by default under the entities definition.\n    \n*   Schema has been migrated from 54 -> 61 in the project file.\n    \n\n**Improvements**\n\n*   `pb init connection` now fetches connection name from the site configuration file, and asks you to specify one as well. If you don’t enter any value and there’s only one entry in the file, then it picks that value.\n*   Default ID stitcher now uses all package models for ID sources as well, in addition to local ones.\n*   Relevant error is now thrown, if ID types for an entity has not been specified in the `pb_project.yaml` file.\n*   An entity project in the RudderStack dashboard no longer fails in case a few columns are missing in the source tables.\n*   Debugging is improved and the correct line number is displayed.\n*   `pb show models` command now includes model dependencies along with some more statistics.\n*   Few retoolings from the ground up.\n\n**Bug Fixes**\n\n*   Resolved bug related to failure when a git repo couldn’t be found in the RudderStack dashboard.\n*   Resolved bug where default ID stitcher was getting created even if there were no ID edges.\n*   Resolved bug where Redshift Profiles projects were failing if names of `entity_var`/`input_var` were longer than 47 characters.\n*   Resolved bug where `pb run --rebase_incremental` command was taking edges from previous runs.\n*   Resolved the issue where a project wasn’t compiling in case it referenced a package having inputs that weren’t defined in the application with the same name.\n\n## Version 0.11.5\n\n_16 April 2024_\n\n**Bug Fixes**\n\n*   Fixed issue for Redshift where the driver version wasn’t getting populated correctly.\n*   Improved cleanup functionality for Redshift by dropping procedures that were used for creating `entity_vars`.\n*   Resolved the issue where migrated project folder’s files weren’t getting deleted.\n*   Fixed the bug where `pb run --rebase_incremental` command was taking edges from previous runs.\n*   Few internal refactorings while returning data types of columns.\n\n## Version 0.11.3\n\n_1 April 2024_\n\n**What’s New**\n\n*   An optional parameter `column_data_type` to specify the data type for an `entity_var`/`input_var`.\n*   Support for programmatic credentials for Redshift.\n*   Schema update in the project yaml file from 53 to 54.\n\n**Improvements**\n\n*   Better error propagation in case of concurrency.\n*   Few internal refactorings for improved overall working.\n\n**Bug Fixes**\n\n*   Resolved `relation still open` error when accessing external tables in Redshift.\n*   Fixed some bugs when getting the `latest seq_no` for a material in BigQuery.\n*   Resolved the issue of conflict in row-ID in case of very large datasets in BigQuery.\n*   Begin and end time of all models are now in UTC timezone. This fixes a few inconsistency issues in models.\n*   Resolved a concurrency issue which occurred on two different root models with the same name.\n\n## Version 0.11.2\n\n_15 March 2024_\n\n**What’s New**\n\n*   You can now do parallel processing while running a project using the `--concurrency` flag. Currently, this is supported only for Snowflake warehouse. It is recommended to use this option judiciously as applying a very large value can impact your system resources.\n*   RedShift users can now access external tables in their data catalog(s).\n\n**Improvements**\n\n*   Project created using `pb init pb-project` now works for all warehouses.\n\n**Bug Fixes**\n\n*   Fixed issues encountered while running BigQuery projects on Windows.\n*   Resolved errors for entity var names in case they match with input column name.\n*   Resolved bugs related to inserting `seq_no`.\n\n## Version 0.11.1\n\n_7 March 2024_\n\n*   Includes bug fixes related to creating vars on ID models and nil model remapping.\n\n## Version 0.11.0\n\n_1 March 2024_\n\n**What’s New**\n\n*   RudderStack now supports BigQuery (beta), offering the same seamless experience as on other data warehouses.\n*   CSV models _(Experimental)_: In the inputs specs, RudderStack has added the ability to read data from a CSV file, instead of a Database table/view. You can use files from local storage, or kept on S3. Under `app_defaults`, instead of `table`/`view`, use `csv` (local storage) or `s3` (kept on S3) followed by the path where the CSV file is kept. Note that this feature is experimental, and RudderStack currently supports S3 on Snowflake and Redshift. A sample code is as follows:\n\n```\n    app_defaults:\n      csv: \"../common.xtra/Temp_tbl_a.csv\"\n…\n    app_defaults:\n      s3: \"s3://s3-wht-input-test-bucket/test/Temp_tbl_d.csv\"\n```\n\n*   Filter IDs: You can now filter out a vast number of ID’s using SQL. For example, if you wish to exclude all blacklisted ID’s that are listed in an input model named `csv_email_blacklist` and user ID’s from an SQL model named `sql_exclusion_model`, then, you may edit your project file as:\n\n```\nid_types:\n  - name: email\n    filters:\n      - type: exclude\n        sql:\n          select: email\n          from: inputs/csv_email_blacklist\n  - name: user_id\n    filters:\n      - type: exclude\n        sql:\n          select: user_id\n          from: models/sql_exclusion_model\n```\n\n*   Pre and Post Hooks: A pre hook enables you to execute an SQL, before running a model, for example, if you want to change DB access, create a DB object, etc. Likewise, a post hook enables you to execute an SQL after running a model. The SQL can also be templatized. Here’s an example code snippet:\n\n```\nmodels:\n  - name: test_id_stitcher\n    model_type: id_stitcher\n    hooks:\n      pre_run: \"CREATE OR REPLACE VIEW {{warehouse.ObjRef('V1')}} AS (SELECT * from {{warehouse.ObjRef('Temp_tbl_a')}});\"\n      post_run: 'CREATE OR REPLACE VIEW {{warehouse.ObjRef(\"V2\")}} AS (SELECT * from {{warehouse.ObjRef(\"Temp_tbl_a\")}});'\n    model_spec:\n```\n\n*   `pb show models` - You can now view in JSON format by passing the flag –json.\n*   For Databricks, RudderStack now supports the `pb validate access` command.\n*   RudderStack has reverted to having a custom ID stitcher in a new project created using `pb init pb-project`.\n*   When creating a new connection in Redshift, you’ll now be asked to input sslmode. You can enter either `disable` (default) or `require`. This will help RudderStack’s tool to work with Redshift DB’s that require SSL mode to be enabled.\n*   RudderStack supports triggering tasks by using URL and also read the status back.\n*   RudderStack dashboard now supports Git Projects hosted on BitBucket and GitLab.\n*   In model specs, a materialization’s `enable_status` is changed to `snake_case`. That is, `enable_status`: `mustHave` -> `enable_status`: `must_have`.\n*   Schema version in the project file has been updated from 49 to 53.\n\n**Improvements**\n\n*   Better error messages are shown in case of incorrect/missing/duplicate entity-vars.\n*   Error handling has been improved at a few places in Python models.\n*   Model path refs are now case insensitive.\n*   The command `pb migrate auto` can now handle the case where model folders aren’t present.\n*   Specific messages are now shown, in case of errors in the material registry.\n*   Due to limitations of Databricks SQL, RudderStack has added restrictions on using catalog `hive_metastore`. So, in case a user on that catalog tries to use RudderStack’s tool, an error is thrown.\n\n**Bug Fixes**\n\n*   Resolved the intermittent issue in Redshift where it throws an error `ptr_to_latest_seqno_cache does not exist`.\n*   Bugs in `pb show idstitcher-report`, `pb show user-lookup`, and `pb cleanup materials` commands have been rectified. `pb show idstitcher-report` is still flaky, however, RudderStack team is working on improving it.\n*   Fixed bug in packages wherein `entityvars`/`inputvars` weren’t able to refer SQL models.\n*   Resolved erroneous queries for validate access command in case of missing privileges.\n*   Recsolved the issue where git repo wasn’t getting cloned in case `cache_dir` in siteconfig was written using tilde notation.\n*   Fixed some bugs related to `begin_time` of models.\n*   Resolved a few issues when cloning Git projects in the web app.\n*   Several fixes in gRPC, making it more stable.\n*   The remapping: key is removed (if exists) in `models/inputs.yaml` as it was redundant.\n*   Resolved some bugs in incremental ID stitcher.\n\n**Known Issues**\n\n*   `pb validate access` command does not work for BigQuery.\n\n## Version 0.10.6\n\n_19 January 2024_\n\nAn internal fix to address issues that arose from a recent update by Snowflake.\n\n## Version 0.10.5\n\n_9 January 2024_\n\nSome internal fixes to make py-native models more robust.\n\n## Version 0.10.4\n\n_15 December 2023_\n\nOur latest version has a plethora of features that makes our product more feature-rich and impactful.\n\n**What’s New**\n\n*   **Vars as models**: Earlier, Vars could only be defined inside the feature table under `vars:` section. Now, Vars are defined independent of feature tables. In the model specs file, we have created a new top level key called `var_groups`. We can create multiple groups of vars that can then be used in various models (eg. in feature table). All vars in a var-group need to have the same entity. So if you have 2 entities, you need at least 2 var groups. However, you can create multiple var\\_groups for every entity. For example, you can create churn\\_vars, revenue\\_vars, engagement\\_vars etc. So that it is easier to navigate and maintain the vars that you need. Each such model shall have name, entity\\_key and vars (list of objects). This is in line with Profiles design philosophy to see everything as a model.\n*   **User defined model types via Python \\[Experimental feature\\]**: Ever wondered what it would take to implement a new model type yourself? Custom model types can now be implemented in Python. Check out [this library](https://github.com/rudderlabs/profiles-pycorelib) for some officially supported model types with their Python source. Note that this is an experimental feature, so the implementation and interfaces can change significantly in the upcoming versions. To use a python package model in your project, simply specify it as a `python_requirement` in `pb_project.yaml`, similar to requirements.txt. The BuildSpec structure is defined using JSON schema within the Python package. Below code snippet shows how the requirements such as for training and config can be specified in the project:\n\n```\n    entities:\n      - name: user\n      python_requirements:\n      - profiles_rudderstack_pysql==0.2.0 #registers py_sql_model model type\n```\n\n```\n    models:\n      - name: test_py_native_model\n        model_type: py_sql_model\n        model_spec:\n          occurred_at_col: insert_ts\n          validity_time: 24h\n          train_config:\n            prop1: \"prop1\"\n            prop2: \"prop2\"\n```\n\n*   **Default ID stitcher**: Until now, when a new project was created using `pb init pb-project`, the file `profiles.yaml` had specifications for creating a custom ID stitcher. That has a few limitations, when edge sources are spanning across packages. Also, we observed that several of our users weren’t doing much changes to the ID stitcher, except for making it `incremental`. As a solution, we have a “default ID stitcher”, that is created by default for all projects. It runs on all the input sources and ID types defined. For quickstart purposes, users needn’t make any changes to the project, to get the ID stitcher working. In case any changes are to be made, then a user can create a custom ID stitcher, as was done in earlier versions.\n    \n*   **Default ID types**: Now, common concepts like ID types can be loaded from packages. So we needn’t define them in all new projects. Hence, we have moved the common ID type definitions into a library project called [`profiles-corelib`](https://github.com/rudderlabs/rudderstack-profiles-corelib). So when you create a new project, the key `id_types` is not created by default. In case you wish to create a custom list of ID types that is different from the default one, then you may do it as was the case in earlier versions.\n    \n*   **Override packages**: Continuing from previous point: packages now have `overrides` materialization spec. In case you wish to add custom ID types to the default list or modify an existing one, then you may extend the package to include your specifications. For the corresponding id\\_type, add the key `extends:` followed by name of the same/different id\\_type that you wish to extend, and corresponding `filters` with include/exclude values. Below is an example of the same:\n    \n\n```\n    packages:\n        - name: foo-bar\n        url: \"https://github.com/rudderlabs/package-555\"\n    id_types:\n        - name: user_id\n        extends: user_id\n        filters:\n            - type: exclude\n              value: 123456\n    id_types:\n        - name: customer_id\n        extends: user_id\n        filters:\n            - type: include\n              regex: sample\n```\n\n*   **entity\\_var tags**: You can now define a list of tags in the project file under `tags:` key. Then, you can add a tag to each entity\\_var.\n*   **Redshift**: We have added support for the RA3 node type. So now our users on that cluster can cross-reference objects in another database/schema.\n*   Schema version in the project file has been updated from 44 -> 49.\n\n**Improvements**\n\n*   Generated ID’s are now more stable. This means that they are unlikely to adapt to merging of ID Clusters, thereby creating a more accurate profile of your users.\n*   By default, every entity\\_var is a feature, unless specified otherwise using `is_feature: false`. So now, you need not explicitly add them to the `features:` list.\n*   You can now add escape characters to an entity\\_var’s description.\n*   Several internal refactorings to improve overall working of the application.\n\n**Bug Fixes**\n\n*   An entity\\_var having a description with special characters was failing during project re-runs. This has now been resolved.\n*   We have fixed the bug where two entity\\_vars across different entities in the same project couldn’t have the same name.\n*   Fixed some bugs related to vars as models, auto migration of projects, and ID lookup.\n\n**Known Issues**\n\n*   Redshift: If two different users create material objects on the same schema, then our tool will throw error when trying to drop views created by the other user, such as `user_var_table`.\n*   Some commands such as `insert` do not work on Redshift and Databricks.\n*   For a few clusters, cross DB references can fail on Redshift.\n*   If you are referring a public package in the project and get `ssh: handshake failed` error, then you’ll have to manually clear `WhtGitCache` folder to make it work.\n*   The code for `validity_time` is redundant and should be removed.\n*   Sometimes you may have sometimes install both the pip packages separately (`profiles-rudderstack` and `profiles-rudderstack-bin`).\n*   You may have to execute the `compile` command once, before executing `validate access`. Otherwise, you can get a `seq_no` error.\n\n## Version 0.9.4\n\n_8 November 2023_\n\nThis release includes the following bug fixes and improvements:\n\n*   `pb run --grep_var_dependencies` - we are now setting default values using the rule “if a project is migrated on load from a version older than 43, then grep\\_var\\_dependencies will default to true otherwise false”. Also, handled a null pointer case for non existent vars listed in dependencies.\n*   `pb migrate_on_load` / `migrate auto` - we have made the message clearer on curly braches in dot syntax message.\n*   `pb migrate manual` - we have removed compatibility-mode as it was no longer required.\n*   A few internal refactorings.\n\n## Version 0.9.3\n\n_2 November 2023_\n\nThis release addresses a few vulnerability fixes.\n\n## Version 0.9.2\n\n_26 October 2023_\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> In case you are unable to install then we recommend having Python3 versions from 3.8 to 3.10.\n\nThis release includes a bug fix on self dependency of vars, in case column has same name as entity-var.\n\n## Version 0.9.1\n\n_19 October 2023_\n\nOur latest release contains some useful features and improvements, as asked by our users.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> After the auto-migration to v44, you might be shown some warnings to do changes in the YAML. Please check the Tutorials section. Or, you may contact our team and we will assist you with the same.\n\n**What’s New**\n\n*   We have added support for Databricks (beta). Now Databricks users can seamlessly create ID stitcher and feature table models, without writing complex SQL queries! If you’re using Databricks and want to try out Profiles, kindly get in touch with our team.\n*   **Vars as models** : Now, entity\\_vars and input\\_vars can be treated as independent models. Presently, they are tied to a feature table model. In SQL template text, for example in SQL model templates, please use `{{entity-name.Var(var-name)}}` going forward to refer to an entity-var or an input-var. For example, for entity\\_var `user_lifespan` in HelloPbProject, change `select: last_seen - first_seen` to `select: '{{user.Var(\"last_seen\")}} - {{user.Var(\"first_seen\")}}'`.\n*   `pb show dataflow` and `pb show dependencies` commands - A new flag `--include_disabled` flag is added to let disabled models be part of the generated image. Also, we now show the relative path from local root, instead of the full path.\n*   `pb run` command - Added flag `--ignore-model-errors` to let the project continue running in case of an erroneous model. So, the execution wouldn’t stop due to 1 bad model.\n*   `pb run` - Added flag `--grep_var_dependencies` (default: true) which searches for vars dependencies by using `grep` over fields from vars definition.\n*   `pb show idstitcher-report` - Added flag `--seq_no`, using which a specific run for an ID stitcher model can be specified.\n*   **Best schema version** - For a library project, in the `url` key of `packages`, we have introduced the concept of “best version tag”. That is, instead of specifying the specific Git URL of the library project, we give a URL with GIT tag `url: https://github.com/rudderlabs/librs360-shopify-features/tag/schema_{{best_schema_version}}`. Using this will make our tool use the best compatible version of the library project, in case of any schema updates.\n*   Schema has been migrated from version 42 -> 44.\n\n**Improvements**\n\n*   The command `pb show user-lookup` now includes more details including the count of rows created and total number of features.\n*   Commenting out features will ensure that the corresponding entity-var and any related entity-var/input-var being used only for computation of this commented feature wont run\n*   Several improvements done beneath the surface.\n\n**Bug Fixes**\n\n*   The flag `-- force` was having issues in dropping priorly created materialization models. This has now been resolved.\n*   Fixed bug where project was unable to run due to giving a custom name to the ID stitcher.\n*   Resolved an issue in the command `pb show idstitcher-report`, in the case if the hash of the ID Stitcher model has changed from that of the last run, rerunning the ID Stitcher model.\n*   Removed flag `-l` from the command `pb show idstitcher-report` as it was redundant.\n\n**Known Issues**\n\n*   Redshift: If two different users create material objects on the same schema, then our tool will throw error when trying to drop views created by the other user, such as `user_var_table`.\n*   Some commands such as `insert` do not work on Redshift and Databricks.\n*   For a few clusters, cross DB references can fail on Redshift.\n\n## Version 0.8.0\n\n_25 August 2023_\n\n**What’s New**\n\n*   Model Contracts - We have added support for model contracts and their validation. For every input or SQL model, there’s a new key `contract:` which contains the following keys: `is_optional` (boolean, to indicate if the model is optional), `is_event_stream` (boolean, in case the data is event stream and has timestamp), `with_entity_ids` (list of all entities model contains), `with_columns` (list of all column names model have). A contract can be passed along with the model path in `this.DeRef`. For more information, check out [Model Contracts](https://www.rudderstack.com/docs/profiles/example/packages/#model-contracts).\n*   Inputs model - The keys `occurred_at_col` and `ids` are now a part of `app_defaults`, to reinforce that they can also be overridden.\n*   Schema has been migrated from 40 -> 42 in the project file.\n\n**Improvements**\n\n*   The command `pb cleanup materials` now removes tables generated by Python models also.\n*   `pb show user-lookup` now includes user traits from Python models as well.\n*   A few changes under the hood, for more efficient processing and execution.\n\n**Bug Fixes**\n\n*   Fixed issue in Python models where validity of the train file wasn’t working and it so was retraining the model(s) on every run.\n*   Resolved the bug where wrong credentials in siteconfig file was not printing the exact error.\n*   Queries for checking warehouse access (grant) were duplicated and therefore recursively checking grants on the same models again and again. This resulted in taking more time than what was required. It has now been fixed.\n*   `pb migrate auto` - There was an issue in migration of multi-line strings of SQL models, that has now been resolved.\n\n## Version 0.7.3\n\n_14 August 2023_\n\n**What’s New**\n\n*   `pb show idstitcher-report`:`pb show idstitcher-report`: By passing flag `--id_stitcher_model`, you can now create an HTML report with relevant results and graphics including largest cluster, ID graph, etc.\n*   Material Registry has been updated to version 4, as additional information is now stored for target (as defined in siteconfig), system username, and invocation metadata (hostname and the project’s invocation folder). So now, if anyone logs into the system and creates material objects using PB, then these details will be stored. This is based on a feature request from one of our customers. Note: make sure to execute `pb validate access` for migrating the registry.\n*   `pb discover materials`:`pb discover materials` - This command now shows a few additional columns - target, username, hostname, invocation folder.\n*   Default ID stitcher: In the inputs file, the key `to_default_stitcher` needs to be set to `true` explicitly for an ID to get picked in the default ID stitcher. This field is optional and by default set to false, without impacting if the project is using a custom ID stitcher. In your project file, if you remove the key `id_stitcher: models/<name of ID stitcher model>`, then it’ll use the default ID stitcher and create a material view of the name `<entity_name>_default_id_stitcher`.\n*   In the inputs.yaml file, table or view names now appear under a key named `app_defaults:`. This signifies that these are values that input defaults to, when the project is run directly. For library projects, inputs can be remapped and appdefaults overridden. when library projects are imported.\n*   Schema has been migrated from 38 -> 40 in the project file.\n\n**Improvements**\n\n*   `pb init pb-project`:`pb init pb-project`: Added keys on default ID stitcher.\n*   A few improvements behind the scenes, for enhancing the overall functionality.\n\n**Bug Fixes**\n\n*   Resolved the issue where projects migrated using `migrate_on_load` were referring to the location of the migrated project in the material registry. This was affecting the count of ID’s before and after stitching.\n*   Fixed bug where ID stitcher wouldn’t check whether a material was actually existing in the database, before running in incremental mode.\n*   When the material registry was on an unsupported common tables version, then the project environment loading would fail, thereby crashing the application. This has now been resolved.\n*   Features defined in Python models, now do appear in the list of features.\n*   Vars can still be specified in specs of a feature table model. However, the app ignores them. This is a bug and would be fixed in subsequent releases.\n\n## Version 0.7.2\n\n_24 July 2023_\n\nOur newest release brings enhanced functionality and a more efficient experience.\n\n**What’s New**\n\n*   **Model Enable/Disable**: You can now enable or disable specific models using the `materialization` key in model specifications. Use the `status` key to set values. For more information, refer to [Models enabling themselves](https://rudderlabs.github.io/pywht/source/120_tutorials.html#models-enabling-themselves).\n*   **Migrate Auto**: When migrating a project, the ordering of elements now remains the same as in the original files, preserving comments.\n*   **Graceful Application Exit**: You can now exit the application gracefully while it’s running. For example, if you’re generating material tables using the run command, you can exit using Ctrl+C.\n*   **Schema Migration**: The schema version in the project file has been updated from 37 to 38.\n\n**Improvements**\n\n*   Projects created using `init pb-project` now include dependencies.\n*   Instead of generating one big SQL file, we now create multiple files in a folder during SQL generation of a feature table model. This reduces the disk space requirements.\n*   Internal optimizations have been implemented to improve overall performance and efficiency.\n\n**Bug Fixes**\n\n*   An issue has been fixed where insufficient grants for accessing the warehouse would lead to duplicate suggested queries. Also, in some cases, incorrect queries were displayed, such as when a Redshift user was asked to grant a role.\n*   The project URL is now being stored in the material registry, instead of GitHub passkey.\n*   Fixed a bug where macros defined in a separate file as global macros were unable to access a common context.\n*   Resolved a bug where Python models were not appearing in the dependency graph.\n\n## Version 0.7.1\n\n_23 June 2023_\n\nOur latest release addresses some critical issues in the previous release. Therefore, if you’re on v0.7.0, then it’s highly recommended to update to the latest version.\n\n## Version 0.7.0\n\n_22 June 2023_\n\nOur newest release is quite significant in terms of new features and improvements offered. Be sure to try it out and share your feedback with us.\n\n**What’s New**\n\n*   `query` - A new command which displays output of tables/views from the warehouse. So you can view generated material tables from the CLI itself. For example, `pb query \"select * from {{this.DeRef(\"models/user_id_stitcher\")}}\"`.\n*   `show idstitcher-report` - A new sub command that creates report on an ID stitcher run. Such as, whether it converged, count of Pre-stitched ID’s before run, Post-stitched ID’s after run, etc. Usage: `pb show idstitcher-report` .\n*   `show user-lookup` - A new sub command that allows you to search a user by using any of the traits as ID types. E.g., `pb show user-lookup -v <trait value>`.\n*   If non-mandatory inputs required by the model are not present in the warehouse, you can still run the model. Applicable to packages and feature tables.\n*   Schema updated from 33 -> 37 in the project file. Please note that the material registry has been migrated to version 3, so you’ll have to execute `pb validate access` once in order to execute the `run` command.\n\n**Improvements**\n\n*   Added an optional field `source_metadata` in the model file inputs.yaml.\n*   Added EnableStatus field in materialization so that models can be enabled and disabled automatically based on whether it is required or not.\n*   Default ID stitcher now supports incremental mode as well.\n*   In macros, you can now specify timestamps in any format.\n\n**Bug Fixes**\n\n*   In case a project is migrated using flag `migrate_on_load`, then src\\_url in the material registry was pointing to the new folder. Now, that is fixed.\n*   Resolved bugs in generating edges for dependency graphs.\n*   Tons of several other improvements and bug fixes under the hood.\n\n## Version 0.6.0\n\n_26 May 2023_\n\nWe are excited to announce the release of PB Version 0.6.0: packed with new features, improvements, and enhanced user experience.\n\n**What’s New**\n\n*   **Support for begin time and end time**: Our latest release introduces the ability to specify time range for your operations, using two new flags `--begin_time` and `--end_time`. By default, the `--end_time` flag is set to `now`. For example, you can use the command `pb run --begin_time 2023-05-01T12:00:00Z` to fetch all data loaded after 1st May 2023. Note that the flag `--timestamp` is now deprecated.\n*   A new flag, `model_refs`, has been introduced which restricts the operation to a specified model. You can specify model references, such as `pb run --model_refs models/user_id_stitcher`.\n*   `seq_no` - Another new flag, using which you can Continue a previous run by specifying its sequence number. Models that already exist would not be rebuilt, unless `--force` is also specified.\n*   **Show command** - `pb show dependencies` has been added to generate a graph showcasing model dependencies. This visual representation will help you understand the relationships between various models in your project.\n*   **Show command** - `pb show dataflow`: Another new command which generates a graph with reversed edges, illustrating the dataflow within your project.\n*   **migrate\\_on\\_load** - A new flag, `migrate_on_load`, has been introduced. When executing the command `pb run --migrate_on_load`, by default this flag creates a `migrations` folder inside the project folder that has migrated version of your project to the latest schema version and runs it on the warehouse. This simplifies the process of upgrading your project to the latest schema version, without changing source files.\n*   **migrated\\_folder\\_path** - Continuing from previous command, you can use this flag to change folder location of the migrated project.\n*   Schema in the project file has been updated to version 33.\n\n**Improvements**\n\n*   SQL Models now provide more relevant and informative error messages instead of generic “not found” errors. This simplifies troubleshooting and debugging processes.\n*   Numerous improvements and optimizations have been made behind the scenes, enhancing the overall performance and stability of PB.\n\n## Version 0.5.2\n\n_5 May 2023_\n\nOur latest release offers significant performance improvements, enhancements, and bug fixes to provide a better experience.\n\n**What’s New:**\n\n*   A new command, `pb show models`, which displays various models and their specifications in the project.\n*   Ability to exit the application while the run command is being executed.\n*   Project schema version has been migrated to 30.\n\n**Improvements:**\n\n*   Major performance improvements for Redshift. In large data sets, it will reduce the time taken to create ID stitcher table to less than 1/4th of the time taken earlier.\n*   `insert` command now picks the connection specified in the current project folder. If not available, it picks “test” in the connection file.\n*   Siteconfig is now validated when project is loaded.\n*   The `cleanup materials` command now removes SQL models as well.\n\n**Bug Fixes:**\n\n*   Resolved the problem where values with null timestamps were excluded from incremental ID stitcher.\n*   The `insert` command was showing a success message even if no tables were inserted in the warehouse. This has been fixed.\n\n## Version 0.5.1\n\n_11 April 2023_\n\n**What’s New**\n\n*   Updated schema to version 28 in the project file.\n\n**Improvements**\n\n*   Changed project path parameter from `-w` to `-p` for improved usability.\n\n**Bug Fixes**\n\n*   Addressed a few reported bugs for an improved user experience.\n*   Implemented performance enhancements to optimize overall system performance.\n\n## Version 0.5.0\n\n_28 March 2023_\n\nThis release offers significant new additions and improvements, as well as bug fixes.\n\n**What’s New**\n\n*   **Cleanup materials** - You can now use the command `pb cleanup materials` to delete materials in the warehouse automatically, without the need for manual deletion. Just specify the retention time period in the number of days (default 180) and all tables/views created prior to that date will be deleted.\n    \n*   Schema has been migrated to 27. This includes the following changes:\n    \n    *   **pb\\_project.yaml** - The schema version has been updated from 25 → 27. Also, `main_id` is removed from `id_types` as main\\_id\\_type is now optional, rudder\\_id is the main\\_id\\_type by default.\n    *   **models/profiles.yaml** - To explicitly declare edge source ids, each value in `edge_sources` now requires a `from:` key to be appended. Also, if you didn’t define `main_id` in the project file, then no need to specify here.\n\n**Improvements**\n\n*   In the backend code we’ve enabled registry migration which flattens the registry, enabling incremental ID stitcher to operate on incomplete materials. It also introduces a mechanism for migrating common tables.\n*   We have implemented better error handling for cases where an incorrect model name is passed. Any errors related to incorrect model names are now properly identified and handled by the system.\n*   Based on feedback from our users, we have renamed default models from `domain_profile<>` to `user_profile<>`.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Due to changes in registry, we will be depricating older versions of PB.\n\n**Bug Fixes**\n\n*   Fixed the bug where some experimental features, such as Discover, were not working for Redshift.\n*   Addressed the problem where validation errors were incorrectly being triggered when a connection had multiple targets, one of which was invalid. The system now only generates an error if the warehouse target that is being passed has errors.\n*   In addition to previous one, a few more bugs were fixed that were related to validation.\n*   Errors were coming for users who had initialized the GIT repository but had not added the remote origin. This issue has now been fixed.\n\n**Known Issues**\n\n*   Warning: While the run command is being executed, canceling it by pressing Ctrl+C doesn’t work as expected. Though it will stop the program’s execution on the CLI, the query will keep running on the data warehouse. This is a documented Snowflake behavior.\n*   In a model, an input can’t use columns named “MAIN\\_ID”, “OTHER\\_ID”, “OTHER\\_ID\\_TYPE”, or “VALID\\_AT” in its ID SQL.\n*   When creating a connection via `init` command, pressing the Ctrl+C command doesn’t exit the application.\n*   `migrate auto` jumbles up the order and removes comments.\n*   On Redshift, validate access passes all tests, but `run` command sometimes fail giving error “permission denied for language plpythonu”.\n*   Some commands such as `insert` do not work on Redshift.\n*   For a few clusters, cross DB references can fail on Redshift.\n*   The command `migrate auto` migrates siteconfig in your home directory but not any local one.\n*   While working with same type of data in Snowflake and Redshift you might encounter errors where it works on Snowflake but not on Redshift. This is due to the fact that implicit casting of different data types for different function or operator might not be supported on one data warehouse while supported on other.\n\n## Version 0.4.0\n\n_2 March 2023_\n\nWe are proud to announce the latest version of PB 0.4.0, which includes several new features and improvements.\n\n**What’s New**\n\n*   **Redshift** - We are excited to share that we now offer Redshift integration. With YAML, you can now effortlessly create ID stitched and feature table models on your Redshift warehouse, without any difficulty.\n    \n*   **Incremental ID stitching**: You can now stitch together data from multiple sources in incremental mode. When new data is added to your source tables, only that data will be fetched, without needing to reload the whole table each time! This shall result in significant performance improvements from earlier versions, especially if the delta of new data is much smaller compared to what’s already been stitched.\n    \n*   **Insert**: A new command, allowing users to add sample data to their warehouse, without having to manually add them.\n    \n*   Schema has been migrated to 25. This includes the following changes:\n    \n    *   **models/profiles.yaml** - Renamed entityvar to `entity_var` and inputvar to `input_var`\n    *   **pb\\_project.yaml** - Renamed profile to `connection`.\n    *   **siteconfig.yaml** - Renamed profiles to `connections`.\n\nBe sure to use the `migrate auto` command to upgrade your project and the connections file.\n\n**Improvements**\n\n*   The command `init profile` has been renamed to `init connection`.\n*   Lots of modifications under the hood.\n\n**Bug Fixes**\n\nResolved issue on default values in an entity var, ensuring that the values are properly set.\n\n**Known Issues**\n\n*   Warning: While the run command is being executed, canceling it by pressing Ctrl+C doesn’t work as expected. Though it will stop the program’s execution on the CLI, the query will keep running on the data warehouse. This is a documented Snowflake behavior.\n*   In a model, an input can’t use columns named “MAIN\\_ID”, “OTHER\\_ID”, “OTHER\\_ID\\_TYPE”, or “VALID\\_AT” in its ID SQL.\n*   When creating a connection via `init` command, pressing the Ctrl+C command doesn’t exit the application.\n*   `migrate auto` jumbles up the order and removes comments.\n*   On Redshift, some experimental commands such as discover do not work.\n*   The command `migrate auto` migrates siteconfig in your home directory but not any local one.\n*   While working with same type of data in Snowflake and Redshift you might encounter errors where it works on Snowflake but not on Redshift. This is due to the fact that implicit casting of different data types for different function or operator might not be supported on one data warehouse while supported on other.\n\n## Version 0.3.1\n\n_3 February 2023_\n\nThis version addresses a crucial defect, so please make sure to update your version. Note that you won’t have to update your schema for this release.\n\n## Version 0.3.0\n\n_25 January 2023_\n\nWe have got a new name! WHT is now called Profile Builder (PB), RS360 is now Profiles. Be sure to check out our newest release that comes with several new features for an enhanced user experience.\n\n**What’s New**\n\n*   **Migrate** - A new command that will enable you to migrate your project to a newer schema. It has two subcommands:\n    \n    *   **Manual** - You will get to know steps you need to follow to manually migrate the project yourself. It will include both breaking and non-breaking changes.\n    *   **Auto** - Automatically migrate from one version to another.\n*   We have made a few significant changes to YAML. The changes consist of:\n    \n    *   Bumping schema version from 9 → 18.\n    *   Entityvar (Feature Table) - We have renamed tablevar, tablefeature and feature to entityvar; as they all were adding columns to an entity with nearly identical YAML. A new `vars:` section of feature table YAML contains list of inputvars and entityvars. Whereas `features:` field same YAML is a list of entityvar names which should be part of the final output table.\n    *   ID Stitcher is now linked to an entity. As a result, all tables using that entity will use the linked ID Stitcher. Earlier, an ID stitcher was linked to a feature model.\n    *   Some of the terms in yaml spec are changed to make it closer to SQL terminologies. For entityvar and inputvar spec: value → select, filter → where , ref → from. In inputs spec: sql → select.\n    *   Project file has a new key named `include_untimed`. If set to `true`, data without timestamps are included when running models. This reduces data errors for timestamp materials. Also, we have deprecated the flag `require-time-clean` in the `run` command.\n    *   Id types can now be re-used between entities. In the project file, entities now have a list of id types names, instead of a list of definitions. In the inputs file, a required entity field is added to the ID list that specifies which entity this ID type is being extracted for.\n    *   Now an inputvar can also read from a macro, just like tablevar.\n    *   Global Macros - You can now define macros in a separate YAML file inside your models folder. They can then be used across different models in your project. Thus a macro becomes independent that can be reused across multiple models.\n    *   wht\\_project.yaml is renamed to pb\\_project.yaml and ml-features.yaml to profiles.yaml.\n*   **Cleanup Materials** - A new command that allows you to review all the created materials and then delete them (NOTE: experimental feature).\n    \n*   **Discover** - A new subcommand `discover materials` has been added. Using it, you can now discover all the materials associated with a project.\n    \n*   **Compile/Run** - GIT URL now supports tags. To use, execute the command `pb compile -w git@github.com:<orgname>/<repo>/tag/<tag_version>/<folderpath>`.\n    \n\n**Improvements**\n\n*   **Web app** - The UI is now more intuitive and user-friendly.\n*   Log tracing is now enabled by default for most commands. Log files are stored in logs/logfile.log of your current working directory. They store upto 10 MB data. Also, the logger file now stores more granular information for easier debugging in case of unexpected errors.\n*   Significant performance improvements in creating ID stitched tables, in case a lot of duplicates are present.\n*   Add extra columns (Hash, SeqNos) to differentiate between entries for commands to discover sources and entities.\n*   When you execute a profile via run command, then the generated SQL gets saved in the output folder.\n*   Added .gitignore file to init project command, to prevent unnecessary files being added to GIT Repo. Such as, .DS\\_Store, output and logs folders.\n*   Tonnes of changes under the hood.\n\n**Bug Fixes**\n\n*   Fixed the bug where window functions were creating multiple rows (duplicates) per main id.\n*   Resolved the bug in inputvars which was doing joins on main\\_id instead of row id.\n*   Executing the command init profile now inputs values in the same order as on the web app.\n*   Resolved the bug where extra gitcreds\\[\\] and warehouse lines were added on overwriting a profile that already existed.\n*   A few redundant parameters were being shown in the validate access command which have been removed.\n*   Removed a couple of redundant subcommands in the init project.\n\n**Known Issues:**\n\n*   Warning: While the run command is being executed, canceling it by pressing Ctrl+C doesn’t work as expected. Though it will stop the program’s execution on the CLI, the query will keep running on the data warehouse. This is a documented Snowflake behavior.\n*   In a model, an input can’t use columns named “MAIN\\_ID”, “OTHER\\_ID”, “OTHER\\_ID\\_TYPE”, or “VALID\\_AT” in its ID SQL.\n*   When creating a profile via `init` command, pressing the Ctrl+C command doesn’t exit the application.\n*   Web app doesn’t allow you to select a date older than 30 days.\n*   Migrate auto jumbles up the order and removes comments.\n\n## Version 0.2.2\n\n_12 November 2022_\n\nOur November release is significant as it has several fixes and improvements for an enhanced experience. Check it out and be sure to let us know your feedback.\n\n**What’s New**\n\n*   **ID Stitcher / Feature Table** - You can now define a view as source, in addition to table, in the inputs file. This is particularly of use when you need to support an sql query that’s complex or out of scope for PB. To use it, in your inputs file define the edge\\_source as `view: <view_name>` instead of `table: <table_name>`.\n*   **Inputvars** - A new identifier which adds temporary helper columns to an input table, for use in calculating a featuretable.\n*   **Window Functions** - In your model file, you can now add window function support to features, tablevars, tablefeatures and inputvars. Also, you can add filters to features.\n\n**Improvements**\n\n*   Schema version 9 makes it more streamlined to define the model. We welcome your feedback for further improvements on this.\n*   Compile command now show errors if the input SQL is buggy.\n*   Discover - subcommands `entities` and `features` now show a few more fields.\n*   Discover - Export to CSV works for subcommands and also generates files in the output folder.\n*   Init pb-project - Based on feedback, it now generates a README file and also has simpler YAML files with comments. It should now be easier for our users to create a model and get it running.\n*   Several internal refactorings on how the application works.\n*   Web app - Massive improvements under the hood related to UI elements, preserving state when entering data, showing correct data and validations, and displaying run time in user’s local time zone.\n\n**Bug Fixes**\n\n*   Fixed the issue where every time `pb run` was executed for a feature table, it was adding a new row to the output of `pb discover features`.\n*   Resolved the bug where error wasn’t shown if an unknown flag was used.\n*   There was an issue generating material tables on a new schema, which has now been resolved.\n*   Bug fix on generating empty SQL files from input models.\n*   Fixed bug where model names with \\_ in the name would sometimes fail to update the latest view pointer correctly.\n*   Web app - Artifacts list now shows different folders for different runs to isolate them.\n*   Web app - When the PB project is running, the screen now shows correct start timestamp.\n*   Web app - Date filters to find PB runs are now working.\n*   Web app - Scheduling UI is now fully responsive about when the run will take place.\n*   Web app - Resolved the issue where a project would run only once and was then showing error.\n\n**Known Issues:**\n\n*   Warning: While the run command is being executed, canceling it by pressing Ctrl+C doesn’t work as expected. Though it will stop the program’s execution on the CLI, the query will keep running on the data warehouse. This is a documented Snowflake behavior.\n*   In a model, an input can’t use columns named “MAIN\\_ID”, “OTHER\\_ID”, “OTHER\\_ID\\_TYPE”, or “VALID\\_AT” in its ID SQL.\n*   When creating a profile via `init` command, pressing the Ctrl+C command doesn’t exit the application.\n*   Logger file generation is disabled at the moment.\n*   Some no-op parameters are shown upon passing the help flag(-h) to `validate access` command.\n\n## Version 0.2.0\n\n_5 October 2022_\n\nThe September release is our largest update yet. We have added a lot of quality of life improvements and net new features to the PB product line. We plan on releasing even more features in our mid-October release to further improve the usability of the product as well as add additional features that will further help form the core of the product. A substantial amount of the features in this release were based directly off feedback from the first beta testing with external users and internal stakeholders. Please feel free to walk through our newest release. We welcome and encourage all constructive feedback on the product.\n\n**What’s New**\n\n*   **Feature Table** - After encouraging feedback from beta testing of the ID Stitcher, we are feeling more confident about sharing our C360 feature table functionality with beta customers. During testing of this release, we benchmarked ourselves against the feature set that our E-Commerce ML models expect. Many features were implemented successfully. Some needed functionality which could not be pushed through QA gates in this September release. Nevertheless, the feature table YAML is now ready for internal customers to explore.\n*   **Web App** - We are now ready to share the scheduling functionality within the web app. This will allow the user to schedule, and automatically run PB models from the Rudder backplane. Any artifacts and log files created during the execution of PB projects are also available for the user to explore. This critical functionality will enable users to debug their cloud PB runs.\n*   **Validate** - A new command, `pb validate` allows users to run various tests on the project related configurations and validate the privileges associated with the role used for running the project. For example, the subcommand `pb validate access` does an exhaustive test of required privileges before accessing the warehouse.\n*   **Version** - This is another new command that provides information on the current version of the app.\n*   **Logger** - When you execute the compile and run commands, all errors and success messages that were previously only displayed on screen, are now also logged in a file inside the project output folder.\n*   **Discover** - You can now export the output of the discover command in a CSV file. The ability to discover across all schemas in one’s warehouse is also added.\n\n**Improvements**\n\n*   We have made many changes to the way ID Stitcher config is written. We are forming a more complete opinion on the semantic model representation for customer’s data. Entities, IDs, and ID types are now defined in the PB project file. The model file syntax is also more organized and easier to write. To see examples of the new syntax check out the section on [Identity stitching](https://www.rudderstack.com/docs/profiles/core-concepts/identity-stitching/) or sample files by executing command `pb init pb-project`. The sample project file also contains include and exclude filters, to illustrate their usage.\n*   In PB command invocation, whenever a file is written, its location is now shown on the console and in log files.\n*   Many enhancements on how errors are handled inside the application.\n*   Massive improvements under the hood.\n\n**Bug Fixes**\n\n*   Fixed the issue in ID stitching where it was not picking up singleton components (i.e. the ones with only 1 edge), due to which they were getting skipped in the final output table.\n*   In the `init` command, not entering any value for target wasn’t setting it to default value as “dev”.\n*   Pressing Ctrl+C wasn’t exiting the application.\n*   The command `init profile` now appends to an existing profile, instead of overwriting it.\n*   Fixed the issue in `discover` command where the material table name was being displayed instead of the model name.\n\n**Known Issues:**\n\n*   Warning: While the run command is being executed, canceling it by pressing Ctrl+C doesn’t work as expected. Though it will stop the program’s execution on the CLI, the query will keep running on the data warehouse. This is a documented Snowflake behavior.\n*   In a model, an input can’t use columns named “MAIN\\_ID”, “OTHER\\_ID”, “OTHER\\_ID\\_TYPE”, or “VALID\\_AT” in its ID SQL.\n*   The web app is not showing a description and last run on the landing page.\n*   In the web app, date filters to find PB runs aren’t working.\n*   In the web app, when the PB project is running, the screen shows an incorrect start timestamp.\n*   Artifacts list changes when a project is running versus when it completes execution. Since all runs on the same Kubernetes pod share the same project folder, we are creating artifacts of different runs under the same parent folder. So, the same folder is currently shown for different runs of the project. In the next release, we will configure different folders for different runs to isolate them.\n*   In case of feature table models, the compile command doesn’t always show error if the input SQL is buggy. Thise error may still be found when the model is run.\n*   When creating a profile via `init` command, pressing the Ctrl+C command doesn’t exit the application.\n*   Creating a PB Project doesn’t currently include a sample independent ID stitcher. Instead, it is a child model to the generated feature table model.\n*   We are working toward better readability of the logger file. We welcome any feedback here.\n*   The command `pb discover features` needs to show a few more fields.\n*   Every time `pb run` is executed for a feature table, it adds a new row to the output of pb discover features. Only one row should appear for each feature.\n*   Export to CSV for the discover command should work for subcommands and also generate files in an output folder.\n*   Some no-op parameters are shown upon passing the help flag(-h) to `validate access` command.\n*   In some cases, error isn’t shown if an unknown flag is used.\n*   Scheduling UI isn’t sometimes fully responsive about when the run will take place.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The documentation for September release does not completely match with the current release. We are currently working on updating the documentation and will have new versions out soon. Please contact the Data Apps team if you are confused by some deviation.\n\n## Version 0.1.0\n\n_18 August 2022_\n\nWe are now in beta! Please do try out PB and share your feedback with us, so that we can make it better.\n\n**What’s New**\n\n*   **ID Stitcher** - ID Stitching solves the problem of tying different identities together, for the same user across different sessions/devices. With v0.1.0, we launch PB ID Stitching. It provides an easy to use and powerful interface to specify Id Stitching inputs.\n*   **Command Line Interface** - Our CLI tool works on Linux, Windows and Mac machines. Using it you can setup a profile having connection to your Database, make a PB project, create SQL from models, run ID stitcher models directly on the Warehouse, and discover all the created models/entities/sources on DW.\n\n**Improvements**\n\n*   We have enhanced the speed of Discover and Compile commands, from minutes to a few seconds.\n*   The description of a few commands in Help has been improved.\n\n**Bug Fixes**\n\n*   The command for discovering entities wasn’t working, which has now been resolved.\n*   Fixed the bug on init profile command where siteconfig wasn’t getting created on first-time installations.\n*   A few bugs resolved related to output of discover command.\n\n**Known Issues:**\n\n*   Warning: While the run command is being executed, please do not cancel it by pressing Ctrl+C. Though it will stop the program’s execution on CLI, the query will keep running on the data warehouse. This is a documented Snowflake behaviour.\n*   Null ID’s in ID stitcher. If first listed Id is null, the entire row may be ignored. That means, results are silently incorrect.\n*   If first listed ID is null, the entire row may be ignored. The first listed ID is assumed to be the key ID. If it is ever null the results may be incorrect.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Changelog | RudderStack Docs",
    "description": "Changelog for all the Profiles versions.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/predictions/",
    "markdown": "# Predictions (Early Access) | RudderStack Docs\n\nUse Profiles’ predictive features to train machine learning models.\n\n* * *\n\n*     7 minute read  \n    \n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Predictions is part of our [Early Access Program](https://www.rudderstack.com/docs/resources/early-access-program/), where we work with early users and customers to test new features and get feedback before making them generally available. These features are functional but can change as we improve them. We recommend connecting with our team before running them in production.\n> \n> [Contact us](https://www.rudderstack.com/contact/) to get access to this feature.\n\nPredictions extends Profiles’ standard [feature development](https://www.rudderstack.com/docs/profiles/core-concepts/feature-development/) functionality. It lets you easily create predictive features in your warehouse and answer questions like:\n\n*   Is a customer likely to churn in the next 30 days?\n*   Will a user make a purchase in the next 7 days?\n*   Is a lead going to convert?\n*   How much is a user likely to spend in the next 90 days?\n\nFurther, you can add the predicted feature to user profiles in your warehouse automatically and deliver ML-based segments and audiences to your marketing, product, and customer success teams.\n\nThe following self-guided tour shows you how to build the predictive traits. You can also follow the [Predictions sample project](https://www.rudderstack.com/docs/profiles/example/predictive-features-snowflake/) guide and build the project yourself, including sample data.\n\n## Use cases\n\n*   **Churn prediction**: Predicting churn is one of the crucial initiatives across businesses. Without a predicted churn score, your actions are reactive, whereas you can act proactively with a user trait like `is_likely_to_churn`. Once you have such features, you can activate them with the appropriate outreach programs to prevent user churn.\n    \n*   **Customer LTV prediction**: Predictions helps you understand your customers’ purchasing behavior over time. You can predict how much amount a particular customer is likely to spend within the predicted time range.\n    \n\n## Python model\n\nYou can generate predictive features using a `python_model` which involves two key steps - `train` and `predict`.\n\nThe following `profiles.yaml` file shows how to use a `python_model`:\n\n```\nmodels:\n  - name: shopify_churn\n    model_type: python_model\n    model_spec:\n      occurred_at_col: insert_ts\n      entity_key: user\n      validity_time: 24h # 1 day\n      py_repo_url: https://github.com/rudderlabs/rudderstack-profiles-classifier.git # Do not modify \n      # this value as the actual logic resides in this repo.\n      train:\n        file_extension: .json\n        file_validity: 60m\n        inputs: &inputs\n          - packages/feature_table/models/shopify_user_features\n        config:\n          data:\n            label_column: is_churned_7_days \n            label_value: 1\n            prediction_horizon_days: 7\n            output_profiles_ml_model: *model_name\n            eligible_users: lower(country) = 'us' and amount_spent_overall > 0\n            inputs: *inputs\n            entity_column: user_main_id\n            recall_to_precision_importance: 1.0\n          preprocessing: \n            ignore_features: [name, gender, device_type]\n      predict:\n        inputs:\n          - packages/feature_table/models/shopify_user_features\n        config:\n          outputs:\n            column_names:\n              percentile: &percentile_name percentile_churn_score_7_days\n              score: churn_score_7_days\n            feature_meta_data: &feature_meta_data\n              features:\n                - name: *percentile_name\n                  description: 'Percentile of churn score. Higher the percentile, higher the probability of churn'\n```\n\n#### Model parameters\n\nThe detailed list of parameters used in the `python_model` along with their description are listed below:\n\n| Parameter | Description |\n| --- | --- |\n| `py_repo_url`  <br>Required | The actual logic for Predictions resides in this remote repository. DO NOT modify this value. |\n| `file_extension`  <br>Required | Indicates the file type. This is a static value and does not need to be modified. |\n| `file_validity`  <br>Required | If the last trained model is older than this duration, then the model is trained again. |\n| `inputs`  <br>Required | Path to the base feature table project. You must add `&inputs` to it. |\n| `label_column`  <br>Required | Name of the feature (`entity_var`) you want to predict. It is defined in the feature table model. |\n| `label_value` | Expected label value for users who performed the event |\n| `prediction_horizon_days`  <br>Required | Number of days in future for which you want to make the prediction.<br><br>See [Prediction horizon days](https://www.rudderstack.com/docs/profiles/glossary/#prediction-horizon-days) for more information. |\n| `output_profiles_ml_model`  <br>Required | Name of the output model. |\n| `eligible_users` | Eligibilty criteria for the users for which you want to define predictive features. You can set this criteria by defining a SQL statement referring to the different `entity_vars`. To build a model for all the available users, you can leave this parameter as blank.<br><br>For example, if you want to train the model and make predictions only for the paying users from US, then define `country='US' and is_payer=true`. |\n| `config.data.inputs` | Path to the referenced project. |\n| `entity_column` | If you change the value of`id_column_name` in the ID stitcher model, you should specify it here. This field is optional otherwise. |\n| `recall_to_precision_importance` | Also referred to as **beta** in f-beta score, this field is used in classification models to fine-tune the model threshold and give more weight to recall against precision.<br><br>**Note**: This is an optional parameter. If not specified, it defaults to `1.0`, giving equal weight to precision and recall. |\n| `ignore_features` | List of columns from the feature table which the model should ignore while training. |\n| `percentile`  <br>Required | Name of column in output table having percentile score. |\n| `score`  <br>Required | Name of column in output table having probabilistic score. |\n| `description`  <br>Required | Custom description for the predictive feature. |\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> If you want to run your python model locally using a [CLI setup](https://www.rudderstack.com/docs/profiles/get-started/profile-builder/), you must set up a python environment with the required packages and add the python path to your [siteconfig.yaml](https://www.rudderstack.com/docs/profiles/cli-user-guide/structure/#site-configuration-file-configuration.md) file.\n\n## Project setup\n\nThis section highlights the project setup steps for a sample churn prediction and LTV model.\n\n### Prerequisites\n\n*   You must be using a [Snowflake](https://www.rudderstack.com/docs/destinations/warehouse-destinations/snowflake/), [BigQuery](https://www.rudderstack.com/docs/destinations/warehouse-destinations/bigquery/), or [Redshift](https://www.rudderstack.com/docs/destinations/warehouse-destinations/redshift/) warehouse.\n*   You must set up a standard Profiles project with a [feature table model](https://www.rudderstack.com/docs/profiles/example/feature-table/).\n*   **Optional**: If you are using Snowflake, you might need to create a [Snowpark](https://www.snowflake.com/en/data-cloud/snowpark/)\\-optimized warehouse if your dataset is significantly large.\n\n### Churn prediction/LTV model\n\n#### 1\\. Create a Profiles project with Feature Table model\n\nFollow the [Feature table](https://www.rudderstack.com/docs/profiles/example/feature-table/) guide to create a Profiles project. Your project must include the definition of the feature you want to predict.\n\nFor example, to predict 30-day inactive churn, you should define it as a feature (`entity_var`) in the feature table so that the model knows how to compute this for historic users.\n\n```\nentity_var:\n  name: churn_30_days\n  select: case when days_since_last_seen >= 30 then 1 else 0 end\n```\n\n#### 2\\. Create a python model and train it\n\nCreate a [`python_model`](#python-model) and pass the Feature table model as an input.\n\nAdd the following set of parameters in the `train` block:\n\n```\ntrain:\n    file_extension: .json\n    file_validity: 168h\n    inputs: &inputs\n      - packages/feature_table/models/shopify_user_features\n    config:\n      data: &model_data_input_configs\n        label_column: churn_30_days\n        label_value: 1\n        prediction_horizon_days: 30\n        output_profiles_ml_model: *model_name\n        eligible_users: ''\n        inputs: *inputs\n        entity_column: user_main_id\n        recall_to_precision_importance: 1.0\n      preprocessing: \n        ignore_features: [name, gender, device_type]\n```\n\n```\ntrain:\n    file_extension: .json\n    file_validity: 168h\n    inputs: &inputs\n      - packages/feature_table/models/shopify_user_features\n    config:\n      data: &model_data_input_configs\n        label_column: amount_spent_past_7_days\n        task: regression\n        prediction_horizon_days: 7\n        output_profiles_ml_model: *model_name\n        eligible_users: ''\n        inputs: *inputs\n        entity_column: user_main_id\n      preprocessing: \n        ignore_features: [name, gender, device_type]\n```\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Note that:\n> \n> *   Unlike churn prediction, you should not specify the `label_value` and `recall_to_precision_importance` fields.\n> *   The LTV model introduces a new parameter called `task` which you must set to `regression`. Profiles assumes a classification model by default, unless explicitly specified otherwise.\n\n#### 3\\. Define predictive features\n\nAdd the following set of parameters in the `predict` block:\n\n```\npredict:\n    inputs:\n      - packages/feature_table/models/shopify_user_features\n    config:\n      data: *model_data_input_configs\n      outputs:\n        column_names:\n          percentile: &percentile_name percentile_churn_score_7_days\n          score: churn_score_7_days\n        feature_meta_data: &feature_meta_data\n          features:\n            - name: *percentile_name\n              description: 'Percentile of churn score. Higher the percentile, higher the probability of churn'\n```\n\n```\npredict:\n    inputs:\n      - packages/feature_table/models/shopify_user_features\n    config:\n      data: *model_data_configs\n      preprocessing: *model_prep_configs\n      outputs:\n        column_names:\n          percentile: &percentile_name percentile_predicted_amount_spent\n          score: predicted_amount_spent\n        feature_meta_data: &feature_meta_data\n          features:\n            - name: *percentile_name\n              description: 'Percentile of predicted future LTV. Higher the percentile, higher the expected LTV.'\n```\n\n#### 4\\. Run your project\n\nOnce you have created the project, you can choose to run it using either of the following ways:\n\n**Using Profile CLI**\n\nIf you have created your Predictions Profiles project locally, run it using the `pb run` [CLI](https://www.rudderstack.com/docs/profiles/get-started/profile-builder/) command to generate output tables.\n\n**Using Profiles UI**\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> [Contact us](mailto:support@rudderstack.com) to enable this feature for your account.\n\nRun your Predictions Profiles project by first uploading it to a Git repository and then [importing it in the RudderStack dashboard](https://www.rudderstack.com/docs/profiles/get-started/import-from-git/#steps).\n\n## Output\n\nOnce your project run is completed, you can:\n\n*   View the output materials in your warehouse for the predictive features.\n*   Check the predicted value for any given user in the RudderStack dashboard’s [Profile Lookup](https://www.rudderstack.com/docs/profiles/get-started/quickstart-ui/#profile-details) section.\n*   View all predictive features in the **Entities** tab of your Profiles project:\n\n[![New personal access token in RudderStack dashboard](https://www.rudderstack.com/docs/images/profiles/predictive-features-2.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-2.webp)\n\nClick **Predictive features** to see the following view:\n\n[![New personal access token in RudderStack dashboard](https://www.rudderstack.com/docs/images/profiles/predictive-features.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features.webp)\n\nThe value of a predictive feature is a probability. You can consider it as `true` or `false` based on your threshold.\n\n## See Also\n\n*   [Predictive features](https://github.com/rudderlabs/rudderstack-profiles-classifier): Builds predictive features such as churn prediction, conversion prediction, etc.\n*   [Shopify churn model](https://github.com/rudderlabs/rudderstack-profiles-shopify-churn/): Builds a churn prediction score on top of the [Shopify library project](https://github.com/rudderlabs/profiles-shopify-features).\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Predictions (Early Access) | RudderStack Docs",
    "description": "Use Profiles' predictive features to train machine learning models.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/data-governance/overview/",
    "markdown": "# Data Governance Overview | RudderStack Docs\n\nLearn about RudderStack’s data governance offerings related to data quality and compliance.\n\n* * *\n\n*     5 minute read  \n    \n\nRudderStack’s data governance feature lets you set controls in place to ensure the quality and integrity of your data in a secure and compliant manner.\n\nSome key features of RudderStack’s data governance offerings include:\n\n*   [**Data quality**](#data-quality): RudderStack guarantees clean data collection at the source, eliminating time-consuming cleaning and wrangling work downstream.\n*   [**Data compliance**](#data-compliance): RudderStack’s data compliance toolkit makes it easy to manage consent, collection, storage, and deletion - all in one central platform.\n\n## Data quality\n\nBad customer data leads to more time spent on data cleaning and wrangling. It limits your ability to support business teams effectively, undermines your AI efforts, and ultimately hinders growth.\n\nRudderStack’s data quality toolkit equips you to collect clean data at the source, so you can spend less time wrangling and more time helping your business drive revenue. You can use it to collaborate on event definitions, manage violations with custom rules, monitor quality, and fix schemas in real time.\n\n[![Data quality](https://www.rudderstack.com/docs/images/data-governance/data-quality.webp)](https://www.rudderstack.com/docs/images/data-governance/data-quality.webp)\n\n### Event catalog\n\nRudderStack provides the [Data Catalog](https://www.rudderstack.com/docs/data-governance/data-catalog/) feature to build a comprehensive event catalog that you can use to set standardized data definitions for your tracking plans.\n\nRudderStack automatically builds an event catalog from all events ingested into the system via your sources. You can also create custom events and properties and add them to your catalog.\n\nWhile creating a new tracking plan, you can add the events and properties from your event catalog and avoid wasting time defining the tracking plan rules.\n\nSee the [Data Catalog](https://www.rudderstack.com/docs/data-governance/data-catalog/) guide for more details on this feature.\n\n### Event Audit API\n\nRudderStack’s [Event Audit API](https://www.rudderstack.com/docs/api/event-audit-api/) allows you to diagnose inconsistencies in your event data programmatically. The feature gives you access to information on all your events and their metadata, including event schema, event payload versions, data types, and more. With this access, your teams can quickly pinpoint the specific nature and source of event data inconsistencies.\n\nSee the [Event Audit API reference](https://www.rudderstack.com/docs/api/event-audit-api/) for more details.\n\n### Tracking plans\n\n[Tracking plans](https://www.rudderstack.com/docs/data-governance/tracking-plans/) let you proactively monitor and act on non-compliant event data coming into your RudderStack sources based on predefined plans. This helps minimize the risk of improperly configured event data breaking your downstream systems.\n\nTracking plans evaluate each incoming event for any inconsistencies and automatically flag violations like unplanned events, erroneous key/value properties, etc. You can also configure your plans to decide what to do with such events, whether to deliver them with a flag, deliver them to a specific destination, or drop them entirely.\n\n### Real-time schema fixes\n\nIf errors are propagated in events, you can use that information in the schema to customize schema fixes for each individual downstream destination. For example, you can fix a data type, delete a property, etc., to deliver a valid event payload.\n\nYou can apply these fixes in the pipeline by leveraging RudderStack’s [Transformations](https://www.rudderstack.com/docs/transformations/overview/) feature to transform faulty event payloads, meaning no dev tickets have to be opened to fix instrumentation upstream in websites and apps.\n\n### Health dashboard\n\nRudderStack’s intuitive health dashboard provides a global view of data health across all your pipelines and integrations, including metrics on data ingestion, delivery, and tracking plan violations.\n\nThe health dashboard is a central place to track trends in data volume and violations so you can identify and fix potential problems before they become acute and impact your downstream systems.\n\nSee the [Health Dashboard](https://www.rudderstack.com/docs/data-governance/health-dashboard/) guide for more details.\n\n## Data compliance\n\nAs privacy regulations tighten and businesses focus on protecting their customers’ sensitive information, data teams often feel the pain of inflexible infrastructure. Cumbersome processes and complex implementations to meet compliance standards create tedious work that slows down product and marketing teams.\n\nRudderStack’s warehouse-native architecture and robust data compliance toolkit make it easy to manage consent-based data collection, storage, and deletion all in one centralized platform.\n\n[![Data compliance](https://www.rudderstack.com/docs/images/data-governance/data-compliance.webp)](https://www.rudderstack.com/docs/images/data-governance/data-compliance.webp)\n\n### Consent management\n\nRudderStack’s holistic approach to consent management lets you:\n\n*   Implement both client-side and server-side consent categorization for each downstream integration.\n*   Set the pre- and post-consent SDK behavior, minimizing any data loss related to attribution, acquisition, and the overall user journey.\n*   Be fully compliant with the internal requirements and region-specific regulatory laws on a tool-by-tool basis, while simplifying implementation.\n*   Maintain granular control over the cookie and storage settings, in which you can map each downstream integration to specific consent categories.\n\nRudderStack offers a fully integrated consent solution with popular consent management tools like OneTrust, Ketch, and other custom-built systems.\n\nSee the [Consent management](https://www.rudderstack.com/docs/data-governance/consent-management/) guide for more details.\n\n### Cookieless tracking\n\nCookies are useful in gathering valuable insights that help in personalizing user experiences. However, gathering these insights while adhering to the stringent privacy norms can be a significant challenge.\n\nRudderStack’s cookieless tracking feature provides an efficient way of gathering user data without relying on cookies. It gives you complete control over what user information to store (`userId`, `anonymousId`, etc.) and where to store it (local storage, browser’s cookies, or not storing it at all) while loading the JavaScript SDK.\n\nSee [Cookieless Tracking](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/data-storage-cookies/persistent-data-storage/) to learn more and explore various configurations to use it.\n\n### User Suppression API\n\nRudderStack provides a [User Suppression API](https://www.rudderstack.com/docs/api/user-suppression-api/) that lets you programmatically create regulations to suspend data collection and delete data for specific users. You can apply these regulations across multiple destination integrations simultaneously and simplify the process of implementing compliance requests.\n\nSee the [User Suppression API reference](https://www.rudderstack.com/docs/api/user-suppression-api/) for more details.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Data Governance Overview | RudderStack Docs",
    "description": "Learn about RudderStack's data governance offerings related to data quality and compliance.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/resources/glossary/",
    "markdown": "# Glossary | RudderStack Docs\n\nFamiliarize yourself with the commonly used terms across RudderStack Profiles.\n\n* * *\n\n*     7 minute read  \n    \n\n## Cohorts\n\nA Cohort refers to a subset of instances of an entity meeting a specified set of characteristics, behaviors, or attributes. Using cohorts, you can define core customer segments and drive targeted marketing campaigns and deliver personalized experiences.\n\nFor example, you can define a cohort for users who purchased items in the last 90 days, users based in a specific geographical location, etc.\n\n## Custom Models (Python)\n\nOne can build custom Python models for ML by downloading pre-defined Python templates. The results are usually saved as attributes of related entities (for example, `churnProbability`).\n\nPython models and pymodels work differently. In case of Python, developers (both RudderStack and external) develop new model types in python using [profiles-rudderstack](https://pypi.org/project/profiles-rudderstack/) package. An example python package implementing a number of Python models is [profiles-pycorelib](https://pypi.org/project/profiles-pycorelib/).\n\n## Edge sources\n\nThe `edge_sources` field provides the input sources for an identity stitching model. You can specify it in the `models/profiles.yaml` file to list the input sources defined in the `inputs.yaml` file.\n\n## Entity\n\nEntity refers to a digital representation of a class of real world distinct objects for which you can create a profile. An entity can be a user, account, customer, product, or any other object that requires profiling.\n\n## `Entity var`/Entity features\n\nThese are various attributes related to an entity whose profile you are trying to create. For example, they can be `name`, `city`, `LastVisitTimestamp`, etc. for the `user` entity. Each attribute is called an `entity_var`, and it is derived by performing calculation or aggregation on a set of values. Together, all the attributes create a complete picture of the entity. By default, every `entity_var` gets stored as a feature, such as `days_active`, `last_seen`, etc.\n\n## Feature Views\n\nIf the features/traits of an entity are spread across multiple entity vars and ML models, you can use Feature Views to get them together into a single view. These models are usually defined in `pb_project.yaml` file by creating entries under `feature_views` key with corresponding entity.\n\n## Features\n\nFeatures are inputs for the machine learning model. In a general sense, features are pieces of user information we already know. For example, number of days they opened the app in the past week, items they left in the cart, etc.\n\n## Feature tables (legacy)\n\nFeature tables are the outputs based on events, user attributes, and other defined criteria across any data set in your data warehouse. You can define models that can create feature tables for users with ID stitching, ML notebooks and external sources, etc.\n\n## ID Stitcher\n\nData usually comes from different sources and these sources may assign different IDs. To track a user’s journey (or any other entity) uniquely across all these data sources, we need to stitch together all these IDs. ID stitching helps map different IDs of the same user (or any other entity) to a single canonical ID. It does this by doing connected component analysis over the Id-Id edge graph specified in its configuration.\n\n## ID Collator\n\nID Collator is similar to ID Stitcher. It is used when entity has only a single ID type associated (for example, session IDs). In these cases, connected component analysis is not required and we use a simpler model type called ID Collator. It consolidates all entity IDs from multiple input tables into a single collated list.\n\n## Inputs\n\nInputs refers to the input data sources used to create the material (output) tables in the warehouse. The inputs file (`models/inputs.yaml`) lists the tables/views you use as input sources, including the column name and SQL expression for retrieving the values.\n\nYou can use data from various input sources such as event stream (loaded from event data), ETL extract (loaded from Cloud Extract), and any existing tables in the warehouse (generated by external tools).\n\n## Input var\n\nInstead of a single value per entity ID, it represents a single value per row of an input model. Think of it as representing addition of an additional column to an input model. It can be used to define entity features. However, it is not itself an entity feature because it does not represent a single value per entity ID.\n\n## Label\n\nLabel is the output of the machine learning model and is the metric we want to predict. In our case, it is the unknown user trait we want to know in advance.\n\n## Machine learning model\n\nA machine learning model can be thought of as a function that takes in some input parameters and returns an output.\n\nUnlike regular programming, this function is not explicitly defined. Instead, a high level architecture is defined and several pieces are filled by looking at the data. This whole process of filling the gaps is driven by different optimisation algorithms as they try to learn complex patterns in the input data that explain the output.\n\n## Materialization\n\nMaterialization refers to the process of creating output tables/views in a warehouse by running models. You can define the following fields for materialization:\n\n*   `output_type`: Determines the type of output you want to create in your warehouse. Allowed values are:\n    \n    *   `table`: Output is built and stored in a table in the warehouse.\n    *   `view`: Output is built and stored as a view in the warehouse.\n    *   `ephemeral`: Output is created in the form of temporary data which serves as an intermediary stage for being consumed by another model.\n*   `run_type`: Determines the run type of models. Allowed values are:\n    \n    *   `discrete` (default): In this mode, the model runs in a full refresh mode, calculating its results from the input sources. A SQL model supports only the `discrete` run type.\n    *   `incremental`: In this mode, the model calculates its results from the previous run and only reads row inserts and updates from the input sources. It only updates or inserts data and does not delete anything making it efficient. However, only the identity stitching model supports this mode.\n\n## Material tables\n\nWhen you run the PB models, they produce materials - that is, tables/views in the database that contain the results of that model run. These output tables are known as material tables.\n\n## Predictions\n\nThe model’s output is called a prediction. A good model makes predictions that are close to the actual label. You generally need predictions where the labels are not available. In our case, most often the labels come a few days later.\n\n## Prediction horizon days\n\nThis refer to the number of days in advance when we make the prediction.\n\nFor example, statements like “A user is likely to sign-up in the next 30 days, 90 days, etc.” are often time-bound, that is, the predictions are meaningless without the time period.\n\n## Profile Builder (PB)\n\nProfile Builder (PB) is a command-line interface (CLI) tool that simplifies data transformation within your warehouse. It generates customer profiles by stitching data together from multiple sources. It takes existing tables or the output of other transformations as input to generate output tables or views based on your specifications.\n\n## PB project\n\nA PB project is a collection of interdependent warehouse transformations. These transformations are run over the warehouse to query the data for sample outputs, discover features in the warehouse, and more.\n\n## PB model\n\nAny transformation that can be applied to the warehouse data is called a PB model. RudderStack supports various types of models like ID stitching, feature tables, Python models, etc.\n\n## Schema versions\n\nEvery PB release supports a specific set of project schemas. A project schema determines the correct layout of a PB project, including the exact keys and their values in all project files.\n\n## SQL template models\n\nSometimes the standard model types provided by Profiles are insufficient to capture complex use cases. In such cases, RudderStack supports the use of SQL template models to explicitly templatize SQL.\n\nSQL template models can be used as an input to an entity-var/ input-var or as an edge-source in id-stitcher.\n\n## Timegrain\n\nUsing `time_grain` parameter for a model, you can restrict the context timestamp of that model to the specified time boundary. In other words, a feature v1 with `time_grain` value of a `day` will look at all the data up to UTC 00:00 hrs of any particular day only.\n\nIf you compute that feature at 3:00PM or 5:00PM, the result would be the same because its inputs change only at the very beginning of the day. Similarly, if `time_grain` for a model is set to a `week`, it needs to be run only once a week. Running it twice within the week won’t change its results.\n\n## Training\n\nTraining refers to the process of a machine learning model looking at the available data and trying to learn a function that explains the [labels](#label).\n\nOnce you train a model on historic users, you can use it to make predictions for new users. You need to keep retraining the model as you get new data so that the model continues to learn any emerging patterns in the new users.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Glossary | RudderStack Docs",
    "description": "Familiarize yourself with the commonly used terms across RudderStack Profiles.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/activation-api/",
    "markdown": "# Activation API (Early Access) | RudderStack Docs\n\nExpose user profiles stored in your Redis instance over an API.\n\n* * *\n\n*     7 minute read  \n    \n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> The Activation API is part of our [Early Access Program](https://www.rudderstack.com/docs/resources/early-access-program/), where we work with users and customers to test new features and get feedback before making them generally available. These features are fully functional but can change as we improve them. We recommend connecting with our team before running them in production.\n> \n> [Contact us](https://www.rudderstack.com/contact/) if you would like access to this feature.\n\nWith RudderStack’s Activation API, you can fetch enriched user traits stored in your Redis instance and use them for near real-time personalization for your target audience.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> You must have a working Redis instance in place before setting up the connection.\n\n[![Activation API](https://www.rudderstack.com/docs/images/profiles/activation-api.webp)](https://www.rudderstack.com/docs/images/profiles/activation-api.webp)\n\n## Overview\n\nA brief summary of how the Activation API works:\n\n1.  Sync all your customer 360 data from your Profiles project to your Redis store.\n2.  The Activation API sits on top of this Redis instance and provides endpoints for retrieving and using the enriched user data for personalization.\n\n## How to use the Activation API\n\n1.  In your Profiles project settings, scroll down to **Activation API** and turn on the **Enable sync to Redis** toggle.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Before you enable the Activation API toggle, make sure that:\n> \n> *   You have at least one successful Profiles run.\n> *   Your `pb_project.yaml` > `entities` defines a `feature_views` property.\n\n[![Enable Redis sync for using Activation API](https://www.rudderstack.com/docs/images/profiles/enable-redis.webp)](https://www.rudderstack.com/docs/images/profiles/enable-redis.webp)\n\n2.  Enter the [account credentials for your Redis instance](#redis-configuration) and click **Create**. This will also create a Redis destination in your dashboard.\n\n[![Enable Redis sync for using Activation API](https://www.rudderstack.com/docs/images/profiles/enable-redis-sync.webp)](https://www.rudderstack.com/docs/images/profiles/enable-redis-sync.webp)\n\n3.  [Generate a personal access token](#faq) with **Admin** role in your RudderStack dashboard. You will need this token for authenticating the Activation API.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Personal access token with an **Admin** role is only available to the **Org Admin** users. Refer [User management](https://www.rudderstack.com/docs/dashboard-guides/user-management/#org-admin) for more information.\n\nNote your Redis destination ID from the [**Settings**](https://www.rudderstack.com/docs/dashboard-guides/destinations/#destination-details) tab. Further, [use the Activation API endpoint](#get-user-profiles) to access your Redis instance and get user data.\n\nThis API uses [Bearer Authentication](https://swagger.io/docs/specification/authentication/bearer-authentication/) for authenticating all requests. Set the [personal access token](#faq) as the bearer token for authentication.\n\n## Base URL\n\n```\nhttps://profiles.rudderstack.com/v1/\n```\n\n## Get user profiles\n\n#### Request body\n\nString\n\nRedis destination ID.\n\nObject\n\nID containing `type` and `value`\n\n```\n{\n  \"entity\": <entity_type>,  // User, project, account, etc.\n  \"destinationId\": <redis_destination_id> , // Redis destination ID\n  \"id\": {\n    \"type\": <id_type>,\n    \"value\": <id_value>\n  }\n}\n```\n\n#### Example request\n\n```\nPOST /v1/activation HTTP/1.1\nHost: profiles.rudderstack.com\nContent-Type: application/json\nAuthorization: Bearer <personal_access_token>\nContent-Length: 90\n\n{\n \"entity\": <entity_type>,\n \"destinationId\": <redis_destination_id>, // Redis destination ID\n \"id\": {\n   \"type\": <id_type>,\n   \"value\": <id_value>\n }\n}\n```\n\n```\ncurl --location 'https://profiles.rudderstack.com/v1/activation' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Bearer <personal_access_token>' \\\n--data '{\n \"entity\": <entity_type>,\n \"destinationId\": <redis_destination_id>, // Redis destination ID\n \"id\": {\n   \"type\": <id_type>,\n   \"value\": <id_value>\n }\n}'\n```\n\n```\nconst axios = require('axios');\nlet data = JSON.stringify({\n  \"destinationId\": <redis_destination_id>,\n  \"entity\": <entity_type>,\n  \"id\": {\n    \"type\": <id_type>,\n    \"value\": <id_value>\n  }\n});\n\nlet config = {\n  method: 'post',\n  maxBodyLength: Infinity,\n  url: 'https://profiles.rudderstack.com/v1/activation',\n  headers: {\n    'Content-Type': 'application/json',\n    'authorization': 'Bearer <personal_access_token>'\n  },\n  data: data\n};\n\naxios.request(config)\n  .then((response) => {\n    console.log(JSON.stringify(response.data));\n  })\n  .catch((error) => {\n    console.log(error);\n  });\n```\n\n#### Responses\n\n*   If the personal access token is absent or trying to access a destination to which it does not have access:\n\n```\nstatusCode: 401\nResponse: {\n  \"error\": \"Unauthorized request. Please check your access token\"\n}\n```\n\n*   If the destination is not Redis or the destination ID is absent/blank:\n\n```\nstatusCode: 404\nResponse: {\n  \"error\": \"Invalid Destination. Please verify you are passing the right destination ID\"\n}\n```\n\n*   If ID is present:\n\n```\nstatusCode: 200\nResponse:\n{\n  \"entity\": <entity_type>,\n  \"id\": {\n    \"type\": <id_type>,\n    \"value\": <id_value>\n  },\n  \"data\": {\n    <traits_from_Redis>\n  }\n}\n```\n\n*   If ID is not present in Redis:\n\n```\nstatusCode: 200\nResponse:\n{\n  \"entity\": <entity_type>,\n  \"id\": {\n    \"type\": <id_type>,\n    \"value\": <id_value>\n  },\n  \"data\": {}\n}\n```\n\n## Use case\n\nYou can use the Activation API for real-time personalization. Once you fetch the user traits from your Redis instance via the API, you can pull them into your client application to alter the application behavior in real-time based on user interactions.\n\nYou can respond immediately with triggered, user-focused messaging based on actions like page views or app clicks and provide a better customer experience.\n\n[![Real time personalization use case](https://www.rudderstack.com/docs/images/profiles/activation-api-use-case.webp)](https://www.rudderstack.com/docs/images/profiles/activation-api-use-case.webp)\n\n## Redis configuration\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> You must have a working Redis instance in place before setting up the connection.\n\n*   **Address**: Enter the public endpoint of your Redis database. If you are using [Redis Cloud](https://app.redislabs.com/#/), you can find this endpoint by going to your Redis database and navigating to **Configuration** tab > **General**.\n\n[![Redis database public endpoint](https://www.rudderstack.com/docs/images/profiles/redis-public-endpoint.webp)](https://www.rudderstack.com/docs/images/profiles/redis-public-endpoint.webp)\n\n*   **Password**: Enter the database password. You can find it in the **Security** section of the **Configuration** tab:\n\n[![Redis database password](https://www.rudderstack.com/docs/images/profiles/redis-database-password.webp)](https://www.rudderstack.com/docs/images/profiles/redis-database-password.webp)\n\n*   **Cluster Mode**: Turn on this setting if you’re connecting to a Redis cluster.\n*   **Secure**: Enable this setting to secure the TLS communication between RudderStack Redis client and your Redis server.\n\n## Data mapping\n\nRudderStack creates multiple Reverse ETL sources automatically based on your Profiles project. You will see separate sources for different `id_served` connected to the same Redis destination.\n\nThe following `pb_project.yaml` snippet shows the sources to be created:\n\n```\nentities:\n  - name: user\n    id_types:\n      - main_id\n      - user_id\n    feature_views:\n      using_ids:\n        - id: email\n          name: features_by_email # Optional. Takes default view name, if not specified.\n        - id: salesforce_id\n          name: salesforce_id_stitched_features\n      features: # Optional\n        - from: models/cart_feature_table\n          include:\n            - \"*\"\n```\n\n## FAQ\n\n#### How do I generate a personal access token to use the Activation API?\n\n1.  Log in to your [RudderStack dashboard](https://app.rudderstack.com/).\n2.  Go to **Settings** > **Your Profile** > **Account** tab and scroll down to **Personal access tokens**. Then, click **Generate new token**:\n\n[![New personal access token in RudderStack dashboard](https://www.rudderstack.com/docs/images/rudderstack-api/personal-access-token-1.webp)](https://www.rudderstack.com/docs/images/rudderstack-api/personal-access-token-1.webp)\n\n3.  Enter the **Token name**. Set **Role** to **Admin** and click **Generate**.\n\n[![Personal access token name and role](https://www.rudderstack.com/docs/images/rudderstack-api/personal-access-token-2.webp)](https://www.rudderstack.com/docs/images/rudderstack-api/personal-access-token-2.webp)\n\n4.  Use the personal access token to authenticate to the Activation API.\n\n[![Personal access token details](https://www.rudderstack.com/docs/images/rudderstack-api/personal-access-token-3.webp)](https://www.rudderstack.com/docs/images/rudderstack-api/personal-access-token-3.webp)\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Save the generated token securely as it will not be visible again once you close this window.\n\n#### How can I make Profiles work with the Activation API?\n\nTo use the Activation API with your Profiles project, you need a successful run of your Profiles project that is not past the retention period.\n\nTo enable the Activation API for your Profiles project, turn on the **Enable sync to Redis** setting. A Profile run will then sync automatically.\n\n[![Toggle API in Settings](https://www.rudderstack.com/docs/images/rudderstack-api/activation-api-toggle-settings.png)](https://www.rudderstack.com/docs/images/rudderstack-api/activation-api-toggle-settings.png)\n\n#### Why am I getting an error trying to enable API in my instance for a custom project hosted on GitHub?\n\nFor GitHub projects, you need to explicitly add the IDs of the custom project that need to be served.\n\nIn your `pb_project.yaml` file, you can specify them as shown:\n\n```\nentities:\n  - name: user\n    id_types:\n      - main_id\n      - user_id\n    feature_views:\n      name: user_feature_view\n      using_ids:\n        - id: email\n          name: features_by_email\n        - id: salesforce_id\n          name: salesforce_id_stitched_features\n      features:\n        - from: models/cart_feature_table\n          include:\n            - \"*\"\n```\n\n#### If I force a full resync, stop it, and then start a new sync, does RudderStack always perform a full sync the next time?\n\nIt depends on the state of the task when it was canceled.\n\n*   If the sync is cancelled while RudderStack is preparing a snapshot, then next run depends on the state of the previous successful run and any mapping changes.\n*   If it is cancelled after the sync data is prepared, the next run is incremental.\n\nGenerally if a sync is cancelled manually, it is recommended to trigger a full sync if the previous cancelled task was a full sync. If the previously cancelled sync was incremental, triggering an incremental sync is recommended.\n\n#### Does RudderStack perform a full sync if I add a new column?\n\nRudderStack does not change the sync mode if you make any column additions. It triggers a full sync only if you change/update the data mappings, for example, if the newly added column is sent to the destination via the [Visual Data Mapper](https://www.rudderstack.com/docs/sources/reverse-etl/visual-data-mapper/).\n\nFor Profiles activation syncs, RudderStack updates the mappings and automatically sends all columns from the customer 360 view by triggering a full sync.\n\n#### Suppose I’m running a full sync and the Profiles job is running in parallel and finishes eventually. What happens to the scheduled sync? Does it get queued?\n\nRudderStack first creates a temporary snapshot copy of any sync when it starts. So its syncing the created copy. Even if a Profiles job is running in parallel, the sync - if started - is not impacted by it.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Activation API (Early Access) | RudderStack Docs",
    "description": "Expose user profiles stored in your Redis instance over an API.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/activations/",
    "markdown": "# Activations | RudderStack Docs\n\nPrivacy Overview\n\nThis site uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are as essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.\n\nNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.",
    "title": "Activations | RudderStack Docs",
    "description": "Activate your cohorts data in downstream systems to run targeted campaigns.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/resources/yaml-refresher/",
    "markdown": "# YAML Best Practices | RudderStack Docs\n\nQuick overview of YAML and its basics for use in Profiles.\n\n* * *\n\n*     4 minute read  \n    \n\nYAML is the preferred choice for writing Profile Builder files due to its simplicity and ease of use.\n\nThis guide explains the base concepts, syntax, and best practices for writing code in YAML.\n\n## What is YAML?\n\n[YAML](https://yaml.org/), short for **YAML Ain’t Markup Language** or **Yet Another Markup Language**, is a data serialization format often used in config files and exchange of data. A YAML file uses indentation, specific characters, and line breaks for representing various data structures.\n\n## Sample YAML file\n\nBelow is how a sample YAML document looks like. It contains key-value pairs where the keys are on the left, followed by a colon (`:`), and the associated values are on the right. The hierarchy and data structure is defined using indentation. The next section explains this in more detail.\n\n```\n# This is a comment\nperson:\n  name: Ruddy Buddy # Note the spacing used for indentation\n  age: 42\n  is_employed: true\n  address: # An object called address\n    street: Jefferson Davis Highway\n    city: Ruther Glen\n    state: Vermont\n    phone: 555-90-210\n  favorite_sports: # A list\n    - soccer\n    - baseball\n```\n\nThe above code has details of an object called `person` with properties like `name`, `age`, `gender`, `is_student`, `address` and `favorite sports`.\n\nHere’s how the same YAML file looks in the JSON format:\n\n```\n{\n  \"person\": {\n    \"name\": \"Ruddy Buddy\",\n    \"age\": 42,\n    \"is_employed\": true,\n    \"address\": {\n      \"street\": \"Jefferson Davis Highway\",\n      \"city\": \"Ruther Glen\",\n      \"state\": \"Vermont\",\n      \"phone\": \"555-90-210\"\n    },\n    \"favorite_sports\": [\n      \"soccer\",\n      \"baseball\"\n    ]\n  }\n}\n```\n\n## Indentation\n\nIn YAML, the indentation is done using spaces - to define the structure of data. Throughout the YAML file, the number of spacing should be consistent. Typically, we use two spaces for indentation. YAML is whitespace-sensitive, so do not mix spaces and tabs.\n\n```\n# Example of correct indentation\nperson:\n  name: Ruddy Buddy # We used 2 spaces\n  age: 42\n\n# Example of incorrect indentation\nperson:\n  name: Ruddy Buddy \n    age: 42 # We mixed spacing and tabs\n```\n\nAs shown above, YAML has single-line comments that start with hash (`#`) symbol, for providing additional explanation or context in the code. Comments are used to improve readability and they do not affect the code’s functionality.\n\n```\n# YAML comment\nperson:\n  name: Ruddy Buddy # Name of the person\n  age: 42 # Age of the person\n```\n\n## Data types in YAML\n\nYAML supports several data types:\n\n*   **Scalars**: Represent strings, numbers, and boolean values.\n*   **Sequences**: Represent lists and are denoted using a hyphen (`-`).\n*   **Mappings**: Key-value pairs used to define objects or dictionaries using colon (`:`).\n\n```\n# Example of data types in YAML\nperson:\n  name: Ruddy Buddy # Scalar (string)\n  age: 42 # Scalar (number)\n  is_employed: true # Scalar (boolean)\n  address: # Mapping (object)\n    street: Jefferson Davis Highway\n    city: Ruther Glen\n    state: Vermont\n    phone: 555-90-210\n  favorite_sports: # Sequence (list)\n    - soccer\n    - baseball\n```\n\n## Chomp modifiers\n\nYAML provides two chomp modifiers for handling line breaks in scalar values.\n\n*   `>`: Removes all newlines and replaces them with spaces.\n\n```\ndescription: >\n  Here is an example of long description\n  which has multiple lines. Later, it\n  will be converted into a single line.  \n```\n\n*   `|`: Preserves line breaks and spaces.\n\n```\ndescription: |\n  Here is another long description, however\n  it will preserve newlines and so the original\n  format shall be as-it-is.  \n```\n\n## Special characters\n\nYou can use escape symbols for special characters in YAML. For example, writing an apostrophe in description can cause the YAML parser to fail. In this case, you can use the escape character.\n\n## Best practices for writing YAML\n\nFollow these best practices for writing clean YAML code in your Profiles projects:\n\n*   Always keep consistent indentation (preferably spaces over tabs).\n*   Give meaningful names to your keys.\n*   Avoid excessive nesting.\n*   YAML is case sensitive, so be mindful of that.\n*   Add comments wherever required.\n*   Use blank lines to separate sections like ID stitcher, feature table, etc.\n*   If your strings contain special characters, then use escape symbols.\n*   Make sure you end the quotes in strings to avoid errors.\n*   Use chomp modifiers for multi-line SQL.\n\n## Conclusion\n\nThe above guidelines constitute some best practices to write effective [Builder](https://www.rudderstack.com/docs/profiles/get-started/profile-builder/) code in Profiles. You can also see the following references:\n\n*   [YAML for VS Code](https://marketplace.visualstudio.com/items?itemName=redhat.vscode-yaml): Extension for comprehensive YAML support in Visual Studio Code.\n*   [YAML Lint](https://www.yamllint.com/) for linting.\n\nFor more information or in any case of any issues, [contact](mailto:support@rudderstack.com) the RudderStack team.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "YAML Best Practices | RudderStack Docs",
    "description": "Quick overview of YAML and its basics for use in Profiles.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/faq/",
    "markdown": "# Profiles FAQ | RudderStack Docs\n\nCommonly asked questions on RudderStack Profiles.\n\n* * *\n\n*     35 minute read  \n    \n\nThis guide contains solutions for some of the commonly asked questions on Profiles. For queries or issues not listed in this guide, contact [RudderStack Support](mailto:support@rudderstack.com).\n\n## Setup and installation\n\n**I have installed Python3, yet when I install and execute `pb` it doesn’t return anything on screen.**\n\nTry restarting your Terminal/Shell/PowerShell and try again.\n\nYou can also try to find the location of your Python executable. PB would be installed where the executables embedded in other Python packages are installed.\n\n**I am an existing user who updated to the new version and now I am unable to use the PB tool. On Windows, I get the error:** `'pb' is not recognized as an internal or external command, operable program or batch file.`\n\nExecute the following commands to do a fresh install:\n\n1.  `pip3 uninstall profiles-rudderstack-bin`\n2.  `pip3 uninstall profiles-rudderstack`\n3.  `pip3 install profiles-rudderstack --no-cache-dir`\n\n**I am unable to download, getting** `ERROR: Package 'profiles-rudderstack' requires a different Python: 3.7.10 not in '>=3.8, <=3.10'`\n\nUpdate your Python 3 to a version greater than or equal to 3.8 and less than or equal to 3.10.\n\n**I am unable to download profile builder by running `pip3 install profiles-rudderstack` even though I have Python installed.**\n\nFirstly, make sure that Python3 is correctly installed. You can also try to substitute `pip3` with `pip` and execute the install command.\n\nIf that doesn’t work, it’s high likely that Python3 is accessible from a local directory.\n\n1.  Navigate to that directory and try the install command again.\n2.  After installation, PB should be accessible from anywhere.\n3.  Validate that you’re able to access the path using `which pb`.\n4.  You may also execute `echo $PATH` to view current path settings.\n5.  In case it doesn’t show the path then you can find out where |ProductName| is installed using :substitution-code:`pip3 show profiles-rudderstack`. This command will display a list of the files associated with the application, including the location in which it was installed, navigate to that directory.\n6.  Navigate to `/bin` subdirectory and execute command `ls` to confirm that `pb` is present there.\n7.  To add the path of the location where PB is installed via pip3, execute: `export PATH=$PATH:<path_to_application>`. This will add the path to your system’s PATH variable, making it accessible from any directory. It is important to note that the path should be complete and not relative to the current working directory.\n\nIf you still face issues, then you can try to install it manually. [Contact us](mailto:support@rudderstack.com) for the executable file and download it on your machine. Follow the below steps afterwards:\n\n1.  Create `rudderstack` directory: `sudo mkdir /usr/local/rudderstack`.\n2.  Move the downloaded file to that directory: `sudo mv <name_of_downloaded_file> /usr/local/rudderstack/pb`.\n3.  Grant executable permission to the file: `chmod +x /usr/local/rudderstack/pb`.\n4.  Navigate to directory `/usr/local/rudderstack` from your file explorer. Ctrl+Click on pb and select **Open** to run it from Terminal.\n5.  Symlink to a filename pb in `/usr/local/bin` so that command can locate it from env PATH. Create file if it does not exist: `sudo touch /usr/local/bin/pb`. Then execute`sudo ln -sf /usr/local/rudderstack/pb /usr/local/bin/pb`.\n6.  Verify the installation by running `pb` in Terminal. In case you get error `command not found: pb` then check if `/usr/local/bin` is defined in PATH by executing command: `echo $PATH`. If not, then add `/usr/local/bin` to PATH.\n\n1.  If the Windows firewall prompts you after downloading, proceed with `Run Anyway`.\n2.  Rename the executable as `pb`.\n3.  Move the file to a safe directory such as `C:\\\\Program Files\\\\Rudderstack`, create the directory if not present.\n4.  Set the path of `pb.exe` file in environment variables.\n5.  Verify the installation by running `pb` in command prompt.\n\n**When I try to install Profile Builder tool using pip3 I get error message saying: `Requirement already satisfied`**\n\nTry the following steps:\n\n1.  Uninstall PB using `pip3 uninstall profiles-rudderstack`.\n2.  Install again using `pip3 install profiles-rudderstack`.\n\nNote that this won’t remove your existing data such as models and siteconfig files.\n\n**I have multiple models in my project. Can I run only a single model?**\n\nYes, you can. In your spec YAML file for the model you don’t want to run, set `materialization` to `disabled`:\n\n```\nmaterialization:\n    enable_status: disabled\n```\n\nA sample `profiles.yaml` file highlighted a disabled model:\n\n```\nmodels:\n- name: test_sql\n  model_type: sql_template\n  model_spec:\n    validity_time: 24h# 1 day\n    materialization:                \n      run_type: discrete\n      enable_status: disabled  // Disables running the model.\n    single_sql: |\n        {%- with input1 = this.DeRef(\"inputs/tbl_a\") -%}\n          select id1 as new_id1, {{input1}}.*\n            from {{input1}}\n        {%- endwith -%}        \n    occurred_at_col: insert_ts\n    ids:\n      - select: \"new_id1\"\n        type: test_id\n        entity: user\n```\n\n**I am facing this error while ugrading my Profiles project: `pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. profiles-pycorelib 0.2.2 requires profiles-rudderstack!=0.10.6,<=0.10.7,>=0.10.5, but you have profiles-rudderstack 0.11.0 which is incompatible.`**\n\nThis is because you must uninstall and then reinstall the `pycorelib` library while upgrading to a recent version.\n\n* * *\n\n## Warehouse issues\n\n**I have two separate roles to read from input tables and write to output tables? How should I define the roles?**\n\nYou need to create an additional role as a union of those two roles. PB project needs to read the input tables and write the results back to the warehouse schema.\n\nFurthermore, each run is executed using a single role as specified in the `siteconfig.yaml` file. Hence, it is best in terms of security to create a new role which has read as well as write access for all the relevant inputs and the output schema.\n\n**Can I refer a table present in another database within the warehouse?**\n\n*   **Snowflake**: You can refer tables from cross-database as long as they are in same warehouse.\n*   **Bigquery**: You can refer tables from cross-projects.\n*   **Databricks**: You can refer tables from database in the same or another warehouse.\n*   **Redshift**: For the following setups:\n    *   Cluster with DC2 Nodes: You cannot use tables from cross-database in the project.\n    *   Cluster with RA3 Nodes/Serverless: You can refer tables from cross-database as long as they are in same warehouse.\n\n**How do I test if the role I am using has sufficient privileges to access the objects in the warehouse?**\n\nYou can use the `pb validate access` command to validate the access privileges on all the input/output objects.\n\n**While working with Profiles, how can I use the tables in my BigQuery warehouse that are partitioned on the time criteria?**\n\nTo refer to the partitioned tables in your Profiles project, you must include a filter based on the partitioned column. To do so, add `is_event_stream: true` and use the partitioned filter as `occurred_at_col: timestamp` while defining your `inputs.yaml` file:\n\n```\n- name: rsTracks\n  contract:\n    is_optional: false\n    is_event_stream: true\n    with_entity_ids:\n      - user\n    with_columns:\n      - name: timestamp\n      - name: user_id\n      - name: anonymous_id\n  app_defaults:\n    table: profiles_new.tracks\n    occurred_at_col: timestamp\n    ids:\n      - select: \"user_id\"\n        type: user_id\n        entity: user\n      - select: \"anonymous_id\"\n        type: anonymous_id\n        entity: user\n```\n\n* * *\n\n## Compile command\n\n**I am trying to execute the `compile` command by fetching a repo via GIT URL but getting this error: `making git new public keys: ssh: no key found`**\n\nYou need to add the OpenSSH private key to your `siteconfig.yaml` file. If you get the error `could not find expected` afterwards, try correcting the spacing in your `siteconfig.yaml` file.\n\n**While trying to segregate identity stitching and feature table in separate model files, I am getting this error: `mapping values are not allowed in this context`**\n\nThis is due to the spacing issue in `siteconfig.yaml` file. You may create a new project to compare the spacing. Also, make sure you haven’t missed any keys.\n\n**While using v0.13, I notice that two subfolders are created inside the output folder for compile and run, even if I execute only the `pb run command`. What exactly is the difference between them?**\n\nRudderStack generates two subfolders for easy debugging as compiling is a substep of running the project. If you encounter an error during the project run and are not able to get the corresponding SQL generated for this step, you can still rely on the SQL generated during the compile step to debug the error.\n\n**I want to build profiles over my Snowflake warehouse data which is pulled in using Salesforce (CRM tool). Is it necessary that the data in my Snowflake warehouse flows via RudderStack? Can I build an entity model for Salesforce users that references the Snowflake table?**\n\nRudderStack Profiles lets you use any data present in your warehouse. It does not need to come in via RudderStack. Further, you can define the entities in a `pb_project.yaml` file and use them declaratively while describing the columns of your input sources.\n\n* * *\n\n## Command progress & lifecycle\n\n**I executed a command and it is taking too long. Is there a way to kill a process on data warehouse?**\n\nIt could be due to the other queries running simultaneously on your warehouse. To clear them up, open the **Queries** tab in your warehouse and manually kill the long running processes.\n\n**Due to the huge data, I am experiencing long execution times. My screen is getting locked, thereby preventing the process from getting completed. What can I do?**\n\nYou can use the `screen` command on UNIX/MacOS to detach your screen and allow the process to run in the background. You can use your terminal for other tasks, thus avoiding screen lockouts and allowing the query to complete successfully.\n\nHere are some examples:\n\n*   To start a new screen session and execute a process in detached mode: `screen -L -dmS profiles_rn_1 pb run`. Here:\n    *   `-L` flag enables logging.\n    *   `-dmS` starts as a daemon process in detached mode.\n    *   `profiles_rn_1` is the process name.\n*   To list all the active screen sessions: `screen -ls`.\n*   To reattach to a detached screen session: `screen -r [PID or screen name]`.\n\n**The CLI was running earlier but it is unable to access the tables now. Does it delete the view and create again?**\n\nYes, every time you run the project, Profiles creates a new materials table and replaces the view.\n\nHence, you need to grant a select on future views/tables in the respective schema and not just the existing views/tables.\n\n**Does the CLI support downloading a git repo using siteconfig before executing** `pb run` **? Or do I have to manually clone the repo first?**\n\nYou can pass the Git URL as a parameter instead of project’s path, as shown:\n\n**When executing** `run` **command, I get a message:** `Please use sequence number ... to resume this project in future runs` **. Does it mean that a user can exit using Ctrl+C and later if they give this seq\\_no then it’ll continue from where it was cancelled earlier?**\n\nThe `pb run --seq_no <>` flag allows for the provision of a sequence number to run the project. This flag can either resume an existing project or use the same context to run it again.\n\nWith the introduction of time-grain models, multiple sequence numbers can be assigned and used for a single project run.\n\n**What flag should I set to force a run for the same input data (till a specified timestamp), even if a previous run exists?**\n\nYou can execute `pb run --force --model_refs models/my_id_stitcher,entity/user/user_var_1,entity/user/user_var_2,...`\n\n**Can the hash change even if schema version did not change?**\n\nYes, as the hash versions depends on project’s implementation while the schema versions are for the project’s YAML layout.\n\n**Is there a way to pick up from a point where my last pb run failed on a subsequent run? For large projects, I don’t want to have to rerun all of the features if something failed as some of these take several hours to run**\n\nYes, you can just execute the run command with the specific sequence number, for example, `pb run —seq_no 8`.\n\n**What is the intent of `pb discover models` and `pb discover materials` command?**\n\nYou can use `pb discover models` to list all the models from registry and `pb discover materials` to list all the materials from the registry.\n\n**I got this while running `pb show models`. What is “Maybe Enabled”?**\n\n[![](https://www.rudderstack.com/docs/images/profiles/show_models.webp)](https://www.rudderstack.com/docs/images/profiles/show_models.webp)\n\nIn the show models command, the enable status is computed without looking at tables in the warehouse. Imagine a model`M` that has an optional input column. So, `M` is enabled if and only if the optional input column is present. Hence, it may or may not be enabled, depending on whether the input column is present or not.\n\n**How can I handle my Profiles project in the development and production workspace in RudderStack?**\n\nProfiles support git branches in the RudderStack dashboard. Refer [Supported Git URLs](https://www.rudderstack.com/docs/profiles/example/packages/#supported-git-urls) for more information.\n\nIn case you wish to run only one project in the CLI and run them differently in dev and prod, you can use **targets**:\n\n1.  Create a connection using `pb init connection` and give a connection name (say `test`). Then, give a default target name, say _prod_. Enter remaining details.\n2.  Create another connection using `pb init connection` and give the same connection name as before (`test`). Then, give a different target name, say `dev`. Enter remaining connection details for connecting to your warehouse.\n3.  When you execute a command via CLI, you need to pass `-t` flag. The first connection you’ve defined is the default one, hence, you don’t need to pass a flag explicitly. However, you can pass it for the other one. For example, `pb run -t dev`.\n\nTargets aren’t yet supported in the UI. So while you can run the same project on different instances (prod, dev) in the CLI; in the UI you have to make either a different project or a different branch/tag/subfolder.\n\n**I am getting an “operation timed out” error even though the `pb validate access` command worked fine.**\n\nRetry the command run after some time. It should resolve the issue.\n\n**I have defined a version constraint in my project and migrated it to the latest schema using `pb migrate auto` command. The project is migrated except the `python_requirements` key which has the same version constraints. How do I change that?**\n\nYou need to manually change the project version in CLI as the version constraints don’t change automatically.\n\n* * *\n\n## Identity stitching\n\n**There are many large size connected components in my warehouse. To increase the accuracy of stitched data, I want to increase the number of iterations. Is it possible?**\n\nThe default value of the largest diameter, that is, the longest path length in connected components, is 30.\n\nYou can increase it by defining a `max_iterations` key under `model_spec` of your ID stitcher model in `models/profiles.yaml`, and specifying its value as the max diameter of connected components.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Note that the algorithm can give incorrect results in case of large number of iterations.\n\n**Do I need to write different query each time for viewing the data of created tables?**\n\nNo, you can instead use a view name, which always points to the latest created material table. For example, if you’ve defined **user\\_stitching** in your `models/profiles.yaml` file, then execute `SELECT * FROM MY_WAREHOUSE.MY_SCHEMA.user_stitching`.\n\n**In my model, I have set the key `validity_time: 24h`. What happens when the validity of generated tables expire? Will re-running the identity stitching model generate the same hash until the validity expires?**\n\nFirstly, hash does not depend on the timestamp, it depends on the yaml in the underlying code. That’s why the material name is `material_name_HASH_SEQNO`. The sequence number (SEQNO) depends on timestamp.\n\nSecondly, a material generated for a specific timestamp (aside for the timeless timestamp) is not regenerated unless you do a `pb run --force`. The CLI checks if the material you are requesting already exists in the database, and if it does, returns that. The `validity_time` is an extension of that.\n\nFor a model with `validity_time: 24h` and inputs having the `timestamp` columns, if you request a material for latest time, but one was generated for that model 5 minutes ago, the CLI will return that one instead. Using the CLI to run a model always generates a model for a certain timestamp, it’s just if you don’t specify a timestamp then it uses the current timestamp.\n\nSo, for a model with validity\\_time (vt), and having the `timestamp` columns, if you request a material for t1, but one already exists for t0 where t1-vt <= t0 <= t1, the CLI will return that one instead.\n\nIf multiple materials exist that satisfy the requirement, then it returns the one with the timestamp closest to t1.\n\n**I want to use `customer_id` instead of `main_id` as the ID type. So I changed the name in `pb_project.yaml`, however now I am getting this error: `Error: validating project sample_attribution: listing models for child source models/: error listing models: error building model domain_profile_id_stitcher: main id type main_id not in project id types`.**\n\nIn addition to making changes in the file `pb_project.yaml` file, you also need to set `main_id_type: customer_id` in the `models/profiles.yaml` file.\n\n**If a user account (`user_id`) is deleted, will the associated `user_main_id` be deleted as well?**\n\nIf a `user_id` is not found in the input sources, it would not be tied to that `user_main_id` after a full run. However, the `user_main_id` would still exist if the first node was from an `anonymousId` for that user.\n\n**Suppose a `user_main_id` has two associated `user_ids` as they share the same phone number. If one of the `user_id` changes their phone number, will the `user_main_id` be updated to include only one of the `user_ids`? Will a new `user_main_id` be created for the other `user_id`?**\n\nIn this case, as the common node (phone number) is removed, after a full run, the two users would not be associated to the same `user_main_id` and a new `user_main_id` would be created for the other user.\n\n**I ran identity stitching model but not able to see the output tables under the list of tables in Snowflake. What might be wrong?**\n\nIn Snowflake, you can check the **Databases** > **Views** dropdown from the left sidebar. For example, if your model name is `domain_profile_id_stitcher`, you should be able to see the table with this name. In case it is still not visible, try changing the role using dropdown menu from the top right section.\n\n**I am using a view as an input source but getting an error that the view is not accessible, even though it exists in DB.**\n\nViews need to be refreshed from time-to-time. You can try recreating the view in your warehouse and also execute a `select *` on the same.\n\n**What might be the reason for following errors:**\n\n*   `processing no result iterator: pq: cannot change number of columns in view`. The output view name already exists in some other project. To fix this, try dropping the view or changing its name.\n    \n*   `creating Latest View of moldel 'model_name': processing no result iterator: pq: cannot change data type of view column \"valid_at\"` Drop the view `domain_profile` in your warehouse and execute the command again.\n    \n*   `processing no result iterator: pq: column \"rudder_id\" does not exist`. This occurs when you execute a PB project with a model name, having `main_id` in it, and then you run another project with the same model name but no `main_id`. To resolve this, try dropping the earlier materials using `cleanup materials` command.\n    \n\n**I have a source table in which `email` gets stored in the column for `user_id`, so the field has a mix of different ID types. I have to tie it to another table where email is a separate field. When doing so, I have two separate entries for email, as type `email` and `user_id`. What should I do?**\n\nYou can implement the following line in the inputs tables in question:\n\n```\n  - select: case when lower(user_id) like '%@%' THEN lower(user_id) else null end\n    type: email \n    entity: user\n    to_default_stitcher: true\n```\n\n**How do I validate the results of identity stitching model?**\n\nContact [RudderStack Support](mailto:support@rudderstack.com) if you need help in validating the clusters.\n\n**Which identifiers would you recommend that I include in the ID stitcher for an ecommerce Profiles project?**\n\nWe suggest including identifiers that are unique for every user and can be tracked across different platforms and devices. These identifiers might include but not limited to:\n\n*   Email ID\n*   Phone number\n*   Device ID\n*   Anonymous ID\n*   User names\n\nThese identifiers can be specified in the file `profiles.yaml` file in the identity stitching model.\n\nRemember, the goal of identity stitching is to create a unified user profile by correlating all of the different user identifiers into one canonical identifier, so that all the data related to a particular user or entity can be associated with that user or entity.\n\n**If I run `--force` with an ID Stitcher model and also pass a `--seq_no` for the most recent run, will it still recreate the full ID Graph? Also, is there a way to know if the model was run incrementally or not?**\n\nThis will re-run the ID stitcher and if it is incremental, it will look for the most recent run of the stitcher. After finding the existing run for that `seq_no`, it will use it as the base. This is because the base for an incremental run could be the current `seq_no`. If you do not want to do this, you can pass the `rebase_incremental` flag.\n\n**I am getting a bunch of NULL `VALID_AT` timestamps. Is it because the table where the data is being referenced from does not have a timestamp fields specified? Will this impact anything in the downstream?**\n\nYes, if there is no timestamp field in the input table (or it is NULL for the row from where the edge source was pulled), then `VALID_AT` column would have NULL value. This only affects the `VALID_AT` column in the final table and nothing in the ID stitching.\n\n**Which identifiers should I include in my `inputs.yaml` file?**\n\nInclude all the IDs that contribute to the ID stitcher model.\n\n**Should I re-run the stitching process once all `user_id`’s have been sorted out with market prefixes? I want to ensure that users are captured separately instead of being grouped under one `rudder_id`.**\n\nIt is recommended to use the `--rebase-incremental` flag and re-run the stitching process from scratch. While it may not be necessary in all cases, doing so ensures a fresh start and avoids any potential pooling of users under a single `rudder_id`. It’s important to note that if you make any changes to the YAML configuration, such as modifying the entity or model settings, the model’s hash will automatically update. However, some changes may not be captured automatically (for example, if you didn’t change YAML but simply edited column values in the input table), so manually rebasing is a good practice.\n\n**While running my ID stitcher model, I get the error “Could not find parent table for alias “”**\n\nThis is because RudderStack tries to access the cross-database objects (views/tables) for inputs, which is only supported on Redshift [RA3 node type clusters](https://docs.aws.amazon.com/redshift/latest/dg/cross-database_usage.html).\n\nTo resolve the issue, you can upgrade your cluster to RA3 node type or copy data from source objects to the database specified in the siteconfig file. **I want to use a SQL model for an exclusion filter which references tables that are not used in the ID stitching process. Do I still need to add those tables to the `inputs.yaml` file?**\n\nIt is not necessary to add the table references to the `inputs.yaml` file. However, it is advised to add it for the following reasons:\n\n*   You can rule out any access/permissions issues for the referenced tables.\n*   The `contract` field in `inputs.yaml` would help you handle errors if the required column doesn’t exist.\n\n* * *\n\n## Feature Table\n\n**How can I run a feature table without running its dependencies?**\n\nSuppose you want to re-run the user entity\\_var `days_active` and the `rsTracks` input\\_var `last_seen` for a previous run with `seq_no 18`.\n\nThen, execute the following command:\n\n```\npb run --force --model_refs entity/user/days_active,inputs/rsTracks/last_seen --seq_no 18\n```\n\n**I have imported a library project but it throws an error: `no matching model found for modelRef rsTracks in source inputs`.**\n\nYou can exclude the missing inputs of the library project by mapping them to nil in the `pb_project.yaml` file.\n\n**Can I run models which consider the input data within a specified time period?**\n\nYes, you can do so by using the `begin_time` and `end_time` parameters with the `run` command. For example, if you want to run the models for data from 2nd February, 2023, use:\n\n```\n$ pb run --begin_time 2023-01-02T12:00:00.0Z\n```\n\nIf you want to run the nmodels for data between 2 May 2022 and 30 April 2023, use:\n\n```\n$ pb run --begin_time 2022-05-01T12:00:00.0Z --end_time 2023-04-30T12:00:00.0Z\n```\n\nIf you want to run the models incrementally (run them from scratch ignoring any previous materials) irrespective of timestamp, use:\n\n```\n$ pb run --rebase_incremental\n```\n\n**Is it possible to run the feature table model independently, or does it require running alongside the ID stitcher model?**\n\nYou can provide a specific timestamp while running the project, instead of using the default latest time. PB recognizes if you have previously executed an identity stitching model for that time and reuses that table instead of generating it again.\n\nYou can execute a command similar to: `pb run --begin_time 2023-06-02T12:00:00.0Z --end_time 2023-06-03T12:00:00.0Z`. Note that:\n\n*   To reuse a specific identity stitching model, the timestamp value must match exactly to when it was run.\n*   If you have executed identity stitching model in the incremental mode and do not have an exact timestamp for reusing it, you can select any timestamp **greater** than a non-deleted run. This is because subsequent stitching takes less time.\n*   To perform another identity stitching using PB, pick a timestamp (for example, `1681542000`) and stick to it while running the feature table model. For example, the first time you execute `pb run --begin_time 2023-06-02T12:00:00.0Z --end_time 2023-06-03T12:00:00.0Z`, it will run the identity stitching model along with the feature models. However, in subsequent runs, it will reuse the identity stitching model and only run the feature table models.\n\n**While trying to add a feature table, I get an error at line 501, but I do not have these many lines in my YAML.**\n\nThe line number refers to the generated SQL file in the output folder. Check the console for the exact file name with the sequence number in the path.\n\n**While creating a feature table, I get this error:** `Material needs to be created but could not be: processing no result iterator: 001104 (42601): Uncaught exception of type 'STATEMENT ERROR': 'SYS _W. FIRSTNAME' in select clause is neither an aggregate nor in the group by clause.`\n\nThis error occurs when you use a window function `any_value` that requires a window frame clause. For example:\n\n```\n  - entity_var:\n      name: email\n      select: LAST_VALUE(email)\n      from: inputs/rsIdentifies\n      window:\n        order_by: \n        - timestamp desc\n```\n\n**Is it possible to create a feature out of an identifier? For example, I have a RS user\\_main\\_id with two of user\\_ids stitched to it. Only one of the user\\_ids has a purchase under it. Is it possible to show that user\\_id in the feature table for this particular user\\_main\\_id?**\n\nIf you know which input/warehouse table served as the source for that particular ID type, then you can create features from any input and also apply a `WHERE` clause within the entity\\_var.\n\nFor example, you can create an aggregate array of user\\_id’s from the purchase history table, where total\\_price > 0 (exclude refunds, for example). Or, if you have some LTV table with user\\_id’s, you could exclude LTV < 0.\n\n**Is it possible to reference an input var in another input var?**\n\nYes - input vars are similar to adding additional columns to the original table. You can use an input var `i1v1` in the definition of input var `i1v2` as long as both input vars are defined in the same input (or SQL model) `i1`.\n\n**I have not defined any input vars on I1. Why is the system still creating I1\\_var\\_table?**\n\nWhen you define an entity var using I1, an internal input var (for entity’s `main_id`) is created which creates `I1_var_table`. RudderStack team is evaluating whether internal input vars should create the var table or not.\n\n**I have an input model I1. Why is the system creating Material\\_I1\\_var\\_table\\_XXXXXX\\_N?**\n\nThis material table is created to keep the input vars defined on I1.\n\n**I am trying to run a single `entity_var` model. How should I reference it?**\n\nThe right way to reference an entity var is: `entity/<entity-name>/<entity-var-name>`.\n\n**I have two identical named fields in two `user` tables and I want my Profiles project to pick the most recently updated one (from either of the `user` tables). What is the best way to do it?**\n\nDefine different `entity_vars` (one for each input) and then pick the one with a non-null value and higher priority.\n\n**What does running material mean?**\n\nIt means that the output (material) table is being created in your warehouse. For example, an output table named `material_user_id_stitcher_3acd249d_21` would mean:\n\n*   `material`: Prefix for all the objects created by Profiles in your warehouse, such as ID stitcher and feature tables.\n*   `user_id_stitcher`: View created in your schema. It will always point to latest ID stitcher table. This name is the same as defined in the `models/profiles.yaml` file.\n*   `3acd249d`: Unique hash which remains the same for every model unless you make any changes to the model’s config, inputs or the config of model’s inputs.\n*   `21`: Sequence number for the run. It is a proxy for the context timestamp. Context timestamp is used to checkpoint input data. Any input row with `occured_at` timestamp value greater than the context timestamp cannot be used in the associated run.\n\n* * *\n\n## YAML\n\n**Are there any best practices I should follow when writing the PB project’s YAML files?**\n\n*   Use spaces instead of tabs.\n*   Always use proper casing. For example: id\\_stitching, and not id\\_Stitching.\n*   Make sure that the source table you are referring to, exists in data warehouse or data has been loaded into it.\n*   If you’re pasting table names from your Snowflake Console, remove the double quotes in the `inputs.yaml` file.\n*   Make sure your syntax is correct. You can compare with the sample files.\n*   Indentation is meaningful in YAML, make sure that the spaces have same level as given in sample files.\n\n**How do I debug my YAML file step-by-step?**\n\nYou can use the `--model_args` parameter of the `pb run` command to do so. It lets you run your YAML file till a specific feature/tablevar. For example:\n\n```\n$ pb run -p samples/attribution --model_args domain_profile:breakpoint:blacklistFlag\n```\n\nSee [run command](https://www.rudderstack.com/docs/profiles/cli-user-guide/commands/#run) for more information.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> This is only applicable to versions prior to v0.9.0.\n\n**Can I use double quotes when referencing another entity\\_var in a macro?**\n\nYou can use an escape character. For example:\n\n```\n  - entity_var:\n      name: days_since_last_seen\n      select: \"{{macro_datediff('{{user.Var(\\\"max_timestamp_bw_tracks_pages\\\")}}')}}\"\n```\n\nAlso, if have a case statement, then you can add something like the following:\n\n`select: CASE WHEN {{user.Var(\"max_timestamp_tracks\")}}>={{user.Var(\"max_timestamp_pages\")}} THEN {{user.Var(\"max_timestamp_tracks\")}} ELSE {{user.Var(\"max_timestamp_pages\")}} END`\n\n**Is it possible to define default arguments in macros?**\n\nNo, RudderStack does not support default arguments in macros.\n\n* * *\n\n## ML/Python Models\n\n**Despite deleting WhtGitCache folder and adding keys to siteconfig, I get this error:** `Error: loading project: populating dependencies for project:base_features, model: churn_30_days_model: getting creator recipe while trying to get ProjectFolder: fetching git folder for git@github.com:rudderlabs/rudderstack-profiles-classifier.git: running git plain clone: repository not found`\n\nIf your token is valid, then replace `git@github.com:rudderlabs/rudderstack-profiles-classifier.git` with `https://github.com/rudderlabs/rudderstack-profiles-classifier.git` in the `profile-ml` file.\n\n**Why is my Profiles project taking so long to run?**\n\nThe first Profiles project run usually takes longer, especially if you are building predictive features.\n\n**I am debugging an error in ML models where I see a view with the model name, without material/hash prefix and suffix but it does not get refreshed even after all the entity vars are created and the material\\_<feature\\_table\\_model> table is also created. What might be the reason?**\n\nIt is because this view is now moved to `PostProjectRunCb`, meaning, it is created async after material Force run step.\n\n* * *\n\n## Activation API\n\n**While using Redis destination, I am facing an error: `These sample records were rejected by the destination`**?\n\nThis error is observed if you have enabled **Cluster mode** setting for Redis in the [RudderStack’s configuration settings](https://www.rudderstack.com/docs/destinations/streaming-destinations/redis/#connection-settings) but you are on the Redis free plan.\n\nTo overcome this, ensure that the Redis plan you are using allows clustering. Alternatively, you can turn off the **Cluster mode** setting.\n\n**Does the user-profiles API (old) and activation API (new) behave differently in updating a key that maps to two different primary keys? For example:**\n\n| Primary key | user\\_id | Feature\\_1 | Feature\\_2 |\n| --- | --- | --- | --- |\n| PK1 | U1  | F1  | null |\n| PK2 | U1  | null | F2  |\n\nUser profiles API\n\n```\n{\n  \"userId\": \"U1\",\n  \"profile\": {\n    \"feature_1\": \"F1\",\n    \"feature_2\": \"F2\"\n  }\n}\n```\n\nActivation API\n\n```\n{\n  \"entity\": \"entity_name\",\n  \"id\": {\n    \"type\": \"user_id\",\n    \"value\": \"U1\"\n  },\n  \"data\": {\n    \"model_name\": {\n      \"feature_1\": null,\n      \"feature_2\": F2\n    }\n  }\n}\n```\n\nIn user profiles API, RudderStack updates the value for a specific key (that is, feature\\_1 in this case). In activation API, RudderStack syncs the entire row as value for the `model_name` key.\n\n**Is it possible to use the Activation API without any Profiles project?**\n\nNo, the Activation API can only be used with a Profiles project and not on any of your non-Profiles output tables.\n\n**I have toggled on the Activation API option in the RudderStack dashboard to generate a Reverse ETL pipeline (connected to the Redis destination) and have defined a single ID in the `feature_views` key. However, two Reverse ETL pipelines are generated on running the project. Which one should I use and what is the difference between the two?**\n\nProfiles generates two `feature_views` models if you define a single ID under the `feature_views` key. One is the default feature view with `main_id` as the identifier and the other is based on the identifier you have defined.\n\nRudderStack assigns the default names to the view such as `user_feature_view` (default one with `main_id` as the identifier), or `feature_view_with_email` (email as the identifier), etc. You can also specify the final view’s name in the `name` key.\n\n## Profiles UI\n\n**I have included some features in the RudderStack dashboard while creating the Profiles project but when I click “download this project”, my project files does not include any feature. What might be the reason?**\n\nIf you have selected pre-defined features from any library project, they are referred to as `profiles-multieventstream-features` in the project by default.\n\nIf you have created any features using the custom feature functionality, they will be a part of your `models/resources.yaml` file. \n\n**While choosing pre-defined features in the RudderStack dashboard, I can preview code for only some of the features. What might be the reason?**\n\nYou can preview the code only for entity var based features. This functionality is not available for features built from ML and SQL models.\n\n**While creating a Profiles project by importing from Git, I dont see any warehouse options in the dropdown selector in the `Validate Profiles project` section. What might be the reason?**\n\nA Profiles project looks for the supported warehouse destinations configured for that workspace. Hence, make sure you have configured any of the following [warehouse destinations](https://www.rudderstack.com/docs/destinations/warehouse-destinations/) in your RudderStack dashboard:\n\n*   Snowflake\n*   Databricks\n*   Redshift\n*   BigQuery\n\n**Why am I not able to see the Concurrency option in the Settings tab of my Profiles project?**\n\nRudderStack supports the **Concurrency** option only for the Snowflake warehouse currently. You will not be able to see this option if you have configured your Profiles project using the Redshift, BigQuery, or Databricks warehouse.\n\n**I have chosen some pre-defined predictive features while creating a Profiles project in the RudderStack dashboard but my project fails on running. What might be the reason?**\n\nOne of the probable reasons could be the lack of adequate data in your input source. Try following the steps suggested in the error message. In case the issue still persists, [contact](https://rudderstack.com/join-rudderstack-slack-community) our support team.\n\n## Miscellaneous\n\n**Why am I getting _Authentication FAILED_ error on my data warehouse while executing the run/compile commands?**\n\nSome possible reasons for this error might be:\n\n*   Incorrect warehouse credentials.\n*   Insufficient user permissions to read and write data. You can ask your administrator to change your role or grant these privileges.\n\n**Why am I getting _Object does not exist or not authorized_ error on running this SQL query: `SELECT * FROM \"MY_WAREHOUSE\".\"MY_SCHEMA\".\"Material_domain_profile_c0635987_6\"`?**\n\nYou must remove double quotes from your warehouse and schema names before running the query, that is `SELECT * FROM MY_WAREHOUSE.MY_SCHEMA.Material_domain_profile_c0635987_6`.\n\n**Is there a way to obtain the timestamp of any material table?**\n\nYes, you can use the `GetTimeFilteringColSQL()` method to get the timestamp column of any material. It filters out rows based on the timestamp. It returns the `occurred_at_col` in case of an event\\_stream table or `valid_at` in case the material has that column. In absense of both, it returns an empty string. For example:\n\n```\n  SELECT * FROM {<from_material>}\n    WHERE\n      <from_material>.GetTimeFilteringColSQL() > <some_timestamp>;\n```\n\n**What is the difference between setting up Profiles in the RudderStack dashboard and Profile Builder CLI tool?**\n\nYou can run Profiles in the RudderStack dashboard or via [Profile Builder CLI](https://www.rudderstack.com/docs/profiles/get-started/profile-builder/).\n\nThe main difference is that the RudderStack dashboard only generates outputs based on the pre-defined templates. However, you can augment those outputs by downloading the config file and updating it manually.\n\nOn the other hand, the CLI tool lets you achieve the end-to-end flow via creating a Profile Builder project.\n\n**Does the Profiles tool have logging enabled by default for security and compliance purposes?**\n\nLogging is enabled by default for nearly all the commands executed by CLI (`init`, `validate access`, `compile`, `run`, `cleanup`, etc.). Logs for all the output shown on screen are stored in the file `logfile.log` in the **logs** directory of your project folder. This includes logs for both successful and failed runs. RudderStack appends new entries at the end of the file once a command is executed.\n\nSome exceptions where the logs are not stored are:\n\n*   `query`: The logger file stores the printing output and does not store the actual database output. However, you can access the SQL queries logs in your warehouse.\n*   `help`: For any command.\n\n**In the warehouse, I see lots of material\\_user\\_id\\_stitcher\\_ tables generated in the rs\\_profiles schema. How do I identify the latest ID stitched table?**\n\nThe view `user_id_stitcher` will always point to the latest generated ID stitcher. You may check its definition to see the exact table name it is referring to.\n\n**How can I remove the material tables that are no longer needed?**\n\nTo clean up all the materials older than a specific duration, for example 10 days, execute the following command:\n\n```\npb cleanup materials -r 10\n```\n\nThe minimum value you can set here is `1`. So if you have run the ID stitcher today, then you can remove all the older materials using `pb cleanup materials -r 1`.\n\n**Which tables and views are important in Profiles schema that should not be deleted?**\n\n*   `material_registry`\n*   `material_registry_<number>`\n*   `pb_ct_version`\n*   `ptr_to_latest_seqno_cache`\n*   `wht_seq_no`\n*   `wht_seq_no_<number>`\n*   Views whose names match your models in the YAML files.\n*   Material tables from the latest run (you may use the `pb cleanup materials` command to delete materials older than a specific duration).\n\n**I executed the auto migrate command and now I see a bunch of nested** `original_project_folder`. **Are we migrating through each different version of the tool?**\n\nThis is a symlink to the original project. Click on it in the Finder (Mac) to open the original project folder.\n\n**I am getting a **`ssh: handshake failed`** error when referring to a public project hosted on GitHub. It throws error for https:// path and works fine for ssh: path. I have set up token in GitHub and added to siteconfig.yaml file but I still get this error.**\n\nYou need to follow a different format for `gitcreds:` in siteconfig. See [SiteConfiguration](https://www.rudderstack.com/docs/profiles/cli-user-guide/structure/#site-configuration-file-configuration.md) for the format.\n\nAfter changing `siteconfig`, if you still get an error, then clear the `WhtGitCache` folder inside the directory having the `siteconfig` file.\n\n**If I add filters to** `id_types` **in the project file, then do all rows that include any of those values get filtered out of the analysis, or is it just the specific value of that id type that gets filered?**\n\nThe PB tool does not extract rows. Instead, it extracts pairs from rows.\n\nSo if you had a row with email, user\\_id, and anonymous\\_id and the anonymous\\_id is excluded, then the PB tool still extracts the email, user\\_id edge from the row.\n\n**In the material registry table, what does** `status: 2` **mean?**\n\n*   `status: 2` means that the material has successfully completed its run.\n*   `status: 1` means that the material did not complete its run.\n\n**I am using Windows and get the following error:** `Error: while trying to migrate project: applying migrations: symlink <path>: A required privilege is not held by the client`.\n\nYour user requires privileges to create a symlink. You may either grant extra privileges to the user or try with a user containing Admin privileges on PowerShell. In case that doesn’t help, try to install and use it via WSL (Widows subsystem for Linux).\n\n**Can I specify any git account like CommitCode while configuring a project in the web app?**\n\nProfiles UI supports repos hosted on GitHub, BitBucket and GitLab.\n\n**If I want to run multiple select models, how can I run something like: `pb run --model_refs \"models/ewc_user_id_graph_all, models/ewc_user_id_graph, models/ewc_user_id_graph_v2`**\n\nYou can do so by passing `--model_refs` multiple times per model:\n\n`pb run -p samples/test_feature_table --model_refs 'models/test_id__, user/all' --migrate_on_load` OR `pb run -p samples/test_feature_table --model_refs models/test_id__ --model_refs user/all --migrate_on_load`\n\n**How can I keep my Profiles projects up to date along with updating the Python package and migrating the schema version?**\n\nYou can check for the latest Profiles updates in the [changelog](https://www.rudderstack.com/docs/profiles/changelog/).\n\nTo update the Python package and migrate the schema version, you can standardise on a single pip release across the org and use the schema version that is native to that binary. When you move to a different binary, migrate your projects to the schema version native to it.\n\nContact Profiles support team in our [Community Slack](https://rudderstack.com/join-rudderstack-slack-community) for specific questions.\n\n**I am facing this error on adding a custom ID `visitor_id` under the `id_types` field in the `pb_project.yaml` file:**\n\n`could not create project: failed to read project yaml Error: validating project sample_attribution: getting models for folder: user: error listing models: error building model user_default_id_stitcher: id type visitor_id not in project id types`\n\nWhile adding a custom ID type, you must extend the package to include its specification in the `pb_project.yaml` file as well. In this case, add the key `extends:` followed by name of the same/different id\\_type that you wish to extend, and corresponding filters with include/exclude values like below:\n\n```\nid_types:\n - name: visitor_id\n   extends: visitor_id\n  filters:\n   - type: exclude\n     value: \"someexcludedvalue\"\n```\n\n**Can I keep multiple projects in a Git Repo?**\n\nYes, you can create multiple folders in your project repo and keep different projects in each folder. While running the project, you can use any suitable URL to run a specific project:\n\n`https://github.com/<org-name>/<repo-name>/tree/<branch-name>/path/to/project` `https://github.com/<org-name>/<repo-name>/tag/<tag-name>/path/to/project` `https://github.com/<org-name>/<repo-name>/commit/<commit-hash>/path/to/project`\n\nSee [Supported Git URLs](https://www.rudderstack.com/docs/profiles/example/packages/#supported-git-urls) for more information.\n\n**Can a models folder contain subfolders?**\n\nYes, you can manually add subfolders to the models folder and reference their path in the `pb_project.yaml` file:\n\n```\nmodel_folders:\n  - models/inputs\n  - models/inputs/web.yml\n```\n\nA sample folder structure is shown:\n\n```\n.\n├── models/\n│   ├── inputs/\n|   │   ├── web.yml\n|   │   ├── mobile.yml\n|   │   └── server.yml\n│   └── ...\n```\n\n**How is Activations different from Audiences?**\n\nActivations qualify as Audiences with a minor exception of having a Profiles project as a source instead of a Reverse ETL source (with schema, database, table etc).\n\n**I am running a Profiles project with the `timegrains` parameter and noticed that multiple subfolders having different `seq_no` are generated. Which `seq_no` should I use to resume an earlier run?**\n\nFor the CLI project, you can resume the project run using CLI commands(like `run`, `compile`, etc.) and passing the `--seq_no` displayed at the top of the terminal output. For the UI project, you cannot choose to stop/resume the project run.\n\n**What is the purpose of the `PTR_TO_LATEST_SEQNO_CACHE` view in a Profiles schema?**\n\nThe `PTR_TO_LATEST_SEQNO_CACHE` view scans the registry to build metadata for finding the latest table or view of any model name or model hash. This metadata then goes into the creation of views named `model` - for each model named `model` - and points to the latest `Material_model_xxxxxxxx_n` after every run.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Profiles FAQ | RudderStack Docs",
    "description": "Commonly asked questions on RudderStack Profiles.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/cohorts/",
    "markdown": "# Cohorts | RudderStack Docs\n\nCreate core customer segments in your warehouse and use them for targeted campaigns.\n\n* * *\n\n*     5 minute read  \n    \n\n**Cohort** is a subset of [entityEntity refers to a digital representation of a class of real world distinct objects for which you can create a profile.](https://www.rudderstack.com/docs/resources/glossary/#entity) instances meeting a specified set of characteristics, behaviors, or attributes. For example, if you have user as an entity, you can define cohorts like known users, new users, or North American users.\n\nUsing RudderStack Profiles, you can create the desired cohorts for entities and target specific user segments by enabling targeted campaigns and analysis.\n\n## Define cohorts\n\nProfiles lets you define cohorts as a model under `model_type` field in your `profiles.yaml` file:\n\n*   **Default cohort**: When you define an entity, a default cohort `<entity>/all` (`user/all` for the `user` entity) is created automatically. It contains the set of all instances of that entity. Any other cohort you define for that entity is derived from it.\n*   **Derived cohort**: When you define a cohort based on a pre-existing cohort (base cohort), it becomes a derived cohort. A derived cohort inherits the features of the base cohort. You can filter out the member instances of the base cohort based on a set of characteristics, behaviors, or attributes for the derived cohort. You must specify the base cohort in the derived cohort’s definition using the `extends` field.\n\nFor example, `known_users` is a cohort derived from the base cohort `user/all` (set of all users), whereas `known_mobile_users` is derived from its base cohort `known_users`.\n\nWhen you run a Profiles project including cohorts, the output of the cohort is stored in a table/view with the same name.\n\n### Sample cohort\n\nYou can apply filters using the `include`/`exclude` clauses to specify a boolean expression over any of the entity vars defined on the base cohort or its ancestors. Certain features might hold relevance only for the specific cohorts. For example, `SSN` feature may only be applicable for American users.\n\n**Example 1**: Let’s consider the following `profiles.yaml` file which defines a cohort `knownUsUsers` to include users from US with a linked email address.\n\n```\nmodels:\n  - name: knownUsUsers\n    model_type: entity_cohort\n    model_spec:\n      extends: user/all\n      materialization:\n        output_type: table\n      filter_pipeline:\n        - type: exclude\n            # exclude users which don't have any linked email.\n          value: \"{{ user.Var('id_type_email_count') }} = 0\"\n        - type: include\n            # include users with country US.\n          value: \"{{ user.Var('country') }} = 'US'\"   \n```\n\nHere, the `extends` keyword specifies the base cohort `users/all`. You can also specify the path of a custom defined base cohort, if applicable. The `value` field in `filter_pipeline` must be a boolean expression over any of the `entity_vars` defined on the base cohort or its ancestor cohorts.\n\n**Example 2**: Let’s derive the `us_credit_card_users` cohort from the `knownUsUsers` as a base cohort. It filters the known US users who possess a credit card and have spent more than 10 thousand USD in last transaction. The `extends` field specifies the path of the base cohort which is `models/knownUsUsers`.\n\n```\nmodels:\n  -  name: us_credit_card_users\n     model_type: entity_cohort\n     model_spec:\n       extends: models/knownUsUsers\n       materialization:\n         output_type: view\n       filter_pipeline:\n         - type: include\n           value: \"{{ knownUsUsers.Var('has_credit_card') }} = 1\"\n         - type: include\n           value: \"{{ user.Var('last_transaction_value') }} > 10000\"\n```\n\n**Example 3**: Let’s consider another scenario where you can unify different cohorts (`north_american_users`, and `south_american_users`) to create a new cohort.\n\n```\nmodels:\n  - name: american_users\n    model_type: entity_cohort\n    model_spec:\n       extends: user/all\n       filter_pipeline:\n         - type: include\n           sql:\n             select: user_main_id\n             from: \"{{ this.DeRef('models/north_american_users') }}\"\n         - type: include\n           sql:\n             select: user_main_id\n             from: \"{{ this.DeRef('models/south_american_users') }}\"\n             where: user_main_id != null\n```\n\n### Associate features with cohort\n\nYou can also use `var_groups` to target a cohort instead of an entire entity which will provide a comprehensive 360-degree view combining relevant features.\n\nTo do so, associate features with a cohort by specifying the `entity_cohort` key and passing the cohort’s path to it within a `var_group`, as shown:\n\n```\nvar_groups:\n  - name: known_us_users_vars #vars targeted to knownUsUsers cohort\n    entity_cohort: models/knownUsUsers\n    vars:\n      - entity_var:\n          name: has_credit_card\n          select: max(case when lower(payment_details_credit_card_company) in ('visa','american express','mastercard') then 1 else 0 end)\n          from: inputs/rsOrderCreated\n          description: If the user has a credit card.\n          default: false\n          \n  - name: user_vars #vars targeted to default user/all cohort\n    entity_key: user\n    vars:\n      - entity_var:\n          name: last_transaction_value\n          from: inputs/rsOrderCreated\n          select: first_value(total_price_usd)\n          window:\n            order_by:\n              - case when TOTAL_PRICE_USD is not null then 2 else 1 end desc\n              - timestamp desc\n      - entity_var:\n          name: country\n          from: inputs/rsIdentifies\n          select: first_value(address_country)\n          where: address_country is not null and address_country != ''\n          window:\n            order_by:\n              - timestamp desc\n```\n\nTo apply the features to the entire user entity, you can use an `entity_key` in `user_vars`.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> In a `var_group`, you can use either `entity_key` or `entity_cohort` but not both. Setting `entity_key` as `user` is equivalent to setting `entity_cohort` as `user/all`.\n\n### Feature view of cohort\n\nYou can establish a holistic **360 feature view** of a cohort within its definition. This view consolidates all the features associated with the specified identifiers, providing a complete overview of the cohort.\n\nThe following example shows how to define a feature view for the `knownUsUsers` cohort:\n\n```\nmodels:\n  - name: knownUsUsers\n    model_type: entity_cohort\n    model_spec:\n      extends: users/all\n      materialization:\n        output_type: table\n      filter_pipeline:\n        - type: exclude\n            # exclude users which don't have any linked email.\n          value: \"{{ user.Var('id_type_email_count') }} = 0\"\n        - type: include\n            # include users with country US.\n          value: \"{{ user.Var('country') }} = 'US'\"\n      # to define a 360 feature view of knownUsUsers cohort [optional]\n      feature_views:\n        # view with entity's `main_id` as identifier\n        name: known_us_users_feature_view\n        using_ids:\n          - id: email\n            # view with `email` as identifier\n            name: us_users_with_email\n```\n\nHere, the `known_us_users_feature_view` view contains all the features of the `knownUsUsers` cohort and uses `main_id` as the identifier. There is another `us_users_with_email` view which also contains all the features of the `knownUsUsers` cohort but uses `email` as the identifier (specified in `using_ids` field).\n\n## Use cohorts\n\nOnce you have defined cohorts in your `profiles.yaml` file, you can choose to run your project in either of the following ways:\n\n### Profile CLI\n\nRun your [Profiles CLI project](https://www.rudderstack.com/docs/profiles/get-started/profile-builder/) using the `pb run` command to generate output tables.\n\n### Profiles UI\n\nTo view cohorts in the RudderStack dashboard, you can make your Profiles CLI project available in a Git repository and import it in the RudderStack dashboard. See [Import Profiles Project from Git](https://www.rudderstack.com/docs/profiles/get-started/import-from-git/) for more information.\n\nOnce imported, you can run your project by navigating to the **History** tab and clicking **Run**. After a successful run of the project, you can view the output for cohorts in the **Entities** tab of the project:\n\n[![Activation API](https://www.rudderstack.com/docs/images/profiles/cohorts-view-ui.webp)](https://www.rudderstack.com/docs/images/profiles/cohorts-view-ui.webp)\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Contact Profiles support team in RudderStack’s [Community Slack](https://rudderstack.com/join-rudderstack-slack-community) if you are unable to see the **Entities** tab.\n\nYou can further activate your cohorts data by syncing it to the downstream destinations. See [Activations](https://www.rudderstack.com/docs/profiles/activations/) for more information.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Cohorts | RudderStack Docs",
    "description": "Create core customer segments in your warehouse and use them for targeted campaigns.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/example/id-stitcher/",
    "markdown": "# Identity Stitching | RudderStack Docs\n\nStep-by-step tutorial on how to stitch together different user identities.\n\n* * *\n\n*     7 minute read  \n    \n\nThis guide provides a detailed walkthrough on how to use a PB project and create output tables in a warehouse for a custom identity stitching model.\n\n## Prerequisites\n\n*   Familiarize yourself with:\n    \n    *   A basic Profile Builder project by following the [Profile Builder CLI](https://www.rudderstack.com/docs/profiles/get-started/profile-builder/) steps.\n    *   [Structure](https://www.rudderstack.com/docs/profiles/cli-user-guide/structure/) of a Profile Builder project and the parameters used in different files.\n\n## Output\n\nAfter [running the project](https://www.rudderstack.com/docs/profiles/get-started/profile-builder/#7-generate-output-tables), you can view the generated material tables:\n\n1.  Log in to your Snowflake console.\n2.  Click **Worksheets** from the top navigation bar.\n3.  In the left sidebar, click **Database** and the corresponding **Schema** to view the list of all tables. You can hover over a table to see the full table name along with its creation date and time.\n4.  Write a SQL query like `select * from <table_name> limit 10;` and execute it to see the results:\n\n1.  Open [Postico2](https://eggerapps.at/postico2/). If required, create a new connection by entering the relevant details. Click **Test Connection** followed by **Connect**.\n2.  Click the **+** icon next to **Queries** in the left sidebar.\n3.  You can click **Database** and the corresponding schema to view the list of all tables/views.\n4.  Double click on the appropriate view name to paste the name on an empty worksheet.\n5.  You can prefix `SELECT *` from the view name pasted previously and suffix `LIMIT 10;` at the end.\n6.  Press Cmd+Enter keys, or click the **Run** button to execute the query.\n\n1.  Enter your Databricks workspace URL in the web browser and log in with your username and password.\n2.  Click the **Catalog** icon in left sidebar.\n3.  Choose the appropriate catalog from the list and click on it to view the contents.\n4.  You will see list of tables/views. Click on the appropriate table/view name to paste the name on the worksheet.\n5.  Then, you can prefix `SELECT * FROM` before the pasted view name and suffix `LIMIT 10;` at the end.\n6.  Select the query text. Press Cmd+Enter or click the **Run** button to execute the query.\n\n1.  Log in to your [Google Cloud Console](https://console.cloud.google.com/)\n2.  Search for Bigquery in the search bar.\n3.  Select Bigquery from **Product and Pages** to open the Bigquery **Explorer**.\n4.  Select the correct project from top left drop down menu.\n5.  In the left sidebar, click the project ID, then the corresponding dataset view list of all the tables and views.\n6.  Write a SQL query like `select * from <table_name> limit 10;` and execute it to see the results.\n\nA sample output containing the results in Snowflake:\n\n![Generated tables (Snowflake)](https://www.rudderstack.com/docs/images/profiles/snowflake-console.webp)\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Profiles project includes an ID stitcher model (`default_id_stitcher`) by default even if you do not define any specs for creating one. It takes all the input sources and ID types defined in the file `inputs.yaml` file. Also, it creates a custom ID stitcher when you define an ID stitcher model explicitly along with the specs.\n\n## Sample project for Custom ID Stitcher\n\nThis sample project considers multiple user identifiers in different warehouse tables to ties them together to create a unified user profile. The following sections describe how to define your PB project files:\n\n### Project detail\n\nThe [`pb_project.yaml`](https://www.rudderstack.com/docs/profiles/cli-user-guide/structure/#project-details) file defines the project details such as name, schema version, connection name and the entities which represent different identifiers.\n\nThere can be different ID types for an entity. You can include all such identifiers in the `id_types` field under `entities`. `main_id` specified under `id_types` is not an ID type but a placeholder for the column which serves as the primary identifier for that entity.\n\nIn case of `id_stitcher` model, the `main_id` for the entity is `rudder_id` (predefined ID type) by default. For other models, any other ID type can be the `main_id`, for example `session_id`. Hence, if you want to specify the ID type of a column as a primary identifier, you can specify `main_id`.\n\n```\n# Project name\nname: sample_id_stitching\n# Project's yaml schema version\nschema_version: 69\n# Warehouse connection\nconnection: test\n# Folder containing models\nmodel_folders:\n  - models\n# Entities in this project and their ids.\nentities:\n  - name: user\n    id_stitcher: models/user_id_stitcher # modelRef of custom ID stitcher model\n    id_types:\n      - main_id # You need to add ``main_id`` to the list only if you have defined ``main_id_type: main_id`` in the id stitcher buildspec.\n      - user_id # one of the identifier from your data source.\n      - email\n# lib packages can be imported in project signifying that this project inherits its properties from there\npackages:\n  - name: corelib\n    url: \"https://github.com/rudderlabs/profiles-corelib/tag/schema_{{best_schema_version}}\"\n    # if required then you can extend the package definition such as for ID types.\n```\n\n### Input\n\nThe [input file](https://www.rudderstack.com/docs/profiles/cli-user-guide/structure/#inputs) (`models/inputs.yaml`) file includes the input table references and corresponding SQL for the above-mentioned entities:\n\n```\ninputs:\n- name: rsIdentifies\n  contract: # constraints that a model adheres to\n    is_optional: false\n    is_event_stream: true\n    with_entity_ids:\n      - user\n    with_columns:\n      - name: timestamp\n      - name: user_id\n      - name: anonymous_id\n      - name: email\n  app_defaults:\n    table: rudder_events_production.web.identifies # one of the WH table RudderStack generates when processing identify or track events.\n    occurred_at_col: timestamp\n    ids:\n      - select: \"user_id\" # kind of identity sql to pick this column from above table.\n        type: user_id\n        entity: user # as defined in project file\n        to_default_stitcher: true # default value\n      - select: \"anonymous_id\"\n        type: anonymous_id\n        entity: user\n        to_default_stitcher: true\n      - select: \"lower(email)\" # can use sql.\n        type: email\n        entity: user\n        to_default_stitcher: true\n- name: rsTracks\n  contract:\n    is_optional: false\n    is_event_stream: true\n    with_entity_ids:\n      - user\n    with_columns:\n      - name: timestamp\n      - name: user_id\n      - name: anonymous_id\n  app_defaults:\n    table: rudder_events_production.web.tracks # another table in WH maintained by RudderStack processing track events.\n    occurred_at_col: timestamp\n    ids:\n      - select: \"user_id\"\n        type: user_id\n        entity: user\n        to_default_stitcher: true\n      - select: \"anonymous_id\"\n        type: anonymous_id\n        entity: user\n        to_default_stitcher: true\n```\n\nColumns specified under `ids` field are automatically sent for identity stitching unless you specify `to_default_stitcher` as `false`.\n\n### Model\n\nProfiles **Identity stitching** model maps and unifies all the specified identifiers (in `pb_project.yaml` file) across different platforms. It tracks the user journey uniquely across all the data sources and stitches them together to a `rudder_id`.\n\nA sample `profiles.yaml` file specifying an identity stitching model (`user_id_stitcher`) with relevant inputs:\n\n```\nmodels:\n  - name: user_id_stitcher\n    model_type: id_stitcher\n    model_spec:\n      validity_time: 24h\n      entity_key: user\n      materialization:\n        run_type: incremental # default value is `discrete` for a custom ID stitcher and `incremental` for the default ID stitcher.\n      incremental_timedelta: 12h\n      main_id_type: main_id\n      edge_sources:\n        - from: inputs/rsIdentifies\n        - from: inputs/rsTracks\n```\n\n##### Model specification fields\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `validity_time` | Time | Specifies the validity of the model with respect to its timestamp. For example, a model run as part of a scheduled nightly job for 2009-10-23 00:00:00 UTC with `validity_time`: `24h` would still be considered potentially valid and usable for any run requests, which do not require precise timestamps between 2009-10-23 00:00:00 UTC and 2009-10-24 00:00:00 UTC. This specifies the validity of generated feature table. Once the validity is expired, scheduling takes care of generating new tables. For example: 24h for 24 hours, 30m for 30 minutes, 3d for 3 days |\n| `entity_key` | String | Specifies the relevant entity from your `input.yaml` file. For example, here it should be set to `user`. |\n| `materialization` | List | Adds the key `run_type`: `incremental` to run the project in incremental mode. This mode considers row inserts and updates from the `edge_sources` input. These are inferred by checking the timestamp column for the next run. One can provide buffer time to consider any lag in data in the warehouse for the next incremental run like if new rows are added during the time of its run. If you do not specify this key then it’ll default to `run_type`: `discrete`. |\n| `incremental_timedelta` | List | (Optional )If materialization key is set to `run_type`: `incremental`, then this field sets how far back data should be fetched prior to the previous material for a model (to handle data lag, for example). The default value is 4 days. |\n| `main_id_type` | ProjectRef | (Optional) ID type reserved for the output of the identity stitching model, often set to `main_id`. It must not be used in any of the inputs and must be listed as an id type for the entity being stitched. If you do not set it, it defaults to `rudder_id`. Do not add this key unless it’s explicitly required, like if you want your identity stitcher table’s `main_id` column to be called `main_id`. For more information, see below. |\n| `edge_sources` | List | Specifies inputs for the identity stitching model as mentioned in the `inputs.yaml` file. |\n\n## Use cases\n\nThis section describes some common identity stitching use cases:\n\n*   **Identifiers from multiple data sources**: You can consider multiple identifiers and tables by:\n    \n    *   Adding entities in `pb_project.yaml` representing identifiers.\n    *   Adding references to table and corresponding sql in `models/inputs.yaml`\n    *   Adding table reference names defined in `models/inputs.yaml` as `edge_sources` in your model definition.\n*   **Leverage Sql Support**: You can use SQL in your `models/inputs.yaml` to achieve different scenarios. For example, you want to tag all the internal users in your organization as one entity. You can use the email domain as the identifier by adding a SQL query to extract the email domain as the identifier value: `lower(split_part({{email_col}}, '@', 2))`\n    \n*   **Custom ID Stitcher**: You can define a custom ID stitcher by defining the required id stitching model in `models/profiles.yaml`.\n    \n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Identity Stitching | RudderStack Docs",
    "description": "Step-by-step tutorial on how to stitch together different user identities.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/api/event-audit-api/",
    "markdown": "# Event Audit API v2 | RudderStack Docs\n\nGet event metadata to ensure compliance with your data governance policies.\n\nAvailable Plans\n\n*   growth\n*   enterprise\n\n* * *\n\n*     8 minute read  \n    \n\nRudderStack’s Event Audit API gives you full access to your event metadata, including event schemas and their versions.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> The Event Audit API is a part of RudderStack’s [Data Governance toolkit](https://www.rudderstack.com/docs/data-governance/overview/) that ensures the quality and integrity of your data in a secure and compliant manner.\n\nFor the older version of this API, see [Event Audit API v1](https://www.rudderstack.com/docs/api/event-audit-api/v1/). Note that this version will be deprecated soon.\n\n## Authentication\n\nThe Event Audit API uses [Bearer authentication](https://swagger.io/docs/specification/authentication/bearer-authentication/) in the following format:\n\n```\nAuthorization: Bearer <PERSONAL_ACCESS_TOKEN>\n```\n\nTo generate your personal access token, go to **Settings** > **Your Profile** > **Account** tab and scroll down to **Personal access tokens**. Then, click **Generate new token**.\n\n[![New personal access token in RudderStack dashboard](https://www.rudderstack.com/docs/images/rudderstack-api/personal-access-token-1.webp)](https://www.rudderstack.com/docs/images/rudderstack-api/personal-access-token-1.webp)\n\nSee [Personal Access Token](https://www.rudderstack.com/docs/dashboard-guides/personal-access-token/) for more information.\n\n## Base URL\n\nUse the base URL for your API requests depending on your region:\n\n```\nhttps://api.rudderstack.com\n```\n\n```\nhttps://api.eu.rudderstack.com\n```\n\n## Enable Event Audit API\n\nTo enable the Event Audit API in the RudderStack dashboard:\n\n1.  Go to **Settings** > **Workspace** and click the **Data Management** tab.\n2.  Scroll down to the **Data governance** section and toggle on the **Event audit API** setting.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Only users with the [Org Admin](https://www.rudderstack.com/docs/dashboard-guides/user-management/#organization-roles) role have the access to this setting.\n\n[![Event Audit API setting in RudderStack dashboard](https://www.rudderstack.com/docs/images/api/event-audit-api-dashboard.webp)](https://www.rudderstack.com/docs/images/api/event-audit-api-dashboard.webp)\n\nWhen this setting is turned on, you can leverage the Event Audit API to create and manage your [tracking plans](https://www.rudderstack.com/docs/data-governance/tracking-plans/). Use these plans to monitor and act on any non-compliant data coming into your RudderStack sources based on predefined rules.\n\nAlso, note that the Event Audit API collects sample events (used for [fetching event schema version by ID](#get-schema-version-by-id)) only if the [Sample event data](https://www.rudderstack.com/docs/dashboard-guides/data-management/#sample-event-data) toggle is turned on.\n\n[![Opt in to sample event data storage](https://www.rudderstack.com/docs/images/dashboard-guides/sample-event-data.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/sample-event-data.webp)\n\n## Get all event schemas\n\n**Example Request**:\n\n```\n\"GET /v2/schemas HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2VhyC7yQumW09M6GF5Yqcp6HIiq\"\n```\n\n```\n\"curl --location 'https://api.rudderstack.com/v2/schemas' \\\n--header 'Authorization: Bearer 2VhyC7yQumW09M6GF5Yqcp6HIiq'\"\n```\n\n**Example Response**:\n\n```\n{\n  \"results\": [{\n      \"uid\": \"2Vi1RvrDVL1cQwij9UHNWr0za2U\",\n      \"writeKey\": \"2VFrTRhKIgDFLYImdhWTvQUiqhE\",\n      \"eventType\": \"track\",\n      \"eventIdentifier\": \"Test event 3\",\n      \"schema\": {\n        \"anonymousId\": \"string\",\n        \"context.ip\": \"string\",\n        \"context.library.name\": \"string\",\n        \"event\": \"string\",\n        \"messageId\": \"string\",\n        \"properties.full-time\": \"bool\",\n        \"properties.name\": \"string\",\n        \"properties.price\": \"float64\",\n        \"properties.product\": \"string\",\n        \"properties.product_id\": \"string\",\n        \"rudderId\": \"string\",\n        \"timestamp\": \"string\",\n        \"type\": \"string\",\n        \"userId\": \"string\"\n      },\n      \"createdAt\": \"2023-09-21T13:47:53.612087Z\",\n      \"lastSeen\": \"2023-09-21T13:55:06.852916Z\",\n      \"count\": 2\n    },\n    {\n      \"uid\": \"2Vi2jEzAD5fY3STlEXQSwjEhEQh\",\n      \"writeKey\": \"2PyHFFtH978n7xob6RCJ3BQ9nKu\",\n      \"eventType\": \"identify\",\n      \"schema\": {\n        \"anonymousId\": \"string\",\n        \"context.ip\": \"string\",\n        \"context.library.name\": \"string\",\n        \"context.traits.city\": \"string\",\n        \"context.traits.country\": \"string\",\n        \"context.traits.email\": \"string\",\n        \"context.traits.name\": \"string\",\n        \"context.traits.testMap.notNested.a\": \"float64\",\n        \"messageId\": \"string\",\n        \"rudderId\": \"string\",\n        \"timestamp\": \"string\",\n        \"traits.age\": \"float64\",\n        \"traits.anonymousId\": \"string\",\n        \"traits.firstName\": \"string\",\n        \"traits.lastName\": \"string\",\n        \"traits.phone\": \"string\",\n        \"traits.userId\": \"string\",\n        \"type\": \"string\",\n        \"userId\": \"string\"\n      },\n      \"createdAt\": \"2023-09-21T13:58:27.993077Z\",\n      \"lastSeen\": \"2023-09-21T13:58:27.993077Z\",\n      \"count\": 1\n    },\n    {\n      \"uid\": \"2Vi2Su09PnHfaBPie2lKEMEkJjB\",\n      \"writeKey\": \"2PyHFFtH978n7xob6RCJ3BQ9nKu\",\n      \"eventType\": \"track\",\n      \"eventIdentifier\": \"Order Viewed 113\",\n      \"schema\": {\n        \"anonymousId\": \"string\",\n        \"context.ip\": \"string\",\n        \"context.library.name\": \"string\",\n        \"context.userAgent\": \"string\",\n        \"event\": \"string\",\n        \"messageId\": \"string\",\n        \"properties.amount\": \"float64\",\n        \"properties.price\": \"float64\",\n        \"properties.product\": \"string\",\n        \"rudderId\": \"string\",\n        \"timestamp\": \"string\",\n        \"type\": \"string\",\n        \"userId\": \"string\"\n      },\n      \"createdAt\": \"2023-09-21T13:56:19.910831Z\",\n      \"lastSeen\": \"2023-09-21T13:56:19.910831Z\",\n      \"count\": 3\n    }\n  ],\n  \"currentPage\": 1\n}\n```\n\n### Filter by source\n\nTo filter event schemas by source, specify the [write keyThe write key (or source write key) is a unique identifier for your source. RudderStack uses this key to send events from a source to the specified destination.](https://www.rudderstack.com/docs/resources/glossary/#write-key) as a query parameter.\n\nGET\n\n/v2/schemas?writeKey={writeKey}\n\n**Path parameters**\n\nString\n\nWrite key of the source for which you want to fetch the event schemas.\n\n* * *\n\n**Example Request**:\n\n```\n\"GET /v2/schemas?writeKey=2PyHFFtH978n7xob6RCJ3BQ9nKu HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2VhyC7yQumW09M6GF5Yqcp6HIiq\"\n```\n\n```\n\"curl --location 'https://api.rudderstack.com/v2/schemas?writeKey=2PyHFFtH978n7xob6RCJ3BQ9nKu' \\\n--header 'Authorization: Bearer 2VhyC7yQumW09M6GF5Yqcp6HIiq'\"\n```\n\n**Example Response**:\n\n```\n{\n  \"results\": [{\n      \"uid\": \"2Vi2jEzAD5fY3STlEXQSwjEhEQh\",\n      \"writeKey\": \"2PyHFFtH978n7xob6RCJ3BQ9nKu\",\n      \"eventType\": \"identify\",\n      \"schema\": {\n        \"anonymousId\": \"string\",\n        \"context.ip\": \"string\",\n        \"context.library.name\": \"string\",\n        \"context.traits.city\": \"string\",\n        \"context.traits.country\": \"string\",\n        \"context.traits.email\": \"string\",\n        \"context.traits.name\": \"string\",\n        \"context.traits.testMap.notNested.a\": \"float64\",\n        \"messageId\": \"string\",\n        \"rudderId\": \"string\",\n        \"timestamp\": \"string\",\n        \"traits.age\": \"float64\",\n        \"traits.anonymousId\": \"string\",\n        \"traits.firstName\": \"string\",\n        \"traits.lastName\": \"string\",\n        \"traits.phone\": \"string\",\n        \"traits.userId\": \"string\",\n        \"type\": \"string\",\n        \"userId\": \"string\"\n      },\n      \"createdAt\": \"2023-09-21T13:58:27.993077Z\",\n      \"lastSeen\": \"2023-09-21T13:58:27.993077Z\",\n      \"count\": 1\n    },\n    {\n      \"uid\": \"2Vi2LAqj4XrEc6N23ztNdpgikYl\",\n      \"writeKey\": \"2PyHFFtH978n7xob6RCJ3BQ9nKu\",\n      \"eventType\": \"track\",\n      \"eventIdentifier\": \"Order Viewed 112\",\n      \"schema\": {\n        \"anonymousId\": \"string\",\n        \"context.ip\": \"string\",\n        \"context.library.name\": \"string\",\n        \"context.userAgent\": \"string\",\n        \"event\": \"string\",\n        \"messageId\": \"string\",\n        \"properties.amount\": \"float64\",\n        \"properties.price\": \"float64\",\n        \"properties.product\": \"string\",\n        \"rudderId\": \"string\",\n        \"timestamp\": \"string\",\n        \"type\": \"string\",\n        \"userId\": \"string\"\n      },\n      \"createdAt\": \"2023-09-21T13:55:19.860445Z\",\n      \"lastSeen\": \"2023-09-21T13:55:21.866016Z\",\n      \"count\": 3\n    },\n    {\n      \"uid\": \"2Vi2Su09PnHfaBPie2lKEMEkJjB\",\n      \"writeKey\": \"2PyHFFtH978n7xob6RCJ3BQ9nKu\",\n      \"eventType\": \"track\",\n      \"eventIdentifier\": \"Order Viewed 113\",\n      \"schema\": {\n        \"anonymousId\": \"string\",\n        \"context.ip\": \"string\",\n        \"context.library.name\": \"string\",\n        \"context.userAgent\": \"string\",\n        \"event\": \"string\",\n        \"messageId\": \"string\",\n        \"properties.amount\": \"float64\",\n        \"properties.price\": \"float64\",\n        \"properties.product\": \"string\",\n        \"rudderId\": \"string\",\n        \"timestamp\": \"string\",\n        \"type\": \"string\",\n        \"userId\": \"string\"\n      },\n      \"createdAt\": \"2023-09-21T13:56:19.910831Z\",\n      \"lastSeen\": \"2023-09-21T13:56:19.910831Z\",\n      \"count\": 3\n    }\n  ],\n  \"currentPage\": 1\n}\n```\n\n### Filter by page\n\nTo filter event schemas by page, specify the page number as a query parameter.\n\nGET\n\n/v2/schemas?page={number}\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Default page size is 50 - one page contains 50 event schemas.\n\n**Example Request**:\n\n```\n\"GET /v2/schemas?page=1 HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2VhyC7yQumW09M6GF5Yqcp6HIiq\"\n```\n\n```\n\"curl --location 'https://api.rudderstack.com/v2/schemas?page=1' \\\n--header 'Authorization: Bearer 2VhyC7yQumW09M6GF5Yqcp6HIiq'\"\n```\n\n**Example Response**:\n\n```\n{\n  \"results\": [{\n      \"uid\": \"2Vi2jEzAD5fY3STlEXQSwjEhEQh\",\n      \"writeKey\": \"2PyHFFtH978n7xob6RCJ3BQ9nKu\",\n      \"eventType\": \"identify\",\n      \"schema\": {\n        \"anonymousId\": \"string\",\n        \"context.ip\": \"string\",\n        \"context.library.name\": \"string\",\n        \"context.traits.city\": \"string\",\n        \"context.traits.country\": \"string\",\n        \"context.traits.email\": \"string\",\n        \"context.traits.name\": \"string\",\n        \"context.traits.testMap.notNested.a\": \"float64\",\n        \"messageId\": \"string\",\n        \"rudderId\": \"string\",\n        \"timestamp\": \"string\",\n        \"traits.age\": \"float64\",\n        \"traits.anonymousId\": \"string\",\n        \"traits.firstName\": \"string\",\n        \"traits.lastName\": \"string\",\n        \"traits.phone\": \"string\",\n        \"traits.userId\": \"string\",\n        \"type\": \"string\",\n        \"userId\": \"string\"\n      },\n      \"createdAt\": \"2023-09-21T13:58:27.993077Z\",\n      \"lastSeen\": \"2023-09-21T13:58:27.993077Z\",\n      \"count\": 1\n    },\n    {\n      \"uid\": \"2Vi2LAqj4XrEc6N23ztNdpgikYl\",\n      \"writeKey\": \"2PyHFFtH978n7xob6RCJ3BQ9nKu\",\n      \"eventType\": \"track\",\n      \"eventIdentifier\": \"Order Viewed 112\",\n      \"schema\": {\n        \"anonymousId\": \"string\",\n        \"context.ip\": \"string\",\n        \"context.library.name\": \"string\",\n        \"context.userAgent\": \"string\",\n        \"event\": \"string\",\n        \"messageId\": \"string\",\n        \"properties.amount\": \"float64\",\n        \"properties.price\": \"float64\",\n        \"properties.product\": \"string\",\n        \"rudderId\": \"string\",\n        \"timestamp\": \"string\",\n        \"type\": \"string\",\n        \"userId\": \"string\"\n      },\n      \"createdAt\": \"2023-09-21T13:55:19.860445Z\",\n      \"lastSeen\": \"2023-09-21T13:55:21.866016Z\",\n      \"count\": 3\n    },\n    {\n      \"uid\": \"2Vi2Su09PnHfaBPie2lKEMEkJjB\",\n      \"writeKey\": \"2PyHFFtH978n7xob6RCJ3BQ9nKu\",\n      \"eventType\": \"track\",\n      \"eventIdentifier\": \"Order Viewed 113\",\n      \"schema\": {\n        \"anonymousId\": \"string\",\n        \"context.ip\": \"string\",\n        \"context.library.name\": \"string\",\n        \"context.userAgent\": \"string\",\n        \"event\": \"string\",\n        \"messageId\": \"string\",\n        \"properties.amount\": \"float64\",\n        \"properties.price\": \"float64\",\n        \"properties.product\": \"string\",\n        \"rudderId\": \"string\",\n        \"timestamp\": \"string\",\n        \"type\": \"string\",\n        \"userId\": \"string\"\n      },\n      \"createdAt\": \"2023-09-21T13:56:19.910831Z\",\n      \"lastSeen\": \"2023-09-21T13:56:19.910831Z\",\n      \"count\": 3\n    }\n  ],\n  \"currentPage\": 1\n}\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> You can also pass the write key and page number together in the following format:\n> \n> GET\n> \n> /v2/schemas?writeKey={writeKey}&page={number}\n\n## Get schema by ID\n\nGets event schema details based on the specified schema ID.\n\nGET\n\n/v2/schemas/{schemaID}\n\n**Path parameters**\n\nString\n\nID of the event schema you want to fetch.\n\n* * *\n\n**Example Request**:\n\n```\n\"GET /v2/schemas/2Vi2Su09PnHfaBPie2lKEMEkJjB HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2VhyC7yQumW09M6GF5Yqcp6HIiq\"\n```\n\n```\n\"curl --location 'https://api.rudderstack.com/v2/schemas/2Vi2Su09PnHfaBPie2lKEMEkJjB' \\\n--header 'Authorization: Bearer 2VhyC7yQumW09M6GF5Yqcp6HIiq'\"\n```\n\n**Example Response**:\n\n```\n{\n  \"uid\": \"2Vi2Su09PnHfaBPie2lKEMEkJjB\",\n  \"writeKey\": \"2PyHFFtH978n7xob6RCJ3BQ9nKu\",\n  \"eventType\": \"track\",\n  \"eventIdentifier\": \"Order Viewed 113\",\n  \"schema\": {\n    \"anonymousId\": \"string\",\n    \"context.ip\": \"string\",\n    \"context.library.name\": \"string\",\n    \"context.userAgent\": \"string\",\n    \"event\": \"string\",\n    \"messageId\": \"string\",\n    \"properties.amount\": \"float64\",\n    \"properties.city\": \"string\",\n    \"properties.park\": \"string\",\n    \"properties.price\": \"float64\",\n    \"properties.product\": \"string\",\n    \"rudderId\": \"string\",\n    \"timestamp\": \"string\",\n    \"type\": \"string\",\n    \"userId\": \"string\"\n  },\n  \"createdAt\": \"2023-09-21T13:56:19.910831Z\",\n  \"lastSeen\": \"2023-09-21T14:09:31.415404Z\",\n  \"count\": 5,\n  \"latestVersions\": [{\n      \"uid\": \"2Vi45IOhtqw4a8yJCh4JJnyTNKs\",\n      \"firstSeen\": \"2023-09-21T14:09:31.415404Z\",\n      \"lastSeen\": \"2023-09-21T14:09:31.415404Z\",\n      \"count\": 1\n    },\n    {\n      \"uid\": \"2Vi42oQQPGWwaBUHOmc6tnZtASa\",\n      \"firstSeen\": \"2023-09-21T14:09:18.399919Z\",\n      \"lastSeen\": \"2023-09-21T14:09:18.399919Z\",\n      \"count\": 1\n    },\n    {\n      \"uid\": \"2Vi2Sq70lF8DhnNEg5PijmU48kR\",\n      \"firstSeen\": \"2023-09-21T13:56:19.910831Z\",\n      \"lastSeen\": \"2023-09-21T13:56:19.910831Z\",\n      \"count\": 3\n    }\n  ]\n}\n```\n\n## Get all versions of event schema\n\nGET\n\n/v2/schemas/{schemaID}/versions\n\n**Path parameters**\n\nString\n\nID of the event schema you want to fetch.\n\n* * *\n\n**Example Request**:\n\n```\n\"GET /v2/schemas/2Vi2Su09PnHfaBPie2lKEMEkJjB/versions HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2VhyC7yQumW09M6GF5Yqcp6HIiq\"\n```\n\n```\n\"curl --location 'https://api.rudderstack.com/v2/schemas/2Vi2Su09PnHfaBPie2lKEMEkJjB/versions' \\\n--header 'Authorization: Bearer 2VhyC7yQumW09M6GF5Yqcp6HIiq'\"\n```\n\n**Example Response**:\n\n```\n{\n  \"results\": [{\n      \"uid\": \"2Vi2Sq70lF8DhnNEg5PijmU48kR\",\n      \"schemaUid\": \"2Vi2Su09PnHfaBPie2lKEMEkJjB\",\n      \"writeKey\": \"2PyHFFtH978n7xob6RCJ3BQ9nKu\",\n      \"eventType\": \"track\",\n      \"eventIdentifier\": \"Order Viewed 113\",\n      \"schema\": {\n        \"anonymousId\": \"string\",\n        \"context.ip\": \"string\",\n        \"context.library.name\": \"string\",\n        \"context.userAgent\": \"string\",\n        \"event\": \"string\",\n        \"messageId\": \"string\",\n        \"properties.amount\": \"float64\",\n        \"properties.price\": \"float64\",\n        \"properties.product\": \"string\",\n        \"rudderId\": \"string\",\n        \"timestamp\": \"string\",\n        \"type\": \"string\",\n        \"userId\": \"string\"\n      },\n      \"firstSeen\": \"2023-09-21T13:56:19.910831Z\",\n      \"lastSeen\": \"2023-09-21T13:56:19.910831Z\",\n      \"count\": 3\n    },\n    {\n      \"uid\": \"2Vi45IOhtqw4a8yJCh4JJnyTNKs\",\n      \"schemaUid\": \"2Vi2Su09PnHfaBPie2lKEMEkJjB\",\n      \"writeKey\": \"2PyHFFtH978n7xob6RCJ3BQ9nKu\",\n      \"eventType\": \"track\",\n      \"eventIdentifier\": \"Order Viewed 113\",\n      \"schema\": {\n        \"anonymousId\": \"string\",\n        \"context.ip\": \"string\",\n        \"context.library.name\": \"string\",\n        \"context.userAgent\": \"string\",\n        \"event\": \"string\",\n        \"messageId\": \"string\",\n        \"properties.amount\": \"float64\",\n        \"properties.city\": \"string\",\n        \"properties.park\": \"string\",\n        \"properties.price\": \"float64\",\n        \"properties.product\": \"string\",\n        \"rudderId\": \"string\",\n        \"timestamp\": \"string\",\n        \"type\": \"string\",\n        \"userId\": \"string\"\n      },\n      \"firstSeen\": \"2023-09-21T14:09:31.415404Z\",\n      \"lastSeen\": \"2023-09-21T14:09:31.415404Z\",\n      \"count\": 1\n    }\n  ],\n  \"currentPage\": 1\n}\n```\n\n### Filter by page\n\nTo filter event schema versions by page, specify the page number as a query parameter.\n\nGET\n\n/v2/schemas?page={number}\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Default page size is 10 - one page contains 10 event schema versions.\n\n**Example Request**:\n\n```\n\"GET /v2/schemas/2Vi2Su09PnHfaBPie2lKEMEkJjB/versions?page=1 HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2VhyC7yQumW09M6GF5Yqcp6HIiq\"\n```\n\n```\n\"curl --location 'https://api.rudderstack.com/v2/schemas/2Vi2Su09PnHfaBPie2lKEMEkJjB/versions?page=1' \\\n--header 'Authorization: Bearer 2VhyC7yQumW09M6GF5Yqcp6HIiq'\"\n```\n\n**Example Response**:\n\n```\n{\n  \"results\": [{\n      \"uid\": \"2Vi2Sq70lF8DhnNEg5PijmU48kR\",\n      \"schemaUid\": \"2Vi2Su09PnHfaBPie2lKEMEkJjB\",\n      \"writeKey\": \"2PyHFFtH978n7xob6RCJ3BQ9nKu\",\n      \"eventType\": \"track\",\n      \"eventIdentifier\": \"Order Viewed 113\",\n      \"schema\": {\n        \"anonymousId\": \"string\",\n        \"context.ip\": \"string\",\n        \"context.library.name\": \"string\",\n        \"context.userAgent\": \"string\",\n        \"event\": \"string\",\n        \"messageId\": \"string\",\n        \"properties.amount\": \"float64\",\n        \"properties.price\": \"float64\",\n        \"properties.product\": \"string\",\n        \"rudderId\": \"string\",\n        \"timestamp\": \"string\",\n        \"type\": \"string\",\n        \"userId\": \"string\"\n      },\n      \"firstSeen\": \"2023-09-21T13:56:19.910831Z\",\n      \"lastSeen\": \"2023-09-21T13:56:19.910831Z\",\n      \"count\": 3\n    },\n    {\n      \"uid\": \"2Vi45IOhtqw4a8yJCh4JJnyTNKs\",\n      \"schemaUid\": \"2Vi2Su09PnHfaBPie2lKEMEkJjB\",\n      \"writeKey\": \"2PyHFFtH978n7xob6RCJ3BQ9nKu\",\n      \"eventType\": \"track\",\n      \"eventIdentifier\": \"Order Viewed 113\",\n      \"schema\": {\n        \"anonymousId\": \"string\",\n        \"context.ip\": \"string\",\n        \"context.library.name\": \"string\",\n        \"context.userAgent\": \"string\",\n        \"event\": \"string\",\n        \"messageId\": \"string\",\n        \"properties.amount\": \"float64\",\n        \"properties.city\": \"string\",\n        \"properties.park\": \"string\",\n        \"properties.price\": \"float64\",\n        \"properties.product\": \"string\",\n        \"rudderId\": \"string\",\n        \"timestamp\": \"string\",\n        \"type\": \"string\",\n        \"userId\": \"string\"\n      },\n      \"firstSeen\": \"2023-09-21T14:09:31.415404Z\",\n      \"lastSeen\": \"2023-09-21T14:09:31.415404Z\",\n      \"count\": 1\n    }\n  ],\n  \"currentPage\": 1\n}\n```\n\n## Get schema version by ID\n\nGET\n\n/v2/schemas/{schemaID}/versions/{versionID}\n\n**Path parameters**\n\nString\n\nID of the event schema you want to fetch.\n\nString\n\nID of the specific schema version you want to fetch.\n\n* * *\n\n**Example Request**:\n\n```\n\"GET /v2/schemas/2Vi2Su09PnHfaBPie2lKEMEkJjB/versions/2Vi45IOhtqw4a8yJCh4JJnyTNKs HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2VhyC7yQumW09M6GF5Yqcp6HIiq\"\n```\n\n```\n\"curl --location 'https://api.rudderstack.com/v2/schemas/2Vi2Su09PnHfaBPie2lKEMEkJjB/versions/2Vi45IOhtqw4a8yJCh4JJnyTNKs' \\\n--header 'Authorization: Bearer 2VhyC7yQumW09M6GF5Yqcp6HIiq'\"\n```\n\n**Example Response**:\n\n```\n{\n  \"uid\": \"2Vi45IOhtqw4a8yJCh4JJnyTNKs\",\n  \"schemaUid\": \"2Vi2Su09PnHfaBPie2lKEMEkJjB\",\n  \"writeKey\": \"2PyHFFtH978n7xob6RCJ3BQ9nKu\",\n  \"eventType\": \"track\",\n  \"eventIdentifier\": \"Order Viewed 113\",\n  \"schema\": {\n    \"anonymousId\": \"string\",\n    \"context.ip\": \"string\",\n    \"context.library.name\": \"string\",\n    \"context.userAgent\": \"string\",\n    \"event\": \"string\",\n    \"messageId\": \"string\",\n    \"properties.amount\": \"float64\",\n    \"properties.city\": \"string\",\n    \"properties.park\": \"string\",\n    \"properties.price\": \"float64\",\n    \"properties.product\": \"string\",\n    \"rudderId\": \"string\",\n    \"timestamp\": \"string\",\n    \"type\": \"string\",\n    \"userId\": \"string\"\n  },\n  \"firstSeen\": \"2023-09-21T14:09:31.415404Z\",\n  \"lastSeen\": \"2023-09-21T14:09:31.415404Z\",\n  \"count\": 1,\n  \"sample\": \"eyJ0eXBlIjogInRyYWNrIiwgImV2ZW50IjogIk9yZGVyIFZpZXdlZCAwOTg3Iiw\n  gInVzZXJJZCI6ICJpZGVudGlmaWVkIHVzZXIgaWQ2OCIsICJjb250ZXh0IjogImFiYyIsICJy\n  dWRkZXJJZCI6ICI3OTNjN2QxNi05YWE0LTRiYTUtODJhMi0xMWUzZGE1YjFkMDAiLCAib\n  WVzc2FnZUlkIjogIjQxNWU4ZDdkLWFlNzgtNDE4Mi1hMWIxLTM2M2Y0Y2JjYjhlOSIsICJ0a\n  W1lc3RhbXAiOiAiMjAyMC0wMi0wMlQwMDoyMzowOS41NDRaIiwgInByb3BlcnRpZXMiOiB\n  7InByaWNlIjogIm5pbmV0eSBvbmUiLCAiYW1vdW50IjogMTAxLCAib3B0aW9ucyI6IHsib3B0\n  aW9uMSI6ICJoeWRlcmFiYWQiLCAib3B0aW9uMiI6ICJiYW5nYWxvcmUiLCAib3B0aW9uMyI\n  6ICJjaGVubmFpIiwgIm9wdGlvbjQiOiAia29jaGkiLCAib3B0aW9uNSI6ICJiYXBhdGxhIiwgIm9w\n  dGlvbjYiOiAibXVtYmFpIiwgIm9wdGlvbjciOiAicG9uZHkifSwgInByb2R1Y3QiOiAic2hvZXMifSw\n  gImFub255bW91c0lkIjogImFub24taWQtbmV3NjgifQ==\"\n}\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> In the above response, the `sample` parameter is the sample event encoded in Base64 format.\n> \n> As mentioned above, the Event Audit API collects sample events only if the [Sample event data](https://www.rudderstack.com/docs/dashboard-guides/data-management/#sample-event-data) toggle is turned on in the [Data management](https://www.rudderstack.com/docs/dashboard-guides/data-management/#sample-event-data) settings.\n\n## API responses\n\nThe API responds with a `200` HTTP status code for all successful requests. If the authentication fails, you will get a `400` status with the appropriate error message.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Event Audit API v2 | RudderStack Docs",
    "description": "Get event metadata to ensure compliance with your data governance policies.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/data-governance/data-catalog/",
    "markdown": "# Data Catalog | RudderStack Docs\n\nBuild a data catalog by creating events and properties for tracking plans.\n\nAvailable Plans\n\n*   growth\n*   enterprise\n\n* * *\n\n*     2 minute read  \n    \n\nRudderStack’s **Data Catalog** feature lets you create the events and properties for configuring [tracking plans](https://www.rudderstack.com/docs/data-governance/tracking-plans/). You can also define all the necessary details for your events and properties like name, type, description, category, etc.\n\nOnce created, you can select the required events and associate them with properties while [creating a tracking plan](https://www.rudderstack.com/docs/data-governance/tracking-plans/#create-tracking-plan).\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> You can also use the [Data Catalog API](https://www.rudderstack.com/docs/api/data-catalog-api/) to:\n> \n> *   Create and manage your tracking plans programmatically.\n> *   Add or update events and properties in your data catalog.\n> *   Create and manage new categories for your data catalog events.\n\nSee this self-paced product tour for data catalog:\n\n## Add event\n\n1.  Log in to the [RudderStack dashboard](https://app.rudderstack.com/) and go to **Monitor** > **Data Catalog** option in the left sidebar.\n2.  In the **Events** tab, click **Add event**.\n\n[![Add new event](https://www.rudderstack.com/docs/images/data-governance/new-event-1.webp)](https://www.rudderstack.com/docs/images/data-governance/new-event-1.webp)\n\n3.  Select event type and category from the dropdown and specify the event name and description. Note that you **cannot** update the event type later.\n4.  Click **Save**.\n\n[![Add new event](https://www.rudderstack.com/docs/images/data-governance/new-event.webp)](https://www.rudderstack.com/docs/images/data-governance/new-event.webp)\n\n### Event details\n\nOnce created, you can click the event to see the following:\n\n*   Event details\n*   Connections to tracking plans, along with the connected sources and associated properties (only visible after you use the event to create a tracking plan)\n*   Delete event\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> You cannot delete an event from the data catalog if it is connected to any tracking plan.\n\nYou can also make any changes to the event and click **Save** for the changes to take effect:\n\n[![View event details in data catalog](https://www.rudderstack.com/docs/images/data-governance/view-event.webp)](https://www.rudderstack.com/docs/images/data-governance/view-event.webp)\n\n## Add property\n\n1.  Log in to the [RudderStack dashboard](https://app.rudderstack.com/) and go to **Monitor** > **Data Catalog** option in the left sidebar.\n2.  In the **Properties** tab, click **Add property**.\n\n[![Add new property](https://www.rudderstack.com/docs/images/data-governance/new-property-1.webp)](https://www.rudderstack.com/docs/images/data-governance/new-property-1.webp)\n\n3.  Specify the property name and description. Additionally, you can choose the data type(s) for your property from the dropdown.\n4.  Click **Save**.\n\n[![Add new property](https://www.rudderstack.com/docs/images/data-governance/new-property.webp)](https://www.rudderstack.com/docs/images/data-governance/new-property.webp)\n\n### Property details\n\nOnce created, you can click the property to see the following:\n\n*   Property details like name, description, and data type.\n*   Connections to tracking plans, along with the connected sources and associated events (only visible after you map the property to an event while creating a tracking plan)\n*   Delete property\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> You cannot delete a property from the data catalog if it is connected to any tracking plan.\n\nYou can also make any changes to the property details and click **Save** for the changes to take effect:\n\n[![Add new property](https://www.rudderstack.com/docs/images/data-governance/view-property.webp)](https://www.rudderstack.com/docs/images/data-governance/view-property.webp)\n\n## Add category\n\nYou can associate an event in the data catalog with a category it best fits into. Go to the **Events** tab, click **Select category**, and choose a category from the dropdown.\n\nRudderStack provides the following four categories by default:\n\n*   Conversion\n*   General\n*   Marketing\n*   Onboarding\n\nTo associate an event with a custom category, click **Select category** and enter the new category name.\n\n[![Data catalog categories](https://www.rudderstack.com/docs/images/data-governance/categories.webp)](https://www.rudderstack.com/docs/images/data-governance/categories.webp)\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Data Catalog | RudderStack Docs",
    "description": "Build a data catalog by creating events and properties for tracking plans.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/example/feature-views/",
    "markdown": "# Feature Views | RudderStack Docs\n\nStep-by-step tutorial on creating an feature view models.\n\n* * *\n\n*     9 minute read  \n    \n\nOnce you have done [identity stitching](https://www.rudderstack.com/docs/profiles/core-concepts/identity-stitching/) to unify the identity of your users across all the cross-platforms, you can evaluate and maintain the required features/traits for each identified user using a feature views model.\n\n## Prerequisites\n\n*   A basic Profile Builder project by following the [Profile Builder CLI](https://www.rudderstack.com/docs/profiles/get-started/profile-builder/) steps.\n*   [Structure](https://www.rudderstack.com/docs/profiles/cli-user-guide/structure/) of a Profile Builder project and the parameters used in different files.\n*   [Identity Stitching](https://www.rudderstack.com/docs/profiles/example/id-stitcher/) model as Feature Views reuses its output to extract the required features/traits.\n\n## Feature Views model\n\nYou can define and extract the required features/traits for an entity from your data warehouse using the feature views model. Once done, you can send them to the downstream destinations. A destination could either be the [Activation API](https://www.rudderstack.com/docs/profiles/activation-api/) or any [Reverse ETL destination](https://www.rudderstack.com/docs/destinations/warehouse-destinations/) that RudderStack supports. Each such destination requires data in the form of a table with an ID column and one or more feature columns.\n\nYou can use the Feature Views model to access the entity features based on any ID type and create a view having all or a specified set of entity features across the project. It also lets you unify the traits/features (defined using `entity_vars`) and ML models to generate a comprehensive customer 360 table.\n\nTo create a feature views model, you can add `feature_views` section under `entities` and provide a list of ID types under the `id_served` field. RudderStack assigns a default name to the model, if not provided, and adds all the available features on the entity into the view by default.\n\n### Default feature views model\n\nThe `pb_project.yaml` file for a default feature views model:\n\n```\n...\nentities:\n  - name: user\n    id_types:\n      - main_id\n      - user_id\n    feature_views:\n      using_ids:\n        - id: email\n          name: features_by_email\n        - id: salesforce_id\n          name: salesforce_id_stitched_features\n      features:\n        - from: models/feature_table_1 #include everything from `feature_table_1` (default behaviour if `include` is not specified)\n          include:\t[\"*\"]\n        - from: models/feature_table_2 #exclude 'middle_name' feature from `feature_table_2`\n          exclude:\t[\"middle_name\"] \n```\n\n### Custom feature views model\n\nYou can also define a custom feature views model by including/excluding features from any other model and adding their references to the `feature_views` section.\n\nThe `models/profiles.yaml` file for a custom feature views model:\n\n```\nmodels:\n  - name: cart_feature_views\n    model_type: feature_views\n    model_spec:\n      validity_time: 24h # 1 day\n      entity_key: user\n      id_served: user_id\n      feature_list:\n        - from: packages/pkg/models/cart_table # a table created by package\n          include: [\"*\"] # will include all the traits\n        - from: models/user_var_table\n          include: [\"*\"]\n          exclude: [cart_quantity, purchase_status] # except two, all the other traits will be included\n        - from: models/sql_model\n          include: [lifetime_value] # will include only one trait\n```\n\n## Sample project\n\nThis sample project uses the output of an identity stitching model as an input to create a feature views. The following sections describe how to define your PB project files:\n\n### Project detail\n\nThe [`pb_project.yaml`](https://www.rudderstack.com/docs/profiles/cli-user-guide/structure/#project-details) file defines the project details such as name, schema version, connection name and the entities which represent different identifiers.\n\nYou can define all the identifiers from different input sources you want to stitch together as a `user_main_id`:\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> You need to add `main_id` to the list only if you have defined `main_id_type: main_id` in the ID stitcher spec.\n\n```\n# Project name\nname: sample_id_stitching\n# Project's yaml schema version\nschema_version: 69\n# Warehouse connection\nconnection: test\n# Folder containing models\nmodel_folders:\n  - models\n# Entities in this project and their ids.\nentities:\n  - name: user\n    id_types:\n      - main_id # You need to add `main_id` to the list only if you have defined `main_id_type: main_id` in the id stitcher spec.\n      - user_id # one of the identifier from your data source.\n      - email\n# lib packages can be imported in project signifying that this project inherits its properties from there\npackages:\n  - name: corelib\n    url: \"https://github.com/rudderlabs/profiles-corelib/tag/schema_{{best_schema_version}}\"\n    # if required then you can extend the package definition such as for ID types.\n```\n\n### Input\n\nThe [input file](https://www.rudderstack.com/docs/profiles/cli-user-guide/structure/#inputs) file includes the input table references and corresponding SQL for the above-mentioned entities:\n\n```\ninputs:\n- name: rsIdentifies\n  contract: # constraints that a model adheres to\n    is_optional: false\n    is_event_stream: true\n    with_entity_ids:\n      - user\n    with_columns:\n      - name: timestamp\n      - name: user_id\n      - name: anonymous_id\n      - name: email\n  app_defaults:\n    table: rudder_events_production.web.identifies # one of the WH table RudderStack generates when processing identify or track events.\n    occurred_at_col: timestamp\n    ids:\n      - select: \"user_id\" # kind of identity sql to pick this column from above table.\n        type: user_id\n        entity: user # as defined in project file\n        to_default_stitcher: true\n      - select: \"anonymous_id\"\n        type: anonymous_id\n        entity: user\n        to_default_stitcher: true\n      - select: \"lower(email)\" # can use sql.\n        type: email\n        entity: user\n        to_default_stitcher: true\n- name: rsTracks\n  contract:\n    is_optional: false\n    is_event_stream: true\n    with_entity_ids:\n      - user\n    with_columns:\n      - name: timestamp\n      - name: user_id\n      - name: anonymous_id\n  app_defaults:\n    table: rudder_events_production.web.tracks # another table in WH maintained by RudderStack processing track events.\n    occurred_at_col: timestamp\n    ids:\n      - select: \"user_id\"\n        type: user_id\n        entity: user\n        to_default_stitcher: true\n      - select: \"anonymous_id\"\n        type: anonymous_id\n        entity: user\n        to_default_stitcher: true\n```\n\n### Model\n\nThe **feature views** model lets you define and extract the features/traits from your warehouse tables. Each feature is defined using an `entity_var`.\n\nA sample `profiles.yaml` file specifying a feature views model:\n\n```\nvar_groups:\n  - name: first_group\n    entity_key: user\n    vars:\n      - entity_var:\n          name: first_seen\n          select: min(timestamp::date)\n          from: inputs/rsTracks\n          where: properties_country is not null and properties_country != ''\n      - entity_var:\n          name: last_seen\n          select: max(timestamp::date)\n          from: inputs/rsTracks\n          is_feature: false # Specifies the entity_var is not a feature\n      - entity_var:\n          name: user_lifespan\n          select: '{{user.Var(\"last_seen\")}} - {{user.Var(\"first_seen\")}}'\n          description: Life Time Value of a customer\n      - entity_var:\n          name: days_active\n          select: count(distinct timestamp::date)\n          from: inputs/rsTracks\n          description: No. of days a customer was active\n      - entity_var:\n          name: campaign_source\n          default: \"'organic'\"\n      - entity_var:\n          name: user_rank\n          default: -1\n      - entity_var:\n          name: campaign_source_first_touch\n          select: first_value(context_campaign_source)\n          window:\n              order_by:\n                  - timestamp asc\n              partition_by:\n                  - main_id\n          from: inputs/rsIdentifies\n          where: context_campaign_source is not null and context_campaign_source != ''\n      - input_var:\n          name: num_c_rank_num_b_partition\n          select: rank()\n          from: inputs/tbl_c\n          default: -1\n          window:\n            partition_by:\n              - '{{tbl_c}}.num_b'\n            order_by:\n              - '{{tbl_c}}.num_c asc'\n          where: '{{tbl_c}}.num_b >= 10'\n      - entity_var:\n          name: min_num_c_rank_num_b_partition\n          select: min(num_c_rank_num_b_partition)\n          from: inputs/tbl_c\n```\n\n**`var_groups`**\n\nThe `var_groups` field groups all the `vars` under it and provides the provision to define any configuration keys that need to be shared across `vars`.\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `name` | String | Name to identify the `var_groups` uniquely. |\n| `entity_key` | String | Specifies the entity to be used. |\n| `vars` | List | Specifies the `entity_var` and `input_var` variables. |\n\n**`entity_var`**\n\nThe `entity_var` field provides inputs for the feature views model. This variable stores the data temporarily, however, you can choose to store its data permanently by specifying the `name` in it as a feature in the `features` key.\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `name` | String | Name of the `entity_var` to identify it uniquely. |\n| `select` | String | Column name/value you want to select from the table. This defines the actual value that will be stored in the variable. You can use simple SQL expressions or select an `entity_var` as `{{entityName.Var(\\\"entity_var\\\")}}`. It has to be an aggregate operation that ensures the output is a unique value for a given `main_id`. For example: min(timestamp), count(\\*), sum(amount) etc. This holds true even when a window function (optional) is used. For example:: first\\_value(), last\\_value() etc are valid while rank(), row\\_number(), etc. are not valid and give unpredictable results. |\n| `from` | List | Reference to the source table from where data is to be fetched. You can either refer to another model from the same YAML or some other table specified in input YAML. |\n| `where` | String | Any filters you want to apply on the input table before selecting a value. This must be SQL compatible and should consider the data type of the table. |\n| `default` | String | Default value in case no data matches the filter. When defining default values, make sure you enclose the string values in single quotes followed by double quotes to avoid SQL failure. However, you can use the non-string values without any quotes. |\n| `description` | String | Textual description of the `entity_var`. |\n| `is_feature` | Boolean | Determines whether the `entity_var` is a feature. The default value is true. |\n| `window` | Object | Specifies the window function. Window functions in SQL usually have both `partition_by` and `order_by` properties. But for `entity_var`, `partition_by` is added with `main_id` as default; so, adding `partition_by` manually is not supported. If you need partitioning on other columns too, check out `input_var` where `partition_by` on arbitrary and multiple columns is supported. |\n\n**`input_var`**\n\nThe syntax of `input_var` is similar to `entity_var`, with the only difference that instead of each value being associated to a row of the feature views, it’s associated with a row of the specified input. While you can think of an `entity_var` as adding a helper column to the feature views, you can consider an `input_var` as adding a helper column to the input.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> If more than one `input_var` are required to derive an `entity_var`, then all the `input_var` must be defined on the same table.\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `name` | String | Name to store the retrieved data. |\n| `select` | String | Data to be stored in the name. |\n| `from` | List | Reference to the source table from where data is to be fetched. |\n| `where` | String | (Optional) Applies conditions for fetching data. |\n| `default` | String | (Optional) Default value for any entity for which the calculated value would otherwise be NULL. |\n| `description` | String | (Optional) Textual description. |\n| `window` | Object | (Optional) Specifies a window over which the value should be calculated. |\n\n**`window`**\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `partition_by` | String | (Optional) List of SQL expressions to use in partitioning the data. |\n| `order_by` | String | (Optional) List of SQL expressions to use in ordering the data. |\n\nIn window option, `main_id` is not added by default, it can be any arbitrary list of columns from the input table. So if a feature should be partitioned by `main_id`, you must add it in the `partition_by` key.\n\n### Output\n\nAfter [running the project](https://www.rudderstack.com/docs/profiles/get-started/profile-builder/#7-generate-output-tables), you can view the generated material tables.\n\n1.  Log in to your Snowflake console.\n2.  Click **Worksheets** from the top navigation bar.\n3.  In the left sidebar, click **Database** and the corresponding **Schema** to view the list of all tables. You can hover over a table to see the full table name along with its creation date and time.\n4.  Write a SQL query like `select * from <table_name>` and execute it to see the results:\n\n1.  Open [Postico2](https://eggerapps.at/postico2/). If required, create a new connection by entering the relevant details. Click **Test Connection** followed by **Connect**.\n2.  Click the **+** icon next to **Queries** in the left sidebar.\n3.  You can click **Database** and the corresponding schema to view the list of all tables/views.\n4.  Double click on the appropriate view name to paste the name on an empty worksheet.\n5.  You can prefix `SELECT *` from the view name pasted previously and suffix `LIMIT 10;` at the end.\n6.  Press Cmd+Enter keys, or click the **Run** button to execute the query.\n\n1.  Enter your Databricks workspace URL in the web browser and log in with your username and password.\n2.  Click the **Catalog** icon in left sidebar.\n3.  Choose the appropriate catalog from the list and click on it to view contents.\n4.  You will see list of tables/views. Click the appropriate table/view name to paste the name on worksheet.\n5.  You can prefix `SELECT * FROM` before the pasted view name and suffix `LIMIT 10;` at the end.\n6.  Select the query text. Press Cmd+Enter, or click the **Run** button to execute the query.\n\n1.  Log in to your [Google Cloud Console](https://console.cloud.google.com/)\n2.  Search for Bigquery in the search bar.\n3.  Select Bigquery from **Product and Pages** to open the Bigquery **Explorer**.\n4.  Select the correct project from top left drop down menu.\n5.  In the left sidebar, click the project ID, then the corresponding dataset view list of all the tables and views.\n6.  Write a SQL query like `select * from <table_name> limit 10;` and execute it to see the results.\n\nA sample output containing the results in Snowflake:\n\n![Generated table (Snowflake)](https://www.rudderstack.com/docs/images/profiles/profiles-feature-table.webp)\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Feature Views | RudderStack Docs",
    "description": "Step-by-step tutorial on creating an feature view models.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/data-governance/alerts/",
    "markdown": "# Configurable Alerts | RudderStack Docs\n\nSet up notifications for critical data issues.\n\nAvailable Plans\n\n*   starter\n*   growth\n*   enterprise\n\n* * *\n\n*     9 minute read  \n    \n\nRudderStack’s smart alerting capabilities let you set up notifications for critical data issues so you can take appropriate actions immediately before they escalate into major problems.\n\nWith RudderStack’s alerting feature, you can:\n\n*   Configure alerts for Event Stream latency, delivery failures, pre-sync or sync failures, event volume drops, and tracking plan violations.\n*   Set failure thresholds at the [workspace](#workspace-level-alerts) and [resource](#resource-level-alerts) level, so you are alerted only when necessary.\n*   [Set up alert delivery channels](#set-up-alert-delivery-channels) of your choice like email, custom webhook, Slack, or any other tool. Once the alert threshold is hit, RudderStack automatically delivers alerts to these systems.\n\n## Set up alerting\n\nRudderStack lets you set up alerts both at the [workspace](#workspace-level-alerts) and [resource](#resource-level-alerts) level.\n\n### Workspace level alerts\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Only [Org Admins](https://www.rudderstack.com/docs/dashboard-guides/user-management/#organization-roles) can set up workspace-level alerts.\n\nGo to **Settings** > **Workspace** and click the **Alerts** tab to set up workspace-level alerts, that is, alerts for sources and destinations across your [Event Stream](https://www.rudderstack.com/docs/data-pipelines/event-stream/) and [Reverse ETL](https://www.rudderstack.com/docs/data-pipelines/reverse-etl/) pipelines for that workspace.\n\n[![Alerts option in RudderStack dashboard](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/configurable-alerts-overview-new.webp)](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/configurable-alerts-overview-new.webp)\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Note the following:\n> \n> *   RudderStack automatically delivers alerts on the [configured channels](#set-up-alert-delivery-channels) if the failures exceed the threshold percentage within the last one hour.\n> *   If you set the error threshold to 0%, even a single failure in processing or delivering events will trigger an alert.\n\n#### Event Stream\n\nIn this section, you can configure alerts and set thresholds for the following incidents:\n\n| Failure type | Description | Applicable to |\n| --- | --- | --- |\n| P95 latency  <br>Beta | Maximum latency for 95% of the events to reach the destination.<br><br>See [P95 latency alerts](#p95-latency-alerts) for more details. | [Event Stream destinations](https://www.rudderstack.com/docs/destinations/streaming-destinations/) |\n| Cloud destination failures | Failures in processing or delivering events to a destination due to incorrect credentials, destination downtime, network error, or any other reason. | [Event Stream destinations](https://www.rudderstack.com/docs/destinations/streaming-destinations/) |\n| Warehouse pre-sync failures | Failures in processing or storing the events in object storage before forwarding them to the warehouse destination. | [Warehouse destinations](https://www.rudderstack.com/docs/destinations/warehouse-destinations/) |\n| Warehouse sync failures | Failures in syncing events to a warehouse destination, that is, syncs to a warehouse destination are aborted. Possible reasons include:<br><br>*   Incorrect warehouse connection credentials<br>*   Warehouse settings changed/updated midway through the syncs<br>*   Source/destination downtime or network error | [Warehouse destinations](https://www.rudderstack.com/docs/destinations/warehouse-destinations/) |\n| Low event volume  <br>Beta | Event volume drop in the last one hour is more than the configured threshold, as compared to the same period from the last week.<br><br>See [Low event volume alerts](#low-event-volume-alerts) for more details. | [Event Stream sources](https://www.rudderstack.com/docs/sources/event-streams/) |\n| Tracking plan violations | [Tracking plan violations](https://www.rudderstack.com/docs/data-governance/tracking-plans/#violation-types) for a particular source, that is, the incoming source events and properties do not comply with the tracking plan connected to that source. | [Event Stream sources](https://www.rudderstack.com/docs/sources/event-streams/) |\n\n##### **P95 latency alerts**\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> This feature is currently in beta and available only to selected customers.\n\nRudderStack triggers the **P95 latency** alert if the maximum latency experienced by 95% of the events to reach the destination exceeds the specified threshold.\n\nFor example, if you send 100 events to an Event Stream destination and the P95 latency alert threshold is set to 15 minutes, then 95 of those events should be delivered in **strictly less than** the specified threshold (that is, 15 minutes). Otherwise, RudderStack triggers an alert.\n\nGo to the **Events** tab of your Event Stream destination to check the average P95 latency across all Event Stream sources.\n\n[![P95 latency for destination](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/p95-latency-events.webp)](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/p95-latency-events.webp)\n\nTo view the P95 latency for events coming from a particular source, filter the Event Stream source from the dropdown:\n\n[![View source-specific P95 latency](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/filter-source-latency.webp)](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/filter-source-latency.webp)\n\n##### **Low event volume alerts**\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> This feature is currently in beta.\n\nRudderStack triggers the **Low event volume** alert if the event volume drop for an [Event Stream source](https://www.rudderstack.com/docs/sources/event-streams/) in the last one hour is more than the configured threshold compared to the event volume for the same time period in the last week.\n\nRudderStack triggers the **Low event volume** alerts based on the below formula:\n\n[![Equation to calculate low event volume triggers](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/low-event-volume-equation.webp)](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/low-event-volume-equation.webp)\n\nFor example, you will get an alert if:\n\n*   An Event Stream source ingests 450 events within the last hour (for example, 11- 12 p.m.), but it ingested 1000 events from 11-12 p.m. a week before.\n*   The alert threshold was set to 50%.\n\nIn this case, RudderStack triggers an alert as the volume drop percentage (55%) exceeds the configured threshold (50%).\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Note that:\n> \n> *   A 0% threshold indicates that RudderStack triggers an alert **even if** the number of ingested events in the past one hour is the same as last week. That is, `last_week_window_count` = `current_window_count`.\n> *   A 100% threshold indicates that RudderStack triggers an alert if the source ingested **no** events in the last one hour but some events (>0) exactly a week before. That is, `current_window_count` = 0 and `last_week_window_count` > 0.\n\n#### Reverse ETL\n\nIn this section, you can configure alerts for the following incidents applicable to all your [Reverse ETL sources](https://www.rudderstack.com/docs/sources/reverse-etl/):\n\n| Failure type | Description |\n| --- | --- |\n| Partial row failures | Failures in syncing records from the warehouse source to the connected destination. |\n| Fatal syncs | Fatal errors causing a running sync to be aborted. Possible reasons include:<br><br>*   Incorrect warehouse connection credentials<br>*   Warehouse settings changed/updated midway through the syncs<br>*   Source/destination downtime or network error |\n\n#### Custom alerts\n\nClick the **Custom alerts** setting present below each failure type to view the resources for which [custom alert overrides](#resource-level-alerts) are configured:\n\n[![Custom alert setting](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/custom-alerts-setting.webp)](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/custom-alerts-setting.webp)\n\nThe resulting sidebar lists all the resources with custom alerts categorized by failure type. You also see the following information:\n\n*   **Name**: The resource name.\n*   **Subscribed**: Whether alerts are on or off for that failure type.\n*   **Threshold**: Custom alert threshold value set for that resource.\n\nClick on a resource to change these settings.\n\n[![Custom alerts](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/custom-alerts.webp)](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/custom-alerts.webp)\n\n### Resource level alerts\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Note the following:\n> \n> *   Only members with [Org Admin](https://www.rudderstack.com/docs/dashboard-guides/user-management/#organization-roles) or [Connections Admin](https://www.rudderstack.com/docs/dashboard-guides/user-management/#resource-roles) permissions can set up resource-level alerts.\n> *   Once you set the alert overrides for a particular resource, any changes to the workspace-level settings will not be applicable for that resource.\n> *   You cannot change the alert delivery channels for a particular resource.\n\nGo to the resource (source or destination) for which you want to customize the alert settings. Then, click the **Settings** tab and scroll down to the alerts section.\n\n[![Resource-level alert settings](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/resource-level-alert-settings.webp)](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/resource-level-alert-settings.webp)\n\nIf configured, you will see the workspace-level alert settings and thresholds enabled for the resource by default. You can change these settings and set custom thresholds for this resource.\n\nOnce you change the settings, you will automatically see the following message pop up:\n\n[![Resource-level alerts](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/resource-level-alerts.webp)](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/resource-level-alerts.webp)\n\n##### **Resource-specific alert types**\n\nThe following table lists the alert types applicable to a particular Event Stream or Reverse ETL resource:\n\n| Resource type | Alert type |\n| --- | --- |\n| Event Stream source | *   Low event volume<br>*   Tracking plan violations |\n| Event Stream destination | Cloud destination failures |\n| Warehouse destination | *   Warehouse pre-sync failures<br>*   Warehouse sync failures |\n| Reverse ETL source | *   Partial row failures<br>*   Fatal syncs |\n\n## Set up alert delivery channels\n\nYou can set up dedicated alert channels to get notified whenever your sources or destinations have failures or errors. This allows you to take proactive measures to fix the problems before they escalate into major issues.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Note that:\n> \n> *   You can set up separate alert delivery channels for your Event Stream and Reverse ETL pipelines.\n> *   Toggling off alerts for a channel automatically removes all the configurations. You will have to reconfigure the channel to use it again.\n> *   RudderStack limits the alert delivery to one alert per resource per [alert type](#resource-specific-alert-types) for each configured channel every 24 hours.\n\nRudderStack provides the following options to set up channels for delivery alerts:\n\n### Slack\n\nToggle on the **Slack** setting to receive alerts on your preferred Slack channel.\n\n[![Slack channel configuration for alerts](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/slack-alerts.webp)](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/slack-alerts.webp)\n\nSet the Slack channel and authorize RudderStack to post the alerts by clicking **Allow**. Note that you should be an admin of the Slack workspace to grant RudderStack the necessary permissions to post to that channel.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> While setting the Slack channel, you will see a **This app is not approved by Slack** ribbon at the top. This is because Slack has not reviewed the app yet. However, it is completely safe to install.\n\n[![Slack channel configuration for alerts](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/configure-slack-channel.webp)](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/configure-slack-channel.webp)\n\nOnce the alert is triggered, RudderStack automatically sends a notification on the specified Slack channel. Click **Review on RudderStack** to go to the specific resource (source or destination) to investigate and fix the errors.\n\n[![Slack alerts](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/slack-alerts-new.webp)](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/slack-alerts-new.webp)\n\n### Microsoft Teams\n\nToggle on the **MS Teams** setting and enter the incoming webhook URL to receive alerts on your preferred Teams channel.\n\n[![Teams channel configuration for alerts](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/teams-alerts.webp)](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/teams-alerts.webp)\n\nOnce the alert is triggered, RudderStack automatically sends a notification on the specified Teams channel:\n\n[![Teams alerts](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/teams-alerts-2.webp)](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/teams-alerts-2.webp)\n\nClick **Review on RudderStack** to go to the specific resource (source or destination) to investigate and fix the errors.\n\n### Webhook\n\nToggle on the **Webhook** setting to forward the alerts to custom webhook channels.\n\nRudderStack sends the alerts as a `POST` request to the configured endpoint while following the Prometheus styling format.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Prometheus is a widely accepted monitoring and alerting tool. Its alert format is compatible with various other monitoring and incident management tools like Squadcast, PagerDuty, etc.\n\nA sample webhook response is shown:\n\n```\n{\n  \"alerts\": [{\n    \"endsAt\": \"0001-01-01T00:00:00Z\",\n    \"labels\": {\n      \"severity\": \"critical\",\n      \"alertname\": \"partial-row-failures\",\n      \"workspace\": \"<workspace_name>\",\n      \"destination\": \"Failing Webhook\",\n      \"workspaceId\": \"<workspace_id>\",\n      \"organization\": \"<org_name>\",\n      \"destinationId\": \"<destination_id>\",\n      \"organizationId\": \"<org_id>\",\n      \"configuredThreshold\": 61\n    },\n    \"status\": \"firing\",\n    \"startsAt\": \"2024-02-05T00:02:49.933Z\",\n    \"annotations\": {\n      \"description\": \"Errors in processing or delivering events to Failing Webhook destination have exceeded the configured threshold of 61% within last 1 hour\"\n    },\n    \"fingerPrint\": \"d9885cc7f11b8db0\"\n  }],\n  \"status\": \"firing\"\n}\n```\n\n##### **Send alerts to downstream tools**\n\nYou can also forward the alerts to any downstream tool supported by RudderStack:\n\n1.  Set up a [webhook source](https://www.rudderstack.com/docs/sources/event-streams/cloud-apps/webhook-source/). Note the webhook URL containing the source write key parameter.\n\n[![Webhook source](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/webhook-source.webp)](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/webhook-source.webp)\n\n2.  Set up a [destination integration](https://www.rudderstack.com/docs/destinations/streaming-destinations/), for example, [PagerDuty](https://www.rudderstack.com/docs/destinations/streaming-destinations/pagerduty/). Connect it to the webhook source created in Step 1.\n3.  Once you set up the connection, specify the webhook source URL obtained in Step 1 in the **Enter URL** field where RudderStack forwards the alerts.\n\n[![Webhook configuration for alerts](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/webhook-alerts.webp)](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/webhook-alerts.webp)\n\n### Email\n\nToggle on the **Email** setting and specify comma-separated email addresses of the users who would like to receive the alerts.\n\n[![Email alerts](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/email.webp)](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/email.webp)\n\nOnce the alert is triggered, these users will automatically get email alerts to investigate and fix the errors.\n\n[![Email alerts](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/email-alert-new.webp)](https://www.rudderstack.com/docs/images/data-governance/configurable-alerts/email-alert-new.webp)\n\n## Alert frequency\n\nRudderStack limits the alert delivery to one alert per resource (source or destination) per [alert type](#resource-specific-alert-types) for each configured channel every 24 hours.\n\nThis alerting logic ensures you are not spammed with notifications, especially in cases where you have configured multiple [alert types](#resource-specific-alert-types) for your pipelines and some resources have their own overrides (custom alert settings) in place.\n\n##### **Use case**\n\nSuppose you get a [Partial row failures](#resource-specific-alert-types) alert for a particular Reverse ETL source. You will not get another alert for the same failure type for another 24 hours even if your data syncs are scheduled at a lesser frequency (for example, every one, five, or 12 hours).\n\nHowever, if that source encounters another failure type like a fatal sync, RudderStack will trigger an alert.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Configurable Alerts | RudderStack Docs",
    "description": "Set up notifications for critical data issues.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/data-governance/geolocation-service/",
    "markdown": "# Geolocation Enrichment at Source | RudderStack Docs\n\nEnrich source events with geolocation data.\n\nAvailable Plans\n\n*   starter\n*   growth\n*   enterprise\n\n* * *\n\n*     4 minute read  \n    \n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> This feature is part of our [Early Access Program](https://www.rudderstack.com/docs/resources/early-access-program/), where we work with early users and customers to test new features and get feedback before making them generally available. These features are functional but can change as we improve them. We recommend connecting with our team before running them in production.\n\nWith RudderStack’s geolocation enrichment feature, you can enrich your incoming source events with the following geolocation information:\n\n*   City\n*   Country\n*   Region\n*   Location\n*   Postal code\n*   Timezone\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> This feature sends the geolocation-enriched events to all the destinations that are connected to the source. However, note that the destinations may or may not accept the geolocation-enriched properties depending on the event format they support. See [FAQ](#faq) for more information.\n\n## Enable geolocation enrichment at source\n\nTo enrich your source events with geolocation data, [add a source](https://www.rudderstack.com/docs/dashboard-guides/sources/) in your RudderStack dashboard. Then, go to the **Settings** tab and turn on the **Enable geolocation enrichment** toggle.\n\n[![Geolocation at source](https://www.rudderstack.com/docs/images/features/geolocation-at-source.webp)](https://www.rudderstack.com/docs/images/features/geolocation-at-source.webp)\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Turning on the **Enable geolocation enrichment** toggle sends the enriched events to **all** the destinations connected to the source.\n\n## How source-level geolocation enrichment works\n\nThe following workflow assumes you have turned on the **Enable geolocation enrichment** toggle in the RudderStack dashboard:\n\n1.  RudderStack ingests the incoming source event.\n2.  It picks the first non-blank value from [`ip`](https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/#how-rudderstack-collects-ip-address:~:text=and%20type.-,ip,-String) passed by the user in the `context` object of the event payload or [`request_ip`](https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/#how-rudderstack-collects-ip-address:~:text=for%20more%20information.-,request_ip,-String) (automatically collected by RudderStack).\n3.  RudderStack enriches the event with the geolocation information at a hardcoded location within the `context` section (`context.geo`). A sample geolocation-enriched object is shown:\n\n```\n{\n  ...\n  \"context\": {\n    \"geo\": {\n      \"city\": \"Gurugram\",\n      \"country\": \"IN\",\n      \"ip\": \"223.190.82.63\",\n      \"location\": \"28.459700,77.028200\",\n      \"postal\": \"122001\",\n      \"region\": \"Haryana\",\n      \"timezone\": \"Asia/Kolkata\"\n    },\n    \"ip\": \"223.190.82.63\"\n  },\n  ...\n}\n```\n\nNote the following:\n\n*   Ideally, the `context` object should be a valid map for RudderStack to attach the geolocation enrichment information.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> If the object is not a valid map but of some other data type, RudderStack will **not** change its data type or format. In this case, the `context` object will remain unchanged and RudderStack will **not** add the enriched geolocation information in `context.geo`.\n\n*   If the first non-blank value is **invalid**, RudderStack updates `context.geo` as follows:\n\n```\n\"context\": {\n  \"geo\": {\n    \"city\": \"\",\n    \"country\": \"\",\n    \"ip\": \"invalid\",\n    \"location\": \"\",\n    \"postal\": \"\",\n    \"region\": \"\",\n    \"timezone\": \"\"\n  }\n},\n```\n\n*   If the event payload already has a `geo` field within the `context` object, RudderStack will not perform geolocation enrichment. It will **not** override the existing `geo` field with the enriched data.\n\n4.  RudderStack then transforms the event into the destination-specific format.\n\n[![Geolocation enrichment process](https://www.rudderstack.com/docs/images/features/geolocation-enrichment-process.webp)](https://www.rudderstack.com/docs/images/features/geolocation-enrichment-process.webp)\n\n## License\n\nThis feature leverages the GeoLite2 data created by MaxMind, available from [](https://www.maxmind.com/)[https://www.maxmind.com](https://www.maxmind.com/).\n\nFor more information, see [Maxmind license agreement](https://dev.maxmind.com/geoip/geolite2-free-geolocation-data#license).\n\n## FAQ\n\n#### **Do all the destinations accept the geolocation-enriched source events?**\n\nThe following destinations accept the geolocation-enriched source events as is:\n\n*   [Warehouse destinations](https://www.rudderstack.com/docs/destinations/warehouse-destinations/)\n*   [Object storage destinations](https://www.rudderstack.com/docs/destinations/streaming-destinations/#object-storage)\n*   [Streaming platforms](https://www.rudderstack.com/docs/destinations/streaming-destinations/#streaming) like Apache Kafka, Amazon Kinesis, etc.\n*   [Serverless platforms](https://www.rudderstack.com/docs/destinations/streaming-destinations/#serverless) like AWS Lambda and Google Cloud Functions.\n*   [Webhooks](https://www.rudderstack.com/docs/destinations/webhooks/)\n\nThe other cloud destinations may or not accept the geolocation-enriched event properties, depending on the event format they support.\n\n#### **I want to send the geolocation-enriched events to selective destinations and not all destinations connected to the source. Is this feature helpful?**\n\nThis feature sends the geolocation-enriched events to **all** the destinations that are connected to the source. To send events to selective destinations, you can connect the [geolocation enrichment transformation](https://www.rudderstack.com/docs/transformations/geolocation-enrichment/) to those destinations instead.\n\n1.  Go to the destination in the dashboard. Click the **Transformation** tab and click **Add a transformation**:\n2.  Click **Create Transformation**.\n3.  Under **New Transformation**, click **Custom transformation**.\n\n[![Add a new transformation](https://www.rudderstack.com/docs/images/features/custom-transformation.webp)](https://www.rudderstack.com/docs/images/features/custom-transformation.webp)\n\n4.  Add the [geolocation enrichment transformation](https://www.rudderstack.com/docs/transformations/geolocation-enrichment/) code.\n5.  Test your transformation and click **Save**.\n\n#### **What happens if `context` object is absent in the event payload?**\n\nRudderStack adds the `context` object and includes the enriched geolocation information in it.\n\n#### **What happens if I toggle off the geolocation enrichment setting?**\n\nOnce you toggle off the **Enable geolocation enrichment** setting, RudderStack stops the enrichment process almost instantly, even if you have valid IPs coming in your source events.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Geolocation Enrichment at Source | RudderStack Docs",
    "description": "Enrich source events with geolocation data.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/example/id-collator/",
    "markdown": "# ID Collator | RudderStack Docs\n\nStep-by-step tutorial stitching different user identities together.\n\n* * *\n\n*     3 minute read  \n    \n\nID Stitching is one of the most important features of Profiles. Being able to perform ID stitching to determine the accounts belonging to the same customer/user is very important to get a 360-degree view of that user.\n\nHowever many a times, we may not require ID stitching for a particular entity, especially if there are no edges in the ID graph of an entity. To build a feature table on such an entity, you will still need to perform ID stitching. Although this approach is not wrong, it is computationally redundant.\n\nProfiles provides the ID Collator is to get all IDs of that particular entity from various input tables and create one collated list of IDs.\n\n## Sample project\n\nLet’s take a case where we have defined two entities in our project - one is `user` and the other is `session`.\n\nIf `user` entity has multiple IDs defined, there are basically edges which make the use of an ID stitcher logical. On the other hand, `session` may have only one ID, `ssn_id`, there won’t be any possibility of edges. In such a case, all we need is a complete list of `ssn_id`.\n\nHere is the corresponding inputs and entities definition.\n\n```\nentities:\n  - name: user\n    id_column_name: user_rud_id\n    id_types:\n      - user_id\n      - anonymous_id\n  - name: session\n    id_column_name: session_id\n    id_types:\n      - ssn_id\n```\n\nProject file:\n\n```\ninputs:\n  - name: user_accounts\n    table: tbl_user_accounts\n    occurred_at_col: insert_ts\n    ids:\n      - select: \"user_id\"\n        type: user_id\n        entity: user\n  - name: sign_in\n    table: tbl_sign_in\n    occurred_at_col: insert_ts\n    ids:\n      - select: \"user_id\"\n        type: user_id\n        entity: user\n      - select: \"ssn_id\"\n        type: ssn_id\n        entity: session\n      - select: \"anonymous_id\"\n        type: anonymous_id\n        entity: user\n  - name: sign_up\n    table: tbl_sign_up\n    occurred_at_col: insert_ts\n    ids:\n      - select: \"user_id\"\n        type: user_id\n        entity: user\n      - select: \"ssn_id\"\n        type: ssn_id\n        entity: session\n      - select: \"anonymous_id\"\n        type: anonymous_id\n        entity: user\n```\n\nHere, the `entity: session` has only one ID type. Creating an ID stitcher for such an entity is possible but unnecessary.\n\nUsing all the models having `ssn_id`, we can just make a union of all `ssn_id` and get all distinct values of it and obtain the final list of sessions.\n\nThe underlying SQL will look as follows:\n\n```\nSELECT ssn_id AS session_id FROM sign_in\nUNION\nSELECT ssn_id AS session_id FROM sign_up;\n```\n\n## YAML Changes\n\nThe YAML writer cannot define a custom ID collator the way they define a custom ID stitcher. If an entity has no edges, the PB project will automatically figure out if an ID collator is needed. To exclude certain inputs (having the required ID) from being used in the collation, we can just set `to_id_stitcher: false` in the input.\n\n```\nentities:\n  - name: session\n    id_column_name: session_id\n    id_types:\n      - ssn_id\n```\n\nThe `id_column_name` is a new field added in the entity definition which will be the name of the ID column and it applies to both ID stitcher and ID collator.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> In the ID collator, you won’t generate a UUID like in ID stitcher.\n\n## Comparing ID Collator and ID Stitcher\n\n| ID Stitcher | ID Collator |\n| --- | --- |\n| Uses edges to converge the ID graph. | Collates all distinct IDs as there is only one ID Type and no edges are present. |\n| Higher cost of computation. | Lower cost of computation. |\n| A UUID is generated and used as the unique identifier for the entity. | Collates the existing IDs only. |\n| The generated ID is always of the type: `rudder_id` | The ID column of the generated ID collator table/view will be of the ID type of the corresponding ID. |\n| User may override the default ID stitcher with custom one. | You cannot override the default ID collator, though you can define a custom ID stitcher to override default ID collator. |\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "ID Collator | RudderStack Docs",
    "description": "Step-by-step tutorial stitching different user identities together.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/example/feature-table/",
    "markdown": "# Feature Table | RudderStack Docs\n\nStep-by-step tutorial on creating a feature table model.\n\n* * *\n\n*     9 minute read  \n    \n\nOnce you have done [identity stitching](https://www.rudderstack.com/docs/profiles/core-concepts/identity-stitching/) to unify the identity of your users across all the cross-platforms, you can evaluate and maintain the required features/traits for each identified user in a feature table.\n\nThis guide provides a detailed walkthrough on how to use a PB project and create output tables in a warehouse for a feature table model.\n\n## Prerequisites\n\nFamiliarize yourself with:\n\n*   A basic Profile Builder project by following the [Profile Builder CLI](https://www.rudderstack.com/docs/profiles/get-started/profile-builder/) steps.\n*   [Structure](https://www.rudderstack.com/docs/profiles/cli-user-guide/structure/) of a Profile Builder project and the parameters used in different files.\n*   [Identity Stitching](https://www.rudderstack.com/docs/profiles/example/id-stitcher/) model as feature table reuses its output to extract the required features/traits.\n\n## Sample GitHub projects\n\n*   [Basic features](https://github.com/rudderlabs/profiles-base-features) like active days, session length, last seen date, name, etc.\n*   [Ecommerce features](https://github.com/rudderlabs/profiles-ecommerce-features) like highest transaction value, days since first purchase, items purchased ever, total products added, etc.\n*   [Features using Shopify tables](https://github.com/rudderlabs/profiles-shopify-features) like products added in past 1 day, transactions in past 90 days, etc.\n*   [Features using Stripe tables](https://github.com/rudderlabs/profiles-stripe-features) like total fees, days since first sale, sales i n past 365 days, has credit card, etc.\n\n## Sample project\n\nThis sample project uses the output of an identity stitching model as an input to create a feature table. The following sections describe how to define your PB project files:\n\n### Project detail\n\nThe [`pb_project.yaml`](https://www.rudderstack.com/docs/profiles/cli-user-guide/structure/#project-details) file defines the project details such as name, schema version, connection name and the entities which represent different identifiers.\n\nYou can define all the identifiers from different input sources you want to stitch together as a `user_main_id`:\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> You need to add `main_id` to the list only if you have defined `main_id_type: main_id` in the ID stitcher buildspec.\n\n```\n# Project name\nname: sample_id_stitching\n# Project's yaml schema version\nschema_version: 69\n# Warehouse connection\nconnection: test\n# Folder containing models\nmodel_folders:\n  - models\n# Entities in this project and their ids.\nentities:\n  - name: user\n    id_types:\n      - main_id # You need to add ``main_id`` to the list only if you have defined ``main_id_type: main_id`` in the id stitcher buildspec.\n      - user_id # one of the identifier from your data source.\n      - email\n# lib packages can be imported in project signifying that this project inherits its properties from there\npackages:\n  - name: corelib\n    url: \"https://github.com/rudderlabs/profiles-corelib/tag/schema_{{best_schema_version}}\"\n    # if required then you can extend the package definition such as for ID types.\n```\n\n### Input\n\nThe [input file](https://www.rudderstack.com/docs/profiles/cli-user-guide/structure/#inputs) file includes the input table references and corresponding SQL for the above-mentioned entities:\n\n```\ninputs:\n- name: rsIdentifies\n  contract: # constraints that a model adheres to\n    is_optional: false\n    is_event_stream: true\n    with_entity_ids:\n      - user\n    with_columns:\n      - name: timestamp\n      - name: user_id\n      - name: anonymous_id\n      - name: email\n  app_defaults:\n    table: rudder_events_production.web.identifies # one of the WH table RudderStack generates when processing identify or track events.\n    occurred_at_col: timestamp\n    ids:\n      - select: \"user_id\" # kind of identity sql to pick this column from above table.\n        type: user_id\n        entity: user # as defined in project file\n        to_default_stitcher: true\n      - select: \"anonymous_id\"\n        type: anonymous_id\n        entity: user\n        to_default_stitcher: true\n      - select: \"lower(email)\" # can use sql.\n        type: email\n        entity: user\n        to_default_stitcher: true\n- name: rsTracks\n  contract:\n    is_optional: false\n    is_event_stream: true\n    with_entity_ids:\n      - user\n    with_columns:\n      - name: timestamp\n      - name: user_id\n      - name: anonymous_id\n  app_defaults:\n    table: rudder_events_production.web.tracks # another table in WH maintained by RudderStack processing track events.\n    occurred_at_col: timestamp\n    ids:\n      - select: \"user_id\"\n        type: user_id\n        entity: user\n        to_default_stitcher: true\n      - select: \"anonymous_id\"\n        type: anonymous_id\n        entity: user\n        to_default_stitcher: true\n```\n\n### Model\n\nProfiles **Feature Table** model lets you define the specific features/traits you want to evaluate from the huge spread of scattered data in your warehouse tables.\n\nA sample `profiles.yaml` file specifying a feature table model (`user_profile`):\n\n```\nmodels:\n  - name: user_profile\n    model_type: feature_table_model\n    model_spec:\n      validity_time: 24h\n      entity_key: user\n      features:\n        - user_lifespan\n        - days_active\n        - min_num_c_rank_num_b_partition\nvar_groups:\n  - name: user_vars\n    entity_key: user\n    vars:\n      - entity_var:\n          name: first_seen\n          select: min(timestamp::date)\n          from: inputs/rsTracks\n          where: properties_country is not null and properties_country != ''\n      - entity_var:\n          name: last_seen\n          select: max(timestamp::date)\n          from: inputs/rsTracks\n      - entity_var:\n          name: user_lifespan\n          select: '{{user.Var(\"last_seen\")}} - {{user.Var(\"first_seen\")}}'\n          description: Life Time Value of a customer\n      - entity_var:\n          name: days_active\n          select: count(distinct timestamp::date)\n          from: inputs/rsTracks\n          description: No. of days a customer was active\n      - entity_var:\n          name: campaign_source\n          default: \"'organic'\"\n      - entity_var:\n          name: user_rank\n          default: -1\n      - entity_var:\n          name: campaign_source_first_touch\n          select: first_value(context_campaign_source)\n          window:\n            order_by:\n              - timestamp asc\n          from: inputs/rsIdentifies\n          where: context_campaign_source is not null and context_campaign_source != ''\n      - input_var:\n          name: num_c_rank_num_b_partition\n          select: rank()\n          from: inputs/tbl_c\n          default: -1\n          window:\n            partition_by:\n              - \"{{tbl_c}}.num_b\"\n            order_by:\n              - \"{{tbl_c}}.num_c asc\"\n          where: \"{{tbl_c}}.num_b >= 10\"\n      - entity_var:\n          name: min_num_c_rank_num_b_partition\n          select: min(num_c_rank_num_b_partition)\n          from: inputs/tbl_c\n      - entity_var:\n          name: first_bill\n          select: min({{tbl_billing.Var(\"payment\")}})\n          from: inputs/tbl_billing\n          column_data_type: '{{warehouse.DataType(\"float\")}}'\n```\n\n##### Model specification fields\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `validity_time` | Time | Specifies the validity of the model with respect to its timestamp. For example, a model run as part of a scheduled nightly job for 2009-10-23 00:00:00 UTC with `validity_time`: `24h` would still be considered potentially valid and usable for any run requests, which do not require precise timestamps between 2009-10-23 00:00:00 UTC and 2009-10-24 00:00:00 UTC. This specifies the validity of generated feature table. Once the validity is expired, scheduling takes care of generating new tables. For example: `24h` for 24 hours, `30m` for 30 minutes, `3d` for 3 days, and so on. |\n| `entity_key` | String | Specifies the relevant entity from your `input.yaml` file. |\n| `features` | String | Specifies the list of `name` in `entity_var`, that must act as a feature. |\n\n**`entity_var`**\n\nThe `entity_var` field defines the features which act as an input for the feature table model. This variable stores the data temporarily, however, you can choose to store its data permanently by specifying the `name` in it as a feature in the `features` key.\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `name` | String | Name of the `entity_var` to identify it uniquely. |\n| `select` | String | Column name/value you want to select from the table. This defines the actual value that will be stored in the variable. You can use simple SQL expressions or select an `entity_var` as `{{entityName.Var(\\\"entity_var\\\")}}`. It has to be an aggregate operation that ensures the output is a unique value for a given `main_id`. For example: min(timestamp), count(\\*), sum(amount) etc. This holds true even when a window function (optional) is used. For example:: first\\_value(), last\\_value() etc are valid while rank(), row\\_number(), etc. are not valid and give unpredictable results. |\n| `from` | List | Reference to the source table from where data is to be fetched. You can either refer to another model from the same YAML or some other table specified in input YAML. |\n| `where` | String | Any filters you want to apply on the input table before selecting a value. This must be SQL compatible and should consider the data type of the table. |\n| `default` | String | Default value in case no data matches the filter. When defining default values, make sure you enclose the string values in single quotes followed by double quotes to avoid SQL failure. However, you can use the non-string values without any quotes. |\n| `description` | String | Textual description of the `entity_var`. |\n| `window` | Object | Specifies the window function. Window functions in SQL usually have both `partition_by` and `order_by` properties. But for `entity_var`, `partition_by` is added with `main_id` as default; so, adding `partition_by` manually is not supported. If you need partitioning on other columns too, check out `input_var` where `partition_by` on arbitrary and multiple columns is supported. |\n| `column_data_type` | String | (Optional) Data type for the `entity_var`. Supported data types are: `integer`, `variant`, `float`, `varchar`, `text`, and `timestamp`. |\n\n**`input_var`**\n\nThe syntax of `input_var` is similar to `entity_var`, with the only difference that instead of each value being associated to a row of the feature table, it’s associated with a row of the specified input. While you can think of an `entity_var` as adding a helper column to the feature table, you can consider an `input_var` as adding a helper column to the input.\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `name` | String | Name to store the retrieved data. |\n| `select` | String | Data to be stored in the name. |\n| `from` | List | Reference to the source table from where data is to be fetched. |\n| `where` | String | (Optional) Applies conditions for fetching data. |\n| `default` | String | (Optional) Default value for any entity for which the calculated value would otherwise be NULL. |\n| `description` | String | (Optional) Textual description. |\n| `column_data_type` | String | (Optional) Data type for the `input_var`. Supported data types are: `integer`, `variant`, `float`, `varchar`, `text`, and `timestamp`. |\n| `window` | Object | (Optional) Specifies a window over which the value should be calculated. |\n\n**`window`**\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `partition_by` | String | (Optional) List of SQL expressions to use in partitioning the data. |\n| `order_by` | String | (Optional) List of SQL expressions to use in ordering the data. |\n\nIn window option, `main_id` is not added by default, it can be any arbitrary list of columns from the input table. So if a feature should be partitioned by `main_id`, you must add it in the `partition_by` key.\n\n### Output\n\nAfter [running the project](https://www.rudderstack.com/docs/profiles/get-started/profile-builder/#7-generate-output-tables), you can view the generated material tables.\n\n1.  Log in to your Snowflake console.\n2.  Click **Worksheets** from the top navigation bar.\n3.  In the left sidebar, click **Database** and the corresponding **Schema** to view the list of all tables. You can hover over a table to see the full table name along with its creation date and time.\n4.  Write a SQL query like `select * from <table_name>` and execute it to see the results:\n\n1.  Open [Postico2](https://eggerapps.at/postico2/). If required, create a new connection by entering the relevant details. Click **Test Connection** followed by **Connect**.\n2.  Click the **+** icon next to **Queries** in the left sidebar.\n3.  You can click **Database** and the corresponding schema to view the list of all tables/views.\n4.  Double click on the appropriate view name to paste the name on an empty worksheet.\n5.  You can prefix `SELECT *` from the view name pasted previously and suffix `LIMIT 10;` at the end.\n6.  Press Cmd+Enter keys, or click the **Run** button to execute the query.\n\n1.  Enter your Databricks workspace URL in the web browser and log in with your username and password.\n2.  Click the **Catalog** icon in left sidebar.\n3.  Choose the appropriate catalog from the list and click on it to view contents.\n4.  You will see list of tables/views. Click the appropriate table/view name to paste the name on worksheet.\n5.  You can prefix `SELECT * FROM` before the pasted view name and suffix `LIMIT 10;` at the end.\n6.  Select the query text. Press Cmd+Enter, or click the **Run** button to execute the query.\n\n1.  Log in to your [Google Cloud Console](https://console.cloud.google.com/)\n2.  Search for Bigquery in the search bar.\n3.  Select Bigquery from **Product and Pages** to open the Bigquery **Explorer**.\n4.  Select the correct project from top left drop down menu.\n5.  In the left sidebar, click the project ID, then the corresponding dataset view list of all the tables and views.\n6.  Write a SQL query like `select * from <table_name> limit 10;` and execute it to see the results.\n\nA sample output containing the results in Snowflake:\n\n![Generated table (Snowflake)](https://www.rudderstack.com/docs/images/profiles/profiles-feature-table.webp)\n\n## Feature table for cohort\n\nTo create feature table for a specific cohort, you can pass the cohort’s path in the `entity_cohort` field:\n\n```\n- name: us_users_features\n  model_type: feature_table_model\n  model_spec:\n    entity_cohort: models/knownUsUsers\n    time_grain: \"day\"\n    validity_time: 24h # 1 day\n    features:\n      - has_credit_card\n```\n\nTo create feature tables for the entire set of an entity’s instance, specify the `entity_key`:\n\n```\n- name: all_users_features\n  model_type: feature_table_model\n  model_spec:\n    entity_key: user\n    time_grain: \"day\"\n    validity_time: 24h # 1 day\n    features:\n      - max_timestamp\n```\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Feature Table | RudderStack Docs",
    "description": "Step-by-step tutorial on creating a feature table model.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/data-governance/health-dashboard/",
    "markdown": "# Health Dashboard | RudderStack Docs\n\nMonitor status of your data pipelines and tracking plans in RudderStack.\n\nAvailable Plans\n\n*   starter\n*   growth\n*   enterprise\n\n* * *\n\n*     5 minute read  \n    \n\nRudderStack’s **Health** dashboard provides an intuitive UI to monitor all your Event Stream and Reverse ETL pipelines. It also provides realtime observability metrics for the tracking plans linked to your sources, including validation errors, violation types, etc.\n\nTo access this dashboard, log in to your [RudderStack account](https://app.rudderstack.com/) and go to **Monitor** > **Health** in the left navigation bar.\n\n## Overview\n\nIn the **Overview** section, you get a quick summary of the destinations with failures across your Event Stream (both [cloud](https://www.rudderstack.com/docs/destinations/streaming-destinations/) and [warehouse](https://www.rudderstack.com/docs/destinations/warehouse-destinations/) destinations) and [Reverse ETL](https://www.rudderstack.com/docs/sources/reverse-etl/) pipelines. You also see the events with violations for all the [tracking plans](https://www.rudderstack.com/docs/data-governance/tracking-plans/) linked to your sources.\n\nYou can filter these metrics by period - one day, one week, or one month - depending on your requirement.\n\n[![Health dashboard overview](https://www.rudderstack.com/docs/images/features/health-dashboard/dashboard-overview.webp)](https://www.rudderstack.com/docs/images/features/health-dashboard/dashboard-overview.webp)\n\n## Event Stream destinations\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> This dashboard shows the event delivery and failure metrics only for cloud mode connections. It does not include data for the device mode connections.\n> \n> See [Connection modes](https://www.rudderstack.com/docs/destinations/rudderstack-connection-modes/) for more details on cloud mode and device mode connections.\n\nIn this view, you get a list of all the Event Stream destinations in your workspace with the following details (along with the [change percentage](#change-percentage-calculation)):\n\n*   Events delivered (sortable by count or rate of change)\n*   Failures\n*   Failure rate\n*   P95 latency\n\n[![Event stream destinations overview](https://www.rudderstack.com/docs/images/features/health-dashboard/event-stream-overview.webp)](https://www.rudderstack.com/docs/images/features/health-dashboard/event-stream-overview.webp)\n\nRudderStack provides a toggle to filter your destinations by [Cloud](https://www.rudderstack.com/docs/destinations/streaming-destinations/) and [Warehouse](https://www.rudderstack.com/docs/destinations/warehouse-destinations/). Click the **Failures** tab to view only the destinations that have event failures.\n\n[![Filter toggle for event stream destinations](https://www.rudderstack.com/docs/images/features/health-dashboard/event-stream-toggle.webp)](https://www.rudderstack.com/docs/images/features/health-dashboard/event-stream-toggle.webp)\n\nYou can also filter metrics for only the enabled/disabled destinations by clicking the filter option in the **Destination** column:\n\n[![Filter for enabled/disabled  destinations](https://www.rudderstack.com/docs/images/features/health-dashboard/enabled-disabled-destinations.webp)](https://www.rudderstack.com/docs/images/features/health-dashboard/enabled-disabled-destinations.webp)\n\n### Destination-level event failure metrics\n\nTo get the destination-level data for event failures, click the row. A panel pops up on the right with details on the failed events.\n\n#### **Cloud destinations**\n\nRudderStack provides the following details for the failed events associated with the cloud destination:\n\n*   **Event name**\n*   **Event type** (`identify`, `track`, `page`, etc.)\n*   **Source**\n*   **Count**: Number of failed events.\n*   **Last happened**: When the error last occurred.\n\nClick the event to see a sample failed event payload along with corresponding error details. For more details, click the **View Destination** button on the top right.\n\n[![Event payload and sample error](https://www.rudderstack.com/docs/images/features/health-dashboard/cloud-event-payload-error.webp)](https://www.rudderstack.com/docs/images/features/health-dashboard/cloud-event-payload-error.webp)\n\n#### **Warehouse destinations**\n\nRudderStack provides the following details for the failed events associated with the warehouse destination:\n\n[![Warehouse destination errors](https://www.rudderstack.com/docs/images/features/health-dashboard/warehouse-destination-errors.webp)](https://www.rudderstack.com/docs/images/features/health-dashboard/warehouse-destination-errors.webp)\n\n*   **Staging events**: These correspond to the errors that occur in the staging process (during transformation or object storage, for example) before the syncs actually start. You will see the following details:\n    \n    *   **Event name**\n    *   **Event type** (`identify`, `track`, `page`, etc.)\n    *   **Source**\n    *   **Count**: Number of failed events with the **Event name**.\n    *   **Last happened**: When the error last occurred.\n\nClick the event to see a sample failed event payload along with corresponding error details. For more details, click the **View Destination** button on the top right.\n\n[![Warehouse destination sample error](https://www.rudderstack.com/docs/images/features/health-dashboard/warehouse-destination-sample-error.webp)](https://www.rudderstack.com/docs/images/features/health-dashboard/warehouse-destination-sample-error.webp)\n\n*   **Syncs**: These correspond to the errors that occur during the warehouse syncs. You will see the following details:\n    \n    *   **Error category**\n    *   **Source**\n    *   **Events count**\n    *   **Syncs count**\n    *   **First happened**\n    *   **Last happened**\n    *   **Status**\n\nClick the event to see a sample error. You can also retry syncing the event to the warehouse by clicking the **Retry all** button.\n\n[![Sample error for warehouse syncs](https://www.rudderstack.com/docs/images/features/health-dashboard/warehouse-sync-error.webp)](https://www.rudderstack.com/docs/images/features/health-dashboard/warehouse-sync-error.webp)\n\n### Change percentage calculation\n\nRudderStack calculates the change percentage for the [Event Stream destinations](#event-stream-destinations) as follows:\n\n| Metric | Change percentage equation |\n| --- | --- |\n| Events delivered | (Current period count - Prior period count) / Prior period count \\* 100 |\n| Failures | (Current period count - Prior period count) / Prior period count \\* 100 |\n| Failure rate | Current percentage - Prior percentage |\n\nHere, **period** is the time period by which you want to filter the metrics - one day, one week, or one month.\n\n[![Time period](https://www.rudderstack.com/docs/images/features/health-dashboard/time-period.webp)](https://www.rudderstack.com/docs/images/features/health-dashboard/time-period.webp)\n\n## Reverse ETL connections\n\nIn this view, you get the following information on the latest syncs that are ongoing or completed across each Reverse ETL connection.\n\n*   Source-destination connection\n*   Status of the latest run (In progress, Completed without failures, Completed with failures, or Aborted)\n*   Duration of the sync\n*   Sync start time\n*   Failures (Percentage of deltas (new rows) that failed to sync)\n*   Invalids (Invalid records sent from the source)\n*   Summary of failed or aborted syncs in the selected duration (1 day, 1 week, or 1 month)\n\n[![Reverse ETL tab overview](https://www.rudderstack.com/docs/images/features/health-dashboard/retl-sync-overview.webp)](https://www.rudderstack.com/docs/images/features/health-dashboard/retl-sync-overview.webp)\n\nEach row corresponds to an individual connection with details on the latest sync and a summary of the failed or aborted syncs during the selected time period.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The **Aborted** status code implies an unsuccessful sync due to a number of reasons:\n> \n> *   Sync was aborted or stopped manually.\n> *   RudderStack encountered issues while connecting to the warehouse due to incorrect configuration, changed credentials, or downtime.\n\nHover over the **Failures** column to see percentage of failed deltas (new records since last sync). In the below image, the latest run status is **Completed, with failures** as the deltas failed to sync.\n\n[![Reverse ETL tab overview](https://www.rudderstack.com/docs/images/features/health-dashboard/failures-column.webp)](https://www.rudderstack.com/docs/images/features/health-dashboard/failures-column.webp)\n\nHover over the **Invalids** column to see percentage of invalid records sent from the source. In the below image, the latest run status is **Completed, no failures** as RudderStack did not face any errors or failures while syncing the deltas.\n\n[![Reverse ETL tab overview](https://www.rudderstack.com/docs/images/features/health-dashboard/invalids-column.webp)](https://www.rudderstack.com/docs/images/features/health-dashboard/invalids-column.webp)\n\n### Get sync details\n\nClick a row to get the additional sync-specific details like:\n\n*   Sync type (full/incremental)\n*   Number of rows in source\n*   Number of deltas (new data since last sync)\n*   Invalid records\n\n[![Individual sync details](https://www.rudderstack.com/docs/images/features/health-dashboard/individual-sync-details.webp)](https://www.rudderstack.com/docs/images/features/health-dashboard/individual-sync-details.webp)\n\n## Tracking plans\n\nIn this view, you get a list of all the sources connected to a [tracking plan](https://www.rudderstack.com/docs/data-governance/tracking-plans/) in your workspace with the following details (along with the change percentage):\n\n*   Tracking Plan\n*   Events validated (sortable by count or rate of change)\n*   Violations (sortable by count or rate of change)\n\nRudderStack also provides a **Violations** tab to view only the sources that have tracking plan violations.\n\n[![Tracking plans overview](https://www.rudderstack.com/docs/images/features/health-dashboard/tracking-plan-overview.webp)](https://www.rudderstack.com/docs/images/features/health-dashboard/tracking-plan-overview.webp)\n\n### Validation error details\n\nTo get the validation error details, click the source. A panel pops up on the right with the following details:\n\n*   **Event name**\n*   **Event type** (`identify`, `track`, `page`, etc.)\n*   **Events validated**\n*   **Events dropped**\n*   **Last occurred**: When the error last occurred.\n\nUse the **Version** dropdown to view the above metrics by tracking plan version. This is helpful if your tracking plan has undergone revisions recently.\n\n[![Filter metrics by tracking plan version](https://www.rudderstack.com/docs/images/features/health-dashboard/tracking-plan-version.webp)](https://www.rudderstack.com/docs/images/features/health-dashboard/tracking-plan-version.webp)\n\nClick the event to see the [violation type](https://www.rudderstack.com/docs/data-governance/tracking-plans/#violation-types). You can also click the violation type to see a sample payload and violation description.\n\n[![Tracking plans violation details](https://www.rudderstack.com/docs/images/features/health-dashboard/tracking-plan-violations.webp)](https://www.rudderstack.com/docs/images/features/health-dashboard/tracking-plan-violations.webp)\n\nFor more information on the above metrics and violation types, see the [Tracking plans](https://www.rudderstack.com/docs/data-governance/tracking-plans/#event-details) guide.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Health Dashboard | RudderStack Docs",
    "description": "Monitor status of your data pipelines and tracking plans in RudderStack.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/example/sql-model/",
    "markdown": "# SQL Models | RudderStack Docs\n\nStep-by-step tutorial on how to create a SQL Template model.\n\n* * *\n\n*     6 minute read  \n    \n\nThis guide provides a detailed walkthrough on how to use a PB project and create SQL Template models using custom SQL queries.\n\n## Prerequisites\n\n*   Familiarize yourself with:\n    \n    *   A basic Profile Builder project by following the [Profile Builder CLI](https://www.rudderstack.com/docs/profiles/get-started/profile-builder/) steps.\n    *   [Structure](https://www.rudderstack.com/docs/profiles/cli-user-guide/structure/) of a Profile Builder project and the parameters used in different files.\n\n## Sample project\n\nThe following sections describe how to define your PB project files:\n\n### Project detail\n\nThe [`pb_project.yaml`](https://www.rudderstack.com/docs/profiles/cli-user-guide/structure/#project-details) file defines the project details such as name, schema version, connection name and the entities which represent different identifiers.\n\nYou can define all the identifiers from different input sources you want to stitch together as a single ID (`main_id` in this example):\n\n```\nname: sample_test\nschema_version: 69\nconnection: test\nmodel_folders:\n  - models\nentities:\n  - name: user\n    id_stitcher: models/test_id__\n    id_types:\n      - test_id\n      - exclude_id\nid_types:\n  - name: test_id\n    filters:\n      - type: include\n        regex: \"([0-9a-z])*\"\n      - type: exclude\n        value: \"\"\n  - name: exclude_id\n```\n\n### Input\n\nThe [input file](https://www.rudderstack.com/docs/profiles/cli-user-guide/structure/#inputs) (`models/inputs.yaml`) file includes the input table references and corresponding SQL for the above-mentioned entities:\n\n```\ninputs:\n  - name: tbl_a\n    app_defaults:\n      table: Temp_tbl_a\n    occurred_at_col: insert_ts\n    ids:\n      - select: TRIM(COALESCE(NULL, id1))\n        type: test_id\n        entity: user\n        to_default_stitcher: true\n      - select: \"id2\"\n        type: test_id\n        entity: user\n        to_default_stitcher: true\n      - select: \"id3\"\n        type: exclude_id\n        entity: user\n        to_default_stitcher: true\n  - name: tbl_b\n    app_defaults:\n      view: Temp_view_b\n    occurred_at_col: timestamp\n    ids:\n      - select: \"id1\"\n        type: test_id\n        entity: user\n        to_default_stitcher: true\n      - select: \"id2\"\n        type: test_id\n        entity: user\n        to_default_stitcher: true\n      - select: \"id3\"\n        type: test_id\n        entity: user\n        to_default_stitcher: true\n  - name: tbl_c\n    app_defaults:\n      table: Temp_tbl_c\n    ids:\n      - select: \"id1\"\n        type: test_id\n        entity: user\n        to_default_stitcher: true\n      - select: \"id2\"\n        type: test_id\n        entity: user\n        to_default_stitcher: true\n```\n\n### Model\n\nProfiles **SQL model** lets you write custom SQL queries to achieve advanced use-cases to create desired output tables.\n\nA sample `profiles.yaml` file specifying a `single_sql` type SQL model:\n\n```\nmodels:\n- name: test_sql\n  model_type: sql_template\n  model_spec:\n    validity_time: 24h# 1 day\n    materialization:                 // optional\n      run_type: discrete             // optional [discrete, incremental]\n    single_sql: |\n        {%- with input1 = this.DeRef(\"inputs/tbl_a\") -%}\n          SELECT \n              id1 AS new_id1, \n              id2 AS new_id2, \n              {{input1}}.*\n          FROM {{input1}}\n        {%- endwith -%}        \n    occurred_at_col: insert_ts        // optional\n    ids:\n      - select: \"new_id1\"\n        type: test_id\n        entity: user\n        to_default_stitcher: true\n      - select: \"new_id2\"\n        type: test_id\n        entity: user\n        to_default_stitcher: true\n      - select: \"id3\"\n        type: test_id\n        entity: user\n        to_default_stitcher: true\n```\n\nA sample `profiles.yaml` file specifying a `multi_sql` type SQL model:\n\n```\nmodels:\n- name: test_sql\n    model_type: sql_template\n    model_spec:\n      validity_time: 24h # 1 day\n      materialization:\n        output_type: table\n        run_type: discrete\n      multi_sql: |\n        {% with input_material1 = this.DeRef(\"models/test_sql1\") input_material2 = this.DeRef(\"inputs/tbl_a\") input_material3 = this.DeRef(\"inputs/tbl_c\") %}\n          create {{this.GetMaterialization().OutputType.ToSql()}} {{this}} as (\n            select b.id1, b.id2, b.id3, b.insert_ts, a.new_id1, a.num_a, c.num_b, c.num_c\n            from {{ input_material1 }} a\n            full outer join {{ input_material2 }} b\n            on a.id2 = b.id2\n            full outer join {{ input_material3 }} c\n            on c.id2 = a.id2\n          );\n        {% endwith  %}        \n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> A `multi_sql` type SQL model only creates a table as an output type in a warehouse whereas `single_sql` type SQL model supports all the output types (deafult is `ephemeral`). See [materialization](https://www.rudderstack.com/docs/profiles/resources/glossary/#materialization) for more information.\n\n##### Model specification fields\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `name` | String | Name of the SQL model. You can also refer this as an input as `models/test_sql`. |\n| `model_type` | String | Defines the type of model. |\n| `model_spec` | Object | Contains the specifications for the target model. |\n| `validity_time` | Time | Time Specifies the validity of the model with respect to its timestamp. For example, a model run as part of a scheduled nightly job for 2009-10-23 00:00:00 UTC with `validity_time`: `24h` would still be considered potentially valid and usable for any run requests, which do not require precise timestamps between 2009-10-23 00:00:00 UTC and 2009-10-24 00:00:00 UTC. This specifies the validity of generated feature table. Once the validity is expired, scheduling takes care of generating new tables. For example: 24h for 24 hours, 30m for 30 minutes, 3d for 3 days. |\n| `materialization` | List | Adds the key `run_type`: `incremental` to run the project in incremental mode. This mode considers row inserts and updates from the edge\\_sources input. These are inferred by checking the timestamp column for the next run. One can provide buffer time to consider any lag in data in the warehouse for the next incremental run like if new rows are added during the time of its run. If you do not specify this key then it’ll default to `run_type`: `discrete`. |\n| `single_sql` | List | Specifies the SQL template which must evaluate to a single SELECT SQL statement. After execution, it should produce a dataset which will materialize based on the provided materialization. |\n| `multi-sql` | List | Specifies the SQL template which can evaluate to multiple SQL statements. One of these SQL statements (typically the last one) must be a CREATE statement which shall be responsible for materializing the model into a table.<br><br>**Note**: You should set only one of `single_sql` or `multi_sql`. |\n| `occurred_at_col` | List | Name of the column which contains the timestamp value in the output of SQL template. |\n| `ids` | List | Specifies the list of all IDs present in the source table along with their column names (or column SQL expressions). It is required in case you want to use SQL models as an input to the `input_var` or `entity_var` fields. |\n\n## SQL template\n\nYou can pass custom SQL queries to the `single_sql` or `multi_sql` fields, which is also known as a **SQL template**. It provides the flexibility to write custom SQL by refering to any of the input sources listed in the `inputs.yaml` or any model listed in `models/profiles.yaml`.\n\nThe SQL templates follow a set query syntax which serves the purpose of creating a model. Follow the below rules to write SQL templates:\n\n*   Write SQL templates in the [pongo2 template engine](https://pkg.go.dev/github.com/flosch/pongo2#readme-first-impression-of-a-template) syntax.\n*   Avoid circular referencing while referencing the models. For example, `sql_model_a` references `sql_model_b` and `sql_model_b` references `sql_model_a`.\n*   Use `timestamp` variable (refers to the start time of the current run) to filter new events.\n*   `this` refers to the current model’s material. You can use the following methods to access the material properties available for `this`:\n    *   `DeRef(\"path/to/model\")`: Use this syntax `{{ this.DeRef(\"path/to/model\") }}` to refer to any model and return a database object corresponding to that model. The database object, in return, gives the actual name of the table/view in the warehouse. Then, generate the output, for example:\n\n```\n{% with input_table = this.DeRef(\"inputs/tbl_a\") %}\n    SELECT\n        t.a AS new_a,\n        t.b AS new_b,\n        t.*\n    FROM {{input_table}} AS t\n{% endwith %}\n```\n\n*   `GetMaterialization()`: Returns a structure with two fields: `MaterializationSpec{OutputType, RunType}`.\n    *   `OutputType`: You must use `OutputType` with `ToSQL()` method:  \n        For example, `CREATE OR REPLACE {{this.GetMaterialization().OutputType.ToSQL()}} {{this.GetSelectTargetSQL()}} AS ...`\n    *   `RunType`: For example, `this.GetMaterialization().RunType`\n\n## Refer SQL contents from another file\n\nIf you want to edit a SQL query in a text editor and not as a field in a YAML file, you can use the `ReadFile` method. It refers to the SQL contents stored in another file:\n\n```\nmodels:\n- name: example_sql_model\n  model_type: sql_template\n  model_spec:\n    validity_time: 24h # 1 day\n    materialization:\n      output_type: view\n      run_type: discrete\n    single_sql: \"{{this.ReadFile('models/compute.sql')}}\" # for a SQL file named compute.sql in the models folder\n    occurred_at_col: insert_ts\n```\n\n## See Also\n\nCreate user features using SQL models:\n\n*   [Profiles Stripe features project](https://github.com/rudderlabs/pb_sample_features)\n*   [Profiles Shopify features project](https://github.com/rudderlabs/profiles-shopify-features)\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "SQL Models | RudderStack Docs",
    "description": "Step-by-step tutorial on how to create a SQL Template model.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/data-governance/consent-management/",
    "markdown": "# Consent Management | RudderStack Docs\n\nIntegrate RudderStack with popular consent management platforms.\n\n* * *\n\n*     less than a minute  \n    \n\nObtaining user consent poses a significant challenges, not only during the initial data collection but also in the subsequent distribution of user preferences to various tools within the customer data stack.\n\nTo overcome these challenges, RudderStack offers a fully-integrated consent solution that works with popular consent management tools like OneTrust, along with other custom-built systems.\n\nRudderStack’s holistic approach to consent management lets you:\n\n*   Implement both client-side and server-side consent categorization for each downstream integration.\n*   Be fully compliant with the internal requirements and region-specific regulatory laws on a tool-by-tool basis, while simplifying implementation.\n*   Control fully-configurable cookie and storage settings, in which you can map each downstream integration to specific consent categories.\n\n### Pre-consent user tracking\n\nRudderStack’s consent management feature enables you to set the pre-consent SDK behavior - either tracking users as fully anonymous, tracking only their sessions, or tracking with `anonymousId` as the user identifier. This minimizes any data loss related to attribution, acquisition, and the overall user journey.\n\n## Consent integrations\n\nRudderStack supports full integrations with the following consent management platforms:\n\n*   [OneTrust](https://www.rudderstack.com/docs/data-governance/consent-management/onetrust/)\n*   [Ketch](https://www.rudderstack.com/docs/data-governance/consent-management/ketch/)\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Consent Management | RudderStack Docs",
    "description": "Integrate RudderStack with popular consent management platforms.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/data-governance/tracking-plans/",
    "markdown": "# Tracking Plans | RudderStack Docs\n\nMonitor your event data with RudderStack tracking plans.\n\nAvailable Plans\n\n*   growth\n*   enterprise\n\n* * *\n\n*     14 minute read  \n    \n\nTracking plans let you proactively monitor and act on non-compliant event data coming into your RudderStack sources based on predefined plans. This can help you prevent or de-risk situations where any missing or improperly configured event data can break your downstream destinations.\n\n## Features\n\n*   Set rules for `track` and non-`track` events (`identify`, `page`, `screen`, and `group`) that you want to send to downstream destinations. You can use these rules to:\n    \n    *   Define which events should pass through, including events with and without properties.\n    *   Specify whether a property or attribute is required and assign the data type required to pass that event.\n*   Use the [Event Audit API](https://www.rudderstack.com/docs/api/event-audit-api/) to evaluate your inbound events and metadata and compare them with your tracking plans.\n    \n*   You can iteratively improve your tracking plans and have better control of your data with a robust versioning system.\n    \n*   Create and manage your tracking plans in the RudderStack dashboard or programmatically using the [Data Catalog API](https://www.rudderstack.com/docs/api/data-catalog-api/).\n    \n\n## Create tracking plan\n\nRudderStack provides you with the following options to create tracking plans:\n\n### Pull from source\n\nYou can create a tracking plan from an existing event data source. This option leverages the [Event Audit API](https://www.rudderstack.com/docs/api/event-audit-api/) to import the events and properties tracked by the event data source and generates an initial plan.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Before you proceed, make sure the **Event Audit API** setting is turned on in your [RudderStack dashboard](https://app.rudderstack.com/).\n> \n> Go to **Settings** > **Workspace** and click the **Data Management** tab. Scroll down to the **Data governance** section and turn on the **Event Audit API** toggle.\n> \n> ![Event Audit API setting in RudderStack dashboard](https://www.rudderstack.com/docs/images/api/event-audit-api-dashboard.webp)\n> \n> See [Enable Event Audit API](https://www.rudderstack.com/docs/api/event-audit-api/#enable-event-audit-api) section for more information.\n\n1.  Log in to the [RudderStack dashboard](https://app.rudderstack.com/) and go to **Collect** > **Tracking Plans** option in the left sidebar.\n2.  Click **Create tracking plan**.\n\n[![Create blank tracking plan](https://www.rudderstack.com/docs/images/data-governance/blank-tracking-plan.webp)](https://www.rudderstack.com/docs/images/data-governance/blank-tracking-plan.webp)\n\n3.  Select **Pull from source** on the next screen.\n\n[![Create blank tracking plan](https://www.rudderstack.com/docs/images/data-governance/pull-from-source.webp)](https://www.rudderstack.com/docs/images/data-governance/pull-from-source.webp)\n\n4.  Select the event stream source from which you want to import the tracked events and properties and click **Continue**.\n5.  Enter a unique name and description for your tracking plan and click **Continue**.\n6.  Select events tracked from the source and click **Continue**.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Note that:\n> \n> *   The events and properties listed here are obtained from the [Event Audit API](https://www.rudderstack.com/docs/api/event-audit-api/).\n> *   RudderStack automatically adds these events and properties to the [data catalog](https://www.rudderstack.com/docs/data-governance/data-catalog/) if they do not exist already.\n\n[![Select events for the tracking plan](https://www.rudderstack.com/docs/images/data-governance/pull-from-source-select-events.webp)](https://www.rudderstack.com/docs/images/data-governance/pull-from-source-select-events.webp)\n\n7.  In the **Map properties to events** section, RudderStack displays the list of tracked events selected in the above step with the associated properties.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> RudderStack supports defining complex nested properties for an event in your tracking plan. Based on the schema sampled from the incoming events, RudderStack shows up to **three levels** of nesting for a property of object or array data type.\n> \n> See [Nested properties for tracking plans created from source](#use-case-for-tracking-plan-created-from-source) for more information.\n\n[![Map properties for the tracking plan](https://www.rudderstack.com/docs/images/data-governance/event-property-mapping-source.webp)](https://www.rudderstack.com/docs/images/data-governance/event-property-mapping-source.webp)\n\n8.  You can add more properties from the data catalog by going to the **Add properties** tab and clicking the **Add** button next to the property you want to add. To mark the property as optional or required, click the **Optional**/**Required** option.\n\n[![Add properties for the events](https://www.rudderstack.com/docs/images/data-governance/event-property-mapping-source-1.webp)](https://www.rudderstack.com/docs/images/data-governance/event-property-mapping-source-1.webp)\n\nIn addition, you can:\n\n*   Remove an event from the tracking plan.\n*   Configure the event settings to allow unplanned properties.\n*   Add properties from the data catalog.\n*   Remove specific properties from the event.\n\n[![Tracking plan template map properties](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-template-map-properties.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-template-map-properties.webp)\n\n9.  Select the sources you want to connect to the tracking plan and click **Continue**.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> You can connect multiple sources to a tracking plan. However, you can connect a source to **only** one tracking plan at a given point.\n\n10.  Configure the tracking plan settings for specific event types and click **Create Tracking Plan**.\n\n[![Create Tracking plan](https://www.rudderstack.com/docs/images/data-governance/create-tracking-plan-settings.webp)](https://www.rudderstack.com/docs/images/data-governance/create-tracking-plan-settings.webp)\n\n11.  (**Optional**) Use [RudderTyper](https://www.rudderstack.com/docs/data-governance/tracking-plans/ruddertyper/) for autocomplete and linting.\n\n### Use tracking plan template\n\nUse this option to import your event and property mappings from a default RudderStack template:\n\n1.  Log in to the [RudderStack dashboard](https://app.rudderstack.com/) and go to **Collect** > **Tracking Plans** option in the left sidebar.\n2.  Click **Create tracking plan**.\n\n[![Create blank tracking plan](https://www.rudderstack.com/docs/images/data-governance/blank-tracking-plan.webp)](https://www.rudderstack.com/docs/images/data-governance/blank-tracking-plan.webp)\n\n3.  Click **Use template**.\n\n[![Create blank tracking plan](https://www.rudderstack.com/docs/images/data-governance/pull-from-source.webp)](https://www.rudderstack.com/docs/images/data-governance/pull-from-source.webp)\n\n4.  Select the default RudderStack template and click **Continue**.\n    \n5.  Add a tracking plan name and description and click **Continue**.\n    \n6.  Map the properties to your events for creating the tracking plan. In addition, you can:\n    \n    *   Remove an event from the tracking plan.\n    *   Configure the event settings to allow unplanned properties.\n    *   Add properties from the data catalog.\n    *   Remove specific properties from the event.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> RudderStack supports defining complex [nested properties](#nested-event-properties) for an event in your tracking plan. You can add up to three levels of nesting for a property of object or array data type.\n\n[![Tracking plan template map properties](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-template-map-properties.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-template-map-properties.webp)\n\n7.  Connect the tracking plan to the sources.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> You can connect multiple sources to a tracking plan. However, you can connect a source to **only** one tracking plan at a given point.\n\n8.  Configure the tracking plan settings for specific event types and click **Create Tracking Plan**.\n\n[![Create Tracking plan](https://www.rudderstack.com/docs/images/data-governance/create-tracking-plan-settings.webp)](https://www.rudderstack.com/docs/images/data-governance/create-tracking-plan-settings.webp)\n\n### From data catalog\n\nYou can create a tracking plan from scratch using the events and properties defined in the [Data Catalog](https://www.rudderstack.com/docs/data-governance/data-catalog/) section:\n\n1.  Log in to the [RudderStack dashboard](https://app.rudderstack.com/) and go to **Collect** > **Tracking Plans** option in the left sidebar.\n2.  Click **Create tracking plan**.\n\n[![Create blank tracking plan](https://www.rudderstack.com/docs/images/data-governance/blank-tracking-plan.webp)](https://www.rudderstack.com/docs/images/data-governance/blank-tracking-plan.webp)\n\n3.  Select **From data catalog** on the next screen.\n\n[![Create blank tracking plan from data catalog](https://www.rudderstack.com/docs/images/data-governance/pull-from-source.webp)](https://www.rudderstack.com/docs/images/data-governance/pull-from-source.webp)\n\n4.  Enter a unique name and description for your tracking plan.\n5.  Choose the required events from the displayed events list (populated from [Data Catalog](https://www.rudderstack.com/docs/data-governance/data-catalog/)) and click **Continue**.\n\n[![Select events for tracking plan](https://www.rudderstack.com/docs/images/data-governance/select-events-new.webp)](https://www.rudderstack.com/docs/images/data-governance/select-events-new.webp)\n\n6.  In the **Map properties to events** section, add properties (populated from [Data Catalog](https://www.rudderstack.com/docs/data-governance/data-catalog/)) to map to each event by clicking the **Add properties** button.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> RudderStack supports defining complex [nested properties](#nested-event-properties) for an event in your tracking plan. You can add up to three levels of nesting for a property of object or array data type.\n\n[![Create blank tracking plan](https://www.rudderstack.com/docs/images/data-governance/event-property-mapping-new.webp)](https://www.rudderstack.com/docs/images/data-governance/event-property-mapping-new.webp)\n\n7.  Click the **Add** button next to the property you want to add. To mark the property as optional or required, click the **Optional**/**Required** option.\n\n[![Add properties for the events](https://www.rudderstack.com/docs/images/data-governance/event-property-mapping-source-1.webp)](https://www.rudderstack.com/docs/images/data-governance/event-property-mapping-source-1.webp)\n\nIn addition, you can:\n\n*   Remove an event from the tracking plan.\n*   Configure the event settings to allow unplanned properties.\n*   Add properties from the data catalog.\n*   Remove specific properties from the event.\n\n[![Tracking plan template map properties](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-template-map-properties.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-template-map-properties.webp)\n\n8.  Select the sources you want to connect to the tracking plan and click **Continue**.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> You can connect multiple sources to a tracking plan. However, you can connect a source to **only** one tracking plan at a given point.\n\n9.  Configure the tracking plan settings for specific event types and click **Create Tracking Plan**.\n\n[![Create Tracking plan](https://www.rudderstack.com/docs/images/data-governance/create-tracking-plan-settings.webp)](https://www.rudderstack.com/docs/images/data-governance/create-tracking-plan-settings.webp)\n\n10.  (**Optional**) Use [RudderTyper](https://www.rudderstack.com/docs/data-governance/tracking-plans/ruddertyper/) for autocomplete and linting.\n\n### Data Catalog API\n\nYou can also use the [Data Catalog API](https://www.rudderstack.com/docs/api/data-catalog-api/) to create and manage your tracking plans programmatically.\n\n## View tracking plans\n\nTo see all the tracking plans associated with your workspace, go to **Collect** > **Tracking Plans**. In this view, you get all the tracking plan-related details like name, description, last modified, tracking plan creation method, connected sources, etc.\n\n[![Tracking Plan list](https://www.rudderstack.com/docs/images/data-governance/view-tracking-plans.webp)](https://www.rudderstack.com/docs/images/data-governance/view-tracking-plans.webp)\n\nThe following table lists the different ways of creating a tracking plan:\n\n| Creation type | Description |\n| --- | --- |\n| Migrated | Tracking plan was [migrated](#migrate-tracking-plans) from the old to new format. |\n| Template | Created using the [default template](#use-tracking-plan-template). |\n| Data Catalog | Created using the [data catalog](#from-data-catalog). |\n| Pull from source | Created from the source events and properties collected via the [Event Audit API](#pull-from-source). |\n| Data Catalog API | Created using the [Data Catalog API](https://www.rudderstack.com/docs/api/data-catalog-api/). |\n| Google sheet/Tracking plan API | Created from the [tracking plan spreadsheet](https://www.rudderstack.com/docs/data-governance/tracking-plans/tracking-plan-spreadsheet/). |\n\n### Tracking plan details\n\nClick a tracking plan to view the following details:\n\n*   **Overview**: Displays the list of events and properties associated with the tracking plan. You can edit these by clicking the **Edit** button.\n\n[![Tracking Plan tabs](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-tabs-new.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-tabs-new.webp)\n\n*   **Sources**: Displays the source(s) connected to the tracking plan. You can view the source details, edit source settings, and disconnect the source from tracking plan by clicking the meatballs menu next to the source.\n*   **Settings**: Lets you edit the name of the tracking plan or delete the tracking plan (only if not connected to any source).\n*   **Activity**: Lets you view all the activities performed on the tracking plan like events/properties added, removed, or updated etc. along with the user who performed that action.\n\n[![Tracking Plan Activity tab](https://www.rudderstack.com/docs/images/data-governance/activity-tab.webp)](https://www.rudderstack.com/docs/images/data-governance/activity-tab.webp)\n\n## Migrate tracking plans\n\nRudderStack lets you easily migrate your tracking plans created using the [Tracking Plan Spreadsheet](https://www.rudderstack.com/docs/data-governance/tracking-plans/tracking-plan-spreadsheet/) to the new format where you can edit events, properties, and tracking plan rules in the dashboard. You will see the **Migration now available** banner below these tracking plans:\n\n[![Tracking Plan migration banner](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-migration-banner.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-migration-banner.webp)\n\nGo to the tracking plan and click **Migrate** to start the migration process.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Note that:\n> \n> *   You must have [Admin](https://www.rudderstack.com/docs/dashboard-guides/user-management/#organization-roles) privileges to migrate tracking plans successfully.\n> *   Make sure to see the [Migration considerations](#considerations) section before you migrate your old tracking plans.\n\n[![Tracking Plan migration process](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-migration-process.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-migration-process.webp)\n\nOnce the tracking plan is migrated successfully, you can view all the events and properties in the dashboard, and [make changes](#edit-tracking-plans) as required.\n\n[![Tracking Plan migration success](https://www.rudderstack.com/docs/images/data-governance/migrated-tracking-plan.webp)](https://www.rudderstack.com/docs/images/data-governance/migrated-tracking-plan.webp)\n\n### Considerations\n\n*   Once you migrate, note that:\n    \n    *   RudderStack deletes the old tracking plan.\n    *   You **cannot** use the spreadsheet to view or manage the newly created tracking plan.\n    *   You can manage your tracking plans via the dashboard or the [Data Catalog API](https://www.rudderstack.com/docs/api/data-catalog-api/).\n*   You will **not see** the historical violations or event counts once you migrate your tracking plan to the new format in the dashboard.\n    \n*   RudderStack supports up to [three levels of nesting](#nested-event-properties) in the event properties of object or array data type. The tracking plan **cannot** be migrated if one or more of your event mappings have more than three levels of nesting and you will see the following error:\n    \n\n![Tracking Plan migration error](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-migration-error.webp)\n\n*   RudderStack does not permit certain [keywords](#advanced-keywords) as names of the event properties. You will encounter an error during migration if your tracking plan rules have these names.\n\n![Tracking Plan migration error because of advanced keywords](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-migration-error-keywords.webp)\n\n## Edit tracking plans\n\nGo to **Collect** > **Tracking Plans** to see all the tracking plans in your workspace. To edit a tracking plan, select a tracking plan and click **Edit**.\n\n[![Edit Tracking Plan](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-edit.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-edit.webp)\n\nHere, you can:\n\n*   Add or remove events and properties from the tracking plan.\n*   Mark properties as required or optional.\n*   Define [how the information is captured in your events](#event-structure-for-tracking-plans).\n*   Specify if the tracking plan should allow unplanned properties for a specific event.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> You cannot change an event type. To do so, delete the event from the data catalog and [create a new event](https://www.rudderstack.com/docs/data-governance/data-catalog/#add-event).\n\n[![Edit tracking plan](https://www.rudderstack.com/docs/images/data-governance/edit-tracking-plan.webp)](https://www.rudderstack.com/docs/images/data-governance/edit-tracking-plan.webp)\n\nClick **Save** to update the tracking plan configuration.\n\n### Event structure for tracking plans\n\nRudderStack applies the tracking plan validation on the following objects by default:\n\n*   `properties` object for `track`, `screen`, and `page` events.\n*   `traits` object for `identify` and `group` events.\n\nIf you are instrumenting your events such that the relevant information is captured in the `traits` or `context.traits` object, make sure to select the relevant option from the **Identity Applied** dropdown.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> This dropdown is only available for the `identify`, `page`, `screen` and `group` events.\n\n[![Identify validation for traits object](https://www.rudderstack.com/docs/images/data-governance/identify-options-new.webp)](https://www.rudderstack.com/docs/images/data-governance/identify-options-new.webp)\n\n### Nested event properties\n\nRudderStack supports defining complex nested properties for an event in your tracking plan, allowing you to validate complex data structures in your inbound events and metadata.\n\nTo nest event properties while [editing your tracking plan](#edit-tracking-plans):\n\n1.  Click **Add properties** and choose an event property of the object or array data type from the right sidebar. Once added, you should see a **+** sign next to it.\n2.  Click the newly added property.\n3.  Choose the event property to nest.\n\n[![Nested event properties](https://www.rudderstack.com/docs/images/data-governance/nested-properties.webp)](https://www.rudderstack.com/docs/images/data-governance/nested-properties.webp)\n\nNote that:\n\n*   You can nest properties only within a property of object or array data type.\n*   RudderStack supports up to **three levels** of nested properties within an event property.\n*   If not explicitly declared, RudderStack allows all data types for a property by default. However, it **does not** support nesting for that property.\n*   Removing the parent property from the tracking plan automatically removes all the nested properties.\n*   You **cannot** nest properties within a property having both array and object data types. An example of such a property is shown:\n\n[![Nested event properties](https://www.rudderstack.com/docs/images/data-governance/nested-properties-restriction.webp)](https://www.rudderstack.com/docs/images/data-governance/nested-properties-restriction.webp)\n\n#### Use case for tracking plan created from source\n\nFor tracking plans created using the [Pull from source](#pull-from-source) option, RudderStack populates the events and properties based on the schema sampled from your incoming events. You can define up to three levels of nesting within an event property of object or array data type.\n\nFor example, consider the following event payload:\n\n```\n{\n  \"type\": \"track\",\n  \"event\": \"Product Viewed\",\n\n  ...\n\n  \"properties\": {\n    \"products\": [{\n        \"name\": \"Product 1\",\n        \"product_id\": \"a123\"\n      },\n      {\n        \"name\": \"Product 2\",\n        \"product_id\": \"a124\"\n      }\n    ],\n    \"filters\": {\n      \"value\": {\n        \"price\": {\n          \"max\": 10000\n        },\n        \"rating\": {\n          \"max\": 5,\n          \"votes\": {\n            \"min\": 1000\n          }\n        }\n      }\n    },\n  },\n  ...\n}\n```\n\nUpon importing the above event in your tracking plan, you see the following nested properties within the `filters` and `products` properties:\n\n[![Map properties for the tracking plan](https://www.rudderstack.com/docs/images/data-governance/event-property-mapping-add-property.webp)](https://www.rudderstack.com/docs/images/data-governance/event-property-mapping-add-property.webp)\n\nIn the above example, RudderStack does not show the property `min` nested within `votes` as it exceeds the third level of nesting.\n\n## Source-specific settings\n\nGo to the source connected to the tracking plan to see the following settings in the **Tracking Plans** tab:\n\n[![Unlink tracking plan from source](https://www.rudderstack.com/docs/images/data-governance/manage-tracking-plan.webp)](https://www.rudderstack.com/docs/images/data-governance/manage-tracking-plan.webp)\n\n*   **Unlink Tracking Plan**: Lets you unlink the tracking plan from your source.\n    \n*   **Previously linked tracking plans**: Lets you view the previously linked tracking plans for a source (in the last 30 days).\n    \n*   **Tracking plan settings**: Lets you edit the following tracking plan settings for each event type for the connected source. Once done, click **Save Settings** for the changes to take effect:\n    \n    *   **Drop events with unplanned event names**: When toggled on, RudderStack drops all events that do not match the predefined event names in the tracking plan (only applicable for `track` events).\n    *   **Drop events with unplanned event properties**: When turned on, RudderStack drops all events that contain properties not matching the list of predefined properties for the specific event.\n    *   **Drop events with other violations**: When toggled on, RudderStack drops all events with violations that include Type Mismatch, Required Fields Missing, and others outlined in the [Violation types](#violation-types) section.\n    *   **Propagate errors**: When turned on, RudderStack captures the validation errors in the event’s `context` object and sends them downstream (user transformations, destinations), depending on your use-case. If toggled off, RudderStack drops the event containing the validation errors. It is recommended to keep this setting toggled on as it helps you assess the performance of your tracking plans.\n\n## Observability\n\nRudderStack gives you complete visibility into the events passing through a tracking plan and details on the tracking plan violations, that is, events that do not comply with the tracking plan rules.\n\nTo see these metrics, click the **Events** tab of the source connected to your tracking plan.\n\n[![Tracking plan observability](https://www.rudderstack.com/docs/images/data-governance/tracking-plans-observability.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plans-observability.webp)\n\n#### Events ingested\n\nThis section shows the tracking plan currently linked to your source and the following details:\n\n*   **Total events**: Captures all events that pass through the source.\n*   **Events validated**: Number of events validated by the tracking plan.\n*   **Events with violations**: Number of events that do not comply with the tracking plan rules.\n*   **Events dropped**: Number of events dropped due to tracking plan violations.\n\nYou can see these metrics for all tracking plans connected to that source and filter them by version and time period (past one day, seven days, or 30 days).\n\n[![Events ingested section](https://www.rudderstack.com/docs/images/data-governance/tracking-plans-observability-1.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plans-observability-1.webp)\n\n#### Event flow\n\nThis section gives a graphical overview of all the events ingested per day over the specified period and the number of events with violations.\n\n[![Event flow section](https://www.rudderstack.com/docs/images/data-governance/tracking-plans-observability-2.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plans-observability-2.webp)\n\n#### Event details\n\nClick the **Events** tab to see all the event-related metrics like:\n\n*   **Event name**\n*   **Count**: Number of events validated by the tracking plan according to filter set in [Events ingested](#events-ingested).\n*   **Last seen**: Number of days since the last observed violation.\n\n[![Events tab](https://www.rudderstack.com/docs/images/data-governance/tracking-plans-observability-3.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plans-observability-3.webp)\n\nClick the **Violations** tab to see the following metrics:\n\n[![Violations tab](https://www.rudderstack.com/docs/images/data-governance/tracking-plans-observability-4.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plans-observability-4.webp)\n\n*   **Event name**\n*   **Event type**: Type of event (`identify`, `track`, `group`, `page`, or `screen`).\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Tracking plans do not validate `alias` events. If you send any `alias` events, they are shown in this view and returned as is without validation.\n\n*   **Events validated**: Number of events validated by the tracking plan according to filter set in [Events ingested](#events-ingested).\n*   **Events with violations**: Number of events that did not comply with the tracking plan rules.\n*   **Events dropped**: Number of events that were not allowed to flow through.\n*   **Last occurred**: Date and time of the last observed violation.\n\nYou can also click on an event to view the [violation type](#violation-types) and individual metrics.\n\n[![Tracking plan observability for individual event](https://www.rudderstack.com/docs/images/data-governance/tracking-plans-observability-5.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plans-observability-5.webp)\n\nClick the **View** option for more details, like the violation description and sample payload for the violation.\n\n[![Violation description](https://www.rudderstack.com/docs/images/data-governance/tracking-plans-observability-6.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plans-observability-6.webp)\n\n## Violation types\n\n| Violation type | Description |\n| --- | --- |\n| `Unplanned-Event` | Event is not defined in the tracking plan. |\n| `Required-Missing` | Properties defined as **Required** are missing in the event. |\n| `Datatype-Mismatch` | Data type of the event property does not match the **Property Type** defined in the tracking plan. |\n| `Additional-Properties` | Occurs if:<br><br>*   **Additional Properties** field in the tracking plan is set to `False`.<br>*   New event properties are received that are not defined in the tracking plan. |\n| `Unknown-Violation` | Any other violation. |\n\n## FAQ\n\n#### Which RudderStack Cloud plans support the tracking plans feature?\n\nThe tracking plans feature is supported in the RudderStack Cloud [Growth and Enterprise](https://rudderstack.com/pricing/) plans.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Although you can create unlimited tracking plans, you can have only five [source-tracking plan connections](#link-tracking-plan-to-source) in the RudderStack Cloud [Growth](https://www.rudderstack.com/pricing/) plan.\n> \n> To remove this restriction, upgrade to the [Enterprise](https://www.rudderstack.com/enterprise-quote/) plan.\n\n#### Which calls are supported by the tracking plans?\n\nThe tracking plans support [`identify`](https://www.rudderstack.com/docs/event-spec/standard-events/identify/), [`track`](https://www.rudderstack.com/docs/event-spec/standard-events/track/), [`page`](https://www.rudderstack.com/docs/event-spec/standard-events/page/), [`screen`](https://www.rudderstack.com/docs/event-spec/standard-events/screen/), and [`group`](https://www.rudderstack.com/docs/event-spec/standard-events/group/) events.\n\nNote that the [`alias`](https://www.rudderstack.com/docs/event-spec/standard-events/alias/) call is not supported.\n\nRudderStack propagates any context related to the tracking plan violations to your destinations. You can use this context in your [transformations](https://www.rudderstack.com/docs/transformations/overview/) for filtering or modifying the events before they reach the destination.\n\n#### Which keywords are not supported while migrating the tracking plan to the new format in the dashboard?\n\nWhile migrating your tracking plans to the new format, you will encounter an error if your tracking plan rules contain any of the following advanced keywords as event property names:\n\n*   `oneOf` / `allOf`\n*   `pattern`\n*   `multipleOf`\n*   `enum`\n*   `minimum` / `maximum`\n*   `if` / `then` / `else`\n*   `$def` / `$ref`\n*   `const`\n*   `default`\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Tracking Plans | RudderStack Docs",
    "description": "Monitor your event data with RudderStack tracking plans.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/example/predictive-features-snowflake/prerequisite/",
    "markdown": "# Prerequisites | RudderStack Docs\n\nPrerequisites to generate predictive features in Snowflake using RudderStack Predictions\n\n* * *\n\n*     8 minute read  \n    \n\nTo follow this guide, you will need access to both RudderStack and Snowflake. If you do not have access, follow these links to create a free [RudderStack account](https://app.rudderstack.com/signup?type=freetrial) and [Snowflake account](https://signup.snowflake.com/).\n\nOnce you set up your RudderStack account, [reach out to our support team](mailto:support@rudderstack.com?subject=I%20would%20like%20access%20to%20your%20Predictions%20feature) to request access to our Predictions feature.\n\n## Set up Snowflake for Event Stream data\n\nBecause Predictions is designed to run in a production environment, you need to perform some basic set up in Snowflake (and later, your RudderStack workspace) to simulate the pipelines you would run when collecting user event data.\n\n### Create a new role and user in Snowflake\n\nIn your Snowflake console, run the following commands to create the role `QUICKSTART`.\n\nVerify the role `QUICKSTART` was successfully created.\n\nCreate a new user QUICKSTART\\_USER with a password `<strong_unique_password>`.\n\n```\nCREATE USER QUICKSTART_USER PASSWORD = '<strong_unique_password>' DEFAULT_ROLE = 'QUICKSTART';\n```\n\nVerify the user `QUICKSTART_USER` was successfully created.\n\n### Create RudderStack schema and grant permissions to role\n\nCreate a dedicated schema `_RUDDERSTACK` in your database.\n\n**Replace `<YOUR_DATABASE>` in all queries with your actual database name.**\n\n```\nCREATE SCHEMA \"<YOUR_DATABASE>\".\"_RUDDERSTACK\";\n```\n\nGrant full access to the schema \\_RUDDERSTACK for the previously created role `QUICKSTART`.\n\n```\nGRANT ALL PRIVILEGES ON SCHEMA \"<YOUR_DATABASE>\".\"_RUDDERSTACK\" TO ROLE QUICKSTART;\n```\n\n### Grant permissions on the warehouse, database, schema, and table\n\nEnable the user `QUICKSTART_USER` to perform all operations allowed for the role `QUICKSTART` (via the privileges granted to it).\n\n```\nGRANT ROLE QUICKSTART TO USER QUICKSTART_USER;\n```\n\nRun the following commands to allow the role `QUICKSTART` to look up the objects within your warehouse, database, schema, and the specific table or view:\n\n```\nGRANT USAGE ON WAREHOUSE \"<YOUR_WAREHOUSE>\" TO ROLE QUICKSTART;\nGRANT USAGE ON DATABASE \"<YOUR_DATABASE>\" TO ROLE QUICKSTART;\nGRANT USAGE ON SCHEMA \"<YOUR_DATABASE>\".\"_RUDDERSTACK\" TO ROLE QUICKSTART;\nGRANT SELECT ON ALL TABLES IN SCHEMA \"<YOUR_DATABASE>\".\"_RUDDERSTACK\" TO ROLE  QUICKSTART;\nGRANT SELECT ON FUTURE TABLES IN SCHEMA \"<YOUR_DATABASE>\".\"_RUDDERSTACK\" TO ROLE QUICKSTART;\nGRANT SELECT ON ALL VIEWS IN SCHEMA \"<YOUR_DATABASE>\".\"_RUDDERSTACK\" TO ROLE QUICKSTART;\nGRANT SELECT ON FUTURE VIEWS IN SCHEMA \"<YOUR_DATABASE>\".\"_RUDDERSTACK\" TO ROLE QUICKSTART;\n```\n\n**Replace `<YOUR_DATABASE>` with the exact Snowflake database name.**\n\n## Import RudderStack event data from the Snowflake marketplace\n\nTo set up automated features, you will need the RudderStack event data in your Snowflake warehouse. If you already use RudderStack and have the following tables and fields (see below), skip to the [Profiles Schema and Permissions](#profiles-schema-and-permissions) section. For this guide, using the provided sample data is recommended.\n\n*   `TRACKS`\n*   `IDENTIFIES`\n    *   `user_id`\n    *   `anonymous_id`\n    *   `email`\n*   `PAGES`\n*   `ORDER_COMPLETED`\n\n**NOTE:** You must have all the three identity types in your `INDENTIFIES` table. If you are using your own data and don’t normally track email, you can send the following `identify` call to add the column:\n\n```\nrudderanalytics.identify('userId', {\n    email:'email@address.com',\n    name:'name'\n})\n```\n\n### Get sample data\n\nIf you are setting up RudderStack for the first time go to the [Snowflake Marketplace](https://app.snowflake.com/marketplace/listing/GZT0Z856CMJ/rudderstack-inc-rudderstack-event-data-for-quickstart) and add RudderStack Event Data for Quickstart to your Snowflake account for free. This will add a database with the needed tables to your Snowflake warehouse with no additional storage cost for you.\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/Snowflake-marketplace.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/Snowflake-marketplace.webp)\n\nAt the next screen, open **Options** and add role `QUICKSTART` to have access to this database.\n\n### Create schema for sample data\n\nThe database with the sample data is read-only so you will need to copy it to a new schema to be able to create a valid event stream pipeline (and run a Predictions job on the data).\n\nCreate a new schema in the database you already set up. Name the schema “EVENTS”.\n\n```\nCREATE SCHEMA \"<YOUR_DATABASE>\".\"EVENTS\";\n```\n\nGive permission to the `QUICKSTART` role to create new tables in the above schema.\n\n```\nGRANT ALL PRIVILEGES ON SCHEMA \"<YOUR_DATABASE>\".\"EVENTS\" FOR ROLE QUICKSTART;\n```\n\nCopy the sample data into the newly create schema.\n\n```\nCREATE TABLE \"<YOUR_DATABASE>\".\"EVENTS\".\"TRACKS\" AS SELECT * FROM \"SNOWFLAKE_QUICKSTART\".\"PUBLIC\".\"TRACKS\";\nCREATE TABLE \"<YOUR_DATABASE>\".\"EVENTS\".\"IDENTIFIES\" AS SELECT * FROM \"SNOWFLAKE_QUICKSTART\".\"PUBLIC\".\"IDENTIFIES\";\nCREATE TABLE \"<YOUR_DATABASE>\".\"EVENTS\".\"PAGES\" AS SELECT * FROM \"SNOWFLAKE_QUICKSTART\".\"PUBLIC\".\"PAGES\";\nCREATE TABLE \"<YOUR_DATABASE>\".\"EVENTS\".\"ORDER_COMPLETED\" AS SELECT * FROM \"SNOWFLAKE_QUICKSTART\".\"PUBLIC\".\"ORDER_COMPLETED\";\n```\n\nNow you are ready to create a pipeline connection in RudderStack.\n\n## Create JavaScript source\n\nRudderStack’s Profiles and Predictions products require a warehouse destination with an active sync from a source (a data pipeline). Therefore we will create a JavaScript source that can send a test event to Snowflake.\n\nAfter logging into RudderStack, navigate to the **Directory** from the sidebar on the left, then select the JavaScript source from the list of sources.\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/select-js-source.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/select-js-source.webp)\n\nEnter “QuickStart Test Site” for the source name and click `Continue`. You have successfully added a source!\n\nNote at the bottom of the JavaScript Source page is a `Write Key`. You will need this for sending a test event after connecting the Snowflake destination.\n\n## Create Snowflake destination\n\nNavigate to the **Overview** tab in the JavaScript source view and click on **Add Destination**.\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/add-destination.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/add-destination.webp)\n\nSelect the Snowflake destination from the list, then on the next page give it the name “Snowflake QuickStart” and click **Continue**.\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/select-snowflake.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/select-snowflake.webp)\n\nAdd in your Snowflake connection credentials:\n\n*   **Account**: Your account name.\n*   **Database**: Your database name that you used in the previous steps for `QUICKSTART`.\n*   **Warehouse**: Your warehouse that you granted usage to `QUICKSTART`.\n*   **User**: `QUICKSTART_USER`\n*   **Role**: `QUICKSTART`\n*   **Password**: Password for `QUICKSTART_USER`.\n*   **Namespace**: `EVENTS`\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/snowflake-config.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/snowflake-config.webp)\n\nAt the bottom under **Object Storage Configuration** toggle **Use RudderStack managed object storage** ON.\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/object-storage-toggle.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/object-storage-toggle.webp)\n\nLeave the defaults for all other settings and click **Continue**. RudderStack will verify credentials and that it has the needed permissions.\n\nYou have now created a pipeline connection in RudderStack!\n\n## Send test event\n\nYou can use a test site to send a `connection_setup` event. This will not effect the sample data tables. But first, get the following configuration data from RudderStack:\n\n*   RudderStack Data Plane URL\n*   JavaScript Source Write Key\n\n### Data Plane URL\n\nGo to the **Connections** page in the RudderStack app and copy the **Data Plane** URL from the top of the page.\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/data-plane-url.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/data-plane-url.webp)\n\n### Write key\n\nGo to your JavaScript source in RudderStack and in the **Setup** tab scroll down and copy the **Write key**.\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/write-key.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/write-key.webp)\n\n### Test event\n\nGo to RudderStack’s [test website](https://ryanmccrary.github.io/rudderstackdemo/) and copy your Data Plane URL and Write Key into the top fields and press **Submit**.\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/test-site-setup.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/test-site-setup.webp)\n\nEnter `connection_setup` into the `event_name` field next to **Send Custom Event** and then click on **Send Custom Event**.\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/test-site-event.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/test-site-event.webp)\n\nYou can check the event using RudderStack’s [**Live events**](https://www.rudderstack.com/docs/dashboard-guides/live-events/) view or check the **Syncs** tab in the Snowflake destination.\n\n**Note that the test event needs to be delivered to Snowflake to validate the pipeline.** If needed, you can run a manual sync by clicking **Sync now** in the **Syncs** tab of the Snowflake destination view in RudderStack.\n\n## Profiles schema and permissions\n\nRemember that Predictions automatically runs a Profiles job to create an identity graph. In this step, create a new schema where the identity graph and the related tables and views will be generated.\n\n```\nCREATE SCHEMA \"<YOUR_DATABASE>\".\"PROFILES\";\n```\n\nNow we need to grant permissions to the `QUICKSTART` role.\n\nProfiles will need the following permissions to run:\n\n*   Read access to all input tables to the model (already complete if you followed the previous setup steps)\n*   Write access to the schemas and common tables that the Profiles project creates.\n\nFor the write access run the following statements:\n\n```\nGRANT ALL PRIVILEGES ON SCHEMA PROFILES_QUICKSTART.PROFILES TO ROLE QUICKSTART;\nGRANT SELECT ON ALL TABLES IN SCHEMA PROFILES_QUICKSTART.PROFILES TO ROLE QUICKSTART;\nGRANT SELECT ON FUTURE TABLES IN SCHEMA PROFILES_QUICKSTART.PROFILES TO ROLE QUICKSTART;\nGRANT SELECT ON ALL VIEWS IN SCHEMA PROFILES_QUICKSTART.PROFILES TO ROLE QUICKSTART;\nGRANT SELECT ON FUTURE VIEWS IN SCHEMA PROFILES_QUICKSTART.PROFILES TO ROLE QUICKSTART;\n```\n\nYou are now ready to run Profiles and Predictions projects in the RudderStack UI!\n\n## Profiles CLI setup\n\nBefore you start building automated features, you need to perform some additional setup steps so that you can transition seamlessly from the UI-based workflow to the code-based workflow in the [code your own custom predictions](https://www.rudderstack.com/docs/profiles/example/predictive-features-snowflake/custom-code/) section.\n\nTo build custom features with code, you will need Python3 and the RudderStack Profiles CLI tool (`PB`, for Profiles Builder) installed on your machine. If you do not have `PB` installed, follow the instructions below. This includes authentication for your Snowflake environment. **Use the warehouse, database, and schema setup in the previous steps.** This authentication will be used for accessing your Snowflake warehouse and running Snowpark. For more information about Profiles CLI tool, see [documentation](https://www.rudderstack.com/docs/profiles/get-started/profile-builder/).\n\n### Install Profile Builder tool\n\nOpen a console window and install the Profile Builder `PB` tool.\n\n```\npip3 install profiles-rudderstack\n```\n\nCheck the version to make sure it is at least `0.10.5`\n\n### Install ML dependency\n\nIn order to run ML models you will need to install the python package `profiles-multieventstream-features`. Run the following command to install it.\n\n```\npip install git+https://github.com/rudderlabs/profiles-pycorelib\n```\n\nEnsure you have the following python packages installed. These are required to use the `rudderstack-profiles-classifier` package to train classification models for predictive features.\n\n```\ncachetools>=4.2.2\nhyperopt>=0.2.7\njoblib>=1.2.0\nmatplotlib>=3.7.1\nseaborn>=0.12.0\nnumpy>=1.23.1\npandas>=1.4.3\nPyYAML>=6.0.1\nsnowflake_connector_python>=3.1.0\nsnowflake-snowpark-python[pandas]>=0.10.0\nscikit_learn>=1.1.1\nscikit_plot>=0.3.7\nshap>=0.41.0\nplatformdirs>=3.8.1\nxgboost>=1.5.0\nredshift-connector\n```\n\n### Create warehouse connection\n\nInitiate a warehouse connection:\n\nFollow the prompts and enter the details for your Snowflake warehouse/database/schema/user.\n\n```\nEnter Connection Name: quickstart\nEnter target:  (default:dev)  # Press enter, leaving it to default\nEnter account: <YOUR_ACCOUNT>\nEnter warehouse: <YOUR_WAREHOUSE>\nEnter dbname: <YOUR_DATABASE>\nEnter schema: PROFILES\nEnter user: QUICKSTART_USER\nEnter password: <password>\nEnter role: QUICKSTART\nAppend to /Users/<user_name>/.pb/siteconfig.yaml? [y/N]\ny\n```\n\n### Enable ML models\n\nFinally, enable ML models within `siteconfig.yaml`.\n\nOpen the file `/Users/<user_name>/.pb/siteconfig.yaml` in a text editor.\n\nAt the bottom of the file there is a `py_models` section. Update it to look like this:\n\n```\npy_models:\n    enabled: true\n    python_path: $(which python3)\n    credentials_presets: null\n    allowed_git_urls_regex: \"\"\n```\n\n## Snowpark\n\nPredictive features utilizes Snowpark within your Snowflake environment. It uses the same authentication as Snowflake and is able to run jobs within Snowflake.\n\nThis will run python code in a virtual warehouse in Snowflake and will incur compute costs. These costs vary depending on the type of model and the quantity of data used in training and prediction. For more general information on Snowflake compute costs, see [Understanding Compute Costs](https://docs.snowflake.com/en/user-guide/cost-understanding-compute).\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Prerequisites | RudderStack Docs",
    "description": "Prerequisites to generate predictive features in Snowflake using RudderStack Predictions",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/example/predictive-features-snowflake/setup-automated-features/",
    "markdown": "# Setup Automated Features | RudderStack Docs\n\nSet up RudderStack to build automated features in the RudderStack UI\n\n* * *\n\n*     6 minute read  \n    \n\nSetting up automated features in the RudderStack UI is a straight-forward process. Predictive features are configured within a Profiles project and automatically added to the feature table output when the project is run.\n\n## Project setup\n\nFollow the steps below to set up a project and build predictive features:\n\n### Log into RudderStack\n\nYou can log-in [here](https://app.rudderstack.com/login).\n\n### Navigate to Profiles screen\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/Navigation.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/Navigation.webp)\n\n### Enter a name and description\n\nEnter a unique name and description for the Profiles Project where you want to build the predictive features.\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/Profiles-Name.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/Profiles-Name.webp)\n\n### Select sources\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/Sources.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/Sources.webp)\n\nSelect your Snowflake warehouse. If you have not configured the Snowflake warehouse, set up an event stream connection to Snowflake in RudderStack ([see details here](https://www.rudderstack.com/docs/destinations/warehouse-destinations/snowflake/)) and refer to the setup steps above.\n\nOnce you select the warehouse, you will be able to choose from RudderStack event sources that are connected to Snowflake. In this example, the JavaScript source created above is used to write to the same schema as the sample data. Profiles will use the `PAGES`, `TRACKS`, `IDENTIFIES`, and `ORDER_COMPLETED` tables from that schema to build automated and predictive features.\n\n## Map ID fields\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/Map-ID.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/Map-ID.webp)\n\nMap the fields from the source table(s) to the correct type of ID. The standard ID types are:\n\n*   `user_id`\n*   `anonymous_id`\n*   `email`\n\n**Note that for RudderStack event sources, standard ID column names will be mapped for you automatically**. If you have included additional identifiers in your payloads, you can map those custom column names to standard identifiers by clicking **Add mapping** at the bottom of the table.\n\n### Map `Order_Completed` table\n\nClick on **Add mapping** and map the `USER_ID` and `ANONYMOUS_ID` columns to standard identifiers to include the `ORDER_COMPLETED` table as a source for the identity graph and user features.\n\n| Source | Event | Property | ID Type |\n| --- | --- | --- | --- |\n| QuickStart Test Site | ORDER\\_COMPLETED | USER\\_ID | user\\_id |\n| QuickStart Test Site | ORDER\\_COMPLETED | ANONYMOUS\\_ID | anonymous\\_id |\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/map-id-orders.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/map-id-orders.webp)\n\n## Create default features in the UI\n\nThere are two types of automated features you can define in the UI:\n\n*   Default features\n*   Custom features\n\nThis guide focuses on the default features that are automatically generated.\n\n### Set up default features\n\nDefault features are features commonly used in Profiles projects. RudderStack provides a template library for these features to make them easy to add to your project. Templated features give you access to over 40 different standard and predictive features, which are generated in Snowflake automatically.\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/feature-categories.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/feature-categories.webp)\n\nDefault features are divided into 4 categories:\n\n*   **Attribution** - campaign, source, and churn features\n*   **Demographics** - user trait features\n*   **Engagement** - user activity features\n*   **Predictive ML Features** - predictive features\n\nYou can open the drop down menu for each category and select as many as you would like for your project.\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/feature-attribution.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/feature-attribution.webp)\n\nFor this guide, select:\n\n*   Attribution\n    *   `first_source_name`\n    *   `is_churned_30_days`\n    *   `is_churned_90_days`\n*   Demographics\n    *   `first_name`\n    *   `last_name`\n    *   `state`\n*   Engagement\n    *   `first_date_seen`\n    *   `last_date_seen`\n    *   `total_sessions_90_days`\n    *   `total_sessions_last_week`\n*   Predictive ML Features\n    *   `percentile_churn_score_30_days`\n\nIt is important to remember that RudderStack runs all of the feature-generation code transparently in Snowflake. For any of the default features, other than Predictive ML Features, you can click on **Preview Code** and get a yaml code snippet defining that feature (the yaml definition is used to generate SQL). This is helpful for technical users who want a deeper understanding of feature logic (and a running start for coding their own features).\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/churn-code-snippet.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/churn-code-snippet.webp)\n\n#### Churn definition\n\nRudderStack Predictions automatically generates a binary churn value for every user based on inactivity over a 7, 30, or 90-day period.\n\nFor example, to calculate the `is_churned_7_days` value, RudderStack looks for any activity timestamp for a particular user in the `TRACKS` and `PAGES` tables over the previous 7 day period. Practically, this means that RudderStack executes a ‘max timestamp’ query against those tables to see if users have viewed a page or performed other tracked actions (like clicks, form submits, add to carts, etc.) and then calculates the difference from today. If the query returns 7 or more, that means they haven’t performed any activity over the last 7 days and their `is_churned_7_days` trait is set to `1`.\n\n#### How Predictions models percentile churn scores\n\nUsing the standard definition (no activity over a defined period), RudderStack Predictions automatically runs a python-based churn model in Snowpark that predicts whether users will become inactive (churn) over the next 7, 30, or 90-day period. This model is trained on existing user data, using the Profiles identity graph, so it is recommended that you have a minimum of 5,000-10,000 unique users to achieve accurate output for business use cases.\n\n**How Predictions automates ML with Snowpark**\n\nPredictions streamlines integration with Snowpark by using the authentication from your existing Snowflake integration in RudderStack.\n\nIn order to run models in Snowpark, there is one additional set of permissions required. To run Predictions jobs, you must have permission to create stages within your schema. For more information see the **CREATE STAGE** [documentation](https://docs.snowflake.com/en/sql-reference/sql/create-stage#access-control-requirements).\n\nOnce permissions are granted, you will be able to run jobs that produce predictive features. **If you have followed the steps in [Prerequisite](https://www.rudderstack.com/docs/profiles/example/predictive-features-snowflake/prerequisite/) guide, that permission has already been granted.**\n\n## Create custom features in the UI\n\nIf a needed feature is not in the template library, you can define a custom feature in the UI. Custom features can be standard or predictive features.\n\n### Add Custom Features\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/custom-feature.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/custom-feature.webp)\n\nClick on **Add a custom feature** at the top of the page and build an `average_order` feature with the following values:\n\n| Field | Value |\n| --- | --- |\n| **Name** | average\\_order |\n| **Description** | Average Order Size including shipping, taxes, and discounts |\n| **Function Type** | AGGREGATE |\n| **Function** | AVG |\n| **Event** | EVENTS.ORDER\\_COMPLETED |\n| **Property or Trait** | TOTAL |\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/custom-feature-define.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/custom-feature-define.webp)\n\nOnce complete click **Save**. The custom feature will be added to the top of the page.\n\n## Set Schedule\n\nThere are three options to set a schedule for how often the feature generation job runs:\n\n*   Basic\n*   Cron\n*   Manual\n\n### Basic\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/schedule-basic.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/schedule-basic.webp)\n\nSchedule on a predetermined interval.\n\nThe frequency can be every:\n\n*   30 minutes\n*   1 hour\n*   3 hours\n*   6 hours\n*   12 hours\n*   24 hours\n\nThen select a starting time for the initial sync.\n\n### Cron\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/schedule-cron.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/schedule-cron.webp)\n\nSchedule using cron expressions for more specific scheduling (i.e. Daily on Tuesdays and Thursdays).\n\nIf you are not familiar with cron expressions, you can use the builder in the UI.\n\n### Manual\n\nOnly runs when manually triggered within the UI. For this guide, select **Manual**.\n\n## Save, review, and create project\n\n### Save project\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/save-project.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/save-project.webp)\n\nFill in the **Schema** field with `PROFILES` (to match what we created earlier). This is where the feature table will be written to in Snowflake.\n\n### Review and create project\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/review-create.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/review-create.webp)\n\nFinally, review all the settings and when ready, click `Create user 360`.\n\n## Review created features\n\nOnce the initial project run is initiated, it may take up to 25-30 minutes to complete. Once the job is done, you are able to explore the data in RudderStack’s UI, including model fit charts for predictive features and individual user records with all features.\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/ui-predictive.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/ui-predictive.webp)\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/ui-predictive-graphs.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/ui-predictive-graphs.webp)\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/ui-explorer.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/ui-explorer.webp)\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Setup Automated Features | RudderStack Docs",
    "description": "Set up RudderStack to build automated features in the RudderStack UI",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/example/predictive-features-snowflake/",
    "markdown": "# Predictive features | RudderStack Docs\n\nCreate predictive features with RudderStack and Snowflake without using MLOps\n\n* * *\n\n*     2 minute read  \n    \n\nPredictive features like future LTV and churn propensity can be game changing for a business. If your marketing, customer success, and other teams want to use them, though, your company often faces a binary choice: use a one-size-fits-all solution within an existing SaaS platform (i.e., marketing automation tool), or build out ML and MLOps capabilities internally.\n\nBoth options have significant drawbacks. First, templated SaaS-based solutions can’t leverage all of your customer data and aren’t configurable, which results in low accuracy and impact. On the other hand, hiring data scientists and setting up MLOps is expensive and complex.\n\nModern data teams need an option in the middle: the ability to deploy model templates on all of their customer data, but without additional tooling, processes and headcount.\n\nWith RudderStack Predictions and Snowflake, you can create predictive features directly in your warehouse, without the need to set up MLOps processes and infrastructure. Predictions leverages the full power of Snowpark to run ML models within your existing data engineering workflow.\n\nIn this section, you will learn about two ways to build predictive features in RudderStack Predictions:\n\n1.  [Set up automated features in the RudderStack UI](https://www.rudderstack.com/docs/profiles/example/predictive-features-snowflake/setup-automated-features/) - You can setup and run the jobs within the RudderStack UI. This process makes it easy for less technical users to implement basic predictive features.\n2.  [Code your own custom predictions](https://www.rudderstack.com/docs/profiles/example/predictive-features-snowflake/custom-code/) - Predictions also supports a code-based approach that gives technical users full control to define custom predictive features that match their unique business logic.\n\nIt’s important to note that Predictions runs on top of RudderStack [Profiles](https://www.rudderstack.com/docs/profiles/overview/), a product that automates identity resolution and user feature development in Snowflake.\n\nPredictions leverages the Profiles identity graph to train and run ML models. Because Predictions is part of Profiles, project outputs include an identity graph, standard user featuers (i.e., `last_seen`) and predictive user features (i.e., `percentile_churn_score_30_days`). Both types of features are built using RudderStack data sources and standardized feature definitions.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Predictive features | RudderStack Docs",
    "description": "Create predictive features with RudderStack and Snowflake without using MLOps",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/data-governance/tracking-plans/ruddertyper/",
    "markdown": "# RudderTyper | RudderStack Docs\n\nUse RudderTyper to generate native clients for your tracking plans.\n\n* * *\n\n*     5 minute read  \n    \n\n[RudderTyper](https://github.com/rudderlabs/rudder-typer) is a tool that lets you generate strongly-typed RudderStack analytics library wrappers based on your [Tracking Plan](https://documenter.getpostman.com/view/16242548/TzeWFT6D) spec.\n\nSimply put, it uses an event from your specified tracking plan and generates an analytics call in the supported languages.\n\n[![Readme](https://www.rudderstack.com/docs/images/readme-example.gif)](https://www.rudderstack.com/docs/images/readme-example.gif)\n\n## Key features\n\nSome key features of RudderTyper are:\n\n*   Allows you to contextualize your analytics instrumentation and validate it with your event spec, before deploying to production.\n*   You can access and validate your event names, properties, types, etc.\n*   It provides compile-time errors and warns you about any missing required properties, data mismatch, and any issues in the JSON schema configured in your tracking plan.\n\n## Get started\n\nTo fire up a quick start wizard to create a `ruddertyper.yml` and generate your first client with the specified configuration details, run the following command:\n\n```\n$ npx rudder-typer init | initialize | quickstart\n```\n\n## Other commands\n\n### Update\n\n```\n$ npx rudder-typer update | u | *   (default)\n```\n\nThis command syncs `plan.json` with RudderStack to pull the latest changes in your tracking plan and then generates an updated development client.\n\n### Build\n\n```\n$ npx rudder-typer build | b | d | dev | development\n```\n\nThis command generates a development client from `plan.json`.\n\n### Production\n\n```\n$ npx rudder-typer prod | p | production\n```\n\nThis command generates a production client from `plan.json`.\n\n### Token\n\n```\n$ npx rudder-typer token | tokens | t\n```\n\nThis command prints the local RudderStack API token configuration.\n\n### Version\n\n```\n$ npx rudder-typer version\n```\n\nThis command prints the RudderTyper CLI version.\n\n### Help\n\nThis command prints the help message describing different commands available with RudderTyper.\n\n## CLI arguments\n\n| Argument | Type | Description |\n| --- | --- | --- |\n| `config` | `string` | An optional path to a `ruddertyper.yml` (or a directory with `ruddertyper.yml`). |\n| `debug` | `boolean` | An optional (hidden) flag for enabling Ink debug mode. |\n| `version` | `boolean` | Standard `--version` flag to print the version of this CLI. |\n| `v` | `boolean` | Standard `-v` flag to print the version of this CLI. |\n| `help` | `boolean` | Standard `--help` flag to print help on a command. |\n| `h` | `boolean` | Standard `-h` flag to print help on a command. |\n\n## Configuration reference\n\nRudderTyper stores its configuration in a `ruddertyper.yml` file in the root of your repository.\n\nA sample configuration looks like the following:\n\n```\n# RudderStack RudderTyper Configuration Reference (https://github.com/rudderlabs/rudder-typer)\n# Just run `npx rudder-typer` to re-generate a client with the latest versions of these events.\n\nscripts:\n  # You can supply a RudderStack API token using a `script.token` command. The output of `script.token` command should be a valid RudderStack API token.\n  token: source .env; echo $RUDDERTYPER_TOKEN\n  # You can supply email address linked to your workspace using a `script.email` command.The output of `script.email` command should be an email address registered with your workspace.\n  email: source .env: echo $EMAIL\n  # You can format any of RudderTyper's auto-generated files using a `script.after` command.\n  # See `Formatting Generated Files` below.\n  after: ./node_modules/.bin/prettier --write analytics/plan.json\n\nclient:\n  # Which RudderStack SDK you are generating for.\n  # Valid values: analytics.js, analytics-node, analytics-ios, analytics-android.\n  sdk: analytics-node\n  # The target language for your RudderTyper client.\n  # Valid values: javascript, java, objective-c, swift.\n  language: javascript\n  # JavaScript Transpilation Settings\n  # Valid values: 'ES3','ES5','ES2015','ES2016','ES2017','ES2018','ES2019','ESNext','Latest'\n  scriptTarget: 'ES6'\n  # Valid values: 'CommonJS','AMD','UMD','System','ES2015','ESNext'\n  moduleTarget: 'ESNext'\n\ntrackingPlans:\n  # The RudderStack Tracking Plan that you are generating a client for.\n  # Provide your workspace slug and Tracking Plan id\n  # You also need to supply a path to a directory to save your RudderTyper client.\n  - id: rs_QhWHOgp7xg8wkYxilH3scd2uRID\n    workspaceSlug: rudderstack-demo\n    path: ./analytics\n```\n\n## Integrating RudderTyper-generated client with your app\n\nThis section includes steps to integrate your RudderTyper-generated client with your app across different RudderStack SDKs.\n\n### RudderStack Android SDK\n\n*   Import all files in the client generated by RudderTyper as a package in your project.\n*   Then, you can directly make the calls using the RudderTyper client as shown below:\n\n```\n// Import your auto-generated RudderTyper client:\nimport com.rudderstack.generated.*\n\n  // Issue your first RudderTyper track call!\n  RudderTyperAnalytics.with(this).orderCompleted(\n    OrderCompleted.Builder()\n    .orderID(\"ck-f306fe0e-cc21-445a-9caa-08245a9aa52c\")\n    .total(39.99)\n    .build()\n  );\n```\n\n### RudderStack iOS SDK\n\n*   Import your RudderTyper client into your project using XCode.\n\n**NOTE**: If you place your generated files into a folder in your project, import the project as a group not a folder reference.\n\n*   Then, you can directly make the calls using the RudderTyper client as shown:\n\n```\n// Import your auto-generated RudderTyper client:\n#import \"RSRudderTyperAnalytics.h\"\n\n// Issue your first RudderTyper track call!\n[RSRudderTyperAnalytics orderCompletedWithOrderID: \"ck-f306fe0e-cc21-445a-9caa-08245a9aa52c\" total: @39.99];\n```\n\n### RudderStack JavaScript SDK\n\n*   Import the RudderTyper-generated client using `require()` and make the calls if your framework supports them. Otherwise, you can use [Browserify](https://browserify.org/) to generate a bundle that supports your implementation. The implementation for each of the alternatives mentioned above will be as shown:\n\n#### Using the `require()` method\n\n```\n// Import RudderStack JS SDK and initialize it\nconst rudderanalytics = require(\"rudder-sdk-js\")\nrudderanalytics.load(YOUR_WRITE_KEY, DATA_PLANE_URL)\n// Import your auto-generated RudderTyper client:\nconst rudderTyper = require(\"./rudderTyperClient\")\n// Pass in your rudder-sdk-js instance to RudderTyper client\nrudderTyper.setRudderTyperOptions({\n  analytics: rudderanalytics,\n})\n// Issue your first RudderTyper track call!\nrudderTyper.orderCompleted({\n  orderID: \"ck-f306fe0e-cc21-445a-9caa-08245a9aa52c\",\n  total: 39.99,\n})\n```\n\n#### Using `browserify`\n\n*   Execute the following command to generate a bundle from the RudderTyper client:\n\n```\nbrowserify rudderTyperClient.js --standalone rudderTyper >  rudderTyperBundle.js\n```\n\n*   Now you can make calls from your `html` file as shown:\n\n```\n<head>\n  <script>\n    rudderanalytics = window.rudderanalytics = [];\n    var methods = [\"load\", \"page\", \"track\", \"identify\", \"alias\", \"group\", \"ready\", \"reset\", \"getAnonymousId\", \"setAnonymousId\"];\n    for (var i = 0; i < methods.length; i++) {\n      var method = methods[i];\n      rudderanalytics[method] = function(methodName) {\n        return function() {\n          rudderanalytics.push([methodName].concat(Array.prototype.slice.call(arguments)));\n        };\n      }(method);\n    }\n    rudderanalytics.load(YOUR_WRITE_KEY, DATA_PLANE_URL);\n    rudderanalytics.page();\n  </script>\n  <script src=\"https://cdn.rudderlabs.com/v1.1/rudder-analytics.min.js\"></script>\n  <script src=\"./rudderTyperBundle.js\"></script>\n  <meta charset=\"UTF-8\">\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Document</title>\n</head>\n<script>\n  rudderTyper.setRudderTyperOptions({\n    analytics: rudderanalytics\n  });\n  rudderTyper.orderCompleted({\n    orderID: 'ck-f306fe0e-cc21-445a-9caa-08245a9aa52c',\n    total: 39.99\n  })\n</script>\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> If you are using an older version of the JavaScript SDK, see the [Version Migration Guide](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/migration-guide/) to migrate to the latest version.\n\n### RudderStack Node.js SDK\n\n*   Import the the RudderTyper-generated client and start making calls using RudderTyper as shown:\n\n```\n// Import Rudder Node SDK and intialize it\nconst Analytics = require(\"@rudderstack/rudder-sdk-node\")\nconst client = new Analytics(WRITE_KEY, DATA_PLANE_URL / v1 / batch)\nconst ruddertyper = require(\"./rudderTyperClient\")\n// Pass in your rudder-sdk-node instance to RudderTyper.\nruddertyper.setRudderTyperOptions({\n  analytics: client,\n})\n// Issue your first RudderTyper track call!\nruddertyper.orderCompleted({\n  orderID: \"ck-f306fe0e-cc21-445a-9caa-08245a9aa52c\",\n  total: 39.99,\n})\n```\n\n## Contribute\n\n*   To submit a bug report or feature request, file an issue [here](https://github.com/rudderlabs/rudder-server/issues).\n*   To develop on `ruddertyper` or propose support for a new language, see our [contributors documentation](https://github.com/rudderlabs/rudder-server/blob/master/CONTRIBUTING.md).\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "RudderTyper | RudderStack Docs",
    "description": "Use RudderTyper to generate native clients for your tracking plans.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/example/predictive-features-snowflake/custom-code/",
    "markdown": "# Custom Predictive Features | RudderStack Docs\n\nCode your own custom predictive features\n\n* * *\n\n*     8 minute read  \n    \n\nWhile automated features are incredibly useful for quickly deploying activity-based churn scores, data teams inevitably want to go deeper and define custom predictions that match their unique business logic and KPIs.\n\nBasic customization is possible in the UI as we covered above, but Predictions also supports a code-based workflow that gives technical users full control and complete customizability, as well as the ability to integrate the process into their existing development workflow.\n\nFor example, if you are an eCommerce company, it can be helpful to predict whether or not a user will make a purchase over a certain dollar amount, over the next `n` days.\n\nRudderStack makes it easy to migrate from the UI-based workflow to the code-based workflow to build these more complex use cases.\n\n## Download project files\n\nOn the Profiles screen, find your project and click the **Download this Project** button on the top right side. This will download all the files for that Profiles project in a compressed (zip) file including the modeling files.\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/download-project.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/download-project.webp)\n\nInside the Profiles folder you will find `pb_project.yaml` and a `models` folder with `resources.yaml`.\n\n```\nRudderStack QuickStart\n├── pb_project.yaml\n├── models\n│   ├── resources.yaml\n```\n\n### pb\\_project.yaml\n\n`pb_project.yaml` is the main configuration file for the Profiles project. The top section defines the `name`, `schema_version`, `connection`, and `model_folder` (where the files that define the details of the Profiles project can be found).\n\nUpdate the following values:\n\n*   `name` to `Profile-Quickstart` to match the name in the UI.\n*   `connection` to `QUICKSTART` to match the database connection we made in the Prerequisites section.\n\n```\nname: Profile-QuickStart\nschema_version: 69 # Or most recent version\nconnection: QUICKSTART\nmodel_folders:\n    - models\n```\n\nBelow there is an `entities` section that defines the entities and the kinds of ID’s make up that entity. An entity is a business concept or unit that will be used to build the identity graph and features. Projects can contain multiple entities like user, household, and organization.\n\nFor this project, there is one entity called `user` with 5 different types of IDs. An ID type maps which ID fields can be joined together. For example, if you have two tables with `user_id` columns called `id` and `userid`, by giving each the type `user_id` Profiles knows to join those tables on those columns.\n\nThe ID fields are already mapped to these types in the UI. Nothing needs to be updated in this section.\n\n```\nentities:\n  - name: user\n    id_types:\n      - main_id\n      - user_id\n    feature_views:\n      using_ids:\n        - id: email\n          name: features_by_email\n        - id: salesforce_id\n          name: salesforce_id_stitched_features\n      features:\n        - from: models/cart_feature_table\n          include:\n            - \"*\"\n```\n\nFinally there is a `packages` section. This section allows you to import a Profiles project from GitHub and use the feature definitions from that project in this one. The imported project provides the definitions for the standard features selected in the UI. Nothing needs to be updated in this section.\n\n```\npackages:\n    - name: base_features\n      url: https://github.com/rudderlabs/rudderstack-profiles-multieventstream-features\n      inputsMap: # These are the tables automatically mapping in the UI (TRACKS, PAGES, IDENTIFIES)\n        rsIdentifies_1: inputs/rsIdentifies_1\n        rsIdentifies_2: nil\n        rsIdentifies_3: nil\n        rsPages_1: inputs/rsPages_1\n        rsPages_2: nil\n        rsPages_3: nil\n        rsTracks_1: inputs/rsTracks_1\n        rsTracks_2: nil\n        rsTracks_3: nil\n      overrides: # By default all features are imported from the project, therefore the features we did not select need to be disabled\n        - requested_enable_status: disabled\n          models:\n            - entity/user/active_days_in_past_365_days\n            - entity/user/active_days_in_past_7_days\n            - entity/user/avg_session_length_in_sec_365_days\n            - entity/user/avg_session_length_in_sec_last_week\n            - entity/user/avg_session_length_in_sec_overall\n            - entity/user/campaign_sources\n            - entity/user/campaigns_list\n            - models/churn_7_days_model\n            - models/churn_90_days_model\n            - entity/user/country\n            - entity/user/currency\n            - entity/user/days_since_account_creation\n            - entity/user/days_since_last_seen\n            - entity/user/first_campaign_name\n            - entity/user/is_churned_7_days\n            - entity/user/last_campaign_name\n            - entity/user/last_source_name\n            - entity/user/max_timestamp_bw_tracks_pages\n            - entity/user/mediums_list\n            - entity/user/sources_list\n            - entity/user/total_sessions_365_days\n            - entity/user/total_sessions_till_date\n```\n\n### resource.yaml\n\n`resources.yaml` contains two main sections: `inputs` and `var_groups`.\n\nThe `inputs` section defines what ID’s are in each table and their mapping. Currently these are all the tables and mappings that were defined in the UI. These tables are used for creating an identity graph and all features related to it.\n\nIf you want to add another table in the future, the table and ID mappings would be added here. Below is an example of the `ORDER_COMPLETED` table we manually mapped in the UI. It consists of the following fields:\n\n| Field | Description |\n| --- | --- |\n| name | alias for the table; the primary reference in the rest of the yaml files |\n| table | `<SCHEMA>.<TABLE_NAME>` |\n| select | column with ID |\n| type | kind of ID |\n| entity | what entity the ID should be mapped to |\n| to\\_default\\_stitcher | `true` unless you decide to use a different ID stitcher |\n| remapping | leave as `null` |\n\n```\n- name: rs_EVENTS_ORDER_COMPLETED\n  app_defaults:\n    table: EVENTS.ORDER_COMPLETED\n    ids:\n        - select: USER_ID\n          type: user_id\n          entity: user\n          to_default_stitcher: true\n        - select: ANONYMOUS_ID\n          type: anonymous_id\n          entity: user\n          to_default_stitcher: true\n  remapping: null\n```\n\nThe `var_groups` section is where custom features are defined, both custom features created in the UI and those added via code in this file. Custom features are organized into groups by entity (in our case only `user`). The entity is like the `group by` variable in a SQL query.\n\nBelow that custom features are defined in the `vars` subsection. Here is the `average_order` feature we created in the UI.\n\n```\n- entity_var:\n    is_feature: true\n    name: average_order\n    description: Average Order Size including shipping, taxes, and discounts\n    select: AVG(TOTAL)\n    from: inputs/rs_EVENTS_ORDER_COMPLETED\n```\n\nA name and description are required for the custom feature and then it is defined using declarative SQL syntax. This allows you to define the custom feature the same way you would if creating a new table with SQL.\n\n## Create a custom predictive feature\n\nJust like in the UI workflow, you must already have defined the feature you want to predict. Therefore we are going to add a new custom feature for large purchases in the last 90 days. **NOTE: Currently predictive features can only be binary (i.e. 1/0)**\n\nA large order is defined here as any order with a `TOTAL` of > $100.\n\nAt the bottom of the `resources.yaml`, add the name and definition for `large_purchase_last_90`.\n\n```\n- entity_var:\n  name: large_purchase_last_90\n  description: Customer that made a purchase of >$100 in the last 90 days.\n  select: CASE WHEN MAX(TOTAL) > 100 THEN 1 ELSE 0 END\n  from: inputs/re_EVENTS_ORDER_COMPLETED\n  where: DATEDIFF(days, TIMESTAMP, CURRENT_DATE) <= 90\n```\n\nYou can use SQL functions and keywords in the definition. FOr example, a `CASE` statement in the SELECT statement and add a `where` statement and use the `DATEDIFF` function. You can also use the alias for the `ORDER_COMPLETED` table in the `from` statement.\n\nFor more details on Profiles and project file structure, you can review the Profiles [documentation](https://www.rudderstack.com/docs/profiles/overview/).\n\n## Organize the project in two files (**OPTIONAL**)\n\nProfiles does not need specific yaml files in the `models` folder in order to run. That allows you to organize your code as you feel is best. You can keep it all in one file or can split it over multiple files.\n\nYou can split the `resources.yaml` file into `inputs.yaml` and `profiles.yaml` by creating the two yaml files. Then copy everything from the `inputs` section into `inputs.yaml` and `var_groups` into `profiles.yaml`.\n\nOnce done, you can delete the `resources.yaml`.\n\n## Add a custom predictive feature\n\nThis section explains how to create 2 new custom predictive features from `large_purchase_last_90` called `likelihood_large_purchase_90` (raw score) and `percentile_large_purchase_90`(percentile score).\n\n#### Add Python ML requirement\n\nIn order to add custom predictive features, add the `profiles-pycorelib` package to the project requirements. At the bottom of `pb_project.yaml` add the following code to `pb_project.yaml`.\n\n```\npython_requirements:\n  - profiles-pycorelib==0.2.1\n```\n\n#### Create ml\\_models.yaml\n\nNow, create a new file and name it `ml_models.yaml`. This file is where you can define 2 new custom predictive features and how to train the ML model. The code for these new predictive features is discussed below.\n\nThis file is organized by the predictive model created for predictive features, not the individual features. The top level consists of:\n\n| Field/Section | Description |\n| --- | --- |\n| `name` | Name of the model (not feature) |\n| `model_type` | `python_model` |\n| `model_spec` | All of the model specifications |\n\n* * *\n\n`model_spec` section:\n\n| Section | Description |\n| --- | --- |\n| `train` | Training configuration |\n| `predict` | Scoring configuration |\n\n```\nmodels:\n    - name: &model_name large_purchase_90_model\n      model_type: python_model\n      model_spec:\n        occurred_at_col: insert_ts\n        entity_key: user\n        validity_time: 24h\n        py_repo_url: git@github.com:rudderlabs/rudderstack-profiles-classifier.git # Model training and scoring repo\n\n        train:\n          file_extension: .json\n          file_validity: 2160h # 90 days; when the model will be retrained\n          inputs: &inputs\n            - packages/base_features/models/rudder_user_base_features # location of the base features created in the UI\n            - packages/large_purchase_last_90 # custom feature created in var_groups\n            - models/average_order # custom feature we created in the UI\n          config:\n            data: &model_data_config\n              package_name: feature_table\n              label_column: large_purchase_last_90 # target feature\n              label_value: 1 # target feature value predicting\n              prediction_horizon_days: 90 # how far into the future\n              features_profiles_model:  'rudder_user_base_features' #taken from inputs\n              output_profiles_ml_model: *model_name\n              eligible_users: 'large_purchase_last_90 is not null' # limit training data to those with non-null values\n              inputs: *inputs\n            preprocessing: &model_prep_config\n              ignore_features: [first_name, last_name, state] # features we do not used in a model\n\n        predict:\n          inputs: *inputs # copy from train\n          config:\n            data: *model_data_config # copy from train\n            preprocessing: *model_prep_config # copy from train\n            outputs:\n              column_names:\n                percentile: &percentile percentile_large_purchase_90 # name of percentile feature\n                score: &raw_score likelihood_large_purchase_90 # name of raw likelihood feature\n              feature_meta_data: &feature_meta_data\n                features:\n                  - name: *percentile\n                    description: 'Percentile of likelihood score. Higher the score the more likely to make a larger purchase'\n                  - name: *raw_score\n                    description: 'Raw likelihood score. Higher the score the more likely to make a larger purchase'\n\n        <<: *feature_meta_data\n```\n\n## Compile and run\n\nSave all files. Now compile the project, this will make sure all SQL and python files are able to be created.\n\nFinally, run the project. This will generate the same files as `compile` and then execute them in Snowflake. The first run can take at least 30 minutes because of training ML models.\n\n## Final table\n\nThe final predictive features can be found in your Snowflake environment together in the same table. The table will provide you with the unified user ID, created by RudderStack, when the features are valid as of (i.e. when the model was last run to create these features), and model ID, and your predictive features.\n\n[![Predictive features in Snowflake](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/final-table.webp)](https://www.rudderstack.com/docs/images/profiles/predictive-features-snowflake/final-table.webp)\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Custom Predictive Features | RudderStack Docs",
    "description": "Code your own custom predictive features",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/data-governance/consent-management/onetrust/",
    "markdown": "# OneTrust Consent Management | RudderStack Docs\n\nPrivacy Overview\n\nThis site uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are as essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.\n\nNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.",
    "title": "OneTrust Consent Management | RudderStack Docs",
    "description": "Integrate RudderStack with the OneTrust consent management platform.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/profiles/example/packages/",
    "markdown": "# Additional Concepts | RudderStack Docs\n\nAdditional concepts related to Profiles like packages, best practices, partial feature tables, etc.\n\n* * *\n\n*     19 minute read  \n    \n\nThis guide explains some of the advanced concepts related to Profiles.\n\n## Packages\n\nProfiles gives you the flexibility to utilize models from existing library projects while defining your own models and inputs within the PB project. This approach allows for a seamless integration of library of pre-existing features, which are readily available and can be applied directly to data streamed into your warehouse.\n\nIn the absence of any explicitly defined models, the PB project is capable of compiling and running models from the library package given that inputs are present in the warehouse as assumed in the lib package.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Packages currently work only on Snowflake.\n\nThe following list of packages are currently available in Profiles. You can [contact the RudderStack team](mailto:support@rudderstack.com) to access these:\n\n*   [profiles-corelib](https://github.com/rudderlabs/profiles-corelib)\n*   [profiles-base-features](https://github.com/rudderlabs/profiles-base-features)\n*   [profiles-shopify-features](https://github.com/rudderlabs/profiles-shopify-features)\n*   [profiles-ecommerce-features](https://github.com/rudderlabs/profiles-ecommerce-features)\n*   [profiles-stripe-features](https://github.com/rudderlabs/profiles-stripe-features)\n*   [profiles-multieventstream-features](https://github.com/rudderlabs/profiles-multieventstream-features)\n\nGenerally, there will be some deviations in terms of the database name and schema name of input models - however, you can easily handle this by remapping inputs.\n\nA sample `pb_project.yaml` file may look as follows:\n\n```\nname: app_project\nschema_version: 69\nprofile: test\npackages:\n  - name: test_ft\n    gitUrl: \"https://github.com/rudderlabs/librs360-shopify-features/tree/main\"\n```\n\nIn this case, the PB project imports a single package. It does not require a separate `models` folder or entities as the input and output models will be sourced from the imported packages.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Note that:\n> \n> *   If non-mandatory inputs required by the model are not present in the warehouse, you can still run the model.\n> *   If there is any deviation in the table/view name for input models, that is, if the inputs assumed in library package are present under some other name, make sure to do the remapping.\n> *   If some of the assumed inputs are not present at all, they should be remapped to `nil`. This way you can create and run imported packages with minimal set of inputs present.\n\nFor example, to import a library package with the name of `shopify_features`:\n\n```\npackages: \n  - name: shopify_features\n    url: https://github.com/rudderlabs/librs360-shopify-features/tree/main\n    inputsMap: \n      rsCartCreate: inputs/rsWarehouseCartCreate\n      rsCartUpdate: inputs/rsCartUpdate\n      rsIdentifies: inputs/rsIdentifies\n      rsOrderCancelled: inputs/rsOrderCancelled\n      rsOrderCreated: inputs/rsOrderCreated\n      rsPages: nil\n      rsTracks: nil\n```\n\nIn `models`/`inputs.yaml`, these inputs need to be defined with table names present in the warehouse.\n\n```\ninputs:\n  - name: rsWarehouseCartCreate\n    table: YOUR_DB.YOUR_SCHEMA.CART_CREATE_TABLE_NAME_IN_YOUR_WH\n    occurred_at_col: timestamp\n    ids:\n      - select: \"anonymous_id\"\n        type: anonymous_id\n        entity: user\n    source_metadata:\n      role: shopify\n      category: webhook\n  - name: rsIdentifies\n    table: YOUR_DB.YOUR_SCHEMA.IDENTIFIES\n    occurred_at_col: timestamp\n    ids:\n      - select: \"user_id\"\n        type: user_id\n        entity: user\n      - select: \"anonymous_id\"\n        type: anonymous_id\n        entity: user\n      - select: \"lower(email)\"\n        type: email\n        entity: user\n    source_metadata:\n      role: shopify\n      category: webhook\n```\n\nNote that the name of the table/view is changed to the appropriate name in your warehouse. If tables are present with the same name (including database name and schema name) then no remapping is required.\n\nYou can also extend the package to modify the existing ID types or add custom ID types to the default list:\n\n### Modify existing ID types\n\nFor the corresponding `id_type`, add the key `extends:` followed by name of the same/different `id_type` that you wish to extend and the `filters` with `include`/`exclude` values.\n\n```\npackages:\n  - name: corelib\n    url: \"https://github.com/rudderlabs/rudderstack-profiles-corelib/tag/schema_{{best_schema_version}}\"\nid_types:\n  - name: user_id\n    extends: user_id\n    filters:\n      - type: exclude\n        value: 123456\nid_types:\n  - name: customer_id\n    extends: user_id\n    filters:\n      - type: include\n        regex: sample\n```\n\n*   **id\\_types**\n\nEnlists the type of identifiers to be used for creating ID stitcher/`entity_var`/`input_var`. For example, you can define anonymous IDs that do not include the value `undefined` or email addresses in proper format.\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `name` | String | Name of the ID type like email, user ID, etc. |\n| `extends` | List | (Optional) Name of the ID type you wish to extend. |\n| `filters` | List | Filter(s) the ID types to include/exclude specific values. The filters are processed in the defined order. |\n\n*   **filters**\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `type` | String | Type of filter. Allowed values are `include` or `exclude`. |\n| `value` | String | Value to match, for example, you can reject certain invalid ID values like `NaN`, `unknown`, `test@domain.com`, etc. |\n| `regex` | String | Regular expression with which to match the values. |\n| `sql` | List | SQL statement with `select` and `from` keys. |\n\n### Add custom ID types\n\nTo have custom list of ID types other than the provisions in the default package, you can remove and add your list as follows:\n\n```\nentities:\n  - name: user\n    id_types:\n      - user_id\n      - anonymous_id\n      - email\n\nid_types:\n  - name: user_id\n  - name: anonymous_id\n    filters:\n      - type: exclude\n        value: \"\"\n      - type: exclude\n        value: \"unknown\"\n      - type: exclude\n        value: \"NaN\"\n  - name: email\n    filters:\n    - type: include\n      regex: \"[A-Za-z0-9+_.-]+@(.+)\"\n```\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Make sure that the ID types are also defined in the entity definition.\n\n### Supported Git URLs\n\nProfiles supports Git URLs for packages. You can host the repos at:\n\n*   GitHub\n*   GitLab\n*   BitBucket\n\n[Contact the RudderStack team](mailto:support@rudderstack.com) if your preferred host isn’t included.\n\nFor private repos, RudderStack only supports SSH Git URLs. You need to add credentials to the `siteconfig.yaml` and public ssh key manually to the platforms. See [Use private Git repos via CLI](#use-private-git-repos-via-cli).\n\nThe URL scheme doesn’t depend on individual Git provider host. You can use the below-mentioned Git URLs:\n\n|     | URL Syntax | Format (Example) |\n| --- | --- | --- |\n| URL for the default branch of a repository | `https://<provider-host>/<org-name>/<repo-name>/path/to/project` | **Github**: `https://github.com/rudderlabs/librs360-shopify-features/shopify-features`<br><br>**Gitlab**: `https://gitlab.com/rudderlabs/librs360-shopify-features/shopify-features`<br><br>**Bitbucket**:`https://bitbucket.org/rudderlabs/librs360-shopify-features/shopify-features` |\n| SSH URL for the default branch of a private repository | `git@<provider-host>:<org-name>/<repo-name>/path/to/project` | **Github**: `git@github.com:rudderlabs/librs360-shopify-features/shopify-features`<br><br>**Gitlab**: `git@gitlab.com:rudderlabs/librs360-shopify-features/shopify-features`<br><br>**Bitbucket**:`git@gbitbucket.org:rudderlabs/librs360-shopify-features/shopify-features` |\n| URL for a specific branch of a repository | `https://<provider-host>/<org-name>/<repo-name>/tree/<branch-name>/path/to/project` | **Github**: `https://github.com/rudderlabs/librs360-shopify-features/tree/main/shopify-features`<br><br>**Gitlab**: `https://gitlab.com/rudderlabs/librs360-shopify-features/tree/main/shopify-features`<br><br>**Bitbucket**:`https://bitbucket.org/rudderlabs/librs360-shopify-features/tree/main/shopify-features` |\n| URL for a specific tag within the repository | `https://<provider-host>/<org-name>/<repo-name>/tag/<tag-name>/path/to/project` | **Github**: `https://github.com/rudderlabs/librs360-shopify-features/tag/wht_test/shopify-features`<br><br>**Gitlab**: `https://gitlab.com/rudderlabs/librs360-shopify-features/tag/wht_test/shopify-features`<br><br>**Bitbucket**:`https://bitbucket.org/rudderlabs/librs360-shopify-features/tag/wht_test/shopify-features` |\n| URL for a specific commit within the repository | `https://<provider-host>/<org-name>/<repo-name>/commit/<commit-hash>/path/to/project` | **Github**: `https://github.com/rudderlabs/librs360-shopify-features/commit/b8d49/shopify-features`<br><br>**Gitlab**: `https://gitlab.com/rudderlabs/librs360-shopify-features/commit/b8d49/shopify-features`<br><br>**Bitbucket**:`https://bitbucket.org/rudderlabs/librs360-shopify-features/commit/b8d49/shopify-features` |\n\n### Best schema version (tags)\n\nIt is recommended to use git-tags instead of the latest commit on main branch of your library projects. Also, you can use a specific tag, for example: `https://github.com/org-name/lib-name/tag/schema_<n>`.\n\nIf you want Profile Builder to figure out the best schema version for every run, you can use the placeholder {{best\\_schema\\_version}}, for example, `https://github.com/org-name/lib-name/tag/schema_{{best_schema_version}}`. The selection of compatible git tags is done by PB, that is, it will figure out the best compatible version for the lib package.\n\nA sample project file:\n\n```\npackages:\n  - name: shopify_features\n    url: https://github.com/org-name/lib-names/tag/schema_{{best_schema_version}}\n    inputsMap:\n      rsCartUpdate: inputs/rsCartUpdate\n      rsIdentifies: inputs/rsIdentifies\n```\n\nUsing this will make Profiles use the best compatible version of the library project in case of any schema updates.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> You don’t have to replace the placeholder `{{best_schema_version}}`. For instance, if `https://github.com/org-name/lib-names/tags/` has a tag for schema\\_44, then `https://github.com/org-name/lib-names/tag/schema_44` will be automatically used. In any case, if you replace the placeholder with actual tag name, the project will work without any issues.\n\n## Model Contracts\n\nYou can use the `contract` field to specify the constraints your model should adhere to while using the warehouse data.\n\nSuppose a model (`M1`) is dependent on model (`M2`). Now, `M1` can specify a contract defining the columns and entities that it needs from `M2` to be executed successfully. Also, it becomes mandatory for `M2` to provide the required columns and entities for contract validation.\n\n**Example 1**\n\nThe following `inputs.yaml` file defines a contract:\n\n```\n- name: rsIdentifies\n  contract:\n    is_optional: false\n    is_event_stream: true\n    with_entity_ids:\n      - user\n    with_columns:\n      - name: timestamp\n      - name: user_id\n      - name: anonymous_id\n```\n\nHere, the contract specifies that:\n\n*   The input table (`rsIdentifies`) must exist in the warehouse.\n*   The model is an event stream model where every row in the table must be an event.\n*   There must be a column in the inputs table (`rsIdentifies`) which represents the user identifier for `user` entity.\n*   The input table (`rsIdentifies`) must have the `timestamp`, `user_id`, and `anonymous_id` columns.\n\n**Example 2**\n\nLet’s consider a SQL model, `rsSessionTable` which takes `shopify_session_features` as an input:\n\n```\nmodels:\n- name: rsSessionTable\n  model_type: sql_template\n  model_spec:\n    ... # model specifications\n    single_sql: |\n      {% set contract = BuildContract('{\"with_columns\":[{\"name\":\"user_id\"}, {\"name\":\"anonymous_id\"}]}') %}\n      {% with SessionFeature = this.DeRef(\"models/shopify_session_features\",contract)%}\n          select user_id as id1, anonymous_id as id2 from {{SessionFeature}}      \n    contract:\n      with_entity_ids:\n        - user\n      with_columns:\n        - name: user_id\n          type: string\n        - name: anonymous_id\n          type: string\n```\n\nThere are two contracts defined in the above example:\n\n*   Contract for `shopify_session_features` model which dictates that the `user_id`, and `anonymous_id` columns must be present.\n*   Contract for `rsSessionTable` model which dictates that it must have a column representing the user identifier for `user` entity. Also, the `user_id`, and `anonymous_id` columns must be present.\n\nThis helps in improving the data quality, error handling, and enables static and dynamic validation of the project.\n\n## Partial feature tables\n\nPartial feature tables are created when only a few input sources are available.\n\nFor example, lets say that you import a library package and some of the input models assumed in the package are not present in your warehouse.\n\nWhen you remap some of these input models to nil, those inputs and the features directly or indirectly dependent upon those inputs are disabled. In such cases, a partial feature table is created from the rest of the available inputs. Similarly, ID stitcher also runs even if few of the edge sources are not present in the warehouse or remapped to nil.\n\n## Pre and post hooks\n\nA pre hook enables you to execute an SQL before running a model, for example, if you want to change DB access, create a DB object, etc. Likewise, a post hook enables you to execute an SQL after running a model. The SQL can also be templatized. Here’s an example code snippet:\n\n```\nmodels:\n  - name: test_id_stitcher\n    model_type: id_stitcher\n    hooks:\n      pre_run: \"CREATE OR REPLACE VIEW {{warehouse.ObjRef('V1')}} AS (SELECT * from {{warehouse.ObjRef('Temp_tbl_a')}});\"\n      post_run: 'CREATE OR REPLACE VIEW {{warehouse.ObjRef(\"V2\")}} AS (SELECT * from {{warehouse.ObjRef(\"Temp_tbl_a\")}});'\n    model_spec:\n      - # rest of model specs go here\n```\n\n## Use Amazon S3 bucket as input\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> This is an experimental feature.\n\nIf you store data in your Amazon S3 bucket in a CSV file format, you can use it as an input for the Profiles models. The S3 URI path must be specified in the `app_defaults.s3`:\n\n```\nname: s3_table\ncontract:\n  is_optional: false\n  is_event_stream: true\n  with_entity_ids:\n    - user\n  with_columns:\n    - name: insert_ts\n      datatype: timestamp\n    - name: num_a\n      datatype: integer\napp_defaults:\n  s3: \"s3://bucket-name/prefix/example.csv\"\n  occurred_at_col: insert_ts\n  ids:\n    - select: \"id1\"\n      type: test_id\n      entity: user\n    - select: \"id2\"\n      type: test_id\n      entity: user\n```\n\nEnsure that the CSV file follows the standard format with the first row as the header containing column names, for example:\n\n```\nID1,ID2,ID3,INSERT_TS,NUM_A\na,b,ex,2000-01-01T00:00:01Z,1\nD,e,ex,2000-01-01T00:00:01Z,3\nb,c,ex,2000-01-01T00:00:01Z,2\nNULL,d,ex,2000-01-01T00:00:01Z,4\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Note that:\n> \n> *   To escape comma (`,`) from any cell of the CSV file, enclose that cell with double quotes `\" \"` .\n> *   Double quotes (`\" \"`) enclosing a cell are ignored.\n\nFollow the below steps to grant PB the required permissions to access the file in S3 Bucket:\n\n### Private S3 bucket\n\nAdd `region`, [`access key id`](#generate-access-key-id-and-secret-access-key), [`secret access key`](#generate-access-key-id-and-secret-access-key), and [`session token`](#generate-session-token) in your `siteconfig` file so that PB can access the private bucket. By default, the region is set to `us-east-1` unless specified otherwise.\n\n```\naws_credential:\n    region: us-east-1\n    access_key: **********\n    secret_access_key: **********\n    session_token: **********\n```\n\n#### Generate `access key id` and `secret access key`\n\n1.  Open the AWS IAM console in your AWS account.\n2.  Click **Policies**.\n3.  Click **Create policy**.\n4.  In the Policy editor section, click the JSON option.\n5.  Replace the existing JSON policy with the following policy and replace the <bucket\\_name> with your actual bucket name:\n\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetObject\",\n                \"s3:GetObjectVersion\"\n            ],\n            \"Resource\": \"arn:aws:s3:::<bucket_name>/*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:ListBucket\",\n                \"s3:GetBucketLocation\"\n            ],\n            \"Resource\": \"arn:aws:s3:::<bucket_name>\",\n            \"Condition\": {\n                \"StringLike\": {\n                    \"s3:prefix\": [\n                        \"*\"\n                    ]\n                }\n            }\n        }\n    ]\n}\n```\n\n6.  Click **Review policy**.\n7.  Enter the policy name. Then, click **Create policy** to create the policy.\n\nFurther, create an IAM user by following the below steps:\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> An IAM user requires the following permissions on an S3 bucket and folder to access files in the folder (and sub-folders):\n> \n> *   s3:GetBucketLocation\n> *   s3:GetObject\n> *   s3:GetObjectVersion\n> *   s3:ListBucket\n\n1.  In AWS IAM console, Click **Users**.\n2.  Click **Create user**.\n3.  Enter a name for the user.\n4.  Select Programmatic access as the access type, then click **Next: Permissions**.\n5.  Click **Attach existing policies directly**, and select the policy you created earlier. Then click **Next**.\n6.  Review the user details, then click **Create user**.\n7.  Copy the access key ID and secret access key values.\n\n#### Generate `session token`\n\n1.  Use the AWS CLI to create a named profile with the AWS credentials that you copied in the previous step.\n2.  To get the session token, run the following command:\n\n```\n $ aws sts get-session-token --profile <named-profile>\n```\n\nSee [Snowflake](https://docs.snowflake.com/en/user-guide/data-load-s3-config-aws-iam-user), [Redshift](https://docs.aws.amazon.com/redshift/latest/dg/copy-usage_notes-access-permissions.html), and [Databricks](https://docs.databricks.com/en/ingestion/copy-into/generate-temporary-credentials.html) for more information.\n\n### Public S3 Bucket\n\nYou **must** have the following permissions on the S3 bucket and folder to access files in the folder (and sub-folders):\n\n*   s3:GetBucketLocation\n*   s3:GetObject\n*   s3:GetObjectVersion\n*   s3:ListBucket\n\nYou can use the following policy in your bucket to grant the above permissions:\n\n1.  Go to the **Permissions** tab of your S3 bucket.\n2.  Edit bucket policy in **Permissions** tab and add the following policy. Replace the <bucket\\_name> with your actual bucket name:\n\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": \"*\",\n            \"Action\": [\n                \"s3:GetObject\",\n                \"s3:GetObjectVersion\"\n            ],\n            \"Resource\": \"arn:aws:s3:::<bucket_name>/*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": \"*\",\n            \"Action\": [\n                \"s3:ListBucket\",\n                \"s3:GetBucketLocation\"\n            ],\n            \"Resource\": \"arn:aws:s3:::<bucket_name>\"\n        }\n    ]\n}\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> In Redshift, you additionally need to set an IAM role as **default** for your cluster, unless access keys are provided. It is necessary because more than one IAM role can be associated with the cluster, and Redshift needs explicit permission granted through an IAM role to access the S3 bucket (Public or Private).\n> \n> Follow [Redshift Documentation](https://docs.aws.amazon.com/redshift/latest/mgmt/default-iam-role.html#set-default-iam) for setting an IAM role as default.\n\n## Use CSV file as input\n\nAn input file (`models/inputs.yaml`) contains details of input sources such as tables, views, or CSV files along with column name and SQL expression for retrieving values.\n\nYou can read data from a CSV file by using `csv: <path_to_filename>` under `app_defaults` in the input specs. CSV data is loaded internally as a single SQL select query, making it useful for seeding tests.\n\nA sample code is as shown:\n\n```\n    app_defaults:\n      csv: \"../common.xtra/Temp_tbl_a.csv\"\n      # remaining syntax is same for all input sources\n```\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> RudderStack does not support CSV files with more than a few hundred rows.\n\n## Filter data\n\nYou can filter out any data by using the `filters` field in your projects file:\n\nFor example, if you want to exclude all the blacklisted email addresses, you can create an input model (for example, `csv_email_blacklist`) with CSV file as a source, that contains all such email addresses:\n\n```\nid_types:\n  - name: email\n    filters:\n      - type: exclude\n        sql:\n          select: email\n          from: inputs/csv_email_blacklist\n```\n\nAnother example, if you want to exclude all the user\\_ids, you can create an SQL model (for example, `sql_exclusion_model`) that contains a specific logic to enlist all such IDs:\n\n```\nid_types:\n  - name: user_id\n    filters:\n      - type: exclude\n        sql:\n          select: user_id\n          from: inputs/models/sql_exclusion_model\n```\n\n## Associate SSH key to Git project\n\nTo add public SSH key to your Git project:\n\n1.  Open your Profile project’s Git repository in the browser and click **Settings**.\n2.  Click **SSH Keys**.\n3.  Assign a name (say `Sample Profiles Key`) and paste the key generated from the RudderStack dashboard or a public-key generated using CLI.\n4.  Click **Add Key**.\n\nFor more information, see:\n\n*   [GitHub documentation](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/managing-deploy-keys#deploy-keys)\n*   [GitLab documentation](https://docs.gitlab.com/ee/user/project/deploy_keys/#create-a-project-deploy-key)\n*   [BitBucket documentation](https://confluence.atlassian.com/bitbucketserver/ssh-access-keys-for-system-use-776639781.html)\n\n## Use private Git repos via CLI\n\nFollow these steps:\n\n1.  [Generate the SSH Key](https://git-scm.com/book/en/v2/Git-on-the-Server-Generating-Your-SSH-Public-Key).\n2.  [Associate the SSH Key to your Git Project](#associate-ssh-key-to-git-project).\n3.  Add private keys as credentials in the `siteconfig.yaml` file:\n\n```\ngitcreds:\n  - reporegex: git@<provider-host>:<org-name>/*\n    key: |\n    -----BEGIN OPENSSH PRIVATE KEY-----\n    b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEb..........\n    -----END OPENSSH PRIVATE KEY-----    \n```\n\n## View model dependencies\n\nYou can create a DAG to see all the model dependencies, that is, how a model is dependent on other models by using any one of the following commands:\n\n`pb show dataflow`  \nOR  \n`pb show dependencies`\n\nFurther, you can use the `pb show models` command to view information about the models in your project. See [show](https://www.rudderstack.com/docs/profiles/cli-user-guide/commands/#show) command for more information.\n\n## Multi-version support\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> This feature is supported for the Profiles versions 0.10.8, 0.11.5, and 0.12.0 onwards.\n\nYou can constraint your Profiles project to run only on specific version(s) by specifying it in the `pb_project.yaml` file, under `python_requirements` key. For example, use the below snippet to run your project on v0.10.8:\n\n```\npython_requirements:\n  - profiles-rudderstack==0.10.8\n```\n\nUse the below snippet to stay on any minor version between 0.12.0 and 0.13.0. If a new minor version is released, your project will be auto-migrated to that version:\n\n```\npython_requirements:\n  - profiles-rudderstack>=0.12.0,<0.13.0\n```\n\nIf you do not specify any version in `pb_project.yaml`, the latest Profiles version is used by default. The version constraints follow the same syntax as those of [Python dependency specifiers](https://packaging.python.org/en/latest/specifications/dependency-specifiers/).\n\nMake sure that the version of Profiles project is the same in your environment and the `pb_project.yaml` file. Otherwise, RudderStack will throw an error.\n\n## Reuse models output\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> This is an experimental feature.\n\nYou can define the `time_grain` parameter for a model to ensure the model runs only once in that time period. It lets you reuse the output material of that model within the time period, preventing unnecessary recalculations⁠.\n\nFor example, if you set the `time_grain` value for an ID stitcher model to a `day` and run the feature table model (based on the ID stitcher) multiple times during a day, the feature table model will reuse the ID stitcher’s output to compute the features. This will save a large amount of time and computations whenever you run the feature table model within that day.\n\nSimilarly, you can choose to run a feature such as `weekly_spends` only once a week, or `last_active_day` on a daily basis.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Setting `time_grain` parameter does not mean that the model will run automatically at the specified time period. It just ensures that the model runs only once during that time period and its outputs are reused within that duration. To schedule your project run, you must use the RudderStack dashboard.\n> \n> For example, if `time_grain` for a model is set to a `week`, its outputs will be reused throughout the week and running it twice within the week won’t change its results.\n\nYou can define the `time_grain` parameter in the `profiles.yaml` file of your project:\n\n```\nmodels:\n  - name: user_id_graph\n    model_type: id_stitcher\n    model_spec:\n      entity_key: user\n      time_grain: \"hour\"\n      materialization:\n        run_type: incremental\n      edge_sources:\n        - from: inputs/rsIdentifies\n        - from: inputs/rsTracks\nvar_groups:\n  - name: user_daily_vars\n    time_grain: \"day\"\n    entity_key: user\n    vars:\n      - entity_var:\n          name: days_since_last_seen\n          select: \"{{macro_datediff('{{user.Var(\\\"max_timestamp\\\")}}')}}\"\n  - name: user_weekly_vars\n    time_grain: \"week\"\n    entity_key: user\n    vars:\n      - entity_var:\n         name: weekly_amt_spent\n         select: sum(total_price_usd) - coalesce(sum(total_price_usd_order_cancelled), 0)\n         from: models/rsOrderCreatedOrderCancelled\n         where: \"{{macro_datediff_n('timestamp','7')}}\"\n```\n\nIn the above example, suppose you schedule your Profiles project to run every hour. The output for `user_id_graph` model will be computed every hour, the output for `user_daily_vars` will be computed once a day, and the output for `user_weekly_vars` will be computed once a week.\n\nFor a default ID stitcher model, you can define the `time_grain` value in the `entities` section as shown below:\n\n```\nentities:\n  - name: user\n    id_types:\n      - test_id\n      - exclude_id\n    default_id_stitcher:\n      time_grain: \"day\"\n```\n\n#### Supported values\n\nYou can set the following values for the `time_grain` field:\n\n*   `tick`: Considers all the data up to the current moment (default value).\n*   `10minutes`: Considers data up to the last 10-minute interval.\n*   `hour`: Considers data up to the end of the previous hour.\n*   `day`: Considers data up to the end of the previous day.\n*   `week`: Considers data up to the end of the previous week.\n*   `month`: Considers data up to the end of the previous month.\n*   `year`: Considers data up to the end of the previous year.\n\n## Enable/disable model run\n\nWhen you have various interdependent models, you might want to run only the required ones for a specific output.\n\nRudderStack provides the `enable_status` parameter which lets you specify whether to run a model or not. Using it, you can exclude the unnecessary models from the execution process. You can assign the following values to the `enable_status` field in your `pb_project.yaml` file:\n\n*   `good_to_have` (default): It will not execute or cause a failure when it is not possible to execute the model.\n*   `must_have`: It will cause a failure when is not possible to execute the model.\n*   `only_if_necessary`: The model gets disabled if it has no dependency on the final output. It is the default value for a default ID stitcher model and ensures that the model is not executed if it is not required.\n*   `disabled`: The model gets disabled and is not executed.\n\nA sample `pb_project.yaml` file with `enable_status` parameter:\n\n```\nname: app_project\nschema_version: 69\nconnection: test\nmodel_folders:\n  - models\nentities:\n  - name: user\n    id_types:\n      - user_id\n      - anonymous_id\n    default_id_stitcher:\n      validity_time: 24h # 1 day\n      materialization:\n        run_type: incremental\n        enable_status: good_to_have\n      incremental_timedelta: 12h # half a day\n\nid_types:\n  - name: user_id\n    filters:\n      - type: include\n        regex: \"([0-9a-z])*\"\n      - type: exclude\n        value: \"\"\n  - name: anonymous_id\n```\n\n**Use-case**\n\nConsider a scenario where an ID stitcher model (`ids`) is dependent on `tbl_a` and `tbl_b`, and a feature table model (`ft1`) depends on the ID Stitcher (`ids`) and an input model `tbl_a`.\n\n*   If the ID stitcher and feature table models are marked as `only_if_necessary`, there is no need to execute either of them. However, if the feature table is marked as `good_to_have`/`must_have`, then all the models must run to create final output.\n*   If `tbl_a` is set to `disabled`, the ID stitcher and feature table will not run. If either of them is marked as `must_have`, the project will run into an error.\n\n## Window functions\n\nA window function operates on a window (group) of related rows. It performs calculation on a subset of table rows that are connected to the current row in some way. The window function has the ability to access more than just the current row in the query result.\n\nThe window function returns one output row for each input row. The values returned are calculated by using values from the sets of rows in that window. A window is defined using a window specification, and is based on three main concepts:\n\n*   Window partitioning, which forms the groups of rows (`PARTITION BY` clause)\n*   Window ordering, which defines an order or sequence of rows within each partition (`ORDER BY` clause)\n*   Window frames, which are defined relative to each row to further restrict the set of rows (`ROWS` specification). It is also known as the frame clause.\n\n**Snowflake** does not enforces users to define the cumulative or sliding frames, and considers `ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING` as the default cumulative window frame. However, you can override this by defining the frame manually.\n\nOn the **Redshift** aggregate window function list given below, specify the `frame_clause` while using any function from the list:\n\n*   `AVG`\n*   `COUNT`\n*   `CUME_DIST`\n*   `DENSE_RANK`\n*   `FIRST_VALUE`\n*   `LAG`\n*   `LAST_VALUE`\n*   `LEAD`\n*   `LISTAGG`\n*   `MAX`\n*   `MEDIAN`\n*   `MIN`\n*   `NTH_VALUE`\n*   `PERCENTILE_CONT`\n*   `PERCENTILE_DISC`\n*   `RATIO_TO_REPORT`\n*   `STDDEV_POP`\n*   `STDDEV_SAMP` (synonym for `STDDEV`)\n*   `SUM`\n*   `VAR_POP`\n*   `VAR_SAMP` (synonym for `VARIANCE`)\n\nIn the Redshift ranking window functions given below, **do not** specify the `frame_clause` while using any function from the list:\n\n*   `DENSE_RANK`\n*   `NTILE`\n*   `PERCENT_RANK`\n*   `RANK`\n*   `ROW_NUMBER`\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Use `frame_clause` carefully when using a window function. While It is not very critical for Snowflake, using it incorrectly in Redshift can lead to errors.\n\nExample of using `frame_clause`:\n\n```\n- entity_var:\n    name: first_num_b_order_num_b\n    select: first_value(tbl_c.num_b) # Specify frame clause as aggregate window function is used\n    from: inputs/tbl_c\n    default: -1\n    where: tbl_c.num_b >= 10\n    window:\n        order_by:\n        - tbl_c.num_b desc\n        frame_clause: ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n- entity_var:\n    name: first_num_b_order_num_b_rank\n    select: rank() # DO NOT specify frame clause as ranking window function is used\n    window:\n        order_by:\n        - first_num_b_order_num_b asc\n```\n\nNote how `frame_clause` is specified in first `entity_var` and not in the second one.\n\n## Macros\n\nMacros are the reusable functions that encapsulate complex processing logic directly within the SQL expression. You can create macros to perform computations and use them in multiple models. For example:\n\n```\nmacros:\n  - name: subtract_range\n    inputs:\n      - first_date\n      - second_date\n    value: \"{{first_date}} - {{second_date}}\"\n  - name: multiplyBy10_add\n    inputs:\n      - first_number\n      - second_number\n    value: \"{{first_number}} * 10 + {{second_number}}\"\n```\n\nYou can create a file (say `macros.yaml`) file under the `models` folder and refer them using the macro name in the `profiles.yaml` file:\n\n```\n- entity_var:\n    name: days_since_first_sale\n    select: \"{{ subtract_range('{{user.Var(\\\"first_sale_time\\\")}}') }}\"\n```\n\n| Field | Data type | Description |\n| --- | --- | --- |\n| `name` | String | Name to uniquely identify the macro. |\n| `inputs` | List | Defines the input variables to be used by the macro function. |\n| `value` | String | Contains the reusable function in the form of a SQL expression. Any reference to the inputs must be encapsulated within double curly brackets. |\n\nSee a sample [Profiles library project](https://github.com/rudderlabs/profiles-stripe-features) that creates user features from Stripe tables using Macros.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Additional Concepts | RudderStack Docs",
    "description": "Additional concepts related to Profiles like packages, best practices, partial feature tables, etc.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/data-governance/consent-management/onetrust/android/",
    "markdown": "# OneTrust Consent Management for Android\n\nIntegrate the RudderStack Android SDK with OneTrust.\n\n* * *\n\n*     3 minute read  \n    \n\nThe [RudderStack Android SDK](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-android-sdk/) lets you specify the user’s consent during initialization.\n\nThis guide lists the steps to develop a consent interceptor for the Android SDK and use the interceptor to initialize the SDK once the user gives their consent.\n\n## Overview\n\nThe consent management is designed to be a filter for the event destinations and the natively added factories. Since the SDK initializes the native integration factories during the startup, you must capture the user’s consent to the cookie categories by then.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> You can add only one consent filter to the Android SDK.\n\nFor filtering, RudderStack uses the `getConsentStatusForGroupId` method from the OneTrust SDK.\n\n## Installing OneTrust consent\n\nThis setup assumes the [Android SDK](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-android-sdk/#installing-the-sdk) and the [OneTrust SDK](https://developer.onetrust.com/onetrust/docs/sdk-overview) are already added to your application.\n\n1.  Add OneTrust Consent Filter to your `build.gradle` (module level).\n\n```\ndependencies {\n    // add other dependencies\n    ...\n    implementation 'com.onetrust.cmp:native-sdk:202301.2.0.0'\n    implementation ('com.rudderstack.android.sdk:core:1.12.0')\n    implementation ('com.rudderstack.android.consentfilter:onetrustconsentfilter:1.1.0')\n    ...\n}\n```\n\n2.  Move the RudderStack initialization consent callback. The following snippet shows a sample application file highlighting the initialization:\n\n```\nclass CustomApplication : Application() {\n    var _rudderClient: RudderClient? = null;\n    val rudderClient\n        get() = _rudderClient\n    private val oneTrustEventListener = object : OTEventListener() {\n        override fun onShowBanner(p0: OTUIDisplayReason?) {\n        }\n        override fun onHideBanner() {\n        }\n        override fun onBannerClickedAcceptAll() {\n            createRudderClientWithOneTrust()\n        }\n        override fun onBannerClickedRejectAll() {\n            createRudderClientWithOneTrust()\n        }\n        override fun onShowPreferenceCenter(p0: OTUIDisplayReason?) {\n        }\n        override fun onHidePreferenceCenter() {\n        }\n        override fun onPreferenceCenterAcceptAll() {\n            createRudderClientWithOneTrust()\n        }\n        override fun onPreferenceCenterRejectAll() {\n            createRudderClientWithOneTrust()\n        }\n        override fun onPreferenceCenterConfirmChoices() {\n            createRudderClientWithOneTrust()\n        }\n        override fun onShowVendorList() {}\n        override fun onHideVendorList() {}\n        override fun onVendorConfirmChoices() {\n        }\n        override fun allSDKViewsDismissed(p0: String?) {}\n        override fun onVendorListVendorConsentChanged(p0: String?, p1: Int) {\n        }\n        override fun onVendorListVendorLegitimateInterestChanged(p0: String?, p1: Int) {}\n        override fun onPreferenceCenterPurposeConsentChanged(p0: String?, p1: Int) {\n        }\n        override fun onPreferenceCenterPurposeLegitimateInterestChanged(p0: String?, p1: Int) {}\n    }\n    internal val otPublishersHeadlessSDK by lazy { OTPublishersHeadlessSDK(this) }\n    override fun onCreate() {\n        super.onCreate()\n        setupOneTrust()\n    }\n    internal fun setupOneTrust() {\n\t\t// set up one trust,\n        // uncomment the following line and pass the credentials\n\t\t// otPublishersHeadlessSDK.startSDK()\n        otPublishersHeadlessSDK.addEventListener(oneTrustEventListener)\n    }\n    private fun createRudderClientWithOneTrust() {\n        _rudderClient = RudderClient.getInstance(\n            this,\n            WRITE_KEY,\n            RudderConfig.Builder()\n                .withDataPlaneUrl(DATA_PLANE_URL)\n                .withTrackLifecycleEvents(true)\n                .withRecordScreenViews(false)\n                .withConsentFilter(RudderOneTrustConsentFilter(otPublishersHeadlessSDK))\n                .build()\n            )\n    }\n    private val otSdkParams\n        get() = OTSdkParams.SdkParamsBuilder.newInstance()\n            .build()\n}\n```\n\n## Creating a custom consent filter\n\nTo create a custom consent filter, follow these steps:\n\n1.  Create a new Android library project.\n2.  Add the following to the `dependencies` section in the module-level `build.gradle` file:\n\n```\ndependencies {\n\t   // add other dependencies\n\t\t...\n    compileOnly 'com.rudderstack.android.sdk:core:1.12.0'\n\t\t...\n}\n```\n\n3.  Create a class to implement `RudderConsentFilterWithCloudIntegration`:\n\n```\npublic final class MyConsentFilter implements RudderConsentFilterWithCloudIntegration {\n\t@Override\n\tpublic Map<String, Boolean> getConsentCategoriesMap() {\n\t\t// return the category id to consent map.\n\t\t// The map should have the category id as key and true if consented,\n\t\t// false otherwise\n\t\t// Rudderstack SDK will filter out the destinations corresponding to\n\t\t// categories that are not consented.\n\t}\n}\n```\n\n4.  Attach `MyConsentFilter` to the RudderStack Android SDK similar to the OneTrust consent filter:\n\n```\n_rudderClient = RudderClient.getInstance(\n            this,\n            WRITE_KEY,\n            RudderConfig.Builder()\n                // other methods\n                .withConsentFilter(MyConsentFilter())\n                .build()\n            )\n```\n\n## Additional settings for cloud mode\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> RudderStack supports OneTrust integration in cloud mode from Android SDK v1.12.0 and above.\n\nYou can specify your OneTrust cookie categories when sending events from your Android source via the [cloud mode](https://www.rudderstack.com/docs/destinations/rudderstack-connection-modes/#cloud-mode). Follow these steps:\n\n1.  [Set up your Android source](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-android-sdk/#sdk-setup-requirements) in the RudderStack dashboard.\n2.  Connect it to a new or existing destination.\n3.  In the destination’s connection settings, enter the OneTrust category ID in the **Category ID** field:\n\n[![OneTrust category ID in consent settings](https://www.rudderstack.com/docs/images/data-governance/consent-management/onetrust-category-id.webp)](https://www.rudderstack.com/docs/images/data-governance/consent-management/onetrust-category-id.webp)\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> When sending events via the cloud mode, make sure you enter the category ID corresponding to the OneTrust cookie category. Specifying the category name will not work.\n> \n> You can find the category IDs in your OneTrust dashboard under **Preference & Consent Management** > **Cookie Compliance** > **Categorizations** > **Categories**.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "OneTrust Consent Management for Android | RudderStack Docs",
    "description": "Integrate the RudderStack Android SDK with OneTrust.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/data-governance/consent-management/ketch/",
    "markdown": "# Ketch Consent Management | RudderStack Docs\n\nIntegrate RudderStack with the Ketch consent management platform.\n\n* * *\n\n*     3 minute read  \n    \n\n[Ketch](https://www.ketch.com/platform/consent-and-preference-management) is a consent and preference management platform. It offers APIs and a robust infrastructure to ensure users’ privacy choices across internal and external systems.\n\nRudderStack’s [JavaScript SDK](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/) seamlessly integrates with the Ketch consent manager, letting you map Ketch’s consent purposes to RudderStack’s consent purposes. RudderStack, in turn, uses the consent information to turn user tracking on/off and sends data to the destinations accordingly.\n\n## Integration overview\n\nThis section explains how the [Ketch Smart Tag](https://developers.ketch.com/docs/ketch-smart-tag-overview) integration with RudderStack works.\n\n1.  Websites with the Ketch Smart Tag present a consent experience for users to decide the consent purposes depending on the applicable regulatory framework.\n2.  User consent is stored in the Ketch backend and cached in the user’s browser.\n3.  RudderStack’s JavaScript SDK fetches the consented purposes and Ketch consent purpose mappings specified in the RudderStack dashboard.\n4.  Depending on the settings, the JavaScript SDK filters the destinations to load on the website.\n5.  If the user maps more than one consent purpose to a destination in the dashboard, the SDK forwards the events to the destination if one of the consent purposes is granted.\n\n### Limitations\n\nThe Ketch consent management integration supports only the following destinations (in both [cloud mode](https://www.rudderstack.com/docs/destinations/rudderstack-connection-modes/#cloud-mode) and [device mode](https://www.rudderstack.com/docs/destinations/rudderstack-connection-modes/#device-mode):\n\n*   [Customer.io](https://www.rudderstack.com/docs/destinations/streaming-destinations/customer.io/)\n*   [Facebook Pixel](https://www.rudderstack.com/docs/destinations/streaming-destinations/fb-pixel/)\n*   [Google Analytics](https://www.rudderstack.com/docs/destinations/streaming-destinations/google-analytics-ga/)\n*   [Google Analytics 4](https://www.rudderstack.com/docs/destinations/streaming-destinations/google-analytics-4/)\n*   [Mixpanel](https://www.rudderstack.com/docs/destinations/streaming-destinations/mixpanel/)\n*   [Snap Pixel](https://www.rudderstack.com/docs/destinations/streaming-destinations/snap-pixel/)\n*   [Snowflake](https://www.rudderstack.com/docs/destinations/warehouse-destinations/snowflake/)\n*   [TikTok Ads](https://www.rudderstack.com/docs/destinations/streaming-destinations/tiktok-ads/)\n\n## Set up Ketch integration\n\nThe following steps highlight the JavaScript SDK integration with Ketch Smart Tag:\n\n### Step 1: Configure Ketch Smart Tag\n\n1.  Create a [Ketch account](https://app.ketch.com/registration/register?planId=plan_ketch_free&_ga=2.14359731.569158512.1689747187-2041817523.1689747186).\n2.  Create and deploy the Ketch Smart Tag. See [Ketch documentation](https://docs.ketch.com/hc/en-us/articles/5922960126615-Deploying-the-Ketch-Smart-Tag-with-Google-Tag-Manager) or their [video tutorial](https://docs.ketch.com/hc/en-us/articles/7166943954967-Video-Tutorial-How-to-Create-a-Property-Deploy-the-Ketch-Smart-Tag) for more information.\n\n### Step 2: Specify Ketch consent purposes in RudderStack\n\nTo enable Ketch for your JavaScript source, specify the Ketch consent purposes (defined in [Step 1](#step-1-configure-ketch-smart-tag)) for each destination connected to the source in RudderStack.\n\nThe following image highlights a consent purpose created in the Ketch dashboard:\n\n[![Ketch consent purposes](https://www.rudderstack.com/docs/images/event-stream-sources/ketch-consent-purposes.webp)](https://www.rudderstack.com/docs/images/event-stream-sources/ketch-consent-purposes.webp)\n\nThe Ketch consent purpose mapped in the RudderStack dashboard:\n\n[![Ketch consent mapping in RudderStack dashboard](https://www.rudderstack.com/docs/images/event-stream-sources/rudderstack-ketch-consent-mapping.webp)](https://www.rudderstack.com/docs/images/event-stream-sources/rudderstack-ketch-consent-mapping.webp)\n\n### Step 3: Set up your website\n\nPlace the scripts in your web page’s `<head>` section in the following sequence:\n\n1.  Place the Ketch script. You can get the script by going to your Ketch dashboard and navigating to **Experience Server** > **Properties**. Select your Ketch Smart Tag and click **Export Code** to get the script. For more information, see [Ketch documentation](https://developers.ketch.com/docs/web-implementation#tag-deployment).\n\nThe following snippet highlights a sample script:\n\n```\n<script>\n  ! function() {\n    window.semaphore = window.semaphore || [], window.ketch = function() {\n      window.semaphore.push(arguments)\n    };\n    var e = new URLSearchParams(document.location.search),\n      o = e.has(\"property\") ? e.get(\"property\") : \"<your-ketch-tag>\",\n      n = document.createElement(\"script\");\n    n.type = \"text/javascript\", n.src = \"https://global.ketchcdn.com/web/v2/config/xxxxxxx/\".concat(o, \"/boot.js\"), n.defer = n.async = !0, document.getElementsByTagName(\"head\")[0].appendChild(n)\n  }();\n</script>\n```\n\n2.  Place the [RudderStack SDK installation snippet](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/installation/#using-cdn).\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Make sure to remove the `load()` function from the script as it needs to be loaded conditionally.\n\n3.  Call the SDK `load` API as shown below:\n\n```\n<script>\nfunction getCookie(key) {\n  return window.document.cookie.split('; ').reduce((r, v) => {\n    const parts = v.split('=')\n    return parts[0] === key ? decodeURIComponent(parts[1]) : r\n  }, '')\n}\n\nif (getCookie('_ketch_consent_v1_')) {\n  rudderanalytics.load(WRITE_KEY, DATA_PLANE_URL, {\n    cookieConsentManager: {\n      ketch: {\n        enabled: true\n      }\n    },\n    //other options\n  });\n} else {\n  // waiting for consent\n  ketch('once', 'hideExperience', () => {\n    rudderanalytics.load(WRITE_KEY, DATA_PLANE_URL, {\n      cookieConsentManager: {\n        ketch: {\n          enabled: true\n        }\n      },\n      //other options\n    });\n  });\n}\n</script>\n```\n\nReplace `WRITE_KEY` and `DATA_PLANE_URL` in the above snippet with their actual values.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Note the following:\n> \n> *   If user updates their consent settings, refresh the web page for the changes to take effect in the SDK.\n> *   For [JavaScript SDK v3](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/), the `load` option for configuring consent management has changed. See [Breaking Changes](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/breaking-changes/) for more information.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Ketch Consent Management | RudderStack Docs",
    "description": "Integrate RudderStack with the Ketch consent management platform.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/data-governance/consent-management/onetrust/javascript/",
    "markdown": "# OneTrust Consent Management for Web\n\nIntegrate the RudderStack JavaScript SDK with the OneTrust SDK.\n\n* * *\n\n*     5 minute read  \n    \n\nThe JavaScript SDK seamlessly integrates with the OneTrust SDK. It lets you map the OneTrust cookie/consent groups to RudderStack’s consent purposes. RudderStack, in turn, uses this consent information to enable/disable tracking and sending the data.\n\n## How the OneTrust-JavaScript SDK integration works\n\nWhenever a user starts browsing a website, OneTrust pops up a modal to take consent from the user. This modal contains a list of cookie groups representing the GDPR consent purposes that the user needs to decline or accept.\n\nThe JavaScript SDK fetches these consented groups and the destination (OneTrust category) mappings specified in the RudderStack dashboard. Depending on these settings, the SDK filters the destinations.\n\n## Setting up the integration\n\nThe following sections highlight the steps to set up the JavaScript SDK integration with OneTrust.\n\n### Prerequisites\n\nYou must have a [OneTrust account](https://my.onetrust.com/s/login/SelfRegister?language=en_US&startURL=%2Fs%2F%3Ft%3D1587743884774) with a subscription to their [Cookie Consent](https://www.onetrust.com/products/cookie-consent/) product.\n\n### Step 1: Configuring OneTrust\n\nFollow these steps to configure OneTrust for your website/web app:\n\n1.  Navigate to **Websites** > **Add Websites**.\n2.  Enter your top-level website URL to scan and click **Start Scan**.\n3.  Go to the **Categorizations** tab and define the new categories or modify the existing ones, as required.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The categories should be associated with/attached to at least one cookie to be displayed in your RudderStack dashboard’s OneTrust modal.\n\n4.  Go to the **Scripts** tab, select the domain to be published and click **Publish** to publish the script.\n\n### Step 2: Specifying the OneTrust Cookie Categories\n\nYou need to enable OneTrust for your JavaScript source. To do so, specify the consent category IDs defined in OneTrust (**Step 1**) for each destination connected to that source.\n\n[![OneTrust category ID in consent settings](https://www.rudderstack.com/docs/images/data-governance/consent-management/onetrust-category-id.webp)](https://www.rudderstack.com/docs/images/data-governance/consent-management/onetrust-category-id.webp)\n\n### Step 3: Setting up your website\n\n1.  Load the OneTrust script that you published in your web app in [Step 1](#step-1-configuring-onetrust):\n\n```\n<!-- OneTrust Cookies Consent Notice start for samplewebsite.com -->\n<script\n        src=\"https://cdn.cookielaw.org/scripttemplates/otSDKStub.js\"\n        type=\"text/javascript\"\n        charset=\"UTF-8\"\n        data-domain-script=\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\" >\n</script>\n<script type=\"text/javascript\">\n        // Required OneTrust callback\n        function OptanonWrapper() { }\n</script>\n<!-- OneTrust Cookies Consent Notice end for samplewebsite.com -->\n```\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> You **must** first load the OneTrust script and then load the JavaScript SDK **only if** the user provides their consent. This is because the SDK determines whether to send events to a destination based on the user’s consent. If a user denies consent in OneTrust, then Rudderstack does not load the destination SDKs or send any events to them.\n\n2.  One way to load the JavaScript SDK after the user provides the consent is to modify the `OptanonWrapper()` callback function provided by OneTrust. You also need to add the [`consentManagement`](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/load-js-sdk/#loading-options) option in the `load()` call and set `provider` as `oneTrust`:\n\n```\nfunction OptanonWrapper() {\n  if (window.OneTrust.IsAlertBoxClosed()) {\n    // Load the SDK\n    rudderanalytics.load(WRITE_KEY, DATA_PLANE_URL, {\n      consentManagement: {\n        enabled: true,\n        provider: \"oneTrust\"\n      },\n      // other options\n    });\n  }\n}\n```\n\n```\nfunction OptanonWrapper() {\n  if (window.OneTrust.IsAlertBoxClosed()) {\n    // Load the SDK\n    rudderanalytics.load(WRITE_KEY, DATA_PLANE_URL, {\n      cookieConsentManager: {\n        oneTrust: {\n          enabled: true\n        }\n      },\n      //other options\n    });\n  }\n}\n```\n\nReplace the [write keyThe write key (or source write key) is a unique identifier for your source. RudderStack uses this key to send events from a source to the specified destination.](https://www.rudderstack.com/docs/resources/glossary/#write-key) and [data plane URLThe data plane URL is the location where events are routed and sent to the RudderStack backend for processing. You can find this URL in the home page of your RudderStack dashboard.](https://www.rudderstack.com/docs/resources/glossary/#data-plane-url) in the snippet with their actual values.\n\nFor [JavaScript SDK v3](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/), the `load` option for configuring consent management has changed. See [Breaking Changes](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/breaking-changes/) for more information.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> If a user updates the consent settings, you must refresh the web page for the changes to take effect in the SDK.\n\nOnce completed, RudderStack reads the consented categories and filters the destinations accordingly.\n\n## Additional settings for cloud mode\n\nYou can specify your OneTrust cookie categories when sending events from your JavaScript source via the [cloud mode](https://www.rudderstack.com/docs/destinations/rudderstack-connection-modes/#cloud-mode). Follow these steps:\n\n1.  [Set up your JavaScript source](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/quickstart/#prerequisites) in the RudderStack dashboard.\n2.  Connect it to a new or existing destination.\n3.  In the destination’s connection settings, enter the OneTrust category ID in the **Category ID** field:\n\n[![OneTrust category ID in consent settings](https://www.rudderstack.com/docs/images/data-governance/consent-management/onetrust-category-id.webp)](https://www.rudderstack.com/docs/images/data-governance/consent-management/onetrust-category-id.webp)\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> When sending events via cloud mode, make sure you enter the category ID corresponding to the OneTrust cookie category. **Specifying the category name will not work**.\n> \n> You can find the category IDs in your OneTrust dashboard under **Preference & Consent Management** > **Cookie Compliance** > **Categorizations** > **Categories**.\n\n## FAQ\n\n#### What happens if the JavaScript SDK is loaded before the OneTrust modal is closed?\n\nIn this case, the JavaScript SDK will not be able to capture the user consent. Hence, it will load all the connected destinations and all the events will flow through to them.\n\n#### Can I integrate the RudderStack JavaScript SDK with any other consent manager?\n\nIf you are using a consent manager other than OneTrust, you can configure the cookie categories to show on your website whenever a user visits.\n\nNext, you need to create an internal mapping between these cookie categories and the destinations configured in RudderStack. For example:\n\n*   Analytical cookie: Amplitude, Google Analytics\n*   Targeting cookie: Bing Ads, Google Ads\n*   Marketing cookie: Braze, Mailchimp, Customer.io\n\nWhen the user provides consent, you should fetch the consent (via the API or SDK provided by your consent manager) and filter the destinations depending on the consent. Once you have the list of destinations for which the user has provided consent, you can load the JavaScript SDK only for those destinations.\n\nFor example, if a user has provided consent for an analytical cookie, then you can load the JavaScript SDK as shown:\n\n```\nrudderanalytics.load(WRITE_KEY,DATA_PLANE_URL,{\n   integrations: {\n       All: false,\n       \"Amplitude\": true,\n       \"Google Analytics\": true\n       // only provide the destinations the user has provide consent for\n   }\n   // pass other initialization options\n});\n```\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "OneTrust Consent Management for Web | RudderStack Docs",
    "description": "Integrate the RudderStack JavaScript SDK with the OneTrust SDK.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/data-governance/consent-management/onetrust/ios/",
    "markdown": "# OneTrust Consent Management for iOS\n\nIntegrate the RudderStack iOS SDK with OneTrust.\n\n* * *\n\n*     3 minute read  \n    \n\nThe [RudderStack iOS SDK](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-ios-sdk/) lets you specify the user’s consent during initialization.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The RudderStack iOS SDK supports OneTrust consent management from version 1.9.0.\n\nThis guide lists the steps to develop a consent interceptor for the iOS SDK and use the interceptor to initialize the SDK once the user gives their consent.\n\n## Overview\n\nThe consent management is designed to be a filter for the event destinations and the natively added factories. Since the SDK initializes the native integration factories during the startup, you must capture the user’s consent to the cookie categories by then.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> You can add only one consent filter to the iOS SDK.\n\nFor filtering, RudderStack uses the `getConsentStatus(forCategory categoryId: String)` method from the OneTrust SDK.\n\n## Installing OneTrust consent\n\nThis setup assumes the [iOS SDK](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-ios-sdk/#installing-the-rudderstack-ios-sdk) and the [OneTrust SDK](https://developer.onetrust.com/onetrust/docs/sdk-overview) are already added to your application.\n\n1.  Install `RudderOneTrustConsentFilter` by adding the following line to your `Podfile`:\n\n```\npod 'RudderOneTrustConsentFilter', '~> 1.0.0'\n```\n\n2.  Import the iOS SDK:\n\n```\n@import RudderOneTrustConsentFilter;\n```\n\n```\nimport RudderOneTrustConsentFilter\n```\n\n3.  Finally, add the imports to your `AppDelegate` file under the `didFinishLaunchingWithOptions` method, as shown:\n\n```\n@interface AppDelegate ()<OTEventListener>\n\n@end\n\n- (BOOL)application:(UIApplication *)application didFinishLaunchingWithOptions:(NSDictionary *)launchOptions {\n    [[OTPublishersHeadlessSDK shared] startSDKWithStorageLocation:STORAGE_LOCATION domainIdentifier:DOMAIN_IDENTIFIER languageCode:@\"en\" params:nil loadOffline:NO completionHandler:^(OTResponse *response) {\n        if (response.status) {\n        \n        }\n    }];\n    \n    [[OTPublishersHeadlessSDK shared] addEventListener:self];\n}\n\n- (void)initializeRudderSDK {\n    RSConfigBuilder *builder = [[RSConfigBuilder alloc] init];\n    [builder withLoglevel:RSLogLevelDebug];\n    [builder withDataPlaneUrl:DATA_PLANE_URL];\n    [builder withConsentFilter:[[RudderOneTrustConsentFilter alloc] init]];\n\n    [RSClient getInstance:rudderConfig.WRITE_KEY config:builder.build];\n}\n\n- (void)onPreferenceCenterConfirmChoices {\n    [self initializeRudderSDK];\n}\n```\n\n```\nclass AppDelegate {\n    func application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -> Bool {\n        OTPublishersHeadlessSDK.shared.startSDK(\n            storageLocation: STORAGE_LOCATION,\n            domainIdentifier: DOMAIN_IDENTIFIER,\n            languageCode: \"en\"\n        ) { response in\n            if response.status {\n        \n            }\n        }\n        \n        OTPublishersHeadlessSDK.shared.addEventListener(self)\n    }\n    \n    func initializeRudderSDK() {\n        let builder: RSConfigBuilder = RSConfigBuilder()\n            .withLoglevel(RSLogLevelDebug)\n            .withDataPlaneUrl(DATA_PLANE_URL)\n            .withConsentFilter(RudderOneTrustConsentFilter())\n\n        RSClient.getInstance(rudderConfig.WRITE_KEY, config: builder.build())\n    }\n}\n\nextension AppDelegate: OTEventListener {\n    func onPreferenceCenterConfirmChoices() {\n        initializeRudderSDK()\n    }\n}\n```\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Make sure you load the SDK only if the user provides their consent.\n\n## Creating a custom consent filter\n\n1.  Create a `CustomConsentIFilter.h` file by extending `RSConsentFilter`:\n\n```\n#import <Foundation/Foundation.h>\n#import <Rudder/Rudder.h>\nNS_ASSUME_NONNULL_BEGIN\n@interface CustomConsentFilter : NSObject<RSConsentFilter>\n@end\nNS_ASSUME_NONNULL_END\n```\n\n2.  Create a `CustomConsentFilter.m` file.\n\n```\n#import \"CustomConsentFilter.h\"\n\n@implementation CustomConsentFilter\n\n- (NSDictionary <NSString *, NSNumber *> * __nullable)filterConsentedDestinations:(NSArray <RSServerDestination *> *)destinations {\n    NSDictionary <NSString *, NSNumber *> *filteredConsentedDestinations;\n    // Do someting\n    return filteredConsentedDestinations;\n}\n\n@end\n```\n\n1.  Create a `CustomConsentFilter` file by extending `RSConsentFilter`.\n\n```\n@objc\nopen class OneTrustInterceptor: NSObject, RSConsentFilter {\n    @objc\n    public override init() {\n        super.init()\n    }\n\n    public func filterConsentedDestinations(_ destinations: [RSServerDestination]) -> [String: NSNumber]? {\n        let filteredConsentedDestinations: [String: NSNumber]\n        // Your code\n        return filteredConsentedDestinations\n    }\n}\n```\n\n### Registering consent filter with iOS SDK\n\nYou can register `CustomConsentFilter` with the iOS SDK during its initialization, as shown:\n\n```\nRSConfigBuilder *builder = [[RSConfigBuilder alloc] init];\n[builder withLoglevel:RSLogLevelDebug];\n[builder withDataPlaneUrl:DATA_PLANE_URL];\n[builder withConsentInterceptor:[[CustomConsentFilter alloc] init]];\n[RSClient getInstance:WRITE_KEY config:builder.build];\n```\n\n```\nlet builder: RSConfigBuilder = RSConfigBuilder()\n    .withLoglevel(RSLogLevelDebug)\n    .withDataPlaneUrl(DATA_PLANE_URL)\n    .withConsentFilter(CustomConsentFilter())\nRSClient.getInstance(rudderConfig.WRITE_KEY, config: builder.build())\n```\n\n## Additional settings for cloud mode\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> RudderStack supports OneTrust integration in cloud mode from iOS SDK v1.12.0 onwards and `RudderOneTrustConsentFilter` 1.1.0.\n\nYou can specify your OneTrust cookie categories when sending events from your iOS source via the [cloud mode](https://www.rudderstack.com/docs/destinations/rudderstack-connection-modes/#cloud-mode). Follow these steps:\n\n1.  [Set up your iOS source](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-ios-sdk/#sdk-setup-requirements) in the RudderStack dashboard.\n2.  Connect it to a new or existing destination.\n3.  In the destination’s connection settings, enter the OneTrust category ID in the **Category ID** field:\n\n[![OneTrust category ID in consent settings](https://www.rudderstack.com/docs/images/data-governance/consent-management/onetrust-category-id.webp)](https://www.rudderstack.com/docs/images/data-governance/consent-management/onetrust-category-id.webp)\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> When sending events via the cloud mode, make sure you enter the category ID corresponding to the OneTrust cookie category. Specifying the category name will not work.\n> \n> You can find the category IDs in your OneTrust dashboard under **Preference & Consent Management** > **Cookie Compliance** > **Categorizations** > **Categories**.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)\n\n  \n\nThis site uses cookies to improve your experience. If you want to learn more about cookies and why we use them, visit our [cookie policy.](https://rudderstack.com/cookie-policy) We'll assume you're ok with this, but you can opt-out if you wish",
    "title": "OneTrust Consent Management for iOS | RudderStack Docs",
    "description": "Integrate the RudderStack iOS SDK with OneTrust.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/data-governance/tracking-plans/tracking-plan-spreadsheet/",
    "markdown": "# Tracking Plan Spreadsheet | RudderStack Docs\n\nConfigure tracking plans using RudderStack’s tracking plan spreadsheet.\n\n* * *\n\n*     8 minute read  \n    \n\nBy default, the tracking plan configuration is in JSON format. RudderStack’s [tracking plan spreadsheet](https://docs.google.com/spreadsheets/d/1QnCY3dbzyz2InB68W3AGIJshsuY3Zu8WA3AfMMxIzAQ/edit#gid=1810167975) is a no-code, spreadsheet representation of your tracking plan configuration. It lets you easily create or use an existing tracking plan.\n\nThis guide details the various options and spreadsheet settings to configure your tracking plan.\n\n## Get started\n\nTo use the tracking plan spreadsheet, go to the default [tracking plan spreadsheet](https://docs.google.com/spreadsheets/d/1QnCY3dbzyz2InB68W3AGIJshsuY3Zu8WA3AfMMxIzAQ/edit#gid=1810167975) and click **File** > **Make a copy** in the Google Sheets menu.\n\n## Spreadsheet overview\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The tracking plan spreadsheet uses the Google Sheets’ scripts functionality to integrate with the [Tracking plan API](https://www.rudderstack.com/docs/api/tracking-plan-api/).\n\nThe configuration settings for your tracking plan are listed in the **Homepage** and **Additional Features** tabs of the spreadsheet. They are linked to the actions listed in the **RudderStack Tracking Plan** menu in the Google Sheets top bar:\n\n[![tracking plan menu](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-menu.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-menu.webp)\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Note that:\n> \n> *   The tracking plan spreadsheet supports the Null, String, Number, Integer, Boolean, Array, and Object data types.\n> *   You can create, delete, or update the events and the associated properties. Once you upload the changes, RudderStack creates a new version of the tracking plan to keep track of your changes.\n\n## Create tracking plan from scratch\n\n1.  Enter the sheet name containing the tracking plan to upload.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> You can replicate the sheet in **Example Tracking Plan** tab and make necessary changes to it. Then, rename this tab and specify the name above.\n\n2.  Assign a name for this tracking plan. RudderStack creates a new tracking plan if a plan with this name does not exist.\n3.  Under **API Key Settings (Global)**, set your [**API Personal Access Token**](https://www.rudderstack.com/docs/dashboard-guides/personal-access-token/#generating-a-personal-access-token).\n4.  Specify the **Email** associated with your RudderStack workspace.\n5.  Click **RudderStack Tracking Plan** > **Upload Tracking Plan to RudderStack** in the top bar.\n6.  Verify if the tracking plan is created. See [Get all tracking plans](#get-all-tracking-plans) for more information.\n\n## Create tracking plan from existing event data\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> This is the easiest way to kickstart your tracking plan program without having to start from scratch.\n\nRudderStack lets you create a tracking plan from an existing event data source. This option leverages the [Event Audit API](https://www.rudderstack.com/docs/api/event-audit-api/) and [Tracking plan API](https://www.rudderstack.com/docs/api/tracking-plan-api/) features to generate an initial plan.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Before you proceed, make sure the **Event Audit API** setting is turned on in your [RudderStack dashboard](https://app.rudderstack.com/).\n> \n> Go to **Settings** > **Workspace** and click the **Data Management** tab. Scroll down to the **Data governance** section and turn on the **Event Audit API** toggle.\n> \n> ![Event Audit API setting in RudderStack dashboard](https://www.rudderstack.com/docs/images/api/event-audit-api-dashboard.webp)\n> \n> See [Enable Event Audit API](https://www.rudderstack.com/docs/api/event-audit-api/#enable-event-audit-api) section for more information.\n\nTo create a tracking plan from an existing RudderStack source, follow these steps:\n\n1.  Make a copy of the [Tracking Plan Sheet](https://docs.google.com/spreadsheets/d/1QnCY3dbzyz2InB68W3AGIJshsuY3Zu8WA3AfMMxIzAQ/edit#gid=1810167975).\n    \n2.  Under **API Key Settings (Global)**, enter the following settings:\n    \n    *   **API Personal Access Token**: Generate and enter your [personal access token](https://www.rudderstack.com/docs/dashboard-guides/personal-access-token/#generate-personal-access-token).\n    *   **Email**: Enter the email ID associated with your RudderStack account.\n\n[![Create tracking plan from existing event data](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-existing-data-1.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-existing-data-1.webp)\n\n3.  Go to the **Additional Features** tab of your tracking plan spreadsheet. Enter the following settings:\n    *   **Write Key**: Enter the [write key](https://www.rudderstack.com/docs/dashboard-guides/sources/#source-details) for the source with which you want to link the tracking plan.\n    *   **Tracking plan name**: Enter the name for the new tracking plan.\n\n[![Create tracking plan from existing event data](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-existing-data-3.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-existing-data-3.webp)\n\n4.  Click **RudderStack Tracking Plan** > **Create Tracking Plan from Existing Source Events** in the top bar to create a new tracking plan.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> For the first time you use the spreadsheet, you will be prompted with an approval request. Select **Allow** to permit Google Apps to execute the scripts. See [Google Apps Permissions](#google-apps-permissions) for more information.\n\n[![Create tracking plan from existing event data](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-existing-data-3.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-existing-data-3.webp)\n\n5.  Verify if the tracking plan is created. See [Get all tracking plans](#get-all-tracking-plans) for more information.\n\n## Upload tracking plan\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> You can use this option to create or update a tracking plan in RudderStack.\n\nTo upload a tracking plan to RudderStack, follow these steps:\n\n1.  Go to **Upload Tracking Plan to RudderStack** section of your spreadsheet’s **Homepage** tab.\n\n[![Upload Tracking Plan](https://www.rudderstack.com/docs/images/data-governance/upload-tracking-plan.webp)](https://www.rudderstack.com/docs/images/data-governance/upload-tracking-plan.webp)\n\n2.  Enter the following settings:\n    \n    *   **Sheet Name (for Upload)**: Enter the tab name of the sheet containing the tracking plan.\n    *   **Tracking Plan name**: Enter the name of the tracking plan you want to upload to RudderStack.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Note that:\n> \n> *   RudderStack creates a new tracking plan if the name does not exist.\n> *   If you have instrumented your `identify` events such that the user traits are captured in the `traits` object of the events, make sure you select `traits` as shown, before [creating or updating the tracking plan](https://www.rudderstack.com/docs/data-governance/tracking-plans/tracking-plan-spreadsheet/#create-tracking-plan-from-scratch).\n> \n> ![Identify validation for traits object](https://www.rudderstack.com/docs/images/data-governance/identify-options.webp)\n\n3.  Upload the tracking plan by going to **RudderStack Tracking Plan** in the top nav bar > **Upload Tracking Plan to RudderStack**.\n\n## Download existing tracking plans\n\nTo download existing tracking plans from RudderStack, follow these steps:\n\n1.  Get a list of all your tracking plans by going to **RudderStack Tracking Plan** > **Show All Tracking Plans**. Note the tracking plan ID.\n2.  Go to **Download Tracking Plan from RudderStack** in the spreadsheet and enter the **Tracking Plan ID**:\n\n[![Download tracking plan](https://www.rudderstack.com/docs/images/data-governance/download-tracking-plan.webp)](https://www.rudderstack.com/docs/images/data-governance/download-tracking-plan.webp)\n\n3.  Click **RudderStack Tracking Plan** > **Download Tracking Plan from RudderStack** in the top bar. This creates a new sheet with your tracking plan.\n\n## Get all tracking plans\n\nTo get a list of all your existing tracking plans, go to **RudderStack Tracking Plan** > **Show All Tracking Plans**.\n\n[![Show tracking plans](https://www.rudderstack.com/docs/images/data-governance/show-tracking-plans.webp)](https://www.rudderstack.com/docs/images/data-governance/show-tracking-plans.webp)\n\nThis option lists all your existing tracking plans along with their respective IDs in the **List of Tracking Plans** sheet.\n\n[![Get tracking plans](https://www.rudderstack.com/docs/images/data-governance/get-tracking-plans.webp)](https://www.rudderstack.com/docs/images/data-governance/get-tracking-plans.webp)\n\n## Link tracking plan to source\n\nWhen you link a tracking plan to a source, all events are processed in accordance with that plan.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> This option lets you define the events that RudderStack will drop or allow to pass through, and the permissible errors in the event’s `context` field.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> See [Server-side validation](#server-side-validation) for more information on how RudderStack enforces the tracking plans on your source events.\n\nTo link a tracking plan to a source, follow these steps:\n\n1.  In the **Additional Features** tab, go to the **Link Tracking Plan to Source** section.\n\n[![Link Tracking Plan](https://www.rudderstack.com/docs/images/data-governance/link-tracking-plan.webp)](https://www.rudderstack.com/docs/images/data-governance/link-tracking-plan.webp)\n\n2.  Then, enter the following settings:\n    \n    *   **Tracking Plan ID**: Enter the tracking plan ID. See [Get all tracking plans](#get-all-tracking-plans) section for more information.\n    *   **Source ID**: Enter your source ID. You can find it by going to the **Settings** tab of your source.\n\n[![Source ID](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-source-id.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-source-id.webp)\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> A source ID uniquely identifies a RudderStack source. It is different to the source write key which is used by RudderStack to send events from the source to your specified destinations.\n\n3.  After finalizing the settings, go to **RudderStack Tracking Plan** > **Link Tracking Plan to Source** in the top bar.\n\n## Event settings\n\n*   **Allow unplanned events**: This setting is exclusive to [`track`](https://www.rudderstack.com/docs/event-spec/standard-events/track/) events and has the following options:\n\n| Option | Description |\n| --- | --- |\n| **TRUE** | RudderStack will not drop the events not defined in your tracking plan. |\n| **FALSE** | RudderStack will drop the events not defined in the tracking plan. |\n\n*   **Unplanned Properties**: This setting has the following options:\n\n| Option | Description |\n| --- | --- |\n| **FORWARD** | The event’s `context` field will be updated with the erroneous/unplanned property and forwarded to RudderStack. |\n| **DROP** | RudderStack will drop the event containing the unplanned properties. |\n\n*   **Other Violations**: These violations include discrepancies such as data type mismatch, missing required properties, etc.\n\n| Option | Description |\n| --- | --- |\n| **FORWARD** | The event’s `context` field will be updated with these violations and forwarded to RudderStack. |\n| **DROP** | RudderStack will drop the event containing the violations. |\n\n*   **Propagate Errors**: This setting has the following options:\n\n| Option | Description |\n| --- | --- |\n| **TRUE** | The validation errors are captured in the event’s `context` and sent downstream (user transformations, destinations) |\n| **FALSE** | RudderStack will drop the event containing the validation errors. |\n\n## Other spreadsheet settings\n\nThis section contains the noteworthy spreadsheet settings required to interact with your tracking plan.\n\n### API key settings (Global)\n\n*   **API Personal Access Token**: Enter your [personal access token](https://www.rudderstack.com/docs/dashboard-guides/personal-access-token/) obtained from the RudderStack dashboard.\n*   **Email**: Enter the email ID associated with your RudderStack account.\n\n### Advanced settings\n\nThese settings define how RudderStack should pick the data (event/property values) from the tracking plan.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Do not change these settings unless absolutely necessary as it may impact the entire tracking plan workflow.\n\n### Google Apps permissions\n\nWhen you run the **RudderStack Tracking Plan** menu options for the first time, Google Apps will prompt you to authorize the scripts using the [Tracking plan API](https://www.rudderstack.com/docs/api/tracking-plan-api/).\n\n[![Google Apps permissions](https://www.rudderstack.com/docs/images/data-governance/tracking-plans-permissions.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plans-permissions.webp)\n\nClick **Allow** to set the permissions required for the script to work.\n\n## Server-side validation\n\nRudderStack uses server-side validation to enforce your tracking plans. When you [link a tracking plan to a source](#linking-tracking-plan-to-a-source), RudderStack will check all new events against the tracking plan.\n\nThe validation adds two new columns for each table and each row that specify:\n\n*   Which tracking plan was used\n*   The error message associated with the plan\n\nThese columns will then propagate to both your data warehouse as well as cloud destinations. This lets you monitor the state of your violations and choose to act on them through manual operations or through the transformations.\n\n## FAQ\n\n#### What does the Format Excess Rows (>1500) option do?\n\nFor the downloaded tracking plans, the formatting and dropdown selection for rule types and data types applies only to the first 1500 rows, as that is the number of rows the sheet displays initially.\n\nIn case the tracking plan rules spill over to more than 1500 rows, you can use the **Format Excess Rows (>1500)** button to reformat the excess rows.\n\n[![Tracking Plan Format Excess Rows button](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-excess-rows-button.webp)](https://www.rudderstack.com/docs/images/data-governance/tracking-plan-excess-rows-button.webp)\n\n#### How does the RudderStack tracking plan spreadsheet apply the validations for different event types?\n\nBy default, RudderStack applies the tracking plan validation on the supported event types as follows:\n\n*   `context.traits` object for `identify` events.\n*   `traits` for `group` events.\n*   `properties` for `track`, `page`, and `screen` events.\n\nIf you have instrumented your `identify` events such that the user traits are captured in the `traits` object of the events, make sure you select `traits` as shown, before [creating or updating the tracking plan](https://www.rudderstack.com/docs/data-governance/tracking-plans/tracking-plan-spreadsheet/#create-tracking-plan-from-scratch).\n\n[![Identify validation for traits object](https://www.rudderstack.com/docs/images/data-governance/identify-options.webp)](https://www.rudderstack.com/docs/images/data-governance/identify-options.webp)\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Tracking Plan Spreadsheet | RudderStack Docs",
    "description": "Configure tracking plans using RudderStack's tracking plan spreadsheet.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/data-governance/cookieless-tracking/",
    "markdown": "# Cookieless Tracking | RudderStack Docs\n\nPrivacy Overview\n\nThis site uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are as essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.\n\nNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.",
    "title": "Cookieless Tracking | RudderStack Docs",
    "description": "Control what user information you collect and where to store it.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/standard-events/page/",
    "markdown": "# Page | RudderStack Docs\n\nGet started with the RudderStack Page API call.\n\n* * *\n\n*     3 minute read  \n    \n\nThe `page` call lets you record your website’s page views with any additional relevant information about the viewed page. Many destinations require the `page` events to be called at least once every page load.\n\n## Sample payload\n\nHere is a sample payload of a `page` call after removing the [common fields](https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/):\n\n```\n{\n  \"type\": \"page\",\n  \"name\": \"Home\",\n  \"properties\": {\n    \"title\": \"Home | RudderStack\",\n    \"url\": \"http://www.rudderstack.com\"\n  }\n}\n```\n\nThe corresponding event that generates the above payload via the [JavaScript SDK](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/) is:\n\n```\nrudderanalytics.page(\"Home\")\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The JavaScript SDK automatically gathers the page `title` and `url` and passes them into the event payload.\n> \n> However, note that the HTTP API or the server-side SDKs do not automatically capture these properties.\n\n## Send a sample `page` call\n\nUse RudderStack’s **Event Playground app** to send sample events to RudderStack and test the data flow without any instrumentation.\n\nClick **Send** to see the API call in the **Network** tab of your browser’s developer tools.\n\nTo send test events to your account:\n\n1.  Sign in to the [RudderStack dashboard](https://app.rudderstack.com/). Note the [data plane URLThe data plane URL is the location where events are routed and sent to the RudderStack backend for processing. You can find this URL in the home page of your RudderStack dashboard.](https://www.rudderstack.com/docs/resources/glossary/#data-plane-url) at the top of the default **Connections** page.\n\n[![Data plane URL](https://www.rudderstack.com/docs/images/general/data-plane-url.webp)](https://www.rudderstack.com/docs/images/general/data-plane-url.webp)\n\n2.  Set up a [source](https://www.rudderstack.com/docs/dashboard-guides/sources/#add-a-source) and note its [write keyThe write key (or source write key) is a unique identifier for your source. RudderStack uses this key to send events from a source to the specified destination.](https://www.rudderstack.com/docs/resources/glossary/#write-key) .\n\n[![JavaScript SDK source write key](https://www.rudderstack.com/docs/images/get-started/quickstart/js-write-key.webp)](https://www.rudderstack.com/docs/images/get-started/quickstart/js-write-key.webp)\n\n3.  Click **Use My Account** in the Event Playground app and specify the write key and data plane URL.\n4.  Click **Save**.\n5.  Select the required **API Method** from the dropdown, edit the relevant fields or traits/properties, and click **Send to my account**.\n6.  To verify the data flow, go to the [Live Events](https://www.rudderstack.com/docs/dashboard-guides/live-events/#view-source-live-events) viewer of your source.\n\n## Page fields\n\nApart from the [common fields](https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/), the `page` call accepts the following fields:\n\n| **Field** | **Type** | **Presence** | **Description** |\n| --- | --- | --- | --- |\n| `name` | String | Optional | The name of the page. |\n| `properties` | Object | Optional | Includes the properties of the page like the `url`, `referrer`, etc.  <br>For more information, see the [Properties](#properties) section below. |\n\n## Properties\n\nProperties are additional information that describe the viewed page.\n\nRudderStack has reserved some standard properties listed in the following table and handles them in a special manner. For instance, `path` should always be the URL path of the page and `referrer` should be the URL of the previously viewed page.\n\n| **Property** | **Type** | **Description** |\n| --- | --- | --- |\n| `name` | String | The page name. This is a reserved property for future use. |\n| `path` | String | The path component of the page URL. |\n| `url` | String | Full page URL. RudderStack first looks for the canonical URL. If it is not present, RudderStack uses the `location.href` component from the DOM API. |\n| `title` | String | The page title. |\n| `referrer` | String | The full URL of the previous page visited by the user. |\n| `search` | String | The querystring component of the page URL. |\n| `keywords` | Array | A list or array of keywords describing the page. These keywords are similar to the keywords used for SEO purposes. This property is not automatically collected. |\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Page | RudderStack Docs",
    "description": "Get started with the RudderStack Page API call.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/standard-events/",
    "markdown": "# RudderStack Event Specification | RudderStack Docs\n\nLearn the fields and properties associated with the standard RudderStack API methods.\n\n* * *\n\n*     3 minute read  \n    \n\nThe **RudderStack Event Spec** outlines how to send event data to RudderStack’s APIs and the proper format to capture events using [RudderStack’s SDKs](https://www.rudderstack.com/docs/sources/event-streams/sdks/).\n\nThe RudderStack Event Spec supports multiple API calls that make it easy to identify users and track their specific actions as events. Using the correct format to capture events ensures that RudderStack can automatically forward those events to any of our supported [destinations](https://www.rudderstack.com/docs/destinations/overview/).\n\n## Supported API calls\n\nThe RudderStack API spec supports the following calls, each gathering important data about the user:\n\n| **API call** | **Description** |\n| --- | --- |\n| [Identify](https://www.rudderstack.com/docs/event-spec/standard-events/identify/) | The user’s identity |\n| [Page](https://www.rudderstack.com/docs/event-spec/standard-events/page/) | Web page details of the user’s current page |\n| [Screen](https://www.rudderstack.com/docs/event-spec/standard-events/screen/) | App screen details |\n| [Track](https://www.rudderstack.com/docs/event-spec/standard-events/track/) | Details of user actions (for example, Clicks, Sign ups, and Purchases) |\n| [Group](https://www.rudderstack.com/docs/event-spec/standard-events/group/) | Group or organization details |\n| [Alias](https://www.rudderstack.com/docs/event-spec/standard-events/alias/) | Merge identities to a known user |\n| [Merge](https://www.rudderstack.com/docs/event-spec/standard-events/merge/) | Perform identity resolution by associating different identifiers to a given customer profile in the warehouse (**Deprecated**) |\n| **Reset** | Resets the information related to the previously identified user |\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Refer to the corresponding [SDK documentation](https://www.rudderstack.com/docs/sources/event-streams/sdks/) for the implementation specifics of the above calls.\n\n## Send sample events\n\nUse RudderStack’s **Event Playground app** to send sample events to RudderStack and test the data flow without any instrumentation.\n\nSelect the relevant **API method** from the dropdown and click **Send** to see the API call in the **Network** tab of your browser’s developer tools.\n\nTo send test events to your account:\n\n1.  Sign in to the [RudderStack dashboard](https://app.rudderstack.com/). Note the [data plane URLThe data plane URL is the location where events are routed and sent to the RudderStack backend for processing. You can find this URL in the home page of your RudderStack dashboard.](https://www.rudderstack.com/docs/resources/glossary/#data-plane-url) at the top of the default **Connections** page.\n\n[![Data plane URL](https://www.rudderstack.com/docs/images/general/data-plane-url.webp)](https://www.rudderstack.com/docs/images/general/data-plane-url.webp)\n\n2.  Set up a [source](https://www.rudderstack.com/docs/dashboard-guides/sources/#add-a-source) and note its [write keyThe write key (or source write key) is a unique identifier for your source. RudderStack uses this key to send events from a source to the specified destination.](https://www.rudderstack.com/docs/resources/glossary/#write-key) .\n\n[![JavaScript SDK source write key](https://www.rudderstack.com/docs/images/get-started/quickstart/js-write-key.webp)](https://www.rudderstack.com/docs/images/get-started/quickstart/js-write-key.webp)\n\n3.  Click **Use My Account** in the Event Playground app and specify the write key and data plane URL.\n4.  Click **Save**.\n5.  Select the required **API Method** from the dropdown, edit the relevant fields or traits/properties, and click **Send to my account**.\n6.  To verify the data flow, go to the [Live Events](https://www.rudderstack.com/docs/dashboard-guides/live-events/#view-source-live-events) viewer of your source.\n\n## How the API calls work\n\nHere’s a quick overview of how the API calls work:\n\n1.  A customer interacts with your website/app triggering an event.\n2.  When an API is called, the event data is sent to the RudderStack backend.\n3.  RudderStack transforms the event data into a destination-specific format.\n4.  The transformed data is then sent to all requested destinations.\n\n## Event data format\n\nThe event data is collected in JSON and includes the [Common Fields](https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/) along with API-specific fields.\n\n**It is strongly recommended large integer values be passed as strings**. This ensures that the values are correctly transmitted to all systems (including various downstream destinations) without any issues.\n\nRudderStack follows the [RFC 7159 standard](https://www.rfc-editor.org/rfc/rfc7159#section-6) which has an upper limit of 253 for integers. If the values passed exceed this number, **you may lose precision**. Furthermore, certain downstream destinations have their own limitations on parsing large integer values.\n\n## Industry Specs\n\n*   **Mobile**\n    *   [Screen](https://www.rudderstack.com/docs/event-spec/standard-events/screen/)\n    *   [Application Lifecycle Events](https://www.rudderstack.com/docs/event-spec/standard-events/application-lifecycle-events-spec/)\n*   [Ecommerce](https://www.rudderstack.com/docs/event-spec/ecommerce-events-spec/)\n*   [Video](https://www.rudderstack.com/docs/event-spec/standard-events/video-events-spec/)\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "RudderStack Event Specification | RudderStack Docs",
    "description": "Learn the fields and properties associated with the standard RudderStack API methods.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/dashboard-guides/personal-access-token/",
    "markdown": "# Personal Access Token | RudderStack Docs\n\nPrivacy Overview\n\nThis site uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are as essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.\n\nNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.",
    "title": "Personal Access Token | RudderStack Docs",
    "description": "Generate and manage your personal access tokens in RudderStack.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/standard-events/screen/",
    "markdown": "# Screen | RudderStack Docs\n\nPrivacy Overview\n\nThis site uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are as essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.\n\nNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.",
    "title": "Screen | RudderStack Docs",
    "description": "Get started with the RudderStack Screen API call.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/standard-events/track/",
    "markdown": "# Track | RudderStack Docs\n\nGet started with the RudderStack Track API call.\n\n* * *\n\n*     4 minute read  \n    \n\nThe `track` call lets you record the user’s actions along with any properties associated with them.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Each user action is called an event. Every event has a name associated with it, for example, `Product Reviewed`. This event can have properties associated with it, like `review_id` and `rating`.\n\n## Event Names\n\nIt is recommended that events have a descriptive human readable name. This allows everyone (include you 6 months from now) to instantly understand the meaning of an event.\n\nVague or abstract names like ProdRV and Event2 should be avoided. Instead focus on unique unabiguous names like **Product Reviewed** and **Order Submitted**. A common framework is to use nouns and past tense verbs.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> Identity data (user traits) will be automatically added to `track` calls from the most recent `identify` call, so you do not need to add it manually. This information will be included in a `traits` object in the `context` fields of the payload. Note that `track` calls also automatically handle `anonymousId` values associated with the user.\n> \n> See our [Identify](https://www.rudderstack.com/docs/event-spec/standard-events/identify/) doc for more details.\n\n## Sample payload\n\nHere is a sample payload for the `track` event after removing [Common fields](https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/):\n\n```\n{\n  \"type\": \"track\",\n  \"event\": \"Product Reviewed\",\n  \"properties\": {\n    \"review_id\": \"86ac1cd43\",\n    \"product_id\" : \"9578257311\",\n    \"rating\" : 3.0,\n    \"review_body\" : \"OK for the price. It works but the material feels flimsy.\"\n  }\n}\n```\n\nThe corresponding event that generates the above payload via the [JavaScript SDK](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/) is:\n\n```\nrudderanalytics.track(\"Product Reviewed\", {\n  review_id: \"86ac1cd43\",\n  product_id: \"9578257311\",\n  rating: 3.0,\n  review_body: \"OK for the price. It works but the material feels flimsy.\"\n})\n```\n\n## Send a sample `track` call\n\nUse RudderStack’s **Event Playground app** to send sample events to RudderStack and test the data flow without any instrumentation.\n\nClick **Send** to see the API call in the **Network** tab of your browser’s developer tools.\n\nTo send test events to your account:\n\n1.  Sign in to the [RudderStack dashboard](https://app.rudderstack.com/). Note the [data plane URLThe data plane URL is the location where events are routed and sent to the RudderStack backend for processing. You can find this URL in the home page of your RudderStack dashboard.](https://www.rudderstack.com/docs/resources/glossary/#data-plane-url) at the top of the default **Connections** page.\n\n[![Data plane URL](https://www.rudderstack.com/docs/images/general/data-plane-url.webp)](https://www.rudderstack.com/docs/images/general/data-plane-url.webp)\n\n2.  Set up a [source](https://www.rudderstack.com/docs/dashboard-guides/sources/#add-a-source) and note its [write keyThe write key (or source write key) is a unique identifier for your source. RudderStack uses this key to send events from a source to the specified destination.](https://www.rudderstack.com/docs/resources/glossary/#write-key) .\n\n[![JavaScript SDK source write key](https://www.rudderstack.com/docs/images/get-started/quickstart/js-write-key.webp)](https://www.rudderstack.com/docs/images/get-started/quickstart/js-write-key.webp)\n\n3.  Click **Use My Account** in the Event Playground app and specify the write key and data plane URL.\n4.  Click **Save**.\n5.  Select the required **API Method** from the dropdown, edit the relevant fields or traits/properties, and click **Send to my account**.\n6.  To verify the data flow, go to the [Live Events](https://www.rudderstack.com/docs/dashboard-guides/live-events/#view-source-live-events) viewer of your source.\n\n## Track fields\n\nApart from the [Common fields](https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/), the `track` call accepts the following fields:\n\n| **Field** | **Type** | **Presence** | **Description** |\n| --- | --- | --- | --- |\n| `event` | String | Required | Name of the user action |\n| `properties` | Object | Optional | Includes the properties associated with the event. For more information, check the [Properties](#properties) section below. |\n\n## Properties\n\nProperties are additional contextual information that are associated with a `track` event, that give more clarity of your users’ actions.\n\nRudderStack has reserved some standard properties listed in the following table and handles them in a special manner.\n\n| **Property** | **Type** | **Description** |\n| --- | --- | --- |\n| `revenue` | Number | The revenue amount as a result of an event. For e.g., a product worth $20.00 would result in a `revenue` of `20.00`. |\n| `currency` | String | The currency of the revenue as a result of the event, set in ISO 4127 format. If this is not set, RudderStack assumes the revenue is in USD. |\n| `value` | String | An abstract value associated with an event, to be used by various teams. |\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> Different destinations recognize some of the above data points differently.\n> \n> With RudderStack, you don’t have to worry about these inconsistencies across destinations. Our open source destination transformer code handles these destination-specific conversions automatically.\n> \n> For example, Mixpanel has a `track_charges` method for tracking revenue. In this case, you can pass the `revenue` property and RudderStack will handle the conversion automatically through our destination transformer code. You can see the Mixpanel transformer code in our [open source Github repo](https://github.com/rudderlabs/rudder-transformer/tree/master/src/v0/destinations/mp).\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Track | RudderStack Docs",
    "description": "Get started with the RudderStack Track API call.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/api/user-suppression-api/",
    "markdown": "# User Suppression API | RudderStack Docs\n\nSuppress and delete user data in accordance with your user suppression policies.\n\nAvailable Plans\n\n*   enterprise\n\n* * *\n\n*     7 minute read  \n    \n\nWith RudderStack’s user suppression APIs, you can create regulations to suspend data collection and delete data for specific users. You can apply these regulations across multiple destination integrations simultaneously, simplifying the process of implementing compliance requests.\n\nWith these APIs, you can:\n\n*   [Add a suppression regulation](#add-a-suppression-regulation): Drop the user events at the source. These events will not be available for debugging, replay, or forwarded to destinations.\n*   [Add a suppress and delete regulation](#add-a-suppression-with-delete-regulation): Delete any user data that was sent to a destination.\n*   [List all regulations](#list-user-supressions): List the regulations created with the User Suppression API.\n*   [Delete a specific regulation](#cancel-a-user-suppression): Delete a previously created regulation.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> The User Suppression API is a part of RudderStack’s [Data Governance toolkit](https://www.rudderstack.com/docs/data-governance/overview/) that ensures the quality and integrity of your data in a secure and compliant manner.\n\nThe User Suppression API uses [Bearer Authentication](https://swagger.io/docs/specification/authentication/bearer-authentication/) in the format `Authorization: Bearer <PERSONAL_ACCESS_TOKEN>`.\n\nYou can retrieve your [personal access token](https://www.rudderstack.com/docs/dashboard-guides/personal-access-token/) from the RudderStack dashboard.\n\n## Base URL\n\nUse the base URL for your API requests depending on your region:\n\n```\nhttps://api.rudderstack.com\n```\n\n```\nhttps://api.eu.rudderstack.com\n```\n\n## Specifying source and destination IDs in your regulation\n\nWhen creating user suppressions with our API, you may wish to name specific sources for a [suppress](#add-a-suppression-regulation) regulation, and specific destinations for a [suppress and delete](#add-a-suppression-with-delete-regulation) regulation. To do so, you must first obtain the source and/or destination IDs.\n\n**Retrieving source and destination IDs**\n\nRetrieve source and destination IDs from your RudderStack dashboard or by using the `/v2/sources` and `/v2/destinations` endpoints:\n\n```\nGET /v2/sources HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2Le5TOgDjwR0djObWRW6Le5kq3E\n```\n\n```\nGET /v2/destinations HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2Le5TOgDjwR0djObWRW6Le5kq3E\n```\n\n## Add a suppression regulation\n\nAdd a new user suppression regulation to suppress a given user’s data.\n\nSee [Request body](#request-body) for details on the request parameters.\n\n**Example Request**:\n\n```\nPOST /v2/regulations HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2Le5TOgDjwR0djObWRW6Le5kq3E\nContent-Type: application/json\nContent-Length: 182\n\n{\n  \"regulationType\": \"suppress\",\n  \"sourceIds\": [\n    \"27OeyCriZ4vGFiOFPihSMgr0Nt1\"\n  ],\n  \"users\": [\n    {\n      \"userId\": \"54321\",\n      \"phone\": \"+12125551212\",\n      \"email\": \"user@email.com\"\n    },\n    {\n      \"userId\": \"54322\",\n      \"randomKey-1\": \"randomVal-1\",\n      \"randomKey-2\": \"randomVal-2\"\n    }\n  ]\n}\n```\n\n```\ncurl --location --request POST 'https://api.rudderstack.com/v2/regulations' \\\n--header 'Authorization: Bearer 2345678Dv9J5NZsEqVJWLQutE4E' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n  \"regulationType\": \"suppress\",\n  \"sourceIds\": [\n    \"27OeyCriZ4vGFiOFPihSMgr0Nt1\"\n  ],\n  \"users\": [\n    {\n      \"userId\": \"54321\",\n      \"phone\": \"+12125551212\",\n      \"email\": \"user@email.com\"\n    },\n    {\n      \"userId\": \"54322\",\n      \"randomKey-1\": \"randomVal-1\",\n      \"randomKey-2\": \"randomVal-2\"\n    }\n  ]\n}'\n```\n\n**Example Response**:\n\n```\n[\n    {\n        \"id\": \"b287a287-6b83-4402-902e-d2793b3e4ba4\",\n        \"workspaceId\": \"2H2WbKP1613awrY1YgA9Q58wBOc\",\n        \"canceled\": false,\n        \"regulationType\": \"suppress\",\n        \"attributes\": {\n            \"email\": \"user@email.com\",\n            \"phone\": \"+12125551212\",\n            \"userId\": \"54321\"\n        }\n    },\n    {\n        \"id\": \"f57475da-5f00-4f77-a22a-26be261ad3b6\",\n        \"workspaceId\": \"2H2WbKP1613awrY1YgA9Q58wBOc\",\n        \"canceled\": false,\n        \"regulationType\": \"suppress\",\n        \"attributes\": {\n            \"randomKey-1\": \"randomVal-1\",\n            \"randomKey-2\": \"randomVal-2\",\n            \"userId\": \"54322\"\n        }\n    }\n]\n```\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> A successful response returns a `201` status.\n\n## Add a suppression with delete regulation\n\nAdd a new regulation to suppress and delete a given user’s data.\n\nSee [Request body](#request-body) for details on the request parameters.\n\n**Example Request**:\n\n```\nPOST /v2/regulations HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2Le5TOgDjwR0djObWRW6Le5kq3E\nContent-Type: application/json\nContent-Length: 182\n\n{\n    \"regulationType\": \"suppress_with_delete\",\n    \"destinationIds\": [\n        \"27OeyCriZ4vGFiOFPihSMgr0Nt1\"\n    ],\n    \"users\": [\n        {\n            \"userId\": \"54321\",\n            \"phone\": \"+12125551212\",\n            \"email\": \"user@email.com\"\n        },\n        {\n            \"userId\": \"54322\",\n            \"randomKey-1\": \"randomVal-1\",\n            \"randomKey-2\": \"randomVal-2\"\n        }\n    ]\n}\n```\n\n```\ncurl --location --request POST 'https://api.rudderstack.com/v2/regulations' \\\n--header 'Authorization: Bearer 2345678Dv9J5NZsEqVJWLQutE4E' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"regulationType\": \"suppress_with_delete\",\n    \"destinationIds\": [\n        \"27OeyCriZ4vGFiOFPihSMgr0Nt1\"\n    ],\n    \"users\": [\n        {\n            \"userId\": \"54321\",\n            \"phone\": \"+12125551212\",\n            \"email\": \"user@email.com\"\n        },\n        {\n            \"userId\": \"54322\",\n            \"randomKey-1\": \"randomVal-1\",\n            \"randomKey-2\": \"randomVal-2\"\n        }\n    ]\n}'\n```\n\n**Example Response**:\n\n```\n[\n    {\n        \"id\": \"5d2417f6-655f-494b-aab7-b0dac55a9b52\",\n        \"workspaceId\": \"2H2WbKP1613awrY1YgA9Q58wBOc\",\n        \"canceled\": false,\n        \"regulationType\": \"suppress_with_delete\",\n        \"attributes\": {\n            \"email\": \"user@email.com\",\n            \"phone\": \"+12125551212\",\n            \"userId\": \"54321\"\n        }\n    },\n    {\n        \"id\": \"f2414ddd-e664-4a22-bd7a-b165138ccd8f\",\n        \"workspaceId\": \"2H2WbKP1613awrY1YgA9Q58wBOc\",\n        \"canceled\": false,\n        \"regulationType\": \"suppress_with_delete\",\n        \"attributes\": {\n            \"randomKey-1\": \"randomVal-1\",\n            \"randomKey-2\": \"randomVal-2\",\n            \"userId\": \"54322\"\n        }\n    }\n]\n```\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> A successful response returns a `201` status.\n\n### Supported destinations\n\nRudderStack supports the `suppress_with_delete` request for the following destinations:\n\n*   [Amplitude](https://www.rudderstack.com/docs/destinations/streaming-destinations/amplitude/)\n*   [AppsFlyer](https://www.rudderstack.com/docs/destinations/streaming-destinations/appsflyer/)\n*   [Braze](https://www.rudderstack.com/docs/destinations/streaming-destinations/braze/)\n*   [CleverTap](https://www.rudderstack.com/docs/destinations/streaming-destinations/clevertap/)\n*   [Google Analytics](https://www.rudderstack.com/docs/destinations/streaming-destinations/google-analytics-ga/)\n*   [Intercom](https://www.rudderstack.com/docs/destinations/streaming-destinations/intercom/)\n*   [Mixpanel](https://www.rudderstack.com/docs/destinations/streaming-destinations/mixpanel/)\n*   [Redis](https://www.rudderstack.com/docs/destinations/streaming-destinations/redis/)\n*   [S3](https://www.rudderstack.com/docs/destinations/streaming-destinations/amazon-s3/)\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> For the above destinations, you can delete a user by specifying the `userId` in the event.\n> \n> Except for **Redis** and **S3** destinations, you can also specify a custom identifier (optional) in the event along with the `userId`.\n\n## Request body\n\nstring\n\nDefines the user suppression type. Can be one of `suppress`, which suppresses incoming user data or `suppress_with_delete` which suppresses and deletes events from your specified destinations.\n\nPossible Values: suppress, suppress\\_with\\_delete\n\narray\n\nSpecify only `sourceIds` with the `suppress` regulation. If no `sourceIds` are specified, RudderStack will suppress data from all sources in the workspace associated with your access token.\n\narray\n\nSpecify only `destinationIds` with the `suppress_with_delete` regulation. Otherwise, RudderStack throws an error.\n\narray\n\nAn array of user objects identifying users to be suppressed. The `userId` field is mandatory for all users. You can pass additional custom identifiers such as `email` in the `users` object.\n\n* * *\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Do not specify both `sourceIds` and `destinationIds` in your request body.\n\n## List user suppressions\n\nList your existing user suppression regulations.\n\n**Example request**:\n\n```\nGET /v2/regulations HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2Le5TOgDjwR0djObWRW6Le5kq3E\n```\n\n```\ncurl --location --request GET 'https://api.rudderstack.com/v2/regulations' \\\n--header 'Authorization: Bearer 23456pCURNbcG0fGRfkgAdcWQsW'\n```\n\n**Example response**:\n\n```\n{\n  \"data\": [\n    {\n      \"id\": \"c8fae8a7-1555-4807-89d8-972837671071\",\n      \"workspaceId\": \"216AlUz1kdkhkh7RFFvJVA9THlq\",\n      \"canceled\": false,\n      \"regulationType\": \"suppress\",\n      \"attributes\": {\n        \"userId\": \"12\",\n        \"phone\": \"1234567890\",\n        \"email\": \"abc@xyz.com\"\n      }\n    },\n    {\n      \"id\": \"1ac629bf-d795-45df-8bfb-be06d22a636b\",\n      \"workspaceId\": \"216AlUz1kdkhkh7RFFvJVA9THlq\",\n      \"canceled\": false,\n      \"regulationType\": \"suppress_with_delete\",\n      \"attributes\": {\n        \"userId\": \"rudder-1\"\n      }\n    },\n    {\n      \"id\": \"7bdf698f-80bd-4278-bb85-414ad8d27888\",\n      \"workspaceId\": \"216AlUz1kdkhkh7RFFvJVA9THlq\",\n      \"canceled\": true,\n      \"regulationType\": \"suppress\",\n      \"attributes\": {\n        \"userId\": \"123\",\n        \"phone\": \"9876543210\",\n        \"email\": \"name@email.com\"\n      }\n    }\n  ],\n  \"paging\": {\n    \"next\": \"/v2/regulations?after_cursor=a450395bb52f4acb99e492c358e104eb\"\n  },\n}\n```\n\n**Response object parameters**:\n\nobject\n\nProvides a `next` URL for fetching paginated results. The `next` URL contains an `after_cursor` query parameter.\n\n* * *\n\n## Cancel a user suppression\n\nCancel an existing user suppression regulation.\n\nDELETE\n\n/v2/regulations{regulation\\_id}\n\n**Query parameters**:\n\nstring\n\nThe ID of the regulation to be canceled. The `regulation_id` is the `id` that is returned for a regulation in `GET /v2/regulations`.\n\n* * *\n\n**Example request**:\n\n```\nDELETE /v2/regulations/f0222ce9-bbaf-4585-9c17-18cde664c0af HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2Le5TOgDjwR0djObWRW6Le5kq3E\n```\n\n```\ncurl --location --request DELETE 'http://api.rudderstack.com/v2/regulations/e44c5f3b-b4ca-4b17-8147-7bc1c9620fe3' \\\n--header 'Authorization: Bearer 12345nuDv9J5NZsEqVJWLQutE4E'\n```\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> A successful response returns a `204 No Content` status.\n\n## Rate Limits\n\nPost regulation requests are rate limited.\n\n| Type | Limit (tokens per hour) |\n| --- | --- |\n| Suppression | 4,000 |\n| Deletion | 200,000 |\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> In the case of suppression, 1 user is equivalent to 1 token. For deletion, RudderStack calculates the number of tokens by multiplying the number of users with the number of destinations. For example, if there are `n` users with `m` destinations, the total number of tokens would be `n * m`.\n\n## Suppression across multiple sources\n\nYou can leverage the User Suppression API to suppress all incoming data for a given user. RudderStack drops the events for that user at the source of collection. Suppression applies across all sources, however you can also specify the specific sources you want to suppress.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Note that after suppression, the events:\n> \n> *   Will not be shown in any debuggers.\n> *   Will not be forwarded to any destinations.\n> *   Will not be available for [event replay](https://www.rudderstack.com/docs/user-guides/administrators-guide/event-replay/).\n\n## Deletion across multiple destinations\n\nWhen a user requests that their data be deleted, you can leverage the User Suppression API to delete user data across multiple downstream destinations like Amplitude, Braze, Redis, and others.\n\nWe are continually adding to the list of destinations supported for deletion. If you need a destination that is not yet supported, [reach out](mailto:docs@rudderstack.com) to our team.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The User Suppression API can delete data only for destinations running in [cloud mode](https://www.rudderstack.com/docs/destinations/rudderstack-connection-modes/#cloud-mode).\n\n## FAQ\n\n#### **How is the User Suppression API helpful?**\n\nTo comply with data regulation statutes and users’ privacy choices, you can use RudderStack’s User Suppression API to:\n\n*   Suppress incoming source data for a user or list of users.\n*   Delete collected data for users that reside in a given destination or across multiple destinations.\n\nFor example, if a user updates their preferences to opt-out of being tracked, you can implement a regulation in the User Suppression API that stops RudderStack from collecting their data at the source, and ensuring no data is sent to downstream destinations. Also, if the user requests to be forgotten, you can delete their data from multiple downstream destinations like Amplitude and Braze with one API call.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "User Suppression API | RudderStack Docs",
    "description": "Suppress and delete user data in accordance with your user suppression policies.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/standard-events/identify/",
    "markdown": "# Identify | RudderStack Docs\n\nGet started with the RudderStack Identify API call.\n\n* * *\n\n*     6 minute read  \n    \n\nThe `identify` call allows you to identify a visiting user and associate their actions to that identity. It also lets you record traits about the user like their name, email address, etc.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> As a best practice, make sure `identify` is called at the start of every session or page load for logged-in users, if possible. This will ensure all the latest traits are captured.\n\n## When should I call identify?\n\nIdeally, you should make an `identify` call in the following scenarios:\n\n*   After a user registers on your website or app\n*   After a user logs in to your site or app\n*   When a user updates their information, e.g., residential address, email ID\n*   When you load a page accessible by a logged-in user: Although this is optional, many tools (such as Intercom) require an initial `identify` call to know who the user is at the session start.\n\n## Sample payload\n\nHere is a sample payload for an `identify` event after removing [Common fields](https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/):\n\n```\n{\n  \"type\": \"identify\",\n  \"context\": {\n    \"traits\": {\n      \"name\": \"Richard Hendricks\",\n      \"email\": \"rhedricks@example.com\",\n      \"logins\": 2\n    }\n  },\n  \"userId\": \"27340af5c8819\"\n}\n```\n\nThe corresponding event that generates the above payload via the [JavaScript SDK](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/) is:\n\n```\nrudderanalytics.identify(\"27340af5c8819\", {\n  name: \"Richard Hendricks\",\n  email: \"rhedricks@example.com\",\n  logins: 2\n})\n```\n\n## Send a sample `identify` call\n\nUse RudderStack’s **Event Playground app** to send sample events to RudderStack and test the data flow without any instrumentation.\n\nClick **Send** to see the API call in the **Network** tab of your browser’s developer tools.\n\nTo send test events to your account:\n\n1.  Sign in to the [RudderStack dashboard](https://app.rudderstack.com/). Note the [data plane URLThe data plane URL is the location where events are routed and sent to the RudderStack backend for processing. You can find this URL in the home page of your RudderStack dashboard.](https://www.rudderstack.com/docs/resources/glossary/#data-plane-url) at the top of the default **Connections** page.\n\n[![Data plane URL](https://www.rudderstack.com/docs/images/general/data-plane-url.webp)](https://www.rudderstack.com/docs/images/general/data-plane-url.webp)\n\n2.  Set up a [source](https://www.rudderstack.com/docs/dashboard-guides/sources/#add-a-source) and note its [write keyThe write key (or source write key) is a unique identifier for your source. RudderStack uses this key to send events from a source to the specified destination.](https://www.rudderstack.com/docs/resources/glossary/#write-key) .\n\n[![JavaScript SDK source write key](https://www.rudderstack.com/docs/images/get-started/quickstart/js-write-key.webp)](https://www.rudderstack.com/docs/images/get-started/quickstart/js-write-key.webp)\n\n3.  Click **Use My Account** in the Event Playground app and specify the write key and data plane URL.\n4.  Click **Save**.\n5.  Select the required **API Method** from the dropdown, edit the relevant fields or traits/properties, and click **Send to my account**.\n6.  To verify the data flow, go to the [Live Events](https://www.rudderstack.com/docs/dashboard-guides/live-events/#view-source-live-events) viewer of your source.\n\n## Identify fields\n\nThe `identify` call has the following fields in addition to the [Common fields](https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/):\n\n| **Field** | **Type** | **Presence** | **Description** |\n| --- | --- | --- | --- |\n| `userId` | String | Optional, **if** `anonymousId` is set | Your user’s unique identifier. Every `identify` call requires a `userId` or an `anonymousId`. |\n| `traits` | Object | Optional | Includes the traits of the user such as their `name`, `email`, etc. For more more information, check the [Traits](#identify-traits) section below. |\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> The field names can change slightly depending on the SDK. However, the functionality remains the same.\n> \n> See the [SDK-specific documentation](https://www.rudderstack.com/docs/sources/event-streams/sdks/) for the implementation specifics and details on the above fields.\n\n## User ID vs Anonymous ID\n\nRudderStack requires every `identify` call to have either a `userId` or an `anonymousId`. This section highlights the differences between the two.\n\n### User ID\n\nA user ID (`userId`) uniquely identifies your user in your database. It is a permanent identifier of your customer which never changes - like a database ID.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> For `identify` calls, include a `userId` as often as possible to identify the most up to date traits of the customer.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> It is recommended to use a database ID as the `userId` instead of usernames or email addresses. This is because users may update their username or email address at any point in the future. Instead, pass these attributes as **traits**.\n\n### Anonymous ID\n\nThere are instances where you may get a visitor on your website/app who may or may not be your customer. Nonetheless, you still want to track their actions and tie them to various events, page views, and traits. In such cases, you should use an Anonymous ID (`anonymousId`) to identify this user.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> An anonymousId can be any identifier. For instance, a session ID corresponding to the visitor’s session. If you don’t have a readily available identifier, we recommend generating a **UUID**.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> RudderStack’s web and mobile [SDKs](https://www.rudderstack.com/docs/sources/event-streams/sdks/) automatically use anonymous IDs to track unknown users on your website or mobile apps, so you don’t have to worry about including an `anonymousId` explicitly.\n\n## Identify traits\n\nTraits are additional user information included in an `identify` call. Some examples of traits include age, gender, or some specific details - for example, a user’s product plan (basic, premium, and so on).\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> There are some differences in the way RudderStack captures and sends the user traits across different SDKs. While RudderStack ideally sends the user traits in the [`context.traits`](https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/#contextual-fields) object (as in case of [JavaScript SDK](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/)), for some SDKs it also sends the user traits in the root-level `traits` object (for backward compatibility).\n> \n> Refer to the [SDK-specific documentation](https://www.rudderstack.com/docs/sources/event-streams/sdks/) for more details on sending user traits.\n\nAfter making an `identify` call, user traits are not required in subsequent calls. You only need to include changed/updated traits since the last `identify` call.\n\nRudderStack has some reserved traits that it handles in special ways. These are listed in the table below:\n\n| **Trait** | **Type** | **Description** |\n| --- | --- | --- |\n| `id` | String | Fallback parameter used only for mapping data **if** `userId` is not available in the event payload. |\n| `firstName` | String | User's first name |\n| `lastName` | String | User's last name |\n| `name` | String | Full name of the user. If you already passed the `firstName` and `lastName`, RudderStack will automatically fill this field. |\n| `age` | Number | User's age |\n| `email` | String | User's email address |\n| `phone` | String | User's phone number |\n| `address` | Object | User's street address. This can optionally contain either/all of the following fields:<br><br>*   `city`<br>*   `country`<br>*   `postalCode`<br>*   `state`<br>*   `street` |\n| `birthday` | Date | User's date of birth |\n| `company` | Object | User's company. This can optionally contain either/all of the following fields:<br><br>*   `name` (String)<br>*   `id` (String / Number)<br>*   `industry` (String)<br>*   `employee_count` (Number)<br>*   `plan` (String) |\n| `createdAt` | Date | Date of user's account creation. We recommend using the **ISO-8601** date string format. |\n| `description` | String | User's description |\n| `gender` | String | User's gender |\n| `title` | String | User's title related to their position in their company |\n| `username` | String | User's username. This should be unique for every user. |\n| `website` | String | User's website |\n| `avatar` | String | URL of the user's avatar image |\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> Different destinations recognize some of the above traits differently. For example, Mixpanel recognizes `createdAt` as `$created`, while Intercom recognizes it as `created_at`.\n> \n> With RudderStack, you don’t have to worry about these inconsistencies, it handles these destination-specific conversions automatically.\n\n## Passing traits to an identify call\n\nWhen you pass traits to an `identify` call, they will be stored in a cookie on the user’s browser or mobile device and will be passed automatically to all subsequent calls.\n\nBelow is an example of how to pass traits to an `identify` call from our [JavaScript SDK](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/). For more examples, check our other [SDKs](https://www.rudderstack.com/docs/sources/event-streams/sdks/).\n\n```\nrudderanalytics.identify(\"27340af5c8819\", {\n  name: \"Richard Hendricks\",\n  gender: \"male\",\n})\n```\n\nIn the above example, `{name: \"Richard Hendricks\", gender: \"male\"}` are stored in a cookie and passed along with all subsequent calls.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Identify | RudderStack Docs",
    "description": "Get started with the RudderStack Identify API call.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/standard-events/group/",
    "markdown": "# Group | RudderStack Docs\n\nGet started with the RudderStack Group API call.\n\n* * *\n\n*     3 minute read  \n    \n\nThe `group` call lets you link an identified user with a group like a company, organization, or an account. You can also record any custom traits associated with that group like the company name, number of employees, etc.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> An identified user can be linked to multiple groups.\n\n## Sample payload\n\nHere is a sample payload for the `group` event after removing the [Common fields](https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/):\n\n```\n{\n  \"type\": \"group\",\n  \"groupId\": \"5e8a78ba9d32d3b1898a6247\",\n  \"traits\": {\n    \"name\": \"Hooli\",\n    \"industry\": \"Technology\",\n    \"employees\": 4500,\n    \"plan\": \"basic\"\n  }\n}\n```\n\nThe corresponding event that generates the above payload via the [JavaScript SDK](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/) is:\n\n```\nrudderanalytics.group(\"5e8a78ba9d32d3b1898a6247\", {\n  name: \"Hooli\",\n  industry: \"Technology\",\n  employees: 4500,\n  plan: \"basic\"\n})\n```\n\n## Group fields\n\nThe `group` call has the following fields in addition to the [Common fields](https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/):\n\n| **Field** | **Type** | **Presence** | **Description** |\n| --- | --- | --- | --- |\n| `groupId` | String | Required | Your group’s unique identifier which lets you identify the group in your database. |\n| `traits` | Object | Optional | Includes the traits of the group such as `name`, `email`, `employees`, etc. For more more information, check the [Traits](#traits) section below. |\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> The field names can change slightly depending on the SDK. However, the functionality remains the same.\n> \n> See the [SDK-specific documentation](https://www.rudderstack.com/docs/sources/event-streams/sdks/) for the implementation specifics and details on the above fields.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> Identity data (user traits) will be automatically added to `group` calls from the most recent `identify` call, so you do not need to add it manually. This information will be included in a `traits` object in the `context` fields of the payload. Note that `group` calls also automatically handle `anonymousId` values associated with the user.\n> \n> See our [Identify](https://www.rudderstack.com/docs/event-spec/standard-events/identify/) doc for more details.\n\n## Traits\n\nTraits are additional information included in a `group` call that adds more context to the group. Some example of traits include the number of employees, name of the industry, or the website of the group.\n\nRudderStack has some reserved traits that it handles in special ways. These are listed in the table below:\n\n| **Trait** | **Type** | **Description** |\n| --- | --- | --- |\n| `id` | String | Fallback parameter used only for mapping data **if** `groupId` is not available in the event payload. |\n| `name` | String | The group name |\n| `email` | String | The group's email address |\n| `phone` | String | Phone number associated with the group |\n| `address` | Object | The group's street address. This can optionally contain any or all of the following fields:<br><br>*   `city`<br>*   `country`<br>*   `postalCode`<br>*   `state`<br>*   `street` |\n| `industry` | String | The name of the industry that the group is a part of |\n| `createdAt` | Date | Date of the group's account creation. We recommend using the **ISO-8601** date string format. |\n| `description` | String | The group's description |\n| `employees` | String | Number of the employees in the group. This is typically used for companies. |\n| `plan` | String | The plan that the group is subscribed to |\n| `website` | String | The group's website |\n| `avatar` | String | URL of the group's avatar image |\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> Different destinations recognize some of the above data points differently.\n> \n> With RudderStack, you don’t have to worry about these inconsistencies across destinations. Our open source destination transformer code handles these destination-specific conversions automatically.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Group | RudderStack Docs",
    "description": "Get started with the RudderStack Group API call.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/standard-events/alias/",
    "markdown": "# Alias | RudderStack Docs\n\nPrivacy Overview\n\nThis site uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are as essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.\n\nNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.",
    "title": "Alias | RudderStack Docs",
    "description": "Get started with the RudderStack Alias API call.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/dashboard-guides/workspaces/",
    "markdown": "# Workspaces | RudderStack Docs\n\nSwitch between multiple workspaces in your RudderStack organization.\n\nAvailable Plans\n\n*   starter\n*   growth\n*   enterprise\n\n* * *\n\n*     4 minute read  \n    \n\nRudderStack’s **Workspaces** feature lets you switch between multiple environments within a RudderStack organization. It provides a clean user experience with organization-level clarity on billing and usage.\n\n## Organization and workspace hierarchy\n\nThis section defines an organization and workspace in RudderStack.\n\n### Organization\n\nWhen you [sign up for RudderStack Cloud](https://app.rudderstack.com/signup), your email is associated with a top-level user account, also referred to as an **organization**. RudderStack calculates all your billing and events usage at an organization level.\n\nTo view the organization details and manage its settings, go to **Settings** > **Organization** in your RudderStack dashboard.\n\n[![Organization in RudderStack](https://www.rudderstack.com/docs/images/dashboard-guides/workspaces/organization.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/workspaces/organization.webp)\n\nIf your email is associated with multiple RudderStack organizations, you will see multiple organizations along with the number of workspaces in it once you log in:\n\n[![Select organization view](https://www.rudderstack.com/docs/images/dashboard-guides/workspaces/select-organization.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/workspaces/select-organization.webp)\n\nYou can select your preferred organization. To switch to a different organization and view the associated workspaces, click the **Switch organization** button:\n\n[![Switch organization](https://www.rudderstack.com/docs/images/dashboard-guides/workspaces/switch-organization.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/workspaces/switch-organization.webp)\n\n### Workspaces\n\nA **workspace** is an environment or nested grouping of resources and related settings. It is walled from other workspaces and you can use it for your development and production use-cases. See [Workspace types](#workspace-types) for more information.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Depending on your RudderStack Cloud plan, your organization can have multiple workspaces. See [Available workspaces by plan](#available-workspaces-by-plan) for more information.\n\nTo view the workspace details and manage its settings, go to **Settings** > **Workspace** in your RudderStack dashboard.\n\n[![Workspace in RudderStack](https://www.rudderstack.com/docs/images/dashboard-guides/workspaces/workspace.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/workspaces/workspace.webp)\n\nYou get the following options in this view:\n\n*   In the **General** tab, you can see the environment type (Dev/Prod) and the workspace ID. A **Workspace ID** is the unique identifier for the workspace. You can also edit your workspace name.\n*   In the **Data Management** tab, you can review and edit your [data retention and privacy](https://www.rudderstack.com/docs/dashboard-guides/data-management/) options.\n*   In the **Audit Logs** tab, you can track user activities within the workspace. See the [Audit Logs](https://www.rudderstack.com/docs/dashboard-guides/audit-logs/) guide for more information.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The workspace-related audit logs can only be accessed by the users having [admin permissions](https://www.rudderstack.com/docs/dashboard-guides/user-management/#organization-roles).\n\n*   In the **Alerts** tab, you can set workspace and source-level alerts for your Event Stream sources and destinations. See the [Alerts](https://www.rudderstack.com/docs/data-governance/alerts/) guide for more information.\n*   In the **Credentials** tab, you can store configuration data like secrets and variables and use them in your transformations. See the [Credentials](https://www.rudderstack.com/docs/transformations/credentials/) guide for more information.\n\n## Workspace types\n\nRudderStack provides the following workspace types:\n\n*   **Production**: In this workspace, you can set up stable and optimized data pipelines made available to your customers and end-users.\n*   **Development**: In this workspace, you can set up, test, and debug your data pipelines for optimal performance without affecting your end-users. You can also experiment with various RudderStack features.\n\nSee [Available workspaces by plan](#available-workspaces-by-plan) for more information on the number of workspaces you can set up based on your RudderStack Cloud plan. See [Add users](https://www.rudderstack.com/docs/dashboard-guides/user-management/#add-users) to add users to different workspaces. For differences between the development and production workspaces, see [FAQ](#faq).\n\n## Switch workspaces\n\nTo switch between workspaces, click **Workspace** > **Switch workspace**. Then, select the workspace you want to view.\n\n[![Switch workspace](https://www.rudderstack.com/docs/images/dashboard-guides/workspaces/switch-workspace.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/workspaces/switch-workspace.webp)\n\n## Access control\n\nYou can set the user permissions and access control rules at the [organization level](https://www.rudderstack.com/docs/dashboard-guides/user-management/#manage-users-in-organization) and the [workspaces level](https://www.rudderstack.com/docs/dashboard-guides/user-management/#manage-users-in-workspaces) within the organization.\n\nThe owner of the RudderStack Cloud account is assigned the role of an **Org Owner** by default. They can invite other members as **Org Admins** or **Org Members**. Further, if you [invite a user](https://www.rudderstack.com/docs/dashboard-guides/user-management/#invite-users) to your organization as **Org Admin**, they will have admin permissions for all the workspaces within that organization.\n\n## Available workspaces by plan\n\n| RudderStack Cloud plan | Number of workspaces | Availability |\n| --- | --- | --- |\n| Starter | 2 (1 Production, 1 Development) | Available by default. |\n| Growth | 2 (1 Production, 1 Development) | Available by default. |\n| Enterprise | Custom | Contact the [RudderStack team](mailto:support@rudderstack.com) to set up workspaces based on contract. |\n\n## FAQ\n\n#### What are the differences between the dev and prod workspaces in RudderStack?\n\nSome key differences between the development and production workspaces in RudderStack are listed below:\n\n*   Users can have different [resource roles](https://www.rudderstack.com/docs/dashboard-guides/user-management/#resource-roles) and [access policies](https://www.rudderstack.com/docs/dashboard-guides/user-management/#edit-access-policy) between development/production workspaces. For example, a user might be a [Connections Admin](https://www.rudderstack.com/docs/dashboard-guides/user-management/#connections) in the development workspace but not in the production workspace.\n*   The development workspace users will not be able to push sources, destinations, and pipeline configurations into the production workspace and vice versa.\n*   The development workspace exists on a slightly different infrastructure to the production workspace. There could be slightly longer processing times for features like [Live Events](https://www.rudderstack.com/docs/dashboard-guides/live-events/) as compared to the production workspace, which runs in a dedicated environment for the users.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Workspaces | RudderStack Docs",
    "description": "Switch between multiple workspaces in your RudderStack organization.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/api/audit-logs-api/",
    "markdown": "# Audit Logs API | RudderStack Docs\n\nAccess audit logs programmatically using the Audit Logs API.\n\nAvailable Plans\n\n*   enterprise\n\n* * *\n\n*     3 minute read  \n    \n\nThe Audit Logs API lets you programmatically access audit logs for running your security audits. You can use the API to:\n\n*   Access all existing audit logs.\n*   Access the audit logs generated after the last access.\n*   Filter audit logs based on workspaces, date, etc.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> You can also view [audit logs](https://www.rudderstack.com/docs/dashboard-guides/audit-logs/) in the RudderStack dashboard.\n\n## Prerequisites\n\n*   You must have the [Org OwnerAn Org Owner owns the RudderStack organization.](https://www.rudderstack.com/docs/resources/glossary/#org-owner) or [Org AdminAn Org Admin is an invited user with full access to the organization.](https://www.rudderstack.com/docs/resources/glossary/#org-admin) user role. See [User Management](https://www.rudderstack.com/docs/dashboard-guides/user-management/#manage-users-in-organization) for more information on user roles.\n*   Generate a [personal access token](https://www.rudderstack.com/docs/dashboard-guides/personal-access-token/) with **Admin** role in the RudderStack dashboard.\n\nTo generate your personal access token, go to **Settings** > **Your Profile** > **Account** tab and scroll down to **Personal access tokens**. Then, click **Generate new token**.\n\n[![New personal access token in RudderStack dashboard](https://www.rudderstack.com/docs/images/rudderstack-api/personal-access-token-1.webp)](https://www.rudderstack.com/docs/images/rudderstack-api/personal-access-token-1.webp)\n\nEnter the token name and choose **Admin** role from the dropdown:\n\n[![New personal access token in RudderStack dashboard](https://www.rudderstack.com/docs/images/api/pat-admin.webp)](https://www.rudderstack.com/docs/images/api/pat-admin.webp)\n\n## Authentication\n\nThe Audit Logs API uses [Bearer authentication](https://swagger.io/docs/specification/authentication/bearer-authentication/) in the following format:\n\n```\nAuthorization: Bearer <PERSONAL_ACCESS_TOKEN>\n```\n\n## Base URL\n\nUse the base URL for your API requests depending on your region:\n\n```\nhttps://api.rudderstack.com\n```\n\n```\nhttps://api.eu.rudderstack.com\n```\n\n## Access audit logs\n\nYou can access audit logs using the below endpoint:\n\n**Query parameters**:\n\nper\\_page\n\noptional, default is `100`\n\ninteger\n\nIndicates the number of items per page. You can set its value anywhere between the range of 1 to 100.\n\nstring\n\nFetches the audit logs corresponding to the workspace ID. If not provided, all the audit logs corresponding to the organization are fetched.\n\nstring\n\nDate and time in the ISO date-time format after which you want to fetch the audit logs.\n\n* * *\n\n*   **Example request**:\n\n```\nGET /v2/audit-logs\nHost: api.rudderstack.com\nAuthorization: Bearer 2QHVKQJeojt6Ae9e4iiOhycHrdG\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/audit-logs?after_cursor=213&per_page=2&workspace_id=1wJCPWvDLHgsi5inTHAChsrFn7O' \\\n--header 'Authorization: Bearer 2QHVKQJeojt6Ae9e4iiOhycHrdG'\n```\n\n*   **Example response**:\n\n```\n{\n  \"data\": [{\n      \"id\": \"2CHj1PJ61lv1NPyQtCiFi2KVX2y\",\n      \"actorId\": \"1vtoxffVBhY2c2iIS6o3GeM0O5B\",\n      \"actorType\": \"user\",\n      \"targetId\": \"2CHj1QBfmNWmpHOMAAkfDZ66fCr\",\n      \"targetType\": \"destination\",\n      \"action\": \"created\",\n      \"ip\": \"::ffff:10.1.3.23\",\n      \"createdAt\": \"2022-07-22T05:03:08.928Z\",\n      \"workspaceId\": \"1vtp6E0bfo3FoGChWFW2f81fogc\",\n      \"organizationId\": \"1vtp6F2GdSqeAHciTsEpNaW9mKy\"\n    },\n    {\n      \"id\": \"2CHj6cFHxk11t2QekhPzKhuu7BK\",\n      \"actorId\": \"1vtoxffVBhY2c2iIS6o3GeM0O5B\",\n      \"actorType\": \"user\",\n      \"targetId\": \"2CHj1QBfmNWmpHOMAAkfDZ66fCr\",\n      \"targetType\": \"destination\",\n      \"action\": \"updated\",\n      \"ip\": \"::ffff:10.1.3.23\",\n      \"createdAt\": \"2022-07-22T05:03:49.495Z\",\n      \"workspaceId\": \"1vtp6E0bfo3FoGChWFW2f81fogc\",\n      \"organizationId\": \"1vtp6F2GdSqeAHciTsEpNaW9mKy\"\n    }\n  ],\n  \"paging\": {\n    \"next\": \"/v2/audit-logs?after_cursor=2CHj6cFHxk11t2QekhPzKhuu7BK&per_page=2&workspace_id=1vtp6E0bfo3FoGChWFW2f81fogc\",\n    \"total\": 200\n  }\n}\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> RudderStack supports specific values for the `targetType` and `action` parameters. See [Supported target types and actions](#supported-target-types-and-actions) for more information.\n\n**Response object parameters**:\n\nobject\n\nContains the audit logs array.\n\nstring\n\nUnique identifier for the audit log entry.\n\nstring\n\nUnique identifier for the user who performed the action.\n\nstring\n\nDescribes who performed the action. RudderStack currently supports only `user` actor type.\n\nstring\n\nUnique identifier for the target of the action.\n\nstring\n\nDescribes the target on which the action is performed.\n\nstring\n\nAction performed by the user.\n\nstring\n\nIP address of the user who performed the action.\n\nstring\n\nTimestamp when the audit log was created\n\nstring\n\nUnique identifier for the workspace where the action was performed.\n\nstring\n\nUnique identifier for the organization where the action was performed.\n\nobject\n\nContains the pagination information.\n\nstring\n\nEndpoint to fetch the next page.\n\ninteger\n\nTotal number of audit logs resulting from the query.\n\n* * *\n\n### Supported target types and actions\n\nRudderStack currently supports following values for the `targetType` and `action` parameters pair:\n\n| `targetType` parameter | `action` parameter |\n| --- | --- |\n| `destination` | `connected_source` |\n| `destination` | `connected_transformation` |\n| `destination` | `created` |\n| `destination` | `deleted` |\n| `destination` | `disconnected_source` |\n| `destination` | `disconnected_transformation` |\n| `destination` | `updated` |\n| `destination` | `updated_transformation` |\n| `notification` | `updated` |\n| `permission` | `deleted_user_permissions` |\n| `permission` | `resource_access_updated` |\n| `permission` | `resource_locked` |\n| `profiles` | `created` |\n| `profiles` | `deleted` |\n| `profiles` | `updated` |\n| `source` | `connected_sql_model` |\n| `source` | `connected_tracking_plan` |\n| `source` | `created` |\n| `source` | `deleted` |\n| `source` | `disconnected_sql_model` |\n| `source` | `disconnected_tracking_plan` |\n| `source` | `updated` |\n| `source` | `updated_tracking_plan_config` |\n| `sql_model` | `created` |\n| `sql_model` | `deleted` |\n| `sql_model` | `updated` |\n| `transformation` | `created` |\n| `transformation` | `deleted` |\n| `transformation` | `updated` |\n| `transformation_library` | `created` |\n| `transformation_library` | `deleted` |\n| `transformation_library` | `updated` |\n| `user` | `added_to_organization` |\n| `user` | `changed_permission` |\n| `user` | `disabled_mfa` |\n| `user` | `enabled_mfa` |\n| `user` | `removed_from_organization` |\n| `user` | `updated_phone_number` |\n| `user_invitation` | `created` |\n| `user_invitation` | `deleted` |\n| `user_invitation` | `updated` |\n| `workspace` | `deleted` |\n| `workspace` | `updated_data_retention` |\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Audit Logs API | RudderStack Docs",
    "description": "Access audit logs programmatically using the Audit Logs API.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/standard-events/merge/",
    "markdown": "# Merge | RudderStack Docs\n\nGet started with the RudderStack Merge API.\n\n* * *\n\n*     2 minute read  \n    \n\n> ![danger](https://www.rudderstack.com/docs/images/danger.svg)\n> \n> **The `merge` API is deprecated and will be discontinued soon.**\n\nRudderStack’s `merge` API lets you merge different user identities and associate them to a single customer profile in the warehouse.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Currently, RudderStack supports `merge` only for identity resolution in its [BigQuery](https://www.rudderstack.com/docs/destinations/warehouse-destinations/bigquery/) and [Snowflake](https://www.rudderstack.com/docs/destinations/warehouse-destinations/snowflake/) warehouse destinations.\n\n## Sample payload\n\nA sample payload for the `merge` event after removing the [common fields](https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/) is shown below:\n\n```\n{\n  \"type\": \"merge\",\n  \"userId\": \"1hKOmRA4GRlm\",\n  \"mergeProperties\": [{\n      \"type\": \"email\",\n      \"value\": \"alex@example.com\"\n    },\n    {\n      \"type\": \"mobile\",\n      \"value\": \"+1-202-555-0146\"\n    }\n  ]\n}\n```\n\nIn the above example, `type` refers to a unique user identifier like email, phone number, device ID, etc. that can be associated to a given customer profile.\n\n## Merge fields\n\nApart from the [Common fields](https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/), the `merge` call accepts the following fields:\n\n| **Field** | **Type** | **Presence** | **Description** |\n| --- | --- | --- | --- |\n| `userId` | String | Required, if `anonymousId` is not present. | The unique user identifier. |\n| `anonymousId` | String | Required, if `userId` is not present. | The anonymous ID associated with a user or visitor. |\n| `mergeProperties` | Object | Required | The user properties to be merged and connected to a given user profile. |\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Either `userId` or `anonymousId` must be present in the `merge` event. Otherwise, you will get a **Request neither has anonymousId nor userId** error.\n\n## FAQ\n\n### Does RudderStack auto-merge any user identifiers?\n\nYes, RudderStack auto-merges the following user identifiers by default so you don’t need to call the `merge` API for them:\n\n*   `userId` and `previousId` for the [`alias`](https://www.rudderstack.com/docs/event-spec/standard-events/alias/) calls.\n*   `userId` and `anonymousId` for the [`identify`](https://www.rudderstack.com/docs/event-spec/standard-events/identify/), [`track`](https://www.rudderstack.com/docs/event-spec/standard-events/track/), [`group`](https://www.rudderstack.com/docs/event-spec/standard-events/group/), and [`screen`](https://www.rudderstack.com/docs/event-spec/standard-events/screen/) calls.\n\nFor merging other user identifiers like device ID, phone number, email ID, etc. you need to use the `merge` API.\n\n### What is the difference between the alias and merge calls?\n\nThe [`alias`](https://www.rudderstack.com/docs/event-spec/standard-events/alias/) call lets you merge two identities of a given user. You can use this call to link the user’s previous identifier `previousId` with the user’s new identifier `userId`. You can merge only two user identifiers at a time using `alias`.\n\nOn the other hand, the `merge` API lets you perform identity resolution by stitching together various user identifiers across different touchpoints to a single customer profile. With this call, you can merge any number of user identifiers corresponding to different customer touchpoints like email, phone number, device ID, etc.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Merge | RudderStack Docs",
    "description": "Get started with the RudderStack Merge API.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/api/data-catalog-api/",
    "markdown": "# Data Catalog API | RudderStack Docs\n\nManage your tracking plans, events, and properties in your data catalog programmatically.\n\nAvailable Plans\n\n*   growth\n*   enterprise\n\n* * *\n\n*     16 minute read  \n    \n\nRudderStack’s Data Catalog API lets you:\n\n*   Create and manage your tracking plans programmatically.\n*   Add or update events and properties in your [data catalog](https://www.rudderstack.com/docs/data-governance/data-catalog/).\n*   Create and manage categories for your data catalog events.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> The Data Catalog API is a part of RudderStack’s [Data Governance toolkit](https://www.rudderstack.com/docs/data-governance/overview/) that ensures the quality and integrity of your data in a secure and compliant manner.\n\n## Prerequisites\n\nGenerate a [personal access token](#faq) in the RudderStack dashboard.\n\n## Authentication\n\nThe Data Catalog API uses [Bearer authentication](https://swagger.io/docs/specification/authentication/bearer-authentication/) in the following format:\n\n```\nAuthorization: Bearer <PERSONAL_ACCESS_TOKEN>\n```\n\n## Base URL\n\nUse the base URL for your API requests depending on your region:\n\n```\nhttps://api.rudderstack.com/v2\n```\n\n```\nhttps://api.eu.rudderstack.com/v2\n```\n\n## Manage tracking plans\n\nThis section covers the API endpoints for creating and managing your [tracking plans](https://www.rudderstack.com/docs/data-governance/tracking-plans/).\n\n### Create tracking plan\n\nPOST\n\n/catalog/tracking-plans\n\n**Request body**\n\nString\n\nTracking plan name.\n\nNote that:\n\n*   The name must be between 3 and 65 characters and should start with a letter.\n*   It must contain only letters, numbers, underscores, commas, spaces, dashes, and dots.\n\nString\n\nTracking plan description.\n\n**Example request**\n\n```\nPOST /v2/catalog/tracking-plans HTTP/1.1\nHost: api.rudderstack.com\nContent-Type: application/json\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\nContent-Length: 83\n\n{\n    \"name\": \"Product Ordered Plan\",\n    \"description\": \"Tracking plan for users placing an order for the product.\"\n}\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/catalog/tracking-plans' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY' \\\n--data '{\n    \"name\": \"Product Ordered Plan\",\n    \"description\": \"Tracking plan for users placing an order for the product.\"\n}'\n```\n\n**Example response**\n\n```\n{\n  \"id\": \"tp_2gopz6tfKxAjpS4TjuqVIeTdm7T\",\n  \"name\": \"Product Ordered Plan\",\n  \"description\": \"Tracking plan for users placing an order for the product.\",\n  \"version\": 1,\n  \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n  \"creationType\": \"BackendAPI\",\n  \"createdAt\": \"2024-05-22T10:34:03.016Z\",\n  \"updatedAt\": \"2024-05-22T10:34:03.016Z\"\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Tracking plan is successfully created. RudderStack also returns an ID for the newly created tracking plan. |\n| 400 | Bad or invalid request. |\n\n### List all tracking plans\n\nGET\n\n/catalog/tracking-plans\n\n**Example request**\n\n```\nGET /v2/catalog/tracking-plans HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/catalog/tracking-plans' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY'\n```\n\n**Example response**\n\n```\n{\n  \"trackingPlans\": [{\n      \"id\": \"tp_2gp8cYq8wYGn6ht5YTUekoiysxL\",\n      \"name\": \"Product Ordered Plan\",\n      \"description\": \"Tracking plan for users placing an order for the product.\",\n      \"version\": 1,\n      \"createdAt\": \"2024-05-22T13:07:18.617Z\",\n      \"updatedAt\": \"2024-05-22T13:07:18.617Z\",\n      \"creationType\": \"BackendAPI\",\n      \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\"\n    },\n    {\n      \"id\": \"tp_2bgGOHm0YH3VWWfO8uMzNP9IINI\",\n      \"name\": \"Order Completed Plan\",\n      \"description\": \"Tracking plan for users completing an order for the product.\",\n      \"version\": 4,\n      \"createdAt\": \"2024-01-30T15:41:14.446Z\",\n      \"updatedAt\": \"2024-02-01T08:59:15.095Z\",\n      \"creationType\": \"Event Audit API\",\n      \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\"\n    }\n  ]\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | List of all tracking plans in the associated workspace. |\n\n### Get tracking plan by ID\n\nGET\n\n/catalog/tracking-plans/{id}\n\n**Path parameters**\n\nString\n\nTracking plan version. Note that it must be a number.\n\n**Example request**\n\n```\nGET /v2/catalog/tracking-plans/tp_2gp8cYq8wYGn6ht5YTUekoiysxL HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/catalog/tracking-plans/tp_2gp8cYq8wYGn6ht5YTUekoiysxL' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY'\n```\n\n**Example response**\n\n```\n{\n  \"id\": \"tp_2gp8cYq8wYGn6ht5YTUekoiysxL\",\n  \"name\": \"Product Ordered Plan\",\n  \"description\": \"Tracking plan for users placing an order for the product.\",\n  \"version\": 1,\n  \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n  \"creationType\": \"BackendAPI\",\n  \"createdAt\": \"2024-05-22T13:07:18.617Z\",\n  \"updatedAt\": \"2024-05-22T13:07:18.617Z\"\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Tracking plan is updated successfully. |\n| 404 | Tracking plan not found for the specified ID. |\n\n### Update tracking plan\n\nPUT\n\n/catalog/tracking-plans/{id}\n\n**Path parameters**\n\n**Request body**\n\nTo update the tracking plan, **at least one** of the following parameters is required:\n\nString\n\nTracking plan name.\n\nNote that:\n\n*   The name must be between 3 and 65 characters and should start with a letter.\n*   It must contain only letters, numbers, underscores, commas, spaces, dashes, and dots.\n\nString\n\nTracking plan description.\n\n**Example request**\n\n```\nPUT /v2/catalog/tracking-plans/tp_2gp8cYq8wYGn6ht5YTUekoiysxL HTTP/1.1\nHost: api.rudderstack.com\nContent-Length: 87\n\n{\n    \"name\": \"New Product Ordered Plan\",\n    \"description\": \"Updated tracking plan for users placing an order for the product.\"\n}\n```\n\n```\ncurl --location --request PUT 'https://api.rudderstack.com/v2/catalog/tracking-plans/tp_2gp8cYq8wYGn6ht5YTUekoiysxL' \\\n--data '{\n    \"name\": \"New Product Ordered Plan\",\n    \"description\": \"Updated tracking plan for users placing an order for the product.\"\n}'\n```\n\n**Example response**\n\n```\n{\n  \"id\": \"tp_2gp8cYq8wYGn6ht5YTUekoiysxL\",\n  \"name\": \"New Product Ordered Plan\",\n  \"description\": \"Updated tracking plan for users placing an order for the product.\",\n  \"version\": 2,\n  \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n  \"creationType\": \"BackendAPI\",\n  \"createdAt\": \"2024-05-22T10:34:03.016Z\",\n  \"updatedAt\": \"2024-05-22T10:36:49.252Z\"\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Tracking plan is updated successfully. |\n| 400 | Bad or invalid request. |\n\n### Delete tracking plan\n\n> ![danger](https://www.rudderstack.com/docs/images/danger.svg)\n> \n> Deleted tracking plans cannot be recovered or restored.\n\nDELETE\n\n/catalog/tracking-plans/{id}\n\n**Path parameters**\n\n**Example request**\n\n```\nDELETE /v2/catalog/tracking-plans/tp_2gp8cYq8wYGn6ht5YTUekoiysxL HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\n```\n\n```\ncurl --location --request DELETE 'https://api.rudderstack.com/v2/catalog/tracking-plans/tp_2gp8cYq8wYGn6ht5YTUekoiysxL' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY'\n```\n\n**Example response**\n\n```\n{\n  \"name\": \"New Product Ordered Plan\",\n  \"version\": 1,\n  \"description\": \"Updated tracking plan for users placing an order for the product.\",\n  \"creationType\": \"BackendAPI\",\n  \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n  \"createdBy\": \"2KDKycoVHAOLttVvzBiqw12O3Hr\",\n  \"updatedBy\": null,\n  \"createdAt\": \"2024-05-22T13:41:33.057Z\",\n  \"updatedAt\": \"2024-05-22T13:41:33.057Z\",\n  \"events\": []\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Tracking plan is deleted successfully. |\n| 400 | Bad or invalid request. |\n\n## Manage events in tracking plans\n\nThis section covers the API endpoints for upserting and managing events in your tracking plans.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> The Data Catalog API creates the events and properties in the data catalog only if they do not exist already.\n\n### Upsert event to tracking plan\n\nPATCH\n\n/catalog/tracking-plans/{id}/events\n\n**Path parameters**\n\n**Request body**\n\nString\n\nName of the event to be upserted.\n\nNote that:\n\n*   The name must be between 3 and 65 characters and should start with a letter.\n*   It must contain only letters, numbers, underscores, commas, spaces, dashes, and dots.\n*   For non-`track` events, the name should be an empty string.\n\nString\n\nType of event to be upserted.\n\nNote that:\n\n*   Once set, the event type **cannot** be updated later.\n*   Allowed event types are `track`, `identify`, `group`, `page`, and `screen`.\n\nString\n\nCategory ID of the event. It should be a valid, non-empty string.\n\nObject\n\n[JSON schema](https://rudderstack.com/docs/api/data-catalog-api/json-schema/) against which RudderStack validates the event. Note that event rules cannot be empty.\n\n**Example request**\n\n```\nPATCH /v2/catalog/tracking-plans/tp_2gopz6tfKxAjpS4TjuqVIeTdm7T/events HTTP/1.1\nHost: api.rudderstack.com\nContent-Type: application/json\nAuthorization: ••••••\nContent-Length: 955\n\n{\n  \"name\": \"Product Viewed\",\n  \"eventType\": \"track\",\n  \"description\": \"User viewed a product.\",\n  \"categoryId\": null,\n  \"rules\": {\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"type\": \"object\",\n    \"properties\": {\n      \"properties\": {\n        \"type\": \"object\",\n        \"required\": [\n          \"amount\"\n        ],\n        \"additionalProperties\": false,\n        \"properties\": {\n          \"amount\": {\n            \"type\": [\n              \"number\"\n            ]\n          },\n        }\n      }\n    }\n  }\n}\n```\n\n```\ncurl --location --request PATCH 'https://api.rudderstack.com/v2/catalog/tracking-plans/tp_2gopz6tfKxAjpS4TjuqVIeTdm7T/events' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY' \\\n--data '{\n  \"name\": \"Product Viewed\",\n  \"eventType\": \"track\",\n  \"description\": \"User viewed a product.\",\n  \"categoryId\": null,\n  \"rules\": {\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"type\": \"object\",\n    \"properties\": {\n      \"properties\": {\n        \"type\": \"object\",\n        \"required\": [\n          \"amount\"\n        ],\n        \"additionalProperties\": false,\n        \"properties\": {\n          \"amount\": {\n            \"type\": [\n              \"number\"\n            ]\n          },\n        }\n      }\n    }\n  }\n}'\n```\n\n**Example response**\n\n```\n{\n  \"id\": \"tp_2gopz6tfKxAjpS4TjuqVIeTdm7T\",\n  \"name\": \"Product Viewed Plan\",\n  \"version\": 3,\n  \"description\": \"User viewed a product.\",\n  \"creationType\": \"BackendAPI\",\n  \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n  \"createdAt\": \"2024-05-22T10:34:03.016Z\",\n  \"updatedAt\": \"2024-05-22T11:01:24.706Z\"\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Event is upserted to the tracking plan successfully. The API gives the updated tracking plan information as a response. |\n| 400 | Bad or invalid request. |\n\n### List all events in tracking plan\n\nGET\n\n/catalog/tracking-plans/{id}/events\n\n**Path parameters**\n\nNumber\n\nEvents shown from given page. Default page size is 50.\n\n**Example request**\n\n```\nGET /v2/catalog/tracking-plans/tp_2gopz6tfKxAjpS4TjuqVIeTdm7T/events HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/catalog/tracking-plans/tp_2gopz6tfKxAjpS4TjuqVIeTdm7T/events' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY'\n```\n\n**Example response**\n\n```\n{\n  \"data\": [{\n    \"id\": \"ev_2gotJFKuOtdDY4XbSdKjkwk4qc2\",\n    \"name\": \"Product Viewed\",\n    \"description\": \"User viewed a product.\",\n    \"eventType\": \"track\",\n    \"categoryId\": null,\n    \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n    \"createdBy\": \"2KDKycoVHAOLttVvzBiqw12O3Hr\",\n    \"updatedBy\": null,\n    \"createdAt\": \"2024-05-22T11:01:24.706Z\",\n    \"updatedAt\": \"2024-05-22T11:01:24.706Z\",\n    \"identitySection\": \"properties\",\n    \"additionalProperties\": false\n  }],\n  \"total\": 1,\n  \"currentPage\": 1,\n  \"pageSize\": 50\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | All the events in a tracking plan are fetched successfully. |\n\n### Get tracking plan event by ID\n\nGET\n\n/catalog/tracking-plans/{id}/events/{eventId}\n\n**Path parameters**\n\n**Example request**\n\n```\nGET /v2/catalog/tracking-plans/tp_2gopz6tfKxAjpS4TjuqVIeTdm7T/events/ev_2gotJFKuOtdDY4XbSdKjkwk4qc2 HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/catalog/tracking-plans/tp_2gopz6tfKxAjpS4TjuqVIeTdm7T/events/ev_2gotJFKuOtdDY4XbSdKjkwk4qc2' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY'\n```\n\n**Example response**\n\n```\n{\n  \"id\": \"ev_2gotJFKuOtdDY4XbSdKjkwk4qc2\",\n  \"name\": \"Product Viewed\",\n  \"description\": \"User viewed a product.\",\n  \"eventType\": \"track\",\n  \"categoryId\": null,\n  \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n  \"createdBy\": \"2KDKycoVHAOLttVvzBiqw12O3Hr\",\n  \"updatedBy\": null,\n  \"createdAt\": \"2024-05-22T11:01:24.706Z\",\n  \"updatedAt\": \"2024-05-22T11:01:24.706Z\",\n  \"identitySection\": \"properties\",\n  \"rules\": {\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"type\": \"object\",\n    \"properties\": {\n      \"properties\": {\n        \"type\": \"object\",\n        \"required\": [\n          \"amount\"\n        ],\n        \"additionalProperties\": false,\n        \"properties\": {\n          \"amount\": {\n            \"type\": [\n              \"number\"\n            ]\n          },\n        }\n      }\n    }\n  }\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Event specified by the ID is fetched successfully. |\n| 404 | Tracking plan event not found for the specified ID. |\n\n### Delete event from tracking plan\n\nDELETE\n\n/catalog/tracking-plans/{id}/events/{eventId}\n\n**Path parameters**\n\n**Example request**\n\n```\nDELETE /v2/catalog/tracking-plans/tp_2gopz6tfKxAjpS4TjuqVIeTdm7T/events/ev_2gotJFKuOtdDY4XbSdKjkwk4qc2 HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\n```\n\n```\ncurl --location --request DELETE 'https://api.rudderstack.com/v2/catalog/tracking-plans/tp_2gopz6tfKxAjpS4TjuqVIeTdm7T/events/ev_2gotJFKuOtdDY4XbSdKjkwk4qc2' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY'\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 204 | Event is deleted from tracking plan successfully. |\n| 400 | Bad or invalid request. |\n\n## Manage events in data catalog\n\nThis section covers the API endpoints for creating and managing events in your [data catalog](https://www.rudderstack.com/docs/data-governance/data-catalog/).\n\n### Create new event\n\n**Request body**\n\nString\n\nName of the event.\n\nNote that:\n\n*   The name must be between 3 and 65 characters and should start with a letter.\n*   It must contain only letters, numbers, underscores, commas, spaces, dashes, and dots.\n*   For non-`track` events, the name should be an empty string.\n\nString\n\nType of event to be created in the data catalog.\n\nNote that:\n\n*   Once set, the event type **cannot** be updated later.\n*   Allowed event types are `track`, `identify`, `group`, `page`, and `screen`.\n\nString\n\nCategory ID of the event. It should be a valid, non-empty string.\n\n**Example request**\n\n```\nPOST /v2/catalog/events HTTP/1.1\nHost: api.rudderstack.com\nContent-Type: application/json\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\nContent-Length: 145\n\n{\n  \"name\": \"Product Viewed\",\n  \"description\": \"User viewed a product\",\n  \"eventType\": \"track\",\n  \"categoryId\": null\n}\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/catalog/events' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: ••••••' \\\n--data '{\n  \"name\": \"Product Viewed\",\n  \"description\": \"User viewed a product\",\n  \"eventType\": \"track\",\n  \"categoryId\": null\n}'\n```\n\n**Example response**\n\n```\n{\n  \"name\": \"Product Viewed\",\n  \"description\": \"User viewed a product.\",\n  \"eventType\": \"track\",\n  \"categoryId\": null,\n  \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n  \"createdBy\": \"2KDKycoVHAOLttVvzBiqw12O3Hr\",\n  \"id\": \"ev_2gqmsfib1Zl6n6QL0mjCi9PJbDS\",\n  \"createdAt\": \"2024-05-23T03:08:09.972Z\",\n  \"updatedAt\": \"2024-05-23T03:08:09.972Z\"\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Event is created successfully. |\n| 400 | Invalid request. |\n\n### List all events\n\n**Query parameters**\n\nString\n\nPage number. The API displays 50 events per page by default.\n\nString\n\nOrder the events list by a specific field.  \n\nAllowed fields are `name`, `createdAt`, `updatedAt`. For example, `name:asc`.\n\n**Example request**\n\n```\nGET /v2/catalog/events?page=1&orderBy=name:desc HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/catalog/events?page=1&orderBy=name%3Adesc' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY'\n```\n\n**Example response**\n\n```\n{\n  \"data\": [{\n      \"id\": \"ev_2g60ZQeit5D54rBHUUh0oK3IxzH\",\n      \"name\": \"Order Placed\",\n      \"description\": \"User placed an order.\",\n      \"eventType\": \"track\",\n      \"categoryId\": null,\n      \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n      \"createdBy\": \"1zirfVbEQN0zIImR235a1JivVYU\",\n      \"updatedBy\": null,\n      \"createdAt\": \"2024-05-06T13:39:34.294Z\",\n      \"updatedAt\": \"2024-05-06T13:39:34.294Z\"\n    },\n    ....\n\n    {\n      \"id\": \"ev_2dJfRK8t0hOmmAaCTc0VvMB36e1\",\n      \"name\": \"Product Added to Cart\",\n      \"description\": \"User added product to cart.\",\n      \"eventType\": \"track\",\n      \"categoryId\": null,\n      \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n      \"createdBy\": \"1zirfVbEQN0zIImR235a1JivVYU\",\n      \"updatedBy\": \"1zirfVbEQN0zIImR235a1JivVYU\",\n      \"createdAt\": \"2024-03-06T13:18:12.044Z\",\n      \"updatedAt\": \"2024-05-13T11:39:40.115Z\"\n    },\n  ],\n  \"total\": 3563,\n  \"currentPage\": 1,\n  \"pageSize\": 50\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | All events in the data catalog are retrieved successfully. |\n\n### Get event by ID\n\n**Path parameters**\n\n**Example request**\n\n```\nGET /v2/catalog/events/ev_2dJfRQIZLrBhqdLoLoxywHpicLp HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/catalog/events/ev_2dJfRQIZLrBhqdLoLoxywHpicLp' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY'\n```\n\n**Example response**\n\n```\n{\n  \"id\": \"ev_2dJfRQIZLrBhqdLoLoxywHpicLp\",\n  \"name\": \"Product Viewed\",\n  \"description\": \"User viewed a product.\",\n  \"eventType\": \"track\",\n  \"categoryId\": null,\n  \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n  \"createdBy\": \"1zirfVbEQN0zIImR235a1JivVYU\",\n  \"updatedBy\": \"2KDKycoVHAOLttVvzBiqw12O3Hr\",\n  \"createdAt\": \"2024-03-06T13:18:12.044Z\",\n  \"updatedAt\": \"2024-05-22T14:57:50.265Z\",\n  \"category\": null\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | All events in the data catalog are retrieved successfully. |\n| 404 | Event not found for the specified event ID. |\n\n### Update event\n\n**Path parameters**\n\n**Request body**\n\nTo update an event in the data catalog, **at least one** of the following parameters is required:\n\nString\n\nName of the event.\n\nNote that:\n\n*   The name must be between 3 and 65 characters and should start with a letter.\n*   It must contain only letters, numbers, underscores, commas, spaces, dashes, and dots.\n*   For non-`track` events, the name should be an empty string.\n\nString\n\nCategory ID of the event. It should be a valid, non-empty string.\n\n**Example request**\n\n```\nPUT /v2/catalog/events/ev_2dJfRQIZLrBhqdLoLoxywHpicLp HTTP/1.1\nHost: api.rudderstack.com\nContent-Type: application/json\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\nContent-Length: 98\n\n{\n  \"name\": \"Product Viewed Again\",\n  \"description\": \"User viewed a product again.\",\n  \"categoryId\": null\n}\n```\n\n```\ncurl --location --request PUT 'https://api.rudderstack.com/v2/catalog/events/ev_2dJfRQIZLrBhqdLoLoxywHpicLp' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY' \\\n--data '{\n  \"name\": \"Product Viewed Again\",\n  \"description\": \"User viewed a product again.\",\n  \"categoryId\": null\n}'\n```\n\n**Example response**\n\n```\n{\n  \"name\": \"Product Viewed Again\",\n  \"description\": \"User revisited a product on the website.\",\n  \"categoryId\": null\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Event is updated successfully. |\n| 404 | Event not found for the specified event ID. |\n\n### Delete event\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> You cannot delete an event that is connected to a tracking plan. Use the [Delete event from tracking plan](#delete-event-from-tracking-plan) API to disconnect the event and then try deleting it.\n\nDELETE\n\n/catalog/events/{id}\n\n**Path parameters**\n\n**Example request**\n\n```\nDELETE /v2/catalog/events/ev_2dJfRQIZLrBhqdLoLoxywHpicLp HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\n```\n\n```\ncurl --location --request DELETE 'https://api.rudderstack.com/v2/catalog/events/ev_2dJfRQIZLrBhqdLoLoxywHpicLp' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY'\n```\n\n**Example response**\n\n```\n{\n  \"name\": \"Product Purchased\",\n  \"description\": \"User purchased a product on the website.\",\n  \"eventType\": \"track\",\n  \"categoryId\": null,\n  \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n  \"createdBy\": \"2KDKycoVHAOLttVvzBiqw12O3Hr\",\n  \"updatedBy\": null,\n  \"createdAt\": \"2024-05-22T14:59:14.287Z\",\n  \"updatedAt\": \"2024-05-22T14:59:14.287Z\"\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Event is deleted from the catalog successfully. |\n| 404 | Event not found for the specified event ID. |\n\n## Manage properties in data catalog\n\nThis section covers the API endpoints for creating and managing properties in your [data catalog](https://www.rudderstack.com/docs/data-governance/data-catalog/).\n\n### Create new property\n\n**Request body**\n\nString\n\nProperty name.\n\nNote that:\n\n*   The name must be of at least one character and should start with a letter.\n*   It must contain only letters, numbers, underscores, and spaces.\n\nString\n\nProperty description.\n\nString\n\nData type of the property.\n\nNote that:\n\n*   The data type must be either string, integer, number, object, array, boolean, null, or multi data type.\n*   If not explicitly set, RudderStack allows all the above data types for the property, by default.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> RudderStack supports multi data type for the `type` parameter. An example is shown:\n> \n> ```\n> {\n>   \"type\": [\"string\", \"integer\", \"boolean\", \"null\"]\n> }\n> ```\n\n**Example request**\n\n```\nPOST /v2/catalog/properties HTTP/1.1\nHost: api.rudderstack.com\nContent-Type: application/json\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\nContent-Length: 117\n\n{\n  \"name\": \"Sample Property\",\n  \"description\": \"A sample property\",\n  \"type\": [\"string\", \"integer\", \"object\"]\n}\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/catalog/properties' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY' \\\n--data '{\n  \"name\": \"Sample Property\",\n  \"description\": \"A sample property\",\n  \"type\": [\"string\", \"integer\", \"object\"]\n}'\n```\n\n**Example response**\n\n```\n{\n  \"name\": \"Sample Property\",\n  \"description\": \"A sample property\",\n  \"type\": \"integer,object,string\",\n  \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n  \"createdBy\": \"2KDKycoVHAOLttVvzBiqw12O3Hr\",\n  \"id\": \"prop_2gqpkKg1GtHWKR8JtNChoKsqhIK\",\n  \"createdAt\": \"2024-05-23T03:31:43.297Z\",\n  \"updatedAt\": \"2024-05-23T03:31:43.297Z\"\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Property is created successfully. |\n| 400 | Invalid request. |\n\n### List all properties\n\n**Path parameters**\n\nString\n\nOrder the properties list by a specific field.  \n\nAllowed fields are `name`, `createdAt`, `updatedAt`. For example, `name:asc`.\n\n**Example request**\n\n```\nGET /v2/catalog/properties?page=1&orderBy=name:asc HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/catalog/properties?page=1&orderBy=name%3Aasc' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY'\n```\n\n**Example response**\n\n```\n{\n  \"data\": [{\n      \"id\": \"prop_2dJfRQ233WrPRpWBPqbF4PuiMc0\",\n      \"name\": \"affiliation\",\n      \"description\": \"Product affiliation\",\n      \"type\": \"string\",\n      \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n      \"createdBy\": \"1zirfVbEQN0zIImR235a1JivVYU\",\n      \"updatedBy\": null,\n      \"createdAt\": \"2024-03-06T13:18:12.044Z\",\n      \"updatedAt\": \"2024-03-06T13:18:12.044Z\"\n    },\n\n    ...\n\n    {\n      \"id\": \"prop_2bfXbQgjn4298XzqlyxmktRAX9d\",\n      \"name\": \"Email\",\n      \"description\": \"User's email\",\n      \"type\": \"string\",\n      \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n      \"createdBy\": \"1zirfVbEQN0zIImR235a1JivVYU\",\n      \"updatedBy\": \"1zirfVbEQN0zIImR235a1JivVYU\",\n      \"createdAt\": \"2024-01-30T09:32:57.983Z\",\n      \"updatedAt\": \"2024-01-30T09:33:18.885Z\"\n    }\n  ],\n  \"total\": 450,\n  \"currentPage\": 1,\n  \"pageSize\": 50\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | All properties in the data catalog are retrieved successfully. |\n\n### Get property by ID\n\nGET\n\n/catalog/properties/{id}\n\n**Path parameters**\n\n**Example request**\n\n```\nGET /v2/catalog/properties/prop_2bfXbQgjn4298XzqlyxmktRAX9d HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/catalog/properties/prop_2bfXbQgjn4298XzqlyxmktRAX9d' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY'\n```\n\n**Example response**\n\n```\n{\n  \"id\": \"prop_2bfXbQgjn4298XzqlyxmktRAX9d\",\n  \"name\": \"Email\",\n  \"description\": \"User's email\",\n  \"type\": \"string\",\n  \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n  \"createdBy\": \"1zirfVbEQN0zIImR235a1JivVYU\",\n  \"updatedBy\": \"1zirfVbEQN0zIImR235a1JivVYU\",\n  \"createdAt\": \"2024-01-30T09:32:57.983Z\",\n  \"updatedAt\": \"2024-01-30T09:33:18.885Z\"\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | All properties in the data catalog are retrieved successfully. |\n| 404 | Property not found for the specified event ID. |\n\n### Update property\n\nPUT\n\n/catalog/properties/{id}\n\n**Path parameters**\n\n**Request body**\n\nTo update the event property in the data catalog, **at least one** of the following parameters is required:\n\nString\n\nProperty name.\n\nNote that:\n\n*   The name must be of at least one character and should start with a letter.\n*   It must contain only letters, numbers, underscores, and spaces.\n\nString\n\nProperty description.\n\nString\n\nData type of the property.\n\nNote that:\n\n*   The data type must be either string, integer, number, object, array, boolean, null, or multi data type.\n*   If not explicitly set, RudderStack allows all the above data types for the property, by default.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> RudderStack supports multi data type for the `type` parameter. An example is shown:\n> \n> ```\n> {\n>   \"type\": [\"string\", \"integer\", \"boolean\", \"null\"]\n> }\n> ```\n\n**Example request**\n\n```\nPUT /v2/catalog/properties/prop_2bfXbQgjn4298XzqlyxmktRAX9d HTTP/1.1\nHost: api.rudderstack.com\nContent-Type: application/json\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\nContent-Length: 45\n\n{\n  \"description\": \"User's email address\"\n}\n```\n\n```\ncurl --location --request PUT 'https://api.rudderstack.com/v2/catalog/properties/prop_2bfXbQgjn4298XzqlyxmktRAX9d' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY' \\\n--data '{\n  \"description\": \"User's email address\"\n}'\n```\n\n**Example response**\n\n```\n{\n  \"id\": \"prop_2bfXbQgjn4298XzqlyxmktRAX9d\",\n  \"name\": \"Email\",\n  \"description\": \"User's email address\",\n  \"type\": \"number\",\n  \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n  \"createdBy\": \"1zirfVbEQN0zIImR235a1JivVYU\",\n  \"updatedBy\": \"2KDKycoVHAOLttVvzBiqw12O3Hr\",\n  \"createdAt\": \"2024-01-30T09:32:57.983Z\",\n  \"updatedAt\": \"2024-05-23T03:41:10.715Z\"\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Property is updated successfully. |\n| 400 | Property not found for the specified event ID. |\n\n### Delete property\n\nDELETE\n\n/catalog/properties/{id}\n\n**Path parameters**\n\n**Example request**\n\n```\nDELETE /v2/catalog/properties/prop_2bfXbQgjn4298XzqlyxmktRAX9d HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\n```\n\n```\ncurl --location --request DELETE 'https://api.rudderstack.com/v2/catalog/properties/prop_2bfXbQgjn4298XzqlyxmktRAX9d' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY'\n```\n\n**Example response**\n\n```\n{\n  \"name\": \"Email\",\n  \"description\": \"User's email address\",\n  \"type\": \"number\",\n  \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n  \"createdBy\": \"1zirfVbEQN0zIImR235a1JivVYU\",\n  \"updatedBy\": \"2KDKycoVHAOLttVvzBiqw12O3Hr\",\n  \"createdAt\": \"2024-01-30T09:32:57.983Z\",\n  \"updatedAt\": \"2024-05-23T03:41:10.715Z\"\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Property is deleted from the catalog successfully. |\n| 400 | Property not found for the specified event ID. |\n\n## Manage categories in data catalog\n\nThis section covers the API endpoints for creating and managing categories in your [data catalog](https://www.rudderstack.com/docs/data-governance/data-catalog/). Go to **Monitor** > **Data Catalog** > **Events** tab in your RudderStack dashboard to view the categories and associate them to your events.\n\n[![Data catalog categories](https://www.rudderstack.com/docs/images/data-governance/categories.webp)](https://www.rudderstack.com/docs/images/data-governance/categories.webp)\n\n### Create new category\n\n**Request body**\n\nString\n\nCategory name.\n\nNote that:\n\n*   The name must be between 3 and 65 characters and should start with a letter.\n*   It must contain only letters, numbers, underscores, commas, spaces, dashes, and dots.\n\nString\n\nCategory description.\n\n**Example request**\n\n```\nPOST /v2/catalog/categories HTTP/1.1\nHost: api.rudderstack.com\nContent-Type: application/json\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\nContent-Length: 70\n\n{\n  \"name\": \"Onboarding\",\n  \"description\": \"Customer onboarding\"\n}\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/catalog/categories' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY' \\\n--data '{\n  \"name\": \"Onboarding\",\n  \"description\": \"Customer onboarding\"\n}'\n```\n\n**Example response**\n\n```\n{\n  \"name\": \"Onboarding\",\n  \"description\": \"Customer onboarding\",\n  \"icon\": \"star\",\n  \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n  \"createdBy\": \"2KDKycoVHAOLttVvzBiqw12O3Hr\",\n  \"id\": \"cat_2gqs1Yzy1VpUIewm69meqc6d8zH\",\n  \"createdAt\": \"2024-05-23T03:50:27.416Z\",\n  \"updatedAt\": \"2024-05-23T03:50:27.416Z\"\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Category is created successfully. |\n| 400 | Invalid Request. |\n\n### List all categories\n\n**Path parameters**\n\nString\n\nOrder the categories list by a specific field.  \n\nAllowed fields are `name`, `createdAt`, `updatedAt`. For example, `name:asc`.\n\n**Example request**\n\n```\nGET /v2/catalog/categories HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/catalog/categories' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY'\n```\n\n**Example response**\n\n```\n{\n  \"data\": [{\n      \"id\": \"cat_2gqs1Yzy1VpUIewm69meqc6d8zH\",\n      \"name\": \"Onboarding\",\n      \"description\": \"Customer onboarding\",\n      \"icon\": \"star\",\n      \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n      \"createdBy\": \"2KDKycoVHAOLttVvzBiqw12O3Hr\",\n      \"updatedBy\": null,\n      \"createdAt\": \"2024-05-23T03:50:27.416Z\",\n      \"updatedAt\": \"2024-05-23T03:50:27.416Z\"\n    },\n\n    ...\n\n    {\n      \"id\": \"cat_2fpA1YOrdbVgIuvu7n6J5eza5ri\",\n      \"name\": \"Product Experience\",\n      \"description\": \"Enhance overall product and customer experience\",\n      \"icon\": \"star\",\n      \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n      \"createdBy\": \"1zirfVbEQN0zIImR235a1JivVYU\",\n      \"updatedBy\": null,\n      \"createdAt\": \"2024-04-30T14:30:30.254Z\",\n      \"updatedAt\": \"2024-04-30T14:30:30.254Z\"\n    }\n  ],\n  \"total\": 10,\n  \"currentPage\": 1,\n  \"pageSize\": 1000\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | All the categories in a tracking plan are fetched successfully. |\n\n### Get category by ID\n\nGET\n\n/catalog/categories/{id}\n\n**Path parameters**\n\n**Example request**\n\n```\nGET /v2/catalog/categories/cat_2gqs1Yzy1VpUIewm69meqc6d8zH HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/catalog/categories/cat_2gqs1Yzy1VpUIewm69meqc6d8zH' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY'\n```\n\n**Example response**\n\n```\n{\n  \"id\": \"cat_2gqs1Yzy1VpUIewm69meqc6d8zH\",\n  \"name\": \"Onboarding\",\n  \"description\": \"Customer onboarding\",\n  \"icon\": \"star\",\n  \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n  \"createdBy\": \"2KDKycoVHAOLttVvzBiqw12O3Hr\",\n  \"updatedBy\": null,\n  \"createdAt\": \"2024-05-23T03:50:27.416Z\",\n  \"updatedAt\": \"2024-05-23T03:50:27.416Z\"\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | All categories in the data catalog are retrieved successfully. |\n| 404 | Category not found for the specified ID. |\n\n### Delete category\n\nDELETE\n\n/catalog/categories/{id}\n\n**Path parameters**\n\n**Example request**\n\n```\nDELETE /v2/catalog/categories/cat_2gqs1Yzy1VpUIewm69meqc6d8zH HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY\n```\n\n```\ncurl --location --request DELETE 'https://api.rudderstack.com/v2/catalog/categories/cat_2gqs1Yzy1VpUIewm69meqc6d8zH' \\\n--header 'Authorization: Bearer 2glZLfSinoRWdkMqsZYPj48X8dY'\n```\n\n**Example response**\n\n```\n{\n  \"name\": \"Onboarding\",\n  \"description\": \"Customer onboarding\",\n  \"icon\": \"star\",\n  \"workspaceId\": \"1zitShAoFT91DD6rfFhBjiTex3e\",\n  \"createdBy\": \"2KDKycoVHAOLttVvzBiqw12O3Hr\",\n  \"updatedBy\": null,\n  \"createdAt\": \"2024-05-23T03:50:27.416Z\",\n  \"updatedAt\": \"2024-05-23T03:50:27.416Z\"\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Category is deleted from the catalog successfully. |\n| 400 | Category not found for the specified event ID. |\n\n## FAQ\n\n#### **How to generate a personal access token to use the Data Catalog API?**\n\nTo generate your [personal access token](https://www.rudderstack.com/docs/dashboard-guides/personal-access-token/), go to **Settings** > **Your Profile** > **Account** tab. Scroll down to **Personal access tokens** and click **Generate new token**.\n\n[![New personal access token in RudderStack dashboard](https://www.rudderstack.com/docs/images/rudderstack-api/personal-access-token-1.webp)](https://www.rudderstack.com/docs/images/rudderstack-api/personal-access-token-1.webp)\n\nEnter the token name and choose **Admin** role from the dropdown:\n\n[![New personal access token in RudderStack dashboard](https://www.rudderstack.com/docs/images/api/pat-admin.webp)](https://www.rudderstack.com/docs/images/api/pat-admin.webp)\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Data Catalog API | RudderStack Docs",
    "description": "Manage your tracking plans, events, and properties in your data catalog programmatically.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/api/http-api/",
    "markdown": "# HTTP API | RudderStack Docs\n\nSend event data from source to destination using our HTTP API.\n\n* * *\n\n*     11 minute read  \n    \n\nRudderStack offers an easy-to-use **HTTP API** that you can use to send your events if you cannot use the SDKs.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> It is recommended to use the [RudderStack SDKs](https://www.rudderstack.com/docs/sources/event-streams/sdks/) for tracking and routing user events from your sources. The SDKs also offer automatic tagging of user context, event batching, and a retry functionality during delivery failure.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> The RudderStack HTTP API is fully Segment-compatible.\n\n## Prerequisites\n\n*   The RudderStack HTTP server must be accessible from your HTTP client. See [Data plane setup](https://www.rudderstack.com/docs/get-started/rudderstack-open-source/data-plane-setup/) for more information.\n*   [Set up a source](https://www.rudderstack.com/docs/dashboard-guides/sources/#adding-a-source) and [destination](https://www.rudderstack.com/docs/dashboard-guides/destinations/#adding-a-destination) in RudderStack.\n*   Import the Postman collection using this [URL](https://www.getpostman.com/collections/480307c55ad2b9dd4e27) and edit the variables `source_write_key` and `data_plane_url`with the [source write key](https://www.rudderstack.com/docs/dashboard-guides/sources/#what-is-a-write-key-why-is-it-required) and the [data plane URL](https://www.rudderstack.com/docs/dashboard-guides/overview/#data-plane-url).\n\nRudderStack uses Basic Authentication for authenticating all HTTP requests.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> All popular HTTP clients (for example, CURL, Postman, HTTPie) have default support for Basic Authentication.\n\nThe Basic Authentication for this API requires a username and password where:\n\n*   Username is the **source write key**.\n*   Password is an empty string (`\"\"`).\n\nFor example, if the source write key is `1Xk5DChfJAol3xtW7qNnK1apo5p`, your HTTP request must have the following HTTP header `Authorization: Basic MVhrNURDaGZKQW9sM3h0VzdxTm5LMWFwbzVwOg==`\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Note that:\n> \n> *   To send events via the RudderStack HTTP API, the **Content-Type** header must be set to `application/json`.\n> *   To generate the HTTP header, you can use the [Basic Authentication Header Generator](https://www.blitter.se/utils/basic-authentication-header-generator/).\n\n## Base URL\n\nUse the [data plane URLThe data plane URL is the location where events are routed and sent to the RudderStack backend for processing. You can find this URL in the home page of your RudderStack dashboard.](https://www.rudderstack.com/docs/resources/glossary/#data-plane-url) as the base URL for your API requests.\n\n## Identify\n\nThe [`identify`](https://www.rudderstack.com/docs/event-spec/standard-events/identify/) call lets you associate a visiting user to their actions and record any associated traits.\n\n#### Sample payload\n\n```\n{\n  \"userId\": \"identified user id\",\n  \"anonymousId\":\"anon-id-new\",\n  \"context\": {\n    \"traits\": {\n       \"trait1\": \"new-val\"  \n    },\n    \"ip\": \"14.5.67.21\",\n    \"library\": {\n        \"name\": \"http\"\n    }\n  },\n  \"timestamp\": \"2020-02-02T00:23:09.544Z\"\n}\n```\n\n#### Usage\n\n```\ncurl -u <source_write_key>: -X POST <data_plane_url>/v1/identify \\\n-d @identify.json \\\n--header \"Content-Type: application/json\" \n```\n\n```\nhttp -a <source_write_key>: <DATA_PLANE_URL>/v1/identify < identify.json\n```\n\n#### Accepted fields\n\nstring\n\nSets the user ID for cases where there is no unique identifier for the user. Either `userId` or `anonymousId` is required.\n\nuserId\n\nrequired, if `anonymousId` is not present\n\nstring\n\nUnique identifier for a particular user in your database.\n\nobject\n\nDictionary of information that provides context about a message. However, it is not directly related to the API call.\n\nobject\n\nA dictionary containing the destinations to be either enabled or disabled.\n\ndatetime\n\nThe timestamp of the message’s arrival. If you are passing the timestamp in the event, make sure it conforms to the ISO 8601 date format `yyyy-MM-ddTHH:mm:ss.SSSZ`. For example: `2022-02-01T19:14:18.381Z`\n\nobject\n\nDictionary of the traits associated with the user, such as `name`or `email`\n\n## Track\n\nThe [`track`](https://www.rudderstack.com/docs/event-spec/standard-events/track/) call lets you track user actions along with any properties associated with them.\n\n#### Sample payload\n\n```\n{\n  \"userId\": \"identified user id\",\n  \"anonymousId\":\"anon-id-new\",\n  \"event\": \"Product Purchased new\",\n  \"properties\": {\n    \"name\": \"Shirt\",\n    \"revenue\": 4.99\n  },\n  \"context\": {\n    \"ip\": \"14.5.67.21\",\n    \"library\": {\n        \"name\": \"http\"\n    }\n  },\n  \"timestamp\": \"2020-02-02T00:23:09.544Z\"\n}\n```\n\n#### Usage\n\n```\ncurl -u <source_write_key>: -X POST <data_plane_url>/v1/track \\\n-d @track.json \\\n--header \"Content-Type: application/json\" \n```\n\n```\nhttp -a <source_write_key>: <DATA_PLANE_URL>/v1/track < track.json\n```\n\n#### Accepted fields\n\nstring\n\nSets the user ID for cases where there is no unique identifier for the user. Either `userId` or `anonymousId` is required.\n\nuserId\n\nrequired, if `anonymousId` is not present\n\nstring\n\nUnique identifier for a particular user in your database.\n\nobject\n\nDictionary of information that provides context about a message. However, it is not directly related to the API call.\n\nstring\n\nName of the event being performed by the user.\n\nobject\n\nDictionary of the properties associated with a particular event.\n\nobject\n\nA dictionary containing the destinations to be either enabled or disabled.\n\ndatetime\n\nThe timestamp of the message’s arrival. If you are passing the timestamp in the event, make sure it conforms to the ISO 8601 date format `yyyy-MM-ddTHH:mm:ss.SSSZ`. For example: `2022-02-01T19:14:18.381Z`\n\n## Page\n\nThe [`page`](https://www.rudderstack.com/docs/event-spec/standard-events/page/) call lets you record your website’s page views with any additional relevant information about the viewed page.\n\n#### Sample payload\n\n```\n{\n  \"userId\": \"identified user id\",\n  \"anonymousId\":\"anon-id-new\",\n  \"name\": \"Page View\",\n  \"properties\": {\n    \"title\": \"Home\",\n    \"path\": \"/\"\n  },\n  \"context\": {\n    \"ip\": \"14.5.67.21\",\n    \"library\": {\n        \"name\": \"http\"\n    }\n  },\n  \"timestamp\": \"2020-02-02T00:23:09.544Z\"\n}\n```\n\n#### Usage\n\n```\ncurl -u <source_write_key>: -X POST <data_plane_url>/v1/page \\\n-d @page.json \\\n--header \"Content-Type: application/json\" \n```\n\n```\nhttp -a <your_write_key>: <DATA_PLANE_URL>/v1/page < page.json\n```\n\n#### Accepted fields\n\nstring\n\nSets the user ID for cases where there is no unique identifier for the user. Either `userId` or `anonymousId` is required.\n\nuserId\n\nrequired, if `anonymousId` is not present\n\nstring\n\nUnique identifier for a particular user in your database.\n\nobject\n\nDictionary of information that provides context about a message. However, it is not directly related to the API call.\n\nobject\n\nA dictionary containing the destinations to be either enabled or disabled.\n\nstring\n\nName of the page being viewed.\n\nobject\n\nDictionary of the properties associated with a particular event.\n\ndatetime\n\nThe timestamp of the message’s arrival. If you are passing the timestamp in the event, make sure it conforms to the ISO 8601 date format `yyyy-MM-ddTHH:mm:ss.SSSZ`. For example: `2022-02-01T19:14:18.381Z`\n\n## Screen\n\nThe [`screen`](https://www.rudderstack.com/docs/event-spec/standard-events/screen/) call is the mobile equivalent of the `page` call. It lets you record whenever your user views their mobile screen with any additional relevant information about the screen.\n\n#### Sample payload\n\n```\n{\n  \"userId\": \"identified user id\",\n  \"anonymousId\":\"anon-id-new\",\n  \"name\": \"Screen View\",\n  \"properties\": {\n    \"prop1\": \"5\"\n  },\n  \"context\": {\n    \"ip\": \"14.5.67.21\",\n    \"library\": {\n        \"name\": \"http\"\n    }\n  },\n  \"timestamp\": \"2020-02-02T00:23:09.544Z\"\n}\n```\n\n#### Usage\n\n```\ncurl -u <source_write_key>: -X POST <data_plane_url>/v1/screen \\\n-d @screen.json \\\n--header \"Content-Type: application/json\" \n```\n\n```\nhttp -a <source_write_key>: <DATA_PLANE_URL>/v1/screen < screen.json\n```\n\n#### Accepted fields\n\nstring\n\nSets the user ID for cases where there is no unique identifier for the user. Either `userId` or `anonymousId` is required.\n\nuserId\n\nrequired, if `anonymousId` is not present\n\nstring\n\nUnique identifier for a particular user in your database.\n\nobject\n\nDictionary of information that provides context about a message. However, it is not directly related to the API call.\n\nobject\n\nA dictionary containing the destinations to be either enabled or disabled.\n\nstring\n\nName of the screen being viewed.\n\nobject\n\nDictionary of the properties associated with the page being viewed, such as `url` and `referrer`.\n\ndatetime\n\nThe timestamp of the message’s arrival. If you are passing the timestamp in the event, make sure it conforms to the ISO 8601 date format `yyyy-MM-ddTHH:mm:ss.SSSZ`. For example: `2022-02-01T19:14:18.381Z`\n\n## Group\n\nThe [`group`](https://www.rudderstack.com/docs/event-spec/standard-events/group/) call lets you link an identified user with a group such as a company, organization, or an account. It also lets you record any custom traits associated with that group, like the name of the company, the number of employees, etc.\n\n#### Sample payload\n\n```\n{\n  \"userId\": \"user123\",\n  \"groupId\": \"group1\",\n  \"traits\": {\n    \"name\": \"Company\",\n    \"industry\": \"Industry\",\n    \"employees\": 123\n  },\n  \"context\": {\n    \"traits\": {\n       \"trait1\": \"new-val\"  \n    },\n    \"ip\": \"14.5.67.21\",\n    \"library\": {\n        \"name\": \"http\"\n    }\n  },\n  \"timestamp\": \"2020-01-21T00:21:34.208Z\"\n}\n```\n\n#### Usage\n\n```\ncurl -u <source_write_key>: -X POST <data_plane_url>/v1/group \\\n-d @group.json \\\n--header \"Content-Type: application/json\" \n```\n\n```\nhttp -a <source_write_key>: <DATA_PLANE_URL>/v1/group < group.json\n```\n\n#### Accepted fields\n\nstring\n\nSets the user ID for cases where there is no unique identifier for the user. Either `userId` or `anonymousId` is required.\n\nuserId\n\nrequired, if `anonymousId` is not present\n\nstring\n\nUnique identifier for a particular user in your database.\n\nobject\n\nDictionary of information that provides context about a message. However, it is not directly related to the API call.\n\nobject\n\nA dictionary containing the destinations to be either enabled or disabled.\n\nstring\n\nUnique identifier of the group, as present in your database.\n\nobject\n\nDictionary of the traits associated with the group, such as `name`or `email`\n\ndatetime\n\nThe timestamp of the message’s arrival. If you are passing the timestamp in the event, make sure it conforms to the ISO 8601 date format `yyyy-MM-ddTHH:mm:ss.SSSZ`. For example: `2022-02-01T19:14:18.381Z`\n\n## Alias\n\nThe [`alias`](https://www.rudderstack.com/docs/event-spec/standard-events/alias/) call lets you merge different identities of a known user.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> `alias` is an advanced method that lets you change the tracked user’s ID explicitly. This method is useful when managing identities for some of the downstream destinations.\n\n#### Sample payload\n\n```\n{\n  \"userId\": \"user123\",\n  \"previousId\": \"previd1\",\n  \"context\": {\n    \"traits\": {\n       \"trait1\": \"new-val\"  \n    },\n    \"ip\": \"14.5.67.21\",\n    \"library\": {\n        \"name\": \"http\"\n    }\n  },\n  \"timestamp\": \"2020-01-21T00:21:34.208Z\"\n}\n```\n\n#### Usage\n\n```\ncurl -u <source_write_key>: -X POST <data_plane_url>/v1/alias \\\n-d @alias.json \\\n--header \"Content-Type: application/json\" \n```\n\n```\nhttp -a <source_write_key>: <DATA_PLANE_URL>/v1/alias < alias.json\n```\n\n#### Accepted fields\n\nuserId\n\nrequired, if `anonymousId` is not present\n\nstring\n\nUnique identifier for a particular user in your database.\n\nobject\n\nDictionary of information that provides context about a message. However, it is not directly related to the API call.\n\nobject\n\nA dictionary containing the destinations to be either enabled or disabled.\n\nstring\n\nThe previous unique identifier of the user.\n\nobject\n\nDictionary of the traits associated with the group, such as `name`or `email`\n\ndatetime\n\nThe timestamp of the message’s arrival. If you are passing the timestamp in the event, make sure it conforms to the ISO 8601 date format `yyyy-MM-ddTHH:mm:ss.SSSZ`. For example: `2022-02-01T19:14:18.381Z`\n\n## Merge\n\n> ![danger](https://www.rudderstack.com/docs/images/danger.svg)\n> \n> This API is deprecated and will be discontinued soon.\n\nThe `merge` call enables you to merge different user identities and associate them to a single customer profile in the warehouse.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> RudderStack supports `merge` for identity resolution in the [BigQuery](https://www.rudderstack.com/docs/destinations/warehouse-destinations/bigquery/) and [Snowflake](https://www.rudderstack.com/docs/destinations/warehouse-destinations/snowflake/) warehouse destinations.\n\n#### Sample Payload\n\n```\n{\n  \"userId\": \"1hKOmRA4GRlm\",\n  \"mergeProperties\": [{\n      \"type\": \"email\",\n      \"value\": \"alex@example.com\"\n    },\n    {\n      \"type\": \"mobile\",\n      \"value\": \"+1-202-555-0146\"\n    }\n  ]\n}\n```\n\n#### Usage\n\n```\ncurl -u <source_write_key>: -X POST <data_plane_url>/v1/merge \\\n-d @merge.json \\\n--header \"Content-Type: application/json\" \n```\n\n```\nhttp -a <source_write_key>: <DATA_PLANE_URL>/v1/merge < merge.json\n```\n\n#### Accepted fields\n\nuserId\n\nrequired, if `anonymousId` is not present\n\nstring\n\nUnique identifier for a particular user in your database.\n\nanonymousId\n\nrequired, if `userId` is not present\n\nstring\n\nSets the user ID for cases where there is no unique identifier for the user. Either `userId` or `anonymousId` is required.\n\nobject\n\nThe user properties to be merged and connected to a given user profile.\n\n## Batch\n\nThe `batch` call allows you to send a series of `identify`, `track`, `page`, `group` and `screen` requests in a single batch. This call helps you minimize the number of outbound requests, thus enabling better performance.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> RudderStack sets a maximum limit of `4 MB` per batch request and `32 KB` per call.\n\n#### Sample payload\n\n```\n{\n    \"batch\": [{\n            \"userId\": \"identified user id\",\n            \"anonymousId\": \"anon-id-new\",\n            \"type\": \"identify\",\n            \"context\": {\n                \"traits\": {\n                    \"trait1\": \"new-val\"\n                },\n                \"ip\": \"14.5.67.21\",\n                \"library\": {\n                    \"name\": \"http\"\n                }\n            },\n            \"timestamp\": \"2020-02-02T00:23:09.544Z\"\n        },\n        {\n            \"userId\": \"identified user id\",\n            \"anonymousId\": \"anon-id-new\",\n            \"event\": \"Product Purchased new\",\n            \"type\": \"track\",\n            \"properties\": {\n                \"name\": \"Shirt\",\n                \"revenue\": 4.99\n            },\n            \"context\": {\n                \"ip\": \"14.5.67.21\",\n                \"library\": {\n                    \"name\": \"http\"\n                }\n            },\n            \"timestamp\": \"2020-02-02T00:23:09.544Z\"\n        },\n        {\n            \"userId\": \"identified user id\",\n            \"anonymousId\": \"anon-id-new\",\n            \"name\": \"Page View\",\n            \"type\": \"page\",\n            \"properties\": {\n                \"title\": \"Home\",\n                \"path\": \"/\"\n            },\n            \"context\": {\n                \"ip\": \"14.5.67.21\",\n                \"library\": {\n                    \"name\": \"http\"\n                }\n            },\n            \"timestamp\": \"2020-02-02T00:23:09.544Z\"\n        },\n        {\n            \"userId\": \"identified user id\",\n            \"anonymousId\": \"anon-id-new\",\n            \"name\": \"Screen View\",\n            \"type\": \"screen\",\n            \"properties\": {\n                \"prop1\": \"5\"\n            },\n            \"context\": {\n                \"ip\": \"14.5.67.21\",\n                \"library\": {\n                    \"name\": \"http\"\n                }\n            },\n            \"timestamp\": \"2020-02-02T00:23:09.544Z\"\n        },\n        {\n            \"userId\": \"user123\",\n            \"type\": \"group\",\n            \"groupId\": \"group1\",\n            \"traits\": {\n                \"name\": \"Company\",\n                \"industry\": \"Industry\",\n                \"employees\": 123\n            },\n            \"context\": {\n                \"traits\": {\n                    \"trait1\": \"new-val\"\n                },\n                \"ip\": \"14.5.67.21\",\n                \"library\": {\n                    \"name\": \"http\"\n                }\n            },\n            \"timestamp\": \"2020-01-21T00:21:34.208Z\"\n        },\n        {\n            \"userId\": \"user123\",\n            \"previousId\": \"previd1\",\n            \"type\":\"alias\",\n            \"context\": {\n                \"traits\": {\n                    \"trait1\": \"new-val\"\n                },\n                \"ip\": \"14.5.67.21\",\n                \"library\": {\n                    \"name\": \"http\"\n                }\n            },\n            \"timestamp\": \"2020-01-21T00:21:34.208Z\"\n        }\n\n    ]\n}\n```\n\n#### Usage\n\n```\ncurl -u <source_write_key>: -X POST <data_plane_url>/v1/batch \\\n-d @batch.json \\\n--header \"Content-Type: application/json\" \n```\n\n```\nhttp -a <source_write_key>: <DATA_PLANE_URL>/v1/batch < batch.json\n```\n\n#### Accepted fields\n\narray\n\nAn array of `identify`, `track`, `page`, `group` and `screen` calls. Each call must have a `type` property and a valid method name.\n\n## HTTP responses\n\n*   The HTTP API returns a `200` response for successful API requests.\n    \n*   The API returns a `400` response for invalid requests with an appropriate error message in the response. Possible invalid requests include:\n    \n    *   Request size too large\n    *   Invalid JSON\n    *   Missing Authorization Header\n    *   Invalid Authorization Header\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> In case of **Invalid Authorization Header** error, verify if the source write key and the basic authentication header is valid.\n\n## Maximum allowed request size\n\nRudderStack allows messages with a maximum size of `32 KB` per call. The [`batch`](#batch) endpoint accepts a maximum call size of `4 MB` per batch, and `32 KB` per call. RudderStack responds with a `400 Bad Request` error if these limits are exceeded.\n\n## Event ordering\n\nTo maintain event ordering while using the HTTP API, make sure to include [`sentAt`](https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/#common-fields) and `anonymousId` as a header in every request.\n\n[![Event ordering](https://www.rudderstack.com/docs/images/api/http-event-ordering.webp)](https://www.rudderstack.com/docs/images/api/http-event-ordering.webp)\n\n## Historical imports\n\nRudderStack lets you import any historical data by simply adding the `timestamp` argument to any of your API calls. However, this can be done only for the destinations that accept historical time-stamped data, like Amplitude, Mixpanel, etc.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> If you are tracking current events, leave out the `timestamp` field. RudderStack will automatically add the timestamps to the event requests.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "HTTP API | RudderStack Docs",
    "description": "Send event data from source to destination using our HTTP API.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/",
    "markdown": "# Common Fields | RudderStack Docs\n\nUnderstand the common fields that define the core RudderStack event data structure.\n\n* * *\n\n*     10 minute read  \n    \n\nRudderStack defines some common fields (event type, timestamps, and more) across all API calls that make up the core event data structure.\n\nThis guide covers the common and contextual fields in detail.\n\n## Common fields\n\n| Name | Data type | Description |\n| --- | --- | --- |\n| `userId`  <br>Required, if `anonymousId` is absent. | String | Unique identification for the user in the database |\n| `anonymousId`  <br>Required, if `userId` is absent. | String | Pseudo-identifier for the user in cases where `userId` is absent. This is the same as the device ID. |\n| `channel`  <br>Required | String | Identifies the source of the event. Permitted values are `mobile`, `web`, `server` and `sources`. |\n| `context`  <br>Required | Object | Contains all additional user information. The RudderStack SDKs populate this information automatically. |\n| `type`  <br>Required | String | Captures the type of event. Values can be either `identify`, `track`, `screen`, `page`, `group`, or `alias`. |\n| `originalTimestamp`  <br>Required | Timestamp | Records the actual time (in UTC) when the event occurred. Make sure it conforms to the ISO 8601 date format `yyyy-MM-ddTHH:mm:ss.SSSZ`.<br><br>For e.g., `2022-02-01T19:14:18.381Z`. |\n| `sentAt`  <br>Required | Timestamp | Captures the time (in UTC) when the event was sent from the client to RudderStack. Make sure it conforms to the ISO 8601 date format `yyyy-MM-ddTHH:mm:ss.SSSZ`.<br><br>For e.g., `2022-02-01T19:14:18.381Z`. |\n| `event` | String | Captures the user action that you want to record. |\n| `integrations` | Object | You can specify the destinations for which you want to enable/disable sending events. |\n| `messageId` | String | Unique identification for the event. |\n| `properties` | Object | Passes all relevant information associated with the event. |\n\nRudderStack also sets the following fields automatically, so you **do not** have to set them explicitly:\n\n| Name | Data type | Description |\n| --- | --- | --- |\n| `receivedAt` | Timestamp | Time in UTC when RudderStack ingests the event. |\n| `timestamp` | Timestamp | RudderStack calculates this field to account for any client-side clock skew using the formula: `timestamp` = `receivedAt` - (`sentAt` - `originalTimestamp`). See [Clock skew considerations](#clock-skew-considerations) for more information. Note that this time is in UTC. |\n| `request_ip` | String | User’s IP address. RudderStack automatically collects and sets this property as a common field. See [How RudderStack collects IP address](#how-rudderstack-collects-ip-address) for more information. |\n\n## Contextual fields\n\nContextual fields give additional information about a particular event. The following table describes the available contextual fields.\n\n| Name | Data type | Description |\n| --- | --- | --- |\n| `app` | Object | Gives detailed information related to your app, like `build`, `name`, `namespace` and `version`. |\n| `campaign` | Object | Gives detailed information about campaigns, like `name`, `source`, `medium`, `content` and `term`. |\n| `device` | Object | Information about the device from which you are capturing the event. It contains the device `id`, `manufacturer`, `model`, `name` and `type`. |\n| `ip` | String | User’s IP address. See [How RudderStack collects IP address](#how-rudderstack-collects-ip-address) for more information. |\n| `library` | Object | Details about the RudderStack SDK you are using, like `name` and `version`. |\n| `locale` | String | Captures the language of the device. |\n| `network` | Object | Contains information about the reachability of the device. Also, it gives you the status of the device’s `bluetooth`, `wifi`, `cellular` network and `carrier` name. |\n| `os` | Object | Captures the operating system details of the device you are tracking.<br><br>**Note**: While the JavaScript SDK does not populate this information automatically, you can get it using the [`uaChTrackLevel`](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/load-js-sdk/#uachtracklevel) `load` API option. |\n| `screen` | Object | Gives you the screen dimensions of the device, i.e. `height`, `width` and the `density`. |\n| `timezone` | String | Captures the timezone of the user you are tracking. |\n| `traits` | Object | Captures any additional relevant information about the user. RudderStack fills in the `anonymousId` for you. You can also associate the [traits](https://www.rudderstack.com/docs/event-spec/standard-events/identify/#identify-traits) from the previously-made `identify` call from the SDK. |\n| `userAgent` | String | The user agent of the device that you are tracking. |\n\n### Automatically collected contextual fields\n\nThe following table describes contextual fields that are automatically collected and populated by the RudderStack SDKs:\n\n| Field | JavaScript | Android | iOS | Description |\n| --- | --- | --- | --- | --- |\n| `app.name` | \\-  | Yes | Yes | Name of the application. |\n| `app.version` | \\-  | Yes | Yes | Version of the application. |\n| `app.build` | \\-  | Yes | Yes | Build of the application. |\n| `campaign.name` | Yes | \\-  | \\-  | Name of the campaign. |\n| `campaign.source` | Yes | \\-  | \\-  | Source of the campaign. |\n| `campaign.medium` | Yes | \\-  | \\-  | Medium of the campaign. |\n| `campaign.term` | Yes | \\-  | \\-  | Term of the campaign. |\n| `campaign.content` | Yes | \\-  | \\-  | Content of the campaign. |\n| `device.type` | \\-  | Yes | Yes | Type of the device. |\n| `device.id` | \\-  | Yes | Yes | ID of the device. |\n| `device.advertisingId` | \\-  | Yes | Yes | Advertising ID of the device. |\n| `device.adTrackingEnabled` | \\-  | \\-  | Yes | If ad tracking is enabled on the device. |\n| `device.manufacturer` | \\-  | Yes | Yes | Manufacturer of the device. |\n| `device.model` | \\-  | Yes | Yes | Model of the device. |\n| `device.name` | \\-  | Yes | Yes | Name of the device. |\n| `library.name` | Yes | Yes | Yes | Name of the library. |\n| `library.version` | Yes | Yes | Yes | Version of the library. |\n| `locale` | Yes | Yes | Yes | Locale string of the user. |\n| `network.bluetooth` | \\-  | Yes\\* | \\-  | Bluetooth information. |\n| `network.carrier` | \\-  | Yes | Yes | Carrier information about the network connection. |\n| `network.cellular` | \\-  | Yes | Yes | Cellular information about the network connection. |\n| `network.wifi` | \\-  | Yes | Yes | WiFi information about the network connection. |\n| `os.name` | \\-  | Yes | Yes | Name of the operating system.<br><br>For JavaScript SDK, you can get it using the [`uaChTrackLevel`](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/load-js-sdk/#uachtracklevel) `load` API option. |\n| `os.version` | \\-  | Yes | Yes | Version of the operating system.<br><br>For JavaScript SDK, you can get it using the [`uaChTrackLevel`](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/load-js-sdk/#uachtracklevel) `load` API option. |\n| `page.path` | Yes | \\-  | \\-  | Path of the current page in the browser. |\n| `page.initial_referrer` | Yes | \\-  | \\-  | Initial referrer of the current page in the browser. |\n| `page.initial_referring_domain` | Yes | \\-  | \\-  | Initial referring domain of the current page in the browser. |\n| `page.referrer` | Yes | \\-  | \\-  | Referrer of the current page in the browser. |\n| `page.referring_domain` | Yes | \\-  | \\-  | Referring domain of the current page in the browser. |\n| `page.search` | Yes | \\-  | \\-  | Search of the current page in the browser. |\n| `page.title` | Yes | \\-  | \\-  | Title of the current page in the browser. |\n| `page.url` | Yes | \\-  | \\-  | URL of the current page in the browser. |\n| `screen.density` | Yes | Yes | Yes | Density of the device’s screen. |\n| `screen.height` | Yes | Yes | Yes | Height of the device’s screen. |\n| `screen.width` | Yes | Yes | Yes | Width of the device’s screen. |\n| `screen.innerWidth` | Yes | \\-  | \\-  | Inner width of the device’s screen. |\n| `screen.innerHeight` | Yes | \\-  | \\-  | Inner height of the device’s screen. |\n| `traits` | \\-  | Yes | Yes | Traits of the user. |\n| `userAgent` | Yes | Yes | \\-  | User agent of the device making the request. |\n| `timezone` | Yes | Yes | Yes | Information about the user’s timezone. |\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> *   For Android SDK v1.6.0 and above, the Bluetooth status is collected in the `network.bluetooth` field only if the Bluetooth permission is present in the app.\n> *   For iOS SDK v1.6.3 and above, the Bluetooth status is not collected in the `network.bluetooth` field as it is a run-time permission.\n\n### Sample payload with contextual fields\n\nThe following sample payload highlights the usage of the common and contextual fields in web and mobile modes:\n\n```\n{\n  \"anonymousId\": \"78c53c15-32a1-4b65-adac-bec2d7bb8fab\",\n  \"channel\": \"web\",\n  \"context\": {\n    \"campaign\": {\n      \"name\": \"sales campaign\",\n      \"source\": \"google\",\n      \"medium\": \"medium\",\n      \"term\": \"event data\",\n      \"content\": \"Make sense of the modern data stack\"\n    },\n    \"ip\": \"192.0.2.0\",\n    \"library\": {\n      \"name\": \"RudderLabs JavaScript SDK\",\n      \"version\": \"2.9.1\"\n    },\n    \"locale\": \"en-US\",\n    \"page\": {\n      \"path\": \"/best-seller/1\",\n      \"initial_referrer\": \"https://www.google.com/search\",\n      \"initial_referring_domain\": \"google.com\",\n      \"referrer\": \"https://www.google.com/search?q=estore+bestseller\",\n      \"referring_domain\": \"google.com\",\n      \"search\": \"estore bestseller\",\n      \"title\": \"The best sellers offered by EStore\",\n      \"url\": \"https://www.estore.com/best-seller/1\"\n    },\n    \"screen\": { \n      \"density\": 420, \n      \"height\": 1794, \n      \"width\": 1080, \n      \"innerHeight\": 200, \n      \"innerWidth\": 100 \n      },\n    \"userAgent\": \"Dalvik/2.1.0 (Linux; U; Android 9; Android SDK built for x86 Build/PSR1.180720.075)\"\n  },\n  \"event\": \"Product Reviewed\",\n  \"integrations\": { \n    \"All\": true \n    },\n  \"messageId\": \"1578564113557-af022c68-429e-4af4-b99b-2b9174056383\",\n  \"properties\": {\n    \"review_id\": \"review_id_1\",\n    \"product_id\": \"product_id_1\",\n    \"rating\": 5.0,\n    \"review_body\": \"It's the greatest!\"\n  },\n  \"originalTimestamp\": \"2020-01-09T10:01:53.558Z\",\n  \"type\": \"track\",\n  \"sentAt\": \"2020-01-09T10:02:03.257Z\"\n}\n```\n\n```\n{\n  \"anonymousId\": \"78c53c15-32a1-4b65-adac-bec2d7bb8fab\",\n  \"channel\": \"mobile\",\n  \"context\": {\n    \"app\": {\n      \"name\": \"RudderAndroidClient\",\n      \"version\": \"1.0\",\n      \"build\": \"1\"\n    },\n    \"device\": {\n      \"type\": \"android\",\n      \"id\": \"78c53c15-32a1-4b65-adac-bec2d7bb8fab\",\n      \"advertisingId\":\"435o4GRlm\",\n      \"manufacturer\": \"Google\",\n      \"model\": \"Android SDK built for x86\",\n      \"name\": \"generic_x86\",\n    },\n    \"ip\": \"192.0.2.0\",\n    \"library\": {\n      \"name\": \"com.rudderstack.android.sdk.core\",\n      \"version\": \"0.1.4\"\n    },\n    \"locale\": \"en-US\",\n    \"network\": {\n      \"bluetooth\": false,\n      \"carrier\": \"Android\",\n      \"cellular\": true,\n      \"wifi\": true\n    },\n    \"os\": { \n      \"name\": \"Android\", \n      \"version\": \"9\" \n      },\n    \"screen\": { \n      \"density\": 420, \n      \"height\": 1794, \n      \"width\": 1080 \n      },\n     \"traits\": { \n      \"anonymousId\": \"78c53c15-32a1-4b65-adac-bec2d7bb8fab\" \n      },\n    \"timezone\": \"Asia/Mumbai\",\n    \"userAgent\": \"Dalvik/2.1.0 (Linux; U; Android 9; Android SDK built for x86 Build/PSR1.180720.075)\"\n  },\n  \"event\": \"Product Reviewed\",\n  \"integrations\": { \n    \"All\": true \n    },\n  \"messageId\": \"1578564113557-af022c68-429e-4af4-b99b-2b9174056383\",\n  \"properties\": {\n    \"review_id\": \"review_id_1\",\n    \"product_id\": \"product_id_1\",\n    \"rating\": 5.0,\n    \"review_body\": \"It's the greatest!\"\n  },\n  \"originalTimestamp\": \"2020-01-09T10:01:53.558Z\",\n  \"type\": \"track\",\n  \"sentAt\": \"2020-01-09T10:02:03.257Z\"\n}\n```\n\n```\n{\n  \"anonymousId\": \"78c53c15-32a1-4b65-adac-bec2d7bb8fab\",\n  \"channel\": \"mobile\",\n  \"context\": {\n    \"app\": {\n      \"name\": \"RudderSampleAppObjC\",\n      \"version\": \"1.0\",\n      \"build\": \"1\"\n    },\n    \"device\": {\n      \"type\": \"iOS\",\n      \"id\": \"78c53c15-32a1-4b65-adac-bec2d7bb8fab\",\n      \"advertisingId\":\"435o4GRlm\",\n      \"adTrackingEnabled\": false,\n      \"manufacturer\": \"Apple\",\n      \"model\": \"iPhone\",\n      \"name\": \"iPhone 12\",\n    },\n    \"ip\": \"192.0.2.0\",\n    \"library\": {\n      \"name\": \"rudder-ios-library\",\n      \"version\": \"1.5.0\"\n    },\n    \"locale\": \"en-US\",\n    \"network\": {\n      \"carrier\": \"unavailable\",\n      \"cellular\": false,\n      \"wifi\": true\n    },\n    \"os\": { \n      \"name\": \"iOS\", \n      \"version\": \"15.2\" \n      },\n    \"screen\": { \n      \"height\": 1794, \n      \"width\": 1080 \n      },\n     \"traits\": { \n      \"anonymousId\": \"78c53c15-32a1-4b65-adac-bec2d7bb8fab\" \n      },\n    \"timezone\": \"Asia/Mumbai\"\n  },\n  \"event\": \"Product Reviewed\",\n  \"integrations\": { \n    \"All\": true \n    },\n  \"messageId\": \"1643629072-8ce81faf-7489-4508-b21b-659e81510991\",\n  \"properties\": {\n    \"review_id\": \"review_id_1\",\n    \"product_id\": \"product_id_1\",\n    \"rating\": 5.0,\n    \"review_body\": \"It's the greatest!\"\n  },\n  \"originalTimestamp\": \"2020-01-09T10:01:53.558Z\",\n  \"type\": \"track\",\n  \"sentAt\": \"2020-01-09T10:02:03.257Z\"\n}\n```\n\n## How RudderStack collects IP address\n\nRudderStack automatically collects the user’s IP address in the `request_ip` property as a **common field**. You can see it in the event received at the destination but not in the [Live Events](https://www.rudderstack.com/docs/dashboard-guides/live-events/) tab. This is because RudderStack adds the IP in the backend while sending the event to the destination; it is not a part of the initial event data generated at the source.\n\nYou can also send the IP information or anonymize IP address in your events. To do so, use the appropriate SDK APIs to set the values for the `ip` field into the source-level [`context`](#contextual-fields) object.\n\n## Clock skew considerations\n\nRudderStack considers the time at its end to be absolute and assumes any differences are on the client-side. Thus, the client clock skew is relative.\n\n| Field | Description |\n| --- | --- |\n| `originalTimestamp` | Time, client-side, when the event occurred at the source. |\n| `sentAt` | Time, client-side, when the event was sent from the client to RudderStack. |\n| `receivedAt` | Time when the event is received(ingested) by the RudderStack server. |\n| `timestamp` | Calculated by RudderStack to account for the client clock skew, if the user does not explicitly specify it in the payload. |\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> All the above timestamps are in UTC.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> **Important considerations for using timestamps in analysis**\n> \n> `originalTimestamp` and `sentAt` should not be used for analysis because they both reflect client-side clock skew.\n> \n> Likewise, `receivedAt` does not guarantee preservation of the chronological order of events, and should not be used for analysis where chronological order is needed.\n> \n> When importing historical events, `timestamp` should be used to preserve chronological order.\n\n### SDK sources\n\nIf you do not specify the `timestamp` field in the payload for [SDK sources](https://www.rudderstack.com/docs/sources/event-streams/sdks/), RudderStack calculates it based on the `originalTimestamp` and `sentAt` to account for the client clock skew.\n\n`sentAt` > `originalTimestamp` is **always true**. However, `timestamp` can be greater or less than the `originalTimestamp`:\n\n**Case 1**: `originalTimestamp` < `receivedAt`\n\nWhen the client-side time is less than the time registered by RudderStack:\n\n| originalTimestamp | sentAt | receivedAt | timestamp = receivedAt - (sentAt - originalTimestamp) |\n| --- | --- | --- | --- |\n| 2020-04-26 07:00:43.400 | 2020-04-26 07:00:45.124 | 2020-04-26 07:00:45.558 | 2020-04-26 07:00:43.834 |\n\nIn this case, `timestamp` will be **greater** than `originalTimestamp`.\n\n**Case 2**: `originalTimestamp` > `receivedAt`\n\nWhen the client-side time is greater than the time registered by RudderStack:\n\n| originalTimestamp | sentAt | receivedAt | timestamp = receivedAt - (sentAt - originalTimestamp) |\n| --- | --- | --- | --- |\n| 2020-04-26 07:00:45.558 | 2020-04-26 07:00:46.124 | 2020-04-26 07:00:43.400 | 2020-04-26 07:00:42.834 |\n\nIn this case, `timestamp` will be **less** than `originalTimestamp`.\n\n### HTTP/Webhook-based sources\n\nRudderStack does not consider any clock skew for HTTP/Webhook-based sources and uses the `timestamp` passed in the `timestamp` payload field.\n\n**Case 1**: When the client-side time is less than the time registered by RudderStack:\n\n| originalTimestamp | sentAt | receivedAt | timestamp = receivedAt - (sentAt - originalTimestamp) | timestamp (payload field) |\n| --- | --- | --- | --- | --- |\n| NA  | NA  | 2020-04-26 07:00:49.400 | NA  | 2020-04-26 07:00:46.400 |\n\n**Case 2**: When the client-side time is greater than the time registered by RudderStack:\n\n| originalTimestamp | sentAt | receivedAt | timestamp = receivedAt - (sentAt - originalTimestamp) | timestamp (payload field) |\n| --- | --- | --- | --- | --- |\n| NA  | NA  | 2020-04-26 07:00:43.400 | NA  | 2020-04-26 07:00:47.400 |\n\nIn the above cases, `timestamp` is the same as specified in the payload. RudderStack sets the `originalTimestamp` as the `currentTime`. You can add a [transformation](https://www.rudderstack.com/docs/transformations/overview/) to correct the clock skew.\n\n**Case 3**: If none of the `originalTimestamp`, `sentAt`, `receivedAt`, and `timestamp` fields are passed in the payload:\n\n| originalTimestamp | sentAt | receivedAt | timestamp = receivedAt - (sentAt - originalTimestamp) | timestamp (payload field) |\n| --- | --- | --- | --- | --- |\n| Set as current time | Set as current time | current time | current time | NA  |\n\nRudderStack sets the `originalTimestamp` and `sentAt` fields to the current time and calculates `timestamp` (same as `receivedAt`/current time).\n\n### Destinations\n\nRudderStack gives priority to the `timestamp` field over `originalTimestamp`. Refer to the [destination documentation](https://www.rudderstack.com/docs/destinations/streaming-destinations/) for more details.\n\n## Timestamp mapping for Reverse ETL sources\n\nWhen you map your warehouse columns to destination fields using [JSON mapper](https://www.rudderstack.com/docs/sources/reverse-etl/json-data-mapping/), RudderStack prefers the timestamp to be set in the following event traits/properties (in the exact preference order):\n\n| Event type | JSON key for timestamp |\n| --- | --- |\n| `track` | `properties.timestamp` |\n| `identify` | 1.  `context.timestamp`<br>2.  `context.traits.timestamp`<br>3.  `traits.timestamp`<br>4.  `timestamp`<br>5.  `originalTimestamp` |\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Note that:\n> \n> *   If the timestamp is not present in any of the outermost timestamp fields, RudderStack takes the timestamp value from the [`originalTimestamp`](https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/#clock-skew-considerations) field (at the outermost level in the event payload).\n> *   RudderStack generates the root level `timestamp` field and it changes every time a full sync is triggered.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Common Fields | RudderStack Docs",
    "description": "Understand the common fields that define the core RudderStack event data structure.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/standard-events/video-events-spec/",
    "markdown": "# Video Events Spec | RudderStack Docs\n\nLearn the syntax and general conventions for sending events when tracking videos.\n\n* * *\n\n*     14 minute read  \n    \n\nRudderStack’s video specification lets you capture data on how a customer engages with your videos and the related ad content.\n\nThis documentation lists the conventions and best practices for sending video tracking events. It also clarifies the overall structure and classification of these events.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Not all RudderStack destinations support video tracking. Refer to the individual [destination’s docs](https://www.rudderstack.com/docs/destinations/overview/) to check if it supports video tracking.\n\nThis guide is organized into the following three event categories:\n\n*   Playback\n*   Content\n*   Ads\n\n## Playback\n\nPlayback events are associated with the actual playback of video content and track information about the video player.\n\nFor example, when a customer plays a video, a `Video Playback Started` event is sent along with a unique `session_id`. All subsequent events generated from this session are tied to this `session_id`.\n\nIf a web page has two video players, two separate sessions and `session_id` would be associated to them. But if two separate videos are played on the same video player that would be a single session with two contents associated to it.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> All playback events are tracked and recorded at the session level.\n\n### Playback events\n\nThis section details all video playback events.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> For more information on each of the properties associated with these events, refer to the [Playback Event Properties](#playback-event-properties) section.\n\n#### Video Playback Started\n\nThis event triggers when the user pressing the play button on the video player.\n\nHere is a sample event:\n\n```\n{\n    \"type\": \"track\",\n    \"event\": \"Video Playback Started\",\n    \"userId\": \"user12345\",\n    \"properties\": {\n      \"session_id\": \"12345\",\n      \"content_asset_ids\": [\"0129370\"],\n      \"content_pod_ids\": [\"RudderA\", \"RudderB\"],\n      \"ad_asset_id\": [\"ad1\", \"ad0\"],\n      \"ad_pod_id\": [\"adRudderA\", \"adRudderB\"],\n      \"ad_type\": [\"mid-roll\", \"post-roll\"],\n      \"position\": 0,\n      \"total_length\": 300,\n      \"bitrate\": 128,\n      \"framerate\": 24.00,\n      \"video_player\": \"youtube\",\n      \"sound\": 68,\n      \"full_screen\": true,\n      \"ad_enabled\": true,\n      \"quality\": \"hd1080\",\n      \"livestream\": false\n    }\n}\n```\n\n#### Video Playback Paused\n\nThis event triggers when the user pauses the video.\n\nHere is a sample event:\n\n```\n{\n    \"type\": \"track\",\n    \"event\": \"Video Playback Paused\",\n    \"userId\": \"user12345\",\n    \"properties\": {\n      \"session_id\": \"12345\",\n      \"content_asset_ids\": [\"0129370\"],\n      \"content_pod_ids\": [\"RudderA\", \"RudderB\"],\n      \"position\": 0,\n      \"total_length\": 300,\n      \"bitrate\": 128,\n      \"framerate\": 24.00,\n      \"video_player\": \"youtube\",\n      \"sound\": 68,\n      \"full_screen\": true,\n      \"ad_enabled\": true,\n      \"quality\": \"hd1080\",\n      \"livestream\": false\n    }\n}\n```\n\n#### Video Playback Interrupted\n\nThis event triggers when video playback stops unintentionally. Common reasons include network loss, user closing the browser, and redirect. You can pass the cause within the property `method`.\n\nHere is a sample event:\n\n```\n{\n    \"type\": \"track\",\n    \"event\": \"Video Playback Interrupted\",\n    \"userId\": \"user12345\",\n    \"properties\": {\n      \"session_id\": \"12345\",\n      \"content_asset_ids\": [\"0129370\"],\n      \"content_pod_ids\": [\"RudderA\", \"RudderB\"],\n      \"position\": 0,\n      \"total_length\": 300,\n      \"bitrate\": 128,\n      \"framerate\": 24.00,\n      \"video_player\": \"youtube\",\n      \"sound\": 68,\n      \"full_screen\": true,\n      \"ad_enabled\": true,\n      \"quality\": \"hd1080\",\n      \"livestream\": false,\n      \"method\":\"network loss\"\n    }\n}\n```\n\n#### Video Playback Buffer Started\n\nThis event triggers when content or an ad is buffering.\n\nHere is a sample event:\n\n```\n{\n    \"type\": \"track\",\n    \"event\": \"Video Playback Buffer Started\",\n    \"userId\": \"user12345\",\n    \"properties\": {\n      \"session_id\": \"12345\",\n      \"content_asset_ids\": [\"0129370\"],\n      \"content_pod_ids\": [\"RudderA\", \"RudderB\"],\n      \"position\": 0,\n      \"total_length\": 300,\n      \"bitrate\": 128,\n      \"framerate\": 24.00,\n      \"video_player\": \"youtube\",\n      \"sound\": 68,\n      \"full_screen\": true,\n      \"ad_enabled\": true,\n      \"quality\": \"hd1080\",\n      \"livestream\": false\n    }\n}\n```\n\n#### Video Playback Buffer Completed\n\nThis event triggers when buffering for content or an ad finishes.\n\nHere is a sample event:\n\n```\n{\n    \"type\": \"track\",\n    \"event\": \"Video Playback Buffer Completed\",\n    \"userId\": \"user12345\",\n    \"properties\": {\n      \"session_id\": \"12345\",\n      \"content_asset_ids\": [\"0129370\"],\n      \"content_pod_ids\": [\"RudderA\", \"RudderB\"],\n      \"position\": 0,\n      \"total_length\": 300,\n      \"bitrate\": 128,\n      \"framerate\": 24.00,\n      \"video_player\": \"youtube\",\n      \"sound\": 68,\n      \"full_screen\": true,\n      \"ad_enabled\": true,\n      \"quality\": \"hd1080\",\n      \"livestream\": false\n    }\n}\n```\n\n#### Video Playback Seek Started\n\nThis event triggers when a user starts manually seeking a certain position of the video or ad in the playback. The `position` property indicates where the user is seeking from (time in seconds) and the `seek_position` indicates the position in the playback where the user is seeking to.\n\nHere is a sample event:\n\n```\n{\n    \"type\": \"track\",\n    \"event\": \"Video Playback Seek Started\",\n    \"userId\": \"user12345\",\n    \"properties\": {\n      \"session_id\": \"12345\",\n      \"content_asset_ids\": [\"0129370\"],\n      \"content_pod_ids\": [\"RudderA\", \"RudderB\"],\n      \"position\": 47,\n      \"seek_position\": 120,\n      \"total_length\": 300,\n      \"bitrate\": 128,\n      \"framerate\": 24.00,\n      \"video_player\": \"youtube\",\n      \"sound\": 68,\n      \"full_screen\": true,\n      \"ad_enabled\": true,\n      \"quality\": \"hd1080\",\n      \"livestream\": false\n    }\n}\n```\n\n#### Video Playback Seek Completed\n\nThis event triggers after a user manually seeks to a certain position of the video or ad in the playback. The `position` property indicates where the user resumes the playback.\n\nHere is a sample event:\n\n```\n{\n    \"type\": \"track\",\n    \"event\": \"Video Playback Seek Completed\",\n    \"userId\": \"user12345\",\n    \"properties\": {\n      \"session_id\": \"12345\",\n      \"content_asset_ids\": [\"0129370\"],\n      \"content_pod_ids\": [\"RudderA\", \"RudderB\"],\n      \"position\": 120,\n      \"total_length\": 300,\n      \"bitrate\": 128,\n      \"framerate\": 24.00,\n      \"video_player\": \"youtube\",\n      \"sound\": 68,\n      \"full_screen\": true,\n      \"ad_enabled\": true,\n      \"quality\": \"hd1080\",\n      \"livestream\": false\n    }\n}\n```\n\n#### Video Playback Resumed\n\nThis event triggers when the user resumes video playback after pausing.\n\nHere is a sample event:\n\n```\n{\n    \"type\": \"track\",\n    \"event\": \"Video Playback Resumed\",\n    \"userId\": \"user12345\",\n    \"properties\": {\n      \"session_id\": \"12345\",\n      \"content_asset_ids\": [\"0129370\"],\n      \"content_pod_ids\": [\"RudderA\", \"RudderB\"],\n      \"position\": 120,\n      \"total_length\": 300,\n      \"bitrate\": 128,\n      \"framerate\": 24.00,\n      \"video_player\": \"youtube\",\n      \"sound\": 68,\n      \"full_screen\": true,\n      \"ad_enabled\": true,\n      \"quality\": \"hd1080\",\n      \"livestream\": false\n    }\n}\n```\n\n#### Video Playback Completed\n\nThis event triggers when playback is complete and only when the session is finished. Note that the `position` property is equal to the `total_length` property.\n\nHere is a sample event:\n\n```\n{\n    \"type\": \"track\",\n    \"event\": \"Video Playback Resumed\",\n    \"userId\": \"user12345\",\n    \"properties\": {\n      \"session_id\": \"12345\",\n      \"content_asset_ids\": [\"0129370\"],\n      \"content_pod_ids\": [\"RudderA\", \"RudderB\"],\n      \"position\": 300,\n      \"total_length\": 300,\n      \"bitrate\": 128,\n      \"framerate\": 24.00,\n      \"video_player\": \"youtube\",\n      \"sound\": 68,\n      \"full_screen\": true,\n      \"ad_enabled\": true,\n      \"quality\": \"hd1080\",\n      \"livestream\": false\n    }\n}\n```\n\n### Playback event properties\n\nAll playback events share the same properties to describe the current state of the video player.\n\nHere are the properties of this playback event:\n\n| Property | Type | Description |\n| --- | --- | --- |\n| `session_id` | String | Unique ID that ties all events generated from a specific playback session. These events include playback, content, and ad events. |\n| `content_asset_id` or `content_asset_ids` | String or Array \\[String\\] | Content asset ID/s of the video/s playing or about to play. For `Video Playback Started` events, an array of unique asset IDs should be sent. For other playback events, a single content asset ID at the time of the event should be sent. |\n| `content_pod_id` or `content_pod_ids` | String or Array \\[String\\] | Content pod ID/s of the video/s playing or about to play. For `Video Playback Started` events, an array of unique pod IDs should be sent. For other playback events, a single content pod ID associated with the current content pod at the time of the event should be sent. |\n| `ad_asset_id` | String or Array \\[String\\] | Ad asset ID/s of the video/s playing or about to play. For `Video Playback Started` events, an array of unique ad asset IDs should be sent. For other playback events, a sinule ad asset ID at the time of the event should be sent. |\n| `ad_pod_id` | String or Array \\[String\\] | Ad pod ID/s of the video/s playing or about to play. For `Video Playback Started` events, an array of unique ad pod IDs should be sent. For other playback events, a single ad pod ID at the time of the event should be sent. |\n| `ad_type` | Enum | Type of ad playing. The values can be `pre-roll`, `mid-roll`, or `post-roll`. |\n| `position` | Integer | Current index position of the playhead in seconds. It includes the time of any seen ads. If the playback is a livestream, refer to the documentation of the relevant destination for steps on correctly passing the playhead position. |\n| `seek_position` | Integer | Index position of the playhead the user is seeking to. Only available for `Video Playback Seek Started` events. On Video Playback Seek Completed events, the `seek_position` should be equal to `position`. |\n| `total_length` | Integer | Total duration of the video playback in seconds. Includes the total time of all content and ads in the session. Set to `null` in case of livestream playback. |\n| `bitrate` | Integer | Bit rate of the video playback in `kbps`. |\n| `framerate` | Float | Average frame rate of the video playback in `fps`. |\n| `video_player` | String | Name of the video player. Example: `youtube`, `vimeo`, etc. |\n| `sound` | Integer | Sound level of the video playback. Range is from 0-100, where 0 is mute and 100 is full volume. |\n| `full_screen` | Boolean | `true` if the playback is in fullscreen mode. |\n| `ad_enabled` | Boolean | `false` if the user has an ad blocker. If the user can view your video ads, it is set to `true`. |\n| `quality` | String | Quality of the video. Examples: `hd1080`, `highres` |\n| `method` | String | For the `Video Playback Interrupted` events, you can send this property noting how the playback was interrupted. Some examples include `device lock`, `call`, and `browser redirect`. |\n| `livestream` | Boolean | `true` if the playback is live stream. |\n\n## Content\n\nA content **pod** refers to a part / group / segment of the video content or the ad within the playback.\n\nSuppose a video playback session has a video and one mid-roll advertisement. The mid-roll ad splits the playback into two separate content pods and a single ad pod.\n\nThe flow is:\n\n*   First Content Pod: from the start of the playback to the start of the mid-roll ad\n*   Ad Pod: from the start to finish of the ad\n*   Second Content Pod: from the the restart of the playback to completion\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> All of these events happen within the flow of one playback start.\n\n### Content events\n\nThis section details all video content events.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> For more information on the properties associated with these events, refer to the [Content Event Properties](#content-event-properties) section.\n\n#### Video Content Started\n\nThis event triggers when a video content segment starts within a playback.\n\nHere is a sample event:\n\n```\n{\n    \"type\": \"track\",\n    \"event\": \"Video Content Started\",\n    \"userId\": \"user12345\",\n    \"properties\": {\n      \"session_id\": \"12345\",\n      \"asset_id\": \"123\",\n      \"pod_id\": \"RudderA\",\n      \"program\": \"Planet of the Apes\",\n      \"title\": \"Introduction\",\n      \"description\": \"Sample description\",\n      \"season\": \"3\",\n      \"position\": 0,\n      \"total_length\": 300,\n      \"genre\": \"SciFi\",\n      \"publisher\": \"Amazon\",\n      \"full_episode\": true,\n      \"keywords\": [\"apes\", \"forests\", \"zoo\"]\n    }\n}\n```\n\n#### Video Content Playing\n\nThese events are heartbeats triggering every `n` seconds to track the user’s current position in the video content, determined by the `position` property.\n\nHere is a sample event:\n\n```\n{\n    \"type\": \"track\",\n    \"event\": \"Video Content Playing\",\n    \"userId\": \"user12345\",\n    \"properties\": {\n      \"session_id\": \"12345\",\n      \"asset_id\": \"123\",\n      \"pod_id\": \"RudderA\",\n      \"program\": \"Planet of the Apes\",\n      \"title\": \"Introduction\",\n      \"description\": \"Sample description\",\n      \"season\": \"3\",\n      \"position\": 234,\n      \"total_length\": 300,\n      \"genre\": \"SciFi\",\n      \"publisher\": \"Amazon\",\n      \"full_episode\": true,\n      \"keywords\": [\"apes\", \"forests\", \"zoo\"]\n    }\n}\n```\n\n#### Video Content Completed\n\nThis event triggers once the video segment, within playback, is completed. Note that the `position` property is equal to the `total_length` property.\n\nHere is a sample event:\n\n```\n{\n    \"type\": \"track\",\n    \"event\": \"Video Content Completed\",\n    \"userId\": \"user12345\",\n    \"properties\": {\n      \"session_id\": \"12345\",\n      \"asset_id\": \"123\",\n      \"pod_id\": \"RudderA\",\n      \"program\": \"Planet of the Apes\",\n      \"title\": \"Introduction\",\n      \"description\": \"Sample description\",\n      \"season\": \"3\",\n      \"position\": 300,\n      \"total_length\": 300,\n      \"genre\": \"SciFi\",\n      \"publisher\": \"Amazon\",\n      \"full_episode\": true,\n      \"keywords\": [\"apes\", \"forests\", \"zoo\"]\n    }\n}\n```\n\n### Content event properties\n\nAll content events share the same properties describing the current state of the video content being viewed by the user.\n\nHere are the content event properties:\n\n| Property | Type | Description |\n| --- | --- | --- |\n| `session_id` | String | Unique ID that ties all events generated from a specific playback session. The value should be same for playback, content, and ad events from the same session. |\n| `asset_id` | String | Unique ID of the video content asset |\n| `pod_id` | String | Unique ID of the video content pod |\n| `title` | String | Title of the video content |\n| `description` | String | Short description of video content |\n| `keywords` | Array \\[String\\] | Array of keywords to describe or categorie the video content |\n| `season` | String | Season number, if applicable |\n| `episode` | String | Episode number, if applicable |\n| `genre` | String | Genre of the video content asset |\n| `program` | String | Name of the program/show, if applicable |\n| `publisher` | String | Publisher/creator/author of the video content asset |\n| `channel` | String | Channel the video content is playing |\n| `full_episode` | Boolean | True if the video content asset is a full episode |\n| `livestream` | Boolean | True if a live stream |\n| `airdate` | ISO 8601 Date String | Original date of the video content airing/publishing |\n| `position` | Integer | Current index position of the video content **in seconds**. This does not include any ads played in this duration. In case of live streams, refer to the specific [destination’s docs](https://www.rudderstack.com/docs/destinations/overview/) for details on how to pass `position`. |\n| `total_length` | Integer | Total length of video content in seconds. This does not include any ads in the playback. For livestream playback this should be set to null. |\n| `bitrate` | Integer | Current bit rate in kbps. |\n| `framerate` | Float | Frame rate in fps. |\n\n## Ads\n\n### Ad events\n\nFor more information on each of the properties associated with these events, refer to the [Ad Event Properties](#ad-event-properties) section.\n\nThis event triggers when an ad starts playing in the video playback.\n\nHere is a sample event:\n\n```\n{\n    \"type\": \"track\",\n    \"event\": \"Video Ad Started\",\n    \"userId\": \"user12345\",\n    \"properties\": {\n      \"session_id\": \"12345\",\n      \"asset_id\": \"123\",\n      \"pod_id\": \"RudderA\",\n      \"type\": \"mid-roll\",\n      \"title\": \"Our Planet\",\n      \"position\": 0,\n      \"total_length\": 25,\n      \"publisher\": \"BBC\",\n      \"load_type\": \"linear\"\n    }\n}\n```\n\nThis event triggers every `n` seconds while the ad is playing and is determined by the `position` property.\n\nHere is a sample event:\n\n```\n{\n    \"type\": \"track\",\n    \"event\": \"Video Ad Playing\",\n    \"userId\": \"user12345\",\n    \"properties\": {\n      \"session_id\": \"12345\",\n      \"asset_id\": \"123\",\n      \"pod_id\": \"RudderA\",\n      \"type\": \"pre-roll\",\n      \"title\": \"Our Planet\",\n      \"position\": 3,\n      \"total_length\": 25,\n      \"publisher\": \"BBC\",\n      \"load_type\": \"linear\"\n    }\n}\n```\n\nThis event triggers after the ad is complete. Note that the `position` property is equal to the `total_length` property.\n\n```\n{\n    \"type\": \"track\",\n    \"event\": \"Video Ad Completed\",\n    \"userId\": \"user12345\",\n    \"properties\": {\n      \"session_id\": \"12345\",\n      \"asset_id\": \"123\",\n      \"pod_id\": \"RudderA\",\n      \"type\": \"pre-roll\",\n      \"title\": \"Our Planet\",\n      \"position\": 25,\n      \"total_length\": 25,\n      \"publisher\": \"BBC\",\n      \"load_type\": \"linear\"\n    }\n}\n```\n\n### Ad event properties\n\nAll the ad events share the same properties that describe the current state of the video ad content in the playback.\n\nHere are the ad event properties:\n\n| Property | Type | Description |\n| --- | --- | --- |\n| `session_id` | String | Unique ID that ties all events generated from a specific playback session. The value should be same for playback, content, and ad events from the same session. |\n| `asset_id` | String | Unique ID of the ad asset |\n| `pod_id` | String | Unique ID of the ad pod |\n| `pod_position` | Integer | Position of the ad asset relative to other ads in the same pod |\n| `pod_length` | Integer | Number of ad assets in the current ad pod |\n| `type` | Enum | Type of ad. Values can be either `pre-roll`, `mid-roll`, or `post-roll`. |\n| `title` | String | Title of the ad |\n| `publisher` | String | Author/creator/publisher of the ad |\n| `position` | Integer | Current position in the ad, in seconds. |\n| `total_length` | Integer | Length of the ad asset in seconds. |\n| `load_type` | Enum | If the ad is loaded dynamically or is the same for all users. Values can be `dynamic` or `linear`. |\n| `content` | Object | Some destinations require content metadata to be sent with ad events. Send all metadata as a Content Event Object under this property. |\n| `quartile` | Integer | For Video Ad Playing events, indicates when a specific ad quartile is reached. If you are using a client-side library to track your video events, this property is optional as RudderStack automatically tracks the ad quartiles. |\n\n## Resuming playback\n\nEvery `Video Playback Resumed` the event should be followed by a heartbeat event (`Video Content Playing`) or a `Video Ad Playing` event, depending on what asset the playback resumes to.\n\n## Video quality\n\nRudderStack lets you track and analyze the performance and quality of your video content during playback.\n\nWhen a user changes the video quality during playback, a Video Quality Updated event triggers along with the following properties:\n\n*   `bitrate`: Updated bit rate in `kbps`.\n*   `framerate`: Updated frame rate in `fps`.\n*   `startupTime`: Time when the video quality was changed by the user.\n*   `droppedFrames`: If any frames were dropped during the video quality change.\n\n## Events lifecycle\n\nThe following event flow demonstrates how you can implement the RudderStack video specification:\n\n#### 1\\. User presses play on a video player\n\n```\nrudderanalytics.track(\"Video Playback Started\", {\n  session_id: \"12345\",\n  content_asset_ids: [\"123\"],\n  content_pod_ids: [\"RudderA\"],\n  ad_asset_ids: [\"ad1\"],\n  ad_pod_ids: [\"adRudderA\"],\n  ad_types: [\"mid-roll\"],\n  position: 0,\n  total_length: 300,\n  bitrate: 128,\n  video_player: \"youtube\",\n  sound: 66,\n  full_screen: true,\n  ad_enabled: false,\n  quality: \"hd1080\",\n})\n```\n\n#### 2\\. Video playback starts playing the content\n\n```\nrudderanalytics.track(\"Video Content Started\", {\n  session_id: \"12345\",\n  asset_id: \"123\",\n  pod_id: \"RudderA\",\n  title: \"Our Planet!\",\n  description: \"Deep look into our amazing planet\",\n  keywords: [\"nature\", \"entertainment\"],\n  season: \"1\",\n  episode: \"90\",\n  genre: \"entertainment\",\n  program: \"BBC\",\n  publisher: \"BBC\",\n  position: 0,\n  total_length: 300,\n  channel: \"ten\",\n  full_episode: true,\n  livestream: false,\n  airdate: \"2020-04-23\",\n})\n```\n\n#### 3\\. User views the content for 10 seconds followed by a 10 second heartbeat\n\n```\nrudderanalytics.track(\"Video Content Playing\", {\n  session_id: \"12345\",\n  asset_id: \"123\",\n  pod_id: \"RudderA\",\n  title: \"Our Planet!\",\n  description: \"Deep look into our amazing planet\",\n  keywords: [\"nature\", \"entertainment\"],\n  season: \"1\",\n  episode: \"90\",\n  genre: \"entertainment\",\n  program: \"BBC\",\n  publisher: \"BBC\",\n  position: 10,\n  total_length: 300,\n  channel: \"ten\",\n  full_episode: true,\n  livestream: false,\n  airdate: \"2020-04-23\",\n})\n```\n\n#### 4\\. Video playback is paused\n\n```\nrudderanalytics.track(\"Video Playback Paused\", {\n  session_id: \"12345\",\n  content_asset_id: \"123\",\n  content_pod_id: \"RudderA\",\n  ad_asset_id: null,\n  ad_pod_id: null,\n  ad_type: null,\n  position: 11,\n  total_length: 300,\n  video_player: \"youtube\",\n  sound: 66,\n  bitrate: 128,\n  full_screen: true,\n  ad_enabled: false,\n  quality: \"hd1080\",\n})\n```\n\n#### 5\\. User resumes the video playback\n\n```\nrudderanalytics.track(\"Video Playback Resumed\", {\n  session_id: \"12345\",\n  content_asset_id: \"123\",\n  content_pod_id: \"RudderA\",\n  ad_asset_id: null,\n  ad_pod_id: null,\n  ad_type: null,\n  position: 11,\n  total_length: 300,\n  video_player: \"youtube\",\n  sound: 66,\n  bitrate: 128,\n  full_screen: true,\n  ad_enabled: false,\n  quality: \"hd1080\",\n})\n```\n\n```\nrudderanalytics.track(\"Video Ad Started\", {\n  session_id: \"12345\",\n  asset_id: \"ad1\",\n  pod_id: \"adRudderA\",\n  type: \"mid-roll\",\n  title: \"Thumbs Up\",\n  publisher: \"Coca Cola\",\n  position: 0,\n  total_length: 15,\n  load_type: \"linear\",\n})\n```\n\n```\nrudderanalytics.track(\"Video Ad Playing\", {\n  session_id: \"12345\",\n  asset_id: \"ad1\",\n  pod_id: \"adRudderA\",\n  type: \"mid-roll\",\n  title: \"Thumbs Up\",\n  publisher: \"Coca Cola\",\n  position: 10,\n  total_length: 15,\n  load_type: \"linear\",\n})\n```\n\n```\nrudderanalytics.track(\"Video Ad Completed\", {\n  session_id: \"12345\",\n  asset_id: \"ad1\",\n  pod_id: \"adRudderA\",\n  type: \"mid-roll\",\n  title: \"Thumbs Up\",\n  publisher: \"Coca Cola\",\n  position: 15,\n  total_length: 15,\n  load_type: \"linear\",\n})\n```\n\n#### 9\\. Video content resumes playing. Heartbeats sent every 10 seconds\n\n```\nrudderanalytics.track(\"Video Content Playing\", {\n  session_id: \"12345\",\n  asset_id: \"123\",\n  pod_id: \"RudderA\",\n  title: \"Our Planet!\",\n  description: \"Deep look into our amazing planet\",\n  keywords: [\"nature\", \"entertainment\"],\n  season: \"1\",\n  episode: \"90\",\n  genre: \"entertainment\",\n  program: \"BBC\",\n  publisher: \"BBC\",\n  position: 11,\n  total_length: 300,\n  channel: \"ten\",\n  full_episode: true,\n  livestream: false,\n  airdate: \"2020-04-23\",\n})\n```\n\n#### 10\\. User finishes watching the video content\n\n```\nrudderanalytics.track(\"Video Content Completed\", {\n  session_id: \"12345\",\n  asset_id: \"123\",\n  pod_id: \"RudderA\",\n  title: \"Our Planet!\",\n  description: \"Deep look into our amazing planet\",\n  keywords: [\"nature\", \"entertainment\"],\n  season: \"1\",\n  episode: \"90\",\n  genre: \"entertainment\",\n  program: \"BBC\",\n  publisher: \"BBC\",\n  position: 300,\n  total_length: 300,\n  channel: \"ten\",\n  full_episode: true,\n  livestream: false,\n  airdate: \"2020-04-23\",\n})\n```\n\n#### 11\\. Video playback finished\n\n```\nrudderanalytics.track(\"Video Playback Completed\", {\n  session_id: \"12345\",\n  content_asset_id: null,\n  content_pod_id: null,\n  ad_asset_id: \"ad1\",\n  ad_pod_id: \"adRudderA\",\n  ad_type: null,\n  position: 300,\n  total_length: 300,\n  sound: 66,\n  bitrate: 128,\n  full_screen: true,\n  video_player: \"youtube\",\n  ad_enabled: false,\n  quality: \"hd1080\",\n})\n```\n\n## FAQ\n\n#### What are pre-roll, mid-roll, and post-roll ads?\n\n*   Pre-roll: Ads that appear before the start of the video playback\n*   Mid-roll: Ads that appear in the middle of the video playback\n*   Post-roll: Ads that appear after the video playback\n\nThese ads can be a promotional video by the sponsors or a piece of content offered by the content provider.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Video Events Spec | RudderStack Docs",
    "description": "Learn the syntax and general conventions for sending events when tracking videos.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/ecommerce-events-spec/",
    "markdown": "# Ecommerce Events Specification | RudderStack Docs\n\nPrivacy Overview\n\nThis site uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are as essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.\n\nNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.",
    "title": "Ecommerce Events Specification | RudderStack Docs",
    "description": "Understand the various ecommerce events captured by RudderStack.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/api/event-audit-api/v1/",
    "markdown": "# Event Audit API v1 | RudderStack Docs\n\nEnsure compliance with your data governance policies.\n\n* * *\n\n*     7 minute read  \n    \n\nRudderStack’s Event Audit API gives you full access to your event metadata. This data includes event payload schemas, data types, and event payload versions.\n\nThis document describes the available calls in the Event Audit API, as well as request parameters and returned object properties.\n\n### Authentication\n\nTo authenticate with the Event Audit API, you will need your `RUDDER_ADMIN_USER` and `RUDDER_ADMIN_PASSWORD`. If you are using the RudderStack-managed hosting service, [contact support](mailto:support@rudderstack.com) for the necessary credentials.\n\nUse [HTTP Basic authentication](https://en.wikipedia.org/wiki/Basic_access_authentication) with your Rudder admin username and password to authenticate requests.\n\n```\nAuthorization: Basic <RUDDER_ADMIN_USER>:<RUDDER_ADMIN_PASSWORD>\n```\n\nAnyone with these credentials can use the same Event Audit API. In case it is compromised, please restart your data plane with different credentials.\n\n## Base URL\n\nUse the [data plane URLThe data plane URL is the location where events are routed and sent to the RudderStack backend for processing. You can find this URL in the home page of your RudderStack dashboard.](https://www.rudderstack.com/docs/resources/glossary/#data-plane-url) as the base URL for your API requests.\n\n## List event models\n\nGet the event models for your data plane.\n\n**Query parameters**\n\nstring\n\nOptionally include your write key as a query parameter to get event models for only one source.\n\n* * *\n\n**Example Request**:\n\n```\nGET /schemas/event-models HTTP/1.1\nHost: <YOUR_DATA_PLANE_URL>\nAuthorization: Basic UlVEREVSX0FETUlOX1VTRVI6UlVEREVSX0FETUlOX1BBU1M=\n```\n\n```\ncurl -u <RUDDER_ADMIN_USER>:<RUDDER_ADMIN_PASSWORD> https://<DATA_PLANE_URL>/schemas/event-models\n```\n\n**Example Response**:\n\n```\n[\n  {\n    \"ID\": 40,\n    \"EventID\": \"1b02d5ec-83b9-405e-ba86-7693d0a2b52b\",\n    \"WriteKey\": \"1Xbp2IIhsZcwqENLgSEJusU70GH\",\n    \"EventType\": \"track\",\n    \"EventIdentifier\": \"Product Purchased\",\n    \"CreatedAt\": \"2020-12-07T22:10:13.945156Z\",\n    \"Schema\": {\n      \"type\": \"string\",\n      \"event\": \"string\",\n      \"sentAt\": \"string\",\n      \"userId\": \"string\",\n      \"rudderId\": \"string\",\n      \"messageId\": \"string\",\n      \"timestamp\": \"string\",\n      \"context.ip\": \"string\",\n      \"anonymousId\": \"string\",\n      \"properties.name\": \"string\",\n      \"originalTimestamp\": \"string\",\n      \"properties.revenue\": \"float64\",\n      \"context.library.name\": \"string\"\n    },\n    \"LastSeen\": \"2020-12-07T22:10:09.247534Z\",\n    \"TotalCount\": 5\n  },\n  {\n    \"ID\": 41,\n    \"EventID\": \"96f10d53-3a94-47a2-95e7-6cca99daed1e\",\n    \"WriteKey\": \"1cUFbgdRJj8LYpA6zGV3O5dGpAq\",\n    \"EventType\": \"page\",\n    \"EventIdentifier\": \"Product Viewed\",\n    \"CreatedAt\": \"2020-12-06T20:17:43.945156Z\",\n    \"Schema\": {\n      \"type\": \"string\",\n      \"name\": \"string\",\n      \"sentAt\": \"string\",\n      \"userId\": \"string\",\n      \"rudderId\": \"string\",\n      \"messageId\": \"string\",\n      \"timestamp\": \"string\",\n      \"context.ip\": \"string\",\n      \"anonymousId\": \"string\",\n      \"properties.name\": \"string\",\n      \"originalTimestamp\": \"string\",\n      \"context.library.name\": \"string\"\n    },\n    \"LastSeen\": \"2020-12-07T22:10:09.247534Z\",\n    \"TotalCount\": 20\n  }\n]\n```\n\n## Get event models for a specific source\n\nIf you want only event models for a specific source, pass the [write keyThe write key (or source write key) is a unique identifier for your source. RudderStack uses this key to send events from a source to the specified destination.](https://www.rudderstack.com/docs/resources/glossary/#write-key) as a query parameter.\n\n**Example Request**:\n\n```\nGET /schemas/event-models?WriteKey=1Xbp2IIhsZcwqENLgSEJusU70GH HTTP/1.1\nHost: https://<DATA_PLANE_URL>\nAuthorization: Basic UlVEREVSX0FETUlOX1VTRVI6UlVEREVSX0FETUlOX1BBU1M=\n```\n\n```\ncurl -u <RUDDER_ADMIN_USER>:<RUDDER_ADMIN_PASSWORD> https://<DATA_PLANE_URL>/schemas/event-models?WriteKey=1Xbp2IIhsZcwqENLgSEJusU70GH\n```\n\n**Example Response**:\n\n```\n[\n  {\n    \"ID\": 40,\n    \"EventID\": \"1b02d5ec-83b9-405e-ba86-7693d0a2b52b\",\n    \"WriteKey\": \"1Xbp2IIhsZcwqENLgSEJusU70GH\",\n    \"EventType\": \"track\",\n    \"EventIdentifier\": \"Product Purchased\",\n    \"CreatedAt\": \"2020-12-07T22:10:13.945156Z\",\n    \"Schema\": {\n      \"type\": \"string\",\n      \"event\": \"string\",\n      \"sentAt\": \"string\",\n      \"userId\": \"string\",\n      \"rudderId\": \"string\",\n      \"messageId\": \"string\",\n      \"timestamp\": \"string\",\n      \"context.ip\": \"string\",\n      \"anonymousId\": \"string\",\n      \"properties.name\": \"string\",\n      \"originalTimestamp\": \"string\",\n      \"properties.revenue\": \"float64\",\n      \"context.library.name\": \"string\"\n    },\n    \"LastSeen\": \"2020-12-07T22:10:09.247534Z\",\n    \"TotalCount\": 5\n  }\n]\n```\n\n## List event versions\n\nGet the schema versions for an event type.\n\nGET\n\n/schemas/event-versions\n\n**Query parameters**\n\nstring\n\nMandatory parameter to get the schema versions for an event model. Obtain the `EventID` from `GET /schemas/event-models`.\n\n* * *\n\n**Example Request**:\n\n```\nGET /schemas/event-versions?EventID=1b02d5ec-83b9-405e-ba86-7693d0a2b52b HTTP/1.1\nHost: https://<DATA_PLANE_URL>\nAuthorization: Basic UlVEREVSX0FETUlOX1VTRVI6UlVEREVSX0FETUlOX1BBU1M=\n```\n\n```\ncurl -u <RUDDER_ADMIN_USER>:<RUDDER_ADMIN_PASSWORD> https://<DATA_PLANE_URL>/schemas/event-versions?EventID=1b02d5ec-83b9-405e-ba86-7693d0a2b52b\n```\n\n**Example Response**:\n\n```\n[\n  {\n    \"ID\": 39,\n    \"VersionID\": \"9e9e6da4-24b7-4cf9-a194-8acb040d7422\",\n    \"EventModelID\": \"1b02d5ec-83b9-405e-ba86-7693d0a2b52b\",\n    \"Schema\": {\n      \"type\": \"string\",\n      \"event\": \"string\",\n      \"sentAt\": \"string\",\n      \"userId\": \"string\",\n      \"rudderId\": \"string\",\n      \"messageId\": \"string\",\n      \"context.ip\": \"string\",\n      \"anonymousId\": \"string\",\n      \"properties.name\": \"string\",\n      \"originalTimestamp\": \"string\",\n      \"properties.revenue\": \"float64\",\n      \"context.library.name\": \"string\"\n    },\n    \"FirstSeen\": \"2020-12-07T22:00:38.437051Z\",\n    \"LastSeen\": \"2020-12-07T22:08:04.036091Z\",\n    \"TotalCount\": 4\n  },\n  {\n    \"ID\": 40,\n    \"VersionID\": \"b39800d9-55d5-4163-b859-1bca04c4003b\",\n    \"EventModelID\": \"1b02d5ec-83b9-405e-ba86-7693d0a2b52b\",\n    \"Schema\": {\n      \"type\": \"string\",\n      \"event\": \"string\",\n      \"userId\": \"string\",\n      \"rudderId\": \"string\",\n      \"messageId\": \"string\",\n      \"timestamp\": \"string\",\n      \"context.ip\": \"string\",\n      \"anonymousId\": \"string\",\n      \"properties.name\": \"string\",\n      \"properties.revenue\": \"float64\",\n      \"context.library.name\": \"string\"\n    },\n    \"FirstSeen\": \"2020-12-07T22:10:09.247629Z\",\n    \"LastSeen\": \"2020-12-07T22:10:09.247698Z\",\n    \"TotalCount\": 1\n  }\n]\n```\n\nRetrieve metadata for an event model.\n\nGET\n\n/schemas/event-model/{EventID}/metadata\n\n**Path parameters**\n\nstring\n\nMandatory path parameter to get metadata for an event model. Obtain the `EventID` from `GET /schemas/event-models`.\n\n* * *\n\n**Response object parameters**:\n\narray\n\nThe sample events belonging to the event model.\n\nnumber\n\nThe number of events collected for the event model.\n\nobject\n\nThis is a list of all values that frequently appear for each key in the master-schema along with their frequencies. By default, we consider any value that is seen once every hundred samples as a frequent value.\n\n* * *\n\n**Example Request**:\n\n```\nGET /schemas/event-model/96f10d53-3a94-47a2-95e7-6cca99daed1e/metadata HTTP/1.1\nHost: https://<DATA_PLANE_URL>\nAuthorization: Basic UlVEREVSX0FETUlOX1VTRVI6UlVEREVSX0FETUlOX1BBU1M=\n```\n\n```\ncurl -u <RUDDER_ADMIN_USER>:<RUDDER_ADMIN_PASSWORD> https://<DATA_PLANE_URL>/schemas/event-model/96f10d53-3a94-47a2-95e7-6cca99daed1e/metadata\n```\n\n**Example Response**:\n\n```\n{\n  \"SampledEvents\": [\n    {\n      \"anonymousId\": \"1hg89d6hvskmygt83nst\",\n      \"context\": {\n        \"ip\": \"1.2.3.4\",\n        \"library\": {\n          \"name\": \"http\"\n        }\n      },\n      \"event\": \"Product Purchased\",\n      \"messageId\": \"messageID\",\n      \"originalTimestamp\": \"2020-02-02T00:23:09.544Z\",\n      \"properties\": {\n        \"name\": \"Shirt\",\n        \"revenue\": 14.99\n      },\n      \"rudderId\": \"d2c78239-ffb7-46b9-9bf9-e995465873b1\",\n      \"sentAt\": \"2020-02-02T00:23:09.544Z\",\n      \"type\": \"track\",\n      \"userId\": \"user12345\"\n    },\n    {\n      \"anonymousId\": \"1hg89d6hvskmygt83nst\",\n      \"context\": {\n        \"ip\": \"1.2.3.4\",\n        \"library\": {\n          \"name\": \"http\"\n        }\n      },\n      \"event\": \"Product Purchased\",\n      \"messageId\": \"messageID\",\n      \"properties\": {\n        \"name\": \"Shirt\",\n        \"revenue\": 14.99\n      },\n      \"rudderId\": \"d2c78239-ffb7-46b9-9bf9-e995465873b1\",\n      \"timestamp\": \"2020-02-02T00:23:09.544Z\",\n      \"type\": \"track\",\n      \"userId\": \"user12345\"\n    }\n  ],\n  \"TotalCount\": 5,\n  \"FrequentValues\": {\n    \"anonymousId\": [\n      {\n        \"Value\": \"1hg89d6hvskmygt83nst\",\n        \"Frequency\": 1\n      }\n    ],\n    \"context.ip\": [\n      {\n        \"Value\": \"1.2.3.4\",\n        \"Frequency\": 1\n      }\n    ],\n    \"context.library.name\": [\n      {\n        \"Value\": \"http\",\n        \"Frequency\": 1\n      }\n    ],\n    \"event\": [\n      {\n        \"Value\": \"Product Purchased\",\n        \"Frequency\": 1\n      }\n    ],\n    \"messageId\": [\n      {\n        \"Value\": \"messageID\",\n        \"Frequency\": 1\n      }\n    ],\n    \"originalTimestamp\": [\n      {\n        \"Value\": \"2020-02-02T00:23:09.544Z\",\n        \"Frequency\": 1\n      }\n    ],\n    \"properties.name\": [\n      {\n        \"Value\": \"Shirt\",\n        \"Frequency\": 1\n      }\n    ],\n    \"properties.revenue\": [\n      {\n        \"Value\": \"14.99\",\n        \"Frequency\": 1\n      }\n    ],\n    \"rudderId\": [\n      {\n        \"Value\": \"d2c78239-ffb7-46b9-9bf9-e995465873b1\",\n        \"Frequency\": 1\n      }\n    ],\n    \"sentAt\": [\n      {\n        \"Value\": \"2020-02-02T00:23:09.544Z\",\n        \"Frequency\": 1\n      }\n    ],\n    \"timestamp\": [\n      {\n        \"Value\": \"2020-02-02T00:23:09.544Z\",\n        \"Frequency\": 1\n      }\n    ],\n    \"type\": [\n      {\n        \"Value\": \"track\",\n        \"Frequency\": 1\n      }\n    ],\n    \"userId\": [\n      {\n        \"Value\": \"user12345\",\n        \"Frequency\": 1\n      }\n    ]\n  }\n}\n```\n\nRetrieve a listing of the metadata for a specific schema version.\n\nGET\n\n/schemas/event-version/{VersionID}/metadata\n\n**Path parameters**\n\nstring\n\nMandatory path parameter to get metadata for a schema version. Obtain the `VersionID` from `GET /schemas/event-models`.\n\n* * *\n\n**Response object parameters**:\n\narray\n\nThe sample events belonging to the given schema version.\n\nnumber\n\nThe number of events collected for the given schema version.\n\nobject\n\nA list of all values that frequently appear for each key in the master-schema along with their frequencies. By default, we consider any value that is seen once every hundred samples as a frequent value.\n\n* * *\n\n**Example Request**:\n\n```\nGET /schemas/event-version/96f10d53-3a94-47a2-95e7-6cca99daed1e/metadata HTTP/1.1\nHost: https://<DATA_PLANE_URL>\nAuthorization: Basic UlVEREVSX0FETUlOX1VTRVI6UlVEREVSX0FETUlOX1BBU1M=\n```\n\n```\ncurl -u <RUDDER_ADMIN_USER>:<RUDDER_ADMIN_PASSWORD> https://<DATA_PLANE_URL>/schemas/event-version/96f10d53-3a94-47a2-95e7-6cca99daed1e/metadata\n```\n\n**Example Response**:\n\n```\n{\n  \"SampledEvents\": [\n    {\n      \"anonymousId\": \"1hg89d6hvskmygt83nst\",\n      \"context\": {\n        \"ip\": \"1.2.3.4\",\n        \"library\": {\n          \"name\": \"http\"\n        }\n      },\n      \"event\": \"Product Purchased\",\n      \"messageId\": \"messageID\",\n      \"originalTimestamp\": \"2020-02-02T00:23:09.544Z\",\n      \"properties\": {\n        \"name\": \"Shirt\",\n        \"revenue\": 14.99\n      },\n      \"rudderId\": \"d2c78239-ffb7-46b9-9bf9-e995465873b1\",\n      \"sentAt\": \"2020-02-02T00:23:09.544Z\",\n      \"type\": \"track\",\n      \"userId\": \"user12345\"\n    }\n  ],\n  \"TotalCount\": 4,\n  \"FrequentValues\": {\n    \"anonymousId\": [\n      {\n        \"Value\": \"1hg89d6hvskmygt83nst\",\n        \"Frequency\": 1\n      }\n    ],\n    \"context.ip\": [\n      {\n        \"Value\": \"1.2.3.4\",\n        \"Frequency\": 1\n      }\n    ],\n    \"context.library.name\": [\n      {\n        \"Value\": \"http\",\n        \"Frequency\": 1\n      }\n    ],\n    \"event\": [\n      {\n        \"Value\": \"Product Purchased\",\n        \"Frequency\": 1\n      }\n    ],\n    \"messageId\": [\n      {\n        \"Value\": \"messageID\",\n        \"Frequency\": 1\n      }\n    ],\n    \"originalTimestamp\": [\n      {\n        \"Value\": \"2020-02-02T00:23:09.544Z\",\n        \"Frequency\": 1\n      }\n    ],\n    \"properties.name\": [\n      {\n        \"Value\": \"Shirt\",\n        \"Frequency\": 1\n      }\n    ],\n    \"properties.revenue\": [\n      {\n        \"Value\": \"14.99\",\n        \"Frequency\": 1\n      }\n    ],\n    \"rudderId\": [\n      {\n        \"Value\": \"d2c78239-ffb7-46b9-9bf9-e995465873b1\",\n        \"Frequency\": 1\n      }\n    ],\n    \"sentAt\": [\n      {\n        \"Value\": \"2020-02-02T00:23:09.544Z\",\n        \"Frequency\": 1\n      }\n    ],\n    \"type\": [\n      {\n        \"Value\": \"track\",\n        \"Frequency\": 1\n      }\n    ],\n    \"userId\": [\n      {\n        \"Value\": \"user12345\",\n        \"Frequency\": 1\n      }\n    ]\n  }\n}\n```\n\n## Get key counts for an event model\n\nGets the key-wise counts for an event model.\n\nGET\n\n/schemas/event-model/{EventID}/key-counts\n\n**Path parameters**\n\nstring\n\nMandatory path parameter to get key counts for the given event model. Obtain the `EventID` from `GET /schemas/event-models`.\n\n* * *\n\n**Example Request**:\n\n```\nGET /schemas/event-model/ad00285b-f49f-4d4f-88e0-8ec293bbd5c7/key-counts HTTP/1.1\nHost: https://<DATA_PLANE_URL>\nAuthorization: Basic UlVEREVSX0FETUlOX1VTRVI6UlVEREVSX0FETUlOX1BBU1M=\n```\n\n```\ncurl -u <RUDDER_ADMIN_USER>:<DATA_PLANE_URL> https://<your-data-plane-url>/schemas/event-model/ad00285b-f49f-4d4f-88e0-8ec293bbd5c7/key-counts\n```\n\n**Example Response**:\n\n```\n{\n  \"anonymousId\": 1234,\n  \"channel\": 1372,\n  \"context.app.build\": 607,\n  \"context.app.name\": 607,\n  \"context.app.namespace\": 607,\n  \"context.app.version\": 607,\n  \"context.device.id\": 1372,\n  \"context.device.manufacturer\": 1372,\n  \"context.device.model\": 1372,\n  \"context.device.name\": 1372,\n  \"context.library.name\": 1372,\n  \"context.locale\": 1372,\n  \"context.network.carrier\": 1372,\n  \"context.screen.density\": 1372,\n  \"context.screen.height\": 1372,\n  \"context.screen.width\": 1372,\n  \"context.traits.anonymousId\": 1372,\n  \"context.user_agent\": 1372,\n  \"event\": 1372,\n  \"integrations.All\": 1372,\n  \"messageId\": 1372,\n  \"originalTimestamp\": 1372,\n  \"properties.category\": 607,\n  \"properties.label\": 607,\n  \"properties.value\": 607,\n  \"sentAt\": 1372,\n  \"type\": 1372\n}\n```\n\n## Get missing keys for a schema version\n\nGET\n\n/schemas/event-version/{VersionID}/missing-keys\n\n**Path parameters**\n\nstring\n\nMandatory path parameter to get missing keys for the given schema version. Obtain the `VersionID` from `GET /schemas/event-versions`.\n\n* * *\n\n**Example Request**:\n\n```\nGET /schemas/event-version/ad00285b-f49f-4d4f-88e0-8ec293bbd5c7/missing-keys HTTP/1.1\nHost: https://<DATA_PLANE_URL>\nAuthorization: Basic UlVEREVSX0FETUlOX1VTRVI6UlVEREVSX0FETUlOX1BBU1M=\n```\n\n```\ncurl -u <RUDDER_ADMIN_USER>:<RUDDER_ADMIN_PASSWORD> https://<DATA_PLANE_URL>/schemas/ad00285b-f49f-4d4f-88e0-8ec293bbd5c7/missing-keys\n```\n\n**Example Response**:\n\n```\n[\n  \"properties.testProp222\",\n  \"properties.keyB\",\n  \"properties.keyA\",\n  \"properties.webhookurl\",\n  \"properties.governanceTest\"\n]\n```\n\n### API responses\n\nThe API responds with a `200` HTTP status code for all successful requests. If the authentication fails, you will get a `400` HTTP status code with the appropriate error message.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Event Audit API v1 | RudderStack Docs",
    "description": "Ensure compliance with your data governance policies.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/standard-events/application-lifecycle-events-spec/",
    "markdown": "# Mobile Application Lifecycle Events Spec\n\nLearn the app lifecyle events tracked out of the box by RudderStack SDKs.\n\n* * *\n\n*     4 minute read  \n    \n\nRudderStack lets you track various application lifecycle events across the mobile SDKs and get insights into app-related metrics like installs, opens, etc. This guide provides the details and semantic definitions of these events and the associated properties.\n\n## Supported lifecycle events\n\nRudderStack **automatically tracks** the following application lifecycle events:\n\n*   [Application Installed](#application-installed)\n*   [Application Opened](#application-opened)\n*   [Application Updated](#application-updated)\n*   [Application Backgrounded](#application-backgrounded)\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> To disable the auto-tracking of these events, set the `withTrackLifecycleEvents` parameter to `false` while initializing the [Android](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-android-sdk/) / [iOS](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-ios-sdk/) SDK.\n\n## Application Installed\n\nThis event is triggered when a user opens an application for the first time after installation.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> RudderStack does not collect this event if the user does not open the app after installation.\n\nThe following properties are supported:\n\n| Property | Type | Description |\n| --- | --- | --- |\n| `version` | String | Application version |\n\nHere is a sample payload:\n\n```\n{\n  \"type\": \"track\",\n  \"event\": \"Application Installed\",\n  \"properties\": {\n    \"version\": \"11.1.7\"\n  }\n}\n```\n\n## Application Opened\n\nThis event is triggered each time a user launches the application (except for the initial launch after installation).\n\nThe following properties are supported:\n\n| Property | Type | Description |\n| --- | --- | --- |\n| `from_background` | Boolean | Was the app was backgrounded initially? |\n| `url`\\* | String | Deep linking URL |\n| `referring_application`\\* | String | External application that referred the user to the app. |\n| `version`\\* | String | Application version |\n\nHere is a sample payload:\n\n```\n{\n  \"userId\": \"1hKOmRA4el9Z\",\n  \"type\": \"track\",\n  \"event\": \"Application Opened\",\n  \"properties\": {\n    \"from_background\": false,\n    \"referring_application\": \"Whatsapp\",\n    \"url\": \"https://www.estore.com/best-seller/1\",\n    \"version\": \"11.1.7\"\n  }\n}\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> `userId` will be present only if the user is logged into the application, i.e., an [identify](https://www.rudderstack.com/docs/event-spec/standard-events/identify/) call was previously triggered.\n\nThere are some differences in the way the RudderStack SDKs handle event properties:\n\n### Android SDK\n\n*   The properties marked with an asterisk (`url`, `referring_application`, `version`) are tracked and sent only if they are available on the first launch of the application.\n*   RudderStack also sends all query parameters received as a part of the deep linking URL as key-value pairs in the `Application Opened` event properties.\n\n### iOS SDK\n\n*   The properties marked with an asterisk (`url`, `referring_application`, `version`) are tracked and sent only if they are available on every application launch.\n\n### Unity SDK\n\n*   The properties marked with an asterisk (`url`, `referring_application`, `version`) are not tracked either for Android or iOS.\n\n### React Native SDK\n\n| Platform | Expected behavior |\n| --- | --- |\n| Android | RudderStack **does not track** the properties marked with an asterisk (`url`, `referring_application`, `version`). |\n| iOS | The properties marked with an asterisk are tracked only if they are available on every application launch. |\n\n### Flutter SDK\n\n| Platform | Expected behavior |\n| --- | --- |\n| Android | **No properties** are tracked. |\n| iOS | The properties marked with an asterisk (`url`, `referring_application`, `version`) are tracked only if they are available on every application launch. |\n\n### Cordova SDK\n\n| Platform | Expected behavior |\n| --- | --- |\n| Android | Same behavior as the [Android SDK](#android-sdk). |\n| iOS | Same behavior as the [iOS SDK](#ios-sdk). |\n\n## Application Updated\n\nThis event is triggered when a user updates their application.\n\nThe following properties are supported:\n\n| Property | Type | Description |\n| --- | --- | --- |\n| `previous_version` | String | Application version before update |\n| `version` | String | Application version after update |\n\nHere is a sample payload:\n\n```\n{\n  \"userId\": \"1hKOmRA4el9Z\",\n  \"type\": \"track\",\n  \"event\": \"Application Updated\",\n  \"properties\": {\n    \"previous_version\": \"11.1.7\",\n    \"version\": \"12.0.1\"\n  }\n}\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> For the Unity SDK, you need to perform additional required [steps](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-unity-sdk/v1/#triggering-application-updated-lifecycle-event) for the Android and iOS platforms to trigger the **Application Updated** lifecycle event.\n\n## Application Backgrounded\n\nThis event is triggered when the user backgrounds the application.\n\nHere is a sample payload:\n\n```\n{\n  \"userId\": \"1hKOmRA4el9Z\",\n  \"type\": \"track\",\n  \"event\": \"Application Backgrounded\",\n  \"properties\": {}\n}\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> RudderStack does not track any properties for this event.\n\n## FAQ\n\n#### What is the format of application lifecycle events follow the standard timestamps?\n\nThe lifecycle events timestamp format is the same as [Common Fields](https://www.rudderstack.com/docs/event-spec/standard-events/common-fields/).\n\n#### Do application lifecycle events include user traits or context objects?\n\nApplication lifecycle events include `context` objects. Note that `userId` will only be present if the user is logged into the application, i.e., an [identify](https://www.rudderstack.com/docs/event-spec/standard-events/identify/) call was previously triggered.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Mobile Application Lifecycle Events Spec | RudderStack Docs",
    "description": "Learn the app lifecyle events tracked out of the box by RudderStack SDKs.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/api/data-catalog-api/json-schema/",
    "markdown": "# JSON Schema | RudderStack Docs\n\nJSON schema specification for upserting events to your tracking plan via Data Catalog API.\n\n* * *\n\n*     4 minute read  \n    \n\n[JSON schema](https://json-schema.org/overview/what-is-jsonschema) is a vocabulary used to annotate and validate JSON documents.\n\nFollow this guide to standardize and define expectations for your events while [upserting them into your tracking plan](https://www.rudderstack.com/docs/api/data-catalog-api/#upsert-event-to-tracking-plan) via the Data Catalog API.\n\n## Keywords\n\nKeywords are properties appearing within a JSON [schema](https://json-schema.org/learn/glossary#schema) object.\n\n```\n{\n  \"title\": \"Example Schema\",\n  \"type\": \"object\"\n}\n```\n\nIn the above snippet, the `title` and `type` are keywords.\n\n### Type-specific keywords\n\nThe `type` keyword specifies the data type for a JSON schema. RudderStack supports the following keywords:\n\n#### Strings\n\nThe [`string`](https://json-schema.org/understanding-json-schema/reference/string) data type is used to represent strings of text and can contain Unicode characters.\n\nA sample schema definition for a string:\n\n#### Integers and numbers\n\nThe JSON schema defines two [numeric data types](https://json-schema.org/understanding-json-schema/reference/numeric):\n\n*   `integer`: Used for integral numbers.\n*   `number`: Used for any numeric type like integers or floating point numbers.\n\nA sample schema definition for an integer and number:\n\n#### Objects\n\nYou can use JSON [objects](https://json-schema.org/understanding-json-schema/reference/object) to map specific keys to values.\n\nWhile using the Data Catalog API, you can use the [`rules`](https://www.rudderstack.com/docs/api/data-catalog-api/#upsert-event-to-tracking-plan) object to specify the property mappings for the event to be upserted in the tracking plan. A sample `rules` object is shown:\n\n```\n{\n  \"identify\": {\n    \"type\": \"object\",\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"properties\": {\n      \"anonymousId\": {\n        \"type\": \"string\"\n      },\n      \"userId\": {\n        \"type\": \"string\"\n      }\n    }\n  }\n}\n```\n\nRudderStack supports the following keywords within an object:\n\n| Keyword | Data type | Description |\n| --- | --- | --- |\n| `properties` | Object | Properties for the event to be upserted in tracking plan. |\n| `additionalProperties` | Boolean | Determines if RudderStack should allow any other properties apart from the ones defined in `properties`. |\n| `required` | Boolean | Determines if a property is required or optional for the event. |\n\nA sample schema definition for an object:\n\n```\n{\n  \"type\": \"object\",\n  \"properties\": {\n    \"number\": {\n      \"type\": \"number\"\n    },\n    \"street_name\": {\n      \"type\": \"string\"\n    },\n    \"street_type\": {\n      \"enum\": [\"Street\", \"Avenue\", \"Boulevard\"]\n    }\n  },\n  \"additionalProperties\": false\n}\n```\n\nFor the above example, the schema definition validates the following JSON:\n\n```\n{\n  \"number\": 1600,\n  \"street_name\": \"Pennsylvania\",\n  \"street_type\": \"Avenue\"\n}\n```\n\nThe above schema definition invalidates the following JSON as it contains an undefined property `direction` and `additionalProperties` is set to false:\n\n```\n{\n  \"number\": 1600,\n  \"street_name\": \"Pennsylvania\",\n  \"street_type\": \"Avenue\",\n  \"direction\": \"North-west\"\n}\n```\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n\n#### Arrays\n\nYou can use [arrays](https://json-schema.org/understanding-json-schema/reference/array) for ordered elements.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> RudderStack expects only objects to be present within an array.\n\nThere are two ways of using arrays in JSON:\n\n*   List validation: Sequence of arbitrary length where each item matches the same schema.\n*   Tuple validation: Sequence of fixed length where each item can have a different schema.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> RudderStack supports only list validation and the [`items`](https://json-schema.org/understanding-json-schema/reference/array#items) keyword to validate the items in the array.\n\nA sample schema definition for an array:\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n\n##### **Nesting properties**\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> This section is applicable to [objects](#object) and [array](#arrays) data types.\n\nRudderStack supports defining complex nested properties within an object or array while defining the event properties.\n\nA sample object highlighting the nested properties is shown:\n\n```\n{\n  \"type\": \"object\",\n  \"properties\": {\n    \"traits\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"name\": {\n          \"type\": \"string\"\n        },\n        \"industry\": {\n          \"type\": \"string\"\n        },\n        \"plan\": {\n          \"type\": \"string\"\n        }\n      }\n    }\n  }\n}\n```\n\nNote that:\n\n*   RudderStack supports up to three levels of nesting within an event property.\n*   You can nest properties only within an object or an array.\n*   Removing the parent object or array automatically removes all the nested properties.\n*   If not explicitly declared, RudderStack allows all data types for a property by default. However, it **does not** support nesting for that property.\n*   You **cannot** nest properties within a property having both array and object data types.\n\n#### Boolean\n\nThe [boolean](https://json-schema.org/understanding-json-schema/reference/boolean) data type supports only two values - `true` and `false`. RudderStack does not support values that evaluate to `true` or `false`, like `1` and `0`.\n\nA sample schema definition for a boolean:\n\n#### Null\n\nThe [null](https://json-schema.org/understanding-json-schema/reference/null) data type accepts only one value - `null`.\n\nA sample schema definition for null data type:\n\n## Multi data types\n\nRudderStack also supports specifying multi data types for the event properties along with the [above data types](#type-specific-keywords).\n\nA sample schema definition for multi data types:\n\n```\n{\n  \"type\": [\"string\", \"integer\", \"boolean\", \"null\"]\n}\n```\n\n## Restricted keyword structures\n\nApart from the data type-specific keywords, RudderStack also restricts usage of the following keyword structures:\n\n*   [const](https://json-schema.org/understanding-json-schema/reference/const)\n*   [enum](https://json-schema.org/understanding-json-schema/reference/enum)\n*   [Conditional subschemas](https://json-schema.org/understanding-json-schema/reference/conditionals)\n*   [String encoding non-JSON data](https://json-schema.org/understanding-json-schema/reference/non_json_data)\n*   [Complex schema structures](https://json-schema.org/understanding-json-schema/structuring)\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "JSON Schema | RudderStack Docs",
    "description": "JSON schema specification for upserting events to your tracking plan via Data Catalog API.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/ecommerce-events-spec/browsing/",
    "markdown": "# Browsing | RudderStack Docs\n\nUnderstand how ecommerce browsing events work in RudderStack.\n\n* * *\n\n*     3 minute read  \n    \n\nThe browsing lifecycle events are associated with key activities that a customer might perform while browsing through your website or mobile app.\n\n## Products Searched\n\nThis event is triggered when a visitor searches for a product on your app/website. The following properties are supported:\n\n| **Property Name** | **Type** | **Description of the Property** |\n| --- | --- | --- |\n| `query` | String / Object | Query searched by the user |\n\nHere is an example of the **Products Searched** event:\n\n```\nrudderanalytics.track(\"Products Searched\", {\n  query: \"HDMI cable\",\n})\n```\n\n## Product List Viewed\n\nThis event is triggered when a visitor views a list or category of products on your website or app. The following properties are supported:\n\n| **Property Name** | **Type** | **Description of the Property** |\n| --- | --- | --- |\n| `list_id` | String | Name of the product list being viewed |\n| `category` | String | Category of the product being viewed |\n| `products` | Array | Array of products displayed in the product list |\n| `products.$.product_id` | String | Product ID displayed on the list |\n| `products.$.sku` | String | SKU (Stock Keeping Unit) of the product being viewed |\n| `products.$.category` | String | Category of the product being viewed |\n| `products.$.name` | String | Name of the product being viewed |\n| `products.$.brand` | String | Name of the brand associated with the product |\n| `products.$.variant` | String | Name of the variant of the product |\n| `products.$.price` | Number | Price of the product being viewed (in USD) |\n| `products.$.quantity` | Number | Quantity of the product |\n| `products.$.coupon` | String | Coupon code associated with a product |\n| `products.$.position` | Number | Position of the product in the product list |\n| `products.$.url` | String | URL of the product page |\n| `products.$.image_url` | String | Image URL of the product |\n\nHere is an example of the **Product List Viewed** event:\n\n```\nrudderanalytics.track(\"Product List Viewed\", {\n  list_id: \"list1\",\n  category: \"What's New\",\n  products: [\n    {\n      product_id: \"017c6f5d5cf86a4b22432066\",\n      sku: \"8732-98\",\n      name: \"Just Another Game\",\n      price: 22,\n      position: 2,\n      category: \"Games and Entertainment\",\n      url: \"https://www.myecommercewebsite.com/product\",\n      image_url: \"https://www.myecommercewebsite.com/product/path.jpg\"\n    },\n    {\n      product_id: \"89ac6f5d5cf86a4b64eac145\",\n      sku: \"1267-01\",\n      name: \"Wrestling Trump Cards\",\n      price: 4,\n      position: 21,\n      category: \"Card Games\"\n    }\n  ]\n});\n```\n\n## Product List Filtered\n\nThis event is triggered when a visitor filters a list or category of products on your website or app. The following properties are supported:\n\n| **Property Name** | **Type** | **Description of the Property** |\n| --- | --- | --- |\n| `list_id` | String | Name of the product list being viewed |\n| `category` | String | Name of the product category being viewed |\n| `filters` | Array | Product filters that the customer has applied |\n| `filters.$.type` | String | ID of the filter type that the customer is using |\n| `filters.$.value` | String | ID of the selection chosen by the customer |\n| `sorts` | Array | Product sorting used by the customer |\n| `sorts.$.type` | String | ID of the sort type used by the customer |\n| `sorts.$.value` | String | ID of the selection-type the customer is using |\n| `products` | Array | Products displayed in the product list |\n| `products.$.product_id` | String | Product ID displayed in the product list |\n| `products.$.sku` | String | SKU of the viewed product |\n| `products.$.category` | String | Product category viewed by the customer |\n| `products.$.name` | String | Name of the product being viewed by the user |\n| `products.$.brand` | String | Brand name associated with the product |\n| `products.$.variant` | String | Name of the product variant |\n| `products.$.price` | Number | Price of the product being viewed (in USD) |\n| `products.$.quantity` | Number | Quantity of a product |\n| `products.$.coupon` | String | Coupon code associated with a product |\n| `products.$.position` | Number | Position of the product in the product list |\n| `products.$.url` | String | URL of the product page |\n| `products.$.image_url` | String | Image URL of the product |\n\nAn example of the **Product List Filtered** event is as shown:\n\n```\nrudderanalytics.track(\"Product List Filtered\", {\n  list_id: \"dealoftheday\",\n  filters: [\n    {\n      type: \"department\",\n      value: \"health\",\n    },\n    {\n      type: \"price\",\n      value: \"under-$75\",\n    },\n  ],\n  sorts: [\n    {\n      type: \"price\",\n      value: \"asc\",\n    },\n  ],\n  products: [\n    {\n      product_id: \"5556ed1b1cf49eb378a32009\",\n      sku: \"4594-58\",\n      name: \"Whey Protein\",\n      price: 55.45,\n      position: 1,\n      category: \"health\",\n      url: \"https://www.myecommercewebsite.com/product/product1123\",\n      image_url: \"https://www.example.com/product/1123.jpg\",\n    },\n    {\n      product_id: \"9281bb1e0af05af308a32009\",\n      sku: \"0966-22\",\n      name: \"Boost\",\n      price: 47.85,\n      position: 12,\n      category: \"health\",\n    },\n  ],\n})\n```\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Browsing | RudderStack Docs",
    "description": "Understand how ecommerce browsing events work in RudderStack.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/api/profiles-api/",
    "markdown": "# Profiles API | RudderStack Docs\n\nRun your Profiles project programmatically and check its run status.\n\nAvailable Plans\n\n*   enterprise\n\n* * *\n\n*     2 minute read  \n    \n\nYou can use the Profiles API to programmatically run your Profiles project and check its run status.\n\n## Prerequisites\n\n*   Set up a Profiles project in the [RudderStack dashboard](https://app.rudderstack.com/).\n*   Generate a [Personal access token](https://www.rudderstack.com/docs/dashboard-guides/personal-access-token/#generate-personal-access-token) with read-write access.\n\n## Authentication\n\nThe Profiles API uses [Bearer authentication](https://swagger.io/docs/specification/authentication/bearer-authentication/) in the following format:\n\n```\nAuthorization: Bearer <PERSONAL_ACCESS_TOKEN>\n```\n\n## Base URL\n\nUse the base URL for your API requests depending on your region:\n\n```\nhttps://api.rudderstack.com/v2\n```\n\n```\nhttps://api.eu.rudderstack.com/v2\n```\n\n## Run project\n\nYou can trigger the run of a Profiles project using the below endpoint:\n\nPOST\n\n/sources/<sourceID>/start\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> To obtain the source ID, go to your project in the RudderStack dashboard and note it down from the URL:\n> \n> ![](https://www.rudderstack.com/docs/images/api/source-id.webp)\n\n**Path parameters**\n\nString\n\nID of the source project for which you want to trigger a run.\n\n* * *\n\n**Request body**\n\nString\n\nBearer token for authorization\n\n**Example request**\n\n```\nPOST /v2/sources/<source_id>/start HTTP/1.1\nHost: api.rudderstack.com\nContent-Type: application/json\nAccept: application/json\nAuthorization: Bearer <token>\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/sources/<source_id>/start' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header 'Authorization: Bearer <token>'\n```\n\n**Example response**\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Run started for the Profiles project. RudderStack also returns a run ID for the project. |\n| 409 | Profiles project is already running for the specified source ID. |\n\n## Get run status\n\nYou can get the run status of your Profiles project using the below endpoint:\n\nGET\n\n/sources/{sourceId}/runs/{runId}/status\n\n**Path parameters**\n\nString\n\nID of the source project for which you want to trigger a run.\n\nString\n\nID of the Profiles project’s run.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> You can obtain the `runId` as the response of the [above API endpoint](#run-project) (`/sources/<sourceID>/start`).\n\n**Example request**\n\n```\nGET /v2/sources/<source_id>/runs/{run_id}/status HTTP/1.1\nHost: api.rudderstack.com\nAccept: application/json\nAuthorization: Bearer <token>\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/sources/<source_id>/runs/<run_id>/status' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header 'Authorization: Bearer <token>'\n```\n\n**Example response**\n\n```\n{\n  \"jobId\": \"string\",\n  \"jobRunId\": \"string\",\n  \"status\": \"string\",\n  \"startedAt\": \"2024-05-31T06:48:08.228Z\",\n  \"finishedAt\": \"2024-05-31T06:48:08.228Z\",\n  \"tasks\": [{\n    \"taskId\": \"string\",\n    \"taskRunId\": \"string\",\n    \"startedAt\": \"2024-05-31T06:48:08.228Z\",\n    \"finishedAt\": \"2024-05-31T06:48:08.228Z\"\n  }]\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Successfully retrieved the run status of the project. |\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)\n\n  \n\nThis site uses cookies to improve your experience. If you want to learn more about cookies and why we use them, visit our [cookie policy.](https://rudderstack.com/cookie-policy) We'll assume you're ok with this, but you can opt-out if you wish",
    "title": "Profiles API | RudderStack Docs",
    "description": "Run your Profiles project programmatically and check its run status.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/api/pixel-api-spec/",
    "markdown": "# Pixel API | RudderStack Docs\n\nRoute event data to your desired destination with our Pixel API.\n\n* * *\n\n*     2 minute read  \n    \n\nThe RudderStack Pixel API allows you to track your customer event data from anywhere and route it to your desired destinations.\n\nThis API is very useful in scenarios where making a POST request is not possible. Some examples include tracking email addresses and page views where POST requests don’t add or append any value.\n\n## Sending a `page` call to RudderStack\n\n| API Method | Base Path |\n| --- | --- |\n| `GET` | `/pixel/v1/page` |\n\n| Required parameters | Type | Location |\n| --- | --- | --- |\n| `writeKey=${writeKey}` | `string` | `query` |\n| `anonymousId=${anonymousId}` | `string` | `query` |\n\n| Optional parameters | Type | Location |\n| --- | --- | --- |\n| `userId=${userId}` | `string` | `query` |\n| `name=${page_name}` | `string` | `query` |\n| `context.library.name` | `string` | `query` |\n| `context.library.version` | `string` | `query` |\n| `context.platform` | `string` | `query` |\n| `context.locale` | `string` | `query` |\n| `context.userAgent` | `string` | `query` |\n| `context.screen.width` | `string` | `query` |\n| `context.screen.height` | `string` | `query` |\n| `context.page.path` | `string` | `query` |\n| `context.page.url` | `string` | `query` |\n| `context.page.referrer` | `string` | `query` |\n| `context.page.title` | `string` | `query` |\n| `properties.<*key1*>=${value}` | `string` | `query` |\n| `properties.<*key2*>=${value}` | `string` | `query` |\n\n| Parameter | Type | Location | Required |\n| --- | --- | --- | --- |\n| `anonymousId` | `string` | `query` | `true` |\n| `userId` | `string` | `query` | `false` |\n| `name` | `string` | `query` | `false` |\n\n| Response | Content | Type |\n| --- | --- | --- |\n| `200` | `OK` | Success |\n| `400 Bad Request` | `error string` | Error |\n\n**Example call**:\n\n```\nhttps://hosted.rudderlabs.com/pixel/v1/page?writeKey=${writeKey}&context.library.name=Rudderstack AMP SDK&context.library.version=1.0.0&context.platform=AMP&anonymousId=${anonymousId}&context.locale=${browserLanguage}&context.userAgent=${userAgent}&context.page.path=${canonicalPath}&context.page.url=${canonicalUrl}&context.page.referrer=${documentReferrer}&context.page.title=${title}&context.screen.width=${screenWidth}&context.screen.height=${screenHeight}&properties.path=${canonicalPath}&properties.url=${canonicalUrl}&properties.referrer=${documentReferrer}&properties.title=${title}&name=${pageName}\n```\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> For this endpoint, RudderStack expects that the basic page view properties like `path`, `url`, `referrer`, `title` be passed either with `context.page.<page_basic_properties>` or with `properties.<page_basic_properties>`.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The dot (`.`) separated query parameters are mapped by RudderStack to a familiar [page](https://www.rudderstack.com/docs/api/http-api/#71-sample-payload) payload before sending them to the destinations.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Note that for this endpoint, RudderStack does not currently support overriding the `integration` key for sending data to selective destinations.\n\n## Sending a `track` call to RudderStack\n\n| API Method | Base Path |\n| --- | --- |\n| `GET` | `/pixel/v1/track` |\n\n| Required parameters | Type | Location |\n| --- | --- | --- |\n| `writeKey=${writeKey}` | `string` | `query` |\n| `anonymousId=${anonymousId}` | `string` | `query` |\n| `event=${event_name}` | `string` | `query` |\n\n| Optional parameters | Type | Location |\n| --- | --- | --- |\n| `userId=${userId}` | `string` | `query` |\n| `name=${page_name}` | `string` | `query` |\n| `context.library.name` | `string` | `query` |\n| `context.library.version` | `string` | `query` |\n| `context.platform` | `string` | `query` |\n| `context.locale` | `string` | `query` |\n| `context.userAgent` | `string` | `query` |\n| `context.screen.width` | `string` | `query` |\n| `context.screen.height` | `string` | `query` |\n| `context.page.path` | `string` | `query` |\n| `context.page.url` | `string` | `query` |\n| `context.page.referrer` | `string` | `query` |\n| `context.page.title` | `string` | `query` |\n| `properties.<*key1*>=${value}` | `string` | `query` |\n| `properties.<*key2*>=${value}` | `string` | `query` |\n\n| Parameter | Type | Location | Required |\n| --- | --- | --- | --- |\n| `anonymousId` | `string` | `query` | `true` |\n| `userId` | `string` | `query` | `false` |\n| `name` | `string` | `query` | `false` |\n\n| Response | Content | Type |\n| --- | --- | --- |\n| `200` | `OK` | Success |\n| `400 Bad Request` | `error string` | Error |\n\n**Example call**:\n\n```\nhttps://hosted.rudderlabs.com/pixel/v1/track?writeKey=${writeKey}&context.library.name=Rudderstack AMP SDK&context.library.version=1.0.0&context.platform=AMP&anonymousId=${anonymousId}&context.locale=${browserLanguage}&context.userAgent=${userAgent}&context.page.path=${canonicalPath}&context.page.url=${canonicalUrl}&context.page.referrer=${documentReferrer}&context.page.title=${title}&context.screen.width=${screenWidth}&context.screen.height=${screenHeight}&event=${eventName}&properties.key1=value1&properties.key2=value2\n```\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> For this endpoint, RudderStack expects the basic `page` view properties like `path`, `url`, `referrer`, and `title` to be passed with `context.page.<page_basic_properties>`. The event-related properties should be sent as `properties.<*key1*>=${value}`.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The dot (`.`) separated query parameters are mapped by RudderStack to a familiar [track](https://www.rudderstack.com/docs/event-spec/standard-events/track/) payload before being sent to destinations.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Note that for this endpoint, RudderStack currently does not support overriding the `integration` key for sending the data to selective destination.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Pixel API | RudderStack Docs",
    "description": "Route event data to your desired destination with our Pixel API.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/ecommerce-events-spec/coupons/",
    "markdown": "# Coupons | RudderStack Docs\n\nUnderstand how ecommerce coupon events work in RudderStack.\n\n* * *\n\n*     2 minute read  \n    \n\nThe following lifecycle events are associated with the key interactions that a customer has with the app or website while using discount coupons:\n\n## Coupon Entered\n\nThis event is triggered when a coupon is entered by the customer, either on a cart or during the order/transaction. The following properties are supported:\n\n| **Property Name** | **Type** | **Description of the Property** |\n| --- | --- | --- |\n| `order_id` | String | Order ID or transaction ID, if applicable |\n| `cart_id` | String | Cart ID, if applicable |\n| `coupon_id` | String | Coupon ID |\n\nHere is an example of the **Coupon Entered** event:\n\n```\nrudderanalytics.track(\"Coupon Entered\", {\n  order_id: \"26988d4c2ead000000000000\",\n  cart_id: \"349349349da27da72ad7d73bc4\",\n  coupon_id: \"earlybird10\",\n})\n```\n\n## Coupon Applied\n\nThis event is triggered when a coupon is applied to a cart or a transaction successfully. The following properties are supported:\n\n| **Property Name** | **Type** | **Description of the Property** |\n| --- | --- | --- |\n| `order_id` | String | Order ID or transaction ID, if applicable |\n| `cart_id` | String | Cart ID, if applicable |\n| `coupon_id` | String | Coupon ID |\n| `coupon_name` | String | Name of the coupon |\n| `discount` | Number | Discount amount applied from the coupon |\n\nHere is an example of the **Coupon Entered** event:\n\n```\nrudderanalytics.track(\"Coupon Applied\", {\n      order_id: \"26988d4c2ead000000000000\",\n      cart_id: \"349349349da27da72ad7d73bc4\"\n      coupon_id: \"earlybird10\",\n      coupon_name: \"Early Bird $10 Discount\",\n      discount: 10.00\n    });\n```\n\n## Coupon Denied\n\nThis event is triggered when an invalid coupon code is applied to a cart or a transaction. The following properties are supported:\n\n| **Property Name** | **Type** | **Description of the Property** |\n| --- | --- | --- |\n| `order_id` | String | Order ID or transaction ID, if applicable |\n| `cart_id` | String | Cart ID, if applicable |\n| `coupon_id` | String | Coupon ID |\n| `coupon_name` | String | Name of the coupon |\n| `reason` | String | Reason why the coupon was declined |\n\nHere is an example of the **Coupon Denied** event:\n\n```\nrudderanalytics.track(\"Coupon Denied\", {\n      order_id: \"26988d4c2ead000000000000\",\n      cart_id: \"349349349da27da72ad7d73bc4\"\n      coupon_id: \"earlybird10\",\n      reason: \"Coupon expired\"\n    });\n```\n\n## Coupon Removed\n\nThis event is triggered when a customer removes an already applied coupon from a cart or transaction. The following properties are supported:\n\n| **Property Name** | **Type** | **Description of the Property** |\n| --- | --- | --- |\n| `order_id` | String | Order ID or transaction ID, if applicable |\n| `cart_id` | String | Cart ID, if applicable |\n| `coupon_id` | String | Coupon ID |\n| `coupon_name` | String | Name of the coupon |\n| `discount` | Number | Discount amount applied from the coupon |\n\nHere is an example of the **Coupon Removed** event:\n\n```\nrudderanalytics.track(\"Coupon Removed\", {\n  order_id: \"26988d4c2ead000000000000\",\n  cart_id: \"349349349da27da72ad7d73bc4\"\n  coupon_id: \"earlybird10\",\n  coupon_name: \"Early Bird $10 Discount\",\n  discount: 10.00\n});\n```\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Coupons | RudderStack Docs",
    "description": "Understand how ecommerce coupon events work in RudderStack.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/api/test-api/",
    "markdown": "# Test API | RudderStack Docs\n\nUse the RudderStack Test API to verify the event workflow for your configured sources and destinations.\n\n* * *\n\n*     11 minute read  \n    \n\nThe **RudderStack Test API** offers two endpoints to verify successful event transformation and delivery for a given source-destination setup, without having to refer to the [Live Events](https://www.rudderstack.com/docs/dashboard-guides/live-events/) tab.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> The Test API is currently not supported for **Open-source RudderStack**.\n> \n> Also, some destinations like Apache Kafka, Google Pub/Sub, Google Sheets, etc. are not supported by this API. For the complete list, refer to the [FAQ](#faq) section below.\n\nThis guide details the various endpoints of the Test API.\n\n## Prerequisites\n\nThe following prerequisites must be met to use the Test API successfully:\n\n*   Set up a source-destination connection in RudderStack. For more details, refer to [Quickstart](https://www.rudderstack.com/docs/data-pipelines/event-stream/quickstart/) guide.\n    \n*   Generate a [Personal Access Token](https://www.rudderstack.com/docs/dashboard-guides/personal-access-token/) in the RudderStack dashboard to authenticate the API successfully.\n    \n\nThe Test API uses **Basic Authentication** for authenticating all requests.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> Basic Authentication concatenates the username and password with a colon (`:`) in between and encodes it using Base64 encryption. All the popular HTTP clients (for example, CURL, Postman, HTTPie) have default support for Basic Authentication.\n\nThe Basic Authentication for this API requires a username and password, where:\n\n*   The username is the **email address** you used to sign up for RudderStack.\n*   The password is the **personal access token** generated previously.\n\nFor example, if the email address is `name@surname.com` and the personal access token is `1zl4GJkLu0HsBdrDK88NgYZzY2E`, your request must have the following HTTP header:\n\n```\nAuthorization: Basic bmFtZUBzdXJuYW1lLmNvbToxemw0R0prTHUwSHNCZHJESzg4TmdZWnpZMkU=\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> In case of the **Invalid Authorization Header** error, verify if the email address and the personal access token are valid.\n\n## Base URL\n\nUse the base URL for your API requests depending on your region:\n\n```\nhttps://api.rudderstack.com\n```\n\n```\nhttps://api.eu.rudderstack.com\n```\n\n## Verifying destination events\n\nThis request verifies if the test events are successfully transformed and delivered to the specified destination.\n\n*   **Request Type**: **POST**\n    \n*   **Request Format**:\n    \n\n```\nhttps://api.rudderstack.com/v0/testDestination/<destination_ID>\n```\n\nHere, `<destination_ID>` should be replaced with the ID associated with the destination configured on the dashboard:\n\n[![Destination ID](https://www.rudderstack.com/docs/images/test-api-1.webp)](https://www.rudderstack.com/docs/images/test-api-1.webp)\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The `/testDestination` endpoint **does not require** a source to be connected to the destination.\n\n*   **Request body**:\n\n```\n{\n  \"stage\": {\n    \"user_transform\": true,\n    \"dest_transform\": true,\n    \"send_to_destination\": true\n  },\n  \"message\": {\n    // RudderStack HTTP Payload (identify, track, etc.)\n  }\n}\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> To learn more about the `stage` object, refer to the [Verification stages](#verification-stages) section below.\n\n*   **Sample payload**:\n\n```\n{\n  \"message\": {\n    \"context\": {\n      \"traits\": {\n        \"firstName\": \"James\",\n        \"lastName\": \"Doe\"\n      }\n    },\n    \"type\": \"identify\",\n    \"userId\": \"abc@123.com\"\n  }\n}\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> For more information on the message `type`, refer to the [Supported message types](#supported-message-types) section below.\n\n*   **Sample request**:\n\n```\ncurl --location --request POST 'https://api.rudderstack.com/v0/testDestination/1zl4i0J8M8T7sozoLnueW46RVYe' \\\n--header 'Authorization: Basic c2FuZGh5YSs5ODdAcnVkZGVyc3RhY2suY29tOjF6bDRzOUt2NkducjVhRkhZV1E3RUg3Z2dwTA==' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"message\": {\n        \"context\": {\n            \"traits\": {\n                \"firstName\": \"James\",\n                \"lastName\": \"Doe\"\n            }\n        },\n        \"type\": \"identify\",\n        \"userId\": \"abc@123.com\"\n    },\n    \"stage\": {\n        \"user_transform\": true,\n        \"dest_transform\": true,\n        \"send_to_destination\": true\n    }\n}'\n```\n\n*   **Expected response**:\n\n```\n{\n  \"destinationId\": \"1zl4i0J8M8T7sozoLnueW46RVYe\",\n  \"destination\": \"WEBHOOK\",\n  \"destinationName\": \"test-webhook-dest\",\n  \"data\": [{\n    \"user_transformed_payload\": {\n      \"error\": \"Transformation VersionID not found\"\n    },\n    \"dest_transformed_payload\": [{\n      \"version\": \"1\",\n      \"type\": \"REST\",\n      \"method\": \"POST\",\n      \"endpoint\": \"https://webhook.site/9d5e3e43-6c2b-4b84-be9f-0147347b4cdf\",\n      \"headers\": {\n        \"content-type\": \"application/json\"\n      },\n      \"params\": {},\n      \"body\": {\n        \"JSON\": {\n          \"context\": {\n            \"traits\": {\n              \"firstName\": \"James\",\n              \"lastName\": \"Doe\"\n            }\n          },\n          \"type\": \"identify\",\n          \"userId\": \"abc@123.com\"\n        },\n        \"JSON_ARRAY\": {},\n        \"XML\": {},\n        \"FORM\": {}\n      },\n      \"files\": {}\n    }],\n    \"destination_response\": [{\n      \"success\": false,\n      \"error\": {\n        \"message\": \"Token not found\",\n        \"id\": null\n      }\n    }],\n    \"destination_response_status\": [\n      404\n    ]\n  }]\n}\n```\n\n### Verifying events for disabled destinations\n\nIf the `/testDestination` endpoint is used to verify the events sent to a disabled destination, the API will return the following response:\n\n```\n{\n  \"destinationId\": \"<destination_ID>\",\n  \"destinationName\": \"<destination_name>\",\n  \"error\": \"Destination with id <destination_ID> is disabled\"\n}\n```\n\nA sample response highlighting the above error is shown below:\n\n```\n{\n  \"destinationId\": \"1zl4i0J8M8T7sozoLnueW46RVYe\",\n  \"destinationName\": \"test-webhook-dest\",\n  \"error\": \"Destination with id 1zl4i0J8M8T7sozoLnueW46RVYe is disabled\"\n}\n```\n\nTo override this behavior and send the event to a disabled destination, you can call the `/testDestination` endpoint with the query parameter `force=true`:\n\n```\nhttps://api.rudderstack.com/v0/testDestination/<destination_ID>?force=true\n```\n\n### Overriding existing destination configuration\n\nYou can also leverage the `/testDestination` endpoint to send your destination configuration as a part of the HTTP request body. This configuration overrides the existing destination configuration in RudderStack.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> To use this feature, you must have set up the destination in RudderStack.\n\nA sample request body highlighting this feature is shown below:\n\n```\n{\n  \"stage\": {\n    \"user_transform\": true,\n    \"dest_transform\": true,\n    \"send_to_destination\": true\n  },\n  \"message\": {\n    // RudderStack HTTP Payload (identify, track, etc.)\n  },\n  \"destinationConfig\": {\n        \"webhookUrl\": \"<webhook_URL>\"\n    }\n}\n```\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> The `destinationConfig` field can be passed only for the `testDestination` endpoint.\n\n#### Getting the destination definition variables\n\nTo override the destination configuration using the `/testDestination` endpoint, you need to know the configuration variables to use within `destinationConfig`. To get these variables, use the **`destination-definitions`** endpoint. The request format is listed below:\n\n*   **Request Type**: **GET**\n    \n*   **Request Format**:\n    \n\n```\nhttps://api.rudderstack.com/destination-definitions\n```\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> This endpoint does not require any authentication.\n\nOnce you run this endpoint, you should be able to view all variable names within the `defaultConfig` parameter of that destination, as seen below:\n\n[![Configuration variables](https://www.rudderstack.com/docs/images/test-api-3.webp)](https://www.rudderstack.com/docs/images/test-api-3.webp)\n\nAs seen in the above example, for the webhook destination, the configuration variables are `webhookUrl`, `webhookMethod`, and `headers`. These correspond to the webhook destination settings as seen in the RudderStack dashboard below:\n\n[![Dashboard settings](https://www.rudderstack.com/docs/images/test-api-4.webp)](https://www.rudderstack.com/docs/images/test-api-4.webp)\n\nTo override the dashboard settings, provide the new values for the destination configuration variables in the request body of the `/testDestination` endpoint as seen in the [Overriding existing destination configuration](https://www.rudderstack.com/docs/api/test-api/#overriding-existing-destination-configuration) section above.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> For a detailed use-case on how to use this feature, refer to the [FAQ](#faq) section below.\n\n## Verifying source events\n\nThis request verifies if the test events are successfully sent from the specified source and delivered to all connected destinations.\n\n*   **Request Type**: **POST**\n    \n*   **Request Format**:\n    \n\n```\nhttps://api.rudderstack.com/v0/testSource/<source_ID>\n```\n\nHere, `<source_ID>` should be replaced with the ID associated with the source configured on the dashboard:\n\n[![Source ID](https://www.rudderstack.com/docs/images/test-api-2.webp)](https://www.rudderstack.com/docs/images/test-api-2.webp)\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The `/testSource` endpoint requires the specified source to be connected to at least one destination.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> The `/testSource` endpoint essentially calls the `/testDestination` endpoint for each destination connected to that source and returns an array of responses.\n\n*   **Request body**:\n\n```\n{\n  \"stage\": {\n    \"user_transform\": true,\n    \"dest_transform\": true,\n    \"send_to_destination\": true\n  },\n  \"message\": {\n    // RudderStack HTTP Payload (identify, track, etc.)\n  }\n}\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> To learn more about the `stage` object, refer to the **Verification stages** section below.\n\n*   **Sample payload**:\n\n```\n{\n  \"message\": {\n    \"context\": {\n      \"traits\": {\n        \"firstName\": \"James\",\n        \"lastName\": \"Doe\"\n      }\n    },\n    \"type\": \"identify\",\n    \"userId\": \"abc@123.com\"\n  }\n}\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> For more information on the message `type`, refer to the [Supported message types](#supported-message-types) section below.\n\n*   **Sample request**:\n\n```\ncurl --location --request POST 'https://api.rudderstack.com/v0/testSource/1zlmsBMe1dcPbu3u6NTZFUFBrNQ' \\\n--header 'Authorization: Basic c2FuZGh5YSs5ODdAcnVkZGVyc3RhY2suY29tOjF6bDRzOUt2NkducjVhRkhZV1E3RUg3Z2dwTA==' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"message\": {\n        \"context\": {\n            \"traits\": {\n                \"firstName\": \"James\",\n                \"lastName\": \"Doe\"\n            }\n        },\n        \"type\": \"identify\",\n        \"userId\": \"abc@123.com\"\n    },\n    \"stage\": {\n        \"user_transform\": true,\n        \"dest_transform\": true,\n        \"send_to_destination\": true\n    }\n}'\n```\n\n*   **Expected response**:\n\n```\n[{\n    \"destinationId\": \"1tIgXcaRnQDlBBtxlJMGGHFUWGb\",\n    \"destinationName\": \"salesforce\",\n    \"error\": \"Destination with id 1tIgXcaRnQDlBBtxlJMGGHFUWGb is disabled\"\n  },\n  {\n    \"destinationId\": \"1zl4i0J8M8T7sozoLnueW46RVYe\",\n    \"destination\": \"WEBHOOK\",\n    \"destinationName\": \"test-webhook-dest\",\n    \"data\": [{\n      \"user_transformed_payload\": {\n        \"error\": \"Transformation VersionID not found\"\n      },\n      \"dest_transformed_payload\": [{\n        \"version\": \"1\",\n        \"type\": \"REST\",\n        \"method\": \"POST\",\n        \"endpoint\": \"https://webhook.site/9d5e3e43-6c2b-4b84-be9f-0147347b4cdf\",\n        \"headers\": {\n          \"content-type\": \"application/json\"\n        },\n        \"params\": {},\n        \"body\": {\n          \"JSON\": {\n            \"context\": {\n              \"traits\": {\n                \"firstName\": \"James\",\n                \"lastName\": \"Doe\"\n              }\n            },\n            \"type\": \"identify\",\n            \"userId\": \"abc@123.com\"\n          },\n          \"JSON_ARRAY\": {},\n          \"XML\": {},\n          \"FORM\": {}\n        },\n        \"files\": {}\n      }],\n      \"destination_response\": [{\n        \"success\": false,\n        \"error\": {\n          \"message\": \"Token not found\",\n          \"id\": null\n        }\n      }],\n      \"destination_response_status\": [\n        404\n      ]\n    }]\n  },\n  {\n    \"destinationId\": \"1tKpO0kantcKjd5czXVD1cdwUBE\",\n    \"destination\": \"MARKETO\",\n    \"destinationName\": \"Marketo\",\n    \"data\": [{\n      \"user_transformed_payload\": {\n        \"error\": \"Transformation VersionID not found\"\n      },\n      \"dest_transformed_payload\": [{\n        \"version\": \"1\",\n        \"type\": \"REST\",\n        \"method\": \"POST\",\n        \"endpoint\": \"https://585-AXP-425.mktorest.com/rest/v1/leads.json\",\n        \"headers\": {\n          \"Authorization\": \"Bearer f96f0384-583b-4718-b8a3-38aaed4bc5ae:ab\",\n          \"Content-Type\": \"application/json\"\n        },\n        \"params\": {},\n        \"body\": {\n          \"JSON\": {\n            \"action\": \"createOrUpdate\",\n            \"input\": [{\n              \"FirstName\": \"James\",\n              \"LastName\": \"Doe\",\n              \"lastName\": \"Doe\",\n              \"firstName\": \"James\",\n              \"id\": 1328262,\n              \"userId\": \"abc@123.com\"\n            }],\n            \"lookupField\": \"id\"\n          },\n          \"JSON_ARRAY\": {},\n          \"XML\": {},\n          \"FORM\": {}\n        },\n        \"files\": {}\n      }],\n      \"destination_response\": [{\n        \"requestId\": \"555d#17d31b0a392\",\n        \"result\": [{\n          \"id\": 1328262,\n          \"status\": \"updated\"\n        }],\n        \"success\": true\n      }],\n      \"destination_response_status\": [\n        200\n      ]\n    }]\n  }\n]\n```\n\nThe above response indicates that the source with the source ID `1zlmsBMe1dcPbu3u6NTZFUFBrNQ` is connected to three destinations:\n\n*   Salesforce, a disabled destination\n*   Webhook, with no transformation specified in the dashboard, and\n*   Marketo\n\n### Verifying events from a disabled source\n\nIf the `/testSource` endpoint is used to verify the events sent from a disabled source, the API will send the following response:\n\n```\n{\n  \"message\": \"Source with <source_ID> is disabled\"\n}\n```\n\nTo override this behavior and send the event from a disabled source to all connected destinations, you can call the `/testSource` endpoint with the query parameter `force=true`:\n\n```\nhttps://api.rudderstack.com/v0/testSource/<source_ID>?force=true\n```\n\n### Verifying events for disabled destinations\n\nIf the `/testSource` endpoint is used to verify the events sent to a disabled destination, the API will send the following response:\n\n```\n{\n  \"destinationId\": \"<destination_ID>\",\n  \"destinationName\": \"<destination_name>\",\n  \"error\": \"Destination with id <destination_ID> is disabled\"\n}\n```\n\nTo override this behavior and send the event to a disabled destination, you can call the `/testSource` endpoint with the query parameter `force=true`:\n\n```\nhttps://api.rudderstack.com/v0/testSource/<source_ID>?force=true\n```\n\n## Verification stages\n\nThe request body for the `testDestination` and `testSource` endpoints of this API is as shown:\n\n```\n{\n  \"stage\": {\n    \"user_transform\": true,\n    \"dest_transform\": true,\n    \"send_to_destination\": true\n  },\n  \"message\": {\n    // RudderStack HTTP Payload (identify, track, etc.)\n  }\n}\n```\n\nHere, `stage` essentially defines the different stages enabled in the pipeline through which the API verifies the event payload. These stages are:\n\n*   `user_transform`\n*   `dest_transform`\n*   `send_to_destination`\n\nThe following sections define each of these stages in detail.\n\n### `user_transform`\n\nIf `user_transform` is set to `true`, the API checks if a user transformation is connected to a destination and returns the transformed event as a response. If set to `false`, the API skips this stage completely and moves to the next stage (`dest_transform`).\n\nNote the following:\n\n*   Suppose you set `user_transform` to `true`, but no user transformation is specified while configuring the destination in the dashboard. In this case, the API returns the following response before skipping to the next stage:\n\n```\n\"user_transformed_payload\": {\n  \"error\": \"Transformation VersionID not found\"\n}\n```\n\n*   If an error occurs while applying the transformation to the payload, the API returns an error, and the next stages are aborted.\n\nA sample API response is shown below:\n\n```\n[{\n  \"data\": [{\n    \"user_transformed_payload\": {\n      \"error\": \"Error: Error.\"\n    },\n    \"dest_transformed_payload\": {\n      \"error\": \"error encountered in user_transformation stage. Aborting.\"\n    },\n    \"destination_response\": {\n      \"error\": \"error encountered in dest_transformation stage. Aborting.\"\n    }\n  }]\n}]\n```\n\n### `dest_transform`\n\nIf `dest_transform` is set to `true`, the API returns the transformer response. This response shows the payload after it has been transformed into a destination-specific format.\n\nA sample API response when `dest_transform` is set to `true` is shown below:\n\n```\n\"dest_transformed_payload\": [{\n  \"version\": \"1\",\n  \"type\": \"REST\",\n  \"method\": \"POST\",\n  \"endpoint\": \"https://webhook.site/9d5e3e43-6c2b-4b84-be9f-0147347b4cdf\",\n  \"headers\": {\n    \"content-type\": \"application/json\"\n  },\n  \"params\": {},\n  \"body\": {\n    \"JSON\": {\n      \"context\": {\n        \"traits\": {\n          \"firstName\": \"James\",\n          \"lastName\": \"Doe\"\n        }\n      },\n      \"type\": \"identify\",\n      \"userId\": \"abc@123.com\"\n    },\n    \"XML\": {},\n    \"FORM\": {}\n  },\n  \"files\": {}\n}]\n```\n\n### `send_to_destination`\n\nWhen `send_to_destination` is set to `true`, the event is sent to the destination and the API returns the response. If set to `false`, this stage is skipped completely.\n\nA sample API response when `send_to_destination` is set to `true` is shown below:\n\n```\n\"destination_response\": [{\n  \"status\": \"success\",\n  \"processed\": 1,\n  \"unprocessed\": []\n}],\n\"destination_response_status\": [200]\n```\n\n## Supported message types\n\nThe Test API supports the following message `type`:\n\n*   `identify`\n*   `track`\n*   `page`\n*   `screen`\n*   `group`\n*   `alias`\n\nIf you specify any other message `type` apart from the supported events mentioned in the above list, you will get the following error:\n\n```\n{\n    \"message\": \"message type is unsupported\"\n}\n```\n\nYou will get the following error message if no message `type` is specified in the payload, or if `type` is not a string:\n\n```\n{\n    \"message\": \"message type missing or invalid\"\n}\n```\n\n## FAQ\n\n#### Which destinations are not supported by the Test API?\n\nThe Test API does not support the destinations that leverage the [rudder-server](https://github.com/rudderlabs/rudder-server) to send the test events. These destinations include:\n\n*   [Amazon Kinesis](https://www.rudderstack.com/docs/destinations/streaming-destinations/amazon-kinesis/)\n*   [Apache Kafka](https://www.rudderstack.com/docs/destinations/streaming-destinations/kafka/)\n*   [Azure Event Hub](https://www.rudderstack.com/docs/destinations/streaming-destinations/azure-event-hubs/)\n*   [Amazon Kinesis Firehose](https://www.rudderstack.com/docs/destinations/streaming-destinations/amazon-kinesis-firehose/)\n*   [Amazon EventBridge](https://www.rudderstack.com/docs/destinations/streaming-destinations/amazon-eventbridge/)\n*   [Amazon Personalize](https://www.rudderstack.com/docs/destinations/streaming-destinations/aws-personalize/)\n*   [Confluent Cloud](https://www.rudderstack.com/docs/destinations/streaming-destinations/confluent-cloud/)\n*   [Google Pub/Sub](https://www.rudderstack.com/docs/destinations/streaming-destinations/google-pub-sub/)\n*   [Google Sheets](https://www.rudderstack.com/docs/destinations/streaming-destinations/google-sheets/)\n*   [Redis](https://www.rudderstack.com/docs/destinations/streaming-destinations/redis/)\n*   [BigQuery Stream](https://www.rudderstack.com/docs/destinations/streaming-destinations/bigquery-stream/)\n*   [Amazon S3](https://www.rudderstack.com/docs/destinations/streaming-destinations/amazon-s3/)\n*   [Azure Blob Storage](https://www.rudderstack.com/docs/destinations/streaming-destinations/microsoft-azure-blob-storage/)\n*   [DigitalOcean Spaces](https://www.rudderstack.com/docs/destinations/streaming-destinations/digitalocean-spaces/)\n*   [Google Cloud Storage](https://www.rudderstack.com/docs/destinations/streaming-destinations/google-cloud-storage/)\n*   [MinIO](https://www.rudderstack.com/docs/destinations/streaming-destinations/minio/)\n\n#### What happens if `type` is not included in the event payload?\n\nSimply put, `type` refers to the event type in the payload.\n\n*   If `type` is missing in the event payload, the API will return the following error:\n\n```\n{\n    \"message\": \"message type missing or invalid\"\n}\n```\n\n*   If you set `type` to any value other than `identify`, `track`, `page`, `screen`, `group`, or `alias`, the API will return the following error:\n\n```\n{\n    \"message\": \"message type is unsupported\"\n}\n```\n\nFor more information, refer to the [supported message types](#supported-message-types) section above.\n\n#### Can I disable a particular verification stage in the `stage` object?\n\nThe request body for the `testDestination` and `testSource` includes the `stage` object, which is defined as follows:\n\n```\n{\n  \"stage\": {\n    \"user_transform\": true,\n    \"dest_transform\": true,\n    \"send_to_destination\": true\n  }\n```\n\nThe `stage` object defines the different stages enabled in the pipeline through which the API verifies the event payload. These stages are:\n\n*   `user_transform`\n*   `dest_transform`\n*   `send_to_destination`\n\nTo disable or a specific verification stage, you can set the value of that parameter to be `false`. For example, if you don’t want the API to check if a user transformation is applied to the event payload, you can set `user_transform` to false:\n\n```\n{\n  \"stage\": {\n    \"user_transform\": false,\n    \"dest_transform\": true,\n    \"send_to_destination\": true\n  }\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Refer to the [Verification stages](#verification-stages) section above for more information on each of the `stage` object parameters.\n\n#### Can I override the destination settings specified in the RudderStack dashboard using this API?\n\nYes, you can.\n\nSuppose you have configured a webhook destination in the RudderStack dashboard with the following settings:\n\n[![Dashboard settings for webhook destination](https://www.rudderstack.com/docs/images/test-api-5.webp)](https://www.rudderstack.com/docs/images/test-api-5.webp)\n\nYou can leverage the [`/testDestination`](#verifying-destination-events) endpoint to send the new configuration as a part of the HTTP request body. This configuration overrides the existing destination settings configured in RudderStack.\n\nYour HTTP request body should look like the following:\n\n```\n{\n  \"stage\": {\n    \"user_transform\": true,\n    \"dest_transform\": true,\n    \"send_to_destination\": true\n  },\n  \"message\": {\n    // RudderStack HTTP Payload (identify, track, etc.)\n  },\n  \"destinationConfig\": {\n        \"webhookUrl\": <webhook_URL>,\n        \"webhookMethod\": <new_webhook_method>\n    }\n}\n```\n\nTo get the variable names to use in `destinationConfig`, run the following **GET** request:\n\n```\nhttps://api.rudderstack.com/destination-definitions\n```\n\nNext, look for the webhook destination and the corresponding configuration variables for it under `defaultConfig`:\n\n[![Configuration variables](https://www.rudderstack.com/docs/images/test-api-3.webp)](https://www.rudderstack.com/docs/images/test-api-3.webp)\n\nFinally, specify the new configuration value for the required variables and run the request. For instance, the new `webhookUrl` and `webhookMethod` values will replace the existing settings configured in the RudderStack dashboard.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Test API | RudderStack Docs",
    "description": "Use the RudderStack Test API to verify the event workflow for your configured sources and destinations.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/ecommerce-events-spec/promotions/",
    "markdown": "# Promotions | RudderStack Docs\n\nPrivacy Overview\n\nThis site uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are as essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.\n\nNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.",
    "title": "Promotions | RudderStack Docs",
    "description": "Understand how ecommerce promotion events work in RudderStack.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/api/retl-connections-api/",
    "markdown": "# Reverse ETL Connections API | RudderStack Docs\n\nProgrammatically run syncs for a Reverse ETL connection.\n\n* * *\n\n*     5 minute read  \n    \n\nThe Reverse ETL Connections API lets you programmatically run syncs for your Reverse ETL connections.\n\nYou can use this API to:\n\n*   Trigger a new sync for a particular connection.\n*   Get details of all syncs for a connection.\n*   Stop a running sync for a connection.\n\n## Prerequisites\n\n*   Get the [connection ID](#faq) for which you want to start/stop syncs from the RudderStack dashboard.\n*   Generate a [personal access token](#faq) in the RudderStack dashboard. Note that your personal access token should have the following permissions to use the associated API endpoints:\n\n| Endpoint | Required permissions |\n| --- | --- |\n| [`/start`](#start-sync) | Read-Write, Admin |\n| [`/syncs`](#all-syncs) | Read-Only, Read-Write, Admin |\n| [`/syncs/{syncId}`](#individual-sync) | Read-Only, Read-Write, Admin |\n| [`/stop`](#cancel-sync) | Read-Write, Admin |\n\n## Authentication\n\nThe Reverse ETL Connections API uses [Bearer authentication](https://swagger.io/docs/specification/authentication/bearer-authentication/) in the following format:\n\n```\nAuthorization: Bearer <PERSONAL_ACCESS_TOKEN>\n```\n\n## Base URL\n\nUse the base URL for your API requests depending on your region:\n\n```\nhttps://api.rudderstack.com/v2\n```\n\n```\nhttps://api.eu.rudderstack.com/v2\n```\n\n## Start sync\n\nYou can start a new sync for a Reverse ETL connection using the below endpoint:\n\nPOST\n\n/retl-connections/{connectionId}/start\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Your [personal access token](#how-to-generate-a-personal-access-token-to-use-the-reverse-etl-connections-api) must have **Read-Write** or **Admin** permissions for authenticating the API to run this endpoint.\n\n**Path parameters**\n\nString\n\nConnection ID for which RudderStack starts a new sync\n\n* * *\n\n**Request body**\n\nObject\n\nSpecify the scope of sync. It can be one of the following:\n\n*   `incremental`: RudderStack syncs only the newly added data in the warehouse since the last sync.\n*   `full`: RudderStack syncs all the data irrespective of whether it was synced to the destination previously.\n\n**Example request**\n\n```\nPOST /v2/retl-connections/<connection_id>/start HTTP/1.1\nHost: api.rudderstack.com\nContent-Type: application/json\nAccept: application/json\nAuthorization: Bearer <token>\n\n{\n  \"syncType\": \"incremental\"  // Other acceptable values: full\n}\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/retl-connections/<connection_id>/start' \\\n--header 'Content-Type: application/json' \\\n--header 'Accept: application/json' \\\n--header 'Authorization: Bearer <token>' \\\n--data '{\n  \"syncType\": \"incremental\"  // Other acceptable values: full\n}'\n```\n\n**Example response**\n\n```\n{\n   “syncId”: “<sync_id>\"\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Sync started for Reverse ETL connection.<br><br>RudderStack also returns a unique ID for the newly created sync. |\n| 404 | Reverse ETL connection was not found for the specified connection ID. |\n| 409 | A Reverse ETL sync is already running for the specified connection ID. |\n\n## Get sync details\n\nUse the following endpoints to get details of [all syncs](#all-syncs) or an [individual sync](#individual-sync) for a particular Reverse ETL connection. You can also filter the results by sync status, start time, and limit the number of results per page.\n\n### All syncs\n\nGET\n\n/retl-connections/{connectionId}/syncs\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Your [personal access token](#how-to-generate-a-personal-access-token-to-use-the-reverse-etl-connections-api) must have **Read-Only**, **Read-Write** or **Admin** permissions for authenticating the API to run this endpoint.\n\n**Path parameters**\n\nString\n\nConnection ID for which RudderStack fetches the syncs details.\n\n**Query parameters**\n\nString\n\nFilter syncs by status. It accepts one of the following values - `running`, `succeeded`, and `failed`.\n\nString (datetime)\n\nFilter syncs started after the specified time (in UTC).\n\nString (datetime)\n\nFilter syncs started before the specified time (in UTC).\n\nInteger\n\nLimit the number of results shown in the page.\n\nInteger\n\nShow a particular page in the results.\n\n* * *\n\n**Example request**\n\n```\nGET /v2/retl-connections/<connection_id>/syncs?status=<status>>&started_after=<started_after_date>&started_before=<started_before_date>&per_page=<results_per_page>>&page=<page_number> HTTP/1.1\nHost: api.rudderstack.com\nAccept: application/json\nAuthorization: Bearer <token>\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/retl-connections/<connection_id>/syncs?status=<status>&started_after=<started_after_time>&started_before=<started_before_time>&per_page=<results_per_page>>&page=<page_number>' \\\n--header 'Accept: application/json' \\\n--header 'Authorization: Bearer <token>'\n```\n\n**Example response**\n\n```\n{\n  \"syncs\": [{\n    \"id\": \"<sync_id>\",\n    \"status\": \"running\",\n    \"startedAt\": \"2024-04-20T05:41:18.871Z\",\n    \"finishedAt\": \"2024-04-20T05:41:18.871Z\",\n    \"error\": \"<string>\",\n    \"metrics\": {\n      \"succeeded\": {\n        \"total\": 0\n      },\n      \"failed\": {\n        \"total\": 0\n      },\n      \"changed\": {\n        \"total\": 0\n      },\n      \"total\": 0\n    }\n  }],\n  \"paging\": {\n    \"total\": 200,\n    \"next\": \"/<collection path>?page=2\"\n  }\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | List of all Reverse ETL syncs for the specified connection ID. |\n| 404 | Reverse ETL connection was not found for the specified connection ID. |\n\n### Individual sync\n\nGET\n\n/retl-connections/{connectionId}/syncs/{syncId}\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Your [personal access token](#how-to-generate-a-personal-access-token-to-use-the-reverse-etl-connections-api) must have **Read-Only**, **Read-Write** or **Admin** permissions for authenticating the API to run this endpoint.\n\n**Path parameters**\n\nString\n\nConnection ID for which RudderStack fetches the syncs details.\n\nString\n\nID for a particular Reverse ETL sync.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> You can find the sync ID from the [`/start`](#start-sync) endpoint response.\n\n**Example request**\n\n```\nGET /v2/retl-connections/<connection_id>/syncs/<sync_id> HTTP/1.1\nHost: api.rudderstack.com\nAccept: application/json\nAuthorization: Bearer <token>\n```\n\n```\ncurl --location 'https://api.rudderstack.com/v2/retl-connections/<connection_id>/syncs/<sync_id>' \\\n--header 'Accept: application/json' \\\n--header 'Authorization: Bearer <token>'\n```\n\n**Example response**\n\n```\n{\n  \"id\": \"<sync_id>\",\n  \"status\": \"running\",\n  \"startedAt\": \"2024-04-20T05:58:14.778Z\",\n  \"finishedAt\": \"2024-04-20T05:58:14.778Z\",\n  \"error\": \"<string>\",\n  \"metrics\": {\n    \"succeeded\": {\n      \"total\": 0\n    },\n    \"failed\": {\n      \"total\": 0\n    },\n    \"changed\": {\n      \"total\": 0\n    },\n    \"total\": 0\n  }\n}\n```\n\n**Response codes**\n\n| Code | Description |\n| --- | --- |\n| 200 | Sync details for the specified connection ID and sync ID. |\n| 404 | Reverse ETL connection was not found for the specified connection ID. |\n\n## Cancel sync\n\nYou can start a new sync for a Reverse ETL connection using the below endpoint:\n\nPOST\n\n/retl-connections/{connectionId}/stop\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Your [personal access token](#how-to-generate-a-personal-access-token-to-use-the-reverse-etl-connections-api) must have **Read-Write** or **Admin** permissions for authenticating the API to run this endpoint.\n\n**Path parameters**\n\nString\n\nConnection ID for which RudderStack starts a new sync\n\n* * *\n\n**Example request**\n\n```\nPOST /v2/retl-connections/<connection_id>/stop HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Bearer <token>\n```\n\n```\ncurl --location --request POST 'https://api.rudderstack.com/v2/retl-connections/<connection_id>/stop' \\\n--header 'Authorization: Bearer <token>'\n```\n\n**Example response**\n\n| Code | Response | Description |\n| --- | --- | --- |\n| 204 | Stop was requested. | RudderStack has successfully sent a cancellation request to stop the Reverse ETL connection sync. |\n| 404 | \\-  | Reverse ETL connection was not found for the specified connection ID. |\n\n## FAQ\n\n#### **Where can I find the connection ID for a Reverse ETL connection?**\n\nGo to the **Settings** tab of the connection to get the Connection ID for a particular Reverse ETL connection:\n\n[![connection ID for Reverse ETL](https://www.rudderstack.com/docs/images/retl-sources/connection-id.webp)](https://www.rudderstack.com/docs/images/retl-sources/connection-id.webp)\n\n#### **How to generate a personal access token to use the Reverse ETL Connections API?**\n\nTo generate your [personal access token](https://www.rudderstack.com/docs/dashboard-guides/personal-access-token/), go to **Settings** > **Your Profile** > **Account** tab. Scroll down to **Personal access tokens** and click **Generate new token**.\n\n[![New personal access token in RudderStack dashboard](https://www.rudderstack.com/docs/images/rudderstack-api/personal-access-token-1.webp)](https://www.rudderstack.com/docs/images/rudderstack-api/personal-access-token-1.webp)\n\nEnter the token name and choose the required permissions from the **Role** dropdown. Note that your personal access token should have the following permissions to use the associated endpoints:\n\n| Endpoint | Required permissions |\n| --- | --- |\n| [`/start`](#start-sync) | Read-Write, Admin |\n| [`/syncs`](#all-syncs) | Read-Only, Read-Write, Admin |\n| [`/syncs/{syncId}`](#individual-sync) | Read-Only, Read-Write, Admin |\n| [`/stop`](#cancel-sync) | Read-Write, Admin |\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Reverse ETL Connections API | RudderStack Docs",
    "description": "Programmatically run syncs for a Reverse ETL connection.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/ecommerce-events-spec/ordering/",
    "markdown": "# Ordering | RudderStack Docs\n\nUnderstand how ecommerce product order events work in RudderStack.\n\n* * *\n\n*     12 minute read  \n    \n\nThese lifecycle events are associated with the key interactions that a customer has with the app or website while placing an order for a product.\n\n## Product Clicked\n\nThis event is triggered when a visitor clicks on a product. The following properties are:\n\n| **Property Name** | **Type** | **Description** |\n| --- | --- | --- |\n| `product_id` | String | Product ID of the product being viewed |\n| `sku` | String | SKU of the product |\n| `category` | String | Category of the product |\n| `name` | String | Name of the product being viewed |\n| `brand` | String | Name of the brand associated with the product |\n| `variant` | String | Variant associated with the product |\n| `price` | Number | Price of the product being viewed |\n| `quantity` | Number | Quantity of the product |\n| `coupon` | String | Coupon code associated with a product |\n| `position` | Number | Position of the product in the product list |\n| `url` | String | URL of the product page |\n| `image_url` | String | Image URL of the product |\n\nHere is an example of the **Product Clicked** event:\n\n```\nrudderanalytics.track(\"Product Clicked\", {\n  product_id: \"622c6f5d5cf86a4c77358033\",\n  sku: \"8472-998-0112\",\n  category: \"Games\",\n  name: \"Cones of Dunshire\",\n  brand: \"Wyatt Games\",\n  variant: \"expansion pack\",\n  price: 49.99,\n  quantity: 5,\n  coupon: \"PREORDER15\",\n  position: 1,\n  url: \"https://www.website.com/product/path\",\n  image_url: \"https://www.website.com/product/path.webp\",\n})\n```\n\n## Product Viewed\n\nThis event is triggered when a visitor views a product. The following properties are supported:\n\n| **Property Name** | **Type** | **Description** |\n| --- | --- | --- |\n| `product_id` | String | Product ID of the product being viewed |\n| `sku` | String | SKU of the product |\n| `category` | String | Category of the product |\n| `name` | String | Name of the product being viewed |\n| `brand` | String | Name of the brand associated with the product |\n| `variant` | String | Variant associated with the product |\n| `price` | Number | Price of the product being viewed |\n| `quantity` | Number | Quantity of the product |\n| `coupon` | String | Coupon code associated with a product |\n| `currency` | String | Currency of the transaction |\n| `position` | Number | Position of the product in the product list |\n| `url` | String | URL of the product page |\n| `image_url` | String | Image URL of the product |\n\nHere is an example of the **Product Viewed** event:\n\n```\nrudderanalytics.track(\"Product Viewed\", {\n  product_id: \"622c6f5d5cf86a4c77358033\",\n  sku: \"8472-998-0112\",\n  category: \"Games\",\n  name: \"Cones of Dunshire\",\n  brand: \"Wyatt Games\",\n  variant: \"expansion pack\",\n  price: 49.99,\n  quantity: 5,\n  coupon: \"PREORDER15\",\n  currency: \"USD\",\n  position: 1,\n  url: \"https://www.website.com/product/path\",\n  image_url: \"https://www.website.com/product/path.webp\",\n})\n```\n\n## Product Added\n\nThis event is triggered when a visitor/customer adds a product to their shopping cart. The following properties are supported by this event:\n\n| **Property Name** | **Type** | **Description** |\n| --- | --- | --- |\n| `cart_id` | String | Cart ID |\n| `product_id` | String | ID of the product being viewed |\n| `sku` | String | SKU of the product being viewed |\n| `category` | String | Category of the product being viewed |\n| `name` | String | Name of the product being viewed |\n| `brand` | String | Name of the brand associated with the product |\n| `variant` | String | Variant associated with the product |\n| `price` | Number | Price of the product being viewed |\n| `quantity` | Number | Quantity of the product |\n| `coupon` | String | Coupon code associated with the product |\n| `position` | Number | Position of the product in the product list |\n| `url` | String | URL of the product page |\n| `image_url` | String | Image URL of the product |\n\nAn example of the **Product Added** event is as shown:\n\n```\nrudderanalytics.track(\"Product Added\", {\n  product_id: \"622c6f5d5cf86a4c77358033\",\n  sku: \"8472-998-0112\",\n  category: \"Games\",\n  name: \"Cones of Dunshire\",\n  brand: \"Wyatt Games\",\n  variant: \"expansion pack\",\n  price: 49.99,\n  quantity: 5,\n  coupon: \"PREORDER15\",\n  position: 1,\n  url: \"https://www.website.com/product/path\",\n  image_url: \"https://www.website.com/product/path.webp\",\n})\n```\n\n## Product Removed\n\nThis event is triggered when a product is removed from the shopping cart by the customer. The following properties are supported:\n\n| **Property Name** | **Type** | **Description** |\n| --- | --- | --- |\n| `cart_id` | String | Cart ID |\n| `product_id` | String | Product ID of the product being viewed |\n| `sku` | String | SKU of the product being viewed |\n| `category` | String | Category of the product being viewed |\n| `name` | String | Name of the product being viewed |\n| `brand` | String | Name of the brand associated with the product |\n| `variant` | String | Variant associated with the product |\n| `price` | Number | Price of the product being viewed |\n| `quantity` | Number | Quantity of the product |\n| `coupon` | String | Coupon code associated with a product |\n| `position` | Number | Position of the product in the product list |\n| `url` | String | URL of the product page |\n| `image_url` | String | Image URL of the product |\n\nHere is an example of the **Product Removed** event:\n\n```\nrudderanalytics.track(\"Product Removed\", {\n  product_id: \"622c6f5d5cf86a4c77358033\",\n  sku: \"8472-998-0112\",\n  category: \"Games\",\n  name: \"Cones of Dunshire\",\n  brand: \"Wyatt Games\",\n  variant: \"expansion pack\",\n  price: 49.99,\n  quantity: 5,\n  coupon: \"PREORDER15\",\n  position: 1,\n  url: \"https://www.website.com/product/path\",\n  image_url: \"https://www.website.com/product/path.webp\",\n})\n```\n\n## Cart Viewed\n\nThis event is triggered whenever a visitor or customer views their shopping cart. The following properties are supported by this event:\n\n| **Property Name** | **Type** | **Description** |\n| --- | --- | --- |\n| `cart_id` | String | Cart ID |\n| `products` | Array | List of products displayed in the product list |\n| `products.$.product_id` | String | Product ID displayed on the list |\n| `products.$.sku` | String | SKU of the product being viewed |\n| `products.$.category` | String | Category of the product being viewed |\n| `products.$.name` | String | Name of the product being viewed |\n| `products.$.brand` | String | Name of the brand associated with the product |\n| `products.$.variant` | String | Variant associated with the product |\n| `products.$.price` | Number | Price of the product being viewed |\n| `products.$.quantity` | Number | Quantity of the product |\n| `products.$.coupon` | String | Coupon code associated with a product |\n| `products.$.position` | Number | Position of the product in the product list |\n| `products.$.url` | String | URL of the product page |\n| `products.$.image_url` | String | Image URL of the product |\n\nHere is an example of the **Cart Viewed** event:\n\n```\nrudderanalytics.track(\"Cart Viewed\", {\n  cart_id: \"6b2c6f5aecf86a4ae77358ae3\",\n  products: [\n    {\n      product_id: \"622c6f5d5cf86a4c77358033\",\n      sku: \"8472-998-0112\",\n      name: \"Cones of Dunshire\",\n      price: 49.99,\n      position: 5,\n      category: \"Games\",\n      url: \"https://www.website.com/product/path\",\n      image_url: \"https://www.website.com/product/path.jpg\",\n    },\n    {\n      product_id: \"577c6f5d5cf86a4c7735ba03\",\n      sku: \"3309-483-2201\",\n      name: \"Five Crowns\",\n      price: 5.99,\n      position: 2,\n      category: \"Games\",\n    },\n  ],\n})\n```\n\n## Checkout Started\n\nThis event is triggered when an order or transaction is initiated. The following properties are supported:\n\n| **Property Name** | **Type** | **Description** |\n| --- | --- | --- |\n| `order_id` | String | Order ID or transaction ID, whichever is applicable |\n| `affiliation` | String | Store or affiliation details from where the transaction occured |\n| `value` | Number | Revenue with discount and coupons factored in |\n| `revenue` | Number | Revenue associated with the transaction, excluding the shipping and tax details |\n| `shipping` | Number | Shipping cost associated with the order or transaction |\n| `tax` | Number | Total tax associated with the order or the transaction |\n| `discount` | Number | Total discount associated with the transaction |\n| `coupon` | String | Coupon redeemed with the transaction |\n| `currency` | String | Currency code associated with an order or transaction |\n| `products` | Array | List of products in the order or transaction |\n| `products.$.product_id` | String | Product ID |\n| `products.$.sku` | String | SKU of the product being viewed |\n| `products.$.category` | String | Category of the product being viewed |\n| `products.$.name` | String | Mame of the product being viewed |\n| `products.$.brand` | String | Name of the brand associated with the product |\n| `products.$.variant` | String | Variant associated with the product |\n| `products.$.price` | Number | Price of the product being viewed |\n| `products.$.quantity` | Number | Quantity of the product |\n| `products.$.coupon` | String | Coupon code associated with a product |\n| `products.$.position` | Number | Position of the product in the product list |\n| `products.$.url` | String | URL of the product page |\n| `products.$.image_url` | String | Image URL of the product |\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> RudderStack’s SDKs do not calculate the value for any of the supported properties (e.g., `revenue`, `value`, `total`, `subtotal`). You must provide these values when triggering the `track` call. Also, RudderStack maps the values associated with these fields to the destination fields where send the data. Therefore, it is helpful to understand how these fields are defined in a specific destination.\n\nHere is an example of the **Checkout Started** event:\n\n```\nrudderanalytics.track(\"Checkout Started\", {\n  order_id: \"40684e8f0eaf000000000000\",\n  affiliation: \"Vandelay Games\",\n  value: 52,\n  revenue: 50.0,\n  shipping: 4,\n  tax: 3,\n  discount: 5,\n  coupon: \"NEWCUST5\",\n  currency: \"USD\",\n  products: [\n    {\n      product_id: \"622c6f5d5cf86a4c77358033\",\n      sku: \"8472-998-0112\",\n      name: \"Cones of Dunshire\",\n      price: 40,\n      position: 1,\n      category: \"Games\",\n      url: \"https://www.website.com/product/path\",\n      image_url: \"https://www.website.com/product/path.jpg\",\n    },\n    {\n      product_id: \"577c6f5d5cf86a4c7735ba03\",\n      sku: \"3309-483-2201\",\n      name: \"Five Crowns\",\n      price: 5,\n      position: 2,\n      category: \"Games\",\n    },\n  ],\n})\n```\n\n## Checkout Step Viewed\n\nThis event is triggered when a checkout step is viewed. The following properties are supported:\n\n| **Property Name** | **Type** | **Description** |\n| --- | --- | --- |\n| `checkout_id` | String | Checkout transaction ID |\n| `step` | Number | Checkout process step number |\n| `shipping_method` | String | Chosen shipping method |\n| `payment_method` | String | Payment method |\n\nHere is an example of the **Checkout Step Viewed** event:\n\n```\nrudderanalytics.track(\"Checkout Step Viewed\", {\n  checkout_id: \"70324a1f0eaf000000000000\",\n  step: 1,\n  shipping_method: \"UPS\",\n  payment_method: \"Mastercard\",\n})\n```\n\n## Checkout Step Completed\n\nThis event is triggered when a checkout step is completed. The following properties are supported:\n\n| **Property Name** | **Type** | **Description** |\n| --- | --- | --- |\n| `checkout_id` | String | Checkout transaction ID |\n| `step` | Number | Checkout process step number |\n| `shipping_method` | String | Chosen shipping method |\n| `payment_method` | String | Payment method |\n\nAn example of the **Checkout Step Completed** event is as shown:\n\n```\nrudderanalytics.track(\"Checkout Step Completed\", {\n  checkout_id: \"70324a1f0eaf000000000000\",\n  step: 1,\n  shipping_method: \"UPS\",\n  payment_method: \"Mastercard\",\n})\n```\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> For the Google Analytics 4 destination, you must include the `products` parameter in the [Checkout Step Completed](https://www.rudderstack.com/docs/destinations/streaming-destinations/google-analytics-4/cloud-mode/#checkout-step-completed) event to send it successfully.\n\n## Payment Info Entered\n\nThis event is triggered when payment information is successfully entered. The following properties are supported:\n\n| **Property Name** | **Type** | **Description** |\n| --- | --- | --- |\n| `checkout_id` | String | Checkout transaction ID |\n| `order_id` | String | Order ID, optionsal |\n| `step` | Number | Checkout process step number |\n| `shipping_method` | String | Chosen shipping method |\n| `payment_method` | String | Payment method |\n\nHere is an example of the **Payment Info Entered** event:\n\n```\nrudderanalytics.track(\"Payment Info Entered\", {\n  checkout_id: \"70324a1f0eaf000000000000\",\n  order_id: \"40684e8f0eaf000000000000\",\n})\n```\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> For the Google Analytics 4 destination, you must include the `products` parameter in the [Payment Info Entered](https://www.rudderstack.com/docs/destinations/streaming-destinations/google-analytics-4/cloud-mode/#payment-info-entered) event to send it successfully.\n\n## Order Updated\n\nThis event is triggered when an order or transaction is updated. The following properties are supported:\n\n| **Property Name** | **Type** | **Description** |\n| --- | --- | --- |\n| `order_id` | String | Order ID or transaction ID, whichever is applicable |\n| `affiliation` | String | Store or affiliation details from where the transaction was started |\n| `total` | Number | Revenue with the discount and coupons factored in |\n| `revenue` | Number | Revenue associated with the transaction, excluding the shipping and tax details |\n| `shipping` | Number | Shipping cost associated with the order or transaction |\n| `tax` | Number | Total tax associated with the order or the transaction |\n| `discount` | Number | Total discount associated with the transaction |\n| `coupon` | String | Coupon redeemed with the transaction |\n| `currency` | String | Currency code associated with an order or transaction |\n| `products` | Array | List of products in the order or transaction |\n| `products.$.product_id` | String | Product ID displayed on the list |\n| `products.$.sku` | String | SKU of the product being viewed |\n| `products.$.category` | String | Category of the product being viewed |\n| `products.$.name` | String | Name of the product being viewed |\n| `products.$.brand` | String | Name of the brand associated with the product |\n| `products.$.variant` | String | Variant associated with the product |\n| `products.$.price` | Number | Price of the product being viewed |\n| `products.$.quantity` | Number | Quantity of the product |\n| `products.$.coupon` | String | Coupon code associated with a product |\n| `products.$.position` | Number | position of the product in the product list |\n| `products.$.url` | String | URL of the product page |\n| `products.$.image_url` | String | Image URL of the product |\n\nAn example of the **Order Updated** event is as shown:\n\n```\nrudderanalytics.track(\"Order Updated\", {\n  order_id: \"40684e8f0eaf000000000000\",\n  affiliation: \"Vandelay Games\",\n  total: 52,\n  revenue: 50.0,\n  shipping: 4,\n  tax: 3,\n  discount: 5,\n  coupon: \"NEWCUST5\",\n  currency: \"USD\",\n  products: [\n    {\n      product_id: \"622c6f5d5cf86a4c77358033\",\n      sku: \"8472-998-0112\",\n      name: \"Cones of Dunshire\",\n      price: 40,\n      position: 1,\n      category: \"Games\",\n      url: \"https://www.website.com/product/path\",\n      image_url: \"https://www.website.com/product/path.jpg\",\n    },\n    {\n      product_id: \"577c6f5d5cf86a4c7735ba03\",\n      sku: \"3309-483-2201\",\n      name: \"Five Crowns\",\n      price: 5,\n      position: 2,\n      category: \"Games\",\n    },\n  ],\n})\n```\n\n## Order Completed\n\nThis event is triggered when an order is completed successfully. The following properties are supported:\n\n| **Property Name** | **Type** | **Description** |\n| --- | --- | --- |\n| `checkout_id` | String | Checkout ID |\n| `order_id` | String | Order ID or transaction ID, whichever is applicable |\n| `affiliation` | String | Store or affiliation details from where the transaction was started |\n| `subtotal` | Number | Order total after discounts but not including the taxes and shipping charges |\n| `total` | Number | Revenue with the discount and coupons factored in |\n| `revenue` | Number | Revenue associated with the transaction, excluding the shipping and tax details |\n| `shipping` | Number | Shipping cost associated with the order or transaction |\n| `tax` | Number | Total tax associated with the order or the transaction |\n| `discount` | Number | Total discount associated with the transaction |\n| `coupon` | String | Coupon redeemed with the transaction |\n| `currency` | String | Currency code associated with an order or transaction |\n| `products` | Array | List of products in the order or transaction |\n| `products.$.product_id` | String | Product ID displayed on the list |\n| `products.$.sku` | String | SKU of the product being viewed |\n| `products.$.category` | String | Category of the product being viewed |\n| `products.$.name` | String | Name of the product being viewed |\n| `products.$.brand` | String | Name of the brand associated with the product |\n| `products.$.variant` | String | Variant associated with the product |\n| `products.$.price` | Number | Price of the product being viewed |\n| `products.$.quantity` | Number | Quantity of the product |\n| `products.$.coupon` | String | Coupon code associated with a product |\n| `products.$.position` | Number | Position of the product in the product list |\n| `products.$.url` | String | URL of the product page |\n| `products.$.image_url` | String | Image URL of the product |\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> RudderStack’s SDKs do not calculate the value for any of the properties (e.g., `revenue`, `value`, `total`, `subtotal`). You must provide these values when triggering the `track` call. Also, RudderStack maps the values associated with these fields to the destination fields where you want to send the data. Therefore, it is helpful to understand how these fields are defined in a specific destination.\n\nHere is an example of the **Order Completed** event:\n\n```\nrudderanalytics.track(\"Order Completed\", {\n  checkout_id: \"70324a1f0eaf000000000000\",\n  order_id: \"40684e8f0eaf000000000000\",\n  affiliation: \"Vandelay Games\",\n  total: 52.0,\n  subtotal: 45.0,\n  revenue: 50.0,\n  shipping: 4.0,\n  tax: 3.0,\n  discount: 5.0,\n  coupon: \"NEWCUST5\",\n  currency: \"USD\",\n  products: [\n    {\n      product_id: \"622c6f5d5cf86a4c77358033\",\n      sku: \"8472-998-0112\",\n      name: \"Cones of Dunshire\",\n      price: 40,\n      position: 1,\n      category: \"Games\",\n      url: \"https://www.website.com/product/path\",\n      image_url: \"https://www.website.com/product/path.jpg\",\n    },\n    {\n      product_id: \"577c6f5d5cf86a4c7735ba03\",\n      sku: \"3309-483-2201\",\n      name: \"Five Crowns\",\n      price: 5,\n      position: 2,\n      category: \"Games\",\n    },\n  ],\n})\n```\n\n## Order Refunded\n\nThis event is triggered when an order is refunded. You must include all items in the cart as **Order Refunded** event properties, with the same properties as the **Order Completed** event.\n\nThe following properties are supported:\n\n| **Property Name** | **Type** | **Description** |\n| --- | --- | --- |\n| `order_id` | String | Order or transaction ID |\n\nHere is an example of the **Order Refunded** event:\n\n```\nrudderanalytics.track(\"Order Refunded\", {\n  order_id: \"40684e8f0eaf000000000000\",\n  total: 52,\n  currency: \"USD\",\n  products: [\n    {\n      product_id: \"622c6f5d5cf86a4c77358033\",\n      sku: \"8472-998-0112\",\n      name: \"Cones of Dunshire\",\n      price: 40,\n      position: 1,\n      category: \"Games\",\n      url: \"https://www.website.com/product/path\",\n      image_url: \"https://www.website.com/product/path.jpg\",\n    },\n    {\n      product_id: \"577c6f5d5cf86a4c7735ba03\",\n      sku: \"3309-483-2201\",\n      name: \"Five Crowns\",\n      price: 5,\n      position: 2,\n      category: \"Games\",\n    },\n  ],\n})\n```\n\n## Order Cancelled\n\nThis event is triggered when an order is canceled. The following properties are supported:\n\n| **Property Name** | **Type** | **Description** |\n| --- | --- | --- |\n| `order_id` | String | Order ID or transaction ID, whichever is applicable |\n| `affiliation` | String | Store or affiliation details from where the transaction was started |\n| `total` | Number | Revenue with the discount and coupons factored in |\n| `revenue` | Number | Revenue associated with the transaction, excluding the shipping and tax details |\n| `shipping` | Number | Shipping cost associated with the order or transaction |\n| `tax` | Number | Total tax associated with the order or the transaction |\n| `discount` | Number | Total discount associated with the transaction |\n| `coupon` | String | Coupon which can be redeemed with the transaction |\n| `currency` | String | Currency code associated with an order or transaction |\n| `products` | Array | List of products in the order or transaction |\n| `products.$.product_id` | String | Product ID displayed on the list |\n| `products.$.sku` | String | SKU of the product being viewed |\n| `products.$.category` | String | Category of the product being viewed |\n| `products.$.name` | String | Name of the product being viewed |\n| `products.$.brand` | String | Name of the brand associated with the product |\n| `products.$.variant` | String | Variant associated with the product |\n| `products.$.price` | Number | Price of the product being viewed |\n| `products.$.quantity` | Number | Quantity of the product |\n| `products.$.coupon` | String | Coupon code associated with a product |\n| `products.$.position` | Number | Position of the product in the product list |\n| `products.$.url` | String | URL of the product page |\n| `products.$.image_url` | String | Image URL of the product |\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> RudderStack’s SDKs do not calculate the value for any of the properties (e.g., `revenue`, `value`, `total`, `subtotal`). You must provide these values when triggering the `track` call. Also, RudderStack maps the values associated with these fields to the destination fields where you want to send the data. Therefore, it is helpful to understand how these fields are defined in a specific destination.\n\nHere is an example of the **Order Cancelled** event:\n\n```\nrudderanalytics.track(\"Order Cancelled\", {\n  order_id: \"40684e8f0eaf000000000000\",\n  affiliation: \"Vandelay Games\",\n  total: 52,\n  revenue: 50.0,\n  shipping: 4,\n  tax: 3,\n  discount: 5,\n  coupon: \"NEWCUST5\",\n  currency: \"USD\",\n  products: [\n    {\n      product_id: \"622c6f5d5cf86a4c77358033\",\n      sku: \"8472-998-0112\",\n      name: \"Cones of Dunshire\",\n      price: 40,\n      position: 1,\n      category: \"Games\",\n      url: \"https://www.website.com/product/path\",\n      image_url: \"https://www.website.com/product/path.jpg\",\n    },\n    {\n      product_id: \"577c6f5d5cf86a4c7735ba03\",\n      sku: \"3309-483-2201\",\n      name: \"Five Crowns\",\n      price: 5,\n      position: 2,\n      category: \"Games\",\n    },\n  ],\n})\n```\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Ordering | RudderStack Docs",
    "description": "Understand how ecommerce product order events work in RudderStack.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/ecommerce-events-spec/reviewing/",
    "markdown": "# Reviewing | RudderStack Docs\n\nPrivacy Overview\n\nThis site uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are as essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.\n\nNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.",
    "title": "Reviewing | RudderStack Docs",
    "description": "Understand how ecommerce product review events work in RudderStack.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/api/tracking-plan-api/",
    "markdown": "# Tracking Plan API | RudderStack Docs\n\nUse our tracking plan API to programmatically manage your tracking plans.\n\n* * *\n\n*     3 minute read  \n    \n\n> ![danger](https://www.rudderstack.com/docs/images/danger.svg)\n> \n> This API is deprecated. See [Data Catalog API](https://www.rudderstack.com/docs/api/data-catalog-api/) to create and manage your tracking plans programmatically.\n\nThe [Tracking plan API](https://documenter.getpostman.com/view/16242548/TzeWFT6D#7df289e7-8758-4ec0-a86e-3aa08bd3260e) lets you programmatically create and manage your [tracking plans](https://www.rudderstack.com/docs/data-governance/tracking-plans/). You can use the API to:\n\n*   Create/update/fetch tracking plans associated with your workspace\n*   Define tracking plan rules\n*   Create/update tracking plan configurations for a particular source\n*   Link and unlink a source/events to a tracking plan\n*   Delete a tracking plan\n\n## Prerequisites\n\nTo use the tracking plan API successfully:\n\n*   Set up a source-destination connection in RudderStack. For more details, refer to [Quickstart](https://www.rudderstack.com/docs/data-pipelines/event-stream/quickstart/) guide.\n*   Generate a [personal access token](https://www.rudderstack.com/docs/dashboard-guides/personal-access-token/) in your RudderStack dashboard.\n\nRudderStack uses **Basic Authentication** for authenticating all API requests.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> All the popular HTTP clients (e.g. CURL, Postman, HTTPie) have default support for basic authentication.\n\nThe basic authentication for this API requires a username and password, where:\n\n*   The username is the **email address** associated with your RudderStack workspace.\n*   The password is the **personal access token** generated above.\n\nFor example, if the email address is `name@surname.com` and the personal access token is `1zl4GJkLu0HsBdrDK88NgYZzY2E`, your request must have the following HTTP header:\n\n```\nAuthorization: Basic bmFtZUBzdXJuYW1lLmNvbToxemw0R0prTHUwSHNCZHJESzg4TmdZWnpZMkU=\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> In case of the **Invalid Authorization Header** error, verify if your email address and the personal access token are valid.\n\n## Base URL\n\nUse the base URL for your API requests depending on your region:\n\n```\nhttps://api.rudderstack.com\n```\n\n```\nhttps://api.eu.rudderstack.com\n```\n\n## Tracking plan API usage\n\n| Tracking plan API | Description |\n| --- | --- |\n| [Tracking Plans](https://documenter.getpostman.com/view/16242548/TzeWFT6D#2a5b999c-b417-4622-ad13-d212e4e211d1) | This section contains all the requests and the examples related to:<br><br>*   Creating a tracking plan<br>*   Fetching a single or all tracking plans<br>*   Updating a tracking plan<br>*   Upserting a tracking plan<br>*   Deleting a tracking plan |\n| [Tracking Plan Rules](https://documenter.getpostman.com/view/16242548/TzeWFT6D#dfa3156f-216f-4399-bd5d-c57e077ba406) | This section contains all the requests and the examples related to setting the tracking plan rules like:<br><br>*   Creating events<br>*   Fetching all events<br>*   Fetching all events linked to a tracking plan<br>*   Updating events by ID<br>*   Linking or unlinking events from a tracking plan<br>*   Deleting events<br><br>It also contains upsert and deletion requests for all non-track rules (applicable for `identify`, `group`, `page`, and `screen` events) like:<br><br>*   Creating or updating a non-track rule for a tracking plan<br>*   Deleting a non-track rule mapped to a tracking plan |\n| [Source Tracking Plan Connections](https://documenter.getpostman.com/view/16242548/TzeWFT6D#4b74ffd2-de44-43c9-b2a4-2d65e4fb61c9) | This section contains all the requests and the examples related to tracking plan configurations like:<br><br>*   Creating or updating tracking plan configurations for a source ID<br>*   Fetching all tracking plan configurations by source ID<br>*   Fetching all sources connected to a tracking plan<br>*   Linking or unlinking a source to a tracking plan |\n\n### Event structure\n\nTo perform the tracking plan validation successfully, your event payload structure must conform to the standard [RudderStack event spec](https://www.rudderstack.com/docs/event-spec/standard-events/).\n\nSee the following sample event payloads for more information:\n\n*   [Identify](https://www.rudderstack.com/docs/event-spec/standard-events/identify/#sample-payload)\n*   [Page](https://www.rudderstack.com/docs/event-spec/standard-events/page/#sample-payload)\n*   [Screen](https://www.rudderstack.com/docs/event-spec/standard-events/screen/#sample-payload)\n*   [Track](https://www.rudderstack.com/docs/event-spec/standard-events/track/#sample-payload)\n*   [Group](https://www.rudderstack.com/docs/event-spec/standard-events/group/#sample-payload)\n\nYou can also see the example request in the [Create Tracking Plan API](https://documenter.getpostman.com/view/16242548/TzeWFT6D#7eec6c80-64e8-444d-bbe4-bd63fb1d886a) for the event formatting structure.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Tracking Plan API | RudderStack Docs",
    "description": "Use our tracking plan API to programmatically manage your tracking plans.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/ecommerce-events-spec/sharing/",
    "markdown": "# Sharing | RudderStack Docs\n\nUnderstand how ecommerce sharing events work in RudderStack.\n\n* * *\n\n*     2 minute read  \n    \n\nProduct sharing events allow customers to share interesting products to their friends or colleagues on various social media platforms.\n\nThis event is triggered when a customer shares a product. The following properties are supported:\n\n| **Property Name** | **Type** | **Description of the Property** |\n| --- | --- | --- |\n| `share_via` | String | Sharing method |\n| `share_message` | String | Message sent by the customer |\n| `recipient` | String | Sharing recipient |\n| `product_id` | String | Product ID of the product |\n| `sku` | String | SKU of the product |\n| `category` | String | Category of the product |\n| `name` | String | Name of the product |\n| `brand` | String | Product brand |\n| `variant` | String | Product variant |\n| `price` | Number | Price of the product (in USD) |\n| `url` | String | URL of the product’s page |\n| `image_url` | String | Image URL of the product |\n\nHere is an example of the **Product Shared** event:\n\n```\nrudderanalytics.track(\"Product Shared\", {\n  share_via: \"email\",\n  share_message: \"Check out this great game!\",\n  recipient: \"buddy@example.com\",\n  product_id: \"622c6f5d5cf86a4c77358033\",\n  sku: \"8472-998-0112\",\n  category: \"Games\",\n  name: \"Cones of Dunshire\",\n  brand: \"Wyatt Games\",\n  variant: \"expansion pack\",\n  price: 49.99,\n  url: \"https://www.myecommercewebsite.com/product/prod\",\n  image_url: \"https://www.myecommercewebsite.com/product/prod.jpg\",\n})\n```\n\nThis event is triggered when a customer shares a shopping cart. The following properties are supported:\n\n| **Property Name** | **Type** | **Description of the Property** |\n| --- | --- | --- |\n| `share_via` | String | Sharing method |\n| `share_message` | String | Message sent by the customer |\n| `recipient` | String | Sharing recipient |\n| `cart_id` | String | Cart ID of the shopping cart being shared |\n| `products` | Array | List of products shared with the recipient |\n| `products.$.product_id` | String | Product ID displayed on the list |\n\nAn example of the **Cart Shared** event is as shown below:\n\n```\nrudderanalytics.track(\"Cart Shared\", {\n  share_via: \"email\",\n  share_message: \"Hello, check out these items!\",\n  recipient: \"buddy@example.com\",\n  cart_id: \"6b2c6f5aecf86a4ae77358ae3\",\n  products: [{ product_id: \"622c6f5d5cf86a4c77358033\" }, { product_id: \"577c6f5d5cf86a4c7735ba03\" }],\n})\n```\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Sharing | RudderStack Docs",
    "description": "Understand how ecommerce sharing events work in RudderStack.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/api/transformation-api/",
    "markdown": "# Transformations API | RudderStack Docs\n\nAPI Specification to manage your RudderStack Transformations and Libraries.\n\n* * *\n\n*     14 minute read  \n    \n\nRudderStack’s Transformations API allows you to create, read, update and delete transformations and libraries programmatically by making HTTP calls.\n\nThis guide describes the various API operations, related request and response structures, and error codes associated with this API.\n\n## Basic Authentication\n\nThe Transformations API is authenticated via HTTP Basic Authentication.\n\nYou can authenticate your account when using the API by including your **email address** in the username field and the secret **access token** in the password field in Authorization, if you’re using Postman.\n\nYou can also pass your personal access token in the authorization headers directly:\n\n```\nAuthorization: Basic {Base64Encoded(emailaddress:accesstoken)}\n```\n\nThe basic auth contains three parts:\n\n*   Basic\n    \n*   Base64Encoded (Token), where:\n    \n    *   Token = `<emailaddress>:<personal_access_token>`\n\nSome examples:\n\n*   Email Address: `alex@example.com`\n*   Personal Access Token: `2211A3jmxS2ip01zY666F80j7`\n*   Headers: `Basic {Base64Encoded(alex@example.com:2211A3jmxS2ip01zY666F80j7)}`\n\n## Base URL\n\nUse the base URL for your API requests depending on your region:\n\n```\nhttps://api.rudderstack.com\n```\n\n```\nhttps://api.eu.rudderstack.com\n```\n\n## Transformations\n\nRudderStack transformations are responsible for converting received event data into a suitable destination-specific format. All the transformation code is written in JavaScript.\n\nTransformations help you to create a user-defined code that allow you to route your events in a manner that is suitable for your destinations.\n\n#### Transformer payload\n\n| **Field** | **Type** | **Presence** | **Description** |\n| --- | --- | --- | --- |\n| `name` | String | Required | Sets the transformation name. |\n| `language` | String | Required | Language of the transformation code. Acceptable values are `javascript` and `pythonfaas`. |\n| `description` | String | Optional | Sets the transformation description. |\n| `code` | String | Optional | User-defined code that maps event data to destinations as defined by the user |\n| `codeVersion` | String | Optional | This is a number value always set to version “1” for API calls. |\n| `createdAt` | Date | Optional | The timestamp of the transformer when it is created |\n| `updatedAt` | Date | Optional | The timestamp of the transformer when it is updated |\n| `versionId` | String | Optional | Maintains a version of transformer every time it is updated |\n| `workspaceId` | Object | Optional | Workspace ID on which this transformation is created |\n| `destinations` | Array | Optional | List of all Destination IDs to which your transformation is connected |\n\n### Create a transformation\n\nCreate an unpublished transformation.\n\nWhen you create a tranfsormation but do not publish it, that is, when `publish` = `false`, RudderStack creates revisions for the transformation, but it is not available to incoming event traffic and cannot connect to destinations.\n\nWhen you wish to make the transformation live, see [Publish a transformation](#publish-a-transformation).\n\n**Query parameters**:\n\npublish\n\noptional, default is `false`\n\nboolean\n\nIf `true`, publishes your transformer to the latest version; code is made live for incoming traffic.\n\n* * *\n\n**Example request**:\n\nIn this example, `publish` is `false`, which is the default setting for the parameter. When unpublished, RudderStack only creates revisions for the transformation, meaning that you cannot connect destinations to the transformation and it cannot be used for incoming event traffic.\n\n```\nPOST /transformations HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=\nContent-Type: application/json\n\n{\n  \"name\": \"Get metdata\",\n  \"description\": \"Gets the metadata for an event\",\n  \"code\" : \"export function transformEvent(message, metadata) { const met = metadata(message); return met; }\",\n  \"language\": \"javascript\"\n}\n```\n\n```\ncurl --location 'https://api.rudderstack.com/transformations' \\\n--header 'Authorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=' \\\n--header 'Content-Type: application/json' \\\n--data '{\n\"name\": \"Get metdata\",\n\"description\": \"Gets the metadata for an event\",\n\"code\" : \"export function transformEvent(event, metadata) { const meta = metadata(event);\\n event.meta = meta;\\n return event; }\",\n\"language\": \"javascript\"\n}\n```\n\n**Request body**:\n\nobject\n\nPass a set of JSON events to be tested for your code. This should be an array of JSON data.\n\narray\n\nPass an array of `destinationIds` that you wish to connect with this transformation. You can connect only if `publish` is set to `true`.\n\nstring\n\nThe transformation name.\n\nstring\n\nDescription of the transformation you are creating.\n\nstring\n\nThe transformation code.\n\nstring\n\nLanguage of the transformation code. Acceptable values are `javascript` and `pythonfaas`.\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\ncontent-type: application/json; charset=utf-8\n\n{\n    \"id\": \"2LnbcGgKON5BbHHuyYVesZ24uqu\",\n    \"versionId\": \"2LnbcImcBqOTkm4FFVCpIakptZJ\",\n    \"name\": \"Get metdata\",\n    \"description\": \"Gets the metadata for an event\",\n    \"code\": \"export function transformEvent(message, metadata) { const met = metadata(message); return met; }\",\n    \"codeVersion\": \"1\",\n    \"language\": \"javascript\",\n    \"createdAt\": \"2023-02-16T01:11:11.586Z\",\n    \"updatedAt\": \"2023-02-16T01:11:11.586Z\"\n}\n```\n\n**Events JSON**: When passing events in the request body, format the events in JSON\n\n```\n{\n  \"events\": [\n    {\n      \"anonymousId\": \"8d872292709c6fbe\",\n      \"channel\": \"mobile\",\n      \"context\": {\n        \"traits\": {\n          \"address\": {\n            \"city\": \"Kolkata\",\n            \"country\": \"India\",\n            \"postalcode\": \"700096\",\n            \"state\": \"West bengal\",\n            \"street\": \"Park Street\"\n          }\n        }\n      },\n      \"properties\": {\n        \"revenue\": \"30\",\n        \"currency\": \"USD\",\n        \"quantity\": \"5\",\n        \"price\": \"58.0\"\n      }\n    }\n  ]\n}\n```\n\n### Publish a transformation\n\nPublish your transformation. This request is the same as [Create transformation](#create-a-transformation) except that you need to include `?publish=true` in the query, which will allow you to connect destinations to the transformation and make it available to incoming traffic.\n\nWhen you publish a transformation, we maintain two copies of the transformer: one is published and the other is used for revisions. The published version can be connected to destinations and its code is made live for incoming traffic.\n\nPOST\n\n/transformations?publish=true\n\n**Query parameters**:\n\npublish\n\noptional, default is `false`\n\nboolean\n\nIf `true`, publishes your transformer to the latest version; code is made live for incoming traffic.\n\n* * *\n\n**Request body**:\n\nobject\n\nPass a set of JSON events to be tested for your code. This should be an array of JSON data.\n\narray\n\nPass an array of `destinationIds` that you wish to connect with this transformation. You can connect only if `publish` is set to `true`.\n\nstring\n\nName of the transformer that you wish to create.\n\nstring\n\nDescription of the transformer you are creating.\n\nstring\n\nThe transformer code.\n\nstring\n\nLanguage of the transformation code. Acceptable values are `javascript` and `pythonfaas`.\n\n```\nPOST /transformations?publish=true HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=\nContent-Type: application/json\n\n{\n  \"name\": \"Cool transformation\",\n  \"description\": \"A test description\",\n  \"code\": \"export function transformEvent(event) { return event; }\",\n  \"destinations\": [\"2C8YtptB4KF2eL3KRi9mCFkY3BF\"],\n  \"language\": \"javascript\"\n}\n```\n\n```\ncurl --location 'https://api.rudderstack.com/transformations?publish=true' \\\n--header 'Authorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=' \\\n--header 'Content-Type: application/json' \\\n--data '{\n  \"name\": \"Cool transformation\",\n  \"description\": \"A test description\",\n  \"code\": \"export function transformEvent(event) { return event; }\",\n  \"destinations\": [\"2C8YtptB4KF2eL3KRi9mCFkY3BF\"],\n  \"language\": \"javascript\"\n}'\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\ncontent-type: application/json; charset=utf-8\n\n{\n  \"id\": \"2LpkmqnLEuUziYZcfRCdNLDQxDk\",\n  \"versionId\": \"2LpkmrHiyW4gXovOzhvtzbhdZ23\",\n  \"name\": \"Cool transformation\",\n  \"description\": \"A test description\",\n  \"code\": \"export function transformEvent(event) { return event; }\",\n  \"codeVersion\": \"1\",\n  \"language\": \"javascript\",\n  \"createdAt\": \"2023-02-16T19:26:13.263Z\",\n  \"updatedAt\": \"2023-02-16T19:26:13.263Z\",\n  \"destinations\": []\n}\n```\n\n### List all transformations\n\nList all published transformations for a workspace.\n\n**Example request**:\n\n```\nGET /transformations HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=\n```\n\n```\ncurl --location 'https://api.rudderstack.com/transformations' \\\n--header 'Authorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=' \\\n--data ''\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\ncontent-type: application/json; charset=utf-8\n\n{\n  \"transformations\": [\n    {\n      \"id\": \"sedrftg\",\n      \"versionId\": \"edrtv\",\n      \"name\": \"new Transformations-2\",\n      \"description\": \"\",\n      \"code\": \"export function transformEvent(event) { return event; }\",\n      \"codeVersion\": \"1\",\n      \"language\": \"javascript\",\n      \"createdAt\": \"2021-03-04T04:48:27.288Z\",\n      \"updatedAt\": \"2021-03-04T04:48:27.288Z\",\n      \"destinations\": []\n    },\n    {\n      \"id\": \"xcgvhcfdx\",\n      \"versionId\": \"dtvbyutbvc\",\n      \"name\": \"Update Transformations and Publish\",\n      \"description\": \"\",\n      \"code\": \"function transformEvent(event) { return event; } \",\n      \"codeVersion\": \"1\",\n      \"language\": \"javascript\",\n      \"createdAt\": \"2021-03-04T10:07:25.513Z\",\n      \"updatedAt\": \"2021-03-04T10:07:25.513Z\",\n      \"destinations\": []\n    }\n  ]\n}\n```\n\n### Retrieve a single transformation\n\nRetrieve a published transformations from an ID.\n\n**Example request**:\n\n```\nGET /transformations/2C8Vk2wj8qkofy00YzJbvJOGeqa HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=\n```\n\n```\ncurl --location 'https://api.rudderstack.com/transformations/2C8Vk2wj8qkofy00YzJbvJOGeqa' \\\n--header 'Authorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=' \\\n--data ''\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\ncontent-type: application/json; charset=utf-8\n\n{\n  \"id\": \"swderftgy\",\n  \"versionId\": \"edftgyhu\",\n  \"name\": \"new Transformations-2\",\n  \"description\": \"\",\n  \"code\": \"export function transformEvent(event) { return event; } \",\n  \"codeVersion\": \"1\",\n  \"language\": \"javascript\",\n  \"createdAt\": \"2021-03-04T04:48:27.288Z\",\n  \"updatedAt\": \"2021-03-04T04:48:27.288Z\",\n  \"destinations\": []\n}\n```\n\n### Update a transformation\n\nUpdating a transformation creates a new **revision** and sets it as **published** if the `publish` flag is set is `true`, and its code becomes live for upcoming traffic. If the `publish` flag is `false` , it only creates a new **revision** for that transformation.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> You cannot update the language used to write the transformation code, that is, a JavaScript transformation cannot be converted to Python and vice versa.\n\nPOST\n\n/transformations/{id}\n\n**Example request**:\n\n```\nGET /transformations/2C8Vk2wj8qkofy00YzJbvJOGeqa HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=\n```\n\n```\ncurl --location 'https://api.rudderstack.com/transformations/2C8Vk2wj8qkofy00YzJbvJOGeqa' \\\n--header 'Authorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=' \\\n--data ''\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\ncontent-type: application/json; charset=utf-8\n\n{\n  \"id\": \"1pHw1RmzAqKpRCNupzHjTGfTrPJ\",\n  \"versionId\": \"1pIfjTI5cOMnSgutkXjTRldt1n3\",\n  \"name\": \"new Transformations-2\",\n  \"description\": \"Hey I am updated\",\n  \"code\": \"export default function cube(x) { return x * x ; }\",\n  \"codeVersion\": \"1\",\n  \"language\": \"javascript\",\n  \"createdAt\": \"2021-03-04T04:48:27.288Z\",\n  \"updatedAt\": \"2021-03-04T04:48:27.288Z\"\n}\n```\n\n### Delete a transformation\n\nDelete a published transformation by ID. Note that RudderStack never deletes a transformation revision.\n\nDELETE\n\n/transformations/{id}\n\n**Example request**:\n\n```\nDELETE /transformations/2LyH0PQOBAJo7UgFXfDoMacGDPZ HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=\n```\n\n```\ncurl --location --request DELETE 'https://api.rudderstack.com/transformations/2LyH0PQOBAJo7UgFXfDoMacGDPZ' \\\n--header 'Authorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=' \\\n--data ''\n```\n\n**Example response**:\n\n### List transformation versions\n\nList all transformation versions for a given transformation ID.\n\nGET\n\n/transformations{id}/versions\n\n**Example request**:\n\n```\nGET /transformations/2C8Vk2wj8qkofy00YzJbvJOGeqa/versions HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=\n```\n\n```\ncurl --location 'https://api.rudderstack.com/transformations/2C8Vk2wj8qkofy00YzJbvJOGeqa/versions' \\\n--header 'Authorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=' \\\n--data ''\n```\n\n**Query parameters**:\n\nnumber\n\nGets the number of objects in your array. By default always returns the first 5 objects.\n\norderBy\n\noptional, default is `asc`\n\nPass either `asc` for ascending or `desc` for descending. By default, it sets the order as ascending on createdAt.\n\nPossible Values: asc, desc\n\n* * *\n\n**Example response**:\n\n```\n{\n  \"TransformationVersions\": [\n    {\n      \"id\": \"1pIYoILGZTNYZP4YYkeyNIKlitl\",\n      \"versionId\": \"1pIYoLfEzcMK3D3M1ihjqI02wnx\",\n      \"name\": \"Update Transformations and Publish\",\n      \"description\": \"\",\n      \"code\": \"export function transformEvent(event) { return event; }\\n\",\n      \"codeVersion\": \"1\",\n      \"language\": \"javascript\",\n      \"createdAt\": \"2021-03-04T10:07:24.562Z\",\n      \"updatedAt\": \"2021-03-04T10:07:24.562Z\"\n    },\n    {\n      \"id\": \"1pIYoILGZTNYZP4YYkeyNIKlitl\",\n      \"versionId\": \"1pIhxFXd7NR7XDA914rLAn5f7wq\",\n      \"name\": \"Update Transformations and Publish\",\n      \"description\": \"Hey I am updated again\",\n      \"code\": \"export default function cube(x) { return x * x * x ; }\",\n      \"codeVersion\": \"1\",\n      \"language\": \"javascript\",\n      \"createdAt\": \"2021-03-04T11:22:36.102Z\",\n      \"updatedAt\": \"2021-03-08T04:22:42.646Z\"\n    }\n  ]\n}\n```\n\n### Retrieve a single transformation version\n\nGet a single transformation revision.\n\nGET\n\n/transformations{id}/versions/{versionId}\n\n**Example request**:\n\n```\nGET /transformations/2C8Vk2wj8qkofy00YzJbvJOGeqa/versions/2C8ifOCgRIpxgyF9voHIgUHFP4c HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=\n```\n\n```\ncurl --location 'https://api.rudderstack.com/transformations/2C8Vk2wj8qkofy00YzJbvJOGeqa/versions/2C8ifOCgRIpxgyF9voHIgUHFP4c' \\\n--header 'Authorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=' \\\n--data ''\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\ncontent-type: application/json; charset=utf-8\n\n{\n  \"id\": \"1pIYoILGZTNYZP4YYkeyNIKlitl\",\n  \"versionId\": \"1pIYoLfEzcMK3D3M1ihjqI02wnx\",\n  \"name\": \"Update Transformations and Publish\",\n  \"description\": \"Updated sample transformation ready to be published\",\n  \"code\": \"export function transformEvent(event) { return event; }\\n\",\n  \"codeVersion\": \"1\",\n  \"language\": \"javascript\",\n  \"createdAt\": \"2021-03-04T10:07:24.562Z\",\n  \"updatedAt\": \"2021-03-04T10:07:24.562Z\"\n}\n```\n\n## Libraries\n\nLibraries are JavaScript code that you can write and export to be used in your transformations. They give you the flexibility for reusing and maintaining different versions of the transformation code.\n\nSuppose you write an aggregation function. You can easily export them and use it within different transformations just by importing that module by the library name.\n\n#### Libraries payload\n\n| **Field** | **Type** | **Presence** | **Description** |\n| --- | --- | --- | --- |\n| `name` | String | Required | Sets the library name. This name is used as modules when it is imported in the transformation code. |\n| `language` | String | Required | Language of the library code. Acceptable values are `javascript` and `pythonfaas`. |\n| `description` | String | Optional | Sets the library description |\n| `code` | String | Optional | The library code. |\n| `importName` | String | Optional | This is library name that users can use in their transformation code while importing that library. |\n| `createdAt` | Date | Optional | The timestamp when the transformer is created. |\n| `updatedAt` | Date | Optional | The timestamp when the transformer is updated. |\n| `versionId` | String | Optional | Maintains a version of library every time it is updated. |\n| `workspace` | Object | Optional | Dictionary of information that provides workspace data where any transformation is used. |\n\n### Create a library\n\nCreate a library and get its object as a response.\n\n**Example request**:\n\n```\nPOST /libraries HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Basic TVlfRU1BSUxfQUREUkVTUzpNWV9BQ0NFU1NfVE9LRU4=\nContent-Type: application/json\nContent-Length: 164\n\n{\n    \"name\": \"cool library\",\n    \"description\": \"cool description\",\n    \"code\": \"export function add(a,b) {return a+b; } export function sub(a,b) {return a-b; }\",\n    \"language\": \"javascript\"\n}\n```\n\n```\ncurl --location 'https://api.rudderstack.com/libraries' \\\n--header 'Authorization: Basic TVlfRU1BSUxfQUREUkVTUzpNWV9BQ0NFU1NfVE9LRU4=' \\\n--header 'Content-Type: application/json' \\\n--data '{\n    \"name\": \"cool library\",\n    \"description\": \"cool description\",\n    \"code\": \"export function add(a,b) {return a+b; } export function sub(a,b) {return a-b; }\",\n    \"language\": \"javascript\"\n}'\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\ncontent-type: application/json; charset=utf-8\n\n{\n  \"id\": \"2M1HnI40CGbHb4FxjjRBj1aFRZK\",\n  \"versionId\": \"2M1HnJoHwL4zXE91pEwZaAHQp8F\",\n  \"name\": \"cool library\",\n  \"description\": \"cool description\",\n  \"code\": \"export function add(a,b) {return a+b; } export function sub(a,b) {return a-b; }\",\n  \"language\": \"javascript\",\n  \"createdAt\": \"2023-02-20T21:25:33.380Z\",\n  \"updatedAt\": \"2023-02-20T21:25:33.380Z\",\n  \"importName\": \"coolLibrary\"\n}\n```\n\n**Query parameters**:\n\npublish\n\noptional, default is `false`\n\nboolean\n\nIf `true`, publishes your transformer to the latest version; code is made live for incoming traffic.\n\n* * *\n\n**Request body**:\n\nstring\n\nName of the library that you wish to create.\n\nstring\n\nDescription of the library you.\n\nstring\n\nLanguage of the library code. Acceptable values are `javascript` and `pythonfaas`.\n\n### List all libraries\n\nGet all published libraries.\n\n**Example request**:\n\n```\nGET /libraries HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Basic TVlfRU1BSUxfQUREUkVTUzpNWV9BQ0NFU1NfVE9LRU4=\n```\n\n```\ncurl --location 'https://api.rudderstack.com/libraries' \\\n--header 'Authorization: Basic TVlfRU1BSUxfQUREUkVTUzpNWV9BQ0NFU1NfVE9LRU4=' \\\n--data ''\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\ncontent-type: application/json; charset=utf-8\n\n{\n  \"libraries\": [\n    {\n      \"id\": \"1pHx15j5rXvmmQUIMBaQdIyrpr2\",\n      \"versionId\": \"1pHxdlGL8IyoP7WfvRil4Qs88cp\",\n      \"name\": \"Get Cube\",\n      \"description\": \"First Library using apiCall\",\n      \"code\": \"export default function cube(x) { return x * x ; }\",\n      \"language\": \"javascript\",\n      \"createdAt\": \"2021-03-04T05:01:46.985Z\",\n      \"updatedAt\": \"2021-03-04T05:01:47.141Z\",\n      \"importName\": \"getCube\"\n    },\n    {\n      \"id\": \"1pT7933tHRBPlEMIZt5Zi3VIht1\",\n      \"versionId\": \"1pT793mcqQkcyHdqwXkxHmtgMMg\",\n      \"name\": \"User Defined Library\",\n      \"description\": \"Get User context\",\n      \"code\": \"    export default function cube(x) { return x * x * x; }\",\n      \"language\": \"javascript\",\n      \"createdAt\": \"2021-03-08T03:47:51.512Z\",\n      \"updatedAt\": \"2021-03-08T03:47:51.512Z\",\n      \"importName\": \"userDefinedLibrary\"\n    }\n  ]\n}\n```\n\n### Retrieve a library\n\nGet a single published library by ID.\n\n**Example request**:\n\n```\nGET /libraries/2DmDQHMNpAk1HvvWBK2SlWhmPS2 HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Basic TVlfRU1BSUxfQUREUkVTUzpNWV9BQ0NFU1NfVE9LRU4=\n```\n\n```\ncurl --location 'https://api.rudderstack.com/libraries/2DmDQHMNpAk1HvvWBK2SlWhmPS2' \\\n--header 'Authorization: Basic TVlfRU1BSUxfQUREUkVTUzpNWV9BQ0NFU1NfVE9LRU4=' \\\n--data ''\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\ncontent-type: application/json; charset=utf-8\n\n{\n  \"id\": \"1pT7933tHRBPlEMIZt5Zi3VIht1\",\n  \"versionId\": \"1pT793mcqQkcyHdqwXkxHmtgMMg\",\n  \"name\": \"User Defined Library\",\n  \"description\": \"Get User context\",\n  \"code\": \"    export default function cube(x) { return x * x * x; }\",\n  \"language\": \"javascript\",\n  \"createdAt\": \"2021-03-08T03:47:51.512Z\",\n  \"updatedAt\": \"2021-03-08T03:47:51.512Z\",\n  \"importName\": \"userDefinedLibrary\"\n}\n```\n\n### List all library versions\n\nGet all library revisions for a library ID.\n\nGET\n\n/libraries/{id}/versions\n\n**Example request**:\n\n```\nGET /libraries/2DmDQHMNpAk1HvvWBK2SlWhmPS2 HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Basic TVlfRU1BSUxfQUREUkVTUzpNWV9BQ0NFU1NfVE9LRU4=\n```\n\n```\ncurl --location 'https://api.rudderstack.com/libraries/2DmDQHMNpAk1HvvWBK2SlWhmPS2' \\\n--header 'Authorization: Basic TVlfRU1BSUxfQUREUkVTUzpNWV9BQ0NFU1NfVE9LRU4=' \\\n--data ''\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\ncontent-type: application/json; charset=utf-8\n\n{\n  \"libraryVersions\": [\n    {\n      \"id\": \"1pT7933tHRBPlEMIZt5Zi3VIht1\",\n      \"versionId\": \"1pT793mcqQkcyHdqwXkxHmtgMMg\",\n      \"name\": \"userDefinedLibrary\",\n      \"description\": \"Get User context\",\n      \"code\": \"export default function cube(x) { return x * x * x; }\",\n      \"language\": \"javascript\",\n      \"createdAt\": \"2021-03-08T03:47:51.686Z\",\n      \"updatedAt\": \"2021-03-08T03:47:51.686Z\",\n      \"isPublished\": false\n    },\n    {\n      \"id\": \"1pT7933tHRBPlEMIZt5Zi3VIht1\",\n      \"versionId\": \"1pT8KDAD66mQxnaUQxJpNs9qLFn\",\n      \"name\": \"userDefinedLibrary\",\n      \"description\": \"Get Divisible by 2\",\n      \"code\": \"export default function cube(x) { return 2 * x; }\",\n      \"language\": \"javascript\",\n      \"createdAt\": \"2021-03-08T03:57:33.738Z\",\n      \"updatedAt\": \"2021-03-08T03:57:33.738Z\",\n      \"isPublished\": true\n    }\n  ]\n}\n```\n\n**Query parameters**:\n\nnumber\n\nGets the number of objects in your array. By default always returns the first 5 objects.\n\norderBy\n\noptional, default is `asc`\n\nPass either `asc` for ascending or `desc` for descending. By default, it sets the order as ascending on createdAt.\n\nPossible Values: asc, desc\n\n* * *\n\n### Retrieve a single library version\n\nGet a single library revision.\n\nGET\n\n/libraries/{id}/versions/{versionId}\n\n**Example request**:\n\n```\nGET /libraries/1pT7933tHRBPlEMIZt5Zi3VIht1/versions/1pT8KDAD66mQxnaUQxJpNs9qLFn HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Basic TVlfRU1BSUxfQUREUkVTUzpNWV9BQ0NFU1NfVE9LRU4=\n```\n\n```\ncurl --location 'https://api.rudderstack.com/libraries/1pT7933tHRBPlEMIZt5Zi3VIht1/versions/1pT8KDAD66mQxnaUQxJpNs9qLFn' \\\n--header 'Authorization: Basic TVlfRU1BSUxfQUREUkVTUzpNWV9BQ0NFU1NfVE9LRU4=' \\\n--data ''\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\ncontent-type: application/json; charset=utf-8\n\n{\n  \"id\": \"1pT7933tHRBPlEMIZt5Zi3VIht1\",\n  \"versionId\": \"1pT8KDAD66mQxnaUQxJpNs9qLFn\",\n  \"name\": \"userDefinedLibrary\",\n  \"description\": \"Get Divisible by 2\",\n  \"code\": \"export default function cube(x) { return 2 * x; }\",\n  \"language\": \"javascript\",\n  \"createdAt\": \"2021-03-08T03:57:33.738Z\",\n  \"updatedAt\": \"2021-03-08T03:57:33.738Z\",\n  \"isPublished\": false\n}\n```\n\n### Update a library\n\nThis request lets you update the code and description of the transformation library by specifying its ID. To publish the library, set the `publish` flag to `true`. If the `publish` flag is `false` , it only creates a new version of that library.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Note that:\n> \n> *   You cannot change the name of the library using this request.\n> *   You cannot update the language used to write the library code, that is, a JavaScript library cannot be converted to Python and vice versa.\n\n**Request body**:\n\nstring\n\nThe updated library description.\n\nstring\n\nThe updated library code.\n\nstring\n\nLanguage of the library code.\n\n**Example request**:\n\n```\nGET /libraries/2MTEP4IhlKLXYtnbOqAOx1kKcBd HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=\n```\n\n```\ncurl --location 'https://api.rudderstack.com/libraries/2MTEP4IhlKLXYtnbOqAOx1kKcBd' \\\n--data '{\n    \"description\": \"Updated library code from cube function to a sum function\",\n    \"code\": \"export default function cube(x) { return 2 * x; }\",\n    \"language\": \"javascript\"\n}'\n```\n\n**Example response**:\n\n```\nHTTP/1.1 200 OK\ncontent-type: application/json; charset=utf-8\n\n{\n  \"id\": \"1pHw1RmzAqKpRCNupzHjTGfTrPJ\",\n  \"versionId\": \"1pIfjTI5cOMnSgutkXjTRldt1n3\",\n  \"name\": \"new Transformations-2\",\n  \"description\": \"Hey I am updated\",\n  \"code\": \"export default function cube(x) { return 2 * x; }\",\n  \"codeVersion\": \"1\",\n  \"language\": \"javascript\",\n  \"createdAt\": \"2021-03-04T04:48:27.288Z\",\n  \"updatedAt\": \"2021-03-04T04:48:27.288Z\"\n}\n```\n\n### Delete a library\n\nDelete a library by ID.\n\n**Example request**:\n\n```\nDELETE /libraries/2LyH0PQOBAJo7UgFXfDoMacGDPZ HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=\n```\n\n```\ncurl --location --request DELETE 'https://api.rudderstack.com/libraries/2LyH0PQOBAJo7UgFXfDoMacGDPZ' \\\n--header 'Authorization: Basic YWxleEBleGFtcGxlLmNvbToyTWxxbW9rRGxTeFE2bWJYQ1ZqcVFmbUpoRXk=' \\\n--data ''\n```\n\n**Example response**:\n\n## Publish API\n\nAs an end user you can create a transformer/library and perform several edits on it. Note that **publishing is optional at `create`**.\n\nIf you perform some edits on this version of transformer, RudderStack takes your latest update as the published version, creates a copy of the older version, and saves it as revisions. Let’s assume that after creating some 7 to 8 such revisions of your transformer, you finally decide to use the second or third version of the transformer.\n\nThis is where the RudderStack **Publish API** comes into play.\n\n### Publish a transformation or library\n\nPublish any transformation revisions or library revisions.\n\n```\nPOST /libraries/publish HTTP/1.1\nHost: api.rudderstack.com\nAuthorization: Basic TVlfRU1BSUxfQUREUkVTUzpNWV9BQ0NFU1NfVE9LRU4=\nContent-Type: application/json\nContent-Length: 591\n\n{\n  \"transformations\": [\n      {\n          \"versionId\": \"2M1iihtQyRHGTDCAkwr39IWSS9U\",\n          \"testInput\": [\n              {\n                  \"anonymousId\": \"8d872292709c6fbe\",\n                  \"channel\": \"mobile\"\n              },\n              {\n                  \"anonymousId\": \"8d872292709c6fbe\",\n                  \"channel\": \"mobile\"\n              }\n          ]\n      }\n  ],\n  \"libraries\": [\n      {\n          \"versionId\": \"2M1iidJVSDoIbtkXfyJsZZKDLz9\"\n      },\n      {\n          \"versionId\": \"2M1iidJVSDoIbtkXfyJsZZKDLz9\"\n      }\n  ]\n}\n```\n\n**Request body**:\n\narray\n\nPass an array of transformer `versionIds` that you wish to publish.\n\narray\n\nPass an array of library `versionIds` that you wish to publish.\n\nOne of above `transformations` or `libraries` must be present to make a successful `publish` call.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> A few things to note:\n> \n> *   You can choose to publish some revisions transformer without the libraries.\n> *   You can choose to publish some revisions libraries without the transformers.\n> *   You can publish both library and transformation revisions.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Whenever you call the `publish` API, we run tests in our server to make sure you won’t save any transformation/libraries code that can lead to any exceptions. In case if your publish is failing, make sure to check your transformation code and the libraries that it is referring to.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Transformations API | RudderStack Docs",
    "description": "API Specification to manage your RudderStack Transformations and Libraries.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/event-spec/ecommerce-events-spec/wishlisting/",
    "markdown": "# Wishlist | RudderStack Docs\n\nUnderstand how ecommerce wishlist events work in RudderStack.\n\n* * *\n\n*     3 minute read  \n    \n\nProduct wishlist events are a customer adding a product to their shopping wishlist. This is useful if your website/app supports a wishlisting feature.\n\n## Product Added to Wishlist\n\nThis event is triggered when a customer adds a product to their shopping wishlist. The following properties are supported:\n\n| **Property Name** | **Type** | **Description of the Property** |\n| --- | --- | --- |\n| `wishlist_id` | String | Wishlist ID |\n| `wishlist_name` | String | Name of the wishlist the product was added to |\n| `product_id` | String | Product ID of the product being viewed |\n| `sku` | String | SKU of the product |\n| `category` | String | Category of the product |\n| `name` | String | Name of the product |\n| `brand` | String | Name of the brand associated with the product |\n| `variant` | String | Name of the variant associated with the product |\n| `price` | Number | Price of the product (in USD) |\n| `quantity` | Number | Quantity of the product |\n| `coupon` | String | Coupon code associated with the product |\n| `position` | Number | Position of the product in the product list |\n| `url` | String | URL of the product page |\n| `image_url` | String | Image URL of the product |\n\nHere is an example of the **Product Added to Wishlist** event:\n\n```\nrudderanalytics.track(\"Product Added to Wishlist\", {\n  wishlist_id: \"74fkdjfl0jfdkdj29j030\",\n  wishlist_name: \"New Games\",\n  product_id: \"622c6f5d5cf86a4c77358033\",\n  sku: \"8472-998-0112\",\n  category: \"Games\",\n  name: \"Cones of Dunshire\",\n  brand: \"Wyatt Games\",\n  variant: \"expansion pack\",\n  price: 49.99,\n  quantity: 1,\n  coupon: \"PREORDER15\",\n  position: 1,\n  url: \"https://www.site.com/product/path\",\n  image_url: \"https://www.site.com/product/path.jpg\",\n})\n```\n\n## Product Removed from Wishlist\n\nThis event is triggered when a customer removes a product from their shopping wishlist. The following properties are supported:\n\n| **Property** | **Type** | **Description** |\n| --- | --- | --- |\n| `wishlist_id` | String | Wishlist ID |\n| `wishlist_name` | String | Name of the wishlist the product was added to |\n| `product_id` | String | Product ID of the product being viewed |\n| `sku` | String | SKU of the product |\n| `category` | String | Category of the product being viewed |\n| `name` | String | Name of the product |\n| `brand` | String | Name of the brand associated with the product |\n| `variant` | String | Name of the variant associated with the product |\n| `price` | Number | Price of the product (in USD) |\n| `quantity` | Number | Quantity of the product |\n| `coupon` | String | Coupon code associated with the product |\n| `position` | Number | Position of the product in the product list |\n| `url` | String | URL of the product page |\n| `image_url` | String | Image URL of the product |\n\nHere is an example of the **Product Removed from Wishlist** event:\n\n```\nrudderanalytics.track(\"Product Removed from Wishlist\", {\n  wishlist_id: \"74fkdjfl0jfdkdj29j030\",\n  wishlist_name: \"New Games\",\n  product_id: \"622c6f5d5cf86a4c77358033\",\n  sku: \"8472-998-0112\",\n  category: \"Games\",\n  name: \"Cones of Dunshire\",\n  brand: \"Wyatt Games\",\n  variant: \"expansion pack\",\n  price: 49.99,\n  quantity: 1,\n  coupon: \"PREORDER15\",\n  position: 1,\n  url: \"https://www.site.com/product/path\",\n  image_url: \"https://www.site.com/product/path.jpg\",\n})\n```\n\n## Wishlist Product Added to Cart\n\nThis event is triggered whenever a wishlisted product is added to the shopping cart by the customer. The following properties are supported by this event:\n\n| **Property** | **Type** | **Description** |\n| --- | --- | --- |\n| `wishlist_id` | String | Wishlist ID |\n| `wishlist_name` | String | Name of the wishlist the product was added to |\n| `product_id` | String | Product ID of the product being viewed |\n| `sku` | String | SKU of the product |\n| `category` | String | Category of the product being viewed |\n| `name` | String | Name of the product |\n| `brand` | String | Name of the brand associated with the product |\n| `variant` | String | Name of the variant associated with the product |\n| `price` | Number | Price of the product (in USD) |\n| `quantity` | Number | Quantity of the product |\n| `coupon` | String | Coupon code associated with the product |\n| `position` | Number | Position of the product in the product list |\n| `url` | String | URL of the product page |\n| `image_url` | String | Image URL of the product |\n\nAn example of the **Wishlist Product Added to Cart** event is as shown:\n\n```\nrudderanalytics.track(\"Wishlist Product Added to Cart\", {\n  wishlist_id: \"74fkdjfl0jfdkdj29j030\",\n  wishlist_name: \"New Games\",\n  product_id: \"622c6f5d5cf86a4c77358033\",\n  sku: \"8472-998-0112\",\n  category: \"Games\",\n  name: \"Cones of Dunshire\",\n  brand: \"Wyatt Games\",\n  variant: \"expansion pack\",\n  price: 49.99,\n  quantity: 1,\n  coupon: \"PREORDER15\",\n  position: 1,\n  url: \"https://www.site.com/product/path\",\n  image_url: \"https://www.site.com/product/path.jpg\",\n})\n```\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Wishlist | RudderStack Docs",
    "description": "Understand how ecommerce wishlist events work in RudderStack.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/user-guides/administrators-guide/",
    "markdown": "# Administrator Guides | RudderStack Docs\n\nPrivacy Overview\n\nThis site uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are as essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.\n\nNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.",
    "title": "Administrator Guides | RudderStack Docs",
    "description": "Reference for some common administrative tasks while using RudderStack.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/user-guides/administrators-guide/sso-setup/okta/scim-configuration/",
    "markdown": "# Okta SCIM Configuration | RudderStack Docs\n\nPrivacy Overview\n\nThis site uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are as essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.\n\nNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.",
    "title": "Okta SCIM Configuration | RudderStack Docs",
    "description": "Configure Okta SCIM provisioning for RudderStack.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/dashboard-guides/sources/",
    "markdown": "# Sources | RudderStack Docs\n\nPrivacy Overview\n\nThis site uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are as essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.\n\nNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.",
    "title": "Sources | RudderStack Docs",
    "description": "Add a source in RudderStack Cloud.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/dashboard-guides/overview/",
    "markdown": "# Dashboard Overview | RudderStack Docs\n\nManage up your data pipelines and use different RudderStack features.\n\n* * *\n\n*     5 minute read  \n    \n\nOnce you [sign up](https://app.rudderstack.com/signup) for RudderStack Cloud, you are presented with a dashboard that lets you set up and manage your event data sources, destinations, and different RudderStack features through an easy-to-use UI.\n\nThis guide walks you through all dashboard options to start using RudderStack Cloud.\n\n## Getting started\n\nOnce you sign up and log in to your RudderStack dashboard, you will see the following checklist. It gives you different options to add a source and destination to set up a connection, view live events, invite other members in your workspace, and more.\n\n[![Get started checklist](https://www.rudderstack.com/docs/images/rs-cloud/get-started.webp)](https://www.rudderstack.com/docs/images/rs-cloud/get-started.webp)\n\n## Directory\n\n**Directory** is a catalog of all the RudderStack-supported sources and destinations. You can search for any source/destination from this view and set them up.\n\n## Collect\n\nThis option lets you set up your data pipelines by connecting different sources and destinations across your customer data stack.\n\n### Connections\n\nThis option shows all the connections between your sources and destinations. You also see the following options:\n\n*   [Add source](https://www.rudderstack.com/docs/dashboard-guides/sources/#add-a-source)\n*   [Add destination](https://www.rudderstack.com/docs/dashboard-guides/destinations/#add-a-destination)\n*   **Data Plane URL**: For routing and processing events to RudderStack, a data plane URL is required. See [RudderStack Architecture](https://www.rudderstack.com/docs/resources/rudderstack-architecture/) for more information on data plane.\n\n[![Data Plane URL](https://www.rudderstack.com/docs/images/rs-cloud/data-plane-url.webp)](https://www.rudderstack.com/docs/images/rs-cloud/data-plane-url.webp)\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> If you’re using [RudderStack Open Source](https://app.rudderstack.com/signup?type=opensource), you must [set up your own data plane](https://www.rudderstack.com/docs/get-started/rudderstack-open-source/data-plane-setup/) in your preferred environment.\n> \n> An open source data plane URL looks like `http:localhost:8080` where `8080` is typically the port where your RudderStack data plane is hosted.\n\n### Sources\n\nThis option lists all the configured sources in your workspace. You can add a new source by clicking the **New Source** button. See [Sources](https://www.rudderstack.com/docs/dashboard-guides/sources/#add-a-source) for more information on adding a source.\n\n### Destinations\n\nThis option lists all the configured destinations in your workspace. You can add a new destination by clicking the **New Destination** button. See [Destinations](https://www.rudderstack.com/docs/dashboard-guides/destinations/#add-a-destination) for more information on adding a destination.\n\n### Transformations\n\nWith this option, you can transform events using custom JavaScript/Python functions before sending them to your destinations. You can also create your own **Libraries** to reuse code in other transformations.\n\nSee [Transformations](https://www.rudderstack.com/docs/transformations/overview/) to learn more about this feature.\n\n### Tracking Plans\n\nThis feature lets you proactively monitor and act on non-compliant event data coming into your RudderStack sources based on predefined plans. It ensures data quality by validating live events delivered to RudderStack against the expected events and their properties.\n\nSee [Tracking plans](https://www.rudderstack.com/docs/data-governance/tracking-plans/) to learn more about this feature.\n\n## Activate\n\nThis section highlights the following RudderStack features to activate your data for a variety of use cases.\n\n### Audiences\n\nThis feature lets you create customer sets that meet a specific criteria and sync them to the destinations connected to your Reverse ETL sources. This is helpful when you want to send targeted messaging to different customer groups.\n\nSee [Audiences](https://www.rudderstack.com/docs/data-pipelines/reverse-etl/features/audiences/) to learn more about this feature.\n\n### Models\n\nThis feature lets you define and execute custom SQL queries on your warehouse, fetch the resultant data, and send it specific destinations via RudderStack.\n\nSee [Models](https://www.rudderstack.com/docs/data-pipelines/reverse-etl/features/models/) to learn more about this feature.\n\n## Monitor\n\nThe options in this section let you monitor your warehouse syncs and get better observability into the events flowing in and out of RudderStack.\n\n### Syncs\n\nThis option provides detailed metrics on the events synced to your warehouse destinations. You can also filter the event data based on a specific source or destination by using the filter option in the header or sync the data manually by using the **Sync Now** button.\n\n[![RudderStack Syncs](https://www.rudderstack.com/docs/images/rs-cloud/syncs-dashboard.webp)](https://www.rudderstack.com/docs/images/rs-cloud/syncs-dashboard.webp)\n\n### Grafana\n\nThis feature is available in the RudderStack Cloud [Starter, Growth, and Enterprise plans](https://rudderstack.com/pricing). It provides an intuitive dashboard for better observability and performance monitoring of your RudderStack setup.\n\nThe Grafana dashboard gives you a real-time view of the events sent and received by RudderStack. It also gives you visibility into various metrics like RudderStack’s performance under load, processing errors, event delivery statistics, events pending delivery, and more.\n\nSee [Grafana dashboard](https://www.rudderstack.com/docs/user-guides/administrators-guide/rudderstack-grafana-dashboard/) to learn more about this feature.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Only members with [admin permissions](https://www.rudderstack.com/docs/dashboard-guides/user-management/#role-permissions) in your workspace can access the Grafana dashboard.\n\n## Settings\n\nThis option lets you manage various account, workspace, and organization-specific settings.\n\n### Your Profile\n\n#### **Account**\n\n*   **Security**: Lets you review and modify your security settings like changing password and setting a two-factor authentication.\n    \n*   **Personal access tokens**: Lets you generate a [Personal Access Token](https://www.rudderstack.com/docs/dashboard-guides/personal-access-token/) required to use the RudderStack APIs.\n    \n\n#### **Access policy**\n\nThis section gives you an overview of your organization access role and the workspace-level roles and permissions assigned to you.\n\n[![Access policy tab](https://www.rudderstack.com/docs/images/rs-cloud/access-policy.webp)](https://www.rudderstack.com/docs/images/rs-cloud/access-policy.webp)\n\nSee [User management](https://www.rudderstack.com/docs/dashboard-guides/user-management/) to set and manage these access policies for your organization members.\n\n### Workspace\n\n#### **General**\n\nThis section displays your workspace information like name and workspace ID.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The RudderStack team uses the workspace ID for tracking data internally and enabling specific features for your account.\n\n#### **Workspace token**\n\nThe workspace token is a unique identifier of your RudderStack workspace.\n\nTo get your workspace token, go to **Settings** > **Workspace**. The workspace token is present in the **General** tab.\n\n[![Workspace Token](https://www.rudderstack.com/docs/images/rs-cloud/workspace-token.webp)](https://www.rudderstack.com/docs/images/rs-cloud/workspace-token.webp)\n\nTo view the workspace token, click the show icon and enter the password associated with your RudderStack account.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> By default, the workspace token is hidden for security purposes. You must have [administrative privileges](https://www.rudderstack.com/docs/dashboard-guides/user-management/#organization-roles) to access the workspace token.\n\n#### **Data management**\n\nThis section lets you configure the data retention and data privacy settings for your workspace.\n\nSee [Data management](https://www.rudderstack.com/docs/dashboard-guides/data-management/) to learn more about this feature.\n\n#### **Audit logs**\n\nThis feature is available only in the RudderStack Cloud [Enterprise](https://rudderstack.com/enterprise-quote) plan. It lets you track user activities within your workspace, like creating or modifying sources and destinations, transformations, implementing Multi-Factor Authentication (MFA), and more.\n\nSee [Audit logs](https://www.rudderstack.com/docs/dashboard-guides/audit-logs/) to learn more about this feature.\n\n#### **Alerts**\n\nThis feature lets you configure workspace and resource-level alerts for event processing or delivery failures across your Event Stream and Reverse ETL pipelines.\n\nSee [Configurable Alerts](https://www.rudderstack.com/docs/data-governance/alerts/) to learn more about this feature.\n\n### Organization\n\n#### **General**\n\nThis tab lets you change your organization name and enforce two-factor authentication for all organization members.\n\n#### **Members**\n\nThis option displays all team members, their roles, and access policy in the current workspace. You can also invite new members by using the **Invite member** button.\n\nSee [User management](https://www.rudderstack.com/docs/dashboard-guides/user-management/) to learn more about this feature.\n\n#### **Usage**\n\nIn this section, you can view your organization’s event usage by product (Event Stream, Cloud Extract, and Reverse ETL). It also indicates your current RudderStack Cloud plan and when your billing cycle resets.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> RudderStack calculates the monthly event volume based on the events ingested at source and **not** the events sent to the destinations.\n> \n> Filtering selective events to destinations using [transformations](https://www.rudderstack.com/docs/transformations/overview/) will not result in a lower event volume.\n\n[![Usage tab](https://www.rudderstack.com/docs/images/rs-cloud/usage.webp)](https://www.rudderstack.com/docs/images/rs-cloud/usage.webp)\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Dashboard Overview | RudderStack Docs",
    "description": "Manage up your data pipelines and use different RudderStack features.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/user-guides/administrators-guide/sso-setup/okta/",
    "markdown": "# Okta SSO Setup | RudderStack Docs\n\nSet up the RudderStack SSO (Single Sign-On) feature with Okta.\n\nAvailable Plans\n\n*   enterprise\n\n* * *\n\n*     4 minute read  \n    \n\nThe [Okta RudderStack app](https://www.okta.com/integrations/rudderstack/) is available on the **Okta Integration Network (OIN)**. This guide lists the steps to set up the integration.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> *   To manually configure and enable Okta SSO for your organization, see the [Manual Setup](https://www.rudderstack.com/docs/user-guides/administrators-guide/sso-setup/okta/manual-setup/) guide.\n> *   If you are anticipating any changes to your SSO like email change, make sure to [contact RudderStack support](mailto:support@rudderstack.com) in advance to avoid any login issues.\n\n## Supported features\n\nThe Okta-RudderStack SAML integration supports the following features:\n\n*   SP-initiated SSO\n*   JIT(Just In Time) Provisioning\n\nFor more information on these features, see [Okta Glossary](https://help.okta.com/en/prod/Content/Topics/Reference/glossary.htm).\n\nAlso, it supports the following SAML attributes:\n\n| Name | Value |\n| --- | --- |\n| FirstName | user.firstName |\n| LastName | user.lastName |\n| Email | user.email |\n\n## Step 1: Add the RudderStack SSO SAML 2.0 app\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Before you enable SAML, note that:\n> \n> *   Your users will not be able to sign in to RudderStack through their regular sign-in page once SAML is enabled. They will be able to access RudderStack only through the Okta service.\n> *   RudderStack **does not** provide a backup sign-in URL where users can log in with their username and password.\n> *   You can contact [RudderStack support](mailto:support@rudderstack.com) to disable SAML, if required.\n\n1.  [Log in to Okta](https://www.okta.com/login/) as an administrator.\n2.  Go to the [RudderStack SSO integration page](https://www.okta.com/integrations/rudderstack/). Then, click **Add Integration**:\n\n[![Add Integration](https://www.rudderstack.com/docs/images/user-guides/rudderstack-okta-sso-1.webp)](https://www.rudderstack.com/docs/images/user-guides/rudderstack-okta-sso-1.webp)\n\n3.  Select the account under **Choose an account**.\n4.  Set the **Application Label** (your preferred application name) and the **Application Visibility**. Check the **Do not display application icon to users** and **Do not display application icon in the Okta Mobile App** settings, as shown. Then, click **Next**.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Since the integration supports only SP-initiated flow, hiding the application icon for the users is highly recommended.\n\n[![Application name and visibility](https://www.rudderstack.com/docs/images/user-guides/rudderstack-okta-sso-2.webp)](https://www.rudderstack.com/docs/images/user-guides/rudderstack-okta-sso-2.webp)\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> You need to check the **Do not display application icon to users** and **Do not display application icon in the Okta Mobile App** settings as this app will not be visible to your users.\n\n5.  Under **Sign on methods**, choose **SAML 2.0**.\n6.  Under **Metadata details**, copy the **Metadata URL**.\n7.  Under **Credentials Details**, set **Application username format** to **Email**. Retain the rest of the settings and click **Done**.\n\n[![SAML 2.0 configuration](https://www.rudderstack.com/docs/images/user-guides/rudderstack-okta-sso-8.webp)](https://www.rudderstack.com/docs/images/user-guides/rudderstack-okta-sso-8.webp)\n\n8.  Share the **Metadata URL** copied above with the [RudderStack team](mailto:support@rudderstack.com) to enable SAML 2.0 for your account.\n\n## Step 2: Add the RudderStack SSO Bookmark app\n\nTo create the SSO bookmark app in Okta:\n\n1.  Go to the [RudderStack SSO integration page](https://www.okta.com/integrations/rudderstack/). Then, click **Add Integration**:\n\n[![Add Integration](https://www.rudderstack.com/docs/images/user-guides/rudderstack-okta-sso-1.webp)](https://www.rudderstack.com/docs/images/user-guides/rudderstack-okta-sso-1.webp)\n\n2.  Set the **Application Label** that you set previously. Then, click **Next**.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Do not check the **Do not display application icon to users** and **Do not display application icon in the Okta Mobile App** settings as this app will be visible to your users.\n\n[![Application name and visibility](https://www.rudderstack.com/docs/images/user-guides/rudderstack-okta-sso-5.webp)](https://www.rudderstack.com/docs/images/user-guides/rudderstack-okta-sso-5.webp)\n\n3.  Under **Sign on methods**, choose **Bookmark-only**. Set the **Login URL** to `https://app.rudderstack.com/sso?domain=<your_website>.com`, where `<your_website>` is your organization’s web domain. Under **Credentials Details**, set **Application username format** to **Email**. Retain the rest of the settings and click **Done**.\n\n[![Bookmark sign on method and Login URL](https://www.rudderstack.com/docs/images/user-guides/rudderstack-okta-sso-9.webp)](https://www.rudderstack.com/docs/images/user-guides/rudderstack-okta-sso-9.webp)\n\n## User authentication\n\nOnce you have set up SSO, the users can authenticate to RudderStack through any of the below approaches:\n\n*   The bookmark app set up in [Step 3](#step-3-add-the-rudderstack-sso-bookmark-app).\n    \n*   [SP-initated SSO](#supported-features) by following these steps:\n    \n    1.  Go to [https://app.rudderstack.com/sso](https://app.rudderstack.com/sso).\n    2.  Enter your email address and click **SIGN IN**.\n\n## SCIM configuration\n\nYou can automatically grant RudderStack access to your users by [configuring SCIM provisioning](https://www.rudderstack.com/docs/user-guides/administrators-guide/sso-setup/okta/scim-configuration/) in Okta.\n\n## Debugging\n\nThere are times when an SSO login might fail for some users due to some reason. In such cases, the RudderStack team requires a HAR (HTTP Archive) file to inspect the requests and identify any SSO-related issues.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> A HAR file is a log of exported network requests from the user’s browser. See the [HAR Analyzer](https://toolbox.googleapps.com/apps/har_analyzer/) guide for steps on generating this file depending on your browser.\n\nOnce you generate the HAR file, share it with the [RudderStack team](mailto:support@rudderstack.com) to troubleshoot the issue.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Note the following before capturing your HAR file:\n> \n> *   Start from `https://app.rudderstack.com/sso` with a clean session, preferably in incognito mode of your browser.\n> *   Complete the SSO flow until the step where you face an error.\n> *   Your HAR file might contain sensitive data - make sure to redact it using a text editor before sharing it with the team.\n\n## FAQ\n\n#### My organization’s email domain has changed from `abc.com` to `xyz.com` and now I am unable to log in. What should I do?\n\nContact [RudderStack support](mailto:support@rudderstack.com) to make the necessary changes to your SSO configuration.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Okta SSO Setup | RudderStack Docs",
    "description": "Set up the RudderStack SSO (Single Sign-On) feature with Okta.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/user-guides/administrators-guide/event-replay/",
    "markdown": "# Event replay | RudderStack Docs\n\nPrivacy Overview\n\nThis site uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are as essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.\n\nNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.",
    "title": "Event replay | RudderStack Docs",
    "description": "Play back events for diagnostics, testing, or in case of failures.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/user-guides/administrators-guide/sso-setup/onelogin/",
    "markdown": "# OneLogin SSO setup | RudderStack Docs\n\nSet up the RudderStack SSO (Single Sign-On) feature with OneLogin.\n\nAvailable Plans\n\n*   enterprise\n\n* * *\n\n*     3 minute read  \n    \n\nThis guide lists the steps to configure and enable OneLogin SSO for your organization.\n\n## Configuring the RudderStack SSO app\n\n1.  Log into your [OneLogin portal](https://app.onelogin.com/login) and click **Administration** in the top menu:\n\n[![Administration option in OneLogin](https://www.rudderstack.com/docs/images/user-guides/onelogin-1.webp)](https://www.rudderstack.com/docs/images/user-guides/onelogin-1.webp)\n\n2.  From the top menu, go to **Applications** > **Applications**:\n\n[![Applications option](https://www.rudderstack.com/docs/images/user-guides/onelogin-2.webp)](https://www.rudderstack.com/docs/images/user-guides/onelogin-2.webp)\n\n3.  Then, click **Add App**:\n\n[![Add App option](https://www.rudderstack.com/docs/images/user-guides/onelogin-3.webp)](https://www.rudderstack.com/docs/images/user-guides/onelogin-3.webp)\n\n4.  In the resulting **Find Applications** page, search for **SAML Custom Connector (Advanced)**. From the search results, select the application:\n\n[![Select SAML Custom Connector option](https://www.rudderstack.com/docs/images/user-guides/onelogin-4.webp)](https://www.rudderstack.com/docs/images/user-guides/onelogin-4.webp)\n\n5.  Name your SAML app and click **Save**:\n\n[![Select SAML app name](https://www.rudderstack.com/docs/images/user-guides/onelogin-5.webp)](https://www.rudderstack.com/docs/images/user-guides/onelogin-5.webp)\n\n6.  In the **Configuration** tab, enter the settings as shown in the following image:\n\n[![SAML app configuration](https://www.rudderstack.com/docs/images/user-guides/onelogin-6.webp)](https://www.rudderstack.com/docs/images/user-guides/onelogin-6.webp)\n\nThe settings to be configured are listed in the following table:\n\n| Setting | Value |\n| --- | --- |\n| Audience (EntityID) | `urn:amazon:cognito:sp:us-east-1_ABZiTjXia` |\n| Recipient | `https://auth2.rudderstack.com/saml2/idpresponse` |\n| ACS (Consumer) URL Validator | `^https:\\/\\/auth2\\.rudderstack\\.com\\/saml2\\/idpresponse\\/\\$` |\n| ACS (Consumer) URL | `https://auth2.rudderstack.com/saml2/idpresponse` |\n| Login URL | `https://app.rudderstack.com/sso?domain=[your-domain.com]` |\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Make sure you enter the correct domain name in the **Login URL** setting. For example, if your employee email is `john@example.com`, then your **Login URL** will be `https://app.rudderstack.com/sso?domain=example.com`.\n\n7.  From the dropdown, select the **SAML initiator** and **SAML nameID format** fields as shown:\n\n[![SAML settings](https://www.rudderstack.com/docs/images/user-guides/onelogin-7.webp)](https://www.rudderstack.com/docs/images/user-guides/onelogin-7.webp)\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> Configure the other SAML settings related to the assertion validity, encryption method, etc. as per your organizational requirements.\n\n8.  Next, go to the **Parameters** tab and add the custom parameters as shown below:\n\n[![Custom parameters](https://www.rudderstack.com/docs/images/user-guides/onelogin-8.webp)](https://www.rudderstack.com/docs/images/user-guides/onelogin-8.webp)\n\nThe custom parameters and their values are listed in the following table:\n\n| Parameter | Value |\n| --- | --- |\n| Email | `Email` |\n| LastName | `Name` |\n| NameID value | `Email` |\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> For the **LastName** custom attribute, you can specify a single field `Name` - which specifies how you would like to see your employees on the RudderStack web app.\n\n9.  To add any other custom parameter, click the **+** button, enter the **Field name**, and select the value from the dropdown:\n\n[![Custom parameter configuration](https://www.rudderstack.com/docs/images/user-guides/onelogin-9.webp)](https://www.rudderstack.com/docs/images/user-guides/onelogin-9.webp)\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Make sure you enable (tick) the **Include in SAML assertion** flag for each custom parameter.\n\n10.  Click **Save** to save the configuration.\n\n## Enabling SSO\n\nGo to the **SSO** tab of your app and copy the **Issuer URL**:\n\n[![Issuer URL](https://www.rudderstack.com/docs/images/user-guides/onelogin-10.webp)](https://www.rudderstack.com/docs/images/user-guides/onelogin-10.webp)\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> The **Issuer URL** is the SAML metadata endpoint that contains the certificate and any other information required to enable SSO for your organization.\n\nShare this **Issuer URL** with the RudderStack team.\n\n## Debugging\n\nThere are times when an SSO login might fail for some users due to some reason. In such cases, the RudderStack team requires a HAR (HTTP Archive) file to inspect the requests and identify any SSO-related issues.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> A HAR file is a log of exported network requests from the user’s browser. See the [HAR Analyzer](https://toolbox.googleapps.com/apps/har_analyzer/) guide for steps on generating this file depending on your browser.\n\nOnce you generate the HAR file, share it with the [RudderStack team](mailto:support@rudderstack.com) to troubleshoot the issue.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Note the following before capturing your HAR file:\n> \n> *   Start from `https://app.rudderstack.com/sso` with a clean session, preferably in incognito mode of your browser.\n> *   Complete the SSO flow until the step where you face an error.\n> *   Your HAR file might contain sensitive data - make sure to redact it using a text editor before sharing it with the team.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "OneLogin SSO setup | RudderStack Docs",
    "description": "Set up the RudderStack SSO (Single Sign-On) feature with OneLogin.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/user-guides/administrators-guide/config-parameters/",
    "markdown": "# Configuration parameters | RudderStack Docs\n\nVarious types of configuration parameters explained with their types, descriptions, and default values\n\n* * *\n\n*     8 minute read  \n    \n\nThis document describes the various configuration parameters for the [`config.yaml`](https://github.com/rudderlabs/rudder-server/blob/master/config/config.yaml) file. You can fine-tune them to suit your application’s needs.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> These configuration parameters are also applicable for the `config.toml` file, in case you have an older RudderStack deployment.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> To best understand some of the terms covered in this guide, we recommend going through the [RudderStack Architecture](https://www.rudderstack.com/docs/resources/rudderstack-architecture/) first.\n\n## Global Parameters\n\n| Parameter name | Type | Description | Default value |\n| --- | --- | --- | --- |\n| `maxProcess` | Int | Number of parallel threads used in server. Should be set to number of cores. | `12` |\n| `gwDBRetention` | String | The time for which the events are stored in the Gateway database after they have been processed. Examples: `1h`, `30m`, `35s`, etc. | `0h` |\n| `routerDBRetention` | String | The time for which the events are stored in the Router database after they have been processed. Examples: `1h`, `30m`, `45s`, etc. | `0h` |\n| `enableProcessor` | Boolean | This variable enables or disables the Processor module. It will be set to `false` when running in [Degraded mode](https://www.rudderstack.com/docs/user-guides/administrators-guide/high-availability/#rudderstack-server-running-modes). | `true` |\n| `enableRouter` | Boolean | This variable enables or disables the Router module. Will be set to `false` when running in [Degraded mode](https://www.rudderstack.com/docs/user-guides/administrators-guide/high-availability/#rudderstack-server-running-modes). | `true` |\n| `enableStats` | Boolean | This variable enables or disables stats. | `true` |\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> For more information on the Processor, Gateway, and Router modules of the RudderStack backend, refer to the [RudderStack Architecture](https://www.rudderstack.com/docs/resources/rudderstack-architecture/).\n\n## \\[Gateway\\]\n\n| Parameter name | Type | Description | Default value |\n| --- | --- | --- | --- |\n| `webPort` | Int | The port on which the RudderStack server runs. | `8080` |\n| `maxUserWebRequestWorkerProcess` | Int | RudderStack spawns this specified number of processes to consume the events at a user level. | `64` |\n| `maxDBWriterProcess` | Int | As requests come in to the Gateway and are batched, RudderStack runs the `maxDBWriterProcess` writers to send these batches to the database and the Configuration Backend. | `256` |\n| `CustomVal` | String | For the creation of a job in the backend PostgreSQL database (jobsDB), the value of this variable will be assigned to the `CustomVal` column. | `GW` |\n| `maxBatchSize` | Int | The batch size used in the Gateway. The requests are batched up to this size before writing to the database. | `32` |\n| `batchTimeout` | String | In case the request batches do not meet the `maxBatchSize`, the batches are are sent to the database and the Configuration Backend in this interval. | `20ms` |\n| `maxReqSizeInKB` | Int | An error message (\"**Request size exceeds max limit**\") is thrown for a particular request is when its size in KB crosses this value\\*.\\* | `4000` |\n| `enableDedup` | Boolean | Enables or disables deduplication of events. RudderStack uses `message_id` to de-dup. The duplicate events are dropped at the Gateway. | `false` |\n| `dedupWindow` | String | Events with the same `message_id` within this timeframe are considered duplicate and are dropped. | `3600s` |\n| `enableRateLimit` | Boolean | Rate limits the number of requests accepted by the Gateway. This is used for running the RudderStack-hosted service. | `false` |\n\n## \\[SourceDebugger\\]\n\n| Parameter name | Type | Description | Default value |\n| --- | --- | --- | --- |\n| `disableEventUploads` | Boolean | Enables or disables the event schema upload. | `false` |\n| `maxBatchSize` | Int | The maximum size of the live events batch sent to the Configuration Backend. | `32` |\n| `maxESQueueSize` | Int | The maximum size of the live events queue in the memory. | `1024` |\n| `maxRetry` | Int | The maximum number of attempts RudderStack makes to upload the request batches, in case of any errors. | `3` |\n| `batchTimeout` | String | In case the request batches do not meet the `maxBatchSize`, the request batches are uploaded to Configuration Backend in this time interval. | `2s` |\n| `retrySleep` | String | In case of errors while uploading the request batches, RudderStack waits for this time interval before retrying. This is done until the `maxRetry` limit is reached. | `100ms` |\n\n## \\[JobsDB\\]\n\n| Parameter name | Type | Description | Default value |\n| --- | --- | --- | --- |\n| `jobDoneMigrateThres` | Float64 | If (`deletedJobsCount` / `totalJobsCount`) >{\" \"} `jobDoneMigrateThres`, RudderStack migrates the table of the jobs that have been processed. | `0.8` |\n| `jobStatusMigrateThres` | Float64 | If (`statusCount` / `totalCount`) > `jobStatusMigrateThres`,<br><br>RudderStack migrates the table of jobs that have been processed. | `5` |\n| `maxDSSize` | Int | The maximum size of a table. If the maximum size is reached, RudderStack migrates all jobs in that table. | `100000` |\n| `maxMigrateOnce` | Int | The maximum number of tables that can be migrated together. | `10` |\n| `maxTableSizeInMB` | Int | The maximum size of the tables in MB. The tables are migrated if they cross this limit. | `300` |\n| `migrateDSLoopSleepDuration` | String | The time RudderStack waits before migrating the datasets. | `30s` |\n| `maxMigrateDSProbe` | Int64 | The maximum number of tables probed to find if they can be migrated. | `10` |\n| `addNewDSLoopSleepDuration` | String | The time RudderStack waits before adding a dataset. | `5s` |\n| `backupCheckSleepDuration` | String | RudderStack waits for this time interval before checking if a dataset needs backing up. | `5s` |\n| `enableBackup` | Boolean | Enables or disables the backup. This is set to `false` in the \\[Degraded\\](https://www.rudderstack.com/docs/user-guides/administrators-guide/high-availability/#rudderstack-server-running-modes) mode. | `true` |\n\n## \\[Router\\]\n\n| Parameter name | Type | Description | Default value |\n| --- | --- | --- | --- |\n| `jobQueryBatchSize` | Int | The size of a jobs batch to get from the database. This includes the retry list, processing list, unprocessed list, or executed list. | `10000` |\n| `updateStatusBatchSize` | Int | The minimum size needed to update the status of a batch of jobs. | `1000` |\n| `readSleep` | String | The time RudderStack waits before fetching the next jobs batch from the database, in case the length of unprocessed and retry list is 0. | `1000ms` |\n| `noOfWorkers` | Int | RudderStack starts this number of workers to send events to the destinations. | `64` |\n| `noOfJobsPerChannel` | Int | The number of jobs a channel in each worker can contain. | `1000` |\n| `maxSleep` | String | The time to wait when the response status code is not **200**. This is to give RudderStack some time before the next retry. | `60s` |\n| `minSleep` | String | The time to sleep when the response status code is **200**. | `0s` |\n| `maxStatusUpdateWait` | String | The time to sleep before ending one round of stats collection. | `5s` |\n| `useTestSink` | Boolean | Runs internal tests if set to `true`. | `false` |\n| `maxFailedCountForJob` | Int | The maximum number of times a job can fail before it is marked as aborted. | `8` |\n| `guaranteeUserEventOrder` | Boolean | RudderStack maintains the order of user events if set to `true`. | `true` |\n| `retryTimeWindow` | String | The minimum retry window in case of **5XX**, **429** errors. | `180m` |\n| `minRetryBackoff` | String | The minimum time before the next retry in case of **5XX**, **429** errors. | `10s` |\n| `maxRetryBackoff` | String | The maximum allowed time between the errors in case of **5XX**, **429** errors. | `300s` |\n\n## \\[BatchRouter\\]\n\n| Parameter name | Type | Description | Default value |\n| --- | --- | --- | --- |\n| `mainLoopSleep` | String | The timeout while running the main loop. | `2s` |\n| `noOfWorkers` | Int | The number of workers to batch jobs before deletion. | `8` |\n| `jobQueryBatchSize` | Int | The number of events picked up from the batch router’s database (Jobs DB) in each query. | `100000` |\n| `uploadFreq` | String | The frequency with which the batch router dumps the events to the storage destinations. | `30s` |\n| `maxFailedCountForJob` | Int | The maximum number of times a job can fail before marking it as aborted. | `128` |\n\n## \\[Warehouse\\]\n\n| Parameter name | Type | Description | Default value |\n| --- | --- | --- | --- |\n| `stagingFilesTable` | String | Table name of the staging files. | `wh_staging_files` |\n| `loadFilesTable` | String | Table name of load files. | `wh_load_files` |\n| `uploadsTable` | String | Table name of uploads. | `wh_uploads` |\n| `schemasTable` | String | Table name of schemas. | `wh_schemas` |\n| `uploadFreq` | String | The frequency of the upload in seconds. | `1800s` |\n| `noOfWorkers` | Int | Number of concurrent writes to the warehouse. | `8` |\n| `mainLoopSleep` | String | The time RudderStack waits between multiple warehouse writes. | `5s` |\n| `stagingFilesBatchSize` | Int | The batch size of the staging files. | `960` |\n\n## \\[Processor\\]\n\n| Variable name | Type | Description | Default value |\n| --- | --- | --- | --- |\n| `loopSleep` | String | In case the length of the user jobs process queue is 0 or the unprocessed and retry list is empty, RudderStack sleeps for this specified time. | `10ms` |\n| `maxLoopSleep` | String | Maximum loop sleep time for the Processor. | `5000ms` |\n| `dbReadBatchSize` | Int | The total number of events to get as a batch from the database. | `10000` |\n| `transformBatchSize` | Int | Batch size of the events added to the request queue before sending them for transformation. | `100` |\n| `userTransformBatchSize` | Int | Batch size of the events added to request queue before sending them to the custom transformation server. **NOTE**: This is used only when a user transformation function is connected to a destination. | `200` |\n| `sessionThresholdEvents` | Int | The minimum number of events needed to be process further. | `20` |\n| `sessionThreshold` | String | The minimum time needed before a new session is created. | `10s` |\n| `maxChanSize` | Int | The maximum channel size for the request and response queue in the transformer. | `2048` |\n| `processSessions` | Boolean | If set to `true`, the status of the job in the database is updated. | `false` |\n| `numTransformWorker` | Int | Specifies the number of Go transform workers. | `8` |\n| `maxRetry` | Int | The maximum number of times a transformer retries hitting the API in case of an error. | `30` |\n| `retrySleep` | String | The sleep time in case of a transformer error while hitting the API, before retrying. | `100ms` |\n\n## \\[BackendConfig\\]\n\n| Variable name | Type | Description | Default value |\n| --- | --- | --- | --- |\n| `pollInterval` | String | The frequency of updating data from the Configuration Backend. | `5s` |\n| `configFromFile` | Boolean | When set to `true`, RudderStack reads the backend workspace configuration from a JSON file instead of fetching it from the API. | `false` |\n| `configJSONPath` | String | The path of the JSON file which contains the backend workspace configuration. | `/etc/rudderstack /workspaceConfig.json` |\n\n## \\[RateLimit\\]\n\n| Variable name | Type | Description | Default value |\n| --- | --- | --- | --- |\n| `eventLimit` | Int64 | The maximum number of events to be allowed in a time interval. | `1000` |\n| `rateLimitWindow` | String | The rolling time interval used to limit the allowed number of events. | `60m` |\n| `noOfBucketsInWindow` | Int32 | The number of buckets `rateLimitWindow` is broken down into. | `12` |\n\n## \\[Diagnostics\\]\n\n| Parameter name | Type | Description | Default value |\n| --- | --- | --- | --- |\n| `enableDiagnosis` | Boolean | RudderStack sends the server diagnostics report to the user. Disabling this will disable sending all diagnostics information. | `true` |\n| `gatewayTimePeriod` | String | The time interval to send the Gateway requests report | `60s` |\n| `routerTimePeriod` | String | The time interval to send the Router requests report. | `60s` |\n| `batchRouterTimePeriod` | String | The time interval to send the Batch router requests report. | `10m` |\n| `enableServerStartMetric` | Boolean | Sends the server start event. | `true` |\n| `enableConfigIdentifyMetric` | Boolean | Sends the workspace config received event. | `true` |\n| `enableServerStartedMetric` | Boolean | Sends the successful server start event. | `true` |\n| `enableConfigProcessedMetric` | Boolean | Sends the workspace config details. | `true` |\n| `enableGatewayMetric` | Boolean | Sends the Gateway request metrics. | `true` |\n| `enableRouterMetric` | Boolean | Sends the Router request metrics. | `true` |\n| `enableBatchRouterMetric` | Boolean | Sends the Batch Router request metrics. | `true` |\n| `enableDestinationFailuresMetric` | Boolean | Sends the destination failures metrics. | `true` |\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Configuration parameters | RudderStack Docs",
    "description": "Various types of configuration parameters explained with their types, descriptions, and default values",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/user-guides/administrators-guide/admin-troubleshooting-guide/",
    "markdown": "# Troubleshooting guide | RudderStack Docs\n\nQuick solutions to the common and not-so-common problems you are likely to encounter as an admin while using RudderStack\n\n* * *\n\n*     4 minute read  \n    \n\nThis section contains solutions to some of the commonly faced issues you are likely to encounter as an Admin.\n\n## The SDK returns success, but I don’t see any events in my destination. What **should I do?**\n\n1.  Check if the server is running in _normal_ mode in the file `/data/rudderstack/recovery_data.json` or `/tmp/recovery_data.json`.\n2.  If the server is in “degraded” or “maintenance” mode, RudderStack just stores the events and will not process them.\n\n## My Data Plane does not start. What should I do?\n\n1.  Check if you have provided the right backend token\n2.  Check if the Control Plane is up ([https://api.rudderlabs.com/health](https://api.rudderlabs.com/health))\n\n## I can’t access the Control Plane. What should I do?\n\nCheck your internal firewall rules and edit if needed. You need access to outbound HTTP.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> If the control plane is accessible from your network but is down, we are already working to fix it. Do leave us a note.\n\n## All the destinations receive events except a few. What should I do?\n\n1.  Check if those destination are enabled in Control Plane\n2.  Verify that the config parameters such as API key, tracking ID, etc. are correct\n\n## Events are lagging in the destination. What should I do?\n\n1.  There is a possibility that a destination service (Google Analytics, S3, etc.) is down.\n2.  Check the number of pending gateway tables (tables that start with `gw_`), router tables (tables that start with `rt_`), and batch router tables (tables that start with `batch_rt_`_)._\n3.  If the number for any of the above possibilities is high (> 5), then we have incoming requests at a higher rate than what we can process. Consider adding another RudderStack node if possible.\n4.  If you have access to RudderStack Enterprise edition, check out the Grafana dashboards.\n\n## RudderStack has entered the degraded mode. What should I do?\n\nWhen RudderStack enters “degraded” mode, it will only log the event and not process the event. If the issue why the server entered the degraded mode is temporary (Transformer is down), then fix the issue and restart the server in the normal mode.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> You can restart the server in the normal mode by updating the `/data/rudderstack/recovery_data.json` or `/tmp/recovery_data.json` and setting the Mode to “normal”.\n\n## RudderStack has entered the maintenance mode. What should I do?\n\nWhen RudderStack enters “maintenance” mode, we take a back up of the old database and create a new database in the “degraded” mode. RudderStack will only log the event and not process the event in this case. If the issue is fixed, start another instance of RudderStack server in normal mode but in a different port (say 8081) pointing to the old DB. That will drain all events in the old DB.  \nThen restart the actual server in the normal mode by updating the `/data/rudderstack/recovery_data.json` or `/tmp/recovery_data.json`. Set the mode to “normal”_._ It will resume routing pending events and the ordering of the events is guaranteed.\n\n## The disk usage is increasing. What should I do?\n\nCheck if your system is in the **degraded** or **maintenance** mode. This could result in only logging the events and not processing them. If needed, increase the storage capacity of your machine till there are no issues in the disk usage.\n\n## The memory usage keeps increasing. What should I do?\n\nIdeally, this should not happen. Restarting the service is recommended in such a scenario.  \nIf you have sessions enabled, RudderStack caches the session information. Please configure `sessionThreshold` and `sessionEvents` in [`config.yaml`](https://github.com/rudderlabs/rudder-server/blob/master/config/config.yaml).\n\n## Gateway tables are not getting dumped\n\n*   If there are tables that start with _\\`\\`_\\`pre_drop\\`\\`\\`_ but if you don’t see them being removed, verify the access credentials to your object storage like S3.\n*   If you have multiple instances of Data Plane, each table dump will be inside a specific folder named after the `INSTANCE_NAME`.\n\n## How do I check the health of RudderStack daily?\n\n1.  If you have access to RudderStack Enterprise, you already have a visualization of the RudderStack server metrics at your disposal for tracking the health of your server.\n2.  Ensure that the number of`jobsDB` tables is not increasing.\n3.  Verify that the server mode is **normal**.\n\n## How do I enable debug logging?\n\nEnable debug logging by setting the following variable in your `.env` file as shown:\n\n```\nLOG_LEVEL=DEBUG\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> For any other issues that you might encounter, please feel free to [contact us](https://rudderstack.com/contact/).\n\n## How to fix the HTTP connection errors?\n\nWe recommend the following configuration for the production deployments. On a Linux machine, add the following lines to `/etc/sysctl.conf`:\n\n```\nnet.ipv4.tcp_max_tw_buckets = 65536\nnet.ipv4.tcp_tw_recycle = 1\nnet.ipv4.tcp_tw_reuse = 0\nnet.ipv4.tcp_max_syn_backlog = 131072\nnet.ipv4.tcp_syn_retries = 3\nnet.ipv4.tcp_synack_retries = 3\nnet.ipv4.tcp_retries1 = 3\nnet.ipv4.tcp_retries2 = 8\nnet.ipv4.tcp_rmem = 16384 174760 349520\nnet.ipv4.tcp_wmem = 16384 131072 262144\nnet.ipv4.tcp_mem = 262144 524288 1048576\nnet.ipv4.tcp_max_orphans = 65536\nnet.ipv4.tcp_fin_timeout = 10\nnet.ipv4.tcp_low_latency = 1\nnet.ipv4.tcp_syncookies = 0\n```\n\nIf your system is hitting TCP limits and returning HTTP errors, the above configuration will help.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Troubleshooting guide | RudderStack Docs",
    "description": "Quick solutions to the common and not-so-common problems you are likely to encounter as an admin while using RudderStack",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/dashboard-guides/destinations/",
    "markdown": "# Destinations | RudderStack Docs\n\nPrivacy Overview\n\nThis site uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are as essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.\n\nNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.",
    "title": "Destinations | RudderStack Docs",
    "description": "Add a destination in RudderStack Cloud.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/user-guides/administrators-guide/high-availability/",
    "markdown": "# High availability | RudderStack Docs\n\nLearn about RudderStack’s high-availability methodologies.\n\n* * *\n\n*     3 minute read  \n    \n\nAny service can go down because of a hardware failure or a software bug. This document explains the engineering design and the deployment model that makes RudderStack highly available despite any failures or bugs.\n\n## Hardware Failures\n\nWe leverage Kubernetes and auto-scaling groups to handle hardware failures and stay highly available.\n\nTo recover from node failures, we recommend provisioning the nodes with an auto-scaling group.\n\nThis is how a standard RudderStack production deployment looks like:\n\n[![](https://www.rudderstack.com/docs/images/rudderstack2x_-7-.webp)](https://www.rudderstack.com/docs/images/rudderstack2x_-7-.webp)\n\n### Deploying RudderStack in a Single Availability Zone\n\nIf the node hosting RudderStack goes down, Kubernetes will automatically schedule it on another available node. If you have an auto-scaling group and Kubernetes is not able to schedule RudderStack, a new node is created and RudderStack is scheduled.\n\n[![](https://www.rudderstack.com/docs/images/rudderstack2x_-9-.webp)](https://www.rudderstack.com/docs/images/rudderstack2x_-9-.webp)\n\nSingle Availability Zone\n\nThis is equivalent to the standard High Availability setup where an infrastructure team creates an extra backup node to switch the master using a heartbeat mechanism.\n\n### Deploying RudderStack in Multiple Availability Zones\n\nThere could be instances of data center failures, where a complete availability zone can go down. If you want RudderStack to be resilient to such failures, your Kubernetes cluster should span multiple availability zones.\n\n[![](https://www.rudderstack.com/docs/images/rudderstack2x_-11-.webp)](https://www.rudderstack.com/docs/images/rudderstack2x_-11-.webp)\n\nMultiple Availability Zones\n\n## Software Failures\n\nRudderStack can switch between different running modes to stay resilient in case of software failures.\n\nIf RudderStack is not available, our web and mobile SDKs cache the events on the customer device and retry till they are delivered to the RudderStack server.\n\n### RudderStack Server Running Modes\n\nRudderStack supports two running modes - **normal and degraded**\n\n#### Normal Mode\n\nIn the normal mode, RudderStack receives events and forwards them to the destinations as usual.\n\n[![](https://www.rudderstack.com/docs/images/rudderstack2x_-12-.webp)](https://www.rudderstack.com/docs/images/rudderstack2x_-12-.webp)\n\nNormal Mode\n\n#### Degraded Mode\n\nIf RudderStack keeps crashing while processing the events, it enters the degraded mode after a threshold number of restarts is reached.\n\nIn the degraded mode, RudderStack receives events and stores them. It will not forward to destinations.\n\n[![](https://www.rudderstack.com/docs/images/rudderstack2x_-13-%20%281%29%20%281%29%20%281%29%20%281%29%20%281%29%20%281%29%20%281%29.webp)](https://www.rudderstack.com/docs/images/rudderstack2x_-13-%20%281%29%20%281%29%20%281%29%20%281%29%20%281%29%20%281%29%20%281%29.webp)\n\nDegraded Mode\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> In this mode, all your events are completely safe and will be sent to destination maintaining the order.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> If RudderStack crashes in degraded mode, we request you to send us the crash reports to identify and fix the issue.\n\n## Alerting in RudderStack\n\nRudderStack has an in-built alerting service that will raise an alert when the server enters `degraded` mode. The alerting service supports integrations with PagerDuty and VictorOps. You can configure this to be alerted when an unexpected issue occurs with the RudderStack server.\n\n## Client SDK Caching\n\nThere may arise a scenario where the RudderStack service is down because of an unexpected issue, and is not reachable for the SDKs. In such a situation, the web and the mobile SDKs will then cache the events in the local storage. The pending events will be retried with a backoff and delivered once the service is available again.\n\nEven during an unexpected downtime, all your events are safe and will be delivered to your destinations without fail.\n\n[![](https://www.rudderstack.com/docs/images/rudderstack2x_-6-.webp)](https://www.rudderstack.com/docs/images/rudderstack2x_-6-.webp)\n\nDowntime Scenario\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "High availability | RudderStack Docs",
    "description": "Learn about RudderStack's high-availability methodologies.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/user-guides/administrators-guide/rudderstack-grafana-dashboard/",
    "markdown": "# Grafana dashboard | RudderStack Docs\n\nDashboard options for better observability and performance monitoring of your RudderStack setup.\n\nAvailable Plans\n\n*   starter\n*   growth\n*   enterprise\n\n* * *\n\n*     7 minute read  \n    \n\nRudderStack’s Grafana dashboard gives you detailed insights into your RudderStack server’s performance. You get a real-time view of the events sent and received by RudderStack along with various metrics like RudderStack’s performance under load, errors encountered while processing events, event delivery statistics, and more.\n\nThis guide explains the various Grafana dashboard options and performance metrics in detail.\n\n## Set up Grafana dashboard\n\n[Contact your Customer Success Manager](mailto:support@rudderstack.com) to enable the Grafana dashboard for your RudderStack account and for any assistance in the setup.\n\n## Terminology\n\nThis section covers some standard terms you are likely to see when using the Grafana dashboard:\n\n| Term | Description |\n| --- | --- |\n| Warehouse | Data warehouses like Redshift, BigQuery, Snowflake, PostgreSQL, etc. - which RudderStack currently supports. |\n| Batch router | Object storage destinations like Amazon S3, Google Cloud Storage, Azure Blob Storage, MinIO, and DigitalOcean Spaces - which RudderStack currently supports. |\n| Router | All the connected destinations other than the two categories mentioned above. |\n| User transformation | RudderStack’s [Transformations](https://www.rudderstack.com/docs/transformations/overview/) feature which lets you enrich real-time events using custom JavaScript functions. |\n| Destination transformation | RudderStack’s internal service which transforms the event payload into a destination-specific format. |\n| Gateway | RudderStack’s internal service responsible for ingesting the incoming events. |\n| Processor | RudderStack’s internal service responsible for processing new events, applying user transformations, and destination transformations. |\n\n## Dashboard overview\n\nRudderStack’s Grafana dashboard gives insight into the total number of requests and the events received and delivered via RudderStack.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> RudderStack stores all the performance metrics in InfluxDB where Grafana queries them and gives you a detailed visual overview.\n\nThe following video explains the different dashboard options in detail:\n\n### Received requests\n\nNumber of HTTP requests RudderStack has received in the selected time period.\n\n### Received events\n\nNumber of events RudderStack has received in the selected time period. You can batch multiple events in a [single HTTP request](https://www.rudderstack.com/docs/api/http-api/#batch).\n\n### Delivered events\n\nNumber of events RudderStack has delivered across all destinations during the selected time period.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> If you have set up a warehouse destination in RudderStack, each event is delivered to two different tables in the warehouse and counted as two delivered events.\n\n## Gateway\n\n[![Gateway](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/gateway.webp)](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/gateway.webp)\n\n### Gateway requests\n\nNumber of requests HTTP requests RudderStack has received across all sources in the selected time period. You can find the details of an individual source in the **Gateway Detailed** section of the dashboard.\n\n### Proxy responses\n\nRudderStack has a reverse proxy in front of the RudderStack nodes. This panel lists all HTTP response codes. You can find a `4xx` status if the requests are invalid and a `5xx` status if the service is down or has encountered an internal error.\n\n### Request latency\n\nRudderStack stores the events are stored in the gateway (PostgreSQL) and acknowledges them. RudderStack lists the time to acknowledge these HTTP requests with 99 percentile, 95 percentile, and mean times.\n\n### Gateway throughput\n\nRudderStack’s processor module picks events from the gateway for further processing. If `Input Requests` > `Output Requests` then the inflow is higher than what the processor can handle.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> This scenario usually occurs during a sudden traffic surge but syncs over some time. However, if the event inflow is consistently higher, **consider adding an extra RudderStack node**.\n\n## Event delivery\n\n[![Event delivery](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/event-delivery.webp)](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/event-delivery.webp)\n\n### Events delivered - batch router\n\nNumber of events delivered to the object storage destinations.\n\n### Events delivered - warehouse\n\nNumber of events delivered to the data warehouse destinations.\n\n### Events delivered - router\n\nNumber of events delivered to all other destinations except object storage and warehouse destinations.\n\n## Event delivery time\n\n[![Event delivery time](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/event-delivery-time.webp)](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/event-delivery-time.webp)\n\n### Event delivery time - batch router\n\nAverage time taken for delivering events to the object storage destinations. RudderStack batches events every 30 seconds (default value), so this is the least time taken to batch and deliver the events.\n\n### Events sync lag time - warehouse\n\nHighlights the largest sync delay for delivering events to the warehouse destination. RudderStack batches events every 30 minutes (default value) before uploading to the data warehouse, so the delivery takes at least this much batching period.\n\nThis metric reports the lag for the oldest event in a batch. For example, if the batching period is `30 mins` and the reported lag time is `50 mins`, then the average lag time would be `50 - \\(30/2\\) = 35 mins`.\n\n### Event delivery time - router\n\nAverage time taken to deliver events to all other destinations except object storage and warehouse destinations.\n\n## Processor\n\n[![Processor](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/processor.webp)](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/processor.webp)\n\n### Active processed destinations\n\nIncludes the list of all active destinations within the selected time window. The destination includes first 15 characters of the destination name and last 6 characters of RudderStack’s internal destination ID.\n\n### Processor events\n\nThis dashboard highlights how input events are multiplexed into destination-specific events.\n\n[![Processor events](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/processor-events.webp)](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/processor-events.webp)\n\n### Destination processing events\n\nNumber of events generated by the processor per destination.\n\n### Destination processing times\n\nTime taken to generate destination events. Note that these events are not sent to the destinations at this stage.\n\n### Errors\n\n[![Destination processing times](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/destination-processing-times.webp)](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/destination-processing-times.webp)\n\nIndicates the number of errors RudderStack encountered during the transformations. Possible reasons are missing mandatory fields for a specific destination, invalid event types, erroneously high number of event properties for warehouse destinations, etc.\n\n## Router throughput\n\n[![Router throughput](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/router-throughput.webp)](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/router-throughput.webp)\n\n### Router throughput - <destination\\_type>\n\nThe router picks the transformed events ready to be sent to the destinations and then forwards them to the destinations. If a destination is down for some time, it retries up to a configured time window (default value being 3 hours). If IN > OUT (refer to the second graph in the image above), there would be a delay in delivering the events. Some possible reasons are a sudden surge of events or that the destination is slow in accepting new event requests.\n\n### Router responses\n\nIndicates all destination HTTP responses grouped by status code.\n\n### Router failures\n\nHighlights metrics on the failures and retries before the event is delivered. If the event keeps failing even after a configured window, then RudderStack marks it as aborted. The aborted events are also shown in this panel.\n\n## Warehouse\n\nRudderStack runs the warehouse uploads as scheduled in the configuration. If there is no defined schedule, it runs the uploads every 30 minutes and the batched data is loaded into the warehouse.\n\n[![Warehouse uploads](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/warehouse-uploads.webp)](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/warehouse-uploads.webp)\n\n### Uploads\n\nThe upload status of every batch is shown in the dashboard panel. If an upload keeps failing, RudderStack marks it as **aborted** after 3 hours. Possible reasons for failure are insufficient warehouse permissions to create and write to tables, reaching column limit on a specific table, warehouse down for maintenance, etc.\n\n### Events delivered - warehouse\n\nNumber of events delivered to the warehouse destinations plotted against the time when RudderStack completed the upload.\n\n[![Events delivered to warehouse](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/events-delivered-warehouse.webp)](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/events-delivered-warehouse.webp)\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Note that:\n> \n> *   RudderStack syncs a `track` event name named `user_logged_in` to the `tracks` and `user_logged_in` tables. See [Warehouse schema](https://www.rudderstack.com/docs/destinations/warehouse-destinations/warehouse-schema/) for more details. Similarly, RudderStack syncs the `identify` events to the `identifies` and `users` tables. **Since each event is being synced to two tables, number of synced rows is generally twice the number of events**.\n> *   If an event property does not match the data type in the corresponding warehouse table, RudderStack does not sync that column into the actual table but moves it to the `rudder_discards` table. See [how RudderStack handles data type mismatch](https://www.rudderstack.com/docs/destinations/warehouse-destinations/warehouse-schema/#how-rudderstack-handles-data-type-mismatch) for more details.\n\n### Synced rows\n\nNumber of new rows created in the `grouped by` table during warehouse uploads. In the example above, if there are different event names (for example, `user_logged_in`, `user_signed_up` ) RudderStack groups them all under **`others`** in the metrics.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> If there are a lot of synced rows in the `rudder_discards` table, the data type may not be consistent in your sources. It is recommended to check such entries and fix the issue.\n\n### Events sync lag time - warehouse\n\nLongest sync delay for delivering events to your warehouse destination. RudderStack batches events every 30 minutes (default value) before uploading to your data warehouse, so the delivery takes at least that much batching time. This panel reports the lag for the oldest event in a batch. For example, if the batching period is `30 min` and the reported lag time is `50 min`, then the average lag time would be `50 - \\(30/2\\) = 35 min`.\n\n## JobsDB\n\n[![JobsDB](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/jobsdb.webp)](https://www.rudderstack.com/docs/images/user-guides/grafana-dashboard/jobsdb.webp)\n\n### JobsDB tables count\n\nSize of the internal queue that RudderStack maintains for routing events. There are three such queues named **gateway** (`gw`), **router** (`rt`) and **batch router** (`batch_rt`).\n\nRudderStack processes events from these queues. If the queue size keeps increasing, it implies that the event outflow is less than inflow.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> For real-time deliveries, maintain queue size at 1 or 2.\n\n## Set up alerts in Grafana\n\nYou can use the Grafana dashboard to set up time-critical alerts for various use cases like:\n\n*   Aborted/failed events to destinations\n*   Event volume spikes crossing a defined threshold.\n\nThe following video tutorial walks you through setting up and enabling alerts in your Grafana dashboard:\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Grafana dashboard | RudderStack Docs",
    "description": "Dashboard options for better observability and performance monitoring of your RudderStack setup.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/dashboard-guides/audit-logs/",
    "markdown": "# Audit Logs | RudderStack Docs\n\nTrack user activities in your RudderStack workspace.\n\nAvailable Plans\n\n*   enterprise\n\n* * *\n\n*     3 minute read  \n    \n\nRudderStack offers the **Audit Logs** feature to track user activities within your RudderStack workspace, like creating or modifying sources and destinations, transformations, implementing Multi-Factor Authentication (MFA), and more.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The Audit Logs feature is available for only in the RudderStack Cloud [Enterprise](https://rudderstack.com/enterprise-quote) plan.\n\n## Accessing the audit logs\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The workspace-related audit logs can only be accessed by the users having [admin permissions](https://www.rudderstack.com/docs/dashboard-guides/user-management/#organization-roles).\n\nYou can access the workspace-related audit logs by going to **Settings** > **Workspace** > **Audit Logs**:\n\n[![Audit Logs](https://www.rudderstack.com/docs/images/rs-cloud/audit-logs.webp)](https://www.rudderstack.com/docs/images/rs-cloud/audit-logs.webp)\n\nFor the audit logs related to a specific source or destination, go to the source/destination details page and click the **Audit Logs** option:\n\n[![Audit Logs details](https://www.rudderstack.com/docs/images/rs-cloud/audit-logs-source.webp)](https://www.rudderstack.com/docs/images/rs-cloud/audit-logs-source.webp)\n\n## Audit logs details\n\nThe audit logs capture the following information:\n\n*   **User**: Name and email of the user in the RudderStack workspace.\n*   **Action**: User action performed on the entity.\n*   **Target**: Entity name, that is, the name assigned to the source, destination, transformation, etc.\n*   **Type**: Entity type, that is, source, destination, transformation, teammate, etc.\n*   **When**: Timestamp when the user action was performed.\n\nThe following sections detail the various user actions captured by the audit logs based on the target type, that is, sources, destinations, transformations, teams, or MFA (multi-factor authentication).\n\n## Source audit\n\n| Action | Description |\n| --- | --- |\n| Created | User created a source in the dashboard. |\n| Updated | User updated the source settings in the dashboard. |\n| Updated Name | User updated the source name in the dashboard. |\n| Deleted | User deleted the source from the dashboard. |\n\n## Destination audit\n\n| Action | Description |\n| --- | --- |\n| Created | User created a destination in the dashboard. |\n| Updated | User updated the destination settings in the dashboard. |\n| Updated Name | User updated the destination name in the dashboard. |\n| Deleted | User deleted the destination from the dashboard. |\n| Connect Source | User connected a source to the destination. |\n| Disconnect Source | User disconnected a source from the destination. |\n| Added Transformation | User added a transformation to the destination. |\n| Deleted Transformation | User removed/disconnected a transformation from the destination. |\n\n## Transformation audit\n\n| Action | Description |\n| --- | --- |\n| Created | User created a new transformation in the dashboard. |\n| Updated | User updated the transformation. |\n| Deleted | User deleted the transformation from the dashboard. |\n\n## Team audit\n\n| Action | Description |\n| --- | --- |\n| Invited | User invited a new user to join the current RudderStack workspace. |\n| Accepted | New user accepted the invitation to join the workspace. |\n| Cancelled | User cancelled the invitation to join the workspace. |\n| Changed Permission | User changed the permissions for a specific user (identified by `userId`) in the workspace. |\n| Deleted | User removed/deleted a user(identified by `userId`) from the workspace. |\n\n## Multi-Factor Authentication (MFA) audit\n\n| Action | Description |\n| --- | --- |\n| Enabled MFA | User enabled MFA for his account. |\n| Disabled MFA | User disabled MFA for his account. |\n| Updated Phonenumber | User updated their phone number used for MFA. |\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Audit Logs | RudderStack Docs",
    "description": "Track user activities in your RudderStack workspace.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/dashboard-guides/live-events/",
    "markdown": "# Live Events | RudderStack Docs\n\nUse the Live Events feature to view your source and destination events in real-time.\n\n* * *\n\n*     4 minute read  \n    \n\nRudderStack’s **Live Events** feature gives you a real-time view of the events flowing from your sources to the connected destinations. You can use this feature for better observability into your events and debug errors in case of any event failures at the destination level.\n\nYou can use this utility to view the following three types of events:\n\n| Live events type | Description |\n| --- | --- |\n| Source live events | View source events collected by RudderStack in real-time. |\n| Destination live events | View events sent to the destination in real-time. |\n| Transformation live events | View transformed events in real-time. |\n\n## Source live events\n\nThis feature provides you with the real-time visibility into the source events collected by RudderStack. You get information like:\n\n*   **Name** of the event\n*   **Type** of the event collected from the source\n*   **Date** and **Time** of the collected event\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> This feature is helpful when you want to verify if your source is correctly configured.\n\n### View source live events\n\n1.  Go to the source for which you want to view the live events.\n2.  Click the **Live events** button.\n\n[![Live Events](https://www.rudderstack.com/docs/images/rs-cloud/source-live-events.webp)](https://www.rudderstack.com/docs/images/rs-cloud/source-live-events.webp)\n\n3.  Once you send the event data from the source to RudderStack, you will be able to see it in the **Live events** window.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Note that:\n> \n> *   It may take a couple of seconds before your events start showing up.\n> *   You can view live events sent up to the past five minutes.\n\n[![Source live events details](https://www.rudderstack.com/docs/images/rs-cloud/source-live-events-details.webp)](https://www.rudderstack.com/docs/images/rs-cloud/source-live-events-details.webp)\n\n## Destination live events\n\nWhen routing events to a destination, there can be instances when the events do not show up in the destination. In such cases, knowing the reason for failure is helpful.\n\nThe **destination live events** feature gives you real-time visibility into your destination’s responses. You get information like:\n\n*   **Name** of the event\n*   **Error message** of the event in case of event failure. It gives the specific details related to an error including the error response and the date and time of the attempt made to send the event.\n*   The **Payload** sent to the destination can be seen by clicking on an event.\n\n### View destination live events\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> You can view live events for cloud mode destinations only, that is, destinations that support sending events via [cloud mode](https://www.rudderstack.com/docs/destinations/rudderstack-connection-modes/#cloud-mode).\n\n1.  Go to the destination for which you want to view the live events.\n2.  Click the **Live events** button.\n3.  Once you send the events from your source to the destination, you will see them in this window.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Note that:\n> \n> *   Live events are shown for all destinations. However, the event payload is not shown for some destination types like the [object storage platforms](https://www.rudderstack.com/docs/destinations/streaming-destinations/#object-storage) and [data warehouses](https://www.rudderstack.com/docs/destinations/warehouse-destinations/).\n> *   It may take a couple of seconds before your events start showing up.\n> *   You can view live events sent up to the past five minutes.\n> *   You can use this view to filter events by source if your destination is connected to multiple sources.\n\n[![Payload to the destination](https://www.rudderstack.com/docs/images/rs-cloud/destination-live-events-details.webp)](https://www.rudderstack.com/docs/images/rs-cloud/destination-live-events-details.webp)\n\n### Use case\n\nSuppose that you send some events to [Facebook Custom Audience](https://www.rudderstack.com/docs/destinations/reverse-etl-destinations/fb-custom-audience/) but they are not delivered. On checking the **Live Events** tab for the **Facebook Custom Audience** destination, you see the following error:\n\n[![Custom Audience destination error](https://www.rudderstack.com/docs/images/rs-cloud/custom-audience-error.webp)](https://www.rudderstack.com/docs/images/rs-cloud/custom-audience-error.webp)\n\nClicking on **See full error** option displays the following error response:\n\n[![Custom Audience full destination error](https://www.rudderstack.com/docs/images/rs-cloud/custom-audience-full-error.webp)](https://www.rudderstack.com/docs/images/rs-cloud/custom-audience-full-error.webp)\n\nAs seen above, an `identify` event is sent to Facebook Custom Audience. The [Custom Audience documentation](https://www.rudderstack.com/docs/destinations/reverse-etl-destinations/fb-custom-audience/) states that RudderStack supports sending only [`audiencelist`](https://www.rudderstack.com/docs/destinations/reverse-etl-destinations/fb-custom-audience/setup-fb-custom-audience/#audiencelist-event-structure) calls.\n\nTherefore, you get an error when RudderStack tries sending the `identify` event to Custom Audience. RudderStack tries sending this event several times before marking it as aborted.\n\n## Transformations live events\n\nYou can also view the live events in case a [transformation](https://www.rudderstack.com/docs/transformations/overview/) is connected to a destination. RudderStack lets you view the events before and after a transformation is applied:\n\n[![Transformation live events](https://www.rudderstack.com/docs/images/rs-cloud/transformation-live-events.webp)](https://www.rudderstack.com/docs/images/rs-cloud/transformation-live-events.webp)\n\nRudderStack also notifies you about any dropped events or errors during the transformation along with the details:\n\n[![Transformation live events error message](https://www.rudderstack.com/docs/images/rs-cloud/transformation-live-events-errors.webp)](https://www.rudderstack.com/docs/images/rs-cloud/transformation-live-events-errors.webp)\n\n## FAQ\n\n#### Why are the events sent to the destination failing?\n\nRouting events to a destination can fail for various reasons. Often, it is due to the incorrect configuration of a destination in the RudderStack dashboard. Some other possible reasons are:\n\n*   Incorrect/bad event payload structure\n*   Rate-limiting by the destination\n*   Network error\n*   Destination downtime\n\nThe [Destination Live Events](#destination-live-events) feature gives you better visibility into how your events are sent to the destination. If there are any delivery failures, the utility also gives you insights into the reasons for the failure.\n\n#### Are live events supported for device mode destinations?\n\nRudderStack does not support the live events functionality for device mode destinations, that is, destinations configured to receive events in [device mode](https://www.rudderstack.com/docs/destinations/rudderstack-connection-modes/#device-mode).\n\nYou can view live events for [cloud mode](https://www.rudderstack.com/docs/destinations/rudderstack-connection-modes/#cloud-mode) destinations only.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Live Events | RudderStack Docs",
    "description": "Use the Live Events feature to view your source and destination events in real-time.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/user-guides/how-to-guides/",
    "markdown": "# How-to Guides | RudderStack Docs\n\nPrivacy Overview\n\nThis site uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are as essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.\n\nNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.",
    "title": "How-to Guides | RudderStack Docs",
    "description": "Reference for different RudderStack use cases.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/dashboard-guides/billings-plans/",
    "markdown": "# Billing and Plans | RudderStack Docs\n\nManage your RudderStack Cloud plan and billing information.\n\nAvailable Plans\n\n*   free\n*   starter\n\n* * *\n\n*     3 minute read  \n    \n\nRudderStack provides an intuitive UI to manage your RudderStack Cloud plan. With the **Billing & plans** feature, you can:\n\n*   Update your RudderStack Cloud plan seamlessly.\n*   Manage your payment and billing contact information.\n*   View past invoices.\n*   Get complete visibility into your purchases, including the pro-rated amount billed for the current month.\n\n## Access billing and plan\n\nGo to **Settings** > **Organization** > **Billing & plans** to access the current billing and payment information and manage your RudderStack Cloud plan.\n\n[![Billing and plans tab](https://www.rudderstack.com/docs/images/dashboard-guides/billings-plans/billings-plans.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/billings-plans/billings-plans.webp)\n\n## Current plan\n\nIn this view, you get a summary of the currently active RudderStack Cloud plan and the monthly event usage. You can also manage your payment and billing contact information by clicking the edit button.\n\nClick the **Invoices** button to view past invoices.\n\n[![Current plan](https://www.rudderstack.com/docs/images/dashboard-guides/billings-plans/current-plan.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/billings-plans/current-plan.webp)\n\n### Payment information\n\nThis option lets you add, remove, and set a default payment method.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Note that:\n> \n> *   You cannot remove the default payment method.\n> *   By providing your card information, you allow RudderStack to charge your card for future payments in accordance with RudderStack’s terms.\n\n[![Payment method](https://www.rudderstack.com/docs/images/dashboard-guides/billings-plans/payment-method.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/billings-plans/payment-method.webp)\n\n### Billing email\n\nThis option lets you update the email address where you will receive all the RudderStack Cloud invoices.\n\n## Manage RudderStack Cloud plan\n\nIn this view, you can update your current RudderStack Cloud plan. You can also compare it with other plans to decide whether your plan suits your event volume and feature requirements.\n\nTo update your RudderStack Cloud plan, choose the relevant plan from the dropdown and select **Update plan**. Alternatively, you can click the **Manage plan** button on the right.\n\n[![Manage plan](https://www.rudderstack.com/docs/images/dashboard-guides/billings-plans/manage-plan.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/billings-plans/manage-plan.webp)\n\nYou can make changes to your RudderStack Cloud plan in this view. You also get the option to set the payment method used for the transaction.\n\nTo confirm your choice, click **Confirm**.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> The updated RudderStack Cloud plan will not come into effect if you do not confirm your choice.\n\n[![Update plan](https://www.rudderstack.com/docs/images/dashboard-guides/billings-plans/update-plan.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/billings-plans/update-plan.webp)\n\n#### **Purchase summary**\n\nRudderStack also gives you a clear purchase summary of the amount it will charge you from the next billing cycle and the pro-rated amount for the current month.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> RudderStack’s billing cycle resets on the 1st day of every month.\n\n[![Payment summary](https://www.rudderstack.com/docs/images/dashboard-guides/billings-plans/payment-summary.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/billings-plans/payment-summary.webp)\n\n#### **Cancel plan**\n\nTo cancel your current RudderStack Cloud plan, click **Cancel plan**.\n\n[![Cancel plan](https://www.rudderstack.com/docs/images/dashboard-guides/billings-plans/cancel-plan.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/billings-plans/cancel-plan.webp)\n\nIf you choose to continue and cancel your plan, note that:\n\n*   Your plan will be cancelled and changed to the [RudderStack Cloud Free](https://www.rudderstack.com/pricing/) plan with a monthly limit of 1 million events.\n*   You can still use your current plan until the end of your billing period, that is, 1st day of the following month.\n\nFor more information on RudderStack Cloud plans and billing-related queries, contact [RudderStack support](mailto:support@rudderstack.com).\n\n## FAQ\n\n#### Why can’t I see the Billing & plans tab in my RudderStack dashboard?\n\nThe **Billing & plans** feature is available only in the [RudderStack Cloud Free and Starter plans](https://rudderstack.com/pricing/).\n\nIf you are using any of these plans and still cannot see the **Billing & plans** tab, contact [RudderStack support](mailto:support@rudderstack.com).\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Billing and Plans | RudderStack Docs",
    "description": "Manage your RudderStack Cloud plan and billing information.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/user-guides/administrators-guide/bucket-configuration-settings/",
    "markdown": "# Bucket configuration settings for event backups\n\nConfigure cloud-specific buckets for your event backups.\n\n* * *\n\n*     3 minute read  \n    \n\nDepending on your [data retention policy](https://www.rudderstack.com/docs/dashboard-guides/data-management/), RudderStack stores the following two types of events:\n\n*   All the raw events ingested by RudderStack.\n*   The final event payload along with the error, in case of delivery failures.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> The events are deleted from the bucket upon successful delivery of the events. **RudderStack does not persist any of the customer data**.\n\nFollow the steps in this guide if you want RudderStack to back up the events in your **own** cloud-specific bucket.\n\n## Bucket configuration settings\n\nIf you are using **RudderStack open source** and want to use your own bucket to store the events, you will need to enable and set certain variables in your RudderStack backend.\n\n### Docker setup\n\n#### Storing events into your S3 bucket\n\nTo store the events in your S3 bucket, uncomment the following lines in your [docker.env](https://github.com/rudderlabs/rudder-server/blob/master/build/docker.env#L45-L50) file:\n\n```\n# JOBS_BACKUP_STORAGE_PROVIDER=S3\n# JOBS_BACKUP_BUCKET=<your_s3_bucket>\n# JOBS_BACKUP_PREFIX=<prefix>\n# AWS_ACCESS_KEY_ID=\n# AWS_SECRET_ACCESS_KEY=\n```\n\nThen follow these steps:\n\n1.  Specify your S3 bucket name for the variable `JOBS_BACKUP_BUCKET`.\n2.  Add the specific AWS IAM keys by following the [Permissions for Amazon S3](#permissions-for-amazon-s3) section below.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The `<prefix>` value for the **`JOBS_BACKUP_PREFIX`** variable refers to the path under the bucket in which RudderStack stores the data. For example, if **`JOBS_BACKUP_PREFIX`** is set to **`prefix`** then RudderStack stores the data in the location **`<your_s3_bucket>/prefix`**.\n\n#### Storing events into your GCS bucket\n\nTo capture the event dumps in your GCS bucket, uncomment the following lines in your [docker.env](https://github.com/rudderlabs/rudder-server/blob/master/build/docker.env#L45-L50) file:\n\n```\n# JOBS_BACKUP_STORAGE_PROVIDER=GCS\n# JOBS_BACKUP_BUCKET=<your_gcs_bucket>\n# JOBS_BACKUP_PREFIX=<prefix>\n# GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials\n```\n\nThen, follow these steps:\n\n1.  Specify your GCS bucket name for the variable `JOBS_BACKUP_BUCKET`.\n2.  Specify the location of the downloaded JSON file containing the required permissions for the variable `GOOGLE_APPLICATION_CREDENTIALS`. You can obtain this JSON file by referring to the [Permissions for GCS](#permissions-for-gcs) section below.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> **If you’re a RudderStack Pro/Enterprise user, you can share the downloaded JSON containing the required permissions with the RudderStack team by [contacting us](https://rudderstack.com/join-rudderstack-slack-community)**.\n> \n> The RudderStack team will then use this service account JSON file to authenticate RudderStack and dump the events into your GCS bucket.\n\n### Kubernetes Setup\n\nSimilar to the Docker setup, you can configure your bucket settings by changing the values in the [values.yaml](https://github.com/rudderlabs/rudderstack-helm/blob/master/values.yaml#L87) file.\n\n## Permissions for Amazon S3\n\nFollow these steps to use your own S3 bucket for RudderStack to store the events:\n\n1.  Create a bucket using the Amazon [S3](https://aws.amazon.com/s3/) service.\n2.  Create a new [customer-managed policy](https://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_managed-policies.html) with the following JSON:\n\n```\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [{\n    \"Effect\": \"Allow\",\n    \"Action\": [\n      \"s3:GetObject\",\n      \"s3:PutObject\",\n      \"s3:ListBucket\",\n      \"s3:ListObjectsV2\",\n      \"s3:AbortMultipartUpload\"\n    ],\n    \"Resource\": \"arn:aws:s3:::{BUCKET_NAME}/*\",\n    \"Resource\": \"arn:aws:s3:::{BUCKET_NAME}\"\n  }]\n}\n```\n\n3.  Create a new group and add the policy created above to this group.\n4.  Create a new [user](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html) in [Identity and Access Management (IAM)](https://console.aws.amazon.com/iam) with the programmatic access and add the user to the above group.\n5.  Download and note the **Access key ID** and **Secret Access Key**.\n\n## Permissions for GCS\n\nThis section lists the steps to use your own GCS bucket for RudderStack to store the events:\n\nUnder **Roles** in your GCP dashboard, you need to create a role with the following permissions:\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Add each permission one after the other.\n\n*   **storage.objects.create**\n*   **storage.objects.get**\n*   **storage.objects.list**\n\n[![](https://www.rudderstack.com/docs/images/admin-guides/gcp-role-permissions.webp)](https://www.rudderstack.com/docs/images/admin-guides/gcp-role-permissions.webp)\n\nThen, create a service account by following these steps:\n\n1.  Assign a name to the service account:\n\n[![Assign a name](https://www.rudderstack.com/docs/images/screenshot-2020-08-05-at-11.40.12-am%20%282%29%20%282%29%20%282%29%20%282%29%20%282%29%20%282%29%20%282%29%20%282%29%20%282%29%20%282%29%20%282%29%20%282%29%20%281%29.webp)](https://www.rudderstack.com/docs/images/screenshot-2020-08-05-at-11.40.12-am%20%282%29%20%282%29%20%282%29%20%282%29%20%282%29%20%282%29%20%282%29%20%282%29%20%282%29%20%282%29%20%282%29%20%282%29%20%281%29.webp)\n\n2.  Add the role you created in step 1.\n\n[![](https://www.rudderstack.com/docs/images/screenshot-2020-08-05-at-11.41.24-am.webp)](https://www.rudderstack.com/docs/images/screenshot-2020-08-05-at-11.41.24-am.webp)\n\n3.  Create a key with the type JSON and save this file locally:\n\n[![Create a key](https://www.rudderstack.com/docs/images/screenshot-2020-08-05-at-11.49.10-am.webp)](https://www.rudderstack.com/docs/images/screenshot-2020-08-05-at-11.49.10-am.webp)\n\n4.  Then, create a bucket with the bucket access control set to **Uniform**:\n\n[![Create a bucket](https://www.rudderstack.com/docs/images/screenshot-2020-08-05-at-11.52.07-am.webp)](https://www.rudderstack.com/docs/images/screenshot-2020-08-05-at-11.52.07-am.webp)\n\nOnce the bucket is created, add the required permissions by following the below steps:\n\n1.  Go to the **Permissions** tab.\n2.  Then, add the member with the service account created above.\n3.  Add the role.\n\n[![Go to Permissions](https://www.rudderstack.com/docs/images/screenshot-2020-08-05-at-11.53.34-am.webp)](https://www.rudderstack.com/docs/images/screenshot-2020-08-05-at-11.53.34-am.webp)\n\n4.  Finally the download the JSON file containing the required permissions.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Bucket configuration settings for event backups | RudderStack Docs",
    "description": "Configure cloud-specific buckets for your event backups.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/user-guides/how-to-guides/custom-domains/",
    "markdown": "# How to Use Custom Domains\n\nUse your own domain to serve the RudderStack JavaScript SDK and send events to the data plane.\n\n* * *\n\n*     8 minute read  \n    \n\nThis guide covers the steps to use your own domain instead of RudderStack domains for:\n\n*   Serving the JavaScript SDK\n*   Source configuration response, and\n*   Sending events to the data plane.\n\nSetting up custom domains for these use cases can help you adhere to your Content Security Policy (CSP), reduce the impact of adblockers, and satisfy any compliance-related requirements.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Note that:\n> \n> *   You will need access to your domain’s DNS settings as well as your CDN settings.\n> *   The examples in this guide use [AWS CloudFront](https://aws.amazon.com/cloudfront/). However, the settings should be similar regardless of your CDN.\n\n## Domains\n\nThe following table lists the three domains that you need to proxy via your own CDN to successfully load the SDK and route the events to the data plane.\n\n| Domain | Use case |\n| --- | --- |\n| `cdn.rudderlabs.com` | To load the [JavaScript SDK](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/). |\n| `api.rudderstack.com` | To fetch the source configuration based on the source [write key](https://www.rudderstack.com/docs/resources/glossary/#write-key). |\n| `DATA_PLANE_URL` | To send events to RudderStack. See [Glossary](https://www.rudderstack.com/docs/resources/glossary/#data-plane-url) for more information on obtaining your data plane URL. |\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> To use your own domain for these endpoints, you will need to route the traffic through your CDN for which you will incur charges.\n\nFor each endpoint, you will need to create a CDN distribution and add a CNAME record in your domain for the distribution domain. This guide shows you how to do that.\n\n## Setup overview\n\nStart by creating a new distribution. To do so, follow these steps:\n\n1.  Log in to your [AWS console](https://aws.amazon.com/console/).\n2.  Click **Services** and go to **Network & Content Delivery** > **CloudFront**.\n3.  Click **Create a CloudFront distribution**.\n\nThe following table gives a high-level overview of the required cache policy, origin request policy, and response headers policy. For detailed distribution settings, click the specific scenario.\n\n| Scenario | Cache policy | Origin request policy | Response headers policy (optional) |\n| --- | --- | --- | --- |\n| [Serving the SDK](#setup-for-serving-sdk) | CachingOptimized | See [Origin request policy settings](#sdk-origin-request-policy-settings). | None |\n| [Serving the source configuration](#setup-for-fetching-source-configuration) | See [Cache policy settings](#cache-policy-settings). | See [Origin request policy settings](#source-origin-request-policy-settings). | CORS-With-Preflight |\n| [Sending events to data plane](#setup-for-sending-events) | CachingDisabled | See [Origin request policy settings](#event-origin-request-policy-settings). | CORS-With-Preflight |\n\n## Setup for serving SDK\n\n### Step 1: Configure distribution\n\nThe following sections highlight the required distribution settings for serving the SDK.\n\n#### **Origin**\n\n[![Custom domains distribution settings](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-1.webp)](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-1.webp)\n\nThe following table summarizes the settings:\n\n| Field | Setting |\n| --- | --- |\n| Origin domain | `cdn.rudderlabs.com` |\n| Protocol | HTTPS Only |\n| HTTPS port | 443 |\n| Minimum origin SSL protocol | TLSv1.2 |\n| Name | `cdn.rudderlabs.com` |\n| Enable Origin Shield | No  |\n\n#### **Default cache behavior settings**\n\n[![Custom domains distribution settings](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-2-new.webp)](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-2-new.webp)\n\nThe following table summarizes the settings:\n\n| Field | Setting |\n| --- | --- |\n| Compress objects automatically | Yes |\n| Viewer protocol policy | Redirect HTTP to HTTPS |\n| Allowed HTTP methods | `GET`, `HEAD`, `OPTIONS`, `PUT`, `POST`, `PATCH`, `DELETE` |\n| Restrict viewer access | No  |\n\n#### **Cache key and origin requests**\n\nSelect **Cache policy and origin request policy (recommended)** and configure the following settings:\n\n[![Custom domains distribution settings](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-3-new.webp)](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-3-new.webp)\n\nThe following table summarizes the settings:\n\n| Field | Setting |\n| --- | --- |\n| Cache policy | CachingOptimized |\n| Origin request policy | See [Origin request policy settings](#sdk-origin-request-policy-settings). |\n| Response headers policy | None |\n\n##### **Origin request policy settings**\n\nCreate a new origin request policy with the following settings:\n\n[![Origin request policy settings](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-origin-request-policy.webp)](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-origin-request-policy.webp)\n\n| Field | Setting |\n| --- | --- |\n| Name | `rudderstack-allow-headers` |\n| Headers | Include the following headers |\n| Add header | *   Access-Control-Request-Headers<br>*   Access-Control-Request-Method<br>*   Origin<br>*   Content-Encoding |\n| Query strings | All |\n| Cookies | None |\n\n#### **Additional distribution settings**\n\n[![Custom domains distribution settings](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-3.webp)](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-3.webp)\n\nThe following table summarizes the settings:\n\n| Field | Setting |\n| --- | --- |\n| Price class | Use all edge locations(best performance) |\n| Alternate domain name(CNAME) | `<YOUR_CUSTOM_DOMAIN>` |\n| SSL Certificate | Add your custom SSL Certificate. See [Use custom SSL certificates](#use-custom-ssl-certificates) for more information. |\n| Supported HTTP versions | HTTP/2 |\n| Standard logging | Off |\n| IPv6 | On  |\n\n### Step 2: Deploy distribution\n\nClick **Create distribution** and wait for CloudFront to be deployed:\n\n[![CloudFront deployment](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-deploy-distribution.webp)](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-deploy-distribution.webp)\n\n#### **Add CNAME Record to DNS**\n\nOnce your distribution is deployed, create a CNAME record for the subdomain you wish to use along with the distribution URL.\n\n| Name | Value |\n| --- | --- |\n| Subdomain you wish to use (used in the creation of the distribution).<br><br>**Note**: This will vary based on your DNS provider but will typically be just the subdomain. For example: for `cdn.yourdomain.com` you would use `cdn`. | The CDN URL for the created distribution. Example: `<prefix>.cloudfront.net` |\n\n[![CDN distribution URL](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-6.webp)](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-6.webp)\n\n### Step 3: Serve SDK\n\nSee the following sections to serve the SDK depending on your installation method:\n\n*   [SDK installation using CDN](#cdn)\n*   [SDK installation using NPM](#npm)\n\n#### **CDN**\n\nPaste the following [snippet](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/installation/#using-cdn) in your website’s `<head>` section and update the URL from:\n\n```\nvar sdkBaseUrl = \"https://cdn.rudderlabs.com/v3\";\n```\n\nto:\n\n```\nvar sdkBaseUrl=\"https://<YOUR_CUSTOM_DOMAIN>/v3\"\n```\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Make sure to replace `<YOUR_CUSTOM_DOMAIN>` in the above snippet with the appropriate value.\n\n*   If you’re loading the JavaScript SDK **asynchronously**, paste the [snippet](https://www.rudderstack.com/docs/archive/javascript-sdk/1.1/quick-start-guide/#using-a-cdn) in your website’s `<head>` section and update the URL from:\n\n```\n\"https://cdn.rudderlabs.com/v1.1/rudder-analytics.min.js\"\n```\n\nto:\n\n```\n\"https://<YOUR_CUSTOM_DOMAIN>/v1.1/rudder-analytics.min.js\"\n```\n\n*   If you’re loading the JavaScript SDK **synchronously**, paste the [snippet](https://www.rudderstack.com/docs/archive/javascript-sdk/1.1/quick-start-guide/#using-a-cdn) in your website’s `<head>` section and update the URL from:\n\n```\n<script src=\"https://cdn.rudderlabs.com/v1.1/rudder-analytics.min.js\"></script>\n```\n\nto:\n\n```\n<script src=\"https://<YOUR_CUSTOM_DOMAIN>/v1.1/rudder-analytics.min.js\"></script>\n```\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Make sure to replace `<YOUR_CUSTOM_DOMAIN>` in the above snippets with the appropriate values.\n\n#### **NPM**\n\nSince you have used the NPM module for integrating the SDK directly into your application, there is no configuration required for serving the core SDK.\n\n#### **Additional configuration**\n\nIrrespective of your SDK installation method, you will need some additional configuration for loading the device mode destinations and plugins:\n\nConfigure the [`load` API](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/load-js-sdk/) option for plugins as follows **if** you are not using the [`@rudderstack/analytics-js/bundled`](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/installation/#sdk-imports-for-bundling-tools-that-process-dynamic-imports) package that bundles all the plugins into the SDK package.\n\n```\nrudderanalytics.load(WRITE_KEY, DATA_PLANE_URL, {\n  pluginsSDKBaseURL: \"https://<YOUR_CUSTOM_DOMAIN>/v3/modern/plugins\"\n});\n```\n\nTo load [device mode destinations](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/migration-guide/#additional-configuration-for-loading-device-mode-destinations), use the following [`load` API](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/load-js-sdk/) option:\n\n```\nrudderanalytics.load(WRITE_KEY, DATA_PLANE_URL, {\n  destSDKBaseURL: \"https://<YOUR_CUSTOM_DOMAIN>/v3/modern/js-integrations\"\n});\n```\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Replace `<YOUR_CUSTOM_DOMAIN>` in the above snippets with the appropriate values.\n\n## Setup for fetching source configuration\n\nWhen the JavaScript SDK is loaded, it uses the source write key to fetch the required source configuration from RudderStack.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The SDK makes a `GET` request to the `https://api.rudderstack.com/sourceConfig` URL to fetch the source configuration. It uses the source write key as the authorization header.\n> \n> For this reason, the distribution settings in this scenario will be slightly different as you need to explicitly allowlist the **Authorization** header to make sure it is sent along with each request.\n\n### Step 1: Configure distribution\n\nThe following sections highlight the required distribution settings.\n\n#### **Origin**\n\n| Field | Setting |\n| --- | --- |\n| Origin domain | `api.rudderstack.com` |\n| Protocol | HTTPS Only |\n| HTTPS port | 443 |\n| Minimum origin SSL protocol | TLSv1.2 |\n| Name | `api.rudderstack.com` |\n| Enable Origin Shield | No  |\n\n#### **Default cache behavior settings**\n\n| Field | Setting |\n| --- | --- |\n| Compress objects automatically | Yes |\n| Viewer protocol policy | Redirect HTTP to HTTPS |\n| Allowed HTTP methods | `GET`, `HEAD`, `OPTIONS`, `PUT`, `POST`, `PATCH`, `DELETE` |\n| Restrict viewer access | No  |\n\n#### **Cache key and origin requests**\n\nSelect **Cache policy and origin request policy (recommended)** and configure the following settings:\n\n| Field | Setting |\n| --- | --- |\n| Cache policy | See [Cache policy settings](#cache-policy-settings). |\n| Origin request policy | See [Origin request policy settings](#source-origin-request-policy-settings). |\n| Response headers policy | CORS-With-Preflight |\n\n##### **Cache policy settings**\n\nCreate a cache policy with the following settings:\n\n[![Custom domains cache policy settings](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-4-latest.webp)](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-4-latest.webp)\n\n| Field | Setting |\n| --- | --- |\n| Name | `<CACHE_POLICY_NAME>` |\n| Description | `<CACHE_POLICY_DESCRIPTION>` |\n| Minimum TTL | `1` |\n| Maximum TTL | `86400` |\n| Default TTL | `300` |\n| Headers | Include the following headers |\n| Add header | Authorization  <br>Origin |\n| Query strings | All |\n| Cookies | None |\n\n##### **Origin request policy settings**\n\nCreate a new origin request policy with the following settings:\n\n[![Origin request policy settings](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-origin-request-policy.webp)](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-origin-request-policy.webp)\n\n| Field | Setting |\n| --- | --- |\n| Name | `rudderstack-allow-headers` |\n| Headers | Include the following headers |\n| Add header | *   Access-Control-Request-Headers<br>*   Access-Control-Request-Method<br>*   Origin<br>*   Content-Encoding |\n| Query strings | All |\n| Cookies | None |\n\n#### **Additional settings**\n\nThese are same as the additional distribution settings for [serving the JavaScript SDK](#additional-distribution-settings).\n\n### Step 2: Deploy distribution\n\nClick **Create distribution** and wait for CloudFront to be deployed:\n\n[![CloudFront deployment](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-deploy-distribution.webp)](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-deploy-distribution.webp)\n\n#### **Add CNAME record to DNS**\n\nThese are same as the settings for [serving the JavaScript SDK](#add-cname-record-to-dns).\n\n### Step 3: Fetch source configuration\n\nTo use a custom URL to fetch the source configuration, add it as an option when loading the JavaScript SDK:\n\n```\nrudderanalytics.load(\n  <SOURCE_WRITE_KEY>,\n  DATA_PLANE_URL,\n  {\n    configUrl: \"https://<YOUR_CUSTOM_DOMAIN>\",\n  }\n)\n```\n\n## Setup for sending events\n\nNormally, all tracked events are sent to RudderStack via your data plane URL. To have events routed through your own domain, you need to set up a proxy to that and then use it as the data plane URL while initializing the SDK.\n\n### Step 1: Configure distribution\n\nThe following sections highlight the required distribution settings.\n\n#### **Origin**\n\n| Field | Setting |\n| --- | --- |\n| Origin domain | `DATA_PLANE_URL` |\n| Protocol | HTTPS Only |\n| HTTPS port | 443 |\n| Minimum origin SSL protocol | TLSv1.2 |\n| Name | `<YOUR_ORIGIN_NAME>` |\n| Enable Origin Shield | No  |\n\n#### **Default cache behavior settings**\n\n| Field | Setting |\n| --- | --- |\n| Compress objects automatically | Yes |\n| Viewer protocol policy | Redirect HTTP to HTTPS |\n| Allowed HTTP methods | `GET`, `HEAD`, `OPTIONS`, `PUT`, `POST`, `PATCH`, `DELETE` |\n| Restrict viewer access | No  |\n\n#### **Cache key and origin requests**\n\nSelect **Cache policy and origin request policy (recommended)** and configure the following settings:\n\n[![Cache and origin request policy](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-sending-events-1.webp)](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-sending-events-1.webp)\n\n| Field | Setting |\n| --- | --- |\n| Cache policy | CachingDisabled |\n| Origin request policy | See [Origin request policy settings](#event-origin-request-policy-settings). |\n| Response headers policy | CORS-With-Preflight |\n\n##### **Origin request policy settings**\n\nCreate a new origin request policy with the following settings:\n\n[![Origin request policy settings](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-origin-request-policy.webp)](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-origin-request-policy.webp)\n\n| Field | Setting |\n| --- | --- |\n| Name | `rudderstack-allow-headers` |\n| Headers | Include the following headers |\n| Add header | *   Access-Control-Request-Headers<br>*   Access-Control-Request-Method<br>*   Origin<br>*   Content-Encoding |\n| Query strings | All |\n| Cookies | None |\n\n#### **Additional settings**\n\nThese are same as the additional distribution settings for [serving the JavaScript SDK](#additional-distribution-settings).\n\n### Step 2: Deploy distribution\n\nClick **Create distribution** and wait for CloudFront to be deployed:\n\n[![CloudFront deployment](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-deploy-distribution.webp)](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-deploy-distribution.webp)\n\n#### **Add CNAME record to DNS**\n\nThese are same as the settings for [serving the JavaScript SDK](#add-cname-record-to-dns).\n\n### Step 3: Send events\n\nOnce the setup and DNS propagation is completed, you can use the newly created URL as the data plane URL when initializing the SDK:\n\nBefore:\n\n```\nrudderanalytics.load( \n  WRITE_KEY ,\n  DATA_PLANE_URL\n)\n```\n\nAfter:\n\n```\nrudderanalytics.load(\n  WRITE_KEY,\n  \"https://<YOUR_CUSTOM_DOMAIN>\"\n)\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Make sure that the events are routed through your own domain and not the `rudderstack.com` domain in the network tab of your browser console. See [JavaScript SDK FAQ](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/faq/#how-can-i-verify-if-the-sdk-is-sending-data-to-the-specified-destinations) for more information.\n\n## Use custom SSL certificates\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> To use your own domain, you can request or import an SSL certificate with your CDN provider. Note that this is an optional setting.\n\nTo use the AWS Certificate Manager with CloudFront, choose the relevant ACM/IAM certificate in the **Custom SSL certificate** field:\n\n[![Custom SSL certificate](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-8.webp)](https://www.rudderstack.com/docs/images/user-guides/custom-domains/custom-domains-8.webp)\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> You can choose your subdomain or use a wildcard domain `*.yourdomain.com` to set up multiple subdomains.\n\nThe AWS Certificate Manager will guide you through the verification by email or DNS TXT records. You will be able to choose your own domain for SSL certificates once verified.\n\n## FAQ\n\n#### **Can I overcome ad blockers by serving the JavaScript SDK on my domain?**\n\nMany popular ad blockers block specific SDK-related downloads and API calls based on the domain name and URL. You can serve the SDK on your CDN to circumvent this issue.\n\n#### **I am using GCP External HTTP(S) Load Balancer to set up my custom domain. Why are any requests from `xyz.mydomain.com` to `cdn.rudderlabs.com` resulting in a 403?**\n\nIf you’re setting up a custom domain using the [GCP External HTTPS Load Balancer](https://cloud.google.com/load-balancing/docs/https), make sure you [add a custom request header](https://cloud.google.com/load-balancing/docs/https/custom-headers#working-with-request) in your backend service config:\n\n| Header name | Value |\n| --- | --- |\n| `Host` | `cdn.rudderlabs.com` |\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "How to Use Custom Domains | RudderStack Docs",
    "description": "Use your own domain to serve the RudderStack JavaScript SDK and send events to the data plane.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/dashboard-guides/data-management/",
    "markdown": "# Data Management | RudderStack Docs\n\nManage your event data with our data retention options.\n\nAvailable Plans\n\n*   starter\n*   growth\n*   enterprise\n\n* * *\n\n*     6 minute read  \n    \n\nRudderStack provides a comprehensive data retention policy and options for opting in or out of data storage.\n\nIt provides the following retention options (available only in the above plans) for your event data:\n\n*   [Do not store event data](#1-do-not-store-event-data)\n*   [Store in your own cloud storage (Recommended)](#2-store-event-data-in-your-own-cloud-storage-recommended)\n*   [Store in RudderStack Cloud on a rolling 7-day basis](#3-store-event-data-in-rudderstack-cloud-storage)\n*   [Store in RudderStack Cloud on a rolling 30-day basis](#3-store-event-data-in-rudderstack-cloud-storage) (Applicable only for the [Enterprise](https://rudderstack.com/enterprise-quote) plan)\n\nThe following sections define different types of RudderStack data and provide steps on opting in to the right setup for your needs.\n\n## Data definitions\n\nRudderStack **does not** permanently store any customer data except the following:\n\n*   Aggregate “Count” data on Event Name, Event Type, Source ID, Destination ID.\n*   Error codes.\n*   RudderStack customers’ records (for example, usernames, billing-related details).\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The storage options vary with the nature of the data and your RudderStack plan. See [Plan-based retention options](#plan-based-retention-options) for more details.\n\nAll other customer data can be classified as either **transient** or **non-transient** and it may either be stored in your location, for example, AWS, or by RudderStack for upto 7 days (or 30 days in case of Enterprise plan).\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> RudderStack’s data retention policy defines data as they pertain to the primary components of its service - the [data plane](https://www.rudderstack.com/docs/resources/glossary/#data-plane) and [control plane](https://www.rudderstack.com/docs/resources/glossary/#control-plane).\n\n### Transient customer data\n\nTransient customer data can be defined as all in-transit data, that is, **stored for less than 3 hours**, as an essential part of delivering the RudderStack product experience. This data includes:\n\n*   **Data plane**: Events that hit the RudderStack gateway. See [data plane architecture](https://www.rudderstack.com/docs/resources/rudderstack-architecture/#data-plane-architecture) for more details.\n*   **Control plane**: The in-transit data captured in the [Live Events](https://www.rudderstack.com/docs/dashboard-guides/live-events/) tab of the RudderStack dashboard.\n\n### Non-transient customer data\n\nNon-transient customer data can be defined as data that can persist for more than 3 hours **only if** configured by the RudderStack user. This includes:\n\n*   **Data plane**: This includes processing errors and gateway dumps.\n    \n    *   **Processing errors**: Events rejected at various stages of the data pipeline, including errors from user transformation, destination transformation (internal to RudderStack), and events rejected by the destination after **3 hours** of retry attempts.\n    *   **Gateway dumps**: Raw data for every successfully-ingested event.\n*   **Control plane**: Data in the reporting service ([sample events and responses](#sample-event-data)).\n    \n\n## Data retention options\n\nRudderStack provides 3 options for your event data storage. To choose how you want to store the event data, follow these steps:\n\n1.  Log in to your [RudderStack dashboard](https://app.rudderstack.com/).\n2.  Go to **Settings** > **Workspace** > **Data Management**.\n3.  Choose one of the 3 data storage options in the **Data retention** section:\n\n[![Choose your data storage option.](https://www.rudderstack.com/docs/images/dashboard-guides/data-retention-options.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/data-retention-options.webp)\n\nThe following sections explain the data retention options in detail.\n\n### 1\\. Do not store event data\n\nIf you choose this option, RudderStack will not store any of your event data.\n\n[![Do not store event data.](https://www.rudderstack.com/docs/images/dashboard-guides/no-data-storage.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/no-data-storage.webp)\n\n### 2\\. Store event data in your own cloud storage (Recommended)\n\nThis is the recommended event storage option, and available in the [Starter, Growth, and Enterprise](https://www.rudderstack.com/pricing/) plans. Selecting this option will bring up a modal allowing you to connect a storage bucket with your RudderStack data.\n\n[![Store your data with your cloud provider.](https://www.rudderstack.com/docs/images/dashboard-guides/connect-cloud-storage.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/connect-cloud-storage.webp)\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> RudderStack supports storage via AWS, GCS, Azure, and MinIO if you select this option.\n\nWhen connecting your cloud storage provider to RudderStack, you will first need to create a storage bucket and configure the credentials for RudderStack to access the datastore. Follow the steps listed below depending on your cloud provider:\n\n1.  Create your [S3 bucket](https://docs.aws.amazon.com/AmazonS3/latest/userguide/creating-bucket.html).\n2.  In the dashboard, specify the **S3 Bucket Name** and **Prefix**.\n3.  **Role Based Authentication** is turned on by default. [Create a RudderStack IAM role](https://www.rudderstack.com/docs/destinations/aws-iam-role-for-rudderstack/) and specify the **IAM Role ARN**.\n\nIf you have disabled **Role Based Authentication** (not recommended), configure the [permissions for your S3 bucket](https://www.rudderstack.com/docs/user-guides/administrators-guide/bucket-configuration-settings/#permissions-for-amazon-s3). Then, enter the **Access key ID** and **Secret Access Key**.\n\n4.  Enable server-side encryption, if needed.\n\n![S3 bucket settings for data retention](https://www.rudderstack.com/docs/images/dashboard-guides/s3-data-retention-settings.webp)\n\n**If you are self-hosting RudderStack using RudderStack Open Source**:\n\n1.  Create your [S3 bucket](https://docs.aws.amazon.com/AmazonS3/latest/userguide/creating-bucket.html).\n2.  Configure relevant [permissions for your S3 bucket](https://www.rudderstack.com/docs/user-guides/administrators-guide/bucket-configuration-settings/#permissions-for-amazon-s3). Note the **Access key ID** and **Secret Access Key**.\n3.  Configure the bucket settings in the dashboard.\n\n1.  Create your [object storage bucket](https://cloud.google.com/storage/docs/creating-buckets).\n2.  Configure the relevant [permissions for your bucket](https://www.rudderstack.com/docs/user-guides/administrators-guide/bucket-configuration-settings/#permissions-for-gcs).\n3.  Connect your storage provider in the RudderStack dashboard.\n\n1.  Login to the [Azure portal](https://portal.azure.com/) and create a [storage account](https://docs.microsoft.com/en-us/azure/storage/common/storage-account-create?tabs=azure-portal).\n2.  Click **Containers** under **Blob service** and create a new container.\n3.  Connect your storage provider in the RudderStack dashboard.\n\n1.  Login to your MinIO service and [set up your bucket](https://www.rudderstack.com/docs/destinations/streaming-destinations/minio/#setting-up-minio).\n2.  Connect your storage provider in the RudderStack dashboard.\n\n### 3\\. Store event data in RudderStack cloud storage\n\nChoosing this option allows RudderStack to store and delete your event data on a rolling 7-day basis. **This is the default setting.**\n\n[![Store in RudderStack cloud storage.](https://www.rudderstack.com/docs/images/dashboard-guides/rs-cloud-storage-7-day.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/rs-cloud-storage-7-day.webp)\n\nIf you are on the [Enterprise](https://rudderstack.com/enterprise-quote) plan, RudderStack lets you store and delete your event data on a rolling 30-day basis.\n\n[![Store in RudderStack cloud storage.](https://www.rudderstack.com/docs/images/dashboard-guides/rs-cloud-storage-30-day.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/rs-cloud-storage-30-day.webp)\n\n## Sample event data\n\nWhen the **Sample event data** setting is enabled, RudderStack stores and deletes sample events and responses on a rolling 30-day basis. This data may be helpful for debugging your events.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> RudderStack **does not** consider the event name or event type to be Personally Identifiable Information (PII).\n\n[![Opt in to sample event data storage.](https://www.rudderstack.com/docs/images/dashboard-guides/sample-event-data.webp)](https://www.rudderstack.com/docs/images/dashboard-guides/sample-event-data.webp)\n\n## Plan-based retention options\n\nBased on your plan, RudderStack provides different options for event storage, giving you the ability to enable or disable retention for the following kinds of data:\n\n*   **Sample events and responses**: As mentioned above, RudderStack will store and delete sample events and responses on a rolling 30-day basis.\n*   **Raw event data**: Events sent to RudderStack. This includes processing errors and gateway dumps.\n\nRefer to the below table for the storage items supported by different [RudderStack pricing plans](https://www.rudderstack.com/pricing/):\n\n| Data type | Free | Starter/Growth | Enterprise |\n| --- | --- | --- | --- |\n| Sample events/responses |     |     |     |\n| Raw event data |     | *   No data storage<br>*   Connect your own cloud storage<br>*   RudderStack 7-day storage (default) | *   No data storage<br>*   Connect your own cloud storage<br>*   RudderStack 7-day storage (default)<br>*   RudderStack 30-day storage |\n\n## Data governance\n\nTo enable the Event Audit API in the RudderStack dashboard:\n\n1.  Go to **Settings** > **Workspace** and click the **Data Management** tab.\n2.  Scroll down to the **Data governance** section and toggle on the **Event audit API** setting.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Only users with the [Org Admin](https://www.rudderstack.com/docs/dashboard-guides/user-management/#organization-roles) role have the access to this setting.\n\n[![Event Audit API setting in RudderStack dashboard](https://www.rudderstack.com/docs/images/api/event-audit-api-dashboard.webp)](https://www.rudderstack.com/docs/images/api/event-audit-api-dashboard.webp)\n\nWhen this setting is turned on, you can leverage the Event Audit API to create and manage your [tracking plans](https://www.rudderstack.com/docs/data-governance/tracking-plans/). Use these plans to monitor and act on any non-compliant data coming into your RudderStack sources based on predefined rules.\n\nSee [Event Audit API](https://www.rudderstack.com/docs/api/event-audit-api/) for more information.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> This feature is only available for the [Enterprise](https://www.rudderstack.com/enterprise-quote/) plan users.\n\nRudderStack’s data privacy options let you safeguard your customers’ privacy by controlling who has access to the raw event data containing PII(Personally Identifiable Information). You can allow anyone on your team to access the PII or restrict access only to a select list of members.\n\nOnly members with PII permissions can view the customers’ PII in the [Live Events](https://www.rudderstack.com/docs/dashboard-guides/live-events/) and errors logs in your [destination’s](https://www.rudderstack.com/docs/dashboard-guides/destinations/#destination-details) **Events** tab:\n\n[![Error logs](https://www.rudderstack.com/docs/images/rs-cloud/permissions-management-4.webp)](https://www.rudderstack.com/docs/images/rs-cloud/permissions-management-4.webp)\n\nTo set the PII permissions, follow these steps:\n\n1.  In your RudderStack dashboard, go to **Settings** > **Workspace** > **Data Management** and scroll down to the **Data Privacy** section.\n    \n2.  Under **Who can view restricted data?**, select the appropriate option:\n    \n    *   **Anyone on your team**: All the members in your workspace can view the raw event data containing PII.\n    *   **Only people you select**: Only specific members with access can view the raw data.\n3.  To allow specific members of your team to edit the object, click **Only people you select**, followed by **Add member**.\n    \n\n[![Add members](https://www.rudderstack.com/docs/images/rs-cloud/permissions-management-5.webp)](https://www.rudderstack.com/docs/images/rs-cloud/permissions-management-5.webp)\n\n4.  Finally, select the workspace members from the drop-down and click **Add Members**:\n\n[![Add members option](https://www.rudderstack.com/docs/images/rs-cloud/permissions-management-6.webp)](https://www.rudderstack.com/docs/images/rs-cloud/permissions-management-6.webp)\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> If the admins are removed from the access list, RudderStack will restrict them from viewing the PII.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Data Management | RudderStack Docs",
    "description": "Manage your event data with our data retention options.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/user-guides/how-to-guides/filter-events/",
    "markdown": "# How to filter events | RudderStack Docs\n\nPrivacy Overview\n\nThis site uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are as essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.\n\nNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.",
    "title": "How to filter events | RudderStack Docs",
    "description": "Filter event data prior to sending it to a destination.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/user-guides/administrators-guide/horizontal-scaling-1/",
    "markdown": "# Horizontal scaling | RudderStack Docs\n\nFamiliarize yourself with RudderStack’s horizontal scaling approach.\n\n* * *\n\n*     2 minute read  \n    \n\nRudderStack makes it easier for you to add more nodes to your Kubernetes cluster, to process the events in a timely and effective manner. This guide shows you how to effectively configure your [Helm charts](https://github.com/rudderlabs/rudderstack-helm) to trigger a horizontal scale up/down, based on the version of RudderStack you are using.\n\n## RudderStack Open-source Version\n\nEach RudderStack node consists of a backend pod and a PostgreSQL pod. In case a RudderStack cluster is not able to process the events, it is advisable to add more more nodes to it. By changing the **`backendReplicaCount`** in the [Helm configuration](https://github.com/rudderlabs/rudderstack-helm/blob/master/values.yaml), you can trigger horizontal scale up/down. If you set this value to any positive number, helm charts will create as many RudderStack nodes.\n\n> ![success](https://www.rudderstack.com/docs/images/tick.svg)\n> \n> The `values.yaml` file can be found [here](https://github.com/rudderlabs/rudderstack-helm/blob/master/values.yaml).\n\nThere are, however, a couple of challenges in scaling up or down this way.\n\n### Event Ordering\n\nIn a single-node cluster, all events are routed to the same RudderStack node. This guarantees the ordering of all events it has received for a given user. In case of a multi-node cluster, since the events of a same user can go to different nodes, the event ordering is not guaranteed by the cluster.\n\n[![](https://www.rudderstack.com/docs/images/image%20%2817%29.webp)](https://www.rudderstack.com/docs/images/image%20%2817%29.webp)\n\nEvent Ordering While Scaling Up from 1 Node to 2 Nodes\n\n### Scale Down\n\nIf you scale down, all pending events in the terminated node will not be delivered to the destination. You will need to make sure that all events in a node are drained before terminating it.\n\n[![](https://www.rudderstack.com/docs/images/image%20%2865%29.webp)](https://www.rudderstack.com/docs/images/image%20%2865%29.webp)\n\nScaling Down from 2 Nodes to 1 Node\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> To understand how RudderStack handles hardware failures and guarantees High Availability, please go through our [High Availability guide](https://www.rudderstack.com/docs/user-guides/administrators-guide/high-availability/).\n\n## RudderStack Enterprise Version\n\nThe Enterprise version of RudderStack makes horizontal scaling seamless, while maintaining the event ordering and guaranteeing the delivery of all events.\n\n### Event Ordering\n\nRudderStack Enterprise has a proxy service that implements a routing algorithm. It forwards a given set of user events to the same RudderStack node every time. Each node then guarantees the event ordering while delivering to the specified destinations. This proxy service is highly available and scalable.\n\n[![](https://www.rudderstack.com/docs/images/image%20%2827%29.webp)](https://www.rudderstack.com/docs/images/image%20%2827%29.webp)\n\nEvent Ordering in RudderStack Enterprise\n\n### Scale Down\n\nRudderStack Enterprise includes a separate process named **Jobs DB Migrator**. This process is responsible for moving all pending events from the existing nodes to the new nodes after scaling up or down. It makes sure all events are migrated to the new nodes and the event ordering is maintained during and after the migration process.\n\n[![](https://www.rudderstack.com/docs/images/image%20%2855%29.webp)](https://www.rudderstack.com/docs/images/image%20%2855%29.webp)\n\nScaling Down in RudderStack Enterprise\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Horizontal scaling | RudderStack Docs",
    "description": "Familiarize yourself with RudderStack's horizontal scaling approach.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/user-guides/administrators-guide/infra-provisioning/",
    "markdown": "# Infrastructure provisioning | RudderStack Docs\n\nProvision your infrastructure for RudderStack performance metrics.\n\n* * *\n\n*     4 minute read  \n    \n\nThis is a brief overview of the stats that we captured by running Backend on different AWS machine configurations that we hope gives a rough idea for users in making the decisions to provision infrastructure to host Rudder. All numbers capture below are by using metrics described in [Monitoring and Metrics](https://www.rudderstack.com/docs/user-guides/administrators-guide/monitoring-and-metrics/#available-metrics).\n\n## Load Test Results\n\nAll tests are done using db.m4.xlarge Amazon RDS instance for hosting the postgres database\n\n### Gateway\n\n| Machine | Load | Response Time (ms) `gateway.response_time` | Throughput `gateway.write_key_requests` | Dangling Tables |\n| --- | --- | --- | --- | --- |\n| m4.2xLarge | 8Core 32GB | 2.5K/s | –   | 2.5K/s |\n| m4.2xLarge | 8Core 32GB | 5K/s | –   | 3K/s |\n| m4.2xLarge | 8Core 32GB | 3K/s | –   | 2.7K/s |\n| m5.xLarge | 4Core 16GB | 2.5K/s | 3   | 1.9K/s |\n| m5.large | 2Core 8GB | 2.5K/s | 4.2 | 1.7K/s |\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Backend migrates and drops tables that have a threshold of jobs processed. Gateway tables are backed up to object storage (S3, MinIO etc.) if configured by user. Dangling tables indicate tables are ready for drop at a rate greater than the rate at which tables are backed up to object storage. Concurrent uploads to object storage is in the roadmap for upcoming versions of Backend.\n\n### Transformer\n\n| Machine | Gateway Throughput `gateway.write_key_requests` | Throughput `processor.transformer_received` |\n| --- | --- | --- |\n| m4.2xLarge | 8Core 32GB | 2.7k/s |\n| m5.xLarge | 4Core 16GB | 1.9K/s |\n| m5.large | 2Core 8GB | 1.7K/s |\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> Transformer is a NodeJS/Koa server launced as cluster of node processes, processses count equal to the number of cores of the machine. Choosing an instance with lower number of core the number of cores in instance processor might reduce the throughput of transformer.\n\n### Batch Router - S3 Destination\n\n| Machine | Gateway Throughput `gateway.write_key_requests` | Throughput `batch_router.dest_successful_events` |\n| --- | --- | --- |\n| m4.2xLarge | 8Core 32GB | 2.7K/s |\n| m5.xLarge | 4Core 16GB | 1.9K/s |\n| m5.large | 2Core 8GB | 1.7K/s |\n\nBelow is an image captured in CloudWatch Metrics showing the captured stats:\n\n[![](https://www.rudderstack.com/docs/images/screenshot-2019-10-25-at-12.22.22-pm.webp)](https://www.rudderstack.com/docs/images/screenshot-2019-10-25-at-12.22.22-pm.webp)\n\nFigure . Gateway Requests and Batch Router Throughputs\n\n## Database Requirements\n\nRudder recommends using a database with at least 1TB allocated storage as there could be downtime to increase storage realtime depending on your database service provider.\n\n### Estimating Storage\n\nIf you want to dig deeper and figure out the right storage size, go through the following example.  \nFollowing variables should be considered to come with a right storage size for your use case.\n\n| Variable | Description | Production sample data |\n| --- | --- | --- |\n| numSources | Total number of sources | 2   |\n| numEventsPerSec | Number of events per sec for a given source | 2500 |\n| avgGwEventSize | Event size that is captured at the gateway by Rudder | 2.1 KB |\n| gwEventOverhead | Size of extra metadata that Rudder stores at Gateway to process the event | 300 B |\n| numDests | Number of enabled destinations for a given source | 3   |\n| avgRtEventSize | The payload size that needs to be sent by the router to the destination after applying transformations | 1.2 KB |\n| rtEventOverhead | Size of extra metadata that Rudder stores to process the event | 300 B |\n\n$$gatewayStorage = numEventsPerSec \\* (avgGwEventSize + gwEventOverhead)$$\n\n$$routerStorage = numEventsPerSec \\* numDests \\* (avgRtEventSize + rtEventOverhead)$$\n\n$$totalStoragePerHour = 3600 \\* \\\\sum\\_{firstSource}^{lastSource} (gatewayStorage + routerStorage)$$\n\nIn the above production example, after substituting the values, _totalStoragePerHour_ adds up to _**120 GB**_\n\nSample your peak load in production to estimate the storage requirements and substitute your values to get an estimate of the storage needed per 1 hour of data.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Event data and tables are ephemeral. In a happy path, we would have only a few minutes of event data being stored.\n> \n> We recommend at least 10 hours worth of event storage computed above to gracefully handle destinations going down for a few hours.\n> \n> If you want to prepare for a destination going for down for days, accommodate them into your storage capacity.\n\n### Estimating Connections\n\nRudder batches requests efficiently to write data. Under heavy load, backend can be configured (`batchTimeoutInMS` and `maxBatchSize` ) to batch more requests to limit concurrent connections to the database. If write latencies to the database are not in permissible thresholds, a new data set needs to be added i.e., backend server and database server.\n\nRudder reads the data back from the database at a constant rate. A sudden spike in user traffic will not result in more read DB requests.\n\n## RAM Requirements\n\nRudder does not cache aggressively and hence does not need huge amount of memory. Load tests were performed on 4 GB and 8 GB memory instances.\n\nRudder caches active user events by default to form configurable user sessions server side. The length of any user session can be configured with `sessionThresholdInS` and `sessionThresholdEvents`. Once a user’s session is formed, that user events are cleared from the cache. If you don’t need sessions, this can be disabled by setting `processSessions` to `false`.\n\n| Variable | Description | Sample data |\n| --- | --- | --- |\n| `numActiveUsers` | Number of active users during a session (2 min) in your application during peak hours | 10000 |\n| `avgGwEventSize` | Event size that is captured at the gateway by Rudder | 2.1 KB |\n| `userEventsInThreshold` | Number of user events in the given threshold i.e., 40 user events in 2 min | 40  |\n\n$$memoryNeeded = numActiveUsers \\* userEventsInThreshold \\* avgGwEventSize$$\n\nMemory required in the above example would be 840 MB.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> The memory estimate does not include the default RAM required for running the OS and the required processes.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Infrastructure provisioning | RudderStack Docs",
    "description": "Provision your infrastructure for RudderStack performance metrics.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/user-guides/administrators-guide/monitoring-and-metrics/",
    "markdown": "# Monitoring and metrics | RudderStack Docs\n\nA look at all stats/metrics generated by the backend and how to monitor the applications using them.\n\n* * *\n\n*     5 minute read  \n    \n\nThe backend uses [statsd](https://github.com/statsd/statsd) client to log stats. These stats can be collected by any statsd server such as Graphite, CloudWatch, etc. For example, [CloudWatch Agent](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Agent-custom-metrics-statsd.html) can be used to collect stats to Amazon CloudWatch.\n\nNote that the collection of stats can be disabled using `enableStats` in [`config.yaml`](https://www.rudderstack.com/docs/user-guides/administrators-guide/config-parameters/).\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Every metric has a dimension called `instanceName` that can be used to filter metrics. This can be helpful in case of multi-node deployments.\n\n## Available metrics\n\n### Recovery Mode\n\nThe backend usually runs in normal mode. If backend crashes and restarts multiple times in a short span, it is started in either **degraded** or **maintenance** mode. In degraded mode, events are collected and stored by the backend gateway, but are not sent to destinations. In maintenance mode, existing database is set aside for further inspection and a new database is used. So, it is important that recovery mode is monitored and appropriate action is taken when backend enters either degraded or maintenance mode.\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> This is the most important metric to monitor as it directly indicates the health of the application.\n\n| Name | Type | Description |\n| --- | --- | --- |\n| `recovery.mode_normal` | `Gauge` | has a value of :<br><br>  <br>1 when running in normal mode<br><br>**0** when running in degraded or maintenance mode |\n\n### Gateway\n\n| Name | Type | Description | Dimensions |\n| --- | --- | --- | --- |\n| `gateway.response_time` | `Timer` | Response time of each request | \\-  |\n| `gateway.batch_size` | `Counter` | Requests are grouped together internally for processing. It captures the size of such batch | \\-  |\n| `gateway.batch_time` | `Timer` | Time taken to process each batch of requests | \\-  |\n| `gateway.write_key_requests` | `Counter` | Number of requests received with each write key | `writekey` |\n| `gateway.write_key_successful_requests` | `Counter` | Number of successful requests with each write key | `writekey` |\n| `gateway.write_key_failed_requests` | `Counter` | Number of failed requests with each write key. \\* | `writekey` |\n\n> \\* Requests fail in cases such as large request size, invalid write key, bad format of events, etc.\n\n### Processor\n\n| Name | Type | Description |\n| --- | --- | --- |\n| `processor.active_users` | `Gauge` | Number of active users. This is based on the most recent events received. Useful for monitoring real time traffic. |\n| `processor.gateway_db_read` | `Counter` | Number of events read from database for processing. |\n| `processor.gateway_db_write` | `Counter` | Number of events whose status is updated in gateway database after processing. |\n| `processor.router_db_write` | `Counter` | Number of events written to router db. |\n| `processor.batch_router_db_write` | `Counter` | Number of events written to batch router db. Note that batch router db is used for handling batch dumping destinations like S3, MinIO, etc. |\n| `processor.transformer_sent` | `Counter` | Number of events sent to transformer. |\n| `processor.transformer_received` | `Counter` | Number of events received from transformer. Note that this may not always be the same as transformer\\_sent even if there are no failures. |\n| `processor.transformer_failed` | `Counter` | Number of events from transformer with error responses. |\n\n### Router\n\n| Name | Type | Description |\n| --- | --- | --- |\n| `router.[destination_code]_delivery_time*` | `Timer` | Time taken to send each event to a specific destination. |\n| `router.[destination_code]_batch_time*` | `Timer` | Time taken by routing worker for each iteration. Multiple events are sent in each iteration. Equivalent to the interval with which a worker picks new batch of events to send.\\*\\* |\n| `router.[destination_code]_failed_attempts*` | `Counter` | Number of retries made for a specification destination. |\n| `router.events_delivered` | `Counter` | Total number of events delivered to all destinations. |\n\n> *   These metrics are each destination type such as GA, AMP, etc. All the different Google Analytics destinations are grouped under a single metric (e.g: router.GA\\_worker\\_network). Useful for monitoring if there are failures or delays in delivering to a particular destination.\n>     \n> *   Number of events picked in each iteration can be configured using `noOfJobsPerChannel` from [`config.yaml`](https://www.rudderstack.com/docs/user-guides/administrators-guide/config-parameters/).\n>     \n\n### BatchRouter\n\nDestinations such as **S3**, **MinIO**, where raw events are dumped, are handled by Batch Router.\n\n| Name | Type | Description | Dimension |\n| --- | --- | --- | --- |\n| `batch_router.dest_successful_events` | `Counter` | Number of successful events sent to a specific destination | `destID` |\n| `batch_router.dest_failed_attempts` | `Counter` | Number of failed attempts per specific destination. Increased number of this metric means we are unable to reach that specific destination (usually due to invalid authorization or endpoint). | `destID` |\n| `batch_router.[destination_code]_dest_upload_time` | `Timer` | Time taken to upload events to a specific destination (S3, MinIO, etc.) | \\-  |\n| `batch_router.errors` | `Counter` | Total number of errors when sending events to destinations | \\-  |\n\n### JobsDB\n\nThese are the backend’s implementation-specific metrics that can be used to analyze the performance based on traffic. JobsDB maintains active events and their statuses. For optimizing db operations, we periodically add new tables in the db and migrate rows from older tables.\n\n| Name | Type | Description |\n| --- | --- | --- |\n| `jobsdb.gw_tables_count` | `Gauge` | Number of gateway tables in JobsDB |\n| `jobsdb.rt_tables_count` | `Gauge` | Number of router tables in JobsDB |\n| `jobsdb.brt_tables_count` | `Gauge` | Number of batch router tables in JobsDB |\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Ideally, the above tables count should not be ever growing. Ever growing tables:\n> \n> *   Indicate events not getting processed and delivered in time.\n> \n> Or\n> \n> *   Indicate the load exceeded what current setup can handle and it is time to scale.\n\n### JobsDB - Table Dump specific\n\nAll the events from gateway tables are periodically dumped to S3/MinIO as a backup and also to facilitate event replay. These stats monitor delays or errors in dumping.\n\n| Name | Type | Description |\n| --- | --- | --- |\n| `jobsdb.table_file_dump_time` | `Timer` | Time taken to dump gateway tables to a JSON file |\n| `jobsdb.file_upload_time` | `Timer` | Time taken to compress and upload the generated JSON files. |\n| `jobsdb.total_table_dump_time` | `Timer` | Total time taken for the whole process of dumping tables to S3. |\n\n### Config Backend Polling\n\nConfiguration of the sources and their corresponding destinations is polled from config backend. Any errors in fetching this config can be monitored using config\\_backend\\_errors.\n\n| Name | Type | Description |\n| --- | --- | --- |\n| `config_backend.errors` | `Counter` | Number of errors in fetching or processing config from control-plane’s backend. |\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "Monitoring and metrics | RudderStack Docs",
    "description": "A look at all stats/metrics generated by the backend and how to monitor the applications using them.",
    "languageCode": "en"
  },
  {
    "url": "https://www.rudderstack.com/docs/user-guides/how-to-guides/how-to-filter-selective-destinations/",
    "markdown": "# How to filter selective destinations\n\nFilter selective destinations while sending your event data via RudderStack.\n\n* * *\n\n*     2 minute read  \n    \n\nRudderStack lets you send your event data only to certain destinations by filtering out the rest.\n\n## Send events to specific destinations\n\nTo send events to specific destinations using the [JavaScript SDK](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-javascript-sdk/), pass an `integrations` object in the `options` parameter of your event method.\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Some RudderStack SDKs follow their own conventions different to the below examples - notably [iOS](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-ios-sdk/#enablingdisabling-events-for-specific-destinations) and [Android](https://www.rudderstack.com/docs/sources/event-streams/sdks/rudderstack-android-sdk/##enabledisable-events-for-specific-destinations). See their respective documentation for the correct event filtering format.\n\nThe following example demonstrates how to send an event **only** to HubSpot and Intercom using the JavaScript SDK:\n\n```\nrudderanalytics.identify(\n  \"1hKOmRA4GRlm\", {\n    email: \"alex@example.com\",\n    name: \"Alex Keener\",\n  }, {\n    integrations: {\n      All: false,\n      \"HubSpot\": true,\n      \"Intercom\": true,\n    },\n  }\n)\n```\n\n> ![info](https://www.rudderstack.com/docs/images/info.svg)\n> \n> Note that:\n> \n> *   `All` is always set to `true` unless explicitly set to `false`. This means RudderStack sends the event to all destinations by default.\n> *   `All: false` instructs RudderStack to not send the event to all destinations.\n\n## Disable events for specific destinations\n\nYou can also disable sending event data to specific destinations. In this case, RudderStack sends the event data to **all the other destinations** except the specified ones.\n\n```\nrudderanalytics.identify(\n  \"1hKOmRA4GRlm\", {\n    email: \"alex@example.com\",\n    name: \"Alex Keener\",\n  }, {\n    integrations: {\n      \"HubSpot\": false,\n      \"Intercom\": false,\n    },\n  }\n)\n```\n\nIn the above code snippet, RudderStack will send the event data to all destinations except HubSpot and Intercom.\n\n## Examples\n\nThis section includes some `track()` calls sent from a variety of SDKs to the specified destinations.\n\n#### **JavaScript SDK**\n\n```\nrudderanalytics.track(\n  \"Page Viewed\", {\n    email: \"alex@example.com\",\n    name: \"Alex Keener\",\n  }, {\n    integrations: {\n      All: false,\n      \"Amazon S3\": true,\n      \"Heap.io\": true,\n    },\n  }\n)\n```\n\n#### **Python SDK**\n\n```\nrudder_analytics.track(\n  \"Page Viewed\", {\n    \"email\": \"alex@example.com\",\n    \"name\": \"Alex Keener\"\n  },\n  integrations = {\n    \"All\": False,\n    \"Amazon S3\": True,\n    \"Heap.io\": True\n  },\n)\n```\n\nIn the above examples, RudderStack SDKs send the `track` events only to the Amazon S3 and Heap.io destinations.\n\n## Destination naming convention\n\nTo filter the destinations, you must specify the exact destination names. To get these names, go to the [RudderStack directory](https://app.rudderstack.com/directory).\n\n> ![warning](https://www.rudderstack.com/docs/images/warning.svg)\n> \n> The destination names are case sensitive.\n\nQuestions? Contact us by [email](mailto:docs@rudderstack.com) or on [Slack](https://rudderstack.com/join-rudderstack-slack-community)",
    "title": "How to filter selective destinations | RudderStack Docs",
    "description": "Filter selective destinations while sending your event data via RudderStack.",
    "languageCode": "en"
  }
]