[{
  "url": "https://docs.growthbook.io/",
  "markdown": "# GrowthBook Documentation | GrowthBook Docs\n\n## Introduction\n\nGrowthBook is an open-source platform for feature flagging and A/B testing built for data teams, engineers, and product managers. It's great whether you're looking to just analyze experiment results or looking to make it easier to deploy code.\n\n### Quick Links[​](#quick-links \"Direct link to Quick Links\")\n\n## Our Goals[​](#our-goals \"Direct link to Our Goals\")\n\nCompanies invest thousands of hours building internal tools for feature flagging and experimentation (A/B testing). They do this to run these systems on their own infrastructure, utilize their own data, and ensure deep integration with their code.\n\nGrowthBook gives data, engineering, and product teams the power of a customizable platform without needing to build it themselves.\n\n*   We believe that **feature flagging** is the best way to release features, and **A/B testing** is the best way to measure their impact.\n    \n*   We believe A/B testing should sit on top of your **existing data and metrics**, wherever they live and however they are defined.\n    \n*   We believe in **data transparency**. See the SQL behind every query, export results as a Jupyter notebook, and view our [stats engines on GitHub](https://github.com/growthbook/growthbook/tree/main/packages/stats).\n    \n*   We are fanatical about **performance**. Our [SDKs](https://docs.growthbook.io/lib) are crazy fast, lightweight, and evaluate everything locally with no network requests.\n    \n*   We believe in **open source**. GrowthBook is open source and free to use. You can run it on your own infrastructure or use our hosted version.\n    \n*   We believe in **privacy & security**. We don't collect any data about your users, and you can run GrowthBook on your own infrastructure.\n    \n*   We believe good ideas come from everywhere. GrowthBook gives you feature flags, making it easy to **test everything** and seamlessly integrate experimentation into your process.\n    \n\nUse the menu or the **Previous**/**Next** links to navigate these docs.\n\n[Join us on Slack](https://slack.growthbook.io/?ref=docs-home) if you need help, want to chat, or are thinking of a new feature. We're here to help—and to make GrowthBook even better.",
  "title": "GrowthBook Documentation | GrowthBook Docs",
  "description": "GrowthBook is an open-source platform for feature flagging and A/B testing built for data teams, engineers, and product managers.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/opensearch.xml",
  "markdown": null,
  "title": "",
  "description": null,
  "languageCode": null
},
{
  "url": "https://docs.growthbook.io/using",
  "markdown": "# Using GrowthBook | GrowthBook Docs\n\n## Guide on using GrowthBook\n\n## Introduction[​](#introduction \"Direct link to Introduction\")\n\nIn today's data-driven world, businesses of all sizes rely on A/B testing to make data-driven decisions. A/B testing, also known as split testing, has come a long way from a simple tool to optimize websites, and is often used as a powerful tool to determine the impact of any changes to your application. By measuring how your user behavior and engagement changes in a controlled manner, you can determine causally if your hypothesis is correct, and make informed data-driven decisions that improve user experience, increase conversions, and drive growth.\n\nThis document is intended to be an open source and continuously updated guide to A/B testing. Whether you're a seasoned expert at running experiments, or just starting out, this book will provide you with the knowledge and skills you need to run a successful A/B testing program, with a specific focus on GrowthBook, an open source feature flagging and A/B testing platform.\n\nIn the following chapters, we'll start with an overview of what A/B testing is, and familiarize you with the terms that are commonly used. We'll cover the basics of statistical significance, sample size, and other key concepts that are essential for understanding A/B testing. Next, we'll cover the best practices for running an A/B test, followed by some of the common mistakes and pitfalls that can affect experiment programs. Finally, we'll go beyond individual A/B tests and talk about how to run an experimentation program, and then specifics of how to do this well with GrowthBook.\n\nWe hope after reading this guide, you'll understand that A/B testing is a critical tool for determining causal impact of the changes you make, as well as optimizing flows. By making informed data-driven decisions, you can improve user experience, increase conversions, and drive growth. With the open source A/B testing tool, GrowthBook, you have a powerful and flexible platform that can help you run experiments quickly and easily. We hope that this guide will give you the knowledge and skills you need to run a successful A/B testing program and make data-driven decisions. Whether you're a developer, product manager, data scientist, marketer, or business owner, A/B testing can help you achieve your goals and drive growth.\n\n## Contents[​](#contents \"Direct link to Contents\")\n\n*   [Fundamentals of AB Testing](https://docs.growthbook.io/using/fundamentals)\n*   [Experimentation Best Practices](https://docs.growthbook.io/using/experimentation-best-practices)\n*   [Experimentation Common Problems](https://docs.growthbook.io/using/experimentation-problems)\n*   [Experimentation As Part of Your Development Process](https://docs.growthbook.io/using/product-development)\n*   [Experimenting in GrowthBook](https://docs.growthbook.io/using/experimenting)\n*   [GrowthBook Organization Best Practices](https://docs.growthbook.io/using/growthbook-best-practices)\n*   [Securing GrowthBook](https://docs.growthbook.io/using/security)\n*   [Experimentation Programs](https://docs.growthbook.io/using/programs)\n\n## Other resources[​](#other-resources \"Direct link to Other resources\")\n\nAt GrowthBook we highly recommended the book: \"Trustworthy Online Controlled Experiments: A Practical Guide to A/B Testing\" by Ron Kohavi, Diane Tang, and Ya Xu. It is available on Amazon or on Ronny's site at [https://www.exp-platform.com/Documents/GuideControlledExperiments.pdf](https://www.exp-platform.com/Documents/GuideControlledExperiments.pdf)",
  "title": "Using GrowthBook | GrowthBook Docs",
  "description": "Introduction",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/overview",
  "markdown": "# An overview of the GrowthBook Platform\n\n## What is GrowthBook?\n\nGrowthBook is a modular platform. You can use it for either Feature Flags, Experiment Analysis, or both.\n\n[**Feature Flags**](https://docs.growthbook.io/app/features) you create in the GrowthBook UI are published to our API as a JSON file. Pass this JSON into our SDKs and use the feature flags throughout your code. If a feature is running as part of an A/B test, we'll fire a tracking callback in the SDK so you can record that event in your data warehouse or analytics platform for later analysis.\n\n[**Experiment Analysis**](https://docs.growthbook.io/app/experiment-configuration) queries your data warehouse for raw experiment data and runs it through our stats engine to produce a report. No raw user-level events or PII are ever sent to GrowthBook. We only get back aggregate info instead (sums, sums of squares, etc.).\n\n![GrowthBook: How it Works Diagram](https://docs.growthbook.io/assets/images/feature-flagging-experimentation-diagram-766-79a603a8de022d325d6e6e7f0cd52d3f.png)\n\n## Feature Flags[​](#feature-flags \"Direct link to Feature Flags\")\n\n[Feature flags](https://docs.growthbook.io/app/features) are a very powerful developer tool. They give you deep control over how and when new functionality is released to your users.\n\nGrowthBook supports 4 types of features:\n\n*   **Boolean (on/off)**\n*   **Number**\n*   **String**\n*   **JSON**\n\nUsing features in your code is easy. Here's an example from our Javascript SDK:\n\n```\n// For boolean featuresif (growthbook.isOn(\"my-feature\")) {  // ... Do something}// For number, string, and JSON featuresconst value = growthbook.getFeatureValue(\"other-feature\", \"fallback\");\n```\n\nGrowthBook also supports multiple environments, so you can, for example, have a feature enabled in **dev** but not **production**.\n\nYou can also change the value of a feature with **Override Rules**. The following types of rules are supported:\n\n*   **Forced Value** - Choose a subset of users based on targeting attributes and assign them all the same value\n*   **Percentage Rollout** - Use random sampling to roll out a new feature value to a percent of users\n*   **A/B Experiment** - Run a controlled A/B test between 2 or more feature values\n\nAll features for an environment are packaged together into a single JSON file. All you need to do is pass this into our [SDKs](https://docs.growthbook.io/lib) along with [user targeting attributes](https://docs.growthbook.io/features/targeting).\n\nRead more about [features here](https://docs.growthbook.io/app/features).\n\n## Experiment Analysis[​](#experiment-analysis \"Direct link to Experiment Analysis\")\n\nGrowthBook needs to connect to your [Data Source](https://docs.growthbook.io/warehouses) in order to query experiment results. We support all of the popular SQL data warehouses in addition to Mixpanel and Google Analytics. GrowthBook is extremely flexible and can support almost any schema structure with a little bit of configuration.\n\n![Data warehouses supported by GrowthBook](https://docs.growthbook.io/assets/images/GrowthBook-supported-DB-766-085e81b3b1c0eca0a0a3b88a05aba730.png)\n\nOnce connected to a data source, you need to build a re-usable library of [Metrics](https://docs.growthbook.io/app/metrics). Metrics are what your experiments are trying to improve. Metrics are defined via SQL (if your data source supports it) or a simple query builder. The following types are supported:\n\n*   **binomial** - simple yes/no conversion metrics (e.g. `started trial`, `bounce rate`, `purchased`)\n*   **count** - when the number or magnitude of conversions matters (e.g. `downloads per user`, `points earned`)\n*   **revenue** - the amount of revenue earned (e.g. `revenue per user`, `average order value`)\n*   **duration** - the time it takes to do something (e.g. `page load time`, `time on site`)\n\nOnce these are metrics are set up, you can import experiments and start analyzing the results. GrowthBook uses a [Bayesian statistics engine](https://docs.growthbook.io/statistics/overview) to determine the probability that a variation is better than the control, as well as how much better it is and how risky it is to stop the experiment now.\n\n![Results Table](https://docs.growthbook.io/assets/images/results-table-781167fd137533b109a3d111851125bf.png)\n\nYour data team can drill down into results by custom [dimensions](https://docs.growthbook.io/app/dimensions), view the raw SQL that GrowthBook is running on your data warehouse, and export results to a Jupyter notebook for even deeper analysis.\n\nRead more about [experiments here](https://docs.growthbook.io/experiments).\n\n## Use Cases[​](#use-cases \"Direct link to Use Cases\")\n\nThere are typically three reasons that teams use GrowthBook.\n\n### 1\\. Full Experimentation Platform[​](#1-full-experimentation-platform \"Direct link to 1. Full Experimentation Platform\")\n\nIn this use case, companies use Feature Flags and our SDKs to run experiments in their applications. Then they use our Experiment Analysis to look at the results and decide on a winner.\n\nThis is best for companies that are either just starting with experimentation or want to completely switch away from their current way of doing things.\n\n### 2\\. Feature Flags Only[​](#2-feature-flags-only \"Direct link to 2. Feature Flags Only\")\n\nIn this use case, companies don't run experiments at all and just use GrowthBook feature flags within their engineering team.\n\nThis is best for companies that don't have enough traffic to run full experiments, but still want all of the benefits that feature flags provide. It's also good for companies that know they will want to run experiments in the future and want to start instrumenting their applications today to get ready.\n\n### 3\\. Experiment Analysis Only[​](#3-experiment-analysis-only \"Direct link to 3. Experiment Analysis Only\")\n\nIn this use case, companies are already running experiments and analyzing results usually with either a home-built reporting system or by manually creating Jupyter notebooks. They use GrowthBook to automate and improve the analysis process to save time and make better decisions.\n\nThis is best for companies that already have a robust process for running experiments and just need a little help analyzing results at scale.\n\n## Next Steps[​](#next-steps \"Direct link to Next Steps\")",
  "title": "An overview of the GrowthBook Platform | GrowthBook Docs",
  "description": "What is GrowthBook and how does it work? Learn about the GrowthBook platform and how it can help you grow your business.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/quick-start",
  "markdown": "# Quick Start Guide to GrowthBook\n\nThis guide walks you through the basics of a full integration of GrowthBook for both feature flagging and A/B testing. You can use GrowthBook for feature flags, running no-code experiments with a visual editor, analyzing experiment results, or any combination of the above. Feel free to skip to the sections that best apply to your use case.\n\nnote\n\nIn our documentation, we use **A/B test** and **experiment** interchangeably.\n\n## Set Up GrowthBook[​](#set-up-growthbook \"Direct link to Set Up GrowthBook\")\n\nUse GrowthBook hosted on our **cloud** or **self-host** it. For the easiest setup, [sign up for a free account](https://app.growthbook.io/). If you prefer to self-host, follow the [instructions here](https://docs.growthbook.io/self-host) or on our GitHub page.\n\nOnce you have a GrowthBook account set up, you're ready to start feature flagging and experimenting!\n\n## Feature Flags[​](#feature-flags \"Direct link to Feature Flags\")\n\n### Step 1. Add an SDK Connection[​](#step-1-add-an-sdk-connection \"Direct link to Step 1. Add an SDK Connection\")\n\nTo use Feature Flags, use an SDK Connection to connect GrowthBook to your app.\n\nFrom the menu, choose **SDK Configuration** → **SDK Connections**. Then, click **Add SDK Connection**.\n\nName your SDK connection, select the language you're using in your application, and configure additional options. Don't worry! These settings can be changed at any time. To use GrowthBook with multiple languages, create a separate SDK Connection for each one.\n\n![New SDK Connection](https://docs.growthbook.io/images/quick-start/quick-start-new-sdk-connection.png)\n\nWith the SDK Connection created, you're now ready to install the SDK in your application.\n\n### Step 2. Integrate GrowthBook Into Your Application[​](#step-2-integrate-growthbook-into-your-application \"Direct link to Step 2. Integrate GrowthBook Into Your Application\")\n\nUse GrowthBook SDKs to evaluate feature flags and run experiments. Tailored instructions based on your selected language and settings will guide you through the installation process. The [full SDK docs](https://docs.growthbook.io/lib) are also available.\n\nThe basics of installing the SDKs are:\n\n*   Grab the [GrowthBook SDK](https://docs.growthbook.io/lib) package for your language.\n*   Add the basic initialization code to your application.\n*   Make sure `clientKey` and `apiHost` are set correctly.\n*   Optionally, add any targeting attributes you wish to use for feature flags and experiments.\n\ntip\n\nIf your application has multiple languages or platforms, you can create a separate SDK Connection for each one. GrowthBook features and experiments will work the same across all languages, platforms, and environments!\n\n### Step 3. Create a Feature Flag[​](#step-3-create-a-feature-flag \"Direct link to Step 3. Create a Feature Flag\")\n\nOn the **Features** page, create your first feature flag.\n\n![Create Feature](https://docs.growthbook.io/images/features/feature-create-feature-1.png)\n\nThe **Feature Key** is what you will reference in your application and cannot be changed later.\n\nFeature flags in GrowthBook are robust, supporting advanced [targeting](https://docs.growthbook.io/features/targeting), powerful [rule evaluation](https://docs.growthbook.io/features/rules), [pre-requisite features](https://docs.growthbook.io/features/prerequisites), JSON schema validation, and more. In this quick start, we'll just stick with a simple boolean feature flag that is always `on` or `off` for everyone.\n\n### Step 4. Use the Feature in Your Application[​](#step-4-use-the-feature-in-your-application \"Direct link to Step 4. Use the Feature in Your Application\")\n\nWhen you create your first feature, you'll see instructions on how to use it in your application. Here's an example using our JavaScript SDK:\n\n```\nif (gb.isOn(\"my-feature\")) {    console.log(\"It's On!\")}\n```\n\nIt really is that simple to get started! For next steps, we recommend reading our [Feature Flag Basics](https://docs.growthbook.io/features/basics) page, which goes into more depth.\n\nFeature flags are the foundation for powerful experimentation. In the next section, we show you how to use them to run no-code experimentation using our Visual Editor. Need more advanced options? Dive into our [complete guide for code-based experimentation](https://docs.growthbook.io/feature-flag-experiments).\n\n## No-Code Experimentation[​](#no-code-experimentation \"Direct link to No-Code Experimentation\")\n\n### Step 1. Create an SDK Connection[​](#step-1-create-an-sdk-connection \"Direct link to Step 1. Create an SDK Connection\")\n\nNavigate to **SDK Configuration** → **SDK Connections**. Then, add a new SDK Connection. For the language, choose any no/low-code options: **Webflow**, **Wordpress**, **Shopify**, or **Script Tag**.\n\n![Add SDK Connection](https://docs.growthbook.io/assets/images/webflow-sdk-connection-e862e170a41e8efc1a1496130070b738.png)\n\n### Step 2. Add the Script Tag to Your Website's Head[​](#step-2-add-the-script-tag-to-your-websites-head \"Direct link to Step 2. Add the Script Tag to Your Website's Head\")\n\nWhen you create an SDK Connection, GrowthBook displays tailored instructions based on your no-code platform and settings. Typically, these instructions involve adding a single script tag to the head of your website. It will look something like the example below (replace `YOUR_CLIENT_KEY` with your uniquely generated client ID):\n\n```\n<script async  data-client-key=\"YOUR_CLIENT_KEY\"  src=\"https://cdn.jsdelivr.net/npm/@growthbook/growthbook/dist/bundles/auto.min.js\"></script>\n```\n\n### Step 3. Install the GrowthBook Chrome Extension[​](#step-3-install-the-growthbook-chrome-extension \"Direct link to Step 3. Install the GrowthBook Chrome Extension\")\n\nBefore using the Visual Editor, you must [install our Chrome Extension](https://chromewebstore.google.com/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia).\n\nThis extension enables you to make changes to your website by pointing and clicking. Use it to test different headlines, CTA text, hero images, and more.\n\n### Step 4. Create a New Visual Experiment[​](#step-4-create-a-new-visual-experiment \"Direct link to Step 4. Create a New Visual Experiment\")\n\nTo use the visual editor, add a new experiment. Go to **Experiments** and click **Add Experiment**.\n\n![Design a new experiment](https://docs.growthbook.io/assets/images/add-experiment-modal-15681f50cca71852a1723562ee4bd078.png)\n\nChoose **Design a New Experiment**. Then, fill out the fields (hypothesis, variation names, goal metrics, etc.). Don't worry, you can change these values later.\n\nOnce you created an experiment, you will be prompted to launch the Visual Editor.\n\nUse the editor to make changes to your site. To return to GrowthBook, click the **Done** button. We have an entire guide dedicated to [setting up and using the Visual Editor](https://docs.growthbook.io/app/visual), so check it out if you get stuck or want to try some of the more advanced features like drag-and-drop reordering.\n\n### Step 5. Start Your Experiment![​](#step-5-start-your-experiment \"Direct link to Step 5. Start Your Experiment!\")\n\nWhen you are ready, click the **Start Experiment** button. Within seconds, GrowthBook will begin to bucket users into your variations. You can just as easily stop or make changes if needed.\n\nFollow the Experiment Analysis section below to learn how to connect GrowthBook to your data and view results. Depending on the analytics tool and data warehouse that you use, it can take up to 24 hours for results to start showing up after you start an experiment.\n\n## Experiment Analysis[​](#experiment-analysis \"Direct link to Experiment Analysis\")\n\n### Step 1. Connect to Your Data Warehouse[​](#step-1-connect-to-your-data-warehouse \"Direct link to Step 1. Connect to Your Data Warehouse\")\n\nGrowthBook is warehouse native: it connects to your data warehouse and queries it to get the results of your experiments. We support all the popular SQL data warehouses such as BigQuery, Snowflake, Postgres, MySQL, Redshift, Databricks, and even Mixpanel. GrowthBook is extremely flexible and can support almost any schema structure with a bit of configuration.\n\n**Don't have a data warehouse?**\n\nTo connect GrowthBook to your data warehouse, add a data source. Go to **Metrics and Data** → **Data Sources**. From here, click **Add Data Source**. Follow the instructions to connect to your data warehouse and event trackers. Providing your data warehouse information enables GrowthBook to connect to your data warehouse and execute queries. The event tracker information allows GrowthBook to generate more accurate SQL templates given the schema the event tracker uses.\n\nAdditional guides on [how to set up the data source for your specific data warehouse](https://docs.growthbook.io/warehouses) are available.\n\n### Step 2. Add a Metric or Two[​](#step-2-add-a-metric-or-two \"Direct link to Step 2. Add a Metric or Two\")\n\nGrowthBook needs to know what metrics you want to measure for your experiments. For the easiest setup, we recommend using Fact Tables. Most users create a Fact Table for each type of event (Sign Up, Purchase, etc.). With Fact Tables in place, you can then quickly create a library of metrics (Sign-Up Rate, Revenue per User, Items per Order, etc.).\n\nGo to **Metrics and Data** → **Fact Tables**. Click **Add a Fact Table** and edit the default SQL if needed. Here's an example SQL query for an Orders fact table.\n\n```\nSELECT  user_id,  timestamp,  qty,  amountFROM orders\n```\n\nOnce the fact table is created, you can easily add metrics on top of it. For example, consider a simple proportion metric, which measures the percentage of experiment users who complete an action at least once. In this case, it'd measure the percentage of users who made a purchase.\n\nMetrics in GrowthBook are powerful and have many advanced settings. Read about them on our [Fact Tables page](https://docs.growthbook.io/app/fact-tables).\n\n### Step 3. View Experiment Results[​](#step-3-view-experiment-results \"Direct link to Step 3. View Experiment Results\")\n\nGo to the **Experiments** page. If you implemented an experiment using feature flags or our Visual Editor, your experiment will already be listed. Click through to it. If you ran your experiment outside of GrowthBook instead, that's fine, too! Add a new experiment and select the **Analyze Existing** option.\n\nOnce inside your experiment, go to the **Results** tab. Edit your analysis settings and pick the metrics you created earlier. The results will show up in a table like this:\n\n![Results Table](https://docs.growthbook.io/assets/images/results-table-781167fd137533b109a3d111851125bf.png)\n\nWe have an [entire page in our docs](https://docs.growthbook.io/app/experiment-results) just about these results and how to interpret them.\n\n## Next Steps[​](#next-steps \"Direct link to Next Steps\")",
  "title": "Quick Start Guide to GrowthBook | GrowthBook Docs",
  "description": "The basic instructions for getting started with GrowthBook",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/app/features",
  "markdown": "# Feature Flags | GrowthBook Docs\n\nFeature Flags enable you to change your application's behavior from within the GrowthBook UI. For example, turn on/off a sales banner or change the title of your pricing page.\n\nYou can set a global value for everyone, use advanced targeting to assign values to users, and run experiments to see which value is better.\n\nFeature flags aren't limited to front-end changes. Use them on your back-end to gradually release a new ML model or enable new fields in an API response.\n\n## Why use Feature Flags?[​](#why-use-feature-flags \"Direct link to Why use Feature Flags?\")\n\nFeature flags are a powerful tool for decoupling code deploys from feature releases. This enables you to release code more frequently and with less risk. It also enables you to do things like easily launch any new feature to a specific subset of users (like beta users), gradually roll out a new features, or turn any feature into an A/B test (experiment).\n\n## How to get started with Feature Flags?[​](#how-to-get-started-with-feature-flags \"Direct link to How to get started with Feature Flags?\")\n\n1.  Create an [SDK Connection](#sdk-connections) in GrowthBook\n2.  See [Feature Flag Basics](https://docs.growthbook.io/features/basics) to learn the fundamentals and see the types of features we support (boolean, number, string, JSON)\n3.  Learn about [Targeting](https://docs.growthbook.io/features/targeting) to target features to users with certain attributes\n4.  Add [Override Rules](https://docs.growthbook.io/features/rules) to target users with a Forced Value, rollout your feature to a percentage of users, or run an experiment\n5.  Learn about [Scheduling](https://docs.growthbook.io/features/scheduling) features and different feature [Environments](https://docs.growthbook.io/features/environments)\n\n## SDK Connections[​](#sdk-connections \"Direct link to SDK Connections\")\n\nIn order to use feature flags in your application, you need to create an **SDK Connection** in GrowthBook.\n\nAt a high level, the SDK Connection generates a unique clientKey which grants read-only access to feature flags in a specific environment. The SDKs use this to fetch feature flag states and override rules from the GrowthBook API.\n\nOn GrowthBook Cloud, we have a global CDN in front of the API ([https://cdn.growthbook.io](https://cdn.growthbook.io/)) to ensure low latency responses from anywhere in the world. The CDN has a 30-second TTL, so changes to a feature may take a little time to be reflected.\n\n### GrowthBook Proxy[​](#growthbook-proxy \"Direct link to GrowthBook Proxy\")\n\nWe also offer a pre-built proxy server you can deploy on your own infrastructure. This can be put in front of either GrowthBook Cloud or a self-hosted GrowthBook instance.\n\nThe GrowthBook Proxy offers the following benefits:\n\n*   Fast - Requests served from an in-memory cache close to your app servers\n*   Scalable - A single Proxy server can handle over 10,000 reqs/second. Horizontally scale for more\n*   Responsive - Changes in GrowthBook are rolled out to users in under a second\n\nYou can read more about the GrowthBook Proxy [here](https://docs.growthbook.io/self-host/proxy).",
  "title": "Feature Flags | GrowthBook Docs",
  "description": "Learn about feature flags and how to use them in your application.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/experiments",
  "markdown": "# Running Experiments on GrowthBook | GrowthBook Docs\n\nGrowthBook has a few different ways to run experiments or AB tests depending on your needs. This guide will walk you through the different ways of running experiments on GrowthBook.\n\n## Server Side and Mobile Experiments[​](#server-side-and-mobile-experiments \"Direct link to Server Side and Mobile Experiments\")\n\nServer-side A/B testing, also known as backend or server-side experimentation, is a technique used in software development and web applications to test measure the impact of any code changes or new features. The changes may impact both the user interface and the backend of the application, but the decision about what version to serve a user is decided on the server. This has a number of advantages over client side experiments, specifically, that it allows you to run very complex tests that may involve a lot of different parts of the code, and span multiple parts of your application. It also avoids any issues with flickering that can happen with client side testing.\n\n### Feature Flag Experiments[​](#feature-flag-experiments \"Direct link to Feature Flag Experiments\")\n\nWith GrowthBook, the easiest way to do server-side testing is by using feature flags. Each feature flag has conditional logic ([rules](https://docs.growthbook.io/features/rules)) which controls how a feature should be shown, and if a feature should be shown as part of an experiment. GrowthBook also lets you target any feature or rule based on the [targeting attributes](https://docs.growthbook.io/features/targeting) you define. With GrowthBook, you can add an experiment rule to a feature that will randomly assign the users based on some hashing attribute into one of your experiment variations. You can read more about feature flag experiment rules [here](https://docs.growthbook.io/features/rules), or more details on running an [experiment with feature flags](https://docs.growthbook.io/feature-flag-experiments).\n\n### Inline Experiments[​](#inline-experiments \"Direct link to Inline Experiments\")\n\nYou can also run server-side experiments by using inline experiments directly with our SDK. This requires no 3rd party requests, as the experiment conditions and settings can be written directly into the code. How you implement in-line experiments depends on the SDK language you're using, you can read more about this from our [SDKs pages](https://docs.growthbook.io/lib).\n\n## Client Side (Browser) Experiments[​](#client-side-browser-experiments \"Direct link to Client Side (Browser) Experiments\")\n\nClient-side A/B testing, also known as frontend or client-side experimentation, is a way to test visual changes to your application. The server returns the same code to all users, and the experiment assignments and variations are handled by the client, typically in [Javascript](https://docs.growthbook.io/lib/js) or [React](https://docs.growthbook.io/lib/react).\n\nWhen the client loads your application, our SDK will check to see if the user should be part of any experiments, and if so, assign them and the client code will serve that variations treatment to them. GrowthBook's client side SDKs can handle all of this for you, and you can also serve client-side A/B test via our feature flags, or using our visual editor.\n\nClient-side A/B tests are great for testing visual changes to your application, but they do have some drawbacks. One of the most common issues is caused by the delay in loading the specific variation to a user, which may cause a flash or flickering as the experiment loads. This can be reduced by using inline-experiments, or by moving the GrowthBook SDK code higher in the code so it loads at the same time or before the page. Sometimes the hashing attribute may not be available until your tracking software has loaded, and you may need to use a custom tracking id.\n\n### Feature Flags[​](#feature-flags \"Direct link to Feature Flags\")\n\nGrowthBook's feature flags can work just as well from the client/browser as it does server side. The feature flag's conditional logic ([rules](https://docs.growthbook.io/features/rules)) controls how a feature should be shown, and if a feature should be shown as part of an experiment. The same targeting and override rules apply exactly the same to client-side experimentation.\n\n### Inline Experiments[​](#inline-experiments-1 \"Direct link to Inline Experiments\")\n\nJust like with inline server-side experiments, you can run experiments inline on the client. This requires no 3rd party requests, as the experiment conditions and settings can be written directly into the code, and processed by the SDK. How you implement in-line experiments depends on the SDK language you're using, you can read more about this from our [SDKs pages](https://docs.growthbook.io/lib).\n\n### Visual Editor (WYSIWYG) Experiments[​](#visual-editor-wysiwyg-experiments \"Direct link to Visual Editor (WYSIWYG) Experiments\")\n\nGrowthBook has a visual editor for running experiments on the front-end of your website without requiring any code changes. Our visual editor uses the same client-side SDK used for feature flags and A/B testing.\n\n## API / ML Experiments[​](#api--ml-experiments \"Direct link to API / ML Experiments\")\n\nGrowthBook's SDKs works well with anywhere code can run, and as such you can use it in the API or when running machine learning models. And, with our deterministic hashing method for assignment, you can even be sure users get assigned the same variation across your platform without needing to store state from GrowthBook.\n\n## Custom Assignment or 3rd Party Experiments[​](#custom-assignment-or-3rd-party-experiments \"Direct link to Custom Assignment or 3rd Party Experiments\")\n\nGrowthBook is a modular platform and can be used for experiment analysis if you are using custom assignment code or another experimentation system for randomization of users into variations. As long as the exposure/assignment information is available from within your data warehouse, you can use GrowthBook to analyse the results of your experiments.\n\n## How GrowthBook Assigns Users to Experiments[​](#how-growthbook-assigns-users-to-experiments \"Direct link to How GrowthBook Assigns Users to Experiments\")\n\nGrowthBook uses a consistent hashing algorithm to assign users to experiments. This means that the same user will always get the same variation given the same experiment settings (experiment key, and user hashing id). This is useful because it means that you can run experiments across multiple pages, or even multiple applications, and the user will always get the same variation. It also means that GrowthBook stores no state, and requires no additional cookies. It's important to note that none of these implies that GrowthBook exposes a mechanism known as sticky-bucketing. It's all about the consistent evaluation of variations based on the particular experiment settings.\n\n## Best Practices[​](#best-practices \"Direct link to Best Practices\")\n\n### Running A/A Tests[​](#running-aa-tests \"Direct link to Running A/A Tests\")\n\nAn A/A test is the same as an A/B test, but each variation has no actual difference in the application. This lets you test out that your systems are working correctly, as you should see no significant differences between the variations. We suggest that you first an A/A test to validate your experimentation implementation is correctly splitting traffic, and producing statistically valid results.\n\n### When to Expose Users to Experiments[​](#when-to-expose-users-to-experiments \"Direct link to When to Expose Users to Experiments\")\n\nWhen running an experiment it is best if you can only expose users as close to the actual treatment exposure as possible. This means that if you're testing something like new signup flow, you don't expose all users, including those who never open that window. Including users who did not see the treatment will increase the noise and reduce the ability to detect any differences.\n\nIf assignment is unavoidably separated from exposure, you can use an activation metric to filter out these un-exposed users from the analysis.\n\n### Avoiding Flickering[​](#avoiding-flickering \"Direct link to Avoiding Flickering\")\n\nFlickering with front end or client-side A/B tests is an artifact from all client-side A/B testing tools. This is caused by a delay in loading the specific variation for a user, which may cause a flash or flickering as the experiment loads. This can be reduced by using inline-experiments, or by moving the GrowthBook SDK code higher in the code file, or using server side A/B tests.\n\nThere are a few other ways to reduce flickering that some platforms utilize. One common \"flicker free\" technique is to load a white overlay, or just hide parts of the page, as the page loads. The result is that users cannot see any flickering that may be happening beneath the overlay as the variations are loaded.\n\n### Sample Size[​](#sample-size \"Direct link to Sample Size\")\n\nUnderstanding experiment power and MDE are important to predict how many samples are required. There are numerous online calculators that can be used to help you predict the sample size. Typical rule of thumb for the lowest number of samples required is that you want at least 200 conversion events per variation. So for example if you have a registration page which has a 10% conversion rate, and you have a 2 way (A and B) experiment that is looking to improve the member registrations, you will want to expose the experiment to at least 4,000 people (2000 per variation).\n\n### Test Duration[​](#test-duration \"Direct link to Test Duration\")\n\nDue to the natural variability in traffic day to day and hour to hour, experimentation teams will often set a minimum test duration within which a test cannot be called. This helps you avoid optimizing a product for just the users that happen to visit when the test is started. For example, if the weekend traffic of your product is different from the traffic during the week, if you started a test on Friday and ended it on Monday, you may not get a complete picture of the impact your changes have to your weekday traffic.\n\nTypical test durations are 1 to 2 weeks, and usually care needs to be taken over holidays. You may also find that a test would need to run for a month or more to get the power required for the experiment. Very long running tests can be hard to justify as you have to keep the variations of the experiment unchanged for duration, and this may limit your team's velocity towards potentially higher impact changes.\n\n### Interaction Effects and Mutual Exclusion[​](#interaction-effects-and-mutual-exclusion \"Direct link to Interaction Effects and Mutual Exclusion\")\n\nWhen you start having the ability to run a lot of A/B tests, you may start worrying about how tests running in parallel may interact and effect the other results. For example you may want to test a change in the CTA button on your purchase page, and also test changing the price. It can be difficult to figure out if any two tests will meaningfully interact, and many will run the tests in serial in an abundance of caution.\n\nHowever, meaningful interactions are actually quite rare, and keeping a higher rate of experimentation is usually more beneficial. You can run analysis after the experiments to see if there were any interaction effects which would change your conclusions. If you need to run mutually exclusive tests, you can use GrowthBook’s namespace feature.\n\n### Experimentation Frequency[​](#experimentation-frequency \"Direct link to Experimentation Frequency\")\n\nHaving a high frequency of A/B testing is important for running a success experimentation program. The main reasons why experimentation frequency is important are:\n\n*   **Maximizing chances**: Since success rates are typically low for any given experiment, and large changes are even more rare, by having a high frequency of A/B testing you are maximizing your chance of having impactful experiments.\n*   **Continuous improvement**: A high frequency of A/B testing allows you to continuously improve your website or application. By testing small changes frequently, you can quickly identify and implement changes that improve user experience, engagement, and conversion rates.\n*   **Adaptability**: A high frequency of A/B testing allows you to quickly adapt to changes in user behavior, market trends, or other external factors that may impact your website or application. By testing frequently, you can identify and respond to these changes more quickly, ensuring that your site or app remains relevant and effective.\n*   **Avoiding stagnation**: A high frequency of A/B testing can help you avoid stagnation and complacency. By continually testing and experimenting, you can avoid falling into a rut or becoming overly attached to a specific design or strategy, and instead remain open to new ideas and approaches.",
  "title": "Running Experiments on GrowthBook | GrowthBook Docs",
  "description": "Understanding the ways to run experiments with GrowthBook",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/warehouses",
  "markdown": "# Connecting to your data warehouse\n\n## Overview[​](#overview \"Direct link to Overview\")\n\nOne of the major benefits of Growthbook is that your data remains securely stored in your data warehouse, and only the aggregated statistics are transmitted to GrowthBook servers or your self-hosted environment.\n\n## Preparing your data warehouse[​](#preparing-your-data-warehouse \"Direct link to Preparing your data warehouse\")\n\nYour data should be safe from modification as GrowthBook only runs `SELECT` queries (or the equivalent for non-SQL data sources). Still we still always recommend creating read-only users with as few permissions as possible - ideally just read permissions on the tables with the data that needs to be aggregated.\n\nIf you are using GrowthBook Cloud ([https://app.growthbook.io](https://app.growthbook.io/)), make sure to whitelist the ip address `52.70.79.40` if applicable.\n\n## Saving your connection configuration on Growthbook Cloud or your self hosted server[​](#saving-your-connection-configuration-on-growthbook-cloud-or-your-self-hosted-server \"Direct link to Saving your connection configuration on Growthbook Cloud or your self hosted server\")\n\nThe data source connection info is encrypted twice - once within the app and again by the database when persisting to disk. Most data sources have straight forward connection parameters like host, port, username, and password. However some are slightly more involved and is convered in the guides below.\n\n## Connection guides[​](#connection-guides \"Direct link to Connection guides\")\n\n*   [AWS Athena](https://docs.growthbook.io/warehouses/athena)\n*   [BigQuery](https://docs.growthbook.io/guide/bigquery)\n*   [ClickHouse](https://docs.growthbook.io/warehouses/clickhouse)\n*   [Databricks](https://docs.growthbook.io/warehouses/databricks)\n*   [Mixpanel](https://docs.growthbook.io/warehouses/mixpanel)\n*   [MsSQL/SQL Server](https://docs.growthbook.io/warehouses/ms-sql-or-sql-server)\n*   [MySQL/MariaDB](https://docs.growthbook.io/warehouses/mysql-or-mariadb)\n*   [Postgres](https://docs.growthbook.io/warehouses/postgres)\n*   [PrestoDB or Trino](https://docs.growthbook.io/warehouses/prestodb-or-trino)\n*   [Redshift](https://docs.growthbook.io/warehouses/redshift)\n*   [Snowflake](https://docs.growthbook.io/warehouses/snowflake)",
  "title": "Connecting to your data warehouse | GrowthBook Docs",
  "description": "This document outlines the steps needed to connect GrowthBook to your data warehouse.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/",
  "markdown": "# GrowthBook SDKs | GrowthBook Docs\n\nWe offer official SDKs for many popular languages and frameworks:\n\n*   [Javascript/Typescript](https://docs.growthbook.io/lib/js)\n*   [React](https://docs.growthbook.io/lib/react)\n*   [Vue](https://docs.growthbook.io/lib/vue)\n*   [HTML Script Tag](https://docs.growthbook.io/lib/script-tag)\n*   [Node.js](https://docs.growthbook.io/lib/node)\n*   [PHP](https://docs.growthbook.io/lib/php)\n*   [Ruby](https://docs.growthbook.io/lib/ruby)\n*   [Python](https://docs.growthbook.io/lib/python)\n*   [Go](https://docs.growthbook.io/lib/go)\n*   [Java](https://docs.growthbook.io/lib/java)\n*   [C#](https://docs.growthbook.io/lib/csharp)\n*   [Elixir](https://docs.growthbook.io/lib/elixir)\n*   [Kotlin (Android)](https://docs.growthbook.io/lib/kotlin)\n*   [Swift](https://docs.growthbook.io/lib/swift)\n*   [Flutter](https://docs.growthbook.io/lib/flutter)\n*   [React Native](https://docs.growthbook.io/lib/react-native)\n\nThere is also a guide if you want to [build your own](https://docs.growthbook.io/lib/build-your-own).\n\nIt's not required to use any of these libraries. The only requirement is that you track in your datasource when users are put into an experiment and which variation they received.",
  "title": "GrowthBook SDKs | GrowthBook Docs",
  "description": "Learn about GrowthBook's supported SDKs",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/node",
  "markdown": "# Node.js SDK | GrowthBook Docs\n\nWe officially support Node 18 and above.\n\n## Installation[​](#installation \"Direct link to Installation\")\n\nInstall with a package manager\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save @growthbook/growthbook\n```\n\n## Quick Usage[​](#quick-usage \"Direct link to Quick Usage\")\n\nGrowthBook instances are scoped to a single incoming request. The easiest way to do this is with Middleware:\n\n```\n// Example using Expressapp.use(function(req, res, next) {  // Create a GrowthBook instance and store in the request  req.growthbook = new GrowthBook({    apiHost: \"https://cdn.growthbook.io\",    clientKey: \"sdk-abc123\"  });  // TODO: Add user targeting attributes from cookies, headers, etc.  req.growthbook.setAttributes({    id: req.user?.id  });  // Clean up at the end of the request  res.on('close', () => req.growthbook.destroy());  // Wait for features to load (will be cached in-memory for future requests)  req.growthbook.init({timeout: 1000}).then(() => next())});\n```\n\nThen, you can access the GrowthBook instance from any route:\n\n```\napp.get(\"/\", (req, res) => {  const gb = req.growthbook;  // Boolean on/off flag  if (gb.isOn(\"my-feature\")) {    // Do something  }  // String/Number/JSON flag  const value = gb.getFeatureValue(\"my-string-feature\", \"fallback\");  console.log(value);})\n```\n\n## Loading Features and Experiments[​](#loading-features-and-experiments \"Direct link to Loading Features and Experiments\")\n\nIn order for the GrowthBook SDK to work, it needs to have feature and experiment definitions from the GrowthBook API. There are a few ways to get this data into the SDK.\n\n### Built-in Fetching and Caching[​](#built-in-fetching-and-caching \"Direct link to Built-in Fetching and Caching\")\n\nIf you pass an `apiHost` and `clientKey` into the GrowthBook constructor, it will handle the network requests, caching, retry logic, etc. for you automatically.\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",});// Wait for features to be downloaded with a timeout (in ms)gb.init({ timeout: 2000 }).then(() => next())\n```\n\nThe network request to download features is cached in memory and uses a stale-while-revalidate (SWR) pattern. So the first call to `gb.init()` may be slow, but all subsequent calls should resolve immediately.\n\n#### Error Handling[​](#error-handling \"Direct link to Error Handling\")\n\nIn the case of network issues that prevent the features from downloading in time, the `init` call will not throw an error. Instead, it will stay in the default state where every feature evaluates to `null`.\n\nYou can still get access to the error if needed:\n\n```\nconst res = await gb.init({  timeout: 1000});console.log(res);\n```\n\nThe return value has 3 properties:\n\n*   **status** - `true` if the GrowthBook instance was populated with features/experiments. Otherwise `false`\n*   **source** - Where this result came from. One of the following values: `network`, `cache`, `init`, `error`, or `timeout`\n*   **error** - If status is `false`, this will contain an `Error` object with more details about the error\n\n### Custom Integration[​](#custom-integration \"Direct link to Custom Integration\")\n\nIf you prefer to handle the network and caching logic yourself, you can pass in a full JSON \"payload\" directly into the SDK. For example, you might store features in Postgres or Redis.\n\n```\nawait gb.init({  payload: {    features: {      \"feature-1\": {...},      \"feature-2\": {...},      \"another-feature\": {...},    }  }})\n```\n\nThe data structure for \"payload\" is exactly the same as what is returned by the GrowthBook SDK endpoints and webhooks.\n\nNote: you don't need to specify `clientKey` or `apiHost` on your GrowthBook instance since no network requests are being made in this case.\n\n#### Synchronous Init[​](#synchronous-init \"Direct link to Synchronous Init\")\n\nThere is a alternate synchronous version of init named `initSync`, which can be useful in some environments. There are some restrictions/differences:\n\n*   You MUST pass in `payload`\n*   The `payload` MUST NOT have encrypted features or experiments\n*   If you use sticky bucketing, you MUST pass `stickyBucketAssignmentDocs` into your GrowthBook constructor\n*   The return value is the GrowthBook instance to enable easy method chaining\n\n## Streaming Updates[​](#streaming-updates \"Direct link to Streaming Updates\")\n\nThe GrowthBook SDK supports streaming with Server-Sent Events (SSE). When enabled, changes to features within GrowthBook will be streamed to the SDK in realtime as they are published. This is only supported on GrowthBook Cloud or if running a GrowthBook Proxy Server.\n\nNode.js does not natively support SSE, but there is a small library you can install:\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save eventsource\n```\n\nThen, do the following during app startup:\n\n```\nconst { setPolyfills, prefetchPayload } = require(\"@growthbook/growthbook\");// Configure GrowthBook to use the eventsource librarysetPolyfills({  EventSource: require(\"eventsource\"),});// Start a streaming connectionprefetchPayload({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  streaming: true}).then(() => console.log(\"Streaming connection open!\"))\n```\n\nThis will make an initial network request to download the features payload from the GrowthBook API. Then, it will open a streaming connection to listen to updates.\n\nWhen a new GrowthBook instance is created in your middleware, it will use the latest available payload. The payload for this GrowthBook instance will be locked and frozen, so you don't have to worry about the payload changing mid-request and causing weird edge cases in your app.\n\n## Caching[​](#caching \"Direct link to Caching\")\n\nThe JavaScript SDK has 2 caching layers:\n\n1.  In-memory cache (enabled by default)\n2.  Persistent localStorage cache (disabled by default, requires configuration)\n\n### Configuring Local Storage[​](#configuring-local-storage \"Direct link to Configuring Local Storage\")\n\nHere is an example of using Redis as your persistent localStorage cache:\n\n```\nconst { setPolyfills } = require(\"@growthbook/growthbook\");setPolyfills({  localStorage: {    // Example using Redis    getItem: (key) => redisClient.get(key),    setItem: (key, value) => redisClient.set(key, value),  }});\n```\n\n### Cache Settings[​](#cache-settings \"Direct link to Cache Settings\")\n\nThere are a number of cache settings you can configure within GrowthBook.\n\nBelow are all of the default values. You can call `configureCache` with a subset of these fields and the rest will keep their default values.\n\n```\nimport { configureCache } from \"@growthbook/growthbook\";configureCache({  // The localStorage key the cache will be stored under  cacheKey: \"gbFeaturesCache\",  // Consider features stale after this much time (60 seconds default)  staleTTL: 1000 * 60,  // Cached features older than this will be ignored (24 hours default)  maxAge: 1000 * 60 * 60 * 24,  // Set to `true` to completely disable both in-memory and persistent caching  disableCache: false,})\n```\n\n## Experimentation (A/B Testing)[​](#experimentation-ab-testing \"Direct link to Experimentation (A/B Testing)\")\n\nIn order to run A/B tests, you need to set up a tracking callback function. This is called every time a user is put into an experiment and can be used to track the exposure event in your analytics system (Segment, Mixpanel, GA, etc.).\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  trackingCallback: (experiment, result) => {    // Example using Segment    analytics.track(\"Experiment Viewed\", {      experimentId: experiment.key,      variationId: result.key,    });  },});\n```\n\n### Feature Flag Experiments[​](#feature-flag-experiments \"Direct link to Feature Flag Experiments\")\n\nThere is nothing special you have to do for feature flag experiments. Just evaluate the feature flag like you would normally do. If the user is put into an experiment as part of the feature flag, it will call the `trackingCallback` automatically in the background.\n\n```\n// If this has an active experiment and the user is included,// it will call trackingCallback automaticallyconst newLogin = gb.isOn(\"new-signup-form\");\n```\n\nIf the experiment came from a feature rule, `result.featureId` in the trackingCallback will contain the feature id, which may be useful for tracking/logging purposes.\n\n### Deferred Tracking[​](#deferred-tracking \"Direct link to Deferred Tracking\")\n\nSometimes, you aren't able to track analytics events from Node.js and you need to do it from the front-end instead.\n\nIf that is the case for your app, do not specify a `trackingCallback` in the constructor. This will queue up tracking calls in the GrowthBook instance.\n\nYou can export the queued tracking calls with the `getDeferredTrackingCalls()` method. The result is a serializable JSON object:\n\n```\nconst tracks = gb.getDeferredTrackingCalls();\n```\n\nSend those down to your front-end and you can fire them in one of two ways:\n\n#### If Using GrowthBook on the Front-End[​](#if-using-growthbook-on-the-front-end \"Direct link to If Using GrowthBook on the Front-End\")\n\nIf you are already using the JavaScript or React SDK on the front-end, you can import with `setDeferredTrackingCalls`. This does not fire them automatically. You must call `fireDeferredTrackingCalls` after.\n\n```\ngb.setDeferredTrackingCalls(tracks);gb.fireDeferredTrackingCalls();\n```\n\nThis will use the `trackingCallback` configured on your front-end GrowthBook instance.\n\n#### Standalone Tracker[​](#standalone-tracker \"Direct link to Standalone Tracker\")\n\nIf you do NOT have a client-side GrowthBook instance, you can still fire these tracking calls with a small custom client-side script:\n\n```\ntracks.forEach(({experiment, result}) => {  // Example using Segment.io  analytics.track(\"Experiment Viewed\", {    experimentId: experiment.key,    variationId: result.key,  });})\n```\n\n### Sticky Bucketing[​](#sticky-bucketing \"Direct link to Sticky Bucketing\")\n\nSticky bucketing ensures that users see the same experiment variant, even when user session, user login status, or experiment parameters change. See the [Sticky Bucketing docs](https://docs.growthbook.io/app/sticky-bucketing) for more information. If your organization and experiment supports sticky bucketing, you must implement an instance of the `StickyBucketService` to use Sticky Bucketing. The JS SDK exports several implementations of this service for common use cases, or you may build your own:\n\n*   `ExpressCookieStickyBucketService` — For NodeJS/Express controller-level bucket persistence using browser cookies; intended to be interoperable with `BrowserCookieStickyBucketService`. Assumes `cookie-parser` is implemented (can be polyfilled). Cookie attributes can also be configured.\n    \n*   `RedisStickyBucketService` — For NodeJS Redis-based bucket persistence. Requires an `ioredis` Redis client instance to be passed in.\n    \n*   Build your own — Implement the abstract `StickyBucketService` class and connect to your own data store, or custom wrap multiple service implementations (ex: read/write to both cookies and Redis).\n    \n\nImplementing most StickyBucketService implementations is straightforward and works with minimal setup. For instance, to use the `ExpressCookieStickyBucketService`:\n\n```\nconst { ExpressCookieStickyBucketService } = require(\"@growthbook/growthbook\");app.use(function(req, res, next) {  // Create a GrowthBook instance and store in the request  req.growthbook = new GrowthBook({    apiHost: \"https://cdn.growthbook.io\",    clientKey: \"sdk-abc123\",    stickyBucketService: new ExpressCookieStickyBucketService({      req,      res    }),  })})\n```\n\n## TypeScript[​](#typescript \"Direct link to TypeScript\")\n\nWhen used in a TypeScript project, GrowthBook includes basic type inference out of the box:\n\n```\n// Type will be `string` based on the fallback provided (\"blue\")const color = gb.getFeatureValue(\"button-color\", \"blue\");// You can manually specify types as well// feature.value will be type `number`const feature = gb.evalFeature<number>(\"font-size\");console.log(feature.value);// Experiments will use the variations to infer the return value// result.value will be type \"string\"const result = gb.run({  key: \"my-test\",  variations: [\"blue\", \"green\"],});\n```\n\n### Strict Typing[​](#strict-typing \"Direct link to Strict Typing\")\n\nIf you want to enforce stricter types in your application, you can do that when creating the GrowthBook instance:\n\n```\n// Define all your feature flags and types hereinterface AppFeatures {  \"button-color\": string;  \"font-size\": number;  \"newForm\": boolean;}// Pass into the GrowthBook instanceconst gb = new GrowthBook<AppFeatures>({  ...});\n```\n\nNow, all feature flag methods will be strictly typed.\n\n```\n// feature.value will by type `number`const feature = gb.evalFeature(\"font-size\");console.log(feature.value);// Typos will cause compile-time errorsgb.isOn(\"buton-color\"); // \"buton\" instead of \"button\"\n```\n\nInstead of defining the `AppFeatures` interface manually like above, you can auto-generate it from your GrowthBook account using the [GrowthBook CLI](https://docs.growthbook.io/tools/cli).\n\n## Updating[​](#updating \"Direct link to Updating\")\n\nAs a general philosophy, we aim to keep the SDK 100% backwards compatible at all times. View the [Changelog](https://github.com/growthbook/growthbook/blob/main/packages/sdk-js/CHANGELOG.md) for a complete list of all SDK changes.\n\n## GrowthBook Instance (reference)[​](#growthbook-instance-reference \"Direct link to GrowthBook Instance (reference)\")\n\n### Attributes[​](#attributes \"Direct link to Attributes\")\n\nYou can specify attributes about the current user and request. These are used for two things:\n\n1.  Feature targeting (e.g. paid users get one value, free users get another)\n2.  Assigning persistent variations in A/B tests (e.g. user id \"123\" always gets variation B)\n\nThe following are some commonly used attributes, but use whatever makes sense for your application.\n\n```\nnew GrowthBook({  attributes: {    id: \"123\",    loggedIn: true,    deviceId: \"abc123def456\",    company: \"acme\",    paid: false,    url: \"/pricing\",    browser: \"chrome\",    mobile: false,    country: \"US\",  },});\n```\n\n#### Updating Attributes[​](#updating-attributes \"Direct link to Updating Attributes\")\n\nIf attributes change, you can call `setAttributes()` to update. This will completely overwrite any existing attributes. To do a partial update, use the following pattern:\n\n```\ngb.setAttributes({  // Only update the `url` attribute, keep the rest the same  ...gb.getAttributes(),  url: \"/new-page\"})\n```\n\n#### Secure Attributes[​](#secure-attributes \"Direct link to Secure Attributes\")\n\nWhen _secure attribute hashing_ is enabled, all targeting conditions in the SDK payload referencing attributes with datatype `secureString` or `secureString[]` will be anonymized via SHA-256 hashing. This allows you to safely target users based on sensitive attributes. You must enable this feature in your SDK Connection for it to take effect.\n\nIf your SDK Connection has secure attribute hashing enabled, you will need to manually hash any `secureString` or `secureString[]` attributes that you pass into the GrowthBook SDK.\n\nTo hash an attribute, use a cryptographic library with SHA-256 support, and compute the SHA-256 hashed value of your attribute _plus_ your organization's secure attribute salt.\n\n```\nconst salt = \"f09jq3fij\"; // Your organization's secure attribute salt (see Organization Settings)// hashing a secureString attributeconst userEmail = sha256(salt + user.email);// hashing an secureString[] attributeconst userTags = user.tags.map(tag => sha256(salt + tag));gb.setAttributes({  id: user.id,  loggedIn: true,  email: userEmail,  tags: userTags,});await gb.init();// In this example, we are using Node.js's built-in crypto libraryfunction sha256(str) {  return crypto.createHash(\"sha256\").update(str).digest(\"hex\");}\n```\n\n### Feature Usage Callback[​](#feature-usage-callback \"Direct link to Feature Usage Callback\")\n\nGrowthBook can fire a callback whenever a feature is evaluated for a user. This can be useful to update 3rd party tools like NewRelic or DataDog.\n\n```\nnew GrowthBook({  onFeatureUsage: (featureKey, result) => {    console.log(\"feature\", featureKey, \"has value\", result.value);  },});\n```\n\nThe `result` argument is the same thing returned from `gb.evalFeature`.\n\nNote: If you evaluate the same feature multiple times (and the value doesn't change), the callback will only be fired the first time.\n\n### evalFeature[​](#evalfeature \"Direct link to evalFeature\")\n\nIn addition to the `isOn` and `getFeatureValue` helper methods, there is the `evalFeature` method that gives you more detailed information about why the value was assigned to the user.\n\n```\n// Get detailed information about the feature evaluationconst result = gb.evalFeature(\"my-feature\");// The value of the feature (or `null` if not defined)console.log(result.value);// Why the value was assigned to the user// One of: `override`, `unknownFeature`, `defaultValue`, `force`, or `experiment`console.log(result.source);// The string id of the rule (if any) which was usedconsole.log(result.ruleId);// Information about the experiment (if any) which was usedconsole.log(result.experiment);// The result of the experiment (or `undefined`)console.log(result.experimentResult);\n```\n\n### Inline Experiments[​](#inline-experiments \"Direct link to Inline Experiments\")\n\nInstead of declaring all features up-front in the context and referencing them by ids in your code, you can also just run an experiment directly. This is done with the `gb.run` method:\n\n```\n// These are the only required optionsconst { value } = gb.run({  key: \"my-experiment\",  variations: [\"red\", \"blue\", \"green\"],});\n```\n\n#### Customizing the Traffic Split[​](#customizing-the-traffic-split \"Direct link to Customizing the Traffic Split\")\n\nBy default, this will include all traffic and do an even split between all variations. There are 2 ways to customize this behavior:\n\n```\n// Option 1: Using weights and coveragegb.run({  key: \"my-experiment\",  variations: [\"red\", \"blue\", \"green\"],  // Only include 10% of traffic  coverage: 0.1,  // Split the included traffic 50/25/25 instead of the default 33/33/33  weights: [0.5, 0.25, 0.25],});// Option 2: Specifying rangesgb.run({  key: \"my-experiment\",  variations: [\"red\", \"blue\", \"green\"],  // Identical to the above  // 5% of traffic in A, 2.5% each in B and C  ranges: [    [0, 0.05],    [0.5, 0.525],    [0.75, 0.775],  ],});\n```\n\n#### Hashing[​](#hashing \"Direct link to Hashing\")\n\nWe use deterministic hashing to assign a variation to a user. We hash together the user's id and experiment key, which produces a number between `0` and `1`. Each variation is assigned a range of numbers, and whichever one the user's hash value falls into will be assigned.\n\nYou can customize this hashing behavior:\n\n```\ngb.run({  key: \"my-experiment\",  variations: [\"A\", \"B\"],  // Which hashing algorithm to use  // Version 2 is the latest and the one we recommend  hashVersion: 2,  // Use a different seed instead of the experiment key  seed: \"abcdef123456\",  // Use a different user attribute (default is `id`)  hashAttribute: \"device_id\",});\n```\n\n**Note**: For backwards compatibility, if no `hashVersion` is specified, it will fall back to using version `1`, which is deprecated. In the future, version `2` will become the default. We recommend specifying version `2` now for all new experiments to avoid migration issues down the line.\n\n#### Meta Info[​](#meta-info \"Direct link to Meta Info\")\n\nYou can also define meta info for the experiment and/or variations. These do not affect the behavior, but they are passed through to the `trackingCallback`, so they can be used to annotate events.\n\n```\ngb.run({  key: \"results-per-page\",  variations: [10, 20],  // Experiment meta info  name: \"Results per Page\",  phase: \"full-traffic\"  // Variation meta info  meta: [    {      key: \"control\",      name: \"10 Results per Page\",    },    {      key: \"variation\",      name: \"20 Results per Page\",    },  ]})\n```\n\n#### Mutual Exclusion[​](#mutual-exclusion \"Direct link to Mutual Exclusion\")\n\nSometimes you want to run multiple conflicting experiments at the same time. You can use the `filters` setting to run mutually exclusive experiments.\n\nWe do this using deterministic hashing to assign users a value between 0 and 1 for each filter.\n\n```\n// Will include 60% of users - ones with a hash between 0 and 0.6gb.run({  key: \"experiment-1\",  variation: [0, 1],  filters: [    {      seed: \"pricing\",      attribute: \"id\",      ranges: [[0, 0.6]]    }  ]});// Will include the other 40% of users - ones with a hash between 0.6 and 1gb.run({  key: \"experiment-2\",  variation: [0, 1],  filters: [    {      seed: \"pricing\",      attribute: \"id\",      ranges: [[0.6, 1.0]]    }  ]});\n```\n\n**Note** - If a user is excluded from an experiment due to a filter, the rule will be skipped and the next matching rule will be used instead.\n\n#### Holdout Groups[​](#holdout-groups \"Direct link to Holdout Groups\")\n\nTo use global holdout groups, use a nested experiment design:\n\n```\n// The value will be `true` if in the holdout group, otherwise `false`const holdout = gb.run({  key: \"holdout\",  variations: [true, false],  // 10% of users in the holdout group  weights: [0.1, 0.9]});// Only run your main experiment if the user is NOT in the holdoutif (!holdout.value) {  const res = gb.run({    key: \"my-experiment\",    variations: [\"A\", \"B\"]  })}\n```\n\n#### Targeting Conditions[​](#targeting-conditions \"Direct link to Targeting Conditions\")\n\nYou can also define targeting conditions that limit which users are included in the experiment. These conditions are evaluated against the `attributes` passed into the GrowthBook context. The syntax for conditions is based on the MongoDB query syntax and is straightforward to read and write.\n\nFor example, if the attributes are:\n\n```\n{  \"id\": \"123\",  \"browser\": {    \"vendor\": \"firefox\",    \"version\": 94  },  \"country\": \"CA\"}\n```\n\nThe following condition would evaluate to `true` and the user would be included in the experiment:\n\n```\ngb.run({  key: \"my-experiment\",  variation: [0, 1],  condition: {    \"browser.vendor\": \"firefox\",    \"country\": {      \"$in\": [\"US\", \"CA\", \"IN\"]    }  }})\n```\n\n#### Inline Experiment Return Value[​](#inline-experiment-return-value \"Direct link to Inline Experiment Return Value\")\n\nA call to `gb.run(experiment)` returns an object with a few useful properties:\n\n```\nconst {  value,  key,  name,  variationId,  inExperiment,  hashUsed,  hashAttribute,  hashValue,} = gb.run({  key: \"my-experiment\",  variations: [\"A\", \"B\"],});// If user is included in the experimentconsole.log(inExperiment); // true or false// The index of the assigned variationconsole.log(variationId); // 0 or 1// The value of the assigned variationconsole.log(value); // \"A\" or \"B\"// The key and name of the assigned variation (if specified in `meta`)console.log(key); // \"0\" or \"1\"console.log(name); // \"\"// If the variation was randomly assigned by hashingconsole.log(hashUsed);// The user attribute that was hashedconsole.log(hashAttribute); // \"id\"// The value of that attributeconsole.log(hashValue); // e.g. \"123\"\n```\n\nThe `inExperiment` flag will be false if the user was excluded from being part of the experiment for any reason (e.g. failed targeting conditions).\n\nThe `hashUsed` flag will only be true if the user was randomly assigned a variation. If the user was forced into a specific variation instead, this flag will be false.\n\n## Feature Definitions (reference)[​](#feature-definitions-reference \"Direct link to Feature Definitions (reference)\")\n\nThe feature definition JSON file contains information about all of the features in your application.\n\nEach feature consists of a unique key, a list of possible values, and rules for how to assign those values to users.\n\n```\n{  \"feature-1\": {...},  \"feature-2\": {...},  \"another-feature\": {...},}\n```\n\n### Basic Feature[​](#basic-feature \"Direct link to Basic Feature\")\n\nAn empty feature always has the value `null`:\n\n#### Default Values[​](#default-values \"Direct link to Default Values\")\n\nYou can change the default assigned value with the `defaultValue` property:\n\n```\n{  \"my-feature\": {    defaultValue: \"green\"  }}\n```\n\n### Override Rules[​](#override-rules \"Direct link to Override Rules\")\n\nYou can override the default value with **rules**.\n\nRules give you fine-grained control over how feature values are assigned to users. There are 2 types of feature rules: `force` and `experiment`. Force rules give the same value to everyone. Experiment rules assign values to users randomly.\n\n#### Rule Ids[​](#rule-ids \"Direct link to Rule Ids\")\n\nRules can specify a unique identifier with the `id` property. This can help with debugging and QA by letting you see exactly why a specific value was assigned to a user.\n\n#### Rule Conditions[​](#rule-conditions \"Direct link to Rule Conditions\")\n\nRules can optionally define targeting conditions that limit which users the rule applies to. These conditions are evaluated against the `attributes` passed into the GrowthBook context. The syntax for conditions is based on the MongoDB query syntax and is straightforward to read and write.\n\nFor example, if the attributes are:\n\n```\n{  \"id\": \"123\",  \"browser\": {    \"vendor\": \"firefox\",    \"version\": 94  },  \"country\": \"CA\"}\n```\n\nThe following condition would evaluate to `true`:\n\n```\n{  \"browser.vendor\": \"firefox\",  \"country\": {    \"$in\": [\"US\", \"CA\", \"IN\"]  }}\n```\n\nIf a condition evaluates to `false`, the rule will be skipped. This means you can chain rules together with different conditions to support even the most complex use cases.\n\n#### Force Rules[​](#force-rules \"Direct link to Force Rules\")\n\nForce rules do what you'd expect - force a specific value for the feature\n\n```\n// Firefox users in the US or Canada get \"green\"// Everyone else gets the default \"blue\"{  \"button-color\": {    defaultValue: \"blue\",    rules: [      {        id: \"rule-123\",        condition: {          browser: \"firefox\",          country: {            $in: [\"US\", \"CA\"]          }        },        force: \"green\"      }    ],  }}\n```\n\n##### Gradual Rollouts[​](#gradual-rollouts \"Direct link to Gradual Rollouts\")\n\nYou can specify a `range` for your rule, which determines what percent of users will get the rule applied to them. Users who do not get the rule applied will fall through to the next matching rule (or default value). You can also specify a `seed` that will be used for hashing.\n\nIn order to figure out if a user is included or not, we use deterministic hashing. By default, we use the user attribute `id` for this, but you can override this by specifying `hashAttribute` for the rule:\n\nThis is useful for gradually rolling out features to users (start with a small range and slowly increase).\n\n```\n{  \"new-feature\": {    defaultValue: false,    rules: [      {        force: true,        hashAttribute: \"device-id\",        seed: 'new-feature-rollout-abcdef123',        // 20% of users        range: [0, 0.2]        // Increase to 40%:        // range: [0, 0.4]      }    ]  }}\n```\n\n#### Experiment Rules[​](#experiment-rules \"Direct link to Experiment Rules\")\n\nExperiment rules let you adjust the percent of users who get randomly assigned to each variation. This can either be used for hypothesis-driven A/B tests or to simply mitigate risk by gradually rolling out new features to your users.\n\n```\n// Each variation gets assigned to a random 1/3rd of users{  \"image-size\": {    rules: [      {        variations: [\"small\", \"medium\", \"large\"]      }    ]  }}\n```\n\n##### Customizing the Traffic Split[​](#customizing-the-traffic-split-1 \"Direct link to Customizing the Traffic Split\")\n\nBy default, an experiment rule will include all traffic and do an even split between all variations. There are 2 ways to customize this behavior:\n\n```\n// Option 1: Using weights and coverage{  variations: [\"red\", \"blue\", \"green\"],  // Only include 10% of traffic  coverage: 0.1,  // Split the included traffic 50/25/25 instead of the default 33/33/33  weights: [0.5, 0.25, 0.25]}// Option 2: Specifying ranges{  variations: [\"red\", \"blue\", \"green\"],  // Identical to the above  // 5% of traffic in A, 2.5% each in B and C  ranges: [    [0, 0.05],    [0.5, 0.525],    [0.75, 0.775]  ]}\n```\n\nA user is assigned a number from 0 to 1 and whichever variation's range includes their number will be assigned to them.\n\n##### Variation Meta Info[​](#variation-meta-info \"Direct link to Variation Meta Info\")\n\nYou can use the `meta` setting to provide additional info about the variations such as name.\n\n```\n{  \"image-size\": {    rules: [      {        variations: [\"sm\", \"md\", \"lg\"],        ranges: [          [0, 0.5],          [0.5, 0.75],          [0.75, 1.0]        ],        meta: [          {            key: \"control\",            name: \"Small\",          },          {            key: \"v1\",            name: \"Medium\",          },          {            key: \"v2\",            name: \"Large\",          }        ]      }    ]  }}\n```\n\n##### Tracking Key and Name[​](#tracking-key-and-name \"Direct link to Tracking Key and Name\")\n\nWhen a user is assigned a variation, we call the `trackingCallback` function so you can record the exposure with your analytics event tracking system. By default, we use the feature id to identify the experiment, but this can be overridden if needed with the `key` setting. You can also optionally provide a human-readable name.\n\n```\n{  \"feature-1\": {    rules: [      {        // Use \"my-experiment\" as the key instead of \"feature-1\"        key: \"my-experiment\",        name: \"My Experiment\",        variations: [\"A\", \"B\"]      }    ]  },}\n```\n\n##### Hash Attribute[​](#hash-attribute \"Direct link to Hash Attribute\")\n\nWe use deterministic hashing to make sure the same user always gets assigned the same value. By default, we use the attribute `id`, but this can be overridden with the `hashAttribute` setting:\n\n```\nconst gb = new GrowthBook({  attributes: {    id: \"123\",    company: \"acme\",  },  features: {    \"my-feature\": {      rules: [        // All users with the same \"company\" value        // will be assigned the same variation        {          variations: [\"A\", \"B\"],          hashAttribute: \"company\",        },        // If \"company\" is empty for the user (e.g. if they are logged out)        // The experiment will be skipped and fall through to this next rule        {          force: \"A\",        },      ],    },  },});\n```\n\n##### Filters[​](#filters \"Direct link to Filters\")\n\nSometimes you want to run multiple conflicting experiments at the same time. You can use the `filters` setting to run mutually exclusive experiments.\n\nWe do this using deterministic hashing to assign users a value between 0 and 1 for each filter.\n\n```\n{  \"feature1\": {    rules: [      // Will include 60% of users - ones with a hash between 0 and 0.6      {        variations: [false, true],        filters: [          {            seed: \"pricing\",            attribute: \"id\",            ranges: [[0, 0.6]]          }        ]      }    ]  },  \"feature2\": {    rules: [      // Will include the other 40% of users - ones with a hash between 0.6 and 1      {        variations: [false, true],        filters: [          {            seed: \"pricing\",            attribute: \"id\",            ranges: [[0.6, 1.0]]          }        ]      },    ]  }}\n```\n\n**Note** - If a user is excluded from an experiment due to a filter, the rule will be skipped and the next matching rule will be used instead.\n\n## Examples[​](#examples \"Direct link to Examples\")\n\n*   [Typescript example app with strict typing](https://github.com/growthbook/examples/tree/main/vanilla-typescript) .",
  "title": "Node.js SDK | GrowthBook Docs",
  "description": "GrowthBook SDK for Node.js",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/script-tag",
  "markdown": "# HTML Script Tag | GrowthBook Docs\n\nWe provide an HTML `<script>` tag option for easily integrating GrowthBook into any website.\n\nThis option is quick and straightforward to use and does not require coding knowledge to implement.\n\n## Installation[​](#installation \"Direct link to Installation\")\n\nFor this, you will need a **Client Key** from an SDK Connection within GrowthBook. This will start with `sdk-`.\n\nAdd the following script tag to your website and replace `YOUR_CLIENT_KEY_HERE` with your actual Client Key:\n\n```\n<script async  data-client-key=\"YOUR_CLIENT_KEY_HERE\"  src=\"https://cdn.jsdelivr.net/npm/@growthbook/growthbook/dist/bundles/auto.min.js\"></script>\n```\n\nOr, if you can't add `data-*` attributes (e.g. in Google Tag Manager), you can use this alternate version:\n\n```\n<script>(function(s) {  s=document.createElement('script'); s.async=true;  s.dataset.clientKey=\"YOUR_CLIENT_KEY_HERE\";  s.src=\"https://cdn.jsdelivr.net/npm/@growthbook/growthbook/dist/bundles/auto.min.js\";  document.head.appendChild(s);})();</script>\n```\n\nFor best performance, we recommend adding this script tag directly before the closing `</head>` tag, however it is also possible to load through something like Google Tag Manager if that is your only option.\n\n### Optional Configuration Settings[​](#optional-configuration-settings \"Direct link to Optional Configuration Settings\")\n\nBesides the Client Key, there are some additional settings you can define with `data-` attributes on the script tag:\n\n*   `data-api-host` - Defaults to GrowthBook Cloud's [https://cdn.growthbook.io](https://cdn.growthbook.io/). This must be set to your own domain instead if self-hosting or using the GrowthBook Proxy.\n*   `data-decryption-key` - Required if you enabled encryption in your SDK Connection settings in GrowthBook\n\nAll other settings can be defined with a `window.growthbook_config` object BEFORE you load the script tag. This accepts the same settings as our [JavaScript SDK](https://docs.growthbook.io/lib/js). Here's an example:\n\n```\n<script>window.growthbook_config = window.growthbook_config || {};// Disable streaming updateswindow.growthbook_config.backgroundSync = false;</script>\n```\n\nIf you need low level access to the GrowthBook SDK instance for any reason, you can use a callback function. This will be called as soon as the GrowthBook SDK instance is ready. If you push to the queue after GrowthBook has already loaded, the callback will be invoked immediately.\n\n```\n<script>window.growthbook_queue = window.growthbook_queue || [];window.growthbook_queue.push((gb) => {  // Do whatever you need with the GrowthBook instance here  console.log(gb.getAttributes());})</script>\n```\n\n## Targeting Attributes[​](#targeting-attributes \"Direct link to Targeting Attributes\")\n\nThe following targeting attributes are set automatically and available for use.\n\n*   `id` - creates a long-lived `gbuuid` cookie if it doesn't exist already\n*   `url`\n*   `path`\n*   `host`\n*   `query`\n*   `pageTitle`\n*   `deviceType` - either `mobile` or `desktop`\n*   `browser` - one of `chrome`, `edge`, `firefox`, `safari`, or `unknown`\n*   `utmSource`\n*   `utmMedium`\n*   `utmCampaign`\n*   `utmTerm`\n*   `utmContent`\n\nIn addition, if you use Google Tag Manager, any variables you set in your Data Layer will also be set here and available for targeting.\n\n### Adding Custom Attributes[​](#adding-custom-attributes \"Direct link to Adding Custom Attributes\")\n\nYou can include your own custom attributes by adding the following BEFORE the GrowthBook snippet:\n\n```\n<script>window.growthbook_config = window.growthbook_config || {};window.growthbook_config.attributes = {    country: \"US\",    otherCustomAttribute: 12,}</script>\n```\n\nYou can also set custom attributes later, after the script tag has been added. Please note, this may cause flickering in your experiments if you reference these custom attributes in your experiment targeting.\n\n```\n<script>window.growthbook_queue = window.growthbook_queue || [];window.growthbook_queue.push((gb) => {  gb.updateAttributes({    country: \"US\",    otherCustomAttribute: 12,  });});</script>\n```\n\n### Refreshing Auto Attributes[​](#refreshing-auto-attributes \"Direct link to Refreshing Auto Attributes\")\n\nThe GrowthBook snippet will automatically watch for URL changes and update attributes when that happens. If you would like more control over this behavior, you can manually trigger updates at any time by firing a `growthbookrefresh` event from JavaScript. For example:\n\n```\ndocument.dispatchEvent(new CustomEvent(\"growthbookrefresh\"));\n```\n\n## Tracking Experiment Views[​](#tracking-experiment-views \"Direct link to Tracking Experiment Views\")\n\nWhen a user views an experiment, a tracking event is fired. There is built-in support for Segment.io (`analytics.js`), GA4 (`gtag`), and Google Tag Manager (`dataLayer`).\n\n### Segment.io[​](#segmentio \"Direct link to Segment.io\")\n\nGrowthBook will automatically fire an event using `window.analytics.track` if it's present on the page. The event name is `Experiment Viewed` and it has two properties: `experiment_id` and `variation_id`.\n\nThere is no additional configuration needed.\n\n### GA4 (`gtag`)[​](#ga4-gtag \"Direct link to ga4-gtag\")\n\nGrowthBook will automatically fire an event using Google Analytic 4's `window.gtag` if it's present on the page. The event name is `experiment_viewed` and it has two properties: `experiment_id` and `variation_id`.\n\nThere is no additional configuration needed.\n\n### Google Tag Manager[​](#google-tag-manager \"Direct link to Google Tag Manager\")\n\nWe send the following event to the Data Layer. You will need to add a trigger based on this and forward it on to your analytics tool of choice.\n\n```\n{    \"event\": \"experiment_viewed\",    \"experiment_id\": \"...\",    \"variation_id\": \"...\"}\n```\n\nWe have a walkthrough tutorial on how to configure this in our [GTM Guide](https://docs.growthbook.io/guide/google-tag-manager-and-growthbook#tracking-via-datalayer-and-gtm)\n\n### Mixpanel[​](#mixpanel \"Direct link to Mixpanel\")\n\nTo work with Mixpanel, we have to set the ID as an attribute for GrowthBook, and also add the custom event tracking callback. Below is an example of how to set up GrowthBook with Mixpanel. The script initializes Mixpanel (which you probably already have) and then sets the Mixpanel distinct ID to a GrowthBook `id` attribute once it has loaded. Then the script defines a trackingCallback to log the experiment exposure event to Mixpanel.\n\n```\n<script>window.growthbook_config = window.growthbook_config || {};mixpanel.init(\"[YOUR PROJECT TOKEN]\", {  debug: true,  loaded: function (mx) {    window.growthbook_queue = window.growthbook_queue || [];    window.growthbook_queue.push((gb) => {     gb.setAttributes({       ...gb.getAttributes(),       id: mx.get_distinct_id(),     });   })  },});window.growthbook_config.trackingCallback = (experiment, result) => {    mixpanel.track(\"$experiment_started\", {      \"Experiment name\": experiment.key,      \"Variant name\": result.variationId,      $source: \"growthbook\",    });</script><!-- then load the GrowthBook SDK --><script async  data-client-key=\"YOUR_CLIENT_KEY_HERE\"  src=\"https://cdn.jsdelivr.net/npm/@growthbook/growthbook/dist/bundles/auto.min.js\"></script>\n```\n\n### Others[​](#others \"Direct link to Others\")\n\nFor any other event tracking system (or if the built-in ones above do not meet your requirements), you can define your own custom tracking callback function. This must be defined _BEFORE_ loading the main GrowthBook snippet on the page.\n\n```\n<script>window.growthbook_config = window.growthbook_config || {};window.growthbook_config.trackingCallback = (experiment, result) => {  customEventTracker(\"Viewed Experiment\", {    experiment_id: experiment.key,    variation_id: result.key  })};</script>\n```\n\n## Sticky Bucketing[​](#sticky-bucketing \"Direct link to Sticky Bucketing\")\n\nThis SDK supports [Sticky Bucketing](https://docs.growthbook.io/app/sticky-bucketing), but it is disabled by default. To enable, add the following to your script tag:\n\n```\ndata-use-sticky-bucket-service=\"cookie\"\n```\n\nThere are 2 possible values:\n\n*   **cookie** - Persist in a cookie that is shared between the browser and your server\n*   **localStorage** - Persist in the browser's localStorage, which is never sent to your server\n\nYou can also customize the key we use to store sticky buckets by adding a prefix:\n\n```\ndata-sticky-bucket-prefix=\"my_prefix\"\n```\n\n## Using Feature Flags[​](#using-feature-flags \"Direct link to Using Feature Flags\")\n\nYou can use feature flags with this SDK, but it does require some manual coding work. Here is an example:\n\n```\n<script>// Wait for the GrowthBook SDK to load before runningwindow.growthbook_queue = window.growthbook_queue || [];window.growthbook_queue.push((gb) => {  // Function that uses feature flags to make changes to the page  const applyFeatureFlags = () => {    if(gb.isOn(\"dark-mode\")) {      document.documentElement.classList.add(\"dark\");    } else {      document.documentElement.classList.remove(\"dark\");    }  }  // Call your function initially plus whenever new data is received  applyFeatureFlags();  document.addEventListener(\"growthbookdata\", applyFeatureFlags)});</script>\n```\n\nBy default, this SDK persists a random unique identifier in a first-party cookie named `gbuuid`. This cookie is required to provide a consistent user experience to your visitors. Without this cookie, if you run an A/B test, a visitor might be re-bucketed into a different variation every time they visit your website.\n\nThe `gbuuid` cookie does not contain any Personally Identifiable Information (it's just a randomly generated id). It is a first-party cookie that is never shared with any third-party services, not even GrowthBook itself. However, we still recommend adding this to your site's cookie policy if you have one.\n\n### Delay Storing the Cookie Until Consent is Granted[​](#delay-storing-the-cookie-until-consent-is-granted \"Direct link to Delay Storing the Cookie Until Consent is Granted\")\n\nIf you must delay persisting the `gbuuid` cookie until a user consents, you can add a `data-no-auto-cookies` attribute to the script tag.\n\nThis will still generate a UUID for the user, but will not persist it. That means, if the user refreshes the page, they will have a new random UUID generated.\n\nYou have the option to manually persist this cookie at any time, for example when a user grants consent on your cookie banner. All you need to do is fire this custom event from javascript:\n\n```\ndocument.dispatchEvent(new CustomEvent(\"growthbookpersist\"));\n```\n\n## Content Security Policy (CSP)[​](#content-security-policy-csp \"Direct link to Content Security Policy (CSP)\")\n\nIf your site uses a Content Security Policy, you may need to make a few changes to the `script-src` directive for this SDK to load and run on your site.\n\nFirst, make sure to add `https://cdn.jsdelivr.net` so the script itself can load. If this isn't possible, you can save the contents of the script and host it on your own domain instead. Just note that doing that means you will no longer get automatic updates when we make improvements to the script tag.\n\nSecond, if you plan to use the Visual Editor to inject custom javascript into your site, you need to allow both `usafe-inline` and `unsafe-eval`. If this isn't possible, we have an alternative using nonces (see below).\n\n### Using Script Nonces[​](#using-script-nonces \"Direct link to Using Script Nonces\")\n\nAs an alternative to allowing `unsafe-inline`, we support \"nonces\", although this requires some very technical and custom configuration to hook up. This is only required if you plan to use the Visual Editor to inject custom javascript into your site.\n\nYou will still need to allow `usafe-eval` due to how our Visual Editor works under-the-hood.\n\nFirst, you will need to generate a unique nonce value for every request and add it to your CSP header. This can be done on the edge such as with a Cloudflare Worker.\n\nLastly, you will also need to inject the following into your page's `<head>` BEFORE you load the GrowthBook snippet. This can be accomplished in the same edge worker. Replace all instances of `$NONCE` with the unique nonce value you generated.\n\n```\n<script nonce=\"$NONCE\">window.growthbook_config = window.growthbook_config || {};window.growthbook_config.jsInjectionNonce = \"$NONCE\";</script>\n```",
  "title": "HTML Script Tag | GrowthBook Docs",
  "description": "Load the GrowthBook SDK in any website or low code platform",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/kotlin",
  "markdown": "# Kotlin SDK | GrowthBook Docs\n\n## Kotlin (Android)\n\nThis SDK supports both Java and Kotlin Android apps using Android SDK 21 and above.\n\n## Installation[​](#installation \"Direct link to Installation\")\n\n```\nrepositories {    mavenCentral()}dependencies {    implementation 'io.growthbook.sdk:GrowthBook:1.1.58'}\n```\n\n## Quick Usage[​](#quick-usage \"Direct link to Quick Usage\")\n\nTo create a GrowthBook SDK instance, use `GBSDKBuilder`. Then, you can evaluate feature flags or run experiments.\n\n```\n// User attributes for targeting and assigning users to experiment variationsval attrs = HashMap<String, Any>()attrs.put(\"id\", \"123\")attrs.put(\"env\", \"dev\")attrs.put(\"betaUser\", true)val gb = GBSDKBuilder(  // Fetch and cache feature definitions from GrowthBook API  // If self-hosting, we recommend using a CDN in production  apiKey = \"key_123abc\",  hostURL = \"https://cdn.growthbook.io/\",  attributes = attrs,  trackingCallback = { gbExperiment, gbExperimentResult ->    // TODO: track in your analytics system    print(\"Viewed Experiment\")    print(\"Experiment Id: \" + gbExperiment.key)    print(\"Variation Id: \" + gbExperimentResult.variationId)  },  networkDispatcher = DefaultGBNetworkClient(),  encryptionKey = \"insert_your_encription_key_if_you_are_using_encryption\",).initialize()\n```\n\nIf you need to set or update attributes asynchronously, you can do so with `setAttributes()`. This will completely overwrite the attributes object with whatever you pass in. Also, be aware that changing attributes may change the assigned feature values. This can be disorienting to users if not handled carefully.\n\nIf you are accessing features the first time there will be no features right after `initialize()` method call because features are not got from Backend yet. If you need to access features as soon as possible, you need to use `GBCacheRefreshHandler`. You can pass your implementation of `GBCacheRefreshHandler` through `setRefreshHandler()` method. Code snippet:\n\n```\nclass ForExampleMainActivity {    var growthBookSDK: GrowthBookSDK? = null    fun someInitMethodForExampleOnStart() {        val gbSdkBuilder = GBSDKBuilder(            ....        )        gbSdkBuilder.setRefreshHandler { isRefreshed, gbError ->            // access your features            growthBookSDK?.feature(\"your_feature_key\").on        }        growthBookSDK = gbSdkBuilder.initialize()    }}\n```\n\n## Using Features[​](#using-features \"Direct link to Using Features\")\n\nThe `feature` method takes a String feature name and returns a `FeatureResult` object with a few useful properties:\n\n*   **value** (`Any`) - The assigned value of the feature\n*   **on** (`Boolean`) - The value cast to a boolean\n*   **off** (`Boolean`) - The value cast to a boolean and then negated\n*   **source** (`String`) - Why the value was assigned to the user. One of \"unknownFeature\", \"defaultValue\", \"force\", or \"experiment\"\n\nWhen the source is \"experiment\", there are 2 additional properties that tell you which experiment was used and more details about the result of the experiment:\n\n*   **experiment** (`GBExperiment`)\n*   **experimentResult** (`GBExperimentResult`)\n\nHere are some examples:\n\n```\nval feature = gb.feature(\"my-feature\")// Do something if feature is truthyif (feature.on) { }// Do something if feature is falsyif (feature.off) { }// Print the actual value of the feature// (depending on the feature, might be a string, number, boolean, etc.)println(feature.value)// Print the experiment id used to assign the feature valueif (feature.source == \"experiment\") {  println(feature.experiment.key)}\n```\n\n## Running Inline Experiments[​](#running-inline-experiments \"Direct link to Running Inline Experiments\")\n\nInstead of just using features defined in the GrowthBook API, you can also just run an experiment directly. This is done with the `run` method which takes a `GBExperiment` object as an argument and returns a `GBExperimentResult` object:\n\n```\ncal exp = GBExperiment()exp.key = \"my-experiment\"exp.variations = arrayOf(\"control\", \"variation\")val result = gb.run(exp)// Either \"control\" or \"variation\"println(result.value)\n```\n\nThe `GBExperiment` class has two required properties - `key` and `variations`. There are also a number of optional properties:\n\n*   **key** (`String`) - The unique identifier for this experiment\n*   **variations** (`Any[]`) - Array of variations to decide between\n*   **weights** (`Float[]`) - How to weight traffic between variations. Must add to 1.\n*   **active** (`Boolean`) - If set to false, always return the control (first variation)\n*   **coverage** (`Float`) - What percent of users should be included in the experiment (between 0 and 1, inclusive)\n*   **condition** (`GBCondition`) - Optional targeting condition\n*   **namespace** (`[String, Int, Int]`) - Adds the experiment to a namespace\n*   **force** (`Int`) - All users included in the experiment will be forced into the specific variation index\n*   **hashAttribute** (`String`) - What user attribute should be used to assign variations (defaults to `id`)\n\nThe `GBExperimentResult` object returns the following properties:\n\n*   **inExperiment** (`Boolean`)\n*   **variationId** (`Int`) - The array index of the assigned variation\n*   **value** (`Any`) - The value of the assigned variation\n*   **hashAttribute** (`String`) - The user attribute used to assign a variation\n*   **hashValue** (`String`) - The value of the attribute used to assign a variation\n\n## More Documentation[​](#more-documentation \"Direct link to More Documentation\")\n\nThe GitHub repo for this SDK has more detailed class and method documentation - [https://github.com/growthbook/growthbook-kotlin](https://github.com/growthbook/growthbook-kotlin)",
  "title": "Kotlin SDK | GrowthBook Docs",
  "description": "GrowthBook SDK for Kotlin - Android",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/api",
  "markdown": "# GrowthBook REST API | GrowthBook Docs\n\nDownload OpenAPI specification:[Download](https://api.growthbook.io/api/v1/openapi.yaml)\n\nGrowthBook offers a full REST API for interacting with the GrowthBook application. This is currently in **beta** as we add more authenticated API routes and features.\n\nRequest data can use either JSON or Form data encoding (with proper `Content-Type` headers). All response bodies are JSON-encoded.\n\nThe API base URL for GrowthBook Cloud is `https://api.growthbook.io`. For self-hosted deployments, it is the same as your API\\_HOST environment variable (defaults to `http://localhost:3100`). The rest of these docs will assume you are using GrowthBook Cloud.\n\n## [](#section/Authentication)Authentication\n\nWe support both the HTTP Basic and Bearer authentication schemes for convenience.\n\nYou first need to generate a new API Key in GrowthBook. Different keys have different permissions:\n\n*   **Personal Access Tokens**: These are sensitive and provide the same level of access as the user has to an organization. These can be created by going to `Personal Access Tokens` under the your user menu.\n*   **Secret Keys**: These are sensitive and provide the level of access for the role, which currently is either `admin` or `readonly`. Only Admins with the `manageApiKeys` permission can manage Secret Keys on behalf of an organization. These can be created by going to `Settings -> API Keys`\n\nIf using HTTP Basic auth, pass the Secret Key as the username and leave the password blank:\n\n```\ncurl https://api.growthbook.io/api/v1 \\\n  -u secret_abc123DEF456:\n# The \":\" at the end stops curl from asking for a password\n```\n\nIf using Bearer auth, pass the Secret Key as the token:\n\n```\ncurl https://api.growthbook.io/api/v1 \\\n-H \"Authorization: Bearer secret_abc123DEF456\"\n```\n\n## [](#section/Errors)Errors\n\nThe API may return the following error status codes:\n\n*   **400** - Bad Request - Often due to a missing required parameter\n*   **401** - Unauthorized - No valid API key provided\n*   **402** - Request Failed - The parameters are valid, but the request failed\n*   **403** - Forbidden - Provided API key does not have the required access\n*   **404** - Not Found - Unknown API route or requested resource\n*   **429** - Too Many Requests - You exceeded the rate limit of 60 requests per minute. Try again later.\n*   **5XX** - Server Error - Something went wrong on GrowthBook's end (these are rare)\n\nThe response body will be a JSON object with the following properties:\n\n*   **message** - Information about the error\n\n## [](#tag/projects)Projects\n\nProjects are used to organize your feature flags and experiments\n\n## [](#tag/projects/operation/listProjects)Get all projects\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/projects \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"projects\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"settings\": {`\n            \n            *   `\"statsEngine\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/projects/operation/postProject)Create a single project\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nname\n\nrequired\n\ndescription\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"settings\": {`\n    \n    *   `\"statsEngine\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"project\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"settings\": {`\n        \n        *   `\"statsEngine\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/projects/operation/getProject)Get a single project\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/projects/prj\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"project\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"settings\": {`\n        \n        *   `\"statsEngine\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/projects/operation/putProject)Edit a single project\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nname\n\ndescription\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"settings\": {`\n    \n    *   `\"statsEngine\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"project\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"settings\": {`\n        \n        *   `\"statsEngine\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/projects/operation/deleteProject)Deletes a single project\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-X DELETE https://api.growthbook.io/api/v1/projects/prj\\_\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"deletedId\": \"prj__123abc\"`\n    \n\n`}`\n\n## [](#tag/environments)Environments\n\nGrowthBook comes with one environment by default (production), but you can add as many as you need. When used with feature flags, you can enable/disable feature flags on a per-environment basis.\n\n## [](#tag/environments/operation/listEnvironments)Get the organization's environments\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/environments \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"environments\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"toggleOnList\": true,`\n            \n        *   `\"defaultState\": true,`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/environments/operation/postEnvironment)Create a new environment\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nid\n\nrequired\n\nstring\n\nThe ID of the new environment\n\ndescription\n\nstring\n\nThe description of the new environment\n\ntoggleOnList\n\nbool\n\nShow toggle on feature list\n\ndefaultState\n\nbool\n\nDefault state for new features\n\nprojects\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"toggleOnList\": null,`\n    \n*   `\"defaultState\": null,`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `]`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"environment\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"toggleOnList\": true,`\n        \n    *   `\"defaultState\": true,`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/environments/operation/putEnvironment)Update an environment\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\ndescription\n\nstring\n\nThe description of the new environment\n\ntoggleOnList\n\nboolean\n\nShow toggle on feature list\n\ndefaultState\n\nboolean\n\nDefault state for new features\n\nprojects\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"description\": \"string\",`\n    \n*   `\"toggleOnList\": true,`\n    \n*   `\"defaultState\": true,`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `]`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"environment\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"toggleOnList\": true,`\n        \n    *   `\"defaultState\": true,`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/environments/operation/deleteEnvironment)Deletes a single environment\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-X DELETE https://api.growthbook.io/api/v1/enviromnents/env\\-id \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"deletedId\": \"string\"`\n    \n\n`}`\n\n## [](#tag/features)Feature Flags\n\nControl your feature flags programatically\n\n## [](#tag/features/operation/listFeatures)Get all features\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\nprojectId\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/features \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"features\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"archived\": true,`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"owner\": \"string\",`\n            \n        *   `\"project\": \"string\",`\n            \n        *   `\"valueType\": \"boolean\",`\n            \n        *   `\"defaultValue\": \"string\",`\n            \n        \n        *   `\"environments\": {`\n            \n            *   `\"property1\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\",`\n                    \n                *   `\"draft\": {`\n                    \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"defaultValue\": \"string\",`\n                        \n                    *   `\"rules\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"description\": \"string\",`\n                                \n                            *   `\"condition\": \"string\",`\n                                \n                            *   `\"savedGroupTargeting\": [`\n                                \n                                *   `{`\n                                    \n                                    *   `\"matchType\": null,`\n                                        \n                                    *   `\"savedGroups\": [ ]`\n                                        \n                                    \n                                    `}`\n                                    \n                                \n                                `],`\n                                \n                            *   `\"id\": \"string\",`\n                                \n                            *   `\"enabled\": true,`\n                                \n                            *   `\"type\": \"force\",`\n                                \n                            *   `\"value\": \"string\"`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"definition\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `},`\n                \n            *   `\"property2\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\",`\n                    \n                *   `\"draft\": {`\n                    \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"defaultValue\": \"string\",`\n                        \n                    *   `\"rules\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"description\": \"string\",`\n                                \n                            *   `\"condition\": \"string\",`\n                                \n                            *   `\"savedGroupTargeting\": [`\n                                \n                                *   `{`\n                                    \n                                    *   `\"matchType\": null,`\n                                        \n                                    *   `\"savedGroups\": [ ]`\n                                        \n                                    \n                                    `}`\n                                    \n                                \n                                `],`\n                                \n                            *   `\"id\": \"string\",`\n                                \n                            *   `\"enabled\": true,`\n                                \n                            *   `\"type\": \"force\",`\n                                \n                            *   `\"value\": \"string\"`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"definition\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `},`\n            \n        *   `\"prerequisites\": [`\n            \n            *   `{`\n                \n                *   `\"parentId\": \"string\",`\n                    \n                *   `\"parentCondition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"revision\": {`\n            \n            *   `\"version\": 0,`\n                \n            *   `\"comment\": \"string\",`\n                \n            *   `\"date\": \"2019-08-24T14:15:22Z\",`\n                \n            *   `\"publishedBy\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/features/operation/postFeature)Create a single feature\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nid\n\nrequired\n\nstring non-empty\n\nA unique key name for the feature. Feature keys can only include letters, numbers, hyphens, and underscores.\n\narchived\n\nboolean\n\ndescription\n\nstring\n\nDescription of the feature\n\nowner\n\nrequired\n\nstring\n\nEmail of the person who owns this experiment\n\nproject\n\nstring\n\nAn associated project ID\n\nvalueType\n\nrequired\n\nstring\n\nEnum: \"boolean\" \"string\" \"number\" \"json\"\n\nThe data type of the feature payload. Boolean by default.\n\ndefaultValue\n\nrequired\n\nstring\n\nDefault value when feature is enabled. Type must match `valueType`.\n\ntags\n\nArray of strings\n\nList of associated tags\n\nobject\n\nA dictionary of environments that are enabled for this feature. Keys supply the names of environments. Environments belong to organization and are not specified will be disabled by default.\n\njsonSchema\n\nstring\n\nUse JSON schema to validate the payload of a JSON-type feature value (enterprise only).\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"archived\": true,`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"project\": \"string\",`\n    \n*   `\"valueType\": \"boolean\",`\n    \n*   `\"defaultValue\": \"string\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"environments\": {`\n    \n    *   `\"property1\": {`\n        \n        *   `\"enabled\": true,`\n            \n        *   `\"rules\": [`\n            \n            *   `{`\n                \n                *   `\"description\": \"string\",`\n                    \n                *   `\"condition\": \"string\",`\n                    \n                *   `\"savedGroupTargeting\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"matchType\": \"all\",`\n                            \n                        *   `\"savedGroups\": [`\n                            \n                            *   `\"string\"`\n                                \n                            \n                            `]`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"id\": \"string\",`\n                    \n                *   `\"enabled\": true,`\n                    \n                *   `\"type\": \"force\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"definition\": \"string\",`\n            \n        *   `\"draft\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"property2\": {`\n        \n        *   `\"enabled\": true,`\n            \n        *   `\"rules\": [`\n            \n            *   `{`\n                \n                *   `\"description\": \"string\",`\n                    \n                *   `\"condition\": \"string\",`\n                    \n                *   `\"savedGroupTargeting\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"matchType\": \"all\",`\n                            \n                        *   `\"savedGroups\": [`\n                            \n                            *   `\"string\"`\n                                \n                            \n                            `]`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"id\": \"string\",`\n                    \n                *   `\"enabled\": true,`\n                    \n                *   `\"type\": \"force\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"definition\": \"string\",`\n            \n        *   `\"draft\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `},`\n    \n*   `\"jsonSchema\": \"string\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"feature\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"archived\": true,`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    *   `\"valueType\": \"boolean\",`\n        \n    *   `\"defaultValue\": \"string\",`\n        \n    \n    *   `\"environments\": {`\n        \n        *   `\"property1\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\",`\n                \n            *   `\"draft\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `},`\n            \n        *   `\"property2\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\",`\n                \n            *   `\"draft\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"prerequisites\": [`\n        \n        *   `{`\n            \n            *   `\"parentId\": \"string\",`\n                \n            *   `\"parentCondition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"revision\": {`\n        \n        *   `\"version\": 0,`\n            \n        *   `\"comment\": \"string\",`\n            \n        *   `\"date\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"publishedBy\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/features/operation/getFeature)Get a single feature\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/features/my\\_feature \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"feature\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"archived\": true,`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    *   `\"valueType\": \"boolean\",`\n        \n    *   `\"defaultValue\": \"string\",`\n        \n    \n    *   `\"environments\": {`\n        \n        *   `\"property1\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\",`\n                \n            *   `\"draft\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `},`\n            \n        *   `\"property2\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\",`\n                \n            *   `\"draft\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"prerequisites\": [`\n        \n        *   `{`\n            \n            *   `\"parentId\": \"string\",`\n                \n            *   `\"parentCondition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"revision\": {`\n        \n        *   `\"version\": 0,`\n            \n        *   `\"comment\": \"string\",`\n            \n        *   `\"date\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"publishedBy\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/features/operation/updateFeature)Partially update a feature\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\ndescription\n\nstring\n\nDescription of the feature\n\narchived\n\nboolean\n\nproject\n\nstring\n\nAn associated project ID\n\nowner\n\nstring\n\ndefaultValue\n\nstring\n\ntags\n\nArray of strings\n\nList of associated tags. Will override tags completely with submitted list\n\nobject\n\njsonSchema\n\nstring\n\nUse JSON schema to validate the payload of a JSON-type feature value (enterprise only).\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"description\": \"string\",`\n    \n*   `\"archived\": true,`\n    \n*   `\"project\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"defaultValue\": \"string\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"environments\": {`\n    \n    *   `\"property1\": {`\n        \n        *   `\"enabled\": true,`\n            \n        *   `\"rules\": [`\n            \n            *   `{`\n                \n                *   `\"description\": \"string\",`\n                    \n                *   `\"condition\": \"string\",`\n                    \n                *   `\"savedGroupTargeting\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"matchType\": \"all\",`\n                            \n                        *   `\"savedGroups\": [`\n                            \n                            *   `\"string\"`\n                                \n                            \n                            `]`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"id\": \"string\",`\n                    \n                *   `\"enabled\": true,`\n                    \n                *   `\"type\": \"force\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"definition\": \"string\",`\n            \n        *   `\"draft\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"property2\": {`\n        \n        *   `\"enabled\": true,`\n            \n        *   `\"rules\": [`\n            \n            *   `{`\n                \n                *   `\"description\": \"string\",`\n                    \n                *   `\"condition\": \"string\",`\n                    \n                *   `\"savedGroupTargeting\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"matchType\": \"all\",`\n                            \n                        *   `\"savedGroups\": [`\n                            \n                            *   `\"string\"`\n                                \n                            \n                            `]`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"id\": \"string\",`\n                    \n                *   `\"enabled\": true,`\n                    \n                *   `\"type\": \"force\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"definition\": \"string\",`\n            \n        *   `\"draft\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `},`\n    \n*   `\"jsonSchema\": \"string\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"feature\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"archived\": true,`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    *   `\"valueType\": \"boolean\",`\n        \n    *   `\"defaultValue\": \"string\",`\n        \n    \n    *   `\"environments\": {`\n        \n        *   `\"property1\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\",`\n                \n            *   `\"draft\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `},`\n            \n        *   `\"property2\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\",`\n                \n            *   `\"draft\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"prerequisites\": [`\n        \n        *   `{`\n            \n            *   `\"parentId\": \"string\",`\n                \n            *   `\"parentCondition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"revision\": {`\n        \n        *   `\"version\": 0,`\n            \n        *   `\"comment\": \"string\",`\n            \n        *   `\"date\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"publishedBy\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/features/operation/toggleFeature)Toggle a feature in one or more environments\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nreason\n\nrequired\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"reason\": \"string\",`\n    \n*   `\"environments\": {`\n    \n    *   `\"property1\": true,`\n        \n    *   `\"property2\": true`\n        \n    \n    `}`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"feature\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"archived\": true,`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    *   `\"valueType\": \"boolean\",`\n        \n    *   `\"defaultValue\": \"string\",`\n        \n    \n    *   `\"environments\": {`\n        \n        *   `\"property1\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\",`\n                \n            *   `\"draft\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `},`\n            \n        *   `\"property2\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\",`\n                \n            *   `\"draft\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"prerequisites\": [`\n        \n        *   `{`\n            \n            *   `\"parentId\": \"string\",`\n                \n            *   `\"parentCondition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"revision\": {`\n        \n        *   `\"version\": 0,`\n            \n        *   `\"comment\": \"string\",`\n            \n        *   `\"date\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"publishedBy\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/features/operation/getFeatureKeys)Get list of feature keys\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nprojectId\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/feature\\-keys?projectId\\=prj\\_5l652 \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n## [](#tag/data-sources)Data Sources\n\nHow GrowthBook connects and queries your data\n\n## [](#tag/data-sources/operation/listDataSources)Get all data sources\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\nprojectId\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/data\\-sources \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"dataSources\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"type\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"projectIds\": [`\n            \n            *   `\"string\"`\n                \n            \n            `],`\n            \n        *   `\"eventTracker\": \"string\",`\n            \n        *   `\"identifierTypes\": [`\n            \n            *   `{`\n                \n                *   `\"id\": \"string\",`\n                    \n                *   `\"description\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"assignmentQueries\": [`\n            \n            *   `{`\n                \n                *   `\"id\": \"string\",`\n                    \n                *   `\"name\": \"string\",`\n                    \n                *   `\"description\": \"string\",`\n                    \n                *   `\"identifierType\": \"string\",`\n                    \n                *   `\"sql\": \"string\",`\n                    \n                *   `\"includesNameColumns\": true,`\n                    \n                *   `\"dimensionColumns\": [`\n                    \n                    *   `\"string\"`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"identifierJoinQueries\": [`\n            \n            *   `{`\n                \n                *   `\"identifierTypes\": [`\n                    \n                    *   `\"string\"`\n                        \n                    \n                    `],`\n                    \n                *   `\"sql\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"mixpanelSettings\": {`\n            \n            *   `\"viewedExperimentEventName\": \"string\",`\n                \n            *   `\"experimentIdProperty\": \"string\",`\n                \n            *   `\"variationIdProperty\": \"string\",`\n                \n            *   `\"extraUserIdProperty\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/data-sources/operation/getDataSource)Get a single data source\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/data\\-sources/ds\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"dataSource\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"type\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"projectIds\": [`\n        \n        *   `\"string\"`\n            \n        \n        `],`\n        \n    *   `\"eventTracker\": \"string\",`\n        \n    *   `\"identifierTypes\": [`\n        \n        *   `{`\n            \n            *   `\"id\": \"string\",`\n                \n            *   `\"description\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"assignmentQueries\": [`\n        \n        *   `{`\n            \n            *   `\"id\": \"string\",`\n                \n            *   `\"name\": \"string\",`\n                \n            *   `\"description\": \"string\",`\n                \n            *   `\"identifierType\": \"string\",`\n                \n            *   `\"sql\": \"string\",`\n                \n            *   `\"includesNameColumns\": true,`\n                \n            *   `\"dimensionColumns\": [`\n                \n                *   `\"string\"`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"identifierJoinQueries\": [`\n        \n        *   `{`\n            \n            *   `\"identifierTypes\": [`\n                \n                *   `\"string\"`\n                    \n                \n                `],`\n                \n            *   `\"sql\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"mixpanelSettings\": {`\n        \n        *   `\"viewedExperimentEventName\": \"string\",`\n            \n        *   `\"experimentIdProperty\": \"string\",`\n            \n        *   `\"variationIdProperty\": \"string\",`\n            \n        *   `\"extraUserIdProperty\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/metrics)Metrics\n\nMetrics used as goals and guardrails for experiments\n\n## [](#tag/metrics/operation/listMetrics)Get all metrics\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\nprojectId\n\ndatasourceId\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/metrics \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"metrics\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"managedBy\": \"\",`\n            \n        *   `\"dateCreated\": \"string\",`\n            \n        *   `\"dateUpdated\": \"string\",`\n            \n        *   `\"owner\": \"string\",`\n            \n        *   `\"datasourceId\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"type\": \"binomial\",`\n            \n        \n        *   `\"archived\": true,`\n            \n        *   `\"behavior\": {`\n            \n            *   `\"goal\": \"increase\",`\n                \n            *   `\"cappingSettings\": {`\n                \n                *   `\"type\": \"none\",`\n                    \n                *   `\"value\": 0,`\n                    \n                *   `\"ignoreZeros\": true`\n                    \n                \n                `},`\n                \n            *   `\"cap\": 0,`\n                \n            *   `\"capping\": \"absolute\",`\n                \n            *   `\"capValue\": 0,`\n                \n            *   `\"windowSettings\": {`\n                \n                *   `\"type\": \"none\",`\n                    \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowValue\": 0,`\n                    \n                *   `\"windowUnit\": \"hours\"`\n                    \n                \n                `},`\n                \n            *   `\"priorSettings\": {`\n                \n                *   `\"override\": true,`\n                    \n                *   `\"proper\": true,`\n                    \n                *   `\"mean\": 0,`\n                    \n                *   `\"stddev\": 0`\n                    \n                \n                `},`\n                \n            *   `\"conversionWindowStart\": 0,`\n                \n            *   `\"conversionWindowEnd\": 0,`\n                \n            *   `\"riskThresholdSuccess\": 0,`\n                \n            *   `\"riskThresholdDanger\": 0,`\n                \n            *   `\"minPercentChange\": 0,`\n                \n            *   `\"maxPercentChange\": 0,`\n                \n            *   `\"minSampleSize\": 0`\n                \n            \n            `},`\n            \n        *   `\"sql\": {`\n            \n            *   `\"identifierTypes\": [`\n                \n                *   `\"string\"`\n                    \n                \n                `],`\n                \n            *   `\"conversionSQL\": \"string\",`\n                \n            *   `\"userAggregationSQL\": \"string\",`\n                \n            *   `\"denominatorMetricId\": \"string\"`\n                \n            \n            `},`\n            \n        *   `\"sqlBuilder\": {`\n            \n            *   `\"identifierTypeColumns\": [`\n                \n                *   `{`\n                    \n                    *   `\"identifierType\": \"string\",`\n                        \n                    *   `\"columnName\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"tableName\": \"string\",`\n                \n            *   `\"valueColumnName\": \"string\",`\n                \n            *   `\"timestampColumnName\": \"string\",`\n                \n            *   `\"conditions\": [`\n                \n                *   `{`\n                    \n                    *   `\"column\": \"string\",`\n                        \n                    *   `\"operator\": \"string\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `},`\n            \n        *   `\"mixpanel\": {`\n            \n            *   `\"eventName\": \"string\",`\n                \n            *   `\"eventValue\": \"string\",`\n                \n            *   `\"userAggregation\": \"string\",`\n                \n            *   `\"conditions\": [`\n                \n                *   `{`\n                    \n                    *   `\"property\": \"string\",`\n                        \n                    *   `\"operator\": \"string\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/metrics/operation/postMetric)Create a single metric\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\ndatasourceId\n\nrequired\n\nstring\n\nID for the [DataSource](#tag/DataSource_model)\n\nmanagedBy\n\nstring\n\nEnum: \"\" \"api\"\n\nWhere this metric must be managed from. If not set (empty string), it can be managed from anywhere.\n\nowner\n\nstring\n\nName of the person who owns this metric\n\nname\n\nrequired\n\nstring\n\nName of the metric\n\ndescription\n\nstring\n\nDescription of the metric\n\ntype\n\nrequired\n\nstring\n\nEnum: \"binomial\" \"count\" \"duration\" \"revenue\"\n\nType of metric. See [Metrics documentation](https://docs.growthbook.io/app/metrics)\n\ntags\n\nArray of strings\n\nList of tags\n\nprojects\n\nArray of strings\n\nList of project IDs for projects that can access this metric\n\narchived\n\nboolean\n\nobject\n\nobject\n\nPreferred way to define SQL. Only one of `sql`, `sqlBuilder` or `mixpanel` allowed, and at least one must be specified.\n\nobject\n\nAn alternative way to specify a SQL metric, rather than a full query. Using `sql` is preferred to `sqlBuilder`. Only one of `sql`, `sqlBuilder` or `mixpanel` allowed, and at least one must be specified.\n\nobject\n\nOnly use for MixPanel (non-SQL) Data Sources. Only one of `sql`, `sqlBuilder` or `mixpanel` allowed, and at least one must be specified.\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"datasourceId\": \"string\",`\n    \n*   `\"managedBy\": \"\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"type\": \"binomial\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"archived\": true,`\n    \n*   `\"behavior\": {`\n    \n    *   `\"goal\": \"increase\",`\n        \n    *   `\"cappingSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"value\": 0,`\n            \n        *   `\"ignoreZeros\": true`\n            \n        \n        `},`\n        \n    *   `\"cap\": 0,`\n        \n    *   `\"capping\": \"absolute\",`\n        \n    *   `\"capValue\": 0,`\n        \n    *   `\"windowSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"delayHours\": 0,`\n            \n        *   `\"windowValue\": 0,`\n            \n        *   `\"windowUnit\": \"hours\"`\n            \n        \n        `},`\n        \n    *   `\"conversionWindowStart\": 0,`\n        \n    *   `\"conversionWindowEnd\": 0,`\n        \n    *   `\"priorSettings\": {`\n        \n        *   `\"override\": true,`\n            \n        *   `\"proper\": true,`\n            \n        *   `\"mean\": 0,`\n            \n        *   `\"stddev\": 0`\n            \n        \n        `},`\n        \n    *   `\"riskThresholdSuccess\": 0,`\n        \n    *   `\"riskThresholdDanger\": 0,`\n        \n    *   `\"minPercentChange\": 0,`\n        \n    *   `\"maxPercentChange\": 0,`\n        \n    *   `\"minSampleSize\": 0`\n        \n    \n    `},`\n    \n*   `\"sql\": {`\n    \n    *   `\"identifierTypes\": [`\n        \n        *   `\"string\"`\n            \n        \n        `],`\n        \n    *   `\"conversionSQL\": \"string\",`\n        \n    *   `\"userAggregationSQL\": \"string\",`\n        \n    *   `\"denominatorMetricId\": \"string\"`\n        \n    \n    `},`\n    \n*   `\"sqlBuilder\": {`\n    \n    *   `\"identifierTypeColumns\": [`\n        \n        *   `{`\n            \n            *   `\"identifierType\": \"string\",`\n                \n            *   `\"columnName\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"tableName\": \"string\",`\n        \n    *   `\"valueColumnName\": \"string\",`\n        \n    *   `\"timestampColumnName\": \"string\",`\n        \n    *   `\"conditions\": [`\n        \n        *   `{`\n            \n            *   `\"column\": \"string\",`\n                \n            *   `\"operator\": \"string\",`\n                \n            *   `\"value\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `},`\n    \n*   `\"mixpanel\": {`\n    \n    *   `\"eventName\": \"string\",`\n        \n    *   `\"eventValue\": \"string\",`\n        \n    *   `\"userAggregation\": \"string\",`\n        \n    *   `\"conditions\": [`\n        \n        *   `{`\n            \n            *   `\"property\": \"string\",`\n                \n            *   `\"operator\": \"string\",`\n                \n            *   `\"value\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `}`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"metric\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"string\",`\n        \n    *   `\"dateUpdated\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"datasourceId\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"type\": \"binomial\",`\n        \n    \n    *   `\"archived\": true,`\n        \n    *   `\"behavior\": {`\n        \n        *   `\"goal\": \"increase\",`\n            \n        *   `\"cappingSettings\": {`\n            \n            *   `\"type\": \"none\",`\n                \n            *   `\"value\": 0,`\n                \n            *   `\"ignoreZeros\": true`\n                \n            \n            `},`\n            \n        *   `\"cap\": 0,`\n            \n        *   `\"capping\": \"absolute\",`\n            \n        *   `\"capValue\": 0,`\n            \n        *   `\"windowSettings\": {`\n            \n            *   `\"type\": \"none\",`\n                \n            *   `\"delayHours\": 0,`\n                \n            *   `\"windowValue\": 0,`\n                \n            *   `\"windowUnit\": \"hours\"`\n                \n            \n            `},`\n            \n        *   `\"priorSettings\": {`\n            \n            *   `\"override\": true,`\n                \n            *   `\"proper\": true,`\n                \n            *   `\"mean\": 0,`\n                \n            *   `\"stddev\": 0`\n                \n            \n            `},`\n            \n        *   `\"conversionWindowStart\": 0,`\n            \n        *   `\"conversionWindowEnd\": 0,`\n            \n        *   `\"riskThresholdSuccess\": 0,`\n            \n        *   `\"riskThresholdDanger\": 0,`\n            \n        *   `\"minPercentChange\": 0,`\n            \n        *   `\"maxPercentChange\": 0,`\n            \n        *   `\"minSampleSize\": 0`\n            \n        \n        `},`\n        \n    *   `\"sql\": {`\n        \n        *   `\"identifierTypes\": [`\n            \n            *   `\"string\"`\n                \n            \n            `],`\n            \n        *   `\"conversionSQL\": \"string\",`\n            \n        *   `\"userAggregationSQL\": \"string\",`\n            \n        *   `\"denominatorMetricId\": \"string\"`\n            \n        \n        `},`\n        \n    *   `\"sqlBuilder\": {`\n        \n        *   `\"identifierTypeColumns\": [`\n            \n            *   `{`\n                \n                *   `\"identifierType\": \"string\",`\n                    \n                *   `\"columnName\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"tableName\": \"string\",`\n            \n        *   `\"valueColumnName\": \"string\",`\n            \n        *   `\"timestampColumnName\": \"string\",`\n            \n        *   `\"conditions\": [`\n            \n            *   `{`\n                \n                *   `\"column\": \"string\",`\n                    \n                *   `\"operator\": \"string\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `},`\n        \n    *   `\"mixpanel\": {`\n        \n        *   `\"eventName\": \"string\",`\n            \n        *   `\"eventValue\": \"string\",`\n            \n        *   `\"userAggregation\": \"string\",`\n            \n        *   `\"conditions\": [`\n            \n            *   `{`\n                \n                *   `\"property\": \"string\",`\n                    \n                *   `\"operator\": \"string\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/metrics/operation/getMetric)Get a single metric\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/metrics/met\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"metric\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"string\",`\n        \n    *   `\"dateUpdated\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"datasourceId\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"type\": \"binomial\",`\n        \n    \n    *   `\"archived\": true,`\n        \n    *   `\"behavior\": {`\n        \n        *   `\"goal\": \"increase\",`\n            \n        *   `\"cappingSettings\": {`\n            \n            *   `\"type\": \"none\",`\n                \n            *   `\"value\": 0,`\n                \n            *   `\"ignoreZeros\": true`\n                \n            \n            `},`\n            \n        *   `\"cap\": 0,`\n            \n        *   `\"capping\": \"absolute\",`\n            \n        *   `\"capValue\": 0,`\n            \n        *   `\"windowSettings\": {`\n            \n            *   `\"type\": \"none\",`\n                \n            *   `\"delayHours\": 0,`\n                \n            *   `\"windowValue\": 0,`\n                \n            *   `\"windowUnit\": \"hours\"`\n                \n            \n            `},`\n            \n        *   `\"priorSettings\": {`\n            \n            *   `\"override\": true,`\n                \n            *   `\"proper\": true,`\n                \n            *   `\"mean\": 0,`\n                \n            *   `\"stddev\": 0`\n                \n            \n            `},`\n            \n        *   `\"conversionWindowStart\": 0,`\n            \n        *   `\"conversionWindowEnd\": 0,`\n            \n        *   `\"riskThresholdSuccess\": 0,`\n            \n        *   `\"riskThresholdDanger\": 0,`\n            \n        *   `\"minPercentChange\": 0,`\n            \n        *   `\"maxPercentChange\": 0,`\n            \n        *   `\"minSampleSize\": 0`\n            \n        \n        `},`\n        \n    *   `\"sql\": {`\n        \n        *   `\"identifierTypes\": [`\n            \n            *   `\"string\"`\n                \n            \n            `],`\n            \n        *   `\"conversionSQL\": \"string\",`\n            \n        *   `\"userAggregationSQL\": \"string\",`\n            \n        *   `\"denominatorMetricId\": \"string\"`\n            \n        \n        `},`\n        \n    *   `\"sqlBuilder\": {`\n        \n        *   `\"identifierTypeColumns\": [`\n            \n            *   `{`\n                \n                *   `\"identifierType\": \"string\",`\n                    \n                *   `\"columnName\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"tableName\": \"string\",`\n            \n        *   `\"valueColumnName\": \"string\",`\n            \n        *   `\"timestampColumnName\": \"string\",`\n            \n        *   `\"conditions\": [`\n            \n            *   `{`\n                \n                *   `\"column\": \"string\",`\n                    \n                *   `\"operator\": \"string\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `},`\n        \n    *   `\"mixpanel\": {`\n        \n        *   `\"eventName\": \"string\",`\n            \n        *   `\"eventValue\": \"string\",`\n            \n        *   `\"userAggregation\": \"string\",`\n            \n        *   `\"conditions\": [`\n            \n            *   `{`\n                \n                *   `\"property\": \"string\",`\n                    \n                *   `\"operator\": \"string\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/metrics/operation/putMetric)Update a metric\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nmanagedBy\n\nstring\n\nEnum: \"\" \"api\"\n\nWhere this metric must be managed from. If not set (empty string), it can be managed from anywhere.\n\nowner\n\nstring\n\nName of the person who owns this metric\n\nname\n\nstring\n\nName of the metric\n\ndescription\n\nstring\n\nDescription of the metric\n\ntype\n\nstring\n\nEnum: \"binomial\" \"count\" \"duration\" \"revenue\"\n\nType of metric. See [Metrics documentation](https://docs.growthbook.io/app/metrics)\n\ntags\n\nArray of strings\n\nList of tags\n\nprojects\n\nArray of strings\n\nList of project IDs for projects that can access this metric\n\narchived\n\nboolean\n\nobject\n\nobject\n\nPreferred way to define SQL. Only one of `sql`, `sqlBuilder` or `mixpanel` allowed.\n\nobject\n\nAn alternative way to specify a SQL metric, rather than a full query. Using `sql` is preferred to `sqlBuilder`. Only one of `sql`, `sqlBuilder` or `mixpanel` allowed\n\nobject\n\nOnly use for MixPanel (non-SQL) Data Sources. Only one of `sql`, `sqlBuilder` or `mixpanel` allowed.\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"managedBy\": \"\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"type\": \"binomial\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"archived\": true,`\n    \n*   `\"behavior\": {`\n    \n    *   `\"goal\": \"increase\",`\n        \n    *   `\"cappingSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"value\": 0,`\n            \n        *   `\"ignoreZeros\": true`\n            \n        \n        `},`\n        \n    *   `\"cap\": 0,`\n        \n    *   `\"capping\": \"absolute\",`\n        \n    *   `\"capValue\": 0,`\n        \n    *   `\"windowSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"delayHours\": 0,`\n            \n        *   `\"windowValue\": 0,`\n            \n        *   `\"windowUnit\": \"hours\"`\n            \n        \n        `},`\n        \n    *   `\"conversionWindowStart\": 0,`\n        \n    *   `\"conversionWindowEnd\": 0,`\n        \n    *   `\"priorSettings\": {`\n        \n        *   `\"override\": true,`\n            \n        *   `\"proper\": true,`\n            \n        *   `\"mean\": 0,`\n            \n        *   `\"stddev\": 0`\n            \n        \n        `},`\n        \n    *   `\"riskThresholdSuccess\": 0,`\n        \n    *   `\"riskThresholdDanger\": 0,`\n        \n    *   `\"minPercentChange\": 0,`\n        \n    *   `\"maxPercentChange\": 0,`\n        \n    *   `\"minSampleSize\": 0`\n        \n    \n    `},`\n    \n*   `\"sql\": {`\n    \n    *   `\"identifierTypes\": [`\n        \n        *   `\"string\"`\n            \n        \n        `],`\n        \n    *   `\"conversionSQL\": \"string\",`\n        \n    *   `\"userAggregationSQL\": \"string\",`\n        \n    *   `\"denominatorMetricId\": \"string\"`\n        \n    \n    `},`\n    \n*   `\"sqlBuilder\": {`\n    \n    *   `\"identifierTypeColumns\": [`\n        \n        *   `{`\n            \n            *   `\"identifierType\": \"string\",`\n                \n            *   `\"columnName\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"tableName\": \"string\",`\n        \n    *   `\"valueColumnName\": \"string\",`\n        \n    *   `\"timestampColumnName\": \"string\",`\n        \n    *   `\"conditions\": [`\n        \n        *   `{`\n            \n            *   `\"column\": \"string\",`\n                \n            *   `\"operator\": \"string\",`\n                \n            *   `\"value\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `},`\n    \n*   `\"mixpanel\": {`\n    \n    *   `\"eventName\": \"string\",`\n        \n    *   `\"eventValue\": \"string\",`\n        \n    *   `\"userAggregation\": \"string\",`\n        \n    *   `\"conditions\": [`\n        \n        *   `{`\n            \n            *   `\"property\": \"string\",`\n                \n            *   `\"operator\": \"string\",`\n                \n            *   `\"value\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `}`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"updatedId\": \"string\"`\n    \n\n`}`\n\n## [](#tag/metrics/operation/deleteMetric)Deletes a metric\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-X DELETE https://api.growthbook.io/api/v1/metrics/met\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"deletedId\": \"string\"`\n    \n\n`}`\n\n## [](#tag/experiments)Experiments\n\n## [](#tag/experiments/operation/listExperiments)Get all experiments\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\nprojectId\n\ndatasourceId\n\nexperimentId\n\nstring\n\nFilter the returned list by the experiment tracking key (id)\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/experiments \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"experiments\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"project\": \"string\",`\n            \n        *   `\"hypothesis\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        \n        *   `\"owner\": \"string\",`\n            \n        *   `\"archived\": true,`\n            \n        *   `\"status\": \"string\",`\n            \n        *   `\"autoRefresh\": true,`\n            \n        *   `\"hashAttribute\": \"string\",`\n            \n        *   `\"fallbackAttribute\": \"string\",`\n            \n        *   `\"hashVersion\": 1,`\n            \n        *   `\"disableStickyBucketing\": null,`\n            \n        *   `\"bucketVersion\": 0,`\n            \n        *   `\"minBucketVersion\": 0,`\n            \n        *   `\"variations\": [`\n            \n            *   `{`\n                \n                *   `\"variationId\": \"string\",`\n                    \n                *   `\"key\": \"string\",`\n                    \n                *   `\"name\": \"string\",`\n                    \n                *   `\"description\": \"string\",`\n                    \n                *   `\"screenshots\": [`\n                    \n                    *   `\"string\"`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"phases\": [`\n            \n            *   `{`\n                \n                *   `\"name\": \"string\",`\n                    \n                *   `\"dateStarted\": \"string\",`\n                    \n                *   `\"dateEnded\": \"string\",`\n                    \n                *   `\"reasonForStopping\": \"string\",`\n                    \n                *   `\"seed\": \"string\",`\n                    \n                *   `\"coverage\": 0,`\n                    \n                *   `\"trafficSplit\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"variationId\": \"string\",`\n                            \n                        *   `\"weight\": 0`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"namespace\": {`\n                    \n                    *   `\"namespaceId\": \"string\",`\n                        \n                    *   `\"range\": [ ]`\n                        \n                    \n                    `},`\n                    \n                *   `\"targetingCondition\": \"string\",`\n                    \n                *   `\"savedGroupTargeting\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"matchType\": \"all\",`\n                            \n                        *   `\"savedGroups\": [`\n                            \n                            *   `\"string\"`\n                                \n                            \n                            `]`\n                            \n                        \n                        `}`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"settings\": {`\n            \n            *   `\"datasourceId\": \"string\",`\n                \n            *   `\"assignmentQueryId\": \"string\",`\n                \n            *   `\"experimentId\": \"string\",`\n                \n            *   `\"segmentId\": \"string\",`\n                \n            *   `\"queryFilter\": \"string\",`\n                \n            *   `\"inProgressConversions\": \"include\",`\n                \n            *   `\"attributionModel\": \"firstExposure\",`\n                \n            *   `\"statsEngine\": \"bayesian\",`\n                \n            *   `\"goals\": [`\n                \n                *   `{`\n                    \n                    *   `\"metricId\": \"string\",`\n                        \n                    *   `\"overrides\": {`\n                        \n                        *   `\"delayHours\": 0,`\n                            \n                        *   `\"windowHours\": 0,`\n                            \n                        *   `\"window\": \"conversion\",`\n                            \n                        *   `\"winRiskThreshold\": 0,`\n                            \n                        *   `\"loseRiskThreshold\": 0`\n                            \n                        \n                        `}`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"guardrails\": [`\n                \n                *   `{`\n                    \n                    *   `\"metricId\": \"string\",`\n                        \n                    *   `\"overrides\": {`\n                        \n                        *   `\"delayHours\": 0,`\n                            \n                        *   `\"windowHours\": 0,`\n                            \n                        *   `\"window\": \"conversion\",`\n                            \n                        *   `\"winRiskThreshold\": 0,`\n                            \n                        *   `\"loseRiskThreshold\": 0`\n                            \n                        \n                        `}`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"activationMetric\": {`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `},`\n            \n        *   `\"resultSummary\": {`\n            \n            *   `\"status\": \"string\",`\n                \n            *   `\"winner\": \"string\",`\n                \n            *   `\"conclusions\": \"string\",`\n                \n            *   `\"releasedVariationId\": \"string\",`\n                \n            *   `\"excludeFromPayload\": true`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/experiments/operation/postExperiment)Create a single experiment\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\ndatasourceId\n\nrequired\n\nstring\n\nID for the [DataSource](#tag/DataSource_model)\n\nassignmentQueryId\n\nrequired\n\nstring\n\nThe ID property of one of the assignment query objects associated with the datasource\n\ntrackingKey\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\nName of the experiment\n\nproject\n\nstring\n\nProject ID which the experiment belongs to\n\nhypothesis\n\nstring\n\nHypothesis of the experiment\n\ndescription\n\nstring\n\nDescription of the experiment\n\ntags\n\nArray of strings\n\nmetrics\n\nArray of strings\n\nguardrailMetrics\n\nArray of strings\n\nowner\n\nstring\n\nEmail of the person who owns this experiment\n\narchived\n\nboolean\n\nstatus\n\nstring\n\nEnum: \"draft\" \"running\" \"stopped\"\n\nautoRefresh\n\nboolean\n\nhashAttribute\n\nstring\n\nfallbackAttribute\n\nstring\n\nhashVersion\n\nnumber\n\nEnum: 1 2\n\ndisableStickyBucketing\n\nboolean;\n\nbucketVersion\n\nnumber\n\nminBucketVersion\n\nnumber\n\nreleasedVariationId\n\nstring\n\nexcludeFromPayload\n\nboolean\n\ninProgressConversions\n\nstring\n\nEnum: \"loose\" \"strict\"\n\nattributionModel\n\nstring\n\nEnum: \"firstExposure\" \"experimentDuration\"\n\nstatsEngine\n\nstring\n\nEnum: \"bayesian\" \"frequentist\"\n\nrequired\n\nArray of objects \\>= 2 items\n\nArray of objects\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"datasourceId\": \"string\",`\n    \n*   `\"assignmentQueryId\": \"string\",`\n    \n*   `\"trackingKey\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"project\": \"string\",`\n    \n*   `\"hypothesis\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"metrics\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"guardrailMetrics\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"archived\": true,`\n    \n*   `\"status\": \"draft\",`\n    \n*   `\"autoRefresh\": true,`\n    \n*   `\"hashAttribute\": \"string\",`\n    \n*   `\"fallbackAttribute\": \"string\",`\n    \n*   `\"hashVersion\": 1,`\n    \n*   `\"disableStickyBucketing\": null,`\n    \n*   `\"bucketVersion\": 0,`\n    \n*   `\"minBucketVersion\": 0,`\n    \n*   `\"releasedVariationId\": \"string\",`\n    \n*   `\"excludeFromPayload\": true,`\n    \n*   `\"inProgressConversions\": \"loose\",`\n    \n*   `\"attributionModel\": \"firstExposure\",`\n    \n*   `\"statsEngine\": \"bayesian\",`\n    \n*   `\"variations\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"key\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"screenshots\": [`\n            \n            *   `{`\n                \n                *   `\"path\": \"string\",`\n                    \n                *   `\"width\": 0,`\n                    \n                *   `\"height\": 0,`\n                    \n                *   `\"description\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `},`\n        \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"key\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"screenshots\": [`\n            \n            *   `{`\n                \n                *   `\"path\": \"string\",`\n                    \n                *   `\"width\": 0,`\n                    \n                *   `\"height\": 0,`\n                    \n                *   `\"description\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"phases\": [`\n    \n    *   `{`\n        \n        *   `\"name\": \"string\",`\n            \n        *   `\"dateStarted\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateEnded\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"reasonForStopping\": \"string\",`\n            \n        *   `\"seed\": \"string\",`\n            \n        *   `\"coverage\": 0,`\n            \n        *   `\"trafficSplit\": [`\n            \n            *   `{`\n                \n                *   `\"variationId\": \"string\",`\n                    \n                *   `\"weight\": 0`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"namespace\": {`\n            \n            *   `\"namespaceId\": \"string\",`\n                \n            \n            *   `\"enabled\": true`\n                \n            \n            `},`\n            \n        *   `\"targetingCondition\": \"string\",`\n            \n        *   `\"reason\": \"string\",`\n            \n        *   `\"condition\": \"string\",`\n            \n        *   `\"savedGroupTargeting\": [`\n            \n            *   `{`\n                \n                *   `\"matchType\": \"all\",`\n                    \n                *   `\"savedGroups\": [`\n                    \n                    *   `\"string\"`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"experiment\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    *   `\"hypothesis\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    \n    *   `\"owner\": \"string\",`\n        \n    *   `\"archived\": true,`\n        \n    *   `\"status\": \"string\",`\n        \n    *   `\"autoRefresh\": true,`\n        \n    *   `\"hashAttribute\": \"string\",`\n        \n    *   `\"fallbackAttribute\": \"string\",`\n        \n    *   `\"hashVersion\": 1,`\n        \n    *   `\"disableStickyBucketing\": null,`\n        \n    *   `\"bucketVersion\": 0,`\n        \n    *   `\"minBucketVersion\": 0,`\n        \n    *   `\"variations\": [`\n        \n        *   `{`\n            \n            *   `\"variationId\": \"string\",`\n                \n            *   `\"key\": \"string\",`\n                \n            *   `\"name\": \"string\",`\n                \n            *   `\"description\": \"string\",`\n                \n            *   `\"screenshots\": [`\n                \n                *   `\"string\"`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"phases\": [`\n        \n        *   `{`\n            \n            *   `\"name\": \"string\",`\n                \n            *   `\"dateStarted\": \"string\",`\n                \n            *   `\"dateEnded\": \"string\",`\n                \n            *   `\"reasonForStopping\": \"string\",`\n                \n            *   `\"seed\": \"string\",`\n                \n            *   `\"coverage\": 0,`\n                \n            *   `\"trafficSplit\": [`\n                \n                *   `{`\n                    \n                    *   `\"variationId\": \"string\",`\n                        \n                    *   `\"weight\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"namespace\": {`\n                \n                *   `\"namespaceId\": \"string\",`\n                    \n                *   `\"range\": [ ]`\n                    \n                \n                `},`\n                \n            *   `\"targetingCondition\": \"string\",`\n                \n            *   `\"savedGroupTargeting\": [`\n                \n                *   `{`\n                    \n                    *   `\"matchType\": \"all\",`\n                        \n                    *   `\"savedGroups\": [`\n                        \n                        *   `\"string\"`\n                            \n                        \n                        `]`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"settings\": {`\n        \n        *   `\"datasourceId\": \"string\",`\n            \n        *   `\"assignmentQueryId\": \"string\",`\n            \n        *   `\"experimentId\": \"string\",`\n            \n        *   `\"segmentId\": \"string\",`\n            \n        *   `\"queryFilter\": \"string\",`\n            \n        *   `\"inProgressConversions\": \"include\",`\n            \n        *   `\"attributionModel\": \"firstExposure\",`\n            \n        *   `\"statsEngine\": \"bayesian\",`\n            \n        *   `\"goals\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"guardrails\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"activationMetric\": {`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"resultSummary\": {`\n        \n        *   `\"status\": \"string\",`\n            \n        *   `\"winner\": \"string\",`\n            \n        *   `\"conclusions\": \"string\",`\n            \n        *   `\"releasedVariationId\": \"string\",`\n            \n        *   `\"excludeFromPayload\": true`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/experiments/operation/getExperiment)Get a single experiment\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/experiments/exp\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"experiment\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    *   `\"hypothesis\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    \n    *   `\"owner\": \"string\",`\n        \n    *   `\"archived\": true,`\n        \n    *   `\"status\": \"string\",`\n        \n    *   `\"autoRefresh\": true,`\n        \n    *   `\"hashAttribute\": \"string\",`\n        \n    *   `\"fallbackAttribute\": \"string\",`\n        \n    *   `\"hashVersion\": 1,`\n        \n    *   `\"disableStickyBucketing\": null,`\n        \n    *   `\"bucketVersion\": 0,`\n        \n    *   `\"minBucketVersion\": 0,`\n        \n    *   `\"variations\": [`\n        \n        *   `{`\n            \n            *   `\"variationId\": \"string\",`\n                \n            *   `\"key\": \"string\",`\n                \n            *   `\"name\": \"string\",`\n                \n            *   `\"description\": \"string\",`\n                \n            *   `\"screenshots\": [`\n                \n                *   `\"string\"`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"phases\": [`\n        \n        *   `{`\n            \n            *   `\"name\": \"string\",`\n                \n            *   `\"dateStarted\": \"string\",`\n                \n            *   `\"dateEnded\": \"string\",`\n                \n            *   `\"reasonForStopping\": \"string\",`\n                \n            *   `\"seed\": \"string\",`\n                \n            *   `\"coverage\": 0,`\n                \n            *   `\"trafficSplit\": [`\n                \n                *   `{`\n                    \n                    *   `\"variationId\": \"string\",`\n                        \n                    *   `\"weight\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"namespace\": {`\n                \n                *   `\"namespaceId\": \"string\",`\n                    \n                *   `\"range\": [ ]`\n                    \n                \n                `},`\n                \n            *   `\"targetingCondition\": \"string\",`\n                \n            *   `\"savedGroupTargeting\": [`\n                \n                *   `{`\n                    \n                    *   `\"matchType\": \"all\",`\n                        \n                    *   `\"savedGroups\": [`\n                        \n                        *   `\"string\"`\n                            \n                        \n                        `]`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"settings\": {`\n        \n        *   `\"datasourceId\": \"string\",`\n            \n        *   `\"assignmentQueryId\": \"string\",`\n            \n        *   `\"experimentId\": \"string\",`\n            \n        *   `\"segmentId\": \"string\",`\n            \n        *   `\"queryFilter\": \"string\",`\n            \n        *   `\"inProgressConversions\": \"include\",`\n            \n        *   `\"attributionModel\": \"firstExposure\",`\n            \n        *   `\"statsEngine\": \"bayesian\",`\n            \n        *   `\"goals\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"guardrails\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"activationMetric\": {`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"resultSummary\": {`\n        \n        *   `\"status\": \"string\",`\n            \n        *   `\"winner\": \"string\",`\n            \n        *   `\"conclusions\": \"string\",`\n            \n        *   `\"releasedVariationId\": \"string\",`\n            \n        *   `\"excludeFromPayload\": true`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/experiments/operation/updateExperiment)Update a single experiment\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nassignmentQueryId\n\nstring\n\ntrackingKey\n\nstring\n\nname\n\nstring\n\nName of the experiment\n\nproject\n\nstring\n\nProject ID which the experiment belongs to\n\nhypothesis\n\nstring\n\nHypothesis of the experiment\n\ndescription\n\nstring\n\nDescription of the experiment\n\ntags\n\nArray of strings\n\nmetrics\n\nArray of strings\n\nguardrailMetrics\n\nArray of strings\n\nowner\n\nstring\n\nEmail of the person who owns this experiment\n\narchived\n\nboolean\n\nstatus\n\nstring\n\nEnum: \"draft\" \"running\" \"stopped\"\n\nautoRefresh\n\nboolean\n\nhashAttribute\n\nstring\n\nfallbackAttribute\n\nstring\n\nhashVersion\n\nnumber\n\nEnum: 1 2\n\ndisableStickyBucketing\n\nboolean;\n\nbucketVersion\n\nnumber\n\nminBucketVersion\n\nnumber\n\nreleasedVariationId\n\nstring\n\nexcludeFromPayload\n\nboolean\n\ninProgressConversions\n\nstring\n\nEnum: \"loose\" \"strict\"\n\nattributionModel\n\nstring\n\nEnum: \"firstExposure\" \"experimentDuration\"\n\nstatsEngine\n\nstring\n\nEnum: \"bayesian\" \"frequentist\"\n\nArray of objects \\>= 2 items\n\nArray of objects\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"assignmentQueryId\": \"string\",`\n    \n*   `\"trackingKey\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"project\": \"string\",`\n    \n*   `\"hypothesis\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"metrics\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"guardrailMetrics\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"archived\": true,`\n    \n*   `\"status\": \"draft\",`\n    \n*   `\"autoRefresh\": true,`\n    \n*   `\"hashAttribute\": \"string\",`\n    \n*   `\"fallbackAttribute\": \"string\",`\n    \n*   `\"hashVersion\": 1,`\n    \n*   `\"disableStickyBucketing\": null,`\n    \n*   `\"bucketVersion\": 0,`\n    \n*   `\"minBucketVersion\": 0,`\n    \n*   `\"releasedVariationId\": \"string\",`\n    \n*   `\"excludeFromPayload\": true,`\n    \n*   `\"inProgressConversions\": \"loose\",`\n    \n*   `\"attributionModel\": \"firstExposure\",`\n    \n*   `\"statsEngine\": \"bayesian\",`\n    \n*   `\"variations\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"key\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"screenshots\": [`\n            \n            *   `{`\n                \n                *   `\"path\": \"string\",`\n                    \n                *   `\"width\": 0,`\n                    \n                *   `\"height\": 0,`\n                    \n                *   `\"description\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `},`\n        \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"key\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"screenshots\": [`\n            \n            *   `{`\n                \n                *   `\"path\": \"string\",`\n                    \n                *   `\"width\": 0,`\n                    \n                *   `\"height\": 0,`\n                    \n                *   `\"description\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"phases\": [`\n    \n    *   `{`\n        \n        *   `\"name\": \"string\",`\n            \n        *   `\"dateStarted\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateEnded\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"reasonForStopping\": \"string\",`\n            \n        *   `\"seed\": \"string\",`\n            \n        *   `\"coverage\": 0,`\n            \n        *   `\"trafficSplit\": [`\n            \n            *   `{`\n                \n                *   `\"variationId\": \"string\",`\n                    \n                *   `\"weight\": 0`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"namespace\": {`\n            \n            *   `\"namespaceId\": \"string\",`\n                \n            \n            *   `\"enabled\": true`\n                \n            \n            `},`\n            \n        *   `\"targetingCondition\": \"string\",`\n            \n        *   `\"reason\": \"string\",`\n            \n        *   `\"condition\": \"string\",`\n            \n        *   `\"savedGroupTargeting\": [`\n            \n            *   `{`\n                \n                *   `\"matchType\": \"all\",`\n                    \n                *   `\"savedGroups\": [`\n                    \n                    *   `\"string\"`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"experiment\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    *   `\"hypothesis\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    \n    *   `\"owner\": \"string\",`\n        \n    *   `\"archived\": true,`\n        \n    *   `\"status\": \"string\",`\n        \n    *   `\"autoRefresh\": true,`\n        \n    *   `\"hashAttribute\": \"string\",`\n        \n    *   `\"fallbackAttribute\": \"string\",`\n        \n    *   `\"hashVersion\": 1,`\n        \n    *   `\"disableStickyBucketing\": null,`\n        \n    *   `\"bucketVersion\": 0,`\n        \n    *   `\"minBucketVersion\": 0,`\n        \n    *   `\"variations\": [`\n        \n        *   `{`\n            \n            *   `\"variationId\": \"string\",`\n                \n            *   `\"key\": \"string\",`\n                \n            *   `\"name\": \"string\",`\n                \n            *   `\"description\": \"string\",`\n                \n            *   `\"screenshots\": [`\n                \n                *   `\"string\"`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"phases\": [`\n        \n        *   `{`\n            \n            *   `\"name\": \"string\",`\n                \n            *   `\"dateStarted\": \"string\",`\n                \n            *   `\"dateEnded\": \"string\",`\n                \n            *   `\"reasonForStopping\": \"string\",`\n                \n            *   `\"seed\": \"string\",`\n                \n            *   `\"coverage\": 0,`\n                \n            *   `\"trafficSplit\": [`\n                \n                *   `{`\n                    \n                    *   `\"variationId\": \"string\",`\n                        \n                    *   `\"weight\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"namespace\": {`\n                \n                *   `\"namespaceId\": \"string\",`\n                    \n                *   `\"range\": [ ]`\n                    \n                \n                `},`\n                \n            *   `\"targetingCondition\": \"string\",`\n                \n            *   `\"savedGroupTargeting\": [`\n                \n                *   `{`\n                    \n                    *   `\"matchType\": \"all\",`\n                        \n                    *   `\"savedGroups\": [`\n                        \n                        *   `\"string\"`\n                            \n                        \n                        `]`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"settings\": {`\n        \n        *   `\"datasourceId\": \"string\",`\n            \n        *   `\"assignmentQueryId\": \"string\",`\n            \n        *   `\"experimentId\": \"string\",`\n            \n        *   `\"segmentId\": \"string\",`\n            \n        *   `\"queryFilter\": \"string\",`\n            \n        *   `\"inProgressConversions\": \"include\",`\n            \n        *   `\"attributionModel\": \"firstExposure\",`\n            \n        *   `\"statsEngine\": \"bayesian\",`\n            \n        *   `\"goals\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"guardrails\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"activationMetric\": {`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"resultSummary\": {`\n        \n        *   `\"status\": \"string\",`\n            \n        *   `\"winner\": \"string\",`\n            \n        *   `\"conclusions\": \"string\",`\n            \n        *   `\"releasedVariationId\": \"string\",`\n            \n        *   `\"excludeFromPayload\": true`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/experiments/operation/getExperimentResults)Get results for an experiment\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### query Parameters\n\nphase\n\ndimension\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/experiments/exp\\_123abc/results \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"result\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateUpdated\": \"string\",`\n        \n    *   `\"experimentId\": \"string\",`\n        \n    *   `\"phase\": \"string\",`\n        \n    *   `\"dateStart\": \"string\",`\n        \n    *   `\"dateEnd\": \"string\",`\n        \n    *   `\"dimension\": {`\n        \n        *   `\"type\": \"string\",`\n            \n        *   `\"id\": \"string\"`\n            \n        \n        `},`\n        \n    *   `\"settings\": {`\n        \n        *   `\"datasourceId\": \"string\",`\n            \n        *   `\"assignmentQueryId\": \"string\",`\n            \n        *   `\"experimentId\": \"string\",`\n            \n        *   `\"segmentId\": \"string\",`\n            \n        *   `\"queryFilter\": \"string\",`\n            \n        *   `\"inProgressConversions\": \"include\",`\n            \n        *   `\"attributionModel\": \"firstExposure\",`\n            \n        *   `\"statsEngine\": \"bayesian\",`\n            \n        *   `\"goals\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"guardrails\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"activationMetric\": {`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    \n    *   `\"results\": [`\n        \n        *   `{`\n            \n            *   `\"dimension\": \"string\",`\n                \n            *   `\"totalUsers\": 0,`\n                \n            \n            *   `\"metrics\": [`\n                \n                *   `{`\n                    \n                    *   `\"metricId\": \"string\",`\n                        \n                    *   `\"variations\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"variationId\": \"string\",`\n                                \n                            *   `\"users\": 0,`\n                                \n                            *   `\"analyses\": [`\n                                \n                                *   `{`\n                                    \n                                    *   `\"engine\": null,`\n                                        \n                                    *   `\"numerator\": null,`\n                                        \n                                    *   `\"denominator\": null,`\n                                        \n                                    *   `\"mean\": null,`\n                                        \n                                    *   `\"stddev\": null,`\n                                        \n                                    *   `\"percentChange\": null,`\n                                        \n                                    *   `\"ciLow\": null,`\n                                        \n                                    *   `\"ciHigh\": null,`\n                                        \n                                    *   `\"pValue\": null,`\n                                        \n                                    *   `\"risk\": null,`\n                                        \n                                    *   `\"chanceToBeatControl\": null`\n                                        \n                                    \n                                    `}`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `]`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/dimensions)Dimensions\n\nDimensions used during experiment analysis\n\n## [](#tag/dimensions/operation/listDimensions)Get all dimensions\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\ndatasourceId\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/dimensions \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"dimensions\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"dateCreated\": \"string\",`\n            \n        *   `\"dateUpdated\": \"string\",`\n            \n        *   `\"owner\": \"string\",`\n            \n        *   `\"datasourceId\": \"string\",`\n            \n        *   `\"identifierType\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"query\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/dimensions/operation/getDimension)Get a single dimension\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/dimensions/dim\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"dimension\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"string\",`\n        \n    *   `\"dateUpdated\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"datasourceId\": \"string\",`\n        \n    *   `\"identifierType\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"query\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/segments)Segments\n\nSegments used during experiment analysis\n\n## [](#tag/segments/operation/listSegments)Get all segments\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\ndatasourceId\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/segments \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"segments\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"owner\": \"string\",`\n            \n        *   `\"datasourceId\": \"string\",`\n            \n        *   `\"identifierType\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"query\": \"string\",`\n            \n        *   `\"dateCreated\": \"string\",`\n            \n        *   `\"dateUpdated\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/segments/operation/getSegment)Get a single segment\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/segments/seg\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"segment\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"datasourceId\": \"string\",`\n        \n    *   `\"identifierType\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"query\": \"string\",`\n        \n    *   `\"dateCreated\": \"string\",`\n        \n    *   `\"dateUpdated\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/sdk-connections)SDK Connections\n\nClient keys and settings for connecting SDKs to a GrowthBook instance\n\n## [](#tag/sdk-connections/operation/listSdkConnections)Get all sdk connections\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\nprojectId\n\nwithProxy\n\nmultiOrg\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/sdk\\-connections \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"connections\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"organization\": \"string\",`\n            \n        \n        *   `\"sdkVersion\": \"string\",`\n            \n        *   `\"environment\": \"string\",`\n            \n        *   `\"project\": \"string\",`\n            \n        \n        *   `\"encryptPayload\": true,`\n            \n        *   `\"encryptionKey\": \"string\",`\n            \n        *   `\"includeVisualExperiments\": true,`\n            \n        *   `\"includeDraftExperiments\": true,`\n            \n        *   `\"includeExperimentNames\": true,`\n            \n        *   `\"includeRedirectExperiments\": true,`\n            \n        *   `\"key\": \"string\",`\n            \n        *   `\"proxyEnabled\": true,`\n            \n        *   `\"proxyHost\": \"string\",`\n            \n        *   `\"proxySigningKey\": \"string\",`\n            \n        *   `\"sseEnabled\": true,`\n            \n        *   `\"hashSecureAttributes\": true,`\n            \n        *   `\"remoteEvalEnabled\": true`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/sdk-connections/operation/postSdkConnection)Create a single sdk connection\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nname\n\nrequired\n\nstring\n\nlanguage\n\nrequired\n\nstring\n\nsdkVersion\n\nstring\n\nenvironment\n\nrequired\n\nstring\n\nprojects\n\nArray of strings\n\nencryptPayload\n\nboolean\n\nincludeVisualExperiments\n\nboolean\n\nincludeDraftExperiments\n\nboolean\n\nincludeExperimentNames\n\nboolean\n\nincludeRedirectExperiments\n\nboolean\n\nproxyEnabled\n\nboolean\n\nproxyHost\n\nstring\n\nhashSecureAttributes\n\nboolean\n\nremoteEvalEnabled\n\nboolean\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"language\": \"string\",`\n    \n*   `\"sdkVersion\": \"string\",`\n    \n*   `\"environment\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"encryptPayload\": true,`\n    \n*   `\"includeVisualExperiments\": true,`\n    \n*   `\"includeDraftExperiments\": true,`\n    \n*   `\"includeExperimentNames\": true,`\n    \n*   `\"includeRedirectExperiments\": true,`\n    \n*   `\"proxyEnabled\": true,`\n    \n*   `\"proxyHost\": \"string\",`\n    \n*   `\"hashSecureAttributes\": true,`\n    \n*   `\"remoteEvalEnabled\": true`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"sdkConnection\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"organization\": \"string\",`\n        \n    \n    *   `\"sdkVersion\": \"string\",`\n        \n    *   `\"environment\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    \n    *   `\"encryptPayload\": true,`\n        \n    *   `\"encryptionKey\": \"string\",`\n        \n    *   `\"includeVisualExperiments\": true,`\n        \n    *   `\"includeDraftExperiments\": true,`\n        \n    *   `\"includeExperimentNames\": true,`\n        \n    *   `\"includeRedirectExperiments\": true,`\n        \n    *   `\"key\": \"string\",`\n        \n    *   `\"proxyEnabled\": true,`\n        \n    *   `\"proxyHost\": \"string\",`\n        \n    *   `\"proxySigningKey\": \"string\",`\n        \n    *   `\"sseEnabled\": true,`\n        \n    *   `\"hashSecureAttributes\": true,`\n        \n    *   `\"remoteEvalEnabled\": true`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/sdk-connections/operation/getSdkConnection)Get a single sdk connection\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/sdk\\-connections/sdk\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"sdkConnection\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"organization\": \"string\",`\n        \n    \n    *   `\"sdkVersion\": \"string\",`\n        \n    *   `\"environment\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    \n    *   `\"encryptPayload\": true,`\n        \n    *   `\"encryptionKey\": \"string\",`\n        \n    *   `\"includeVisualExperiments\": true,`\n        \n    *   `\"includeDraftExperiments\": true,`\n        \n    *   `\"includeExperimentNames\": true,`\n        \n    *   `\"includeRedirectExperiments\": true,`\n        \n    *   `\"key\": \"string\",`\n        \n    *   `\"proxyEnabled\": true,`\n        \n    *   `\"proxyHost\": \"string\",`\n        \n    *   `\"proxySigningKey\": \"string\",`\n        \n    *   `\"sseEnabled\": true,`\n        \n    *   `\"hashSecureAttributes\": true,`\n        \n    *   `\"remoteEvalEnabled\": true`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/sdk-connections/operation/putSdkConnection)Update a single sdk connection\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nname\n\nstring\n\nlanguage\n\nstring\n\nsdkVersion\n\nstring\n\nenvironment\n\nstring\n\nprojects\n\nArray of strings\n\nencryptPayload\n\nboolean\n\nincludeVisualExperiments\n\nboolean\n\nincludeDraftExperiments\n\nboolean\n\nincludeExperimentNames\n\nboolean\n\nincludeRedirectExperiments\n\nboolean\n\nproxyEnabled\n\nboolean\n\nproxyHost\n\nstring\n\nhashSecureAttributes\n\nboolean\n\nremoteEvalEnabled\n\nboolean\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"language\": \"string\",`\n    \n*   `\"sdkVersion\": \"string\",`\n    \n*   `\"environment\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"encryptPayload\": true,`\n    \n*   `\"includeVisualExperiments\": true,`\n    \n*   `\"includeDraftExperiments\": true,`\n    \n*   `\"includeExperimentNames\": true,`\n    \n*   `\"includeRedirectExperiments\": true,`\n    \n*   `\"proxyEnabled\": true,`\n    \n*   `\"proxyHost\": \"string\",`\n    \n*   `\"hashSecureAttributes\": true,`\n    \n*   `\"remoteEvalEnabled\": true`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"sdkConnection\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"organization\": \"string\",`\n        \n    \n    *   `\"sdkVersion\": \"string\",`\n        \n    *   `\"environment\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    \n    *   `\"encryptPayload\": true,`\n        \n    *   `\"encryptionKey\": \"string\",`\n        \n    *   `\"includeVisualExperiments\": true,`\n        \n    *   `\"includeDraftExperiments\": true,`\n        \n    *   `\"includeExperimentNames\": true,`\n        \n    *   `\"includeRedirectExperiments\": true,`\n        \n    *   `\"key\": \"string\",`\n        \n    *   `\"proxyEnabled\": true,`\n        \n    *   `\"proxyHost\": \"string\",`\n        \n    *   `\"proxySigningKey\": \"string\",`\n        \n    *   `\"sseEnabled\": true,`\n        \n    *   `\"hashSecureAttributes\": true,`\n        \n    *   `\"remoteEvalEnabled\": true`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/visual-changesets)Visual Changesets\n\nGroups of visual changes made by the visual editor to a single page\n\n## [](#tag/visual-changesets/operation/listVisualChangesets)Get all visual changesets\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe experiment id the visual changesets belong to\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/experiments/exp\\_123abc/visual\\-changesets \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"visualChangesets\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"urlPatterns\": [`\n            \n            *   `{`\n                \n                *   `\"include\": true,`\n                    \n                *   `\"type\": \"simple\",`\n                    \n                *   `\"pattern\": null`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"editorUrl\": \"string\",`\n            \n        *   `\"experiment\": \"string\",`\n            \n        *   `\"visualChanges\": [`\n            \n            *   `{`\n                \n                *   `\"description\": \"string\",`\n                    \n                *   `\"css\": \"string\",`\n                    \n                *   `\"js\": \"string\",`\n                    \n                *   `\"variation\": \"string\",`\n                    \n                *   `\"domMutations\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"selector\": \"string\",`\n                            \n                        *   `\"action\": \"append\",`\n                            \n                        *   `\"attribute\": \"string\",`\n                            \n                        *   `\"value\": \"string\",`\n                            \n                        *   `\"parentSelector\": \"string\",`\n                            \n                        *   `\"insertBeforeSelector\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/visual-changesets/operation/getVisualChangeset)Get a single visual changeset\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### query Parameters\n\nincludeExperiment\n\ninteger\n\nInclude the associated experiment in payload\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/visual\\-changesets/ds\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"visualChangeset\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"urlPatterns\": [`\n        \n        *   `{`\n            \n            *   `\"include\": true,`\n                \n            *   `\"type\": \"simple\",`\n                \n            *   `\"pattern\": null`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"editorUrl\": \"string\",`\n        \n    *   `\"experiment\": \"string\",`\n        \n    *   `\"visualChanges\": [`\n        \n        *   `{`\n            \n            *   `\"description\": \"string\",`\n                \n            *   `\"css\": \"string\",`\n                \n            *   `\"js\": \"string\",`\n                \n            *   `\"variation\": \"string\",`\n                \n            *   `\"domMutations\": [`\n                \n                *   `{`\n                    \n                    *   `\"selector\": \"string\",`\n                        \n                    *   `\"action\": \"append\",`\n                        \n                    *   `\"attribute\": \"string\",`\n                        \n                    *   `\"value\": \"string\",`\n                        \n                    *   `\"parentSelector\": \"string\",`\n                        \n                    *   `\"insertBeforeSelector\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `},`\n    \n*   `\"experiment\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    *   `\"hypothesis\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    \n    *   `\"owner\": \"string\",`\n        \n    *   `\"archived\": true,`\n        \n    *   `\"status\": \"string\",`\n        \n    *   `\"autoRefresh\": true,`\n        \n    *   `\"hashAttribute\": \"string\",`\n        \n    *   `\"fallbackAttribute\": \"string\",`\n        \n    *   `\"hashVersion\": 1,`\n        \n    *   `\"disableStickyBucketing\": null,`\n        \n    *   `\"bucketVersion\": 0,`\n        \n    *   `\"minBucketVersion\": 0,`\n        \n    *   `\"variations\": [`\n        \n        *   `{`\n            \n            *   `\"variationId\": \"string\",`\n                \n            *   `\"key\": \"string\",`\n                \n            *   `\"name\": \"string\",`\n                \n            *   `\"description\": \"string\",`\n                \n            *   `\"screenshots\": [`\n                \n                *   `\"string\"`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"phases\": [`\n        \n        *   `{`\n            \n            *   `\"name\": \"string\",`\n                \n            *   `\"dateStarted\": \"string\",`\n                \n            *   `\"dateEnded\": \"string\",`\n                \n            *   `\"reasonForStopping\": \"string\",`\n                \n            *   `\"seed\": \"string\",`\n                \n            *   `\"coverage\": 0,`\n                \n            *   `\"trafficSplit\": [`\n                \n                *   `{`\n                    \n                    *   `\"variationId\": \"string\",`\n                        \n                    *   `\"weight\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"namespace\": {`\n                \n                *   `\"namespaceId\": \"string\",`\n                    \n                *   `\"range\": [ ]`\n                    \n                \n                `},`\n                \n            *   `\"targetingCondition\": \"string\",`\n                \n            *   `\"savedGroupTargeting\": [`\n                \n                *   `{`\n                    \n                    *   `\"matchType\": \"all\",`\n                        \n                    *   `\"savedGroups\": [`\n                        \n                        *   `\"string\"`\n                            \n                        \n                        `]`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"settings\": {`\n        \n        *   `\"datasourceId\": \"string\",`\n            \n        *   `\"assignmentQueryId\": \"string\",`\n            \n        *   `\"experimentId\": \"string\",`\n            \n        *   `\"segmentId\": \"string\",`\n            \n        *   `\"queryFilter\": \"string\",`\n            \n        *   `\"inProgressConversions\": \"include\",`\n            \n        *   `\"attributionModel\": \"firstExposure\",`\n            \n        *   `\"statsEngine\": \"bayesian\",`\n            \n        *   `\"goals\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"guardrails\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"activationMetric\": {`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"resultSummary\": {`\n        \n        *   `\"status\": \"string\",`\n            \n        *   `\"winner\": \"string\",`\n            \n        *   `\"conclusions\": \"string\",`\n            \n        *   `\"releasedVariationId\": \"string\",`\n            \n        *   `\"excludeFromPayload\": true`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/visual-changesets/operation/putVisualChangeset)Update a visual changeset\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-XPUT https://api.growthbook.io/api/v1/visual\\-changesets/vc\\_123abc\n  \\-d '{\"editorUrl\": \"https://docs.growthbook.io\", \"urlPatterns\":\"\\[{ ... }\\]\"}' \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"nModified\": 0,`\n    \n*   `\"visualChangeset\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"urlPatterns\": [`\n        \n        *   `{`\n            \n            *   `\"include\": true,`\n                \n            *   `\"type\": \"simple\",`\n                \n            *   `\"pattern\": null`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"editorUrl\": \"string\",`\n        \n    *   `\"experiment\": \"string\",`\n        \n    *   `\"visualChanges\": [`\n        \n        *   `{`\n            \n            *   `\"description\": \"string\",`\n                \n            *   `\"css\": \"string\",`\n                \n            *   `\"js\": \"string\",`\n                \n            *   `\"variation\": \"string\",`\n                \n            *   `\"domMutations\": [`\n                \n                *   `{`\n                    \n                    *   `\"selector\": \"string\",`\n                        \n                    *   `\"action\": \"append\",`\n                        \n                    *   `\"attribute\": \"string\",`\n                        \n                    *   `\"value\": \"string\",`\n                        \n                    *   `\"parentSelector\": \"string\",`\n                        \n                    *   `\"insertBeforeSelector\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/visual-changesets/operation/postVisualChange)Create a visual change for a visual changeset\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-XPOST https://api.growthbook.io/api/v1/visual\\-changesets/vc\\_123abc/visual\\-change \\\\\n  \\-d '{\"variation\": \"v\\_123abc\", \"domMutations\":\"\\[\\]\"}' \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n## [](#tag/visual-changesets/operation/putVisualChange)Update a visual change for a visual changeset\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\nvisualChangeId\n\nrequired\n\nstring\n\nSpecify a specific visual change\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-XPUT https://api.growthbook.io/api/v1/visual\\-changesets/vc\\_123abc/visual\\-change/vch\\_abc123 \\\\\n  \\-d '{\"variation\": \"v\\_123abc\", \"domMutations\":\"\\[\\]\"}' \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n## [](#tag/saved-groups)Saved Groups\n\nDefined sets of attribute values which can be used with feature rules for targeting features at particular users.\n\n## [](#tag/saved-groups/operation/listSavedGroups)Get all saved group\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/saved\\-groups \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"savedGroups\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"type\": \"condition\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"owner\": \"string\",`\n            \n        *   `\"condition\": \"string\",`\n            \n        *   `\"attributeKey\": \"string\",`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/saved-groups/operation/postSavedGroup)Create a single saved group\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nname\n\nrequired\n\nstring\n\nThe display name of the Saved Group\n\ntype\n\nstring\n\nEnum: \"condition\" \"list\"\n\nThe type of Saved Group (inferred from other arguments if missing)\n\ncondition\n\nstring\n\nWhen type = 'condition', this is the JSON-encoded condition for the group\n\nattributeKey\n\nstring\n\nWhen type = 'list', this is the attribute key the group is based on\n\nvalues\n\nArray of strings\n\nWhen type = 'list', this is the list of values for the attribute key\n\nowner\n\nstring\n\nThe person or team that owns this Saved Group. If no owner, you can pass an empty string.\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"type\": \"condition\",`\n    \n*   `\"condition\": \"string\",`\n    \n*   `\"attributeKey\": \"string\",`\n    \n*   `\"values\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"owner\": \"string\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"savedGroup\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"type\": \"condition\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"condition\": \"string\",`\n        \n    *   `\"attributeKey\": \"string\",`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/saved-groups/operation/getSavedGroup)Get a single saved group\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/saved\\-groups/ds\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"savedGroup\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"type\": \"condition\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"condition\": \"string\",`\n        \n    *   `\"attributeKey\": \"string\",`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/saved-groups/operation/updateSavedGroup)Partially update a single saved group\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nname\n\nstring\n\nThe display name of the Saved Group\n\ncondition\n\nstring\n\nWhen type = 'condition', this is the JSON-encoded condition for the group\n\nvalues\n\nArray of strings\n\nWhen type = 'list', this is the list of values for the attribute key\n\nowner\n\nstring\n\nThe person or team that owns this Saved Group. If no owner, you can pass an empty string.\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"condition\": \"string\",`\n    \n*   `\"values\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"owner\": \"string\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"savedGroup\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"type\": \"condition\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"condition\": \"string\",`\n        \n    *   `\"attributeKey\": \"string\",`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/saved-groups/operation/deleteSavedGroup)Deletes a single saved group\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-X DELETE https://api.growthbook.io/api/v1/saved\\-groups/grp\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"deletedId\": \"string\"`\n    \n\n`}`\n\n## [](#tag/organizations)Organizations\n\nOrganizations are used for multi-org deployments where different teams can run their own isolated feature flags and experiments. These endpoints are only via a super-admin's Personal Access Token.\n\n## [](#tag/organizations/operation/listOrganizations)Get all organizations (only for super admins on multi-org Enterprise Plan only)\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nsearch\n\nstring\n\nSearch string to search organization names, owner emails, and external ids by\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/organizations \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"organizations\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"externalId\": \"string\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"ownerEmail\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/organizations/operation/postOrganization)Create a single organization (only for super admins on multi-org Enterprise Plan only)\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nname\n\nrequired\n\nstring\n\nThe name of the organization\n\nexternalId\n\nstring\n\nAn optional identifier that you use within your company for the organization\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"externalId\": \"string\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"organization\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"externalId\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"ownerEmail\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/organizations/operation/putOrganization)Edit a single organization (only for super admins on multi-org Enterprise Plan only)\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nname\n\nstring\n\nThe name of the organization\n\nexternalId\n\nstring\n\nAn optional identifier that you use within your company for the organization\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"externalId\": \"string\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"organization\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"externalId\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"ownerEmail\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-tables)Fact Tables\n\nFact Tables describe the shape of your data warehouse tables\n\n## [](#tag/fact-tables/operation/listFactTables)Get all fact tables\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\ndatasourceId\n\nprojectId\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/fact\\-tables \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTables\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"owner\": \"string\",`\n            \n        \n        *   `\"datasource\": \"string\",`\n            \n        *   `\"userIdTypes\": [`\n            \n            *   `\"string\"`\n                \n            \n            `],`\n            \n        *   `\"sql\": \"string\",`\n            \n        *   `\"managedBy\": \"\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/postFactTable)Create a single fact table\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nname\n\nrequired\n\nstring\n\ndescription\n\nstring\n\nDescription of the fact table\n\nowner\n\nstring\n\nThe person who is responsible for this fact table\n\nprojects\n\nArray of strings\n\nList of associated project ids\n\ntags\n\nArray of strings\n\nList of associated tags\n\ndatasource\n\nrequired\n\nstring\n\nThe datasource id\n\nuserIdTypes\n\nrequired\n\nArray of strings\n\nList of identifier columns in this table. For example, \"id\" or \"anonymous\\_id\"\n\nsql\n\nrequired\n\nstring\n\nThe SQL query for this fact table\n\nmanagedBy\n\nstring\n\nEnum: \"\" \"api\"\n\nSet this to \"api\" to disable editing in the GrowthBook UI\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"datasource\": \"string\",`\n    \n*   `\"userIdTypes\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"sql\": \"string\",`\n    \n*   `\"managedBy\": \"\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTable\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    \n    *   `\"datasource\": \"string\",`\n        \n    *   `\"userIdTypes\": [`\n        \n        *   `\"string\"`\n            \n        \n        `],`\n        \n    *   `\"sql\": \"string\",`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/getFactTable)Get a single fact table\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/fact\\-tables/ftb\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTable\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    \n    *   `\"datasource\": \"string\",`\n        \n    *   `\"userIdTypes\": [`\n        \n        *   `\"string\"`\n            \n        \n        `],`\n        \n    *   `\"sql\": \"string\",`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/updateFactTable)Update a single fact table\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nname\n\nstring\n\ndescription\n\nstring\n\nDescription of the fact table\n\nowner\n\nstring\n\nThe person who is responsible for this fact table\n\nprojects\n\nArray of strings\n\nList of associated project ids\n\ntags\n\nArray of strings\n\nList of associated tags\n\nuserIdTypes\n\nArray of strings\n\nList of identifier columns in this table. For example, \"id\" or \"anonymous\\_id\"\n\nsql\n\nstring\n\nThe SQL query for this fact table\n\nmanagedBy\n\nstring\n\nEnum: \"\" \"api\"\n\nSet this to \"api\" to disable editing in the GrowthBook UI\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"userIdTypes\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"sql\": \"string\",`\n    \n*   `\"managedBy\": \"\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTable\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    \n    *   `\"datasource\": \"string\",`\n        \n    *   `\"userIdTypes\": [`\n        \n        *   `\"string\"`\n            \n        \n        `],`\n        \n    *   `\"sql\": \"string\",`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/deleteFactTable)Deletes a single fact table\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-X DELETE https://api.growthbook.io/api/v1/fact\\-tables/ftb\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"deletedId\": \"ftb_123abc\"`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/listFactTableFilters)Get all filters for a fact table\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nfactTableId\n\nrequired\n\nstring\n\nSpecify a specific fact table\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/fact\\-tables/ftb\\_123abc/filters \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTableFilters\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"value\": \"string\",`\n            \n        *   `\"managedBy\": \"\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/postFactTableFilter)Create a single fact table filter\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nfactTableId\n\nrequired\n\nstring\n\nSpecify a specific fact table\n\n##### Request Body schema: application/json\n\nname\n\nrequired\n\ndescription\n\nstring\n\nDescription of the fact table filter\n\nvalue\n\nrequired\n\nstring\n\nThe SQL expression for this filter.\n\nmanagedBy\n\nstring\n\nEnum: \"\" \"api\"\n\nSet this to \"api\" to disable editing in the GrowthBook UI. Before you do this, the Fact Table itself must also be marked as \"api\"\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"value\": \"country = 'US'\",`\n    \n*   `\"managedBy\": \"\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTableFilter\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"value\": \"string\",`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/getFactTableFilter)Get a single fact filter\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nfactTableId\n\nrequired\n\nstring\n\nSpecify a specific fact table\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/fact\\-tables/ftb\\_123abc/filters/flt\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTableFilter\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"value\": \"string\",`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/updateFactTableFilter)Update a single fact table filter\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nfactTableId\n\nrequired\n\nstring\n\nSpecify a specific fact table\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nname\n\ndescription\n\nstring\n\nDescription of the fact table filter\n\nvalue\n\nstring\n\nThe SQL expression for this filter.\n\nmanagedBy\n\nstring\n\nEnum: \"\" \"api\"\n\nSet this to \"api\" to disable editing in the GrowthBook UI. Before you do this, the Fact Table itself must also be marked as \"api\"\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"value\": \"country = 'US'\",`\n    \n*   `\"managedBy\": \"\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTableFilter\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"value\": \"string\",`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/deleteFactTableFilter)Deletes a single fact table filter\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nfactTableId\n\nrequired\n\nstring\n\nSpecify a specific fact table\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-X DELETE https://api.growthbook.io/api/v1/fact\\-tables/ftb\\_123abc/filter/flt\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"deletedId\": \"flt_123abc\"`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/postBulkImportFacts)Bulk import fact tables, filters, and metrics\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTables\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"data\": {`\n            \n            *   `\"name\": \"string\",`\n                \n            *   `\"description\": \"string\",`\n                \n            *   `\"owner\": \"string\",`\n                \n            \n            *   `\"datasource\": \"string\",`\n                \n            *   `\"userIdTypes\": [`\n                \n                *   `\"string\"`\n                    \n                \n                `],`\n                \n            *   `\"sql\": \"string\",`\n                \n            *   `\"managedBy\": \"\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"factTableFilters\": [`\n    \n    *   `{`\n        \n        *   `\"factTableId\": \"string\",`\n            \n        *   `\"id\": \"string\",`\n            \n        *   `\"data\": {`\n            \n            *   `\"name\": \"string\",`\n                \n            *   `\"description\": \"string\",`\n                \n            *   `\"value\": \"country = 'US'\",`\n                \n            *   `\"managedBy\": \"\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"factMetrics\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"data\": {`\n            \n            *   `\"name\": \"string\",`\n                \n            *   `\"description\": \"string\",`\n                \n            *   `\"owner\": \"string\",`\n                \n            \n            *   `\"metricType\": \"proportion\",`\n                \n            *   `\"numerator\": {`\n                \n                *   `\"factTableId\": \"string\",`\n                    \n                *   `\"column\": \"string\",`\n                    \n                \n                `},`\n                \n            *   `\"denominator\": {`\n                \n                *   `\"factTableId\": \"string\",`\n                    \n                *   `\"column\": \"string\",`\n                    \n                \n                `},`\n                \n            *   `\"inverse\": true,`\n                \n            *   `\"quantileSettings\": {`\n                \n                *   `\"type\": \"event\",`\n                    \n                *   `\"ignoreZeros\": true,`\n                    \n                *   `\"quantile\": 0.001`\n                    \n                \n                `},`\n                \n            *   `\"cappingSettings\": {`\n                \n                *   `\"type\": \"none\",`\n                    \n                *   `\"value\": 0,`\n                    \n                *   `\"ignoreZeros\": true`\n                    \n                \n                `},`\n                \n            *   `\"windowSettings\": {`\n                \n                *   `\"type\": \"none\",`\n                    \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowValue\": 0,`\n                    \n                *   `\"windowUnit\": \"hours\"`\n                    \n                \n                `},`\n                \n            *   `\"priorSettings\": {`\n                \n                *   `\"override\": true,`\n                    \n                *   `\"proper\": true,`\n                    \n                *   `\"mean\": 0,`\n                    \n                *   `\"stddev\": 0`\n                    \n                \n                `},`\n                \n            *   `\"regressionAdjustmentSettings\": {`\n                \n                *   `\"override\": true,`\n                    \n                *   `\"enabled\": true,`\n                    \n                *   `\"days\": 0`\n                    \n                \n                `},`\n                \n            *   `\"riskThresholdSuccess\": 0,`\n                \n            *   `\"riskThresholdDanger\": 0,`\n                \n            *   `\"minPercentChange\": 0,`\n                \n            *   `\"maxPercentChange\": 0,`\n                \n            *   `\"minSampleSize\": 0,`\n                \n            *   `\"managedBy\": \"\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"success\": true,`\n    \n*   `\"factTablesAdded\": 0,`\n    \n*   `\"factTablesUpdated\": 0,`\n    \n*   `\"factTableFiltersAdded\": 0,`\n    \n*   `\"factTableFiltersUpdated\": 0,`\n    \n*   `\"factMetricsAdded\": 0,`\n    \n*   `\"factMetricsUpdated\": 0`\n    \n\n`}`\n\n## [](#tag/fact-metrics)Fact Metrics\n\nFact Metrics are metrics built on top of Fact Table definitions\n\n## [](#tag/fact-metrics/operation/listFactMetrics)Get all fact metrics\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\ndatasourceId\n\nprojectId\n\nfactTableId\n\nstring\n\nFilter by Fact Table Id (for ratio metrics, we only look at the numerator)\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/fact\\-metrics \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factMetrics\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"owner\": \"string\",`\n            \n        \n        *   `\"datasource\": \"string\",`\n            \n        *   `\"metricType\": \"proportion\",`\n            \n        *   `\"numerator\": {`\n            \n            *   `\"factTableId\": \"string\",`\n                \n            *   `\"column\": \"string\",`\n                \n            \n            `},`\n            \n        *   `\"denominator\": {`\n            \n            *   `\"factTableId\": \"string\",`\n                \n            *   `\"column\": \"string\",`\n                \n            \n            `},`\n            \n        *   `\"inverse\": true,`\n            \n        *   `\"quantileSettings\": {`\n            \n            *   `\"type\": \"event\",`\n                \n            *   `\"ignoreZeros\": true,`\n                \n            *   `\"quantile\": 0.001`\n                \n            \n            `},`\n            \n        *   `\"cappingSettings\": {`\n            \n            *   `\"type\": \"none\",`\n                \n            *   `\"value\": 0,`\n                \n            *   `\"ignoreZeros\": true`\n                \n            \n            `},`\n            \n        *   `\"windowSettings\": {`\n            \n            *   `\"type\": \"none\",`\n                \n            *   `\"delayHours\": 0,`\n                \n            *   `\"windowValue\": 0,`\n                \n            *   `\"windowUnit\": \"hours\"`\n                \n            \n            `},`\n            \n        *   `\"regressionAdjustmentSettings\": {`\n            \n            *   `\"override\": true,`\n                \n            *   `\"enabled\": true,`\n                \n            *   `\"days\": 0`\n                \n            \n            `},`\n            \n        *   `\"riskThresholdSuccess\": 0,`\n            \n        *   `\"riskThresholdDanger\": 0,`\n            \n        *   `\"minPercentChange\": 0,`\n            \n        *   `\"maxPercentChange\": 0,`\n            \n        *   `\"minSampleSize\": 0,`\n            \n        *   `\"managedBy\": \"\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/fact-metrics/operation/postFactMetric)Create a single fact metric\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nname\n\nrequired\n\nstring\n\ndescription\n\nstring\n\nowner\n\nstring\n\nprojects\n\nArray of strings\n\ntags\n\nArray of strings\n\nmetricType\n\nrequired\n\nstring\n\nEnum: \"proportion\" \"mean\" \"quantile\" \"ratio\"\n\nrequired\n\nobject\n\nobject\n\nOnly when metricType is 'ratio'\n\ninverse\n\nboolean\n\nSet to true for things like Bounce Rate, where you want the metric to decrease\n\nobject\n\nControls the settings for quantile metrics (mandatory if metricType is \"quantile\")\n\nobject\n\nControls how outliers are handled\n\nobject\n\nControls the conversion window for the metric\n\nobject\n\nControls the bayesian prior for the metric. If omitted, organization defaults will be used.\n\nobject\n\nControls the regression adjustment (CUPED) settings for the metric\n\nriskThresholdSuccess\n\nnumber \\>= 0\n\nThreshold for Risk to be considered low enough, as a proportion (e.g. put 0.0025 for 0.25%).  \nMust be a non-negative number and must not be higher than `riskThresholdDanger`.\n\nriskThresholdDanger\n\nnumber \\>= 0\n\nThreshold for Risk to be considered too high, as a proportion (e.g. put 0.0125 for 1.25%).  \nMust be a non-negative number.\n\nminPercentChange\n\nnumber \\>= 0\n\nMinimum percent change to consider uplift significant, as a proportion (e.g. put 0.005 for 0.5%)\n\nmaxPercentChange\n\nnumber \\>= 0\n\nMaximum percent change to consider uplift significant, as a proportion (e.g. put 0.5 for 50%)\n\nminSampleSize\n\nnumber \\>= 0\n\nmanagedBy\n\nstring\n\nEnum: \"\" \"api\"\n\nSet this to \"api\" to disable editing in the GrowthBook UI\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"metricType\": \"proportion\",`\n    \n*   `\"numerator\": {`\n    \n    *   `\"factTableId\": \"string\",`\n        \n    *   `\"column\": \"string\",`\n        \n    \n    `},`\n    \n*   `\"denominator\": {`\n    \n    *   `\"factTableId\": \"string\",`\n        \n    *   `\"column\": \"string\",`\n        \n    \n    `},`\n    \n*   `\"inverse\": true,`\n    \n*   `\"quantileSettings\": {`\n    \n    *   `\"type\": \"event\",`\n        \n    *   `\"ignoreZeros\": true,`\n        \n    *   `\"quantile\": 0.001`\n        \n    \n    `},`\n    \n*   `\"cappingSettings\": {`\n    \n    *   `\"type\": \"none\",`\n        \n    *   `\"value\": 0,`\n        \n    *   `\"ignoreZeros\": true`\n        \n    \n    `},`\n    \n*   `\"windowSettings\": {`\n    \n    *   `\"type\": \"none\",`\n        \n    *   `\"delayHours\": 0,`\n        \n    *   `\"windowValue\": 0,`\n        \n    *   `\"windowUnit\": \"hours\"`\n        \n    \n    `},`\n    \n*   `\"priorSettings\": {`\n    \n    *   `\"override\": true,`\n        \n    *   `\"proper\": true,`\n        \n    *   `\"mean\": 0,`\n        \n    *   `\"stddev\": 0`\n        \n    \n    `},`\n    \n*   `\"regressionAdjustmentSettings\": {`\n    \n    *   `\"override\": true,`\n        \n    *   `\"enabled\": true,`\n        \n    *   `\"days\": 0`\n        \n    \n    `},`\n    \n*   `\"riskThresholdSuccess\": 0,`\n    \n*   `\"riskThresholdDanger\": 0,`\n    \n*   `\"minPercentChange\": 0,`\n    \n*   `\"maxPercentChange\": 0,`\n    \n*   `\"minSampleSize\": 0,`\n    \n*   `\"managedBy\": \"\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factMetric\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    \n    *   `\"datasource\": \"string\",`\n        \n    *   `\"metricType\": \"proportion\",`\n        \n    *   `\"numerator\": {`\n        \n        *   `\"factTableId\": \"string\",`\n            \n        *   `\"column\": \"string\",`\n            \n        \n        `},`\n        \n    *   `\"denominator\": {`\n        \n        *   `\"factTableId\": \"string\",`\n            \n        *   `\"column\": \"string\",`\n            \n        \n        `},`\n        \n    *   `\"inverse\": true,`\n        \n    *   `\"quantileSettings\": {`\n        \n        *   `\"type\": \"event\",`\n            \n        *   `\"ignoreZeros\": true,`\n            \n        *   `\"quantile\": 0.001`\n            \n        \n        `},`\n        \n    *   `\"cappingSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"value\": 0,`\n            \n        *   `\"ignoreZeros\": true`\n            \n        \n        `},`\n        \n    *   `\"windowSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"delayHours\": 0,`\n            \n        *   `\"windowValue\": 0,`\n            \n        *   `\"windowUnit\": \"hours\"`\n            \n        \n        `},`\n        \n    *   `\"regressionAdjustmentSettings\": {`\n        \n        *   `\"override\": true,`\n            \n        *   `\"enabled\": true,`\n            \n        *   `\"days\": 0`\n            \n        \n        `},`\n        \n    *   `\"riskThresholdSuccess\": 0,`\n        \n    *   `\"riskThresholdDanger\": 0,`\n        \n    *   `\"minPercentChange\": 0,`\n        \n    *   `\"maxPercentChange\": 0,`\n        \n    *   `\"minSampleSize\": 0,`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-metrics/operation/getFactMetric)Get a single fact metric\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/fact\\-metrics/fact\\_\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factMetric\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    \n    *   `\"datasource\": \"string\",`\n        \n    *   `\"metricType\": \"proportion\",`\n        \n    *   `\"numerator\": {`\n        \n        *   `\"factTableId\": \"string\",`\n            \n        *   `\"column\": \"string\",`\n            \n        \n        `},`\n        \n    *   `\"denominator\": {`\n        \n        *   `\"factTableId\": \"string\",`\n            \n        *   `\"column\": \"string\",`\n            \n        \n        `},`\n        \n    *   `\"inverse\": true,`\n        \n    *   `\"quantileSettings\": {`\n        \n        *   `\"type\": \"event\",`\n            \n        *   `\"ignoreZeros\": true,`\n            \n        *   `\"quantile\": 0.001`\n            \n        \n        `},`\n        \n    *   `\"cappingSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"value\": 0,`\n            \n        *   `\"ignoreZeros\": true`\n            \n        \n        `},`\n        \n    *   `\"windowSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"delayHours\": 0,`\n            \n        *   `\"windowValue\": 0,`\n            \n        *   `\"windowUnit\": \"hours\"`\n            \n        \n        `},`\n        \n    *   `\"regressionAdjustmentSettings\": {`\n        \n        *   `\"override\": true,`\n            \n        *   `\"enabled\": true,`\n            \n        *   `\"days\": 0`\n            \n        \n        `},`\n        \n    *   `\"riskThresholdSuccess\": 0,`\n        \n    *   `\"riskThresholdDanger\": 0,`\n        \n    *   `\"minPercentChange\": 0,`\n        \n    *   `\"maxPercentChange\": 0,`\n        \n    *   `\"minSampleSize\": 0,`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-metrics/operation/updateFactMetric)Update a single fact metric\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nname\n\nstring\n\ndescription\n\nstring\n\nowner\n\nstring\n\nprojects\n\nArray of strings\n\ntags\n\nArray of strings\n\nmetricType\n\nstring\n\nEnum: \"proportion\" \"mean\" \"quantile\" \"ratio\"\n\nobject\n\nobject\n\nOnly when metricType is 'ratio'\n\ninverse\n\nboolean\n\nSet to true for things like Bounce Rate, where you want the metric to decrease\n\nobject\n\nControls the settings for quantile metrics (mandatory if metricType is \"quantile\")\n\nobject\n\nControls how outliers are handled\n\nobject\n\nControls the conversion window for the metric\n\nobject\n\nControls the regression adjustment (CUPED) settings for the metric\n\nriskThresholdSuccess\n\nnumber \\>= 0\n\nThreshold for Risk to be considered low enough, as a proportion (e.g. put 0.0025 for 0.25%).  \nMust be a non-negative number and must not be higher than `riskThresholdDanger`.\n\nriskThresholdDanger\n\nnumber \\>= 0\n\nThreshold for Risk to be considered too high, as a proportion (e.g. put 0.0125 for 1.25%).  \nMust be a non-negative number.\n\nminPercentChange\n\nnumber \\>= 0\n\nMinimum percent change to consider uplift significant, as a proportion (e.g. put 0.005 for 0.5%)\n\nmaxPercentChange\n\nnumber \\>= 0\n\nMaximum percent change to consider uplift significant, as a proportion (e.g. put 0.5 for 50%)\n\nminSampleSize\n\nnumber \\>= 0\n\nmanagedBy\n\nstring\n\nEnum: \"\" \"api\"\n\nSet this to \"api\" to disable editing in the GrowthBook UI\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"metricType\": \"proportion\",`\n    \n*   `\"numerator\": {`\n    \n    *   `\"factTableId\": \"string\",`\n        \n    *   `\"column\": \"string\",`\n        \n    \n    `},`\n    \n*   `\"denominator\": {`\n    \n    *   `\"factTableId\": \"string\",`\n        \n    *   `\"column\": \"string\",`\n        \n    \n    `},`\n    \n*   `\"inverse\": true,`\n    \n*   `\"quantileSettings\": {`\n    \n    *   `\"type\": \"event\",`\n        \n    *   `\"ignoreZeros\": true,`\n        \n    *   `\"quantile\": 0.001`\n        \n    \n    `},`\n    \n*   `\"cappingSettings\": {`\n    \n    *   `\"type\": \"none\",`\n        \n    *   `\"value\": 0,`\n        \n    *   `\"ignoreZeros\": true`\n        \n    \n    `},`\n    \n*   `\"windowSettings\": {`\n    \n    *   `\"type\": \"none\",`\n        \n    *   `\"delayHours\": 0,`\n        \n    *   `\"windowValue\": 0,`\n        \n    *   `\"windowUnit\": \"hours\"`\n        \n    \n    `},`\n    \n*   `\"regressionAdjustmentSettings\": {`\n    \n    *   `\"override\": true,`\n        \n    *   `\"enabled\": true,`\n        \n    *   `\"days\": 0`\n        \n    \n    `},`\n    \n*   `\"riskThresholdSuccess\": 0,`\n    \n*   `\"riskThresholdDanger\": 0,`\n    \n*   `\"minPercentChange\": 0,`\n    \n*   `\"maxPercentChange\": 0,`\n    \n*   `\"minSampleSize\": 0,`\n    \n*   `\"managedBy\": \"\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factMetric\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    \n    *   `\"datasource\": \"string\",`\n        \n    *   `\"metricType\": \"proportion\",`\n        \n    *   `\"numerator\": {`\n        \n        *   `\"factTableId\": \"string\",`\n            \n        *   `\"column\": \"string\",`\n            \n        \n        `},`\n        \n    *   `\"denominator\": {`\n        \n        *   `\"factTableId\": \"string\",`\n            \n        *   `\"column\": \"string\",`\n            \n        \n        `},`\n        \n    *   `\"inverse\": true,`\n        \n    *   `\"quantileSettings\": {`\n        \n        *   `\"type\": \"event\",`\n            \n        *   `\"ignoreZeros\": true,`\n            \n        *   `\"quantile\": 0.001`\n            \n        \n        `},`\n        \n    *   `\"cappingSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"value\": 0,`\n            \n        *   `\"ignoreZeros\": true`\n            \n        \n        `},`\n        \n    *   `\"windowSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"delayHours\": 0,`\n            \n        *   `\"windowValue\": 0,`\n            \n        *   `\"windowUnit\": \"hours\"`\n            \n        \n        `},`\n        \n    *   `\"regressionAdjustmentSettings\": {`\n        \n        *   `\"override\": true,`\n            \n        *   `\"enabled\": true,`\n            \n        *   `\"days\": 0`\n            \n        \n        `},`\n        \n    *   `\"riskThresholdSuccess\": 0,`\n        \n    *   `\"riskThresholdDanger\": 0,`\n        \n    *   `\"minPercentChange\": 0,`\n        \n    *   `\"maxPercentChange\": 0,`\n        \n    *   `\"minSampleSize\": 0,`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-metrics/operation/deleteFactMetric)Deletes a single fact metric\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-X DELETE https://api.growthbook.io/api/v1/fact\\-metrics/fact\\_\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"deletedId\": \"fact__123abc\"`\n    \n\n`}`\n\n## [](#tag/code-references)Code References\n\n## [](#tag/code-references/operation/postCodeRefs)Submit list of code references\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nbranch\n\nrequired\n\nrepoName\n\nrequired\n\nrequired\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"branch\": \"string\",`\n    \n*   `\"repoName\": \"string\",`\n    \n*   `\"refs\": [`\n    \n    *   `{`\n        \n        *   `\"filePath\": \"string\",`\n            \n        *   `\"startingLineNumber\": 0,`\n            \n        *   `\"lines\": \"string\",`\n            \n        *   `\"flagKey\": \"string\",`\n            \n        *   `\"contentHash\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"featuresUpdated\": [`\n    \n    *   `\"string\"`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/DataSource_model)DataSource\n\nid\n\nrequired\n\nstring\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\ntype\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\ndescription\n\nrequired\n\nstring\n\nprojectIds\n\nrequired\n\nArray of strings\n\neventTracker\n\nrequired\n\nstring\n\nrequired\n\nArray of objects\n\nrequired\n\nArray of objects\n\nrequired\n\nArray of objects\n\nobject\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"type\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"projectIds\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"eventTracker\": \"string\",`\n    \n*   `\"identifierTypes\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"description\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"assignmentQueries\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"identifierType\": \"string\",`\n            \n        *   `\"sql\": \"string\",`\n            \n        *   `\"includesNameColumns\": true,`\n            \n        *   `\"dimensionColumns\": [`\n            \n            *   `\"string\"`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"identifierJoinQueries\": [`\n    \n    *   `{`\n        \n        *   `\"identifierTypes\": [`\n            \n            *   `\"string\"`\n                \n            \n            `],`\n            \n        *   `\"sql\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"mixpanelSettings\": {`\n    \n    *   `\"viewedExperimentEventName\": \"string\",`\n        \n    *   `\"experimentIdProperty\": \"string\",`\n        \n    *   `\"variationIdProperty\": \"string\",`\n        \n    *   `\"extraUserIdProperty\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/Dimension_model)Dimension\n\nid\n\nrequired\n\nstring\n\ndateCreated\n\nrequired\n\nstring\n\ndateUpdated\n\nrequired\n\nstring\n\nowner\n\nrequired\n\nstring\n\ndatasourceId\n\nrequired\n\nstring\n\nidentifierType\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\nquery\n\nrequired\n\nstring\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"dateCreated\": \"string\",`\n    \n*   `\"dateUpdated\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"datasourceId\": \"string\",`\n    \n*   `\"identifierType\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"query\": \"string\"`\n    \n\n`}`\n\n## [](#tag/Environment_model)Environment\n\nid\n\nrequired\n\ndescription\n\nrequired\n\ntoggleOnList\n\nrequired\n\ndefaultState\n\nrequired\n\nprojects\n\nrequired\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"toggleOnList\": true,`\n    \n*   `\"defaultState\": true,`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/Experiment_model)Experiment\n\nid\n\nrequired\n\nstring\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\nname\n\nrequired\n\nstring\n\nproject\n\nrequired\n\nstring\n\nhypothesis\n\nrequired\n\nstring\n\ndescription\n\nrequired\n\nstring\n\ntags\n\nrequired\n\nArray of strings\n\nowner\n\nrequired\n\nstring\n\narchived\n\nrequired\n\nboolean\n\nstatus\n\nrequired\n\nstring\n\nautoRefresh\n\nrequired\n\nboolean\n\nhashAttribute\n\nrequired\n\nstring\n\nfallbackAttribute\n\nstring\n\nhashVersion\n\nrequired\n\nnumber\n\nEnum: 1 2\n\ndisableStickyBucketing\n\nboolean;\n\nbucketVersion\n\nnumber\n\nminBucketVersion\n\nnumber\n\nrequired\n\nArray of objects\n\nrequired\n\nArray of objects\n\nrequired\n\nobject (ExperimentAnalysisSettings)\n\nobject\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"project\": \"string\",`\n    \n*   `\"hypothesis\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"archived\": true,`\n    \n*   `\"status\": \"string\",`\n    \n*   `\"autoRefresh\": true,`\n    \n*   `\"hashAttribute\": \"string\",`\n    \n*   `\"fallbackAttribute\": \"string\",`\n    \n*   `\"hashVersion\": 1,`\n    \n*   `\"disableStickyBucketing\": null,`\n    \n*   `\"bucketVersion\": 0,`\n    \n*   `\"minBucketVersion\": 0,`\n    \n*   `\"variations\": [`\n    \n    *   `{`\n        \n        *   `\"variationId\": \"string\",`\n            \n        *   `\"key\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"screenshots\": [`\n            \n            *   `\"string\"`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"phases\": [`\n    \n    *   `{`\n        \n        *   `\"name\": \"string\",`\n            \n        *   `\"dateStarted\": \"string\",`\n            \n        *   `\"dateEnded\": \"string\",`\n            \n        *   `\"reasonForStopping\": \"string\",`\n            \n        *   `\"seed\": \"string\",`\n            \n        *   `\"coverage\": 0,`\n            \n        *   `\"trafficSplit\": [`\n            \n            *   `{`\n                \n                *   `\"variationId\": \"string\",`\n                    \n                *   `\"weight\": 0`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"namespace\": {`\n            \n            *   `\"namespaceId\": \"string\",`\n                \n            *   `\"range\": [ ]`\n                \n            \n            `},`\n            \n        *   `\"targetingCondition\": \"string\",`\n            \n        *   `\"savedGroupTargeting\": [`\n            \n            *   `{`\n                \n                *   `\"matchType\": \"all\",`\n                    \n                *   `\"savedGroups\": [`\n                    \n                    *   `\"string\"`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"settings\": {`\n    \n    *   `\"datasourceId\": \"string\",`\n        \n    *   `\"assignmentQueryId\": \"string\",`\n        \n    *   `\"experimentId\": \"string\",`\n        \n    *   `\"segmentId\": \"string\",`\n        \n    *   `\"queryFilter\": \"string\",`\n        \n    *   `\"inProgressConversions\": \"include\",`\n        \n    *   `\"attributionModel\": \"firstExposure\",`\n        \n    *   `\"statsEngine\": \"bayesian\",`\n        \n    *   `\"goals\": [`\n        \n        *   `{`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"guardrails\": [`\n        \n        *   `{`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"activationMetric\": {`\n        \n        *   `\"metricId\": \"string\",`\n            \n        *   `\"overrides\": {`\n            \n            *   `\"delayHours\": 0,`\n                \n            *   `\"windowHours\": 0,`\n                \n            *   `\"window\": \"conversion\",`\n                \n            *   `\"winRiskThreshold\": 0,`\n                \n            *   `\"loseRiskThreshold\": 0`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `},`\n    \n*   `\"resultSummary\": {`\n    \n    *   `\"status\": \"string\",`\n        \n    *   `\"winner\": \"string\",`\n        \n    *   `\"conclusions\": \"string\",`\n        \n    *   `\"releasedVariationId\": \"string\",`\n        \n    *   `\"excludeFromPayload\": true`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/ExperimentAnalysisSettings_model)ExperimentAnalysisSettings\n\ndatasourceId\n\nrequired\n\nstring\n\nassignmentQueryId\n\nrequired\n\nstring\n\nexperimentId\n\nrequired\n\nstring\n\nsegmentId\n\nrequired\n\nstring\n\nqueryFilter\n\nrequired\n\nstring\n\ninProgressConversions\n\nrequired\n\nany\n\nEnum: \"include\" \"exclude\"\n\nattributionModel\n\nrequired\n\nany\n\nEnum: \"firstExposure\" \"experimentDuration\"\n\nstatsEngine\n\nrequired\n\nany\n\nEnum: \"bayesian\" \"frequentist\"\n\nrequired\n\nArray of objects (ExperimentMetric)\n\nrequired\n\nArray of objects (ExperimentMetric)\n\nobject (ExperimentMetric)\n\n`{`\n\n*   `\"datasourceId\": \"string\",`\n    \n*   `\"assignmentQueryId\": \"string\",`\n    \n*   `\"experimentId\": \"string\",`\n    \n*   `\"segmentId\": \"string\",`\n    \n*   `\"queryFilter\": \"string\",`\n    \n*   `\"inProgressConversions\": \"include\",`\n    \n*   `\"attributionModel\": \"firstExposure\",`\n    \n*   `\"statsEngine\": \"bayesian\",`\n    \n*   `\"goals\": [`\n    \n    *   `{`\n        \n        *   `\"metricId\": \"string\",`\n            \n        *   `\"overrides\": {`\n            \n            *   `\"delayHours\": 0,`\n                \n            *   `\"windowHours\": 0,`\n                \n            *   `\"window\": \"conversion\",`\n                \n            *   `\"winRiskThreshold\": 0,`\n                \n            *   `\"loseRiskThreshold\": 0`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"guardrails\": [`\n    \n    *   `{`\n        \n        *   `\"metricId\": \"string\",`\n            \n        *   `\"overrides\": {`\n            \n            *   `\"delayHours\": 0,`\n                \n            *   `\"windowHours\": 0,`\n                \n            *   `\"window\": \"conversion\",`\n                \n            *   `\"winRiskThreshold\": 0,`\n                \n            *   `\"loseRiskThreshold\": 0`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"activationMetric\": {`\n    \n    *   `\"metricId\": \"string\",`\n        \n    *   `\"overrides\": {`\n        \n        *   `\"delayHours\": 0,`\n            \n        *   `\"windowHours\": 0,`\n            \n        *   `\"window\": \"conversion\",`\n            \n        *   `\"winRiskThreshold\": 0,`\n            \n        *   `\"loseRiskThreshold\": 0`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/ExperimentMetric_model)ExperimentMetric\n\n`{`\n\n*   `\"metricId\": \"string\",`\n    \n*   `\"overrides\": {`\n    \n    *   `\"delayHours\": 0,`\n        \n    *   `\"windowHours\": 0,`\n        \n    *   `\"window\": \"conversion\",`\n        \n    *   `\"winRiskThreshold\": 0,`\n        \n    *   `\"loseRiskThreshold\": 0`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/ExperimentResults_model)ExperimentResults\n\nid\n\nrequired\n\nstring\n\ndateUpdated\n\nrequired\n\nstring\n\nexperimentId\n\nrequired\n\nstring\n\nphase\n\nrequired\n\nstring\n\ndateStart\n\nrequired\n\nstring\n\ndateEnd\n\nrequired\n\nstring\n\nrequired\n\nobject\n\nrequired\n\nobject (ExperimentAnalysisSettings)\n\nqueryIds\n\nrequired\n\nArray of strings\n\nrequired\n\nArray of objects\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"dateUpdated\": \"string\",`\n    \n*   `\"experimentId\": \"string\",`\n    \n*   `\"phase\": \"string\",`\n    \n*   `\"dateStart\": \"string\",`\n    \n*   `\"dateEnd\": \"string\",`\n    \n*   `\"dimension\": {`\n    \n    *   `\"type\": \"string\",`\n        \n    *   `\"id\": \"string\"`\n        \n    \n    `},`\n    \n*   `\"settings\": {`\n    \n    *   `\"datasourceId\": \"string\",`\n        \n    *   `\"assignmentQueryId\": \"string\",`\n        \n    *   `\"experimentId\": \"string\",`\n        \n    *   `\"segmentId\": \"string\",`\n        \n    *   `\"queryFilter\": \"string\",`\n        \n    *   `\"inProgressConversions\": \"include\",`\n        \n    *   `\"attributionModel\": \"firstExposure\",`\n        \n    *   `\"statsEngine\": \"bayesian\",`\n        \n    *   `\"goals\": [`\n        \n        *   `{`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"guardrails\": [`\n        \n        *   `{`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"activationMetric\": {`\n        \n        *   `\"metricId\": \"string\",`\n            \n        *   `\"overrides\": {`\n            \n            *   `\"delayHours\": 0,`\n                \n            *   `\"windowHours\": 0,`\n                \n            *   `\"window\": \"conversion\",`\n                \n            *   `\"winRiskThreshold\": 0,`\n                \n            *   `\"loseRiskThreshold\": 0`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `},`\n    \n*   `\"queryIds\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"results\": [`\n    \n    *   `{`\n        \n        *   `\"dimension\": \"string\",`\n            \n        *   `\"totalUsers\": 0,`\n            \n        \n        *   `\"metrics\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"variations\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"variationId\": \"string\",`\n                            \n                        *   `\"users\": 0,`\n                            \n                        *   `\"analyses\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"engine\": \"bayesian\",`\n                                    \n                                *   `\"numerator\": 0,`\n                                    \n                                *   `\"denominator\": 0,`\n                                    \n                                *   `\"mean\": 0,`\n                                    \n                                *   `\"stddev\": 0,`\n                                    \n                                *   `\"percentChange\": 0,`\n                                    \n                                *   `\"ciLow\": 0,`\n                                    \n                                *   `\"ciHigh\": 0,`\n                                    \n                                *   `\"pValue\": 0,`\n                                    \n                                *   `\"risk\": 0,`\n                                    \n                                *   `\"chanceToBeatControl\": 0`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `]`\n                            \n                        \n                        `}`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/FactMetric_model)FactMetric\n\nid\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\ndescription\n\nrequired\n\nstring\n\nowner\n\nrequired\n\nstring\n\nprojects\n\nrequired\n\nArray of strings\n\ntags\n\nrequired\n\nArray of strings\n\ndatasource\n\nrequired\n\nstring\n\nmetricType\n\nrequired\n\nstring\n\nEnum: \"proportion\" \"mean\" \"quantile\" \"ratio\"\n\nrequired\n\nobject\n\nobject\n\ninverse\n\nrequired\n\nboolean\n\nSet to true for things like Bounce Rate, where you want the metric to decrease\n\nobject\n\nControls the settings for quantile metrics (mandatory if metricType is \"quantile\")\n\nrequired\n\nobject\n\nControls how outliers are handled\n\nrequired\n\nobject\n\nControls the conversion window for the metric\n\nrequired\n\nobject\n\nControls the regression adjustment (CUPED) settings for the metric\n\nriskThresholdSuccess\n\nrequired\n\nnumber\n\nriskThresholdDanger\n\nrequired\n\nnumber\n\nminPercentChange\n\nrequired\n\nnumber\n\nmaxPercentChange\n\nrequired\n\nnumber\n\nminSampleSize\n\nrequired\n\nnumber\n\nmanagedBy\n\nrequired\n\nstring\n\nEnum: \"\" \"api\"\n\nWhere this fact metric must be managed from. If not set (empty string), it can be managed from anywhere.\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"datasource\": \"string\",`\n    \n*   `\"metricType\": \"proportion\",`\n    \n*   `\"numerator\": {`\n    \n    *   `\"factTableId\": \"string\",`\n        \n    *   `\"column\": \"string\",`\n        \n    \n    `},`\n    \n*   `\"denominator\": {`\n    \n    *   `\"factTableId\": \"string\",`\n        \n    *   `\"column\": \"string\",`\n        \n    \n    `},`\n    \n*   `\"inverse\": true,`\n    \n*   `\"quantileSettings\": {`\n    \n    *   `\"type\": \"event\",`\n        \n    *   `\"ignoreZeros\": true,`\n        \n    *   `\"quantile\": 0.001`\n        \n    \n    `},`\n    \n*   `\"cappingSettings\": {`\n    \n    *   `\"type\": \"none\",`\n        \n    *   `\"value\": 0,`\n        \n    *   `\"ignoreZeros\": true`\n        \n    \n    `},`\n    \n*   `\"windowSettings\": {`\n    \n    *   `\"type\": \"none\",`\n        \n    *   `\"delayHours\": 0,`\n        \n    *   `\"windowValue\": 0,`\n        \n    *   `\"windowUnit\": \"hours\"`\n        \n    \n    `},`\n    \n*   `\"regressionAdjustmentSettings\": {`\n    \n    *   `\"override\": true,`\n        \n    *   `\"enabled\": true,`\n        \n    *   `\"days\": 0`\n        \n    \n    `},`\n    \n*   `\"riskThresholdSuccess\": 0,`\n    \n*   `\"riskThresholdDanger\": 0,`\n    \n*   `\"minPercentChange\": 0,`\n    \n*   `\"maxPercentChange\": 0,`\n    \n*   `\"minSampleSize\": 0,`\n    \n*   `\"managedBy\": \"\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n    \n\n`}`\n\n## [](#tag/FactTable_model)FactTable\n\nid\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\ndescription\n\nrequired\n\nstring\n\nowner\n\nrequired\n\nstring\n\nprojects\n\nrequired\n\nArray of strings\n\ntags\n\nrequired\n\nArray of strings\n\ndatasource\n\nrequired\n\nstring\n\nuserIdTypes\n\nrequired\n\nArray of strings\n\nsql\n\nrequired\n\nstring\n\nmanagedBy\n\nrequired\n\nstring\n\nEnum: \"\" \"api\"\n\nWhere this fact table must be managed from. If not set (empty string), it can be managed from anywhere.\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"datasource\": \"string\",`\n    \n*   `\"userIdTypes\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"sql\": \"string\",`\n    \n*   `\"managedBy\": \"\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n    \n\n`}`\n\n## [](#tag/FactTableFilter_model)FactTableFilter\n\nid\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\ndescription\n\nrequired\n\nstring\n\nvalue\n\nrequired\n\nstring\n\nmanagedBy\n\nrequired\n\nstring\n\nEnum: \"\" \"api\"\n\nWhere this fact table filter must be managed from. If not set (empty string), it can be managed from anywhere.\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"value\": \"string\",`\n    \n*   `\"managedBy\": \"\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n    \n\n`}`\n\n## [](#tag/Feature_model)Feature\n\nid\n\nrequired\n\nstring\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\narchived\n\nrequired\n\nboolean\n\ndescription\n\nrequired\n\nstring\n\nowner\n\nrequired\n\nstring\n\nproject\n\nrequired\n\nstring\n\nvalueType\n\nrequired\n\nstring\n\nEnum: \"boolean\" \"string\" \"number\" \"json\"\n\ndefaultValue\n\nrequired\n\nstring\n\ntags\n\nrequired\n\nArray of strings\n\nrequired\n\nobject\n\nArray of objects\n\nrequired\n\nobject\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"archived\": true,`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"project\": \"string\",`\n    \n*   `\"valueType\": \"boolean\",`\n    \n*   `\"defaultValue\": \"string\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"environments\": {`\n    \n    *   `\"property1\": {`\n        \n        *   `\"enabled\": true,`\n            \n        *   `\"defaultValue\": \"string\",`\n            \n        *   `\"rules\": [`\n            \n            *   `{`\n                \n                *   `\"description\": \"string\",`\n                    \n                *   `\"condition\": \"string\",`\n                    \n                *   `\"savedGroupTargeting\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"matchType\": \"all\",`\n                            \n                        *   `\"savedGroups\": [`\n                            \n                            *   `\"string\"`\n                                \n                            \n                            `]`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"id\": \"string\",`\n                    \n                *   `\"enabled\": true,`\n                    \n                *   `\"type\": \"force\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"definition\": \"string\",`\n            \n        *   `\"draft\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"property2\": {`\n        \n        *   `\"enabled\": true,`\n            \n        *   `\"defaultValue\": \"string\",`\n            \n        *   `\"rules\": [`\n            \n            *   `{`\n                \n                *   `\"description\": \"string\",`\n                    \n                *   `\"condition\": \"string\",`\n                    \n                *   `\"savedGroupTargeting\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"matchType\": \"all\",`\n                            \n                        *   `\"savedGroups\": [`\n                            \n                            *   `\"string\"`\n                                \n                            \n                            `]`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"id\": \"string\",`\n                    \n                *   `\"enabled\": true,`\n                    \n                *   `\"type\": \"force\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"definition\": \"string\",`\n            \n        *   `\"draft\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `},`\n    \n*   `\"prerequisites\": [`\n    \n    *   `{`\n        \n        *   `\"parentId\": \"string\",`\n            \n        *   `\"parentCondition\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"revision\": {`\n    \n    *   `\"version\": 0,`\n        \n    *   `\"comment\": \"string\",`\n        \n    *   `\"date\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"publishedBy\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/FeatureDefinition_model)FeatureDefinition\n\ndefaultValue\n\nrequired\n\nstring or number or array or object or null\n\n`{`\n\n*   `\"defaultValue\": \"string\",`\n    \n*   `\"rules\": [`\n    \n    *   `{`\n        \n        *   `\"force\": \"string\",`\n            \n        \n        *   `\"variations\": [`\n            \n            *   `\"string\"`\n                \n            \n            `],`\n            \n        *   `\"hashAttribute\": \"string\",`\n            \n        \n        *   `\"key\": \"string\",`\n            \n        *   `\"coverage\": 0,`\n            \n        *   `\"condition\": { }`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/FeatureEnvironment_model)FeatureEnvironment\n\nenabled\n\nrequired\n\ndefaultValue\n\nrequired\n\nrequired\n\nArray of any (FeatureRule)\n\ndefinition\n\nstring\n\nA JSON stringified [FeatureDefinition](#tag/FeatureDefinition_model)\n\n`{`\n\n*   `\"enabled\": true,`\n    \n*   `\"defaultValue\": \"string\",`\n    \n*   `\"rules\": [`\n    \n    *   `{`\n        \n        *   `\"description\": \"string\",`\n            \n        *   `\"condition\": \"string\",`\n            \n        *   `\"savedGroupTargeting\": [`\n            \n            *   `{`\n                \n                *   `\"matchType\": \"all\",`\n                    \n                *   `\"savedGroups\": [`\n                    \n                    *   `\"string\"`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"id\": \"string\",`\n            \n        *   `\"enabled\": true,`\n            \n        *   `\"type\": \"force\",`\n            \n        *   `\"value\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"definition\": \"string\",`\n    \n*   `\"draft\": {`\n    \n    *   `\"enabled\": true,`\n        \n    *   `\"defaultValue\": \"string\",`\n        \n    *   `\"rules\": [`\n        \n        *   `{`\n            \n            *   `\"description\": \"string\",`\n                \n            *   `\"condition\": \"string\",`\n                \n            *   `\"savedGroupTargeting\": [`\n                \n                *   `{`\n                    \n                    *   `\"matchType\": \"all\",`\n                        \n                    *   `\"savedGroups\": [`\n                        \n                        *   `\"string\"`\n                            \n                        \n                        `]`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"id\": \"string\",`\n                \n            *   `\"enabled\": true,`\n                \n            *   `\"type\": \"force\",`\n                \n            *   `\"value\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"definition\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/FeatureExperimentRefRule_model)FeatureExperimentRefRule\n\ndescription\n\nrequired\n\nstring\n\nid\n\nrequired\n\nstring\n\nenabled\n\nrequired\n\nboolean\n\ntype\n\nrequired\n\nstring\n\nValue: \"experiment-ref\"\n\ncondition\n\nstring\n\nrequired\n\nArray of objects\n\nexperimentId\n\nrequired\n\nstring\n\n`{`\n\n*   `\"description\": \"string\",`\n    \n*   `\"id\": \"string\",`\n    \n*   `\"enabled\": true,`\n    \n*   `\"type\": \"experiment-ref\",`\n    \n*   `\"condition\": \"string\",`\n    \n*   `\"variations\": [`\n    \n    *   `{`\n        \n        *   `\"value\": \"string\",`\n            \n        *   `\"variationId\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"experimentId\": \"string\"`\n    \n\n`}`\n\n## [](#tag/FeatureExperimentRule_model)FeatureExperimentRule\n\ndescription\n\nrequired\n\nstring\n\ncondition\n\nrequired\n\nstring\n\nid\n\nrequired\n\nstring\n\nenabled\n\nrequired\n\nboolean\n\ntype\n\nrequired\n\nstring\n\nValue: \"experiment\"\n\ntrackingKey\n\nstring\n\nhashAttribute\n\nstring\n\nfallbackAttribute\n\nstring\n\ndisableStickyBucketing\n\nboolean;\n\nbucketVersion\n\nnumber\n\nminBucketVersion\n\nnumber\n\nnamespace\n\nobect\n\ncoverage\n\nnumber\n\nArray of objects\n\n`{`\n\n*   `\"description\": \"string\",`\n    \n*   `\"condition\": \"string\",`\n    \n*   `\"id\": \"string\",`\n    \n*   `\"enabled\": true,`\n    \n*   `\"type\": \"experiment\",`\n    \n*   `\"trackingKey\": \"string\",`\n    \n*   `\"hashAttribute\": \"string\",`\n    \n*   `\"fallbackAttribute\": \"string\",`\n    \n*   `\"disableStickyBucketing\": null,`\n    \n*   `\"bucketVersion\": 0,`\n    \n*   `\"minBucketVersion\": 0,`\n    \n*   `\"namespace\": null,`\n    \n*   `\"coverage\": 0,`\n    \n*   `\"value\": [`\n    \n    *   `{`\n        \n        *   `\"value\": \"string\",`\n            \n        *   `\"weight\": 0,`\n            \n        *   `\"name\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/FeatureForceRule_model)FeatureForceRule\n\ndescription\n\nrequired\n\nstring\n\ncondition\n\nrequired\n\nstring\n\nArray of objects\n\nid\n\nrequired\n\nstring\n\nenabled\n\nrequired\n\nboolean\n\ntype\n\nrequired\n\nstring\n\nValue: \"force\"\n\nvalue\n\nrequired\n\nstring\n\n`{`\n\n*   `\"description\": \"string\",`\n    \n*   `\"condition\": \"string\",`\n    \n*   `\"savedGroupTargeting\": [`\n    \n    *   `{`\n        \n        *   `\"matchType\": \"all\",`\n            \n        *   `\"savedGroups\": [`\n            \n            *   `\"string\"`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"id\": \"string\",`\n    \n*   `\"enabled\": true,`\n    \n*   `\"type\": \"force\",`\n    \n*   `\"value\": \"string\"`\n    \n\n`}`\n\n## [](#tag/FeatureRolloutRule_model)FeatureRolloutRule\n\ndescription\n\nrequired\n\nstring\n\ncondition\n\nrequired\n\nstring\n\nArray of objects\n\nid\n\nrequired\n\nstring\n\nenabled\n\nrequired\n\nboolean\n\ntype\n\nrequired\n\nstring\n\nValue: \"rollout\"\n\nvalue\n\nrequired\n\nstring\n\ncoverage\n\nrequired\n\nnumber\n\nhashAttribute\n\nrequired\n\nstring\n\n`{`\n\n*   `\"description\": \"string\",`\n    \n*   `\"condition\": \"string\",`\n    \n*   `\"savedGroupTargeting\": [`\n    \n    *   `{`\n        \n        *   `\"matchType\": \"all\",`\n            \n        *   `\"savedGroups\": [`\n            \n            *   `\"string\"`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"id\": \"string\",`\n    \n*   `\"enabled\": true,`\n    \n*   `\"type\": \"rollout\",`\n    \n*   `\"value\": \"string\",`\n    \n*   `\"coverage\": 0,`\n    \n*   `\"hashAttribute\": \"string\"`\n    \n\n`}`\n\n## [](#tag/FeatureRule_model)FeatureRule\n\ndescription\n\nrequired\n\nstring\n\ncondition\n\nrequired\n\nstring\n\nArray of objects\n\nid\n\nrequired\n\nstring\n\nenabled\n\nrequired\n\nboolean\n\ntype\n\nrequired\n\nstring\n\nforce\n\nvalue\n\nrequired\n\nstring\n\n`{`\n\n*   `\"description\": \"string\",`\n    \n*   `\"condition\": \"string\",`\n    \n*   `\"savedGroupTargeting\": [`\n    \n    *   `{`\n        \n        *   `\"matchType\": \"all\",`\n            \n        *   `\"savedGroups\": [`\n            \n            *   `\"string\"`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"id\": \"string\",`\n    \n*   `\"enabled\": true,`\n    \n*   `\"type\": \"force\",`\n    \n*   `\"value\": \"string\"`\n    \n\n`}`\n\n## [](#tag/Metric_model)Metric\n\nid\n\nrequired\n\nstring\n\nmanagedBy\n\nrequired\n\nstring\n\nEnum: \"\" \"api\" \"config\"\n\nWhere this metric must be managed from. If not set (empty string), it can be managed from anywhere.\n\ndateCreated\n\nrequired\n\nstring\n\ndateUpdated\n\nrequired\n\nstring\n\nowner\n\nrequired\n\nstring\n\ndatasourceId\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\ndescription\n\nrequired\n\nstring\n\ntype\n\nrequired\n\nstring\n\nEnum: \"binomial\" \"count\" \"duration\" \"revenue\"\n\ntags\n\nrequired\n\nArray of strings\n\nprojects\n\nrequired\n\nArray of strings\n\narchived\n\nrequired\n\nboolean\n\nrequired\n\nobject\n\nobject\n\nobject\n\nobject\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"managedBy\": \"\",`\n    \n*   `\"dateCreated\": \"string\",`\n    \n*   `\"dateUpdated\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"datasourceId\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"type\": \"binomial\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"archived\": true,`\n    \n*   `\"behavior\": {`\n    \n    *   `\"goal\": \"increase\",`\n        \n    *   `\"cappingSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"value\": 0,`\n            \n        *   `\"ignoreZeros\": true`\n            \n        \n        `},`\n        \n    *   `\"cap\": 0,`\n        \n    *   `\"capping\": \"absolute\",`\n        \n    *   `\"capValue\": 0,`\n        \n    *   `\"windowSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"delayHours\": 0,`\n            \n        *   `\"windowValue\": 0,`\n            \n        *   `\"windowUnit\": \"hours\"`\n            \n        \n        `},`\n        \n    *   `\"priorSettings\": {`\n        \n        *   `\"override\": true,`\n            \n        *   `\"proper\": true,`\n            \n        *   `\"mean\": 0,`\n            \n        *   `\"stddev\": 0`\n            \n        \n        `},`\n        \n    *   `\"conversionWindowStart\": 0,`\n        \n    *   `\"conversionWindowEnd\": 0,`\n        \n    *   `\"riskThresholdSuccess\": 0,`\n        \n    *   `\"riskThresholdDanger\": 0,`\n        \n    *   `\"minPercentChange\": 0,`\n        \n    *   `\"maxPercentChange\": 0,`\n        \n    *   `\"minSampleSize\": 0`\n        \n    \n    `},`\n    \n*   `\"sql\": {`\n    \n    *   `\"identifierTypes\": [`\n        \n        *   `\"string\"`\n            \n        \n        `],`\n        \n    *   `\"conversionSQL\": \"string\",`\n        \n    *   `\"userAggregationSQL\": \"string\",`\n        \n    *   `\"denominatorMetricId\": \"string\"`\n        \n    \n    `},`\n    \n*   `\"sqlBuilder\": {`\n    \n    *   `\"identifierTypeColumns\": [`\n        \n        *   `{`\n            \n            *   `\"identifierType\": \"string\",`\n                \n            *   `\"columnName\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"tableName\": \"string\",`\n        \n    *   `\"valueColumnName\": \"string\",`\n        \n    *   `\"timestampColumnName\": \"string\",`\n        \n    *   `\"conditions\": [`\n        \n        *   `{`\n            \n            *   `\"column\": \"string\",`\n                \n            *   `\"operator\": \"string\",`\n                \n            *   `\"value\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `},`\n    \n*   `\"mixpanel\": {`\n    \n    *   `\"eventName\": \"string\",`\n        \n    *   `\"eventValue\": \"string\",`\n        \n    *   `\"userAggregation\": \"string\",`\n        \n    *   `\"conditions\": [`\n        \n        *   `{`\n            \n            *   `\"property\": \"string\",`\n                \n            *   `\"operator\": \"string\",`\n                \n            *   `\"value\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/Organization_model)Organization\n\nid\n\nstring\n\nThe Growthbook unique identifier for the organization\n\nexternalId\n\nstring\n\nAn optional identifier that you use within your company for the organization\n\ndateCreated\n\nstring <date-time\\>\n\nThe date the organization was created\n\nname\n\nstring\n\nThe name of the organization\n\nownerEmail\n\nstring\n\nThe email address of the organization owner\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"externalId\": \"string\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"ownerEmail\": \"string\"`\n    \n\n`}`\n\n## [](#tag/Project_model)Project\n\nid\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\ndescription\n\nstring\n\nobject\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"settings\": {`\n    \n    *   `\"statsEngine\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/SavedGroup_model)SavedGroup\n\nid\n\nrequired\n\nstring\n\ntype\n\nrequired\n\nstring\n\nEnum: \"condition\" \"list\"\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\nname\n\nrequired\n\nstring\n\nowner\n\nstring\n\ncondition\n\nstring\n\nWhen type = 'condition', this is the JSON-encoded condition for the group\n\nattributeKey\n\nstring\n\nWhen type = 'list', this is the attribute key the group is based on\n\nvalues\n\nArray of strings\n\nWhen type = 'list', this is the list of values for the attribute key\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"type\": \"condition\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"condition\": \"string\",`\n    \n*   `\"attributeKey\": \"string\",`\n    \n*   `\"values\": [`\n    \n    *   `\"string\"`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/SdkConnection_model)SdkConnection\n\nid\n\nrequired\n\nstring\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\nname\n\nrequired\n\nstring\n\norganization\n\nrequired\n\nstring\n\nlanguages\n\nrequired\n\nArray of strings\n\nsdkVersion\n\nstring\n\nenvironment\n\nrequired\n\nstring\n\nproject\n\nrequired\n\nstring\n\nUse 'projects' instead. This is only for backwards compatibility and contains the first project only.\n\nprojects\n\nArray of strings\n\nencryptPayload\n\nrequired\n\nboolean\n\nencryptionKey\n\nrequired\n\nstring\n\nincludeVisualExperiments\n\nboolean\n\nincludeDraftExperiments\n\nboolean\n\nincludeExperimentNames\n\nboolean\n\nincludeRedirectExperiments\n\nboolean\n\nkey\n\nrequired\n\nstring\n\nproxyEnabled\n\nrequired\n\nboolean\n\nproxyHost\n\nrequired\n\nstring\n\nproxySigningKey\n\nrequired\n\nstring\n\nsseEnabled\n\nboolean\n\nhashSecureAttributes\n\nboolean\n\nremoteEvalEnabled\n\nboolean\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"organization\": \"string\",`\n    \n*   `\"languages\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"sdkVersion\": \"string\",`\n    \n*   `\"environment\": \"string\",`\n    \n*   `\"project\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"encryptPayload\": true,`\n    \n*   `\"encryptionKey\": \"string\",`\n    \n*   `\"includeVisualExperiments\": true,`\n    \n*   `\"includeDraftExperiments\": true,`\n    \n*   `\"includeExperimentNames\": true,`\n    \n*   `\"includeRedirectExperiments\": true,`\n    \n*   `\"key\": \"string\",`\n    \n*   `\"proxyEnabled\": true,`\n    \n*   `\"proxyHost\": \"string\",`\n    \n*   `\"proxySigningKey\": \"string\",`\n    \n*   `\"sseEnabled\": true,`\n    \n*   `\"hashSecureAttributes\": true,`\n    \n*   `\"remoteEvalEnabled\": true`\n    \n\n`}`\n\n## [](#tag/Segment_model)Segment\n\nid\n\nrequired\n\nstring\n\nowner\n\nrequired\n\nstring\n\ndatasourceId\n\nrequired\n\nstring\n\nidentifierType\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\nquery\n\nrequired\n\nstring\n\ndateCreated\n\nrequired\n\nstring\n\ndateUpdated\n\nrequired\n\nstring\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"datasourceId\": \"string\",`\n    \n*   `\"identifierType\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"query\": \"string\",`\n    \n*   `\"dateCreated\": \"string\",`\n    \n*   `\"dateUpdated\": \"string\"`\n    \n\n`}`\n\n## [](#tag/VisualChange_model)VisualChange\n\ndescription\n\ncss\n\njs\n\nvariation\n\nrequired\n\n`{`\n\n*   `\"description\": \"string\",`\n    \n*   `\"css\": \"string\",`\n    \n*   `\"js\": \"string\",`\n    \n*   `\"variation\": \"string\",`\n    \n*   `\"domMutations\": [`\n    \n    *   `{`\n        \n        *   `\"selector\": \"string\",`\n            \n        *   `\"action\": \"append\",`\n            \n        *   `\"attribute\": \"string\",`\n            \n        *   `\"value\": \"string\",`\n            \n        *   `\"parentSelector\": \"string\",`\n            \n        *   `\"insertBeforeSelector\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/VisualChangeset_model)VisualChangeset\n\nid\n\nrequired\n\neditorUrl\n\nrequired\n\nexperiment\n\nrequired\n\nrequired\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"urlPatterns\": [`\n    \n    *   `{`\n        \n        *   `\"include\": true,`\n            \n        *   `\"type\": \"simple\",`\n            \n        *   `\"pattern\": null`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"editorUrl\": \"string\",`\n    \n*   `\"experiment\": \"string\",`\n    \n*   `\"visualChanges\": [`\n    \n    *   `{`\n        \n        *   `\"description\": \"string\",`\n            \n        *   `\"css\": \"string\",`\n            \n        *   `\"js\": \"string\",`\n            \n        *   `\"variation\": \"string\",`\n            \n        *   `\"domMutations\": [`\n            \n            *   `{`\n                \n                *   `\"selector\": \"string\",`\n                    \n                *   `\"action\": \"append\",`\n                    \n                *   `\"attribute\": \"string\",`\n                    \n                *   `\"value\": \"string\",`\n                    \n                *   `\"parentSelector\": \"string\",`\n                    \n                *   `\"insertBeforeSelector\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`",
  "title": "GrowthBook REST API | GrowthBook Docs",
  "description": "GrowthBook offers a full REST API for interacting with the GrowthBook application. This is currently in **beta** as we add more authenticated API routes and features.\n\nRequest data can use either JSON or Form data encoding (with proper `Content-Type` headers). All response bodies are JSON-encoded.\n\nThe API base URL for GrowthBook Cloud is `https://api.growthbook.io`. For self-hosted deployments, it is the same as your API_HOST environment variable (defaults to `http://localhost:3100`). The rest of these docs will assume you are using GrowthBook Cloud.\n\n## Authentication\n\nWe support both the HTTP Basic and Bearer authentication schemes for convenience.\n\nYou first need to generate a new API Key in GrowthBook. Different keys have different permissions:\n\n- **Personal Access Tokens**: These are sensitive and provide the same level of access as the user has to an organization. These can be created by going to `Personal Access Tokens` under the your user menu.\n- **Secret Keys**: These are sensitive and provide the level of access for the role, which currently is either `admin` or `readonly`. Only Admins with the `manageApiKeys` permission can manage Secret Keys on behalf of an organization. These can be created by going to `Settings -> API Keys`\n\nIf using HTTP Basic auth, pass the Secret Key as the username and leave the password blank:\n\n```bash\ncurl https://api.growthbook.io/api/v1 \\\n  -u secret_abc123DEF456:\n# The \":\" at the end stops curl from asking for a password\n```\n\nIf using Bearer auth, pass the Secret Key as the token:\n\n```bash\ncurl https://api.growthbook.io/api/v1 \\\n-H \"Authorization: Bearer secret_abc123DEF456\"\n```\n\n## Errors\n\nThe API may return the following error status codes:\n\n- **400** - Bad Request - Often due to a missing required parameter\n- **401** - Unauthorized - No valid API key provided\n- **402** - Request Failed - The parameters are valid, but the request failed\n- **403** - Forbidden - Provided API key does not have the required access\n- **404** - Not Found - Unknown API route or requested resource\n- **429** - Too Many Requests - You exceeded the rate limit of 60 requests per minute. Try again later.\n- **5XX** - Server Error - Something went wrong on GrowthBook's end (these are rare)\n\nThe response body will be a JSON object with the following properties:\n\n- **message** - Information about the error\n",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/edge/cloudflare",
  "markdown": "# Cloudflare Workers Edge App & SDK\n\n## Overview[​](#overview \"Direct link to Overview\")\n\nGrowthBook currently supports two levels of integration with most edge workers, including Cloudflare:\n\n1.  Our turnkey Edge App\n    \n    *   Automatically run server-side or hybrid [Visual Experiments](https://docs.growthbook.io/app/visual) without redraw flicker.\n    *   Automatically run server-side or hybrid [URL Redirect Experiments](https://docs.growthbook.io/app/url-redirects) without flicker or delay.\n    *   Optionally inject the JavaScript SDK with hydrated payload, allowing the front-end to pick up where the edge left off without any extra network requests. We use an enhanced version of our [HTML Script Tag](https://docs.growthbook.io/lib/script-tag) for this purpose.\n2.  Support for edge apps using our JavaScript SDK\n    \n    *   Enhanced support and examples for using our JavaScript SDK in an edge environment\n\nRegardless of your use case, our Cloudflare integration makes easy to synchronize feature and experiment values between GrowthBook and Cloudflare's KV store. This eliminates the network request to the GrowthBook API, unlocking blazingly fast edge-side and client-side SDK performance.\n\n## References[​](#references \"Direct link to References\")\n\n*   Our Cloudflare Workers SDK repository, which supports the above use cases, is [here](https://github.com/growthbook/growthbook-proxy/tree/main/packages/lib/edge-cloudflare)\n*   A turnkey implementation of the Edge App (compatible with Wrangler) is [here](https://github.com/growthbook/growthbook-proxy/tree/main/packages/lib/edge-cloudflare/example)\n*   You may find it useful to review our [JavaScript SDK](https://docs.growthbook.io/lib/js). Many of the concepts which apply to both on-edge and injected frontend SDKs are based on our JS SDK.\n\n## Worker Configuration[​](#worker-configuration \"Direct link to Worker Configuration\")\n\ntip\n\nThis tutorial assumes some familiarity with building and deploying Cloudflare Worker applications. You can quickly get up to speed by following the Cloudflare Workers [Getting Started](https://developers.cloudflare.com/workers/get-started/guide/) guide.\n\nYou may either use our turnkey Edge App for Cloudflare Workers or build your own app from scratch using our JavaScript and Cloudflare SDKs.\n\n## Turnkey Edge App[​](#turnkey-edge-app \"Direct link to Turnkey Edge App\")\n\nOur Edge App runs as a smart proxy layer between your application and your end users. In absence of Visual or URL Redirect experiments, the Edge App will simply proxy the user request to your site and return the response, optionally injecting a fully-bootstrapped JavaScript SDK onto the rendered HTML page. If the request URL matches an Visual or URL Redirect experiment and the targeting conditions are satisfied, the Edge App may also perform one or more URL redirects behind the scenes (the public-facing URL does not change) and/or mutate the DOM for Visual Experiments.\n\nURL Redirects on edge\n\nThe Edge App defaults to running URL Redirect Experiments in the browser only. This is because edge redirects load a separate page's content without altering the URL. After the redirect, some sites may experience problems with loading assets or endpoints with relative paths.\n\nYou can enable URL Redirects on edge by setting environment variable `RUN_URL_REDIRECT_EXPERIMENTS` ([see below](#environment-variables)).\n\nSetting up our turnkey Edge App is simple. Assuming that you have a basic Worker application set up, simply install the SDK and implement our custom request handler. Or if you prefer, you may pull down our fully-functional [example implementation](https://github.com/growthbook/growthbook-proxy/tree/main/packages/lib/edge-cloudflare/example) and follow along.\n\n### Install the SDK[​](#install-the-sdk \"Direct link to Install the SDK\")\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save @growthbook/edge-cloudflare\n```\n\n### Implement the Edge App request handler[​](#implement-the-edge-app-request-handler \"Direct link to Implement the Edge App request handler\")\n\nA basic implementation of our Edge App only requires a few lines of code:\n\n```\nimport { handleRequest } from \"@growthbook/edge-cloudflare\";export default {  fetch: async function (request, env, ctx) {    return await handleRequest(request, env);  },};\n```\n\n### Configure the Edge App[​](#configure-the-edge-app \"Direct link to Configure the Edge App\")\n\nUse a combination of environment variables and optional runtime configuration to add required fields and to customize the Edge App behavior.\n\n#### Environment variables[​](#environment-variables \"Direct link to Environment variables\")\n\nEdit your `wrangler.toml` file and, at minimum, add these required fields:\n\n```\n[vars]PROXY_TARGET=\"https://internal.mysite.io\"  # The non-edge URL to your websiteGROWTHBOOK_API_HOST=\"https://cdn.growthbook.io\"GROWTHBOOK_CLIENT_KEY=\"sdk-abc123\"GROWTHBOOK_DECRYPTION_KEY=\"key_abc123\"  # Only include for encrypted SDK Connections\n```\n\nYou may want to further customize the app. Here is a list of common customization variables:\n\n```\n# Disable or change the rendering behavior of Visual Experiments:# ==========RUN_VISUAL_EDITOR_EXPERIMENTS=\"everywhere\"|\"edge\"|\"browser\"|\"skip\"  # default: \"everywhere\"# URL Redirect Experiments are disabled on edge by default. Because the URL does not change, some sites# may experience problems with loading assets or endpoints with relative paths:# ==========RUN_URL_REDIRECT_EXPERIMENTS=\"everywhere\"|\"edge\"|\"browser\"|\"skip\"  # default: \"browser\"RUN_CROSS_ORIGIN_URL_REDIRECT_EXPERIMENTS=\"everywhere\"|\"edge\"|\"browser\"|\"skip\"  # default: \"browser\"# Mutate browser URL via window.history.replaceState() to reflect the new URL:INJECT_REDIRECT_URL_SCRIPT=\"true\"  # default \"true\".# Do not inject a bootstrapped JavaScript SDK onto the page:# ==========DISABLE_INJECTIONS=\"true\"  # default \"false\"# Customize the edge or injected browser SDK behavior:# ==========ENABLE_STREAMING=\"true\"  # default \"false\". Streaming SSE updates on browser.ENABLE_STICKY_BUCKETING=\"true\"  # default \"false\". Use cookie-based sticky bucketing on edge and browser.\n```\n\n#### Runtime configuration[​](#runtime-configuration \"Direct link to Runtime configuration\")\n\nYou may want to provide context to your edge app at runtime rather than using environment variables. For example, if you have additional [targeting attributes](https://docs.growthbook.io/lib/js#attributes) available, you may inject them by modifying your request handler code:\n\n```\nimport { handleRequest } from \"@growthbook/edge-cloudflare\";import { parse } from \"cookie\";export default {  fetch: async function (request, env, ctx) {    const cookie = parse(request.headers.get(\"Cookie\") || \"\");    const config = {      attributes: {        userType: cookie[\"userId\"] ? \"logged in\" : \"anonymous\"      }    };    return await handleRequest(request, env, config);  },};\n```\n\n#### More customization options[​](#more-customization-options \"Direct link to More customization options\")\n\nFor a full list of customizations, view our vendor-agnostic [Edge Utility repository](https://github.com/growthbook/growthbook-proxy/tree/main/packages/lib/edge-utils) .\n\n### Set up a Payload Cache[​](#set-up-a-payload-cache \"Direct link to Set up a Payload Cache\")\n\nYou can configure GrowthBook payload caching by using a [Cloudflare KV](https://developers.cloudflare.com/kv/reference/how-kv-works/) store. This eliminates network requests from your edge to GrowthBook which speeds up page delivery while reducing network costs.\n\nOur Cloudflare Edge App will automatically use either webhook-based or just-in-time payload caching (or both) depending on how you've set up your KV namespaces, bindings, and SDK Webhooks.\n\nMore information about setting up your payload cache can be found in the [Payload Caching with Cloudflare KV Store](#payload-caching-with-cloudflare-kv-store) doc section below.\n\n### Tracking Experiment Views[​](#tracking-experiment-views \"Direct link to Tracking Experiment Views\")\n\nRunning A/B tests requires a [tracking callback](https://docs.growthbook.io/lib/js#experimentation-ab-testing). Our turnkey Edge App defaults to using built-in front-end tracking. The tracking call automatically integrates with Segment.io, GA4, and Google Tag Manager by using the mechanism outlined in our [HTML Script Tag](https://docs.growthbook.io/lib/script-tag#tracking-experiment-views). In order to do this, the app keeps track of tracking calls triggered on edge and injects them into the front-end SDK to be automatically triggered on page load.\n\nYou may wish to either customize front-end tracking or switch to edge tracking (or use both concurrently if running hybrid edge + front-end experiments).\n\nWhy might you be interested in tracking on edge? Tracking on an edge or backend environment allows you to ensure the callback is fired before any differentiation across variations, eliminating experimental bias. While not eliminating this risk, the default injected front-end tracking introduced by our Edge App does reduce this risk relative to solely using a front-end SDK.\n\nTo change the front-end tracking callback, set the `GROWTHBOOK_TRACKING_CALLBACK` to your custom tracking JS code:\n\n```\n# todo: replace with your own tracking libraryGROWTHBOOK_TRACKING_CALLBACK=\"(experiment, results) => { console.log('browser tracking callback', {experiment, results}); }\"\n```\n\nTo track on edge, you must inject your own tracking callback into the edge request handler code. Any experiments that run on edge will use the edge tracking callback and not the front-end callback (hybrid edge + front-end experiments being an exception):\n\n```\nimport { handleRequest } from \"@growthbook/edge-cloudflare\";export default {  fetch: async function (request, env, ctx) {    const config = {      edgeTrackingCallback: (experiment, results) => {        // todo: replace with your tracking library        console.log('edge tracking callback', {experiment, results});      }    };    return await handleRequest(request, env, config);  },};\n```\n\n### Targeting Attributes[​](#targeting-attributes \"Direct link to Targeting Attributes\")\n\nThe following targeting attributes are set automatically by the Edge App.\n\n*   `id` - creates a long-lived `gbuuid` cookie if it doesn't exist already\n*   `url`\n*   `path`\n*   `host`\n*   `query`\n*   `pageTitle`\n*   `deviceType` - either `mobile` or `desktop`\n*   `browser` - one of `chrome`, `edge`, `firefox`, `safari`, or `unknown`\n*   `utmSource`\n*   `utmMedium`\n*   `utmCampaign`\n*   `utmTerm`\n*   `utmContent`\n\nYou can customize both the primary identifier name (`id`) and cookie name (`gbuuid`) by setting the `UUID_KEY` and `UUID_COOKIE_NAME` environment variables respectively.\n\nAs shown in the [runtime configuration](#runtime-configuration) section above, you can also pass custom attributes via runtime config. You can also skip automatic attribute generation and rely solely on custom attributes by setting the environment variable `SKIP_AUTO_ATTRIBUTES=\"true\"`.\n\n### Routing[​](#routing \"Direct link to Routing\")\n\nBy default, the Edge App will process all `GET` requests (other HTTP verbs are proxied through without running through our app logic).\n\nIt is generally preferable to configure your routing rules outside of our Edge App. For instance, you may only want to invoke the Edge App at `https://yourdomain.io/landing-page`. You can configure Cloudflare routing by following the Cloudflare Workers [Routes](https://developers.cloudflare.com/workers/configuration/routing/routes/) documentation.\n\nThere may be situations when you will need to provide finer-grained routing / URL targeting rules within our Edge App. You will need to include a JSON encoded string of route rules in your `ROUTES` environment variable.\n\nFor instance, you may want to do a proxy pass-through (do not process) for `mysite.io/account/*` or `mysite.io/settings/*`. Your routes may look like this:\n\n```\nROUTES='[{ \"pattern\":\"mysite.io/account/*\", \"behavior\":\"proxy\" }, { \"pattern\":\"mysite.io/settings/*\", \"behavior\":\"proxy\" }]'\n```\n\nA route uses the following interface, with many of the properties being optional:\n\n```\n{  pattern: string;  type?: \"regex\" | \"simple\";  // default: \"simple\"  behavior?: \"intercept\" | \"proxy\" | \"error\";  // default: \"intercept\"  includeFileExtensions?: boolean;  // Include requests to filenames like \"*.jpg\". default: false (pass-through).  statusCode?: number; // Alter the status code (default is 404 when using \"error\")  body?: string; // Alter the body (for setting an error message body)}\n```\n\nWhen multiple routes are included in your `ROUTES` array, only the first match is used.\n\n### Cookie Policy and GDPR[​](#cookie-policy-and-gdpr \"Direct link to Cookie Policy and GDPR\")\n\nBy default, the Edge App will persist a random unique identifier in a first-party cookie named `gbuuid`. Its purpose is to provide a consistent user experience to your visitors by preventing them from being re-bucketed into different A/B test variations. It follows the same mechanism as discussed in our [HTML Script Tag docs](https://docs.growthbook.io/lib/script-tag#cookie-policy-and-gdpr).\n\n#### Delay Storing the Cookie Until Consent is Granted[​](#delay-storing-the-cookie-until-consent-is-granted \"Direct link to Delay Storing the Cookie Until Consent is Granted\")\n\nIf you must delay persisting the `gbuuid` cookie until a user consents, you can set the environment variable `NO_AUTO_COOKIES=\"true\"`.\n\nThis will still generate a UUID for the user, but will not persist it. That means, if the user refreshes the page, they will have a new random UUID generated.environment\n\nYou have the option to manually persist this cookie at any time, for example when a user grants consent on your cookie banner. All you need to do is fire this custom event from javascript on the rendered page:\n\n```\ndocument.dispatchEvent(new CustomEvent(\"growthbookpersist\"));\n```\n\nnote\n\nIf you are using Sticky Bucketing, a persistent sticky bucket assignments cookie will automatically be generated. If you require user permission before writing cookies, you should:\n\n*   Either do not enable Sticky Bucketing on edge (do not use `ENABLE_STICKY_BUCKETING`)\n*   Or only enable Sticky Bucketing per each user via runtime configuration. (only pass `config.enableStickyBucketing: true` if user has consented — identifiable by checking for presence of the `gbuuid` cookie).\n\n## Manual SDK Integration on Edge[​](#manual-sdk-integration-on-edge \"Direct link to Manual SDK Integration on Edge\")\n\nYou may be interested in building your own edge application using the GrowthBook SDK and not using our turnkey Edge App. Or you may want to do custom feature flagging on specific routes while running our Edge App on other routes.\n\nTo use the GrowthBook on edge, simply include our standard [JavaScript SDK](https://docs.growthbook.io/lib/js) (`@growthbook/growthbook` NPM package).\n\nIn our `@growthbook/edge-cloudflare` NPM package, we export a few Cloudflare-specific utility functions to simplify SDK payload caching (we discuss payload caching strategies in the subsequent doc section).\n\n```\nimport { GrowthBook, setPolyfills } from \"@growthbook/growthbook\";import { getPayloadFromKV, getKVLocalStoragePolyfill } from \"@growthbook/edge-cloudflare\";export default {  async fetch(request) {    // 1. Init the GrowthBook SDK and choose an optional caching strategy    // A. Use the KV as a managed payload store to eliminate SDK requests to the GrowthBook API entirely.    // Requires setting up an SDK Webhook.    const payload = await getPayloadFromKV(env);    const growthbook = new GrowthBook(gbContext);    await growthbook.init({ payload: payload });    // B. Or provide a KV cache layer so that the GrowthBook SDK doesn't need to make as many requests    // to the GrowthBook API. No SDK Webhook needed.    const localStoragePolyfill = getKVLocalStoragePolyfill(env);    setPolyfills({ localStorage: localStoragePolyfill });    await growthbook.init();    // 2. Start feature flagging    if (growthbook.isOn(\"my-feature\")) {      return new Response(\"<h1>foo</h1>\");    }    return new Response(\"<h1>bar</h1>\");  }}\n```\n\n## Payload Caching with Cloudflare KV Store[​](#payload-caching-with-cloudflare-kv-store \"Direct link to Payload Caching with Cloudflare KV Store\")\n\nBy default, the Edge App will make a network request to the GrowthBook API on each user request in order to fetch the current feature and experiment values. This is a blocking call that delays page delivery. There is an in-memory short-lived cache layer on this call, but it won't always protect you.\n\nConvenient solutions this problem are realized through [Cloudflare KV](https://developers.cloudflare.com/kv/reference/how-kv-works/) , an on-edge key-val store which we can leverage for persistent payload caching. There are 2 levels of KV integration available:\n\n1.  You can either completely eliminate the blocking call to the GrowthBook API by implementing a GrowthBook-to-Cloudflare-KV push model via **SDK Webhooks**.\n2.  Alternatively, you can eliminate most of these network requests by using Cloudflare KV as a just-in-time payload cache.\n\nYou can also use either of these strategies in your own manual SDK integration via the `getPayloadFromKV` and `getKVLocalStoragePolyfill` utility functions.\n\n### Configuring the KV store[​](#configuring-the-kv-store \"Direct link to Configuring the KV store\")\n\nCreate a Cloudflare KV namespace for your worker to interface with. You can do this either using the Cloudflare dashboard or via Wrangler commands. By default, the GrowthBook Edge App and KV utility functions use the following KV namespaces; you only need to choose one, not both, depending on your desired level of integration:\n\n1.  KV stored payloads: `KV_GB_PAYLOAD`\n2.  KV payload cache: `KV_GB_CACHE`\n\nFor KV stored payloads (1), we also assume a KV key of `\"gb_payload\"`. You will likely not need to modify this, but for manual implementations both the namespace and key can be specified in the utility functions.\n\nYou must also create a KV binding so that your Cloudflare Worker can access the KV namespace. Edit your `wrangler.toml` file to add the binding:\n\n```\n# You probably do not need both bindings:kv_namespaces = [  { binding = \"KV_GB_PAYLOAD\", id = \"abcdefg1234567\" },  { binding = \"KV_GB_CACHE\", id = \"qwertyuiop12345\" }][vars]...\n```\n\n### Configuring a SDK Webhook[​](#configuring-a-sdk-webhook \"Direct link to Configuring a SDK Webhook\")\n\nFor KV stored payloads (1), we eliminate network requests from edge to GrowthBook by using a GrowthBook SDK Webhook to push the SDK payload to the KV store on change.\n\n1.  Create an [SDK Webhook](https://docs.growthbook.io/app/webhooks/sdk-webhooks) on the same SDK Connection that you are using for edge integration. You do not need to worry about the receiving end of the webhook (verifying GrowthBook signatures, etc).\n2.  Set the **Endpoint URL** to the Cloudflare's REST API endpoint for KV. At the time of writing, it follows this format:\n\n```\nhttps://api.cloudflare.com/client/v4/accounts/{accountId}/storage/kv/namespaces/{namespaceId}/values/gb_payload\n```\n\n3.  Change the **Method** to `PUT`.\n4.  Add appropriate authorization header:\n\n```\n{  \"Authorization\": \"Bearer YOUR_CF_REST_API_TOKEN\"}\n```\n\n5.  Set the **Payload format** to \"SDK Payload only\".\n\nNow whenever feature and experiment values change, your Cloudflare worker will have immediate access to the latest values. You can also test the webhook by using the \"Test Webhook\" button on the SDK Connection page.",
  "title": "Cloudflare Workers Edge App & SDK | GrowthBook Docs",
  "description": "GrowthBook SDK for Cloudflare Workers",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/build-your-own",
  "markdown": "# Build Your Own | GrowthBook Docs\n\n**Latest spec version: 0.7.0 [View Changelog](#changelog)**\n\nThis guide is meant for library authors looking to build a GrowthBook SDK in a currently unsupported language.\n\nAll libraries should follow this specification as closely as the language permits to maintain consistency and make updates and maintenance easier.\n\nAt the end of this guide is an extensive test suite with over 400 language-agnostic unit tests in JSON format. All SDKs must pass 100% of these test cases. It's recommended to add additional manual unit tests as needed on top of these.\n\n## Data structures[​](#data-structures \"Direct link to Data structures\")\n\nHere are a number of important data structures in GrowthBook SDKs, listed alphabetically.\n\n### Attributes[​](#attributes \"Direct link to Attributes\")\n\n**Attributes** are an arbitrary JSON object containing user and request attributes. Here's an example:\n\n```\n{  \"id\": \"123\",  \"anonId\": \"abcdef\",  \"company\": \"growthbook\",  \"url\": \"/pricing\",  \"country\": \"US\",  \"browser\": \"firefox\",  \"age\": 25,  \"beta\": true,  \"account\": {    \"plan\": \"team\",    \"seats\": 10  }}\n```\n\n### BucketRange[​](#bucketrange \"Direct link to BucketRange\")\n\nA tuple that describes a range of the numberline between `0` and `1`.\n\nThe tuple has 2 parts, both floats - the start of the range and the end. For example:\n\n### Condition[​](#condition \"Direct link to Condition\")\n\nA **Condition** is evaluated against **Attributes** and used to target features/experiments to specific users.\n\nThe syntax is inspired by MongoDB queries. Here is an example:\n\n```\n{  \"country\": \"US\",  \"browser\": {    \"$in\": [\"firefox\", \"chrome\"]  },  \"email\": {    \"$not\": {      \"$regex\": \"@gmail.com$\"    }  }}\n```\n\n### ParentCondition[​](#parentcondition \"Direct link to ParentCondition\")\n\nA **ParentCondition** defines a prerequisite. It consists of a parent feature's **id** (`string`), a **condition** (`Condition`), and an optional **gate** (`boolean`) flag.\n\nInstead of evaluating against attributes, the condition evaluates against the returned value of the parent feature. The condition will always reference a \"value\" property. Here is an example of a gating prerequisite where the parent feature must be on (`true`)\n\n```\n{  \"id\": \"parent-feature\",  \"condition\": {    \"value\": {      \"$eq\": true    }  },  \"gate\": true}\n```\n\n### Context[​](#context \"Direct link to Context\")\n\n**Context** object passed into the GrowthBook constructor. Has a number of optional properties:\n\n*   **enabled** (`boolean`) - Switch to globally disable all experiments. Default true.\n*   **apiHost** (`string`) - The GrowthBook API Host. Optional\n*   **clientKey** (`string`) - The key used to fetch features from the GrowthBook API. Optional\n*   **decryptionKey** (`string`) - The key used to decrypt encrypted features from the API. Optional\n*   **attributes** (`Attributes`) - Map of user attributes that are used to assign variations\n*   **url** (`string`) - The URL of the current page\n*   **features** (`FeatureMap`) - Feature definitions (usually pulled from an API or cache)\n*   **forcedVariations** (`ForcedVariationsMap`) - Force specific experiments to always assign a specific variation (used for QA)\n*   **qaMode** (`boolean`) - If true, random assignment is disabled and only explicitly forced variations are used.\n*   **trackingCallback** (`TrackingCallback`) - A function that takes `experiment` and `result` as arguments.\n\n### Experiment[​](#experiment \"Direct link to Experiment\")\n\nDefines a single **Experiment**. Has a number of properties:\n\n*   **key** (`string`) - The globally unique identifier for the experiment\n*   **variations** (`any[]`) - The different variations to choose between\n*   **weights** (`float[]`) - How to weight traffic between variations. Must add to 1.\n*   **active** (`boolean`) - If set to false, always return the control (first variation)\n*   **coverage** (`float`) - What percent of users should be included in the experiment (between 0 and 1, inclusive)\n*   **ranges** (`BucketRange[]`) - Array of ranges, one per variation\n*   **condition** (`Condition`) - Optional targeting condition\n*   **namespace** (`Namespace`) - Adds the experiment to a namespace\n*   **force** (`integer`) - All users included in the experiment will be forced into the specific variation index\n*   **hashAttribute** (`string`) - What user attribute should be used to assign variations (defaults to `id`)\n*   **fallbackAttribute** (`string`) - When using sticky bucketing, can be used as a fallback to assign variations\n*   **hashVersion** (`integer`) - The hash version to use (default to `1`)\n*   **meta** (`VariationMeta[]`) - Meta info about the variations\n*   **filters** (`Filter[]`) - Array of filters to apply\n*   **seed** (`string`) - The hash seed to use\n*   **name** (`string`) - Human-readable name for the experiment\n*   **phase** (`string`) - Id of the current experiment phase\n*   **disableStickyBucketing** (`boolean`) - If true, sticky bucketing will be disabled for this experiment. (Note: sticky bucketing is only available if a StickyBucketingService is provided in the Context)\n*   **bucketVersion** (`integer`) - An sticky bucket version number that can be used to force a re-bucketing of users (default to `0`)\n*   **minBucketVersion** (`integer`) - Any users with a sticky bucket version less than this will be excluded from the experiment\n\nThe only required properties are `key` and `variations`. Everything else is optional.\n\n### ExperimentResult[​](#experimentresult \"Direct link to ExperimentResult\")\n\nThe result of running an **Experiment** given a specific **Context**\n\n*   **inExperiment** (`boolean`) - Whether or not the user is part of the experiment\n*   **variationId** (`int`) - The array index of the assigned variation\n*   **value** (`any`) - The array value of the assigned variation\n*   **hashUsed** (`boolean`) - If a hash was used to assign a variation\n*   **hashAttribute** (`string`) - The user attribute used to assign a variation\n*   **hashValue** (`string`) - The value of that attribute\n*   **featureId** (`string` or `null`) - The id of the feature (if any) that the experiment came from\n*   **key** (`string`) - The unique key for the assigned variation\n*   **bucket** (`float`) - The hash value used to assign a variation (float from `0` to `1`)\n*   **name** (`string` or `null`) - The human-readable name of the assigned variation\n*   **passthrough** (`boolean`) - Used for holdout groups\n*   **stickyBucketUsed** (`boolean`) - If sticky bucketing was used to assign a variation\n\nThe `variationId` and `value` should always be set, even when `inExperiment` is false.\n\nThe `hashAttribute` and `hashValue` should always be set, even when `hashUsed` is false.\n\nThe `key` should always be set, even if `experiment.meta` is not defined or incomplete. In that case, convert the variation's array index to a string (e.g. `0` -> `\"0\"`) and use that as the `key` instead.\n\n### Feature[​](#feature \"Direct link to Feature\")\n\nA **Feature** object consists of a default value plus rules that can override the default.\n\n*   **defaultValue** (`any`) - The default value (should use `null` if not specified)\n*   **rules** (`FeatureRule[]`) - Array of **FeatureRule** objects that determine when and how the defaultValue gets overridden\n\n### FeatureMap[​](#featuremap \"Direct link to FeatureMap\")\n\nA hash or map of **Feature** objects. Keys are string ids for the features. Values are **Feature** objects. For example:\n\n```\n{  \"feature-1\": {    \"defaultValue\": false  },  \"my_other_feature\": {    \"defaultValue\": 1,    \"rules\": [      {        \"force\": 2      }    ]  }}\n```\n\n### FeatureResult[​](#featureresult \"Direct link to FeatureResult\")\n\nThe result of evaluating a **Feature**. Has a number of properties:\n\n*   **value** (`any`) - The assigned value of the feature\n*   **on** (`boolean`) - The assigned value cast to a boolean\n*   **off** (`boolean`) - The assigned value cast to a boolean and then negated\n*   **source** (`enum`) - One of \"unknownFeature\", \"defaultValue\", \"force\", or \"experiment\"\n*   **experiment** (`Experiment` or `null`) - When source is \"experiment\", this will be an Experiment object\n*   **experimentResult** (`ExperimentResult` or `null`) - When source is \"experiment\", this will be an ExperimentResult object\n\n### FeatureRule[​](#featurerule \"Direct link to FeatureRule\")\n\nOverrides the defaultValue of a **Feature**. Has a number of optional properties\n\n*   **id** (`string`) - Optional rule id, reserved for future use\n*   **condition** (`Condition`) - Optional targeting condition\n*   **parentConditions** (`ParentCondition[]`) - Each item defines a prerequisite where a `condition` must evaluate against a parent feature's value (identified by `id`). If `gate` is true, then this is a blocking feature-level prerequisite; otherwise it applies to the current rule only.\n*   **coverage** (`float`) - What percent of users should be included in the experiment (between 0 and 1, inclusive)\n*   **force** (`any`) - Immediately force a specific value (ignore every other option besides condition and coverage)\n*   **variations** (`any[]`) - Run an experiment (A/B test) and randomly choose between these variations\n*   **key** (`string`) - The globally unique tracking key for the experiment (default to the feature key)\n*   **weights** (`float[]`) - How to weight traffic between variations. Must add to 1.\n*   **namespace** (`Namespace`) - Adds the experiment to a namespace\n*   **hashAttribute** (`string`) - What user attribute should be used to assign variations (defaults to `id`)\n*   **hashVersion** (`integer`) - The hash version to use (default to `1`)\n*   **range** (`BucketRange`) - A more precise version of `coverage`\n*   **ranges** (`BucketRange[]`) - Ranges for experiment variations\n*   **meta** (`VariationMeta[]`) - Meta info about the experiment variations\n*   **filters** (`Filter[]`) - Array of filters to apply to the rule\n*   **seed** (`string`) - Seed to use for hashing\n*   **name** (`string`) - Human-readable name for the experiment\n*   **phase** (`string`) - The phase id of the experiment\n*   **tracks** (`TrackData[]`) - Array of tracking calls to fire\n\n### Filter[​](#filter \"Direct link to Filter\")\n\nObject used for mutual exclusion and filtering users out of experiments based on random hashes. Has the following properties:\n\n*   **seed** (`string`) - The seed used in the hash\n*   **ranges** (`BucketRange[]`) - Array of ranges that are included\n*   **hashVersion** (`integer`) - The hash version to use (default to `2`)\n*   **attribute** (`string`, optional) - The attribute to use (default to `\"id\"`)\n\n### ForcedVariationsMap[​](#forcedvariationsmap \"Direct link to ForcedVariationsMap\")\n\nA hash or map that forces an **Experiment** to always assign a specific variation. Useful for QA.\n\nKeys are the experiment key, values are the array index of the variation. For example:\n\n```\n{  \"my-test\": 0,  \"other-test\": 1}\n```\n\n### Namespace[​](#namespace \"Direct link to Namespace\")\n\nA tuple that specifies what part of a namespace an experiment includes. If two experiments are in the same namespace and their ranges don't overlap, they wil be mutually exclusive.\n\nThe tuple has 3 parts:\n\n1.  The namespace id (`string`)\n2.  The beginning of the range (`float`, between `0` and `1`)\n3.  The end of the range (`float`, between `0` and `1`)\n\nFor example:\n\n### TrackingCallback[​](#trackingcallback \"Direct link to TrackingCallback\")\n\nA callback function that is executed every time a user is included in an **Experiment**. Here's an example:\n\n```\nfunction track(experiment, result) {  analytics.track(\"Experiment Viewed\", {    experimentId: experiment.key,    variationId: result.variationId,  });}\n```\n\n### TrackData[​](#trackdata \"Direct link to TrackData\")\n\nUsed for remote feature evaluation to trigger the `TrackingCallback`. An object with 2 properties:\n\n*   **experiment** - `Experiment`\n*   **result** - `ExperimentResult`\n\n### VariationMeta[​](#variationmeta \"Direct link to VariationMeta\")\n\nMeta info about an experiment variation. Has the following properties:\n\n*   **key** (`string`, optional) - A unique key for this variation\n*   **name** (`string`, optional) - A human-readable name for this variation\n*   **passthrough** (`boolean`, optional) - Used to implement holdout groups\n\n## Helper Functions[​](#helper-functions \"Direct link to Helper Functions\")\n\nThere are some helper functions which are used a few times throughout the SDK.\n\n### hash(seed: string, value: string, version: integer): float|null[​](#hashseed-string-value-string-version-integer-floatnull \"Direct link to hash(seed: string, value: string, version: integer): float|null\")\n\nHashes a string to a float between 0 and 1.\n\nUses the simple [Fowler–Noll–Vo](https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function) algorithm, specifically fnv32a. An implementation of this is available in most languages already, and if not it's only a few lines of code to implement yourself. Fnv32a returns an integer, so we convert that to a float using a modulus.\n\nThe original hash version (1) had a flaw that caused bias when running experiments in parallel.\n\n```\n// New hashing algorithmif (version === 2) {  n = fnv32a(fnv32a(seed + value) + \"\");  return (n % 10000) / 10000;}// Original hashing algorithm (with a bias flaw)else if (version === 1) {  n = fnv32a(value + seed);  return (n % 1000) / 1000;}return null;\n```\n\n**Note**: It's important to use the exact hashing algorithms outlined here so all SDKs behave identically.\n\n### inRange(n: float, range: BucketRange): boolean[​](#inrangen-float-range-bucketrange-boolean \"Direct link to inRange(n: float, range: BucketRange): boolean\")\n\nDetermines if a number `n` is within the provided range.\n\n```\nreturn n >= range[0] && n < range[1]>;\n```\n\n### inNamespace(userId: string, namespace: Namespace): boolean[​](#innamespaceuserid-string-namespace-namespace-boolean \"Direct link to inNamespace(userId: string, namespace: Namespace): boolean\")\n\nThis checks if a userId is within an experiment namespace or not.\n\nThe `namespace` argument is a tuple with 3 parts: id (string), start (float), and end (float).\n\n1.  Hash the userId and namespace name with two underscores as a delimiter\n    \n    ```\n    n = hash(\"__\" + namespace[0], userId, 1);\n    ```\n    \n2.  Return if hash is greater than (inclusive) the namespace start and less than (exclusive) the namespace end:\n    \n    ```\n    return n >= namespace[1] && n < namespace[2];\n    ```\n    \n\n### getEqualWeights(numVariations: integer): float\\[\\][​](#getequalweightsnumvariations-integer-float \"Direct link to getEqualWeights(numVariations: integer): float[]\")\n\nReturns an array of floats with `numVariations` items that are all equal and sum to 1. For example, `getEqualWeights(2)` would return `[0.5, 0.5]`.\n\nIt's ok if the sum is slightly off due to rounding. So a sum of `0.9999999` is fine for example.\n\n1.  If numVariations is less than 1, return empty array\n2.  Create array with a length of `numVariations`\n3.  Fill the array with `1.0/numVariations` and return\n\n### getBucketRanges(numVariations: integer, coverage: float, weights: float\\[\\]): BucketRange\\[\\][​](#getbucketrangesnumvariations-integer-coverage-float-weights-float-bucketrange \"Direct link to getBucketRanges(numVariations: integer, coverage: float, weights: float[]): BucketRange[]\")\n\nThis converts and experiment's coverage and variation weights into an array of bucket ranges.\n\n`numVariations` is an integer, `coverage` is a float, and `weights` is an array of floats.\n\n1.  Clamp the value of `coverage` to between 0 and 1 inclusive.\n    \n    ```\n    if (coverage < 0) coverage = 0;if (coverage > 1) coverage = 1;\n    ```\n    \n2.  Default to equal weights if the weights don't match the number of variations.\n    \n    ```\n    if (weights.length != numVariations) {  weights = getEqualWeights(numVariations);}\n    ```\n    \n3.  Default to equal weights if the sum is not equal `1` (or close enough when rounding errors are factored in):\n    \n    ```\n    if (sum(weights) < 0.99 || sum(weights) > 1.01) {  weights = getEqualWeights(numVariations);}\n    ```\n    \n4.  Convert weights to ranges and return\n    \n    ```\n    cumulative = 0;ranges = [];for (w in weights) {  start = cumulative;  cumulative += w;  ranges.push([start, start + coverage * w]);}return ranges;\n    ```\n    \n\nSome examples:\n\n*   `getBucketRanges(2, 1, [0.5, 0.5])` -> `[[0, 0.5], [0.5, 1]]`\n*   `getBucketRanges(2, 0.5, [0.4, 0.6])` -> `[[0, 0.2], [0.4, 0.7]]`\n\n### chooseVariation(n: float, ranges: BucketRange\\[\\]): integer[​](#choosevariationn-float-ranges-bucketrange-integer \"Direct link to chooseVariation(n: float, ranges: BucketRange[]): integer\")\n\nGiven a hash and bucket ranges, assign one of the bucket ranges.\n\n1.  Loop through ranges\n    1.  If n is within the range, return the range index\n        \n        ```\n        if (inRange(n, ranges[i])) {  return i;}\n        ```\n        \n2.  Return `-1` if it makes it through the whole ranges array without returning\n\nIf multiple ranges match, return the first matching one.\n\n### getQueryStringOverride(id: string, url: string, numVariations: integer): null|integer[​](#getquerystringoverrideid-string-url-string-numvariations-integer-nullinteger \"Direct link to getQueryStringOverride(id: string, url: string, numVariations: integer): null|integer\")\n\nThis checks if an experiment variation is being forced via a URL query string. This may not be applicable for all SDKs (e.g. mobile).\n\nAs an example, if the id is `my-test` and url is `http://localhost/?my-test=1`, you would return `1`.\n\nIf possible, you should use a proper URL parsing library vs relying on simple regexes.\n\nReturn `null` if any of these are true:\n\n*   There is no querystring\n*   The id is not a key in the querystring\n*   The variation is not an integer\n*   The variation is less than 0 or greater than or equal to numVariations\n\n### decrypt(encryptedString: string, decryptionKey: string): string[​](#decryptencryptedstring-string-decryptionkey-string-string \"Direct link to decrypt(encryptedString: string, decryptionKey: string): string\")\n\nThis decrypts a string using the AES-CBC 128KB algorithm. This is used if the GrowthBook App is configured to encrypt feature flag definitions.\n\nHere's an example in PHP:\n\n```\nfunction decrypt(string $encryptedString, string $decryptionKey) {  // Split the string into two parts, delimited by \".\"  list($iv, $cipherText) = explode(\".\", $encryptedString, 2);  // The Initialization Vector (iv) is base64 encoded  $iv = base64_decode($iv);  // Decrypt using the AES-CBC 128kb algorithm  // Will throw an Exception if unable to decrypt  return openssl_decrypt($cipherText, \"aes-128-cbc\", $decryptionKey, 0, $iv);}\n```\n\nThe return value will be a JSON-encoded string. If an error occurs, you can throw an exception (or whatever is typically used for error handling).\n\n## Evaluating Conditions[​](#evaluating-conditions \"Direct link to Evaluating Conditions\")\n\nIn addition to the helper functions above, there are a number of methods related to evaluating targeting conditions.\n\nThere is only one public method `evalCondition` and everything else is a private helper function.\n\n### public evalCondition(attributes: Attributes, condition: Condition): boolean[​](#public-evalconditionattributes-attributes-condition-condition-boolean \"Direct link to public evalCondition(attributes: Attributes, condition: Condition): boolean\")\n\nThis is the main function used to evaluate a condition. It loops through the condition key/value pairs and checks each entry:\n\n1.  If condition key is `$or`, check if `evalOr(attributes, condition[\"$or\"])` is false. If so, break out of the loop and return false\n2.  If condition key is `$nor`, check if `!evalOr(attributes, condition[\"$nor\"])` is false. If so, break out of the loop and return false\n3.  If condition key is `$and`, check if `evalAnd(attributes, condition[\"$and\"])` is false. If so, break out of the loop and return false\n4.  If condition key is `$not`, check if `!evalCondition(attributes, condition[\"$not\"])` is false. If so, break out of the loop and return false\n5.  Otherwise, check if `evalConditionValue(value, getPath(attributes, key))` is false. If so, break out of the loop and return false\n\nIf none of the entries failed their checks, `evalCondition` returns true\n\n### private evalOr(attributes: Attributes, conditions: Condition\\[\\]): boolean[​](#private-evalorattributes-attributes-conditions-condition-boolean \"Direct link to private evalOr(attributes: Attributes, conditions: Condition[]): boolean\")\n\n`conditions` is an array of Condition objects\n\n1.  If conditions is empty, return true\n2.  Loop through conditions\n    1.  If `evalCondition(attributes, conditions[i])` is true, break out of the loop and return true\n3.  Return false\n\n### private evalAnd(attributes: Attributes, conditions: Condition\\[\\]): boolean[​](#private-evalandattributes-attributes-conditions-condition-boolean \"Direct link to private evalAnd(attributes: Attributes, conditions: Condition[]): boolean\")\n\n`conditions` is an array of Condition objects\n\n1.  Loop through conditions\n    1.  If `evalCondition(attributes, conditions[i])` is false, break out of the loop and return false\n2.  Return true\n\n### private isOperatorObject(obj): boolean[​](#private-isoperatorobjectobj-boolean \"Direct link to private isOperatorObject(obj): boolean\")\n\nThis accepts a parsed JSON object as input and returns `true` if every key in the object starts with `$`.\n\n*   `{\"$gt\": 1}` -> `true`\n*   `{\"$gt\": 1, \"$lt\": 10}` -> `true`\n*   `{\"foo\": \"bar\"}` -> `false`\n*   `{\"$gt\": 1, \"foo\": \"bar\"}` -> `false`\n\nIf the object is empty and has no keys, this should also return true.\n\n### private getType(attributeValue): string[​](#private-gettypeattributevalue-string \"Direct link to private getType(attributeValue): string\")\n\nThis returns the data type of the passed in argument.\n\nThe valid types to return are:\n\n*   `string`\n*   `number`\n*   `boolean`\n*   `array`\n*   `object`\n*   `null`\n*   `undefined`\n*   `unknown`\n\nThe difference between `null` and `undefined` can be illustrated as follows:\n\n```\nobj = JSON.parse('{\"foo\": null}');getType(obj[\"foo\"]); // nullgetType(obj[\"bar\"]); // undefined\n```\n\nThe value `unknown` is there just in case you can't figure out the data type for whatever reason. It will never be used in most implementations.\n\n### private getPath(attributes: Attributes, path: string): any[​](#private-getpathattributes-attributes-path-string-any \"Direct link to private getPath(attributes: Attributes, path: string): any\")\n\nGiven attributes and a dot-separated path string, return the value at that path (or `null`/`undefined` if the path doesn't exist)\n\nGiven the input:\n\n```\n{  \"name\": \"john\",  \"job\": {    \"title\": \"developer\"  }}\n```\n\nIt should return:\n\n*   `getPath(input, \"name\")` -> `\"john\"`\n*   `getPath(input, \"job.title\")` -> `\"developer\"`\n*   `getPath(input, \"job.company\")` -> `null` or `undefined`\n\n### private evalConditionValue(conditionValue, attributeValue): boolean[​](#private-evalconditionvalueconditionvalue-attributevalue-boolean \"Direct link to private evalConditionValue(conditionValue, attributeValue): boolean\")\n\n1.  If `conditionValue` is an object and `isOperatorObject(conditionValue)` is true\n    1.  Loop over each key/value pair\n        1.  If `evalOperatorCondition(key, attributeValue, value)` is false, return false\n    2.  Return true\n2.  Else, do a deep comparison between `attributeValue` and `conditionValue`. Return true if equal, false if not.\n\n### private elemMatch(conditionValue, attributeValue): boolean[​](#private-elemmatchconditionvalue-attributevalue-boolean \"Direct link to private elemMatch(conditionValue, attributeValue): boolean\")\n\nThis checks if `attributeValue` is an array, and if so at least one of the array items must match the condition\n\n1.  If `attributeValue` is not an array, return false\n2.  Loop through items in `attributeValue`\n    1.  If `isOperatorObject(conditionValue)`\n        1.  If `evalConditionValue(conditionValue, item)`, break out of loop and return true\n    2.  Else if `evalCondition(item, conditionValue)`, break out of loop and return true\n3.  Return false\n\n### private paddedVersionString(input): string[​](#private-paddedversionstringinput-string \"Direct link to private paddedVersionString(input): string\")\n\nThis function can be used to help with the evaluation of the version string comparsion.\n\nThere are 6 operators that are used for comparing version strings, e.g. `v1.2.3` or `1.2.3`:\n\nCondition\n\nComparison\n\nDescription\n\n`$veq`\n\n`==`\n\nVersions are equal\n\n`$vne`\n\n`!=`\n\nVersions are not equal\n\n`$vlt`\n\n`<`\n\nThe first version is lesser than the second version\n\n`$vlte`\n\n`<=`\n\nThe first version is lesser than or equal to the second version\n\n`$vgt`\n\n`>`\n\nThe first version is greater than the second version\n\n`$vgte`\n\n`>=`\n\nThe first version is greater than or equal to the second version\n\nRules:\n\n*   Segments are separated by `.` and `-` characters\n*   Segments should be compared alphanumerically from the left-most segment\n    *   Digit-only segments should be left-padded with a space so that they have the same number of characters.\n*   A leading `v` in a version string should be ignored\n*   Semantic version syntax used to denote build information (as denoted by a `+`, e.g. `+mybuild`) should be ignored for comparisons.\n\nHere's an example:\n\n```\nexport function paddedVersionString(input: string): string {  // Remove build info and leading `v` if any  // Split version into parts (both core version numbers and pre-release tags)  // \"v1.2.3-rc.1+build123\" -> [\"1\",\"2\",\"3\",\"rc\",\"1\"]  const parts = input.replace(/(^v|\\+.*$)/g, \"\").split(/[-.]/);  // If it's SemVer without a pre-release, add `~` to the end  // [\"1\",\"0\",\"0\"] -> [\"1\",\"0\",\"0\",\"~\"]  // \"~\" is the largest ASCII character, so this will make \"1.0.0\" greater than \"1.0.0-beta\" for example  if (parts.length === 3) {    parts.push(\"~\");  }  // Left pad each numeric part with spaces so string comparisons will work (\"9\">\"10\", but \" 9\"<\"10\")  // Then, join back together into a single string  return parts    .map((v) => (v.match(/^[0-9]+$/) ? v.padStart(5, \" \") : v))    .join(\"-\");}\n```\n\n### private isIn(conditionValue, actualValue): boolean[​](#private-isinconditionvalue-actualvalue-boolean \"Direct link to private isIn(conditionValue, actualValue): boolean\")\n\nChecks to see if `actualValue` is in the `conditionValue` array. This implements the `$in` and `$nin` operators.\n\n1.  If `actualValue` is an array\n    1.  Return `true` if the intersection between `actualValue` and `conditionValue` has at least 1 element. Otherwise, return `false`.\n2.  Else\n    1.  Return `true` if `conditionValue` contains `actualValue`. Otherwise, return `false`.\n\n### private evalOperatorCondition(operator, attributeValue, conditionValue)[​](#private-evaloperatorconditionoperator-attributevalue-conditionvalue \"Direct link to private evalOperatorCondition(operator, attributeValue, conditionValue)\")\n\nThis function is just a case statement that handles all the possible operators\n\nThere are basic comparison operators in the form `attributeValue {op} conditionValue`:\n\n*   `$eq` ==\n*   `$ne` != (not equals)\n*   `$lt` <\n*   `$lte` <=\n*   `$gt` >\n*   `$gte` >=\n*   `$regex` ~ (regex match)\n\nThere are 3 operators where conditionValue is an array. All of these should return `false` if `conditionValue` is not an array for whatever reason.\n\n*   `$in`\n    1.  Return `isIn(conditionValue, attributeValue)`\n*   `$nin`\n    1.  Return `not isIn(conditionValue, attributeValue)`\n*   `$all`\n    1.  If attributeValue is not an array, return `false`\n    2.  Loop through conditionValue array\n        1.  If none of the elements in the attributeValue array pass `evalConditionValue(conditionValue[i], attributeValue[j])`, return false\n    3.  Return true\n\nThere are 2 operators where attributeValue is an array:\n\n*   `$elemMatch`\n    1.  Return `elemMatch(conditionValue, attributeValue)`\n*   `$size`\n    1.  If attributeValue is not an array, return false\n    2.  Return `evalConditionValue(conditionValue, attributeValue.length)`\n\nThere are 3 other operators:\n\n*   `$exists`\n    1.  If conditionValue is false, return true if attributeValue is null or undefined\n    2.  Else, return true if attributeValue is NOT null or undefined\n    3.  Return false by default\n*   `$type`\n    1.  Return `getType(attributeValue) == conditionValue`\n*   `$not`\n    1.  Return `!evalConditionValue(conditionValue, attributeValue)`\n\nThere are 6 operators that are used for comparing version strings, e.g. `v1.2.3` or `1.2.3`. See [paddedVersionString(input)](#private-paddedversionstringinput-string) for details.\n\nIf operator doesn't match any of these, return false and potentially log the error for debug purposes.\n\n## GrowthBook Class[​](#growthbook-class \"Direct link to GrowthBook Class\")\n\nThe GrowthBook class is the main export of the SDK.\n\n### constructor[​](#constructor \"Direct link to constructor\")\n\nThe constructor takes a Context object and stores the properties for later. Nothing else needs to be done during initialization.\n\nThis class has a few helper methods as well as 2 main public methods - `evalFeature` and `run`.\n\n### Getters and Setters[​](#getters-and-setters \"Direct link to Getters and Setters\")\n\nThere should be simple getters and setters for a few of the context properties:\n\n*   `attributes`\n*   `features`\n*   `forcedVariations`\n*   `url`\n*   `enabled`\n\n### private getFeatureResult(value, source, experiment, experimentResult): FeatureResult[​](#private-getfeatureresultvalue-source-experiment-experimentresult-featureresult \"Direct link to private getFeatureResult(value, source, experiment, experimentResult): FeatureResult\")\n\nThis is a helper method to create a `FeatureResult` object. The first two arguments, `value`, and `source` are required. The last two, `experiment` and `experimentResult` are optional and should default to `null`.\n\nBesides the passed-in arguments, there are two derived values - `on` and `off`, which are just the value cast to booleans.\n\nvalue can be any JSON type. Only the following values are considered to be \"falsy\":\n\n*   `null`\n*   `false`\n*   `\"\"`\n*   `0`\n\nEverything else is considered \"truthy\", including empty arrays and objects.\n\nIf value is \"truthy\", then `on` should be true and `off` should be false. If the value is \"falsy\", then they should take opposite values.\n\n### private isFilteredOut(filters: Filters\\[\\]): boolean[​](#private-isfilteredoutfilters-filters-boolean \"Direct link to private isFilteredOut(filters: Filters[]): boolean\")\n\nThis is a helper method to evaluate `filters` for both feature flags and experiments.\n\n1.  Loop through filters array\n    \n    1.  Get the hashAttribute and hashValue\n    \n    ```\n    hashAttribute = filter.attribute || \"id\";hashValue = context.attributes[hashAttribute] || \"\";\n    ```\n    \n    2.  If hashValue is empty, return `true`\n    3.  Determine the bucket for the user\n        \n        ```\n        n = hash(filter.seed, hashValue, filter.hashVersion || 2);\n        ```\n        \n    4.  If `inRange(n, range)` is false for every range in `filter.ranges`, return `true`\n2.  If you made it through the entire array without returning early, return `false` now\n\n### private isIncludedInRollout(seed: string, hashAttribute: string | null, range: BucketRange | null, coverage: float | null, hashVersion: integer | null): boolean[​](#private-isincludedinrolloutseed-string-hashattribute-string--null-range-bucketrange--null-coverage-float--null-hashversion-integer--null-boolean \"Direct link to private isIncludedInRollout(seed: string, hashAttribute: string | null, range: BucketRange | null, coverage: float | null, hashVersion: integer | null): boolean\")\n\nDetermines if the user is part of a gradual feature rollout.\n\n1.  Either `coverage` or `range` are required. If both are `null`, return `true` immediately\n    \n2.  If `range` is null and `coverage` is zero, return `false` immediately. This catches an edge case where the bucket is zero and users are let through when they shouldn't be\n    \n3.  Get the hashAttribute and hashValue\n    \n    ```\n    hashAttribute = hashAttribute || \"id\";hashValue = context.attributes[hashAttribute] || \"\";\n    ```\n    \n4.  If `hashValue` is empty, return `false` immediately\n    \n5.  Determine the bucket for the user\n    \n    ```\n    n = hash(seed, hashValue, hashVersion || 1)\n    ```\n    \n6.  Check if user is included\n    \n    ```\n    if (range) { return inRange(n, range)}else if (coverage !== null) { return n <= coverage}return true\n    ```\n    \n\n### private getExperimentResult(experiment, variationIndex, hashUsed, featureId, bucket): ExperimentResult[​](#private-getexperimentresultexperiment-variationindex-hashused-featureid-bucket-experimentresult \"Direct link to private getExperimentResult(experiment, variationIndex, hashUsed, featureId, bucket): ExperimentResult\")\n\nThis is a helper method to create an `ExperimentResult` object. The arguments are:\n\n*   `experiment` - Experiment object (required)\n*   `variationIndex` - The assigned variation index (optional, default to `-1`)\n*   `hashUsed` - Whether or not the hash was used to assign a variation (optional, default to `false`)\n*   `featureId` - The id of the feature (if any) that the experiment came from (optional, default to `null`)\n*   `bucket` - The hash bucket value for the user. Float from `0` to `1` (optional, default to `null`)\n\nThe method is pretty simple:\n\n1.  Handle case when user is not in the experiment (e.g. variationIndex = -1)\n    \n    ```\n    // By default, assume everyone is in the experimentlet inExperiment = true;// If the variation is invalid, use the baseline and set the inExperiment flag to falseif (variationIndex < 0 || variationIndex >= experiment.variations.length) {  variationIndex = 0;  inExperiment = false;}\n    ```\n    \n2.  Get the hashAttribute and hashValue\n    \n    ```\n    hashAttribute = experiment.hashAttribute || \"id\";hashValue = context.attributes[hashAttribute] || \"\";\n    ```\n    \n3.  Get meta info for the assigned variation (if any)\n    \n    ```\n    meta = experiment.meta ? experiment.meta[variationIndex] : null\n    ```\n    \n4.  Build return object\n    \n    ```\n    res = {  key: (meta && meta.key) ? meta.key : (\"\" + variationIndex),  featureId: featureId,  inExperiment: inExperiment,  hashUsed: hashUsed,  variationId: variationIndex,  value: experiment.variations[variationIndex],  hashAttribute: hashAttribute,  hashvalue: hashValue,};\n    ```\n    \n5.  Add optional properties and return\n    \n    ```\n    if (meta && meta.name) res.name = meta.name;if (meta && meta.passthrough) res.passthrough = true;if (bucket !== null) res.bucket = bucket;return res;\n    ```\n    \n\n### public evalFeature(key: string): FeatureResult[​](#public-evalfeaturekey-string-featureresult \"Direct link to public evalFeature(key: string): FeatureResult\")\n\nThe `evalFeature` method takes a single string argument, which is the unique identifier for the feature and returns a `FeatureResult` object.\n\n```\ngrowthbook = new GrowthBook(context);myFeature = growthbook.evalFeature(\"my-feature\");\n```\n\nThere are a few ordered steps to evaluate a feature\n\n1.  If the key doesn't exist in `context.features`\n    1.  Return `getFeatureResult(null, \"unknownFeature\")`\n2.  Loop through the feature rules (if any)\n    1.  If the rule has `parentConditions` (prerequisites) defined, loop through each one:\n        1.  Call `evalFeature` on the parent condition\n            *   If a cycle is detected, break out of feature evaluation and return `getFeatureResult(null, \"cyclicPrerequisite\")`\n        2.  Using the evaluated parent's result, create an object\n            \n            ```\n            const evalObj = { \"value\": parentResult.value }\n            ```\n            \n        3.  Evaluate this object against the parentCondition's condition:\n            \n            ```\n            evalCondition(evalObj, parentResult.value);\n            ```\n            \n        4.  If any of the parentConditions fail evaluation then:\n            *   If `parentCondition.gate` is true (a blocking prerequisite), return `getFeatureResult(null, \"prerequisite\")`\n            *   Otherwise, skip this rule and continue to the next one\n    2.  If the rule has `filters` defined\n        1.  if `isFilteredOut(rule.filters)`, skip this rule and continue to the next one\n    3.  If the rule has a `condition`\n        1.  If `evalCondition(context.attributes, rule.condition)` is false, skip this rule and continue to the next one\n    4.  If `rule.force` is set\n        1.  If not `isIncludedInRollout`, skip this rule and continue to the next one\n            \n            ```\n            if (!isIncludedInRollout(  rule.seed || featureKey,  rule.hashAttribute,  rule.range,  rule.coverage,  rule.hashVersion)) { continue;}\n            ```\n            \n        2.  If `rule.tracks` is set, fire the `TrackingCallback` for each element in the `rule.tracks` array.\n        3.  Return `getFeatureResult(rule.force, \"force\")`\n    5.  Otherwise, convert the rule to an Experiment object\n        \n        ```\n        const exp = {  variations: rule.variations,  key: rule.key || featureKey,};\n        ```\n        \n    6.  Copy over additional settings from the rule to `exp` if defined:\n        *   `coverage`\n        *   `weights`\n        *   `hashAttribute`\n        *   `fallbackAttribute`\n        *   `disableStickyBucketing`\n        *   `bucketVersion`\n        *   `minBucketVersion`\n        *   `namespace`\n        *   `meta`\n        *   `ranges`\n        *   `name`\n        *   `phase`\n        *   `seed`\n        *   `hashVersion`\n        *   `filters`\n        *   `condition`\n    7.  Run the experiment\n    8.  If `result.inExperiment` is false OR `result.passthrough` is true, skip this rule and continue to the next one\n    9.  Otherwise, return\n        \n        ```\n        return getFeatureResult(result.value, \"experiment\", exp, result);\n        ```\n        \n3.  Return `getFeatureResult(feature.defaultValue || null, \"defaultValue\")`\n\n### public run(experiment: Experiment): ExperimentResult[​](#public-runexperiment-experiment-experimentresult \"Direct link to public run(experiment: Experiment): ExperimentResult\")\n\nThe `run` method takes an Experiment object and returns an `ExperimentResult`.\n\nThere are a bunch of ordered steps to run an experiment:\n\n1.  If `experiment.variations` has fewer than 2 variations, return `getExperimentResult(experiment)`\n2.  If `context.enabled` is false, return `getExperimentResult(experiment)`\n3.  If `context.url` exists\n    \n    ```\n    qsOverride = getQueryStringOverride(experiment.key, context.url);if (qsOverride != null) {  return getExperimentResult(experiment, qsOverride);}\n    ```\n    \n4.  Return if forced via context\n    \n    ```\n    if (experiment.key in context.forcedVariations) {  return getExperimentResult(    experiment,    context.forcedVariations[experiment.key]  );}\n    ```\n    \n5.  If `experiment.active` is set to false, return `getExperimentResult(experiment)`\n6.  Get the user hash value and return if empty\n    \n    ```\n    hashAttribute = experiment.hashAttribute || \"id\";hashValue = context.attributes[hashAttribute] || \"\";if (hashValue == \"\") {  if (experiment.fallbackAttribute && context.attributes[experiment.fallbackAttribute]) {    // check if a fallbackAttribute exists (sticky bucketing)    hashAttribute = experiment.fallbackAttribute;    hashValue = context.attributes[hashAttribute];  } else {    // no hashAttribute or fallbackAttribute, return    return getExperimentResult(experiment);  }}\n    ```\n    \n    6.5 If sticky bucketing is permitted, check to see if a sticky bucket value exists. If so, skip steps 7-8.\n7.  Apply filters and namespace\n    1.  If `experiment.filters` is set\n        \n        ```\n        if (isFilteredOut(experiment.filters)) { return getExperimentResult(experiment)}\n        ```\n        \n    2.  Else if `experiment.namespace` is set, return if not in range\n        \n        ```\n        if (!inNamespace(hashValue, experiment.namespace)) { return getExperimentResult(experiment);}\n        ```\n        \n8.  Return if any conditions are not met, return\n    \n    1.  If `experiment.condition` is set, return if it evaluates to false\n    \n    ```\n    if (!evalCondition(context.attributes, experiment.condition)) {  return getExperimentResult(experiment);}\n    ```\n    \n    2.  If `experiment.parentConditions` is set (prerequisites), return if any of them evaluate to false. See the corresponding logic in **evalFeature** for more details. (Note that the `gate` flag should not be set in an experiment)\n    3.  Apply any url targeting based on experiment.urlPatterns, return if no match\n9.  Choose a variation\n    1.  If a sticky bucket value exists, use it.\n        1.  If the found sticky bucket version is blocked (doesn't exceed `experiment.minBucketVersion`), then skip enrollment\n    2.  Else, calculate bucket ranges for the variations and choose one\n        \n        ```\n        ranges = experiment.ranges || getBucketRanges(  experiment.variations.length,  experiment.converage ?? 1,  experiment.weights ?? []);n = hash(  experiment.seed || experiment.key,  hashValue,  experiment.hashVersion || 1);assigned = chooseVariation(n, ranges);\n        ```\n        \n10.  If assigned == `-1`, return `getExperimentResult(experiment)`\n11.  If experiment has a forced variation, return\n    \n    ```\n    if (\"force\" in experiment) {  return getExperimentResult(experiment, experiment.force);}\n    ```\n    \n12.  If `context.qaMode`, return `getExperimentResult(experiment)`\n13.  Build the result object\n    \n    ```\n    result = getExperimentResult(experiment, assigned, true, n);``13.5 If sticky bucketing is permitted, store the sticky bucket value\n    ```\n    \n14.  Fire `context.trackingCallback` if set and the combination of hashAttribute, hashValue, experiment.key, and variationId has not been tracked before\n15.  Return `result`\n\n### Feature helper methods[​](#feature-helper-methods \"Direct link to Feature helper methods\")\n\nThere are 3 tiny helper methods that wrap `evalFeature` for a better developer experience:\n\n```\npublic isOn(key) {  return this.evalFeature(key).on}public isOff(key) {  return this.evalFeature(key).off}public getFeatureValue(key, fallback) {  value = this.evalFeature(key).value  return value === null ? fallback : value}\n```\n\nFor strongly typed languages, you can use generics (if supported) for `getFeatureValue` and coerce the return value to always match the data type of fallback. If generics are not supported, you can use type-specific versions of the function such as `getFeatureValueAsString`.\n\n## Fetching and Caching Features[​](#fetching-and-caching-features \"Direct link to Fetching and Caching Features\")\n\nWhen the Context contains a `clientKey`, the SDK should fetch and cache features automatically.\n\nIf `apiHost` is not specified, default to `https://cdn.growthbook.io`. Make sure to strip and trailing slashes on user-entered hosts (e.g. `http://example.com/` becomes `http://example.com`).\n\nFeatures should be fetched from `{apiHost}/api/features/{clientKey}` and all errors should be handled gracefully. A network error while fetching features should never be a fatal error that stops execution.\n\nThe API responses should be parsed and cached so future GrowthBook instances with the same clientKey can avoid a duplicate network request. The standard cache TTL to use is 60 seconds.\n\nFor best performance, a stale-while-revalidate pattern should be used. If a cache entry is older than the TTL, return the cached value immediately and start a background process to update the cache from the API.\n\nThe initial download should be intiated by a `growthbook.loadFeatures()` method call. This method may take optional parameters, such as `timeout` or `skipCache`, if it makes sense.\n\nThere should be an easy way for the user to wait until features finish loading. Depending on the language, this might be an event emitter, a Promise, a callback, or something similar. Use whatever method is standard for the language.\n\n### Server-Sent Events[​](#server-sent-events \"Direct link to Server-Sent Events\")\n\nThe API response (`/api/features/{clientKey}`) may contain a response header:\n\n> x-sse-support: enabled\n\nIf set to \"enabled\", you are able to subscribe to the API for realtime changes to feature definitions by using the [GrowthBook Proxy](https://docs.growthbook.io/self-host/proxy). This will let you update the cache immediately when a feature changes instead of waiting for the 60s TTL to expire.\n\nThe URL for subscribing to changes is `{apiHost}/sub/{clientKey}`.\n\nSDKs should not attempt to subscribe to the `/sub/` endpoint unless the header `x-sse-support: enabled` is present on the `/api/features` endpoint response.\n\nAn example implementation in JavaScript is below:\n\n```\nconst channel = new EventSource(`${apiHost}/sub/${clientKey}`);channel.addEventListener(\"features\", (event) => {  const data = JSON.parse(event.data);  cache.set(clientKey, data.features);})\n```\n\nSome important things to note:\n\n*   The SDK should implement reconnect logic to support both client and server dropping the connection.\n*   The response will be the same as when fetching from the `/api/features/{clientKey}` endpoint\n\n### Encrypted Features[​](#encrypted-features \"Direct link to Encrypted Features\")\n\nThe `/api/features/{clientKey}` endpoint can have encryption enabled (128-bit AES-CBC). When this is the case, the API response will look like this:\n\n```\n{  \"features\": {},  \"encryptedFeatures\": \"abcdef123456.ghijklmnop789jksdkfaksfadfasdfkahsfa\"}\n```\n\nBefore you can use this response, you will need to decrypt it. This requires the user to set `Context.decryptionKey` when creating the GrowthBook instance.\n\n## Type Hinting[​](#type-hinting \"Direct link to Type Hinting\")\n\nMost languages have some sort of strong typing support, whether in the language itself or via annotations. This helps to reduce errors and is highly encouraged for SDKs.\n\nIf possible, use generics to type the return value. For example, if `experiment.variations` is type `T[]`, then `result.value` should be type `T`. Or, if the fallback of `getFeatureValue` is type `string`, the return type should also be type `string`.\n\n## Handling Errors[​](#handling-errors \"Direct link to Handling Errors\")\n\nThe general rule is to be strict in development and lenient in production.\n\nYou can throw exceptions in development, but someone's production app should never crash because of a call to `growthbook.evalFeature` or `growthbook.run`.\n\nFor the below edge cases in production, just act as if the problematic property didn't exist and ignore errors:\n\n*   `experiment.weights` is a different length from `experiment.variations`\n*   `experiment.weights` adds up to something other than 1\n*   `experiment.coverage` or `feature.coverage` is greater than 1 or less than 0\n*   `context.trackingCallback` throws an error\n*   URL querystring specifies an invalid variation index\n\nFor the below edge cases in production, the experiment should be disabled (everyone gets assigned variation `0`):\n\n*   `experiment.coverage` is less than 0\n*   `experiment.force` specifies an invalid variation index\n*   `context.forcedVariations` specifies an invalid variation index\n*   `experiment.hashAttribute` is an empty string\n\n## Subscriptions[​](#subscriptions \"Direct link to Subscriptions\")\n\nSometimes it's useful to be able to \"subscribe\" to a GrowthBook instance and be alerted every time `growthbook.run` is called. This is different from the tracking callback since it also fires when a user is _not_ included in an experiment.\n\n```\ngrowthbook.subscribe(function (experiment, result) {  // do something});\n```\n\nIt's best to only re-fire the callbacks for an experiment if the result has changed. That means either the `inExperiment` flag has changed or the `variationId` has changed.\n\nIf it makes sense for your language, this function should return an \"unsubscriber\". A simple callback that removes the subscription.\n\n```\nunsubscriber = growthbook.subscribe(...)unsubscriber()\n```\n\nIn addition to subscriptions you may also want to expose a `growthbook.getAllResults` method that returns a map of the latest results indexed by experiment key.\n\n## Memory Management[​](#memory-management \"Direct link to Memory Management\")\n\nSubscriptions and tracking calls require storing references to many objects and functions. If it makes sense for your language, libraries should provide a `growthbook.destroy` method to remove all of these references and release their memory.\n\n## Tests[​](#tests \"Direct link to Tests\")\n\nWe strive to have 100% test coverage for all of our SDKs.\n\nThere is a language-agnostic test suite stored as a JSON file ([https://github.com/growthbook/growthbook/blob/main/packages/sdk-js/test/cases.json](https://github.com/growthbook/growthbook/blob/main/packages/sdk-js/test/cases.json)) with more than 400 unit tests. This extensively tests all of the public methods mentioned above.\n\nThe cases.json file is an object. The keys are the function being tested, and the values are arrays of test cases. The test case arrays structure is different for each function and listed below:\n\n*   **evalCondition**\n    *   name of the test case (string)\n    *   condition\n    *   attributes\n    *   expected return value (boolean)\n    *   definitions for Saved Groups referenced in the test case (object of keys: ID of list -> values: array of members)\n*   **hash**\n    *   seed (string)\n    *   value to hash (string)\n    *   hash version to use (integer)\n    *   expected result (float)\n*   **getBucketRange**\n    *   Name of the test case (string)\n    *   Arguments array (\\[numVariations, coverage, weights or null\\])\n    *   expected result\n*   **feature** (evalFeature)\n    *   name of the test case (string)\n    *   context passed into GrowthBook constructor\n    *   name of the feature (string)\n    *   expected result\n*   **run**\n    *   name of the test case (string)\n    *   context passed into GrowthBook constructor\n    *   experiment object\n    *   expected value\n    *   inExperiment (boolean)\n    *   hashUsed (boolean)\n*   **chooseVariation**\n    *   name of the test case (string)\n    *   n (hash)\n    *   bucket ranges\n    *   expected result\n*   **getQueryStringOverride**\n    *   name of the test case (string)\n    *   experiment key\n    *   url\n    *   numVariations\n    *   expected result\n*   **inNamespace**\n    *   name of the test case (string)\n    *   id\n    *   namespace\n    *   expected result\n*   **getEqualWeights**\n    *   numVariations\n    *   expected result (weights rounded to 8 decimal places)\n*   **decrypt**\n    *   name of the test case (string)\n    *   encrypted text (string)\n    *   decryption key (string)\n    *   expected result (string or `null` if the decryption should fail)\n*   **stickyBucket**\n    *   name of the test case (string)\n    *   context passed into GrowthBook constructor\n    *   array of preexisting sticky bucket assignment docs\n    *   name of the feature (string)\n    *   expected result\n    *   expected sticky bucket assignment docs\n*   **urlRedirect**\n    *   name of the test case (string)\n    *   context passed into GrowthBook constructor\n    *   expected array of result objects\n\nIn addition to the above, you should write custom test cases for things like event subscriptions, tracking callbacks, getters/setters, etc. that are more language-specific.\n\n## Getting Help[​](#getting-help \"Direct link to Getting Help\")\n\nJoin our [Slack community](https://slack.growthbook.io/?ref=docs-buildyourown) if you need help or want to chat. We're also happy to hop on a call and do some pair programming.\n\n## Attribution[​](#attribution \"Direct link to Attribution\")\n\nOpen a [GitHub issue](https://github.com/growthbook/growthbook/issues) with a link to your project and we'll make sure we add it to our docs and give you proper credit for your hard work.\n\n## Changelog[​](#changelog \"Direct link to Changelog\")\n\n*   **v0.1** 2022-05-23\n    *   Don't skip experiment rules that are forced\n*   **v0.2** 2022-07-19\n    *   Add `featureId` to ExperimentResult object\n*   **v0.2.1** 2022-08-01\n    *   Add test case for when an experiment's hashAttribute is `null`\n*   **v0.2.2** 2022-09-08\n    *   Add test case for when an experiment's hashAttribute is an integer\n*   **v0.2.3** 2022-12-06\n    *   Add test case for when an experiment's coverage is set to 0\n*   **v0.3.0** 2023-01-18\n    *   New `apiHost`, `clientKey`, and `decryptionKey` Context properties\n    *   Built-in fetching and caching\n    *   Server Sent Events (SSE) support for realtime feature updates\n*   **v0.4.0** 2023-02-24\n    *   Changed signature of `hash` method and added multiple hashing versions\n    *   New `inRange`, `isIncludedInRollout`, and `isFilteredOut` helper methods\n    *   New `hashVersion`, `range`, `ranges`, `meta`, `filters`, `seed`, `name`, `tracks`, and `phase` properties of FeatureRules\n    *   New `hashVersion`, `ranges`, `meta`, `filters`, `seed`, `name`, and `phase` properties of Experiments\n    *   New `key`, `name`, `bucket`, and `passthrough` fields in Experiment Results\n    *   New `Filter`, `VariationMeta`, and `TrackData` data structures\n*   **v0.4.1** 2023-04-13\n    *   Added `decrypt` function and set of test cases\n    *   `hash` function now returns `null` instead of `-1` when an invalid hashVersion is specified\n    *   Fixed broken feature test case (was using `[0.99]` instead of `0.99` for coverage)\n*   **v0.4.2** 2023-04-30\n    *   Add test cases when targeting condition value is `null`\n*   **v0.5.0** 2023-05-17\n    *   Add support for new version string comparison operators (`$veq`, `$vne`, `$vgt`, `$vgte`, `$vlt`, `$vlte`) and new `paddedVersionString` helper function\n    *   New `isIn` helper function for conditions, plus new evalCondition test cases for `$in` and `$nin` operators when attribute is an array\n*   **v0.5.1** 2023-10-19\n    *   Add 2 new test cases for matching on a `$groups` array attribute\n*   **v0.5.2** 2023-10-30\n    *   Add 3 new test cases for comparison operators to handle more edge cases\n*   **v0.5.3** 2024-01-02\n    *   Experiment conditions are now evaluated within the experiment object\n    *   New `fallbackAttribute`, `disableStickyBucketing`, `bucketVersion`, `minBucketVersion`, properties of FeatureRules\n    *   New `fallbackAttribute`, `disableStickyBucketing`, `bucketVersion`, `minBucketVersion`, properties of Experiments\n    *   Add `stickyBucketUsed` to ExperimentResult object\n*   **v0.5.4** 2024-02-23\n    *   New `parentConditions` property of FeatureRules\n    *   New `parentConditions` property of Experiments\n*   **v0.5.5** 2024-04-09\n    *   Add test cases for URL Redirects\n    *   Add `navigate` method to Context\n    *   Add `persistQueryString` property to Experiment\n    *   Add and improve test cases for StickyBucket\n*   **v0.6.0** 2024-04-30\n    *   Remove `versionCompare` test cases (these are now just included as part of `evalCondition`)\n    *   Tweak to `isIncludedInRollout` to handle an edge case when coverage is zero. Also added test case for this.\n    *   Add `id` property to feature rules (reserved for future use)\n*   **v0.6.1** 2024-05-13\n    *   Update logic in `evalCondition` to allow for and/or/not/nor operators to appear at the same level as other conditions\n    *   Added test cases for multiple operators on the same level\n*   **v0.7.0** 2024-06-25\n    *   New Operators `$inGroup` and `$notInGroup` to check Saved Groups by reference\n    *   Add argument to `evalCondition` for definition of Saved Groups\n    *   Add test cases for `evalCondition`, `feature`, and `run` using the new operators",
  "title": "Build Your Own | GrowthBook Docs",
  "description": "This guide is meant for library authors looking to build a GrowthBook SDK in a currently unsupported language.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/self-host",
  "markdown": "# Self-Hosting GrowthBook | GrowthBook Docs\n\nGrowthBook consists of a NextJS front-end, an ExpressJS API, and a Python stats engine. Everything is bundled together in a single [Docker Image](https://hub.docker.com/r/growthbook/growthbook).\n\nIn addition to the app itself, you will also need a MongoDB instance to store login credentials, cached experiment results, and metadata.\n\ntip\n\nDon't want to install or host the app yourself? [GrowthBook Cloud](https://app.growthbook.io/) is a fully managed version that's free to get started.\n\n## Installation[​](#installation \"Direct link to Installation\")\n\nYou can use **docker-compose** to get started quickly:\n\n```\n# docker-compose.ymlversion: \"3\"services:  mongo:    image: \"mongo:latest\"    environment:      - MONGO_INITDB_ROOT_USERNAME=root      - MONGO_INITDB_ROOT_PASSWORD=password    volumes:      - mongodata:/data/db  growthbook:    image: \"growthbook/growthbook:latest\"    ports:      - \"3000:3000\"      - \"3100:3100\"    depends_on:      - mongo    environment:      - MONGODB_URI=mongodb://root:password@mongo:27017/growthbook?authSource=admin    volumes:      - uploads:/usr/local/src/app/packages/back-end/uploadsvolumes:  uploads:  mongodata:\n```\n\nThen, just run `docker-compose up -d` to start everything and view the app at [http://localhost:3000](http://localhost:3000/)\n\ncaution\n\nThe use of the mongo image within the docker-compose.yml is meant to quickly get a dev or staging environment up and running. For production you may want to use a more scalable and stable solution (ie. AWS DocumentDB, Google Cloud MongoDB Atlas, Azure Cosmos DB for Mongo, etc.) You may also want to have a [Growthbook Proxy](https://docs.growthbook.io/self-host/proxy) running as well for speed, scalability, sercurity, and real-time feature rollouts.\n\nBuilds are published automatically from the [GitHub repo](https://github.com/growthbook/growthbook) main branch. The most recent commit is tagged with `latest`.\n\nGitHub Releases are also tagged using SemVer (e.g. `0.2.1`).\n\nIf you need to reference the image for a specific git commit for any reason, you can use the git shorthash tag (e.g. `git-41278e9`).\n\n## Updating to Latest[​](#updating-to-latest \"Direct link to Updating to Latest\")\n\nIf you are using docker-compose, and assuming you specify the growthbook container with `:latest`, you can update with:\n\n```\ndocker-compose pull growthbookdocker-compose stop growthbookdocker-compose up -d growthbook\n```",
  "title": "Self-Hosting GrowthBook | GrowthBook Docs",
  "description": "Learn how to set a self-hosted version of GrowthBook",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/app/api",
  "markdown": "# API | GrowthBook Docs\n\n## API\n\nbeta\n\nGrowthBook offers a full REST API for interacting with the GrowthBook application. This is currently in **beta** as we add more authenticated API routes and features.\n\n[View REST API Docs](https://docs.growthbook.io/api/)\n\n## SDK Connection Endpoints[​](#sdk-connection-endpoints \"Direct link to SDK Connection Endpoints\")\n\nIn addition to the REST API above, there is one additional readonly endpoint - the SDK Connection Endpoint.\n\nThe SDK Connection Endpoint provides readonly access to a subset of your feature flag data, just enough for the [GrowthBook SDKs](https://docs.growthbook.io/lib) to assign values to users. They are meant to be public and do not require authentication to view.\n\nIn **GrowthBook Cloud**, the SDK Connection Endpoints are served from our global CDN: `https://cdn.growthbook.io/api/features/...`. If you are self-hosting, you can run the [GrowthBook Proxy server](https://docs.growthbook.io/self-host/proxy), which provides built-in caching and performance optimizations.\n\nSDK Connection Endpoints are scoped to a single Environment (e.g. `dev` or `production`) and can also be scoped to a single Project. Manage all of your SDK Connections on the **Features → SDKs** page.\n\nTypescript Type Definition\n\n```\ninterface SDKEndpointResponse {  status: 200;  features: {    [key: string]: FeatureDefinition  }}interface FeatureDefinition {  defaultValue: any;  rules?: FeatureDefinitionRule[];}interface FeatureDefinitionRule {  force?: any;  weights?: number[];  variations?: any[];  hashAttribute?: string;  hashVersion?: number;  seed?: string;  namespace?: [string, number, number];  key?: string;  coverage?: number;  condition?: any;  meta?: VariationMeta[];  name?: string;  phase?: string;}interface VariationMeta = {  passthrough?: boolean;  key?: string;  name?: string;}\n```\n\nExample JSON object\n\n```\n{  \"status\": 200,  \"features\": {    \"feature-key\": {      \"defaultValue\": true    },    \"another-feature\": {      \"defaultValue\": \"blue\",      \"rules\": [        {          \"condition\": {            \"browser\": \"firefox\"          },          \"force\": \"green\"        }      ]    }  }}\n```\n\n### Encryption[​](#encryption \"Direct link to Encryption\")\n\nIf you've enabled encryption for your SDK endpoint, the response format changes:\n\nTypescript Type Definition\n\n```\ninterface SDKEncryptedEndpointResponse {  status: 200;  encryptedFeatures: string;}\n```\n\nExample JSON object\n\n```\n{  \"status\": 200,  \"encryptedFeatures\": \"abcdef123456GHIJKL0987654321...\"}\n```\n\nYou will need to decrypt the features first before passing into the SDK. Our front-end SDKs (Javascript and React) handle this for you automatically and we're in the process of adding built-in support to our other SDKs.",
  "title": "API | GrowthBook Docs",
  "description": "API",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/app/webhooks",
  "markdown": "# Webhooks Overview | GrowthBook Docs\n\nGrowthBook provides a variety of different outbound webhooks, all of which enable push communication from the GrowthBook server to applications. We will briefly discuss the different types of webhooks that GrowthBook supports and when you might want to use them.\n\n### Event Webhooks[​](#event-webhooks \"Direct link to Event Webhooks\")\n\n**See: [Event Webhooks](https://docs.growthbook.io/app/webhooks/event-webhooks)**  \nAccess via: **Settings → Webhooks**\n\nThese trigger when GrowthBook's state changes. For example, sending a detailed message about how a feature was modified or a new experiment was created. Filterable by project, environment, and event type(s).\n\n##### Common Use Cases:[​](#common-use-cases \"Direct link to Common Use Cases:\")\n\n*   Pinging an internal monitoring service\n*   Maintaining a custom audit log\n*   Messaging on Slack or Discord\n\nEvent webhooks can be formatted for Slack and Discord out of the box. For integration details, see:\n\n*   [Slack Integration](https://docs.growthbook.io/integrations/slack)\n*   [Discord Integration](https://docs.growthbook.io/integrations/discord)\n\n### SDK Webhooks[​](#sdk-webhooks \"Direct link to SDK Webhooks\")\n\n**See: [SDK Webhooks](https://docs.growthbook.io/app/webhooks/sdk-webhooks)**  \nAccess via: **SDK Configuration → SDK Connections**, choose a connection, click **Add Webhook**\n\nThese are tightly coupled with your SDK Connections. They trigger whenever the connection's SDK payload (feature and experiment definitions) changes. They can optionally send the new SDK payload.\n\n##### Common Use Cases:[​](#common-use-cases-1 \"Direct link to Common Use Cases:\")\n\n*   Updating or flushing CDN cache\n*   Updating a cache microservice\n*   Pushing feature/experiment updates to your application\n\n### Global SDK Webhooks[​](#global-sdk-webhooks \"Direct link to Global SDK Webhooks\")\n\n**See: [Global SDK Webhooks](https://docs.growthbook.io/app/webhooks/global-sdk-webhooks)**\n\nGlobal SDK Webhooks are limited to self-hosted users only.\n\nThese are similar to SDK webhooks, but are not limited to a single SDK Connection. Instead, GrowthBook will fire _all_ SDK Connection changes to one or more webhooks, which are defined via environment variables.\n\n##### Use Cases:[​](#use-cases \"Direct link to Use Cases:\")\n\n*   For larger organizations, this saves the trouble of needing to manually configure hundreds of individual SDK Webhooks for each connection.\n*   This pattern is especially common for multi-org installations of GrowthBook.\n\n### GrowthBook Proxy Webhook[​](#growthbook-proxy-webhook \"Direct link to GrowthBook Proxy Webhook\")\n\n**See: [GrowthBook Proxy documentation](https://docs.growthbook.io/self-host/proxy)**\n\nSimilar to SDK webhooks, this webhook is a special use webhook for communicating with the GrowthBook Proxy. Unlike SDK webhooks, proxy webhooks are not customizable.\n\n*   Self-hosted users should configure a single global proxy webhook using environment variables.\n*   Cloud users may optionally configure a GrowthBook Proxy webhook for each SDK Connection.\n\n## Notable Mentions[​](#notable-mentions \"Direct link to Notable Mentions\")\n\nLess common or soon-to-be-deprecated webhooks:\n\n### Legacy Webhooks[​](#legacy-webhooks \"Direct link to Legacy Webhooks\")\n\nThese function similarly to SDK Webhooks. They should not be used going forward; existing legacy webhooks will likely be migrated to SDK Webhooks during a future GrowthBook version release.\n\n### Fastly CDN Purge Webhook[​](#fastly-cdn-purge-webhook \"Direct link to Fastly CDN Purge Webhook\")\n\nIf you are using Fastly as your CDN, and have defined surrogate keys for each SDK endpoint, you can pass `FASTLY_SERVICE_ID` and `FASTLY_API_TOKEN` into your environment variables to enable automatic cache purging. However, we recommend using SDK Webhooks for more control and flexibility.",
  "title": "Webhooks Overview | GrowthBook Docs",
  "description": "An overview of the various webhooks that exist in GrowthBook",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/integrations/slack",
  "markdown": "# Slack integration | GrowthBook Docs\n\nThe GrowthBook Slack integration allows you to receive alerts for the events that you care about in a Slack channel of your choosing.\n\nNew\n\nThe GrowthBook Slack integration is a brand new feature. If you experience any issues, let us know either on [Slack](https://slack.growthbook.io/) or [create an issue](https://github.com/growthbook/growthbook-sdk-java/issues).\n\n## Creating and configuring an app in Slack[​](#creating-and-configuring-an-app-in-slack \"Direct link to Creating and configuring an app in Slack\")\n\n### Create a Slack app[​](#create-a-slack-app \"Direct link to Create a Slack app\")\n\nThe first step to setting up the GrowthBook Slack integration is to create a new app under your workspace's owned apps. You will need administrative privileges for your workspace in order to be able to manage apps.\n\nNavigate to your workspace’s apps and choose to create a new app. You can get to that page directly [here](https://api.slack.com/apps?new_app=1).\n\n![](https://docs.growthbook.io/assets/images/slack-create-app-25002ff66d7fbb85e4a823e687053850.png)\n\nName the app and choose the workspace. In this case we are created the app named GrowthBook Alerts and are picking the GrowthBook Dev workspace.\n\n![](https://docs.growthbook.io/assets/images/slack-name-app-choose-workspace-faf55662a5072c9c2eff289b855b0cd2.png)\n\n### Create an Incoming Webhook[​](#create-an-incoming-webhook \"Direct link to Create an Incoming Webhook\")\n\nWe will be alerting via Slack's incoming webhooks functionality. Under the **Basic Information** tab of your app, click on **Incoming Webhooks**.\n\n![](https://docs.growthbook.io/assets/images/slack-incoming-webhooks-d0d8cf0c2975a55681d3eaf042dc5b1b.png)\n\n### Subscribe a channel to alerts[​](#subscribe-a-channel-to-alerts \"Direct link to Subscribe a channel to alerts\")\n\nClick on the button at the bottom of the **Incoming Webhooks** page that says **Add New Webhook to Workspace**.\n\nYou will be asked to install the app into your workspace. Choose the desired channel you'd like to receive notifications in.\n\n![](https://docs.growthbook.io/assets/images/slack-install-flow-41d350633457e3a670be071092e8a91a.png)\n\nOnce you've completed this flow, you will see a URL available for you to copy. Save this value for later.\n\n![](https://docs.growthbook.io/assets/images/slack-copy-webhook-url-486bc547426412808f41155d28f2fff1.png)\n\n## Add the Slack integration to GrowthBook[​](#add-the-slack-integration-to-growthbook \"Direct link to Add the Slack integration to GrowthBook\")\n\nNext step is to login to the GrowthBook app and visit the **Webhooks** tab under **Settings**, also available [here](https://app.growthbook.io/settings/webhooks). You will need privileges to manage webhooks in order for this menu item to be available.\n\nClick the **Create an Event Webhook** button. You should see a modal pop up with some fields for configuring the Slack notification webhook.\n\n![](https://docs.growthbook.io/assets/images/new-webhook-8cf3a4bd099ba7024f022712027542eb.png)\n\nThen, configure the following:\n\n*   **Name**: The name of the integration. In case you have multiple integrations, this can help you tell them apart. This will also show in the contextual text alongside the alerts.\n*   **Endpoint URL**: Copy and paste the webhook URL provided by your slack app.\n*   **Payload**: Select the `Slack` payload.\n*   **Event filters**: You can optionally filter by events you care about. For example, if you only care about when features are deleted, you can choose `feature.deleted` from the list. If you care about all events, leave this blank.\n*   **Environment filters**: You can optionally choose to filter by environment. For example, if you only want to hear about events that are for the production environment, you can choose `production` from the list. For all environments, leave this blank.\n*   **Project filters**: You can optionally choose to filter by project. For example, if you have a project named \"Onboarding V2\" and you only want to alert for that project, you can choose that project from the projects list. For all projects, leave this blank.\n*   **Tag filters**: You can optionally choose to filter by tag. For all events regardless of tag, leave this blank.\n\nAfter configuring all the fields, press **Create** to save your new Slack notification webhook.\n\nYou can also edit these fields at any point if you make a mistake.\n\n![](https://docs.growthbook.io/assets/images/edit-webhook-230f339ce05e40edc9de0b89d8c2fa87.png)\n\n### Adding more alerts[​](#adding-more-alerts \"Direct link to Adding more alerts\")\n\nIf you'd like to be alerted in another Slack channel, you can add another Incoming Webhook in Slack.\n\nThen, you can create new integrations in the GrowthBook dashboard, specifying all of the same information except adding your new webhook URL.\n\n## Testing your alerts[​](#testing-your-alerts \"Direct link to Testing your alerts\")\n\nYou are now ready to test your alerts. First, you can hit the `Test` button on the webhook settings page. This should trigger a test notification.\n\nNext, perform one of the actions you're watching if you've added Event filters. If you haven't added any event filters, the quickest way to test it's working is to either create a new test feature (then delete it if it's not needed), or toggle an environment on or off for an existing feature.",
  "title": "Slack integration | GrowthBook Docs",
  "description": "The GrowthBook Slack integration allows you to receive alerts for the events that you care about in a Slack channel of your choosing.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/account/user-permissions",
  "markdown": "# User & Team Permissions | GrowthBook Docs\n\nIn the context of GrowthBook, a user, or member, is an individual who has access to your organization's GrowthBook account. Each user is assigned a role that determines the level of access they have within the application. GrowthBook offers a range of roles, from `No Access` to `Admin` and even custom roles, each with a specific set of permissions (see below). GrowthBook's user permissions system allows organizations to define the level of access each user has within the application. This granular control ensures that users can only access the resources they need to perform their job, enhancing security and privacy.\n\n## Adding Users[​](#adding-users \"Direct link to Adding Users\")\n\nTeam members can be added to your GrowthBook account via the `Settings` → `Members` page. From this main page, you'll see an \"Invite Member\" button on the right. If you do not see this button, you do not have permission to add members to your organization. Clicking on \"Invite Member\" will open a modal window from which you can choose some options for the new user.\n\n![Inviting members modal](https://docs.growthbook.io/assets/images/invite-member-modal-71e3c65b5cf628d20a53f9da725ca3e4.png)\n\nEach GrowthBook user needs an email address, and you can select what global permissions you want to assign (See below for a full list of permission levels).\n\nInviting a new member to your organization will send an email to that user inviting them to join.\n\nIt is possible for a user to join more than one organization. If the user is a member to multiple organizations, they will see a drop-down next to their email address on the top right of the page, where they can select the organization they want to work in.\n\n### Environment Specific Limits[​](#environment-specific-limits \"Direct link to Environment Specific Limits\")\n\n![Environment Specific Limits](https://docs.growthbook.io/assets/images/user-permissions-env-specific-7676a8e33cbef9a12e5e73b8d190f63b.png)\n\nGrowthBook's user permissions also include environment specific limits. This permission level applies only to `Engineer` and `Experimenter` roles in Pro or Enterprise accounts. It allows you to limit the feature flags and experiments a user can manage to specific environments. For example, you can allow an `Engineer` to create and run experiments in a staging environment, but not in production.\n\n### Project Specific Permissions[​](#project-specific-permissions \"Direct link to Project Specific Permissions\")\n\nBesides the global permissions, you can also assign project-specific permissions to users. This allows you to define a user's default role across all projects and select per-project overrides. For example, a new user could be a `collaborator` by default for all projects, but on the `mobile` project, they could be an `experimenter` so they can manage all feature flags and experiments assigned to that project.\n\n### How permissions are evaluated[​](#how-permissions-are-evaluated \"Direct link to How permissions are evaluated\")\n\nGrowthBook evaluates user permissions based on whether an action is taking place within a specific project. If so, project-level permissions are checked first, followed by the user's global role. If the action is not within a project, only the user's global role is checked.\n\nFor organizations without a Pro or Enterprise account, user permissions are evaluated solely based on their global role.\n\nnote\n\nIf your organization has enabled the setting to allow verified users to automatically join your organization, they will receive the `Collaborator` role by default when they join. However, you can change your organizations' default role at the bottom of the Team page.\n\n### Self-registering and Automatic Approvals[​](#self-registering-and-automatic-approvals \"Direct link to Self-registering and Automatic Approvals\")\n\nIf users create an account with a verified email address that matches the domain of your account owner, they will be presented with an option to join your organization. If you have not selected `Automatically approve new verified users` (which is the default), those users will be listed at the bottom of the page under a section called `Pending Members`. From this list, you'll have the option of approving or deleting these self-registered users.\n\n![Self-registering and Automatic Approvals Toggle](https://docs.growthbook.io/images/using/auto-approve-members.png)\n\nIf you are the account owner, you will see a toggle at the top of the members' page that allows you to automatically approve new members who match your domain. This means that instead of being placed in your `pending members` list, they will automatically join your organization.\n\n### Removing Users[​](#removing-users \"Direct link to Removing Users\")\n\nTo remove a user from your organization, you can click on the three dots next to their name and select `Remove User`. This will remove the user from your organization and revoke their access to all projects and resources within your organization.\n\n## Permissions[​](#permissions \"Direct link to Permissions\")\n\nFine-tuning user permissions in an application like GrowthBook ensures a tailored experience, empowering organizations to grant precisely defined access levels. This granular control not only enhances security but also enables teams to collaborate efficiently while safeguarding sensitive features or data.\n\nOrganizations using GrowthBook have a number of different ways of defining a user's permission level, depending on the organization's plan.\n\nRegardless of the plan, all organizations can assign a global role when inviting a user which defines their permissions across all projects. If you have a Pro or Enterprise account, you can also assign project-level roles for each user.\n\nnote\n\nFor example, you can assign a user the global role of `Collaborator`, allowing them to view features and experiments, add comments, and contribute ideas. You can then assign them an `Experimenter` role for a specific project, which allows them to create and run experiments, but only for that project.\n\nAnd, for our Enterprise organizations, we offer the ability to create `Teams`, which are groups of users, all of which inherit the roles and permissions of the Team they're on.\n\nThe table below lists the roles available in GrowthBook and their associated permissions.\n\n|     | No Access | Read Only | Collaborator | Engineer | Analyst | Experimenter | Admin |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n| Feature Flags | \\-  | View | View  <br>Comment | View  <br>Comment  <br>Add  <br>Edit | View  <br>Comment | View  <br>Comment  <br>Add  <br>Edit | View  <br>Comment  <br>Add  <br>Edit |\n| Experiments | \\-  | View | View  <br>Comment | View  <br>Comment  <br>Edit | View  <br>Comment  <br>Add  <br>Edit  <br>Run Queries | View  <br>Comment  <br>Add  <br>Edit  <br>Run Queries | View  <br>Comment  <br>Add  <br>Edit  <br>Run Queries |\n| Metrics | \\-  | View | View | View | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Dimensions | \\-  | View | View | View | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Segments | \\-  | View | View | View | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Datasources | \\-  | View | View | View | View  <br>Edit\\* | View  <br>Edit\\* | View  <br>Add  <br>Edit |\n| Ideas | \\-  | View | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| SDK Connections | \\-  | View  <br>Add | View  <br>Add | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Attributes | \\-  | View | View | View  <br>Add  <br>Edit | View | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Namespaces | \\-  | View | View | View  <br>Add  <br>Edit | View | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Environments | \\-  | View | View | View  <br>Add  <br>Edit | View | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Saved Groups | \\-  | View | View | View  <br>Add  <br>Edit | View | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Tags | \\-  | \\-  | \\-  | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Slack Integration | \\-  | \\-  | \\-  | \\-  | \\-  | \\-  | View  <br>Add  <br>Edit |\n| Manage Projects | \\-  | \\-  | \\-  | \\-  | \\-  | \\-  | Yes |\n| Manage Team | \\-  | \\-  | \\-  | \\-  | \\-  | \\-  | Yes |\n| Manage Plan | \\-  | \\-  | \\-  | \\-  | \\-  | \\-  | Yes |\n| Manage Billing | \\-  | \\-  | \\-  | \\-  | \\-  | \\-  | Yes |\n\n\\*_Limited to editing a subset of data source settings - identifier types, experiment assignment queries, Jupyter Notebook queries and Data Pipeline settings. Editing datasource name, projects, description, and connection parameters requires Admin permissions._\n\n### How does the No Access role work?[​](#how-does-the-no-access-role-work \"Direct link to How does the No Access role work?\")\n\nThe `No Access` role is available to organizations enrolled in an Enterprise plan.\n\nIn some cases, an organization might want to hide certain projects from a user entirely. This is possible with the `No Access` role. The `No Access` role can either be applied as the user's global role, or it can be a project-specific role.\n\nIn the event you want a user to have access to a subset of projects, you can give them a global role of `No Access` and then give project-specific permissions for the projects you want them to be able to view.\n\nIf, however, you only want to hide a certain project from a user, you can assign their project-level role of `No Access` which will make it so the user isn't able to view the project.\n\nIf you need to apply these rules to many users as once, you can create a Team with the permissions needed, and then add users to that team. But, keep in mind, the user's permissions will be a combination of their user permissions, and the permissions of any team their on, so after adding the user to a team, you may want to reduce their user-level permissions to ensure their previous user-level permissions don't override the permissions inherited by the team(s) they're on.\n\nnote\n\nWithin GrowthBook, not all resources are project-specific. For example, `Saved Groups`, `Dimensions`, `Segments`, `Namespaces`, `Environments`, `Presentations`, and `Ideas` all live at the organization level. This means that all users, regardless of role, will be able to view these resources.\n\nIf security of these resources is paramount to your organization, we recommend creating a separate organization, and keeping the resources you want to hide in that organization.\n\n### Teams[​](#teams \"Direct link to Teams\")\n\nEnterprise organizations using GrowthBook can create Teams with distinct capabilities. When setting up a Team, you have the option to define both a global role and project-level roles, much like how you do for individual users. Once a Team is established, multiple users can be added to it. Any user added to a Team will automatically inherit all permissions assigned to that Team. This feature becomes particularly useful when combined with [GrowthBook's SCIM integration](https://docs.growthbook.io/integrations/scim), enabling automated user provisioning and de-provisioning.\n\nTo create a Team, you can go to `Settings` → `Team` via the Sidebar and then select the `Teams` tab at the top of the page. Here, you can create and configure various Teams, before adding members to a Team. When evaluating whether or not a user has permission to perform a certain action, we will merge the user's permissions with the permissions inherited from all the Teams the user is on. So if the user's global role is `Collaborator` but they're on a Team that grants them `Engineer` permissions, that user's permission will then be a merger of the `Collaborator` and `Engineer` roles.\n\n### Custom roles[​](#custom-roles \"Direct link to Custom roles\")\n\nEnterprise organizations using GrowthBook also have the added flexibility of defining custom roles, which enable organizations to fine-tune a role's permissions. These custom roles can be used just like a standard role and can be applied to users and teams at both the global and project levels. A custom role can also be set as your organization's default role, so if you have auto-join enabled, new members will automatically receive the organization's default role, even if it is a custom role.\n\nWhen creating a custom role, you can either create a role from scratch or duplicate an existing role and then update the role's description along with the policies, which control the role's permissions.\n\nOnce created, the name of a custom role cannot be changed. If you need to change the name, you will need to duplicate the role and set the new name before saving. Once saved, you'll need to update users to use this new role.\n\n#### Policies & Permissions[​](#policies--permissions \"Direct link to Policies & Permissions\")\n\nWhen creating and editing custom roles, organizations have the ability to select specific policies for each role, where the policy contains the underlying permissions.\n\nBelow, we've outlined the current policies and their associated permissions. If your use case is not met with the current policies, please let us know by creating a [Github Issue](https://github.com/growthbook/growthbook/issues).\n\n| Policy Group | Policy | Description | Permissions |\n| --- | --- | --- | --- |\n| **Global** | ReadData | View all resources - features, metrics, experiments, data sources, etc. | readData |\n|     | Comments | Add comments to any resource | readData, addComments |\n| **Features** | FeaturesFullAccess | Create, edit, and delete feature flags | readData, manageFeatureDrafts, manageFeatures, manageArchetype, canReview, |\n|     | ArchetypesFullAccess | Create, edit, and delete saved User Archetypes for feature flag debugging | readData, manageArchetype |\n|     | FeaturesBypassApprovals | Bypass required approval checks for feature flag changes | readData, manageFeatureDrafts, manageFeatures, canReview, bypassApprovalChecks |\n| **Experiments** | ExperimentsFullAccess | Create, edit, and delete experiments. Does not include Visual Editor access. | readData, createAnalyses, runQueries |\n|     | VisualEditorFullAccess | Use the Visual Editor to implement experiment changes. | readData, manageVisualChanges |\n|     | superDeleteReports | Delete ad-hoc reports made by other users. Typically assigned to admins only. | readData, superDeleteReport |\n| **Metrics & Data** | DataSourcesFullAccess | Create, edit, and delete data sources | readData, createDatasources, editDatasourceSettings, runQueries |\n|     | DataSourceConfiguration | Edit existing data source configuration settings (identifier types, experiment assignment queries) | readData, editDatasourceSettings, runQueries |\n|     | RunQueries | Execute queries against data sources. Required to refresh experiment results. | readData, runQueries |\n|     | MetricsFullAccess | Create, edit, and delete regular metrics (does not include Fact Metrics) | readData, createMetrics, runQueries |\n|     | FactTablesFullAccess | Create, edit, and delete fact tables, metrics, and filters. | readData, manageFactTables, manageFactMetrics, manageFactFilters, runQueries |\n|     | FactMetricsFullAccess | Create, edit, and delete fact metrics and filters. | readData, manageFactMetrics, manageFactFilters, runQueries |\n|     | DimensionsFullAccess | Create, edit, and delete dimensions | readData, createDimensions, runQueries |\n|     | SegmentsFullAccess | Create, edit, and delete segments | readData, createSegments, runQueries |\n| **Management** | IdeasFullAccess | Create, edit, and delete ideas | readData, createIdeas |\n|     | PresentationsFullAccess | Create, edit, and delete presentations | readData, createPresentations |\n| **SDK Configuration** | SDKPayloadPublish | Make changes that affect data sent to SDKs. For example: edit a saved group, toggle a feature flag, stop an experiment, etc. | readData, publishFeatures, runExperiments |\n|     | SDKConnectionsFullAccess | Create, edit, and delete SDK Connections | readData, manageSDKConnections, manageSDKWebhooks |\n|     | AttributesFullAccess | Create, edit, and delete targeting attributes | readData, manageTargetingAttributes |\n|     | EnvironmentsFullAccess | Create, edit, and delete environments | readData, manageEnvironments |\n|     | NamespacesFullAccess | Create, edit, and delete namespaces | readData, manageNamespaces |\n|     | SavedGroupsFullAccess | Create, edit, and delete saved groups | readData, manageSavedGroups |\n| **Settings** | GeneralSettingsFullAccess | Edit organization general settings | readData, organizationSettings |\n|     | NorthStarMetricFullAccess | Configure North Star metrics | readData, manageNorthStarMetric |\n|     | TeamManagementFullAccess | Invite users, delete users, change user roles, add/remove users from teams. | readData, manageTeam |\n|     | CustomRolesFullAccess | Create, edit, and delete projects | readData, manageProjects |\n|     | ProjectsFullAccess | Create, edit, and delete tags | readData, manageTags |\n|     | TagsFullAccess | Create, edit, and delete API secret keys. Not required to create Personal Access Tokens. | readData, manageApiKeys |\n|     | APIKeysFullAccess | Set up and configure integrations - GitHub, Vercel, etc. | readData, manageIntegrations |\n|     | IntegrationsFullAccess | Create, edit, and delete event-based webhooks. Used for Slack/Discord notifications. | readData, manageEventWebhooks, viewAuditLog |\n|     | EventWebhooksFullAccess | View and edit license key. View invoices and update billing info. | readData, manageBilling |\n|     | BillingFullAccess | View and export audit logs | readData, viewAuditLog |\n|     | AuditLogsFullAccess | Create, edit, and delete custom roles | readData, manageTeam, manageCustomRoles |\n\n#### Deactivating Roles[​](#deactivating-roles \"Direct link to Deactivating Roles\")\n\nAs we do not support the ability for an organization to delete a standard role, we have introduced the ability for enterprise organizations to deactivate both standard and custom roles. When a role is deactivated, we remove the role from the roles dropdown when adding a new user or updating an existing user's role. If you deactivate a role that is assigned to a user, the user will experience no changes to their permission level. The deactivation of the role simply removes it from the role options.\n\nThe only guardrail in place around deactivating roles is that you cannot deactivate your organization's default role.",
  "title": "User & Team Permissions | GrowthBook Docs",
  "description": "GrowthBook's User & Team Permissions",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/integrations/scim",
  "markdown": "# Configuring SCIM for GrowthBook | GrowthBook Docs\n\n## SCIM Integration for Enterprise Organizations\n\nnote\n\nSCIM is only available with an Enterprise plan and requires [Single Sign-On (SSO)](https://docs.growthbook.io/sso) to be enabled. Currently, GrowthBook only supports Okta as the identity provider.\n\nSCIM, or [System for Cross-domain Identity Management](https://scim.cloud/), is the standard for managing users and groups across multiple applications. With SCIM, you can automate the provisioning and deprovisioning of users in your GrowthBook account through your identity provider.\n\nGrowthBook's SCIM integration currently offers the following features:\n\n*   User provisioning\n*   User deprovisioning\n*   Group Push\n\nWhen a user is provisioned, they are added to your GrowthBook organization with your organization's default role. After provisioning, admin users can adjust their roles and permissions via the GrowthBook application as needed. It's important to note that if a user is provisioned through SCIM, they can only be deprovisioned through your identity provider.\n\nGrowthBook does support the ability to optionally [define a role when provisioning a user](#how-to-define-user-role-when-provisioning). Project-level permissions are not supported when provisioning a user via SCIM. That must be done via the GrowthBook application.\n\nWhen a group is added to \"Push Groups\" in your Okta SCIM application, groups and their members will be synced with GrowthBook via a corresponding [Team](https://docs.growthbook.io/account/user-permissions). Please note that only members that have been provisioned into the GrowthBook app will be added to the Team in GrowthBook. For example, if you have a push group with members A, B, and C and only A and B are assigned to GrowthBook on the \"Assignments\" tab, the corresponding team on GrowthBook will only include members A and B. Just like how user provisioning works, new Teams will be set up with your organization's default role. You'll need to adjust the permissions for the Team in GrowthBook. Group removal or membership changes will need to be done through your identity provider.\n\nnote\n\nWe are actively working on adding support for additional identity providers.\n\n## Configuring SCIM Integration[​](#configuring-scim-integration \"Direct link to Configuring SCIM Integration\")\n\n### Okta Setup[​](#okta-setup \"Direct link to Okta Setup\")\n\n1.  Verify that your GrowthBook organization is on an enterprise plan with SSO enabled.\n    \n2.  Log in to your Okta account and go to the Applications page. Select \"Browse App Catalog,\" then search for \"SCIM 2.0 Test App (OAuth Bearer Token).\" Click \"Add Integration\" to add the app to your Okta account.\n    \n\n![](https://docs.growthbook.io/assets/images/GrowthBook-SCIM-Add-Okta-Integration-b8f37987beca197b7b4be77cdb2b557f.png)\n\n3.  Once the app is added, you can change its name, for example, to \"GrowthBook SCIM.\" Click \"Next.\"\n\n![](https://docs.growthbook.io/assets/images/GrowthBook-SCIM-Add-Name-77507b06187378284271efef8d249b92.png)\n\n4.  On the next page, you don't need to modify any settings. Simply click \"Done.\"\n    \n5.  With the application created, click on the \"Provisioning\" tab and select \"Configure API Integration.\"\n    \n\n![](https://docs.growthbook.io/assets/images/GrowthBook-SCIM-Enable-API-Integration-0e476007640d15db9b3ddf1405f53930.png)\n\n6.  Now you can enter the Base URL and your OAUTH Bearer Token.\n\n*   For GrowthBook Cloud users, the Base URL is `https://api.growthbook.io/scim/v2`. If you're self-hosting GrowthBook, the Base URL will be `{YOUR_API_HOST}/scim/v2`.\n*   You can obtain your OAuth Bearer Token by creating a new Secret API Key with an `Admin` role. To do this, go to your GrowthBook account, and in the left navigation, select \"Settings → API Keys.\" We recommend creating a dedicated API key exclusively for your SCIM integration.\n\n7.  After adding your credentials, click \"Test API Credentials\" to ensure they are valid. If they pass the test, click \"Save.\"\n\n![](https://docs.growthbook.io/assets/images/GrowthBook-SCIM-Add-Credentials-e7a549b34df8bb2f37346d19a854bf48.png)\n\n8.  Next, click on the \"To App\" tab and select \"Edit\" to enable \"Create Users\" and \"Deactivate Users.\" Once enabled, click \"Save.\"\n\n![](https://docs.growthbook.io/assets/images/GrowthBook-SCIM-Configure-Options-d338c0b6cfe186252099dfc26fcf95a0.png)\n\n9.  Congratulations! Your application is now set up. You can navigate to the \"Assignments\" tab and assign people to GrowthBook and to the \"Push Groups\" tab to sync groups with GrowthBook Teams.\n\n### How to define user role when provisioning[​](#how-to-define-user-role-when-provisioning \"Direct link to How to define user role when provisioning\")\n\n1.  First, ensure that you've followed the general setup instructions above.\n    \n2.  In Okta, navigate to the Application you created for GrowthBook SCIM, and click on the \"Provisioning\" tab, and scroll to the \"Attribute Mappings\" section, before clicking \"Go to Profile Editor\".\n    \n3.  Then, you'll click \"Add Attribute\" to create a new attribute. with the following details.\n    \n\n*   Data type: string\n*   Display name: GrowthBook Role\n*   Variable name: growthbookRole\n*   External name: growthbookRole\n*   External namespace: urn:ietf:params:scim:schemas:core:2.0:User\n*   Check the box to define an enumerated list of values\n*   Here, you need to add the following enum Options\n    *   Display name: Read only\n    *   Value: readonly\n    *   Display name: Collaborator\n    *   Value: collaborator\n    *   Display name: Engineer\n    *   Value: engineer\n    *   Display name: Analyst\n    *   Value: analyst\n    *   Display name: Experimenter\n    *   Value: experimenter\n    *   Display name: Admin\n    *   Value: admin\n\n![](https://docs.growthbook.io/assets/images/GrowthBook-SCIM-Define-Role-Attribute-535f4808ce87291764954a799dd27889.png)\n\nnote\n\nIt's important each of these values are entered exactly as shown above, including capitalization. If there is a descrepancy, the user's role will fall back to your organizations default role.\n\n4.  Once complete, when you provision a user, you can select their role from the dropdown, and that will be applied to the user in GrowthBook. If you're not sure which role a user should have, you can view GrowthBook role permissions [here](https://docs.growthbook.io/account/user-permissions).\n\n![](https://docs.growthbook.io/assets/images/GrowthBook-SCIM-Define-User-Role-afa348f6755fcebbd16a880b1a68c7ad.png)\n\n## Frequently Asked Questions[​](#frequently-asked-questions \"Direct link to Frequently Asked Questions\")\n\n**What features are supported with SCIM?**\n\nCurrently, GrowthBook supports user provisioning and deprovisioning, and group pushing.\n\n**What identity providers are supported?**\n\nAt present, GrowthBook only supports Okta, but we are actively working on adding support for additional identity providers.\n\n**What happens if I deprovision a user in my identity provider?**\n\nIf a user is deprovisioned in your identity provider, they will be removed from GrowthBook. If they are re-provisioned, they will be added back to GrowthBook, and their role will reset to the organization's default role.\n\n**All the users from my group aren't being synced with my GrowthBook team. What's happening?**\n\nIf you notice that some users that you expect to be in your GrowthBook team from your identity provider are not being added in GrowthBook, double check that those users are assigned to the GrowthBook SCIM application in your identity provider. Only users that are both assigned and withing the group will be synced to the corresponding team.\n\n**What if I already have users in GrowthBook?**\n\nExisting users in GrowthBook will not be affected by SCIM. You can continue to manage them through the GrowthBook application as usual. If you wish to transition them to be managed by your identity provider, you can provision them through your identity provider. As long as the email matches, the existing GrowthBook user will be converted to be managed by your identity provider.\n\n**Does GrowthBook follow SCIM 1.1 or 2.0 Protocol?**\n\nGrowthBook follows the SCIM 2.0 protocol.\n\n**What happens if I provision a user with a role that doesn't exist?**\n\nGrowthBook will fallback to your organization's default role.\n\n**Can I provision a user with project-specific permissions?**\n\nNo, at this time, you can only provision a user's global role. Project-specific permissions must be managed through the GrowthBook application.\n\n**Can I change a user's global role after they've been provisioned?**\n\nYes, you can change a user's global role through the GrowthBook application or via Okta. Please note that if you change a user's global role through the GrowthBook Application, it will then be out-of-date in Okta. If you then update the user in Okta, it will update the user's global role.\n\n**I'm changing the user's role in Okta, but it's not changing in GrowthBook**\n\nIn order for the user's role to be updated in GrowthBook, you must update your Application provisioning to support \"updates\". Please note that the only property GrowthBook supports updating is the `growthBookRole`.",
  "title": "Configuring SCIM for GrowthBook | GrowthBook Docs",
  "description": "Setting up SCIM Integration with GrowthBook",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/sso",
  "markdown": "# SSO Instructions | GrowthBook Docs\n\n## Enterprise SSO\n\nnote\n\nSSO is available as part of our Enterprise plan.\n\nSSO is available on GrowthBook Cloud or Self-hosted via OpenID Connect. If you are using the Cloud, your account representative will help you get this setup, though the steps are mostly the same. To enable SSO on your self hosted GrowthBook instance, you will need an active license key and then you may add the SSO settings for your provider. If your provider is not listed below, you can use the generic Open ID Connect.\n\nFor GrowthBook Cloud, you will need to send your account representative the following: **CLIENT\\_ID**, **CLIENT\\_SECRET**, **EMAIL\\_DOMAIN**, what provider you're using, and for some providers, the **TENANT\\_ID**. You can use the instructions below to get these values.\n\nIf you are self-hosting, you can use the instructions below to create a JSON object with the settings, then it should be JSON encoded and then set to the environment variable `SSO_CONFIG`.\n\n## Generic Open ID Connect[​](#generic-open-id-connect \"Direct link to Generic Open ID Connect\")\n\n*   **LICENSE\\_KEY** - Your signed license key provided by the GrowthBook team\n*   **SSO\\_CONFIG** - A JSON-encoded string that configures SSO (using OpenID Connect). It should be an object with the following keys:\n*   `clientId` (string)\n*   `clientSecret` (string)\n*   `emailDomain` (string, optional) - Allow [auto-joining](https://docs.growthbook.io/account/user-permissions#self-registering-and-automatic-approvals) from a specified email domain.\n*   `metadata` (object)\n*   `issuer` (string)\n*   `authorization_endpoint` (string)\n*   `jwks_uri` (string)\n*   `id_token_signing_alg_values_supported` (array of strings)\n*   `token_endpoint` (string)\n*   `code_challenge_methods_supported` (array of strings)\n*   `logout_endpoint` (string, optional)\n*   `extraQueryParams` (object, optional) - Dictionary of extra query params to be passed along with the `/authorize` OAuth call\n*   `additionalScope` (string, optional) - Additional scopes to include, along with the default value: `openid profile email`\n\nFor SSO, make sure the following callback URL is whitelisted:\n\n*   `{APP_ORIGIN}/oauth/callback`\n\nFor the best SSO user experience, enable offline access and refresh tokens in your Identity Provider.\n\nNote\n\nWith all the SSO providers listed below, replace the all caps values with values from the provider, JSON encode the object, and set to the `SSO_CONFIG` environment variable for GrowthBook.\n\n## SSO Providers[​](#sso-providers \"Direct link to SSO Providers\")\n\n### Okta[​](#okta \"Direct link to Okta\")\n\n```\n{    \"clientId\": \"CLIENT_ID\",    \"clientSecret\": \"CLIENT_SECRET\",    \"emailDomain\": \"EMAIL_DOMAIN\",    \"additionalScope\": \"offline_access\",    \"metadata\": {        \"issuer\": \"BASE_URL\",        \"authorization_endpoint\": \"BASE_URL/oauth2/v1/authorize\",        \"id_token_signing_alg_values_supported\": [            \"RS256\"        ],        \"jwks_uri\": \"BASE_URL/oauth2/v1/keys\",        \"token_endpoint\": \"BASE_URL/oauth2/v1/token\",        \"code_challenge_methods_supported\": [            \"S256\"        ]    }}\n```\n\nSee complete Okta instructions\n\n1.  **Create an OIDC Web application:**  \n    ![](https://docs.growthbook.io/images/guides/SSO-Okta-1.png)\n2.  Allow refresh tokens and specify callback URLs. If you are using the cloud, you can use the following values:\n    \n    *   **Sign-in redirect URIs** - `[https://app.growthbook.io/oauth/callback](https://app.growthbook.io/oauth/callback)`\n    *   **Sign-out redirect URIs** (optional) - `[https://app.growthbook.io](https://app.growthbook.io/)`\n    \n    If you are self-hosting, replace with `[https://app.growthbook.io](https://app.growthbook.io/)` with the value from your `API_HOST`\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Okta-2.png)\n3.  **Require PKCE as additional verification**(optional)  \n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Okta-3.png)  \n    \n    You will need the following in order to configure SSO in GrowthBook:\n    \n    *   `CLIENT_ID`\n    *   `CLIENT_SECRET`\n    *   `BASE_URL`\n    *   `EMAIL_DOMAIN`\n    \n    If using GrowthBook Cloud, send your account representative the above and we will enable SSO on your account.\n    \n    If self-hosting, add the environment settings at the beginning of this section to enable SSO on your instance.\n    \n\n### Google[​](#google \"Direct link to Google\")\n\n```\n{    \"clientId\": \"CLIENT_ID\",    \"clientSecret\": \"CLIENT_SECRET\",    \"emailDomain\": \"EMAIL_DOMAIN\",    \"metadata\": {        \"issuer\": \"https://accounts.google.com\",        \"authorization_endpoint\": \"https://accounts.google.com/o/oauth2/v2/auth\",        \"token_endpoint\": \"https://oauth2.googleapis.com/token\",        \"jwks_uri\": \"https://www.googleapis.com/oauth2/v3/certs\",        \"id_token_signing_alg_values_supported\": [            \"RS256\"        ],        \"code_challenge_methods_supported\": [            \"S256\"        ]    },    \"extraQueryParams\": {        \"access_type\": \"offline\",        \"prompt\": \"consent\"    }}\n```\n\n### Auth0[​](#auth0 \"Direct link to Auth0\")\n\n```\n{    \"clientId\": \"CLIENT_ID\",    \"clientSecret\": \"CLIENT_SECRET\",    \"emailDomain\": \"EMAIL_DOMAIN\",    \"additionalScope\": \"offline_access\",    \"metadata\": {        \"issuer\": \"https://TENANT.auth0.com/\",        \"authorization_endpoint\": \"https://TENANT.auth0.com/authorize\",        \"logout_endpoint\": \"https://TENANT.auth0.com/v2/logout?client_id=CLIENT_ID\",        \"id_token_signing_alg_values_supported\": [            \"HS256\",            \"RS256\"        ],        \"jwks_uri\": \"https://TENANT.auth0.com/.well-known/jwks.json\",        \"token_endpoint\": \"https://TENANT.auth0.com/oauth/token\",        \"code_challenge_methods_supported\": [            \"S256\",            \"plain\"        ],        \"audience\": \"AUDIENCE\"    }}\n```\n\nnote\n\nWhen setting up Auth0, please ensure that you've enabled offline access, and check the `OIDC Compliant` checkbox.\n\n### Azure AD[​](#azure-ad \"Direct link to Azure AD\")\n\n```\n{  \"clientId\": \"CLIENT_ID\",  \"clientSecret\": \"CLIENT_SECRET\",  \"emailDomain\": \"EMAIL_DOMAIN\",  \"additionalScope\": \"offline_access\",  \"metadata\": {    \"token_endpoint\": \"https://login.microsoftonline.com/TENANT_ID/oauth2/v2.0/token\",    \"jwks_uri\": \"https://login.microsoftonline.com/TENANT_ID/discovery/v2.0/keys\",    \"id_token_signing_alg_values_supported\": [\"RS256\"],    \"code_challenge_methods_supported\": [\"S256\"],    \"issuer\": \"https://login.microsoftonline.com/TENANT_ID/v2.0\",    \"authorization_endpoint\": \"https://login.microsoftonline.com/TENANT_ID/oauth2/v2.0/authorize\",    \"logout_endpoint\": \"https://login.microsoftonline.com/TENANT_ID/oauth2/v2.0/logout\"  }}\n```\n\nnote\n\nIn Azure, register an Application, instead of Enterprise, as we use OpenID Connect, not SAML.\n\nSee complete Azure instructions\n\n1.  Register an Application (we use OpenID Connect, so choose regular app, not Enterprise)\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Azure-1.png)\n2.  Enter the redirect URL as APP\\_HOST/oauth/callback\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Azure-2.png)\n3.  Take note of your Application Id (CLIENT\\_ID) and Directory Id (TENANT\\_ID). You will need it later\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Azure-3.png)\n4.  Generate a new Client Secret  \n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Azure-4.png)\n5.  Take note of the Secret Value (CLIENT\\_SECRET). You will need it in the next step\n    \n6.  Construct the JSON configuration for GrowthBook. Replace\n    \n    CLIENT\\_ID\n    \n    , CLIENT\\_SECRET, EMAIL\\_DOMAIN, and TENANT\\_ID, as into the JSON object above.\n7.  Pass the JSON string into the environment variable SSO\\_CONFIG of your GrowthBook container\n    \n\n### OneLogin[​](#onelogin \"Direct link to OneLogin\")\n\n```\n{  \"clientId\": \"CLIENT_ID\",  \"clientSecret\": \"CLIENT_SECRET\",  \"emailDomains\": [    \"EMAIL_DOMAIN\"  ],  \"additionalScope\": \"\",  \"metadata\": {    \"issuer\": \"https://[ONELOGIN_DOMAIN]/oidc/2\",    \"authorization_endpoint\": \"https://[ONELOGIN_DOMAIN]/oidc/2/auth\",    \"token_endpoint\": \"https://[ONELOGIN_DOMAIN]/oidc/2/token\",    \"id_token_signing_alg_values_supported\": [      \"RS256\",      \"HS256\",      \"PS256\"    ],    \"jwks_uri\": \"https://[ONELOGIN_DOMAIN]/oidc/2/certs\",    \"code_challenge_methods_supported\": [      \"S256\"    ],    \"logout_endpoint\": \"https://[ONELOGIN_DOMAIN]/oidc/2/logout\"  }}\n```\n\nSee complete OneLogin instructions\n\n1.  Create a new OIDC Web application. Browse to the Applications section of OneLogin from the top nav, then choose \"Add App\" from the top right.\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Onelogin-1.png)\n2.  When the list of applications opens, search for **\"openid connect\"**. Select the option named **\"OpenID Connect (OIDC)\"**.\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Onelogin-2.png)\n3.  Add the name \"GrowthBook\" (or whatever you would like to name it), an optional description and click save. The first save may not look like anything has happened, but you should see more options on the left menu when successful.\n    \n4.  Click on the \"Configuration\" item in the left nav menu, and enter the following values for the three input fields (note: for self-hosting, replace\n    \n    app.growthbook.io\n    \n    with your own domain)\n    \n    *   **Login URL**:\n        \n        [https://app.growthbook.io](https://app.growthbook.io/)\n        \n    *   **Redirect URIs**:\n        \n        [https://app.growthbook.io/oauth/callback](https://app.growthbook.io/oauth/callback)\n        \n    *   **Post Logout Redirect URIs**:\n        \n        [https://app.growthbook.io](https://app.growthbook.io/)\n        \n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Onelogin-3.png)\n    \n    You can optionally add images for the application from the info if you like. **Click Save**.\n    \n5.  Click on the \"SSO\" item from the left nav menu. Here you need to record the **Client ID** and **Client Secret** and **Issuer URL**\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Onelogin-4.png)\n    \n    You can leave the other settings as default (Application Type: Web, and Authentication Method: Basic). Click save if you haven't already.\n    \n6.  For self-hosted instances: construct the JSON configuration for GrowthBook. Replace CLIENT\\_ID, CLIENT\\_SECRET, EMAIL\\_DOMAIN, and TENANT\\_ID, as into the JSON object above. The ONELOGIN\\_DOMAIN will be the same domain from your Issuer URL you recorded earlier.\n    \n7.  Pass the JSON string into the environment variable SSO\\_CONFIG of your GrowthBook container\n    \n\n### JumpCloud[​](#jumpcloud \"Direct link to JumpCloud\")\n\n```\n{  \"clientId\": \"CLIENT_ID\",  \"clientSecret\": \"CLIENT_SECRET\",  \"emailDomains\": [    \"EMAIL_DOMAIN\"  ],  \"additionalScope\": \"offline_access\",  \"metadata\": {    \"token_endpoint\": \"https://oauth.id.jumpcloud.com/oauth2/token\",    \"jwks_uri\": \"https://oauth.id.jumpcloud.com/.well-known/jwks.json\",    \"id_token_signing_alg_values_supported\": [      \"RS256\"    ],    \"code_challenge_methods_supported\": [      \"S256\"    ],    \"issuer\": \"https://oauth.id.jumpcloud.com/\",    \"authorization_endpoint\": \"https://oauth.id.jumpcloud.com/oauth2/auth\",    \"logout_endpoint\": \"https://oauth.id.jumpcloud.com/oauth2/sessions/logout\",    \"audience\": \"\"  }}\n```\n\nSee complete JumpCloud instructions\n\n1.  Create a new SSO Application. Browse to the User Authentication → SSO Applications from the left nav. Choose \"Add new Application\" from the top left.\n    \n2.  Choose a custom application by clicking 'select' under `custom application`, then click next then next again to confirm.\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-jumpcloud-1.png)![](https://docs.growthbook.io/images/guides/SSO-jumpcloud-2.png)\n3.  You will then be asked what features you want to enable. Select `Manage Single Sign-On (SSO)`. Then, in the radio buttons, select **\"Configure SSO with OIDC\"**.\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-jumpcloud-3.png)\n4.  Add the name \"GrowthBook\" (or whatever you would like to name it), an optional description and click `next`. When you've confirmed the details, click `Configure Application`.\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-jumpcloud-4.png)![](https://docs.growthbook.io/images/guides/SSO-jumpcloud-5.png)\n5.  This will open a window letting you add additional configuration options for the GrowthBook application. Here are the settings you should set:\n    \n    *   **Grant types**: Select \"Refresh Token\" and Authentication Code\n    *   **Redirect URIs**:\n        \n        [https://app.growthbook.io/oauth/callback](https://app.growthbook.io/oauth/callback)\n        \n    *   **Client Authentication Type**: Client Secret Basic\n    *   **Login URL**:\n        \n        [https://app.growthbook.io](https://app.growthbook.io/)\n        \n    *   **Attribute Mapping**: Select both email and profile. The defaults for the fields that appear are all that is required.\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-jumpcloud-6.png)\n    \n    Once you have made the above settings, click 'Activate' from the bottom bar.\n    \n6.  You'll then be presented with a modal giving you the client id and client secret. Here you need to record the **Client ID** and **Client Secret**\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-jumpcloud-7.png)\n7.  For self-hosted instances, construct the JSON configuration for GrowthBook. Replace CLIENT\\_ID, CLIENT\\_SECRET, and EMAIL\\_DOMAIN, as into the JSON object above.\n    \n8.  Pass the JSON string into the environment variable SSO\\_CONFIG of your GrowthBook container",
  "title": "SSO Instructions | GrowthBook Docs",
  "description": "Configuring GrowthBook for SSO",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/compliance",
  "markdown": "# Compliance | GrowthBook Docs\n\n## Security Compliance\n\nGrowthBook takes security seriously and is compliant with **SOC2**, **GDPR**, and **HIPAA**. We perform regular penetration testing, have an active bug bounty program, and maintain strict controls to protect data privacy.\n\nView our [Trust Center](https://trust.growthbook.io/) to request access to the above ceritifications, as well as our most recent penetration test report, incident response plan, access control policy, and more.",
  "title": "Compliance | GrowthBook Docs",
  "description": "Compliance",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/account/audit-logs",
  "markdown": "# Audit logs | GrowthBook Docs\n\nGrowthBook keeps an audit log of all actions taken on the platform. You can access this page from the Settings → Log in the left navigation.\n\n![Audit log page](https://docs.growthbook.io/images/using/audit-logs.png)\n\nThese logs are useful for auditing what users have done, and figuring out the cause of any issues. These logs are not user editable. For enterprise customers, this log is exportable. We have more filtering options coming soon.",
  "title": "Audit logs | GrowthBook Docs",
  "description": "GrowthBook's Audit Logs",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/guide",
  "markdown": "# How to Guides for installing the platform\n\n## GrowthBook Detailed Guides.\n\nThe following sections contain detailed walkthrough's on how to set up GrowthBook with various technologies.\n\nThis is not a complete list of the ways GrowthBook can be integrated.\n\n## Tutorials[​](#tutorials \"Direct link to Tutorials\")\n\n*   [GrowthBook with Next.js (App Router)](https://docs.growthbook.io/guide/nextjs-app-router)\n*   [GrowthBook with Next.js (Pages Router)](https://docs.growthbook.io/guide/nextjs-and-growthbook)\n*   [GrowthBook with Create React App](https://docs.growthbook.io/guide/create-react-app-and-growthbook)\n*   [GrowthBook with Next.js and Rudderstack](https://docs.growthbook.io/guide/rudderstack-and-nextjs-with-growthbook)\n*   [GrowthBook with Google Tag Manager](https://docs.growthbook.io/guide/google-tag-manager-and-growthbook)\n*   [GrowthBook with Webflow](https://docs.growthbook.io/integrations/webflow)\n*   [GrowthBook with Shopify](https://docs.growthbook.io/integrations/shopify)\n*   [GrowthBook with Wordpress](https://docs.growthbook.io/integrations/wordpress)\n\n## A/B testing guide[​](#ab-testing-guide \"Direct link to A/B testing guide\")\n\n*   [The Open Guide to Successful A/B Testing (pdf)](https://docs.growthbook.io/assets/files/open-guide-to-ab-testing.v1.0-228e9312b957a9716766cd8887b18a11.pdf)",
  "title": "How to Guides for installing the platform | GrowthBook Docs",
  "description": "The following sections contain detailed walkthrough's on how to set up GrowthBook with various technologies.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/faq",
  "markdown": "# FAQ | GrowthBook Docs\n\nBelow are some frequently asked questions about GrowthBook.\n\n## Do users always get assigned the same experiment variation?[​](#do-users-always-get-assigned-the-same-experiment-variation \"Direct link to Do users always get assigned the same experiment variation?\")\n\nGrowthBook SDKs use deterministic hashing to ensure the same user always gets assigned the same variation in an experiment.\n\nIn a nutshell, GrowthBook hashes together the `hashAttribute` (the user attribute used to assign a variation, ex: user id) and the experiment `trackingKey` which produces a decimal between 0 and 1. Each variation is assigned a range of values (e.g. `0 to 0.5` and `0.5 to 1.0`) and the user is assigned to whichever one their hash falls into.\n\nThis does mean, if you change the experiment configuration, some users may switch their assigned variation. For example, if someone has the hash `0.49` and you adjust the weights to a 40/60 experiment, the variation ranges become `0 to 0.4` and `0.4 to 1.0`. In this case, the user was previously in the control group, but will now be in the variation.\n\nGrowthBook will detect issues like this and will remove users who see both variations from the analysis automatically. However, to keep things simple and safe, we recommend not relying on this and treating experiments as immutable once they are running.\n\nIt's important to note that the above only applies when changing the traffic split between variations. If you keep the split the same, but increase the percent of traffic included, users will not switch variations. For example, if you are running a 50/50 experiment on 20% of traffic, the variation ranges will be `0 to 0.1` and `0.5 to 0.6`. Users outside those ranges will be excluded from the experiment. If you increase the percent of traffic to 40%, but keep the 50/50 split, the ranges will become: `0 to 0.2` and `0.5 to 0.7`. As you can see, no users switch variations. Instead, some users who were previously excluded are now part of the experiment.\n\n## What do I use for an \"id\" attribute in the SDK if my users aren't logged in?[​](#what-do-i-use-for-an-id-attribute-in-the-sdk-if-my-users-arent-logged-in \"Direct link to What do I use for an \"id\" attribute in the SDK if my users aren't logged in?\")\n\nIf your application has both logged-in and anonymous users, we recommend using two identifier attributes:\n\n*   `id` which is the database identifier of logged-in users (or empty string for anonymous)\n*   `deviceId` (or `sessionId`, etc.) which is a random anonymous hash, persisted in a cookie or local storage. This should always be set for both anonymous and logged-in users.\n\nIf your application only has anonymous users (e.g. a static marketing site), then we recommend a single `id` attribute which, similar to `deviceId` or `sessionId` above, is a random hash persisted in a cookie or local storage.\n\n## Why is the trackingCallback not firing in the SDK?[​](#why-is-the-trackingcallback-not-firing-in-the-sdk \"Direct link to Why is the trackingCallback not firing in the SDK?\")\n\nThe `trackingCallback` only fires when a user is included in an experiment. If you're expecting to be included and you're still not seeing the callback fire, it's likely for one of the following reasons:\n\n*   You are missing the `hashAttribute` for the experiment. For example, when you are splitting users by \"company\", but the company attribute is empty.\n*   The feature is disabled for the environment you are in (dev/prod)\n*   The experiment has reduced coverage. For example, if it's only running for 10% of users and you are in the 90% that are excluded.\n*   There is another feature rule that is taking precedence over the experiment.\n\nIf you are using the Javascript or React SDK in a browser environment, you can install the [GrowthBook DevTools Chrome Extension](https://chrome.google.com/webstore/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia) to help you debug.\n\n**Note**: To use the plugin, you will need to pass `enableDevMode: true` when creating your GrowthBook instance.\n\n```\nconst growthbook = new GrowthBook({  enableDevMode: true,})\n```\n\n## How do I run an A/B test in GrowthBook?[​](#how-do-i-run-an-ab-test-in-growthbook \"Direct link to How do I run an A/B test in GrowthBook?\")\n\nThe recommended way to run an A/B test is by using Feature Flags and our SDKs.\n\n1.  Create a feature in GrowthBook (e.g. `new-signup-form`) with an A/B Experiment rule\n2.  Use our SDKs to serve the different variations\n    \n    ```\n    if (growthbook.feature(\"new-signup-form\").on) {  // Variation} else {  // Control}\n    ```\n    \n\n## What is the best way to redirect users to a URL based on their experiment variation?[​](#what-is-the-best-way-to-redirect-users-to-a-url-based-on-their-experiment-variation \"Direct link to What is the best way to redirect users to a URL based on their experiment variation?\")\n\nYou can now easily set up URL Redirect experiments within GrowthBook and customize navigation depending on your application. Read more about running a URL Redirect experiment [here](https://docs.growthbook.io/app/url-redirects).\n\n## How much traffic do I need to run A/B tests?[​](#how-much-traffic-do-i-need-to-run-ab-tests \"Direct link to How much traffic do I need to run A/B tests?\")\n\nWhat matters most for A/B testing is not traffic, but conversions. The general rule of thumb is to have at least 100-200 conversions per variation before you might start reaching significance.\n\nSo that means if you do 50 orders per week and that's the metric you are trying to optimize, you'll need to run a simple 2-way A/B test for at least 4-8 weeks. If you run a 3-way test, it will take 6-12 weeks.\n\n## Can I run multiple A/B tests at a time?[​](#can-i-run-multiple-ab-tests-at-a-time \"Direct link to Can I run multiple A/B tests at a time?\")\n\nYes! In fact, we recommend running many experiments in parallel in your application. Most A/B tests fail, so the more shots-on-goal you take, the more likely you are to get a winner. Running tests in parallel is a great way to increase your velocity.\n\nNow it's possible your experiments might have interaction effects, but these are actually pretty rare in practice. One example is if one test is changing the text color on a page and another test is changing the background color. Some users might see end up seeing black text on a black background, which is obviously not ideal. For these rare cases, you can use [Namespaces](https://docs.growthbook.io/features/rules#namespaces) to run mutually exclusive experiments.\n\nAs long as you apply a little common sense to avoid situations like the above, running multiple experiments has low risk and really high reward.\n\n## What is the difference between a Dimension and a Segment?[​](#what-is-the-difference-between-a-dimension-and-a-segment \"Direct link to What is the difference between a Dimension and a Segment?\")\n\nA dimension is a user attribute that can have multiple values. Some examples are `country`, `account_type`, and `browser`.\n\nA segment is a specific group of users. Some examples are `visitors in the US`, `premium users`, and `chrome users`.\n\nDimensions are used to explore experiment results. For example, you can use a `country` dimension to see which countries had the highest conversion rates. Or an `account_type` dimension to see if there was a significant difference in how free vs paid users behaved. Or a `browser` dimension to detect any browser-specific bugs in your implementation.\n\nSegments can apply a filter to results, usually to compensate for bad data. For example, if your experiment was only visible to premium users, but your database inaccurately shows that free users were also included, you could apply a `premium users` segment to only include those who were actually exposed to the test. Ideally, you could just fix the underlying data, but that's often not feasible so segments provide a quick and dirty alternative.\n\n## Which docker image tag should I use when self-hosting?[​](#which-docker-image-tag-should-i-use-when-self-hosting \"Direct link to Which docker image tag should I use when self-hosting?\")\n\nWe recommend using the `latest` tag for both dev and production self-hosted deployments. This tag represents the latest stable build of GrowthBook and is what the Cloud app uses.\n\nSpecific version tags (e.g. `v1.1.0`) are only released periodically (about once a month) and you will miss out on the many bug fixes and features added between major releases.\n\nWe also recommend updating the image regularly. You can do that by downloading the latest image (`docker pull growthbook/growthbook:latest`) and restarting the container.\n\n## What are the hardware requirements for self-hosting GrowthBook?[​](#what-are-the-hardware-requirements-for-self-hosting-growthbook \"Direct link to What are the hardware requirements for self-hosting GrowthBook?\")\n\nThe GrowthBook application is very lightweight and efficient. For most usecases, 2GB of memory is sufficient even for large production deployments.\n\nGrowthBook only deals with aggregate data and the bulk of the processing is offloaded to your data source. Because of this, you can easily analyze terrabytes of data from your laptop or a small container in the cloud.\n\nIf you are using feature flags, **we strongly recommend** adding a caching layer between the GrowthBook API and your application in production. This will also help you stay within the limits of our [Fair Use Policy](https://www.growthbook.io/fair-use). Some of our [code examples](https://github.com/growthbook/examples) implement caching. We offer a pre-built [GrowthBook Proxy server](https://docs.growthbook.io/self-host/proxy) you can run that handles caching and invalidation automatically. You can also setup your own custom system using a CDN or distributed cache like Redis.\n\n## I can't upload to S3/getting 400 error when uploading to S3?[​](#i-cant-upload-to-s3getting-400-error-when-uploading-to-s3 \"Direct link to I can't upload to S3/getting 400 error when uploading to S3?\")\n\n*   Make sure you've correctly set the `S3_BUCKET` and `S3_REGION` environment variables\n*   Enable bucket ACL and set ownership to Bucket owner preferred: [read more here](https://stackoverflow.com/questions/70333681/for-an-amazon-s3-bucket-deplolyent-from-guithub-how-do-i-fix-the-error-accesscon).\n*   Make sure the S3 bucket is publically accessible\n*   Make sure CORS settings are correct. Add your URLs to the AllowedOrigins array or set to \"\\*\"\n\n*   Make sure you are using the React or Javascript SDK\n*   Install the [Chrome DevTools Extension](https://chrome.google.com/webstore/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia)\n*   Pass the `enableDevMode: true` option into the GrowthBook constructor\n\n```\nconst growthbook = new GrowthBook({  enableDevMode: true,})\n```\n\n## My old exported notebook stopped working. How can I fix it?[​](#my-old-exported-notebook-stopped-working-how-can-i-fix-it \"Direct link to My old exported notebook stopped working. How can I fix it?\")\n\nThere's a good chance that the SQL we are exporting and your version of our Python stats library, `gbstats`, are out of sync. In February of 2023 we updated our SQL engines and `gbstats` library to only use sums and sums of squares, rather than averages and standard deviations.\n\nIf the queries in your notebook return averages and standard deviations (using `AVG` and `VAR` SQL operators as part of the `__stats` CTE), then you need to run that notebook with `gbstats` version 0.3.1. You can download this from PyPI [here](https://pypi.org/project/gbstats/0.3.1/) using `pip install gbstats==0.3.1` and ensure that your kernel uses that version of `gbstats`. Ideally in this case you can redownload the notebook and use the new `gbstats` library (0.4.0 or newer). You can download a new notebook by navigating to your experiment in GrowthBook and clicking `Download Notebook` again. This should now use the updated SQL and `gbstats` syntax. Then, if you install `gbstats` 0.4.0 or later, everything should work as expected.\n\nIf the queries in your notebook return sums and sums of squares as part of the `__stats` CTE but your notebook is still erroring, then you probably have an old `gbstats` version installed and need to update to 0.4.0 or later. You can download this from PyPI [here](https://pypi.org/project/gbstats) using `pip install gbstats` and ensure that your kernel uses that version of `gbstats`.\n\n## My features aren't refreshing as expected. What can I do?[​](#my-features-arent-refreshing-as-expected-what-can-i-do \"Direct link to My features aren't refreshing as expected. What can I do?\")\n\nOur SDK's implement a stale-while-revalidate approach to cacheing with a configurable time-to-live (TTL) value.\n\nThis means that if the feature payload is considered stale (i.e. more than the TTL amount of time has passed since it's been updated), **the next request will return the stale features** and refetch an update asynchronously so that on the next request, the features will be up to date. You can learn more about how our SDK's implement this in detail [here](https://docs.growthbook.io/lib/build-your-own#fetching-and-caching-features).\n\nIf you would like something more real-time than this stale-while-revalidate approach, you may want to consider implementing the [GrowthBook Proxy](https://docs.growthbook.io/self-host/proxy) on your self-hosted instance.\n\n## How do I configure environments in the SDK?[​](#how-do-i-configure-environments-in-the-sdk \"Direct link to How do I configure environments in the SDK?\")\n\nWhen you create an SDK connection, it is linked to a specific environment. You can learn more about environments [here](https://docs.growthbook.io/features/environments).\n\n## How do I disable the on-screen celebrations?[​](#how-do-i-disable-the-on-screen-celebrations \"Direct link to How do I disable the on-screen celebrations?\")\n\nThroughout the GrowthBook application, we randomly celebrate key milestones like launching experiments with on-screen confetti. If you'd like to disable this, you can click on your avatar in the top right corner and select \"Edit Profile\". From there, you can disable the toggle for \"Allow Celebrations\". Please note this is persisted in your browser's local storage, so if you clear your browser's local storage, you will need to disable this again.\n\n## How do I make my own identifier?[​](#how-do-i-make-my-own-identifier \"Direct link to How do I make my own identifier?\")\n\nThere are cases when using feature flags client side where the 3rd party identifiers used for assignment will be slow to load, and may cause flickering as some of the DOM rerenders. In these cases, generating your own identifier will make sure that features are assigned correctly when GrowthBook loads. This id that is generated will typically align one to one with the other identifiers, and does not need to be passed outside the SDK (though can be useful for debugging to pass this value in the trackingCallback).\n\nThe code below can be used to generate a unique user id and save it in a cookie for the maximum amount of time allowed. Note, this technique is already included with our HTML/no-code SDK. Please be aware of any cookie policies this code may impact. This id will be unique to the browser and not the user, so if a user switches devices, they will have a different id.\n\n```\nconst getUUID = () => {  const COOKIE_NAME = \"gbuuid\";  const COOKIE_DAYS = 400; // 400 days is the max cookie duration for chrome  // use the browsers crypto.randomUUID if set  const genUUID = () => {    if(window?.crypto?.randomUUID) return window.crypto.randomUUID();    return ([1e7]+-1e3+-4e3+-8e3+-1e11).replace(/[018]/g, c =>      (c ^ crypto.getRandomValues(new Uint8Array(1))[0] & 15 >> c / 4).toString(16)    );  }  const getCookie = (name) => {    let value = `; ${document.cookie}`;    let parts = value.split(`; ${name}=`);    if (parts.length === 2) {      let existing = parts.pop().split(';').shift();      setCookie(name, existing);      return existing;    }  }  const setCookie = (name, value) => {    var d = new Date();    d.setTime(d.getTime() + 24*60*60*1000*COOKIE_DAYS);    document.cookie = name + \"=\" + value + \";path=/;expires=\" + d.toGMTString();  }  // get the existing UUID from cookie if set, otherwise create one and store it in the cookie  let existing = getCookie(COOKIE_NAME);  if(existing) return existing;  const uuid = genUUID();  setCookie(COOKIE_NAME, uuid);  return uuid;}\n```\n\nBelow is the same code, minified:\n\n```\nconst getUUID=()=>{const a=(a,b)=>{var c=new Date;c.setTime(c.getTime()+86400000*400),document.cookie=a+\"=\"+b+\";path=/;expires=\"+c.toGMTString()};let b=(b=>{let c=`; ${document.cookie}`,d=c.split(`; ${b}=`);if(2===d.length){let c=d.pop().split(\";\").shift();return a(b,c),c}})(\"gbuuid\");if(b)return b;const c=(()=>window?.crypto?.randomUUID?window.crypto.randomUUID():\"10000000-1000-4000-8000-100000000000\".replace(/[018]/g,a=>(a^crypto.getRandomValues(new Uint8Array(1))[0]&15>>a/4).toString(16)))();return a(\"gbuuid\",c),c};\n```\n\n* * *\n\n## Can't find your question?[​](#cant-find-your-question \"Direct link to Can't find your question?\")\n\nIf you can't find an answer to your question above, please let us know so we can help you out and improve the docs for future users!\n\nYou can join our [Slack channel](https://slack.growthbook.io/?ref=docs-faq) for the fastest response times.\n\nOr send an email to [hello@growthbook.io](mailto:hello@growthbook.io) if Slack isn't your thing.",
  "title": "FAQ | GrowthBook Docs",
  "description": "Frequently asked questions about GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/using/fundamentals",
  "markdown": "# A/B Testing Fundamentals | GrowthBook Docs\n\nIf you are new to A/B testing, you may find a lot of new terminology. The goal of this section is to help you understand the basics of A/B testing.\n\n## Glossary - Common Experimentation Terms[​](#glossary---common-experimentation-terms \"Direct link to Glossary - Common Experimentation Terms\")\n\n### Control (or Baseline)[​](#control-or-baseline \"Direct link to Control (or Baseline)\")\n\nThe existing version of the product that you are trying to improve upon.\n\n### Variation (or Treatment)[​](#variation-or-treatment \"Direct link to Variation (or Treatment)\")\n\nA new version of the page that you are testing against the Control.\n\n### Hypothesis[​](#hypothesis \"Direct link to Hypothesis\")\n\nFormal way to describe what you are changing and what you think it will do.\n\n### Statistical Significance[​](#statistical-significance \"Direct link to Statistical Significance\")\n\nAn indicator that the difference in performance between the control and treatment groups is unlikely to have occurred by chance.\n\n### Confidence level[​](#confidence-level \"Direct link to Confidence level\")\n\nThe level of certainty we want before the result of a test is statistically significant. A common confidence level used in A/B testing is 95%.\n\n### Sample size[​](#sample-size \"Direct link to Sample size\")\n\nThe number of visitors or users who are included in the A/B test.\n\n### Test duration[​](#test-duration \"Direct link to Test duration\")\n\nThe length of time that the A/B test is run. This can vary depending on the sample size and the desired confidence level.\n\n### Variance[​](#variance \"Direct link to Variance\")\n\nThe degree to which the results of an A/B test vary over time or across different segments of the user base.\n\n## Anatomy of an A/B test[​](#anatomy-of-an-ab-test \"Direct link to Anatomy of an A/B test\")\n\n![Anatomy of an A/B test](https://docs.growthbook.io/assets/images/ab-test-diagram-63db820ea7e29530da0b5847145714d4.png)\n\n|     |     |     |     |     |\n| --- | --- | --- | --- | --- |\n| **Hypothesis**<br><br>Come up with an idea you want to test | **Assignment**<br><br>Randomly split your audience into persistent groups | **Variations**<br><br>Create and show different experiences to each group | **Tracking**<br><br>Record events and behaviors of the two groups | **Results**<br><br>Use statistics to determine if the differences in behavior are significant |\n\n### Hypothesis[​](#hypothesis-1 \"Direct link to Hypothesis\")\n\nGood A/B tests, and really any project, starts with a hypothesis about what you’re trying to do. A good hypothesis should be as simple, specific, and falsifiable as possible.\n\nA good A/B test hypothesis should be:\n\n*   **Specific**: The hypothesis should clearly state what you want to test and what outcome you expect to see.\n*   **Measurable**: The hypothesis should include a metric or metrics that can be used to evaluate the outcome of the test.\n*   **Relevant**: The hypothesis should be relevant to your business goals and objectives.\n*   **Clear**: The hypothesis should be easy to understand and communicate to others.\n*   **Simple**: The fewer variables that are involved in the experiment, the more causality can be implied in the results.\n*   **Falsifiable**: The hypothesis should be something that can be tested using an A/B test to determine the validity of the hypothesis.\n\nOverall, a good A/B test hypothesis should be a clear statement that identifies a specific change you want to make and the expected impact on a measurable outcome, while being grounded in data and relevant to your business goals.\n\n### Audience and Assignments[​](#audience-and-assignments \"Direct link to Audience and Assignments\")\n\nChoose the audience for your experiment. To increase the detectable effect of your experiment, the audience you choose should be as close to the experiment as possible. For example, if you’re focusing on a new user registration form, you should select as your audience just unregistered users. If you were to include all users, you would have users who could not see the experiment, which would increase the noise and reduce the ability to detect an effect. Once you have selected your audience, you will randomize users to one variation or another.\n\n### Variations[​](#variations \"Direct link to Variations\")\n\nAn A/B test can include as many variations as you like. Typically the A variation is the control variation. The variations can have as many changes as you like, but the more you change the less certain you can be what caused the change.\n\n### Tracking[​](#tracking \"Direct link to Tracking\")\n\nTracking is the process of recording events and behaviors that your users do. In the context of AB testing, you want to track events that happen after exposure to the experiment, as these events will be used to determine if there is a change in performance due to being exposed to the experiment. AB testing systems either are \"warehouse native\" (like GrowthBook) as in they use your existing event trackers (like GA, Segment, Rudderstack, etc), or they require you to send event data to them.\n\n### Results[​](#results \"Direct link to Results\")\n\nWith A/B testing we use statistics to determine if the effect we measure on a metric of interest is significantly different across variations. The results of an A/B test on a particular metric can have three possible outcomes: win, loss, or inconclusive. With GrowthBook we offer two different statistical approaches, Frequentist and Bayesian. By default, GrowthBook uses Bayesian statistics. Each method has their pros and cons, but both will provide you with evidence as to how each variation affected your metrics.\n\n## Experimentation Basics[​](#experimentation-basics \"Direct link to Experimentation Basics\")\n\n### Typical success rates[​](#typical-success-rates \"Direct link to Typical success rates\")\n\nA/B testing can be incredibly humbling—one quickly learns how often our intuition about what will be successful with our users is incorrect. Industry wide average success rates are only about 33%. ⅓ of the time our experiments are successful in improving the metrics we intended to improve, ⅓ of the time we have no effect, and ⅓ of the time we hurt those metrics. Furthermore, the more optimized your product is, the lower your success rates tend to be.\n\nBut A/B testing is not only humbling, it can dramatically improve decision making. Rather than thinking we only win 33% of the time, the above statistics really show that A/B tests help us make a clearly right decision about 66% of the time. Of course, shipping a product that won (33% of the time) is a win, but so is not shipping a product that lost (another 33% of the time). Failing fast through experimentation is success in terms of loss avoidance, as you are not shipping products that are hurting your metrics of interest.\n\n### Experiment power[​](#experiment-power \"Direct link to Experiment power\")\n\nWith A/B testing, power analysis refers to whether a test can reliably detect an effect. Specifically, it is often written as the percent of the time a test would detect an effect of a given size with a given number of users. You can also think of the power of a test with respect to the sample size. For example: \"How many times do I need to toss a coin to conclude it is rigged by a certain amount?\"\n\n### Minimal Detectable Effect (MDE)[​](#minimal-detectable-effect-mde \"Direct link to Minimal Detectable Effect (MDE)\")\n\nMinimal Detectable Effect is the minimum difference in performance between the control and treatment groups that can be detected by the A/B test, given a certain statistical significance threshold and power. The MDE is an important consideration when designing an A/B test because if the expected effect size is smaller than the MDE, then the test may not be able to detect a significant difference between the groups, even if one exists. Therefore, it is useful to calculate the MDE based on the desired level of statistical significance, power, and sample size, and ensure that the expected effect size is larger than the MDE in order to ensure that the A/B test is able to accurately detect the difference between the control and treatment groups.\n\n### False Positives (Type I Errors) and False Negatives (Type II Errors)[​](#false-positives-type-i-errors-and-false-negatives-type-ii-errors \"Direct link to False Positives (Type I Errors) and False Negatives (Type II Errors)\")\n\nWhen making decisions about an experiment, we can say that we made the right decision when choosing to ship a winning variation or shut down a losing variation. However, because there is always uncertainty in the world and we rely on statistics, sometimes we make mistakes. Generally, there are two kinds of errors we can make: Type I and Type II errors.\n\n**Type I Errors**: also known as False Positives, these are errors we make when we think the experiment provides us with a clear winner or a clear loser, but in reality the data are not clear enough to make this decision. For example, your metrics all appear to be winners, but in reality the experiment has no effect.\n\n**Type II Errors**: also known as False Negatives, these are errors we make when the data appear inconclusive, but in reality there is a winner or a loser. For example, you run an experiment for as long as you planned to, and the data aren’t showing a clear winner or loser when actually a variation is much better or worse. Type II errors often require you to collect more data or choose blindly rather than provide you with the correct, clear answer\n\n|     |     |     |     |     |\n| --- | --- | --- | --- | --- |\n|     |     | Actual Results |     |     |\n| **Inconclusive** | **Lost** | **Won** |\n| Decision Made | **Inconclusive** | Correct Inference | Type II error  <br>(false negative) | Type II error  <br>(false negative) |\n| **Shut down** | Type I error  <br>(false positive) | Correct Inference | Type I error  <br>(false positive) |\n| **Ship** | Type I error  <br>(false positive) | Type I error  <br>(false positive) | Correct Inference |\n\n### P-Value[​](#p-value \"Direct link to P-Value\")\n\nIn frequentist statistics, a p-value is a measure of the evidence against a null hypothesis. The null hypothesis is the hypothesis that there is no significant difference between two groups, or no relationship between two variables. In the context of A/B testing, the p-value is a statistical measure that indicates whether there is a significant difference between two groups, A and B.\n\nThe p-value is the probability of observing a difference as extreme or more extreme as your actual difference, given there is actually no difference between groups. If the p-value is less than a predetermined level of significance (often 0.05), the result is deemed to be statistically significant as the difference is not likely due to chance.\n\nFor example, let's say that you conduct an A/B test in which you randomly assign users to either group A (the control group) or group B (the experimental group). You measure a specific metric such as conversion rate for each group, and you calculate the p-value to test the hypothesis that there is no difference between the two groups. If the p-value is less than 0.05, the observed difference conversion rate between the two groups is unlikely if there wasn't truly a difference in groups; we say the effect is statistically significant and likely not due to chance.\n\nIt's important to note that p-value alone cannot determine the importance or practical significance of the findings. Additionally, it's essential to consider other factors such as effect size, sample size, and study design when interpreting the results.\n\n### A/A Tests[​](#aa-tests \"Direct link to A/A Tests\")\n\nA/A testing is a form of A/B testing in which instead of serving two different variations, two identical versions of a product or design are tested against each other. In A/A testing, the purpose is not to compare the performance of the two versions, but rather to check the consistency of the testing platform and methodology.\n\nThe idea behind A/A testing is that if the two identical versions of the product or design produce significantly different results, then there may be an issue with the testing platform or methodology that is causing the inconsistency. By running an A/A test, you can identify and address any potential issues before running an A/B test, which can help ensure that the results of the A/B test are reliable and meaningful.\n\nA/A testing is a useful tool for ensuring the accuracy and reliability of A/B tests, and can help improve the trust in the platform, and faith in the quality of the insights and decisions that are based on the results of these tests.\n\n[Read more about running A/A tests in GrowthBook](https://docs.growthbook.io/kb/experiments/aa-tests).\n\n### Interaction effects[​](#interaction-effects \"Direct link to Interaction effects\")\n\nWhen you run more than one test at a time, there is a chance that the tests may interfere with each other. For example, you could have two tests that change the price on two different parts of your product. Some combinations of the two experiments can cause users to see two different prices confused and lose trust in your product. This is an extreme example. A more common example is someone who sees an experiment on the account registration page, and then another test on the checkout page. If the tests are run in parallel, you will have users who see all combinations of variations: **AA, AB, BA**, and **BB**. A _meaningful_ interaction effect would be the combination of AA, for example, out performs the other combinations more than each test alone. If there are interaction effects of tests run in parallel, but they are unlikely to be meaningful. Most often they will just increase the variance of the tests without changing the results.\n\n### Novelty and Primacy Effects[​](#novelty-and-primacy-effects \"Direct link to Novelty and Primacy Effects\")\n\nNovelty and primacy effects are psychological phenomena that can influence the results of A/B testing. The novelty effect refers to the tendency of people to react positively to something new and different. In the context of A/B testing, a new design or feature may initially perform better than an existing design simply because it is new and novel. However, over time, the novelty effect may wear off and the performance of the new design may decrease.\n\nThe primacy effect refers to the tendency of people to remember and give more weight to information that they encounter first. With A/B testing, this can manifest as an initial reduction in the improvement for metrics as users prefer the original treatment of the product.\n\nOne way to mitigate the effects of novelty is to run tests over a longer period of time to allow for the novelty effect to wear off. Another approach is to stagger the rollout of a new design or feature to gradually introduce it to users and avoid a sudden and overwhelming change.\n\nTo account for the primacy effect, you can target or segment an experiment to just new users to ensure that they won’t be influenced by how things used to work. This can help ensure that the results of the test are truly reflective of user behavior and preferences, rather than the order in which designs were presented.",
  "title": "A/B Testing Fundamentals | GrowthBook Docs",
  "description": "If you are new to A/B testing, you may find a lot of new terminology. The goal of this section is to help",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/kb/experiments/troubleshooting-experiments",
  "markdown": "# Troubleshooting Experiments | GrowthBook Docs\n\n## Problem 1: No traffic flowing into the experiment[​](#problem-1-no-traffic-flowing-into-the-experiment \"Direct link to Problem 1: No traffic flowing into the experiment\")\n\nThere are a few common reasons why there may not be any data showing in the Results tab of your experiment's detail page, first among them is a lack of experiment traffic. You'll likely see a banner like this:\n\n![No Data Banner](data:image/png;base64,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)\n\nCheck the following to correct a lack of traffic to the experiment:\n\n*   **Ensure the trackingCallback in the SDK is configured correctly.** It should be using the intended tracking library (e.g. Google Analytics \\[GA4\\], Segment, Amplitude) and actually emitting tracking events to your data warehouse.\n*   **Ensure the Hash Attribute identifier is being set for each user.** When you start an experiment in GrowthBook, you need to choose which Attribute to use to assign users to variations, often the user `id`. If you do not set that Attribute when you instantiate the GrowthBook SDK, then users can't be assigned to the right variation and users will default to not entering the experiment at all.\n*   **Ensure the Experiment Assignment Query in your data source is configured correctly.** You can find this query on your data source's detail page.\n\n## Problem 2: SRM errors (traffic imbalance) in the experiment[​](#problem-2-srm-errors-traffic-imbalance-in-the-experiment \"Direct link to Problem 2: SRM errors (traffic imbalance) in the experiment\")\n\nA clue that the traffic to the experiment isn't balanced is the presence of a Sample Ratio Mismatch error, shown as a warning banner at the top of the Results tab.\n\n![SRM Warning](data:image/png;base64,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)\n\nWhenever there is traffic imbalance in your GrowthBook experiment, the cause is usually one (or several) of these problems:\n\n1.  **The trackingCallback is configured incorrectly**, which is causing it to send an event to your data warehouse _only under certain condition_s.\n2.  You are using an **Activation Metric** that is triggered differently by users across variations.\n3.  **The Hash Attribute doesn't match the \"Identifier Type\" in your data source.**\n4.  **You made a change to the experiment targeting after it started, or created a new phase without re-randomizing.**\n\n### Solution 1: Ensure the trackingCallback is triggered unconditionally[​](#solution-1-ensure-the-trackingcallback-is-triggered-unconditionally \"Direct link to Solution 1: Ensure the trackingCallback is triggered unconditionally\")\n\nThe trackingCallback you configure is used by the SDK to send tracking events to your data warehouse whenever a user is exposed to an experiment. Make sure that whether the trackingCallback method sends event data is _not conditional_ on the experiment variation.\n\nAs you create the GrowthBook-related logic in your application code, be careful not to have users in control variations emit trackingCallbacks under more conditions than users who are _not_ bucketed into the control variation. Otherwise, you are likely to have Sample Ratio Mismatch (SRM) issues.\n\nIt is much better to emit a tracking event as soon as possible within the trackingCallback, before doing any other custom logic that may differ across users based on the experiment variations they are exposed to.\n\n### Solution 2: Only use Activation Metrics that do not differ across variations[​](#solution-2-only-use-activation-metrics-that-do-not-differ-across-variations \"Direct link to Solution 2: Only use Activation Metrics that do not differ across variations\")\n\nIf you are using an Activation Metric to filter users that get into your experiment analysis, you may be introducing bias if the Activation Metric is downstream of any differences between users in your variations.\n\nSimilar to the above issue where your trackingCallback fires more for users in one variation than another, if you filter out users based on some activity that differs across variations then you could be introducing bias and causing SRM errors.\n\nThe upshot is that you should not use an Activation Metric lightly. It should be a Metric that is downstream of changes to the user experience caused by the experiment. Imagine you want to check a user variation on page load, but you want to use an Activation Metric to only look at effects once users open the checkout modal where the experiment is. If you have to load more data for users in your test variation, the page may crash or be slower for those users; if this happens before you measure the Activation Metric, then you may be causing traffic imbalance as you will see fewer users in the variation in your experiment sample.\n\nIn fact, using an Activation Metric that is downstream of any difference in variations can cause bias that is not picked up by SRM errors, so you should try to avoid this whenever possible.\n\nBest practices:\n\n*   Try not to use Activation Metrics at all, and instead only use the SDK to look up experiment membership as close as possible to the actual experiment.\n*   If you must use an Activation Metric, make sure it is not downstream of any differences in the user experience caused by the experiment.\n*   Check the Health Tab on your experiment results to see traffic breakdowns by Activation Status to help you understand what your Activation Metric is doing to your sample.\n\n### Solution 3: Ensure the Hash Attribute and Identifier Type match[​](#solution-3-ensure-the-hash-attribute-and-identifier-type-match \"Direct link to Solution 3: Ensure the Hash Attribute and Identifier Type match\")\n\nGrowthBook randomizes users according to the Hash Attribute that you set for each user, often a `user_id`. When you analyze experiments, you set an \"Identifier Type\" that corresponds to columns in your data warehouse. Ideally, the Hash Attribute that you choose for users is both (1) logged to the data warehouse in the trackingCallback, and (2) is used as the \"Identifier Type\" for all of these experiments. By doing this, you establish a 1:1 relationship between the Hash Attribute and the Identifier Type.\n\nFor example, suppose you run experiments and you sometimes randomize users by `device_id` and sometimes randomize by `user_id`, setting the Hash Attribute as `device_id` or `user_id` respectively. You would set up your trackingCallback so that the Identifier Types are logged to your data warehouse with each experiment exposure.\n\nThen, you would also have two Identifier Types in your data source, one for each Hash Attribute (`device_id` and `user_id`), and define Experiment Assignment Queries to query your data source for all the experiments of each Identifier Type.\n\nIf for some reason the Identifier in your data warehouse is different from your Hash Attribute, you could see Multiple Exposure warnings and Sample Ratio Mismatch (SRM) errors, because the ID chosen to randomize users doesn't match the ID on which queries are running in your data warehouse. You would fix this so that there is a 1:1 mapping between the Identifier and Hash Attribute by ensuring the Hash Attributes are always emitted to the data warehouse, and use set these values as the Identifier Types in GrowthBook.\n\n**Why might the Hash Attribute and Identifier Type be different?**\n\nThere are times where it might be beneficial to have the Hash Attribute differ from the Identifier Type. The consequence is that there may be minor traffic imbalance or Multiple Exposures, but you may be willing to accept some slippage in the 1:1 mapping between Identifier Type and Hash Attribute in order to more easily join experiment exposure data with metric data.\n\nFor example, on client-side experiments with Google Analytics (GA4), you may wish to avoid flickering by hashing on some custom ID as we do in our [Script Tag SDK](https://docs.growthbook.io/lib/script-tag) and not wait for the IDs provided by GA4.\n\nWhile you could send this custom ID in your trackingCallback you may prefer to use GA4 identifiers as the Identifier Type instead, because they are already tracked with many of the other GA4 events that you are using as Metrics.\n\n### Solution 4: Minimize Experiment targeting changes while running[​](#solution-4-minimize-experiment-targeting-changes-while-running \"Direct link to Solution 4: Minimize Experiment targeting changes while running\")\n\nWhen you make changes to the targeting of an experiment or created a new phase without re-randomizing users, it's possible that the traffic to the experiment will become imbalanced. This is because the users who were already in the experiment may continue to be in the same variation at differing rates. Whenever creating a new phase, you should re-randomize traffic when possible, and only certain changes to an experiment's targeting conditions can be done without re-randomizing.\n\nYou can read more about the [rules for changing experiment targeting](https://docs.growthbook.io/app/making-experiment-changes) and [carryover bias](https://docs.growthbook.io/kb/experiments/carryover-bias) in our documentation.\n\nIf your experiment is suffering from these issues, unfortunately the only solution may be to restart the experiment (you can do this by creating a new phase and choosing to re-randomize traffic). Of course, some amount of bias and SRM may be preferable to throwing out your data, but this depends on the magnitude of the problem.\n\n## Problem 3: Multiple Exposures[​](#problem-3-multiple-exposures \"Direct link to Problem 3: Multiple Exposures\")\n\nWe default to allowing 1 percent of units (e.g. users) in an experiment have multiple exposures without raising a warning due to the fact that many experimenters have slight mismatches in hashing attributes and warehouse tracking that can cause minor errors. You can adjust this in your organization settings under Settings > General > Experiment Settings.\n\nIf you have multiple exposure errors, the issue is fundamentally caused by a mismatch between the attribute that you are randomizing on (your \"hash attribute\") and the identifier being stored in your data warehouse. You can [read more about this problem and how to solve it here](#solution-3-ensure-the-hash-attribute-and-identifier-type-match).\n\nAnother potential issue is that you made unsafe changes to your experiment targeting and randomization. We attempt to prevent this by having a curated flow for making changes, but we provide you with flexibility to make a whole host of changes that could result in multiple exposures if you choose to override our warnings. YOu can read more about our [rules for changing experiments while running here](https://docs.growthbook.io/app/making-experiment-changes).\n\n## Problem 4: Metric averages don't look as expected[​](#problem-4-metric-averages-dont-look-as-expected \"Direct link to Problem 4: Metric averages don't look as expected\")\n\nIt's important to ensure that the Metric values in the baseline and variation are what you would expect. This helps confirm that the Metrics are set up correctly and that they are joining properly to the Experiment Assignment Queries.\n\nIn the image below, notice that the values look like reasonable, per-user averages. If there is no data or if the values are very different from what you'd expect, consider the solutions below.\n\n![Reasonable Metric Averages](data:image/png;base64,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)\n\n### Solution: Understand the experiment's population[​](#solution-understand-the-experiments-population \"Direct link to Solution: Understand the experiment's population\")\n\nSometimes the Metric values in an experiment may surprise you if you are targeting an experiment to new users (values may be low!) or power users (values may be high!). Each experiment can have different targeting Attributes, and it is totally possible that the values are representing that experiment's population. Consider this before launching into in-depth investigations of your Metric's set-up.\n\n### Solution: Check the Metric's configuration[​](#solution-check-the-metrics-configuration \"Direct link to Solution: Check the Metric's configuration\")\n\nYou can confirm that the Metric is returning the right values in the table rows on a per-user basis. Navigate to the Metric page, edit the SQL for the Metric, and use the Edit SQL interface to run test queries and make modifications to make sure the rows you are getting are what you expect. The results should show the right identifiers, timestamps, and values.\n\nYou should also make sure the [Metric Window](https://docs.growthbook.io/app/metrics#metric-windows) is not too short and not too long, otherwise it could be excluding or including too much data.\n\n### Solution: Make sure your Identifier Types are correct[​](#solution-make-sure-your-identifier-types-are-correct \"Direct link to Solution: Make sure your Identifier Types are correct\")\n\nIf you are seeing some users flow into your experiment but aren't seeing any Metric data, you should ensure that the Metric data is able to join to your experiment exposure data.\n\nThis is illustrated in the image below. Notice the 38,919 total users in the upper left corner, but no data in the \"Baseline\", \"Variation\", or \"Chance to Win\" columns:\n\n![No Metric Values](data:image/png;base64,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)\n\nGrowthBook relies on the Identifier Type in your data source to merge users in your experiment with Metric values. This is accomplished through the Experiment Assignment Query (for users) and the Metric (for Metric values). These Identifier Types must be the same, or linked by a Join Table, to run a query in GrowthBook. While we actually will throw an error if you can't join them, you may still have set up one or the other incorrectly to point to the wrong column, or the data in the columns for your Experiment Assignment Query and Metric may not overlap. It's a good idea to ensure that the values being produced by both queries are what you expect.\n\n### Solution: Understand the overall query logic better[​](#solution-understand-the-overall-query-logic-better \"Direct link to Solution: Understand the overall query logic better\")\n\nYou can view the queries generated by GrowthBook by navigating to the experiment's Results tab, looking on the right side of the page (shown below) and clicking \"View Queries\". You can then use parts of these queries and debug them by running raw SQL in your own data warehouse to make sure that your configuration is correct.\n\n![View Queries Button](https://docs.growthbook.io/assets/images/view-queries-button-18b880bbb11c604d1e5b362668127e3a.png)",
  "title": "Troubleshooting Experiments | GrowthBook Docs",
  "description": "Troubleshooting Experiments",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/using/experimentation-best-practices",
  "markdown": "# Experimentation Best Practices | GrowthBook Docs\n\n## Running experiments[​](#running-experiments \"Direct link to Running experiments\")\n\n### Running Your First Experiment[​](#running-your-first-experiment \"Direct link to Running Your First Experiment\")\n\nWhen you’ve finished integrating your experimentation platform (which for GrowthBook, is adding the SDK to your code), it’s time to start running an experiment. We suggest that you first an A/A test to validate your experimentation implementation is correctly splitting traffic, and producing statistically valid results.\n\n### Sample Sizes[​](#sample-sizes \"Direct link to Sample Sizes\")\n\nUnderstanding experiment power and MDE are important to predict how many samples are required. There are numerous online calculators that can be used to help you predict the sample size. Typical rule of thumb for the lowest number of samples required is that you want at least 100 conversion events per variation. So for example if you have a registration page which has a 10% conversion rate, and you have a 2 way (A and B) experiment that is looking to improve the member registrations, you will want to expose the experiment to at least 2,000 people (1000 per variation).\n\n### Test Duration[​](#test-duration \"Direct link to Test Duration\")\n\nDue to the natural variability in traffic day to day and hour to hour, experimentation teams will often set a minimum test duration within which a test cannot be called. This helps you avoid optimizing a product for just the users that happen to visit when the test is started. For example, if the weekend traffic of your product is different from the traffic during the week, if you started a test on Friday and ended it on Monday, you may not get a complete picture of the impact your changes have to your weekday traffic. Typical test durations are 1 to 2 weeks, and usually care needs to be taken over holidays.\n\nYou may also find that a test would need to run for a month or more to get the power required for the experiment. Very long running tests can be hard to justify as you have to keep the variations of the experiment unchanged for duration, and this may limit your team's velocity towards potentially higher impact changes.\n\n### Interaction Effects and Mutual Exclusion[​](#interaction-effects-and-mutual-exclusion \"Direct link to Interaction Effects and Mutual Exclusion\")\n\nWhen you start having the ability to run a lot of A/B tests, it can be tempting to not want to run tests in parallel in case they have interaction effects (see above). For example you may want to test a change in the CTA button on your purchase page, and also test changing the price. It can be difficult to figure out if any two tests will meaningfully interact, and many will run the tests in serial in an abundance of caution.\n\nHowever, meaningful interactions are actually quite rare, and keeping a higher rate of experimentation is usually more beneficial. You can run analysis after the experiments to see if there were any interaction effects which would change your conclusions (GrowthBook is working on an integrated solution for this). If you need to run mutually exclusive tests, you can use GrowthBook’s [namespace](https://docs.growthbook.io/features/rules#namespaces) feature.\n\n### Experimentation Frequency[​](#experimentation-frequency \"Direct link to Experimentation Frequency\")\n\nHaving a high frequency of A/B testing is important for running a success experimentation program. The main reasons why experimentation frequency is important are:\n\n**Maximizing chances**: Since success rates are typically low for any given experiment, and large changes are even more rare, by having a high frequency of A/B testing you are maximizing your chance of having impactful experiments.\n\n**Continuous improvement**: A high frequency of A/B testing allows you to continuously improve your website or application. By testing small changes frequently, you can quickly identify and implement changes that improve user experience, engagement, and conversion rates.\n\n**Adaptability**: A high frequency of A/B testing allows you to quickly adapt to changes in user behavior, market trends, or other external factors that may impact your website or application. By testing frequently, you can identify and respond to these changes more quickly, ensuring that your site or app remains relevant and effective.\n\n**Avoiding stagnation**: A high frequency of A/B testing can help you avoid stagnation and complacency. By continually testing and experimenting, you can avoid falling into a rut or becoming overly attached to a specific design or strategy, and instead remain open to new ideas and approaches.\n\nQuote\n\n**_“If you want to have good ideas you must have many ideas. Most of them will be wrong, and what you have to learn is which ones to throw away.”_**\n\n\\- Linus Pauling",
  "title": "Experimentation Best Practices | GrowthBook Docs",
  "description": "Running experiments",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/using/product-development",
  "markdown": "# Experimentation-driven product development | GrowthBook Docs\n\nExperimentation-driven product development is a shift in product development from focusing **shipping** new products, to focus on shipping features that have an **impact** on your business. The best way of determining impact is through A/B testing.\n\n_The ideal goal with product-driven experimentation is to test every new feature that is developed._ This level of experimentation often requires adjusting your existing product process.\n\nIf you want to read more about how to make the case for experimentation-driven product development, or the benefits to your culture, you can read our section on [experimentation programs](https://docs.growthbook.io/using/programs).\n\n## Platform integration[​](#platform-integration \"Direct link to Platform integration\")\n\nExperimentation-driven product development requires a tight integration between your product and the experimentation platform. This is important to keep the incremental cost of running an experiment low, while increasing the ability to run a high volume of experiments. The cost can be cost in terms of effort, and cost in terms of actual money. You want to keep these a low as possible and make sure your platform encourages your team to run experiments.\n\nGiven this, many companies choose to build their own experimentation platform. This is a big undertaking, and much harder than it might seem at first. There is also ongoing maintenance costs, as well as the risk in making product decisions on a platform that might have undiscovered bugs.\n\n### Reducing costs[​](#reducing-costs \"Direct link to Reducing costs\")\n\nCosts of running experiments can be broken down into a few categories: the cost of data storage, the cost of engineering time, and the cost of the platform itself. GrowthBook is designed to address these costs directly and allow you to run a lot of experiments. GrowthBook is warehouse native and uses any data you already have. It was also designed to be extremely easy to add an experiment (2 lines of code) and have a high-quality developer experience that reduces engineering costs. GrowthBook itself is open-core and extremely economical to run.\n\n## Product prioritization changes[​](#product-prioritization-changes \"Direct link to Product prioritization changes\")\n\nAs you become aware of HiPPOs effect on your decision-making process and start to move away from this, you need another way to prioritize projects. There are many prioritization frameworks to help with this (we have a [whole section on experimentation prioritization frameworks](https://docs.growthbook.io/using/programs#prioritization)), but the goal the system you choose should be to encourage building smaller testable features, a high frequency of experiments, and to make sure you have a good mix of ideas and sizes of projects.\n\nThis is a big change from the traditional product development process, where we would spend a lot of time trying to predict what features will work, and then spend a lot of time building them. With experimentation-driven product development, we spend less time predicting and guessing and more time testing. This means that we can spend less time building features that don’t work, and more time building features that do work.\n\n### HAMM[​](#hamm \"Direct link to HAMM\")\n\nHAMM is a framework to help you think about experimentation-focused product development. It stands for Hypothesis, Actions, Measure, and MVP. It is one product framework to help increase your learning rate, and build a culture of experimentation.\n\n*   **Hypothesis**: What is the hypothesis you are testing? This should be a clear, falsifiable statement of what you are trying to learn. See our section on how to make good [hypothesis](https://docs.growthbook.io/using/fundamentals#hypothesis-1).\n*   **Actions**: What are the actions you expect your user to take if this hypothesis is true?\n*   **Measure**: What are the metrics that you could measure that would indicate that the user is doing the actions you expect? What might be a counterfactual metric that would indicate that the user is not doing the actions you expect? What are the guardrail metrics that you want to make sure you don't negatively impact?\n*   **MVP**: Given the above, what is the smallest thing you could build to test this hypothesis?\n\nThinking about the HAMM process at the beginning of a project lays the groundwork for a high-quality experiment. You'll have the hypothesis, the metrics, and the success criteria (OEC). With a smaller MVP or MTP (Minimum Testable Products), you can also increase your experimentation rate and therefore your learning rate.\n\n![John Hamm](https://docs.growthbook.io/images/using/jon_hamm-cropped.png)\n\n## Why you're not seeing experiment impacts[​](#why-youre-not-seeing-experiment-impacts \"Direct link to Why you're not seeing experiment impacts\")\n\nQuite often, companies run A/B tests that show positive results, and yet when overall metrics are examined, the impact of these tests is invisible. You might be expecting to see inflection points around the time the experiment was implemented. Here are some reasons why:\n\n*   **Confusing statistics** - Interpreting results can be confusing without a solid grasp of what the statistics are telling.\n*   **Bad practices** - You may be running experiments that are not valid, or are not measuring the right thing. See the Peeking problem.\n*   **Lost in the noise** - The impact of the experiment may be too small to be visible. This is especially true if you are running a lot of experiments - but this is not bad, just hard to see on a macro level.\n*   **Optimizing wrong product** - You might be experimenting with a section of your product that doesn't represent a large fraction of your overall use. Even if you're successful in these areas of the product, the overall impact will be limited by the small fraction of users that you've affected.\n*   **Optimizing wrong metric** - You might be optimizing for a metric that doesn't matter. For example, you might be optimizing for a metric that is not correlated with revenue, your main KPI. This is especially true if you are optimizing for a proxy metric, such as clicks, instead of the actual metric, such as revenue.\n\nYou can read more about this topic on our blog post [Why the impact of A/B testing can seem invisible](https://medium.com/growth-book/why-the-impact-of-a-b-testing-can-seem-invisible-5b2d69efa48)",
  "title": "Experimentation-driven product development | GrowthBook Docs",
  "description": "Experimentation-driven product development is a shift in product development from focusing shipping",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/using/experimentation-problems",
  "markdown": "# Where Experimentation goes wrong | GrowthBook Docs\n\nThe following contains a list of common pitfalls and mistakes that can happen when running A/B tests. It is important to be aware of these issues and to take steps to avoid them in order to ensure that your A/B tests are valid and reliable. It is by no means an exhaustive list.\n\n### Multiple Testing Problem[​](#multiple-testing-problem \"Direct link to Multiple Testing Problem\")\n\nThe multiple testing problem refers to the issue that arises when statistical hypothesis testing is performed on multiple variables simultaneously, leading to an increased likelihood of incorrectly rejecting a true null hypothesis ([Type I error](https://docs.growthbook.io/using/fundamentals#false-positives-type-i-errors-and-false-negatives-type-ii-errors)).\n\nFor example, if you test the same hypothesis at a 5% level of significance for 20 different metrics, the probability of finding at least one statistically significant result by chance alone is around 64%. This probability increases as the number of tests performed increases. This math assumes that the metrics are independent from one another, which in most cases for a digital application there will be some interaction between metrics (ie, page views is most likely related to sales funnel starts, or member registration to purchase events)\n\nTo address this problem, various multiple comparison correction methods can be used, such as the Bonferroni correction, False Discovery Rate (FDR) correction, or the Benjamini-Hochberg procedure. These methods adjust the significance level or the p-value threshold to account for the increased risk of false positives when multiple comparisons are made.\n\nIt's essential to be aware of this issue and select an appropriate correction method when conducting multiple statistical tests to avoid false discoveries and improve the accuracy and reliability of research findings. If you are using a high number of metrics, draw conclusions from the test thoughtfully and if you may consider running a follow up test just to test that one result or metric.\n\n### Texas Sharpshooter Fallacy[​](#texas-sharpshooter-fallacy \"Direct link to Texas Sharpshooter Fallacy\")\n\nThe Texas sharpshooter problem is a cognitive bias that involves cherry-picking data clusters to suit a particular argument, hypothesis, or bias. The name comes from the idea of a Texan marksman shooting at a barn and then painting a target around the cluster of bullet holes to create the appearance of accuracy. As the story goes, he then showed his neighbors and convinced them he was a great shot. It is closely related to the Multiple Testing Problem/Multiple Comparison Problem.\n\nIn the context of data analysis and statistics, the Texas sharpshooter problem refers to the danger of finding apparent patterns or correlations in data purely by chance and then using those patterns as if they were meaningful. This can lead to false conclusions and misguided decision-making. Texas sharpshooter problem is relevant in the sense that if you analyze the results of a test without a clear hypothesis or before setting up the experiment, you may be susceptible to finding patterns that are purely due to random variation. If you analyze the data in multiple ways or look at various subgroups without adjusting for multiple comparisons, you might identify spurious patterns that do not actually represent a true effect.\n\n### P-Hacking[​](#p-hacking \"Direct link to P-Hacking\")\n\nP-hacking, or data dredging, is a statistical fallacy that involves manipulating or analyzing data in various ways until a statistically significant result is achieved. It occurs when researchers or analysts repeatedly test their data using different methodologies or subsets of the data until they find a statistically significant result, even if the observed effect is due to chance.\n\nIn the context of A/B testing, p-hacking can be a significant concern. A/B testing involves comparing at least two versions (A and B) to determine which performs better. The danger of p-hacking arises when analysts, either consciously or unconsciously, explore different metrics, time periods, or subgroups until they find a statistically significant difference between the A and B groups.\n\n### Peeking[​](#peeking \"Direct link to Peeking\")\n\nThe peeking problem refers to the issue of experimenters making decisions about the results of an experiment based on early data. The more often the experiment is looked at, or ‘peeked’, the higher the false positive rates will be, meaning that the results are more likely to be significant by chance alone. Peeking typically applies to Frequentist statistics, which are statistically valid at their predetermined sample size. However, Bayesian statistics can also suffer from peeking depending on how decisions are made on the basis of Bayesian results.\n\nThe peeking problem in A/B testing occurs when the experimenter looks at the data during the experiment and decides to stop the test early based on the observed results, rather than waiting until the predetermined sample size or duration has been reached. This can lead to inflated false positive rates, as the results are more likely to be significant by chance alone if the experimenter stops the test early based on what they see in the data. The more often the experiment is looked at, or ‘peeked’, the higher the false positive rates will be.\n\nTo avoid the peeking problem in A/B testing, it's important to use a predetermined sample size or duration for the experiment and stick to the plan without making any changes based on the observed results. This helps to ensure that the statistical test is valid and that the results are not influenced by experimenter bias.\n\nAnother way to avoid the peeking problem in A/B testing is to use a statistical engine that is less susceptible to peeking, like a Bayesian with custom priors, or to use a method that accounts for peeking like Sequential testing.\n\n### Problems with client side A/B testing[​](#problems-with-client-side-ab-testing \"Direct link to Problems with client side A/B testing\")\n\nClient-side A/B testing is a technique where variations of a web page or application are served to users via JavaScript on the user's device, without requiring any server-side code changes. This technique can offer a fast and flexible way to test different variations of a website or application, but it can also present some potential problems, one of which is known as \"flickering.\"\n\nFlickering is a problem that can occur when the A/B test is implemented in a way that causes the user interface to render the original version, then flash or flicker as the variations are loaded. This can happen when the A/B test code is slow to load or when the A/B testing library is lacking performance. As a result, the user may see the original version of the page briefly before it is replaced with one of the variations being tested, leading to a jarring and confusing user experience. This flickering can lead to inaccurate or unreliable test results. Rather counterintuitively, flickering may have a positive effect on the results, sometimes the flashing may draw a users attention to that variation, and cause an inflation in the effect.\n\nTo avoid flickering in client-side A/B testing, it is important to implement the test code in a way that minimizes the delay between the original page and the variations being tested. This may involve preloading the test code or optimizing the code for faster loading times. GrowthBook’s SDKs are built for very high performance, and allow you to use client side A/B testing code inline, so there are no blocking 3rd party calls.\n\nYou can also use an alternative technique such as server-side testing or redirect-based testing to avoid flickering issues. If loading the SDK in the head does not sufficiently prevent flicking, you can also use an anti-flickering script. These scripts hide the page while the content is loading, and reveal the page after the experiment loaded. The problem with this is that while it technically prevents flickering, it slows how quickly your site appears to load.\n\n### Redirect tests (Split testing)[​](#redirect-tests-split-testing \"Direct link to Redirect tests (Split testing)\")\n\nRedirect-based A/B testing is a technique where users are redirected to different URLs or pages based on the A/B test variation they are assigned to. While this technique can be effective in certain scenarios, it can also present several potential problems that should be considered before implementation.\n\n**SEO**: Redirects can negatively impact SEO, as search engines may not be able to crawl the redirected pages or may see them as duplicate content. This can result in lower search engine rankings and decreased traffic to the site.\n\n**Load times/User experience**: Redirects can increase page load times, as the browser has to make an additional HTTP request to load the redirect page. This can result in slower load times, which can impact user experience, conversion rates, and A/B test outcomes.\n\n**Data accuracy**: Redirects can also impact the accuracy of the test results, as users may drop off or exit the site before completing the desired action due to a slower load time or confusing user experience. It can also be harder technically to fire the tracking event, causing a loss in data.\n\nTo mitigate these problems, it's important to carefully consider whether redirect-based A/B testing is the most appropriate technique for your specific use case. If you do choose to use redirects, it's important to implement them correctly and thoroughly test them to ensure that they do not negatively impact user experience or test results. Additionally, it may be helpful to use other techniques such as server-side testing or client-side testing to supplement redirect-based testing and ensure the accuracy and reliability of the test results like testing on the edge or using middleware to serve different pages.\n\n### Semmelweis Effect[​](#semmelweis-effect \"Direct link to Semmelweis Effect\")\n\nThe Semmelweis effect refers to the tendency of people to reject new evidence or information that challenges their established beliefs or practices. It is named after Ignaz Semmelweis, a Hungarian physician who, in the 19th century, discovered that hand washing could prevent the spread of infectious diseases in hospitals. Despite his findings, he was ridiculed and ignored by his colleagues, and it took many years for his ideas to be accepted and implemented.\n\nIn the context of A/B testing, the Semmelweis effect can manifest in several ways. For example, a company may have a long-standing belief that a certain design or feature is effective and produces good results, and may not want to experiment with it because everyone knows it ‘correct’. Even if an experiment is run against this entrenched belief, and the results of an A/B test challenge established norms, there may be resistance to accept the new evidence and change the established practice.\n\nTo avoid the Semmelweis effect in A/B testing, it is important to approach experimentation with an open mind and a willingness to challenge established beliefs and practices. It is crucial to let the data guide decision-making and to be open to trying new things, even if they go against conventional wisdom or past practices. It is also important to regularly review and evaluate the results of A/B tests to ensure that the company's beliefs and practices are aligned with the latest evidence and insights, and haven’t changed over time.\n\n### Confirmation Bias[​](#confirmation-bias \"Direct link to Confirmation Bias\")\n\nConfirmation bias refers to the tendency to favor information that confirms our preexisting beliefs and to ignore or discount information that contradicts our beliefs. In the context of A/B testing, confirmation bias can lead to flawed decision-making and missed opportunities for optimization.\n\nFor example, if a company believes that a certain website design or feature is effective, they may only run A/B tests that confirm their beliefs and ignore tests that challenge their beliefs. This can lead to a bias towards interpreting data in a way that supports preexisting beliefs, rather than objectively evaluating the results of the tests. Or a PM may believe a new version of their product will be superior, and only acknowledge evidence that confirms this belief.\n\nConfirmation bias can also manifest in the way tests are designed and implemented. If a company designs an A/B test in a way that biases the results towards a particular outcome, such as by using a biased sample or by selecting a suboptimal metric to measure success, it can lead to misleading results that confirm preexisting beliefs.\n\nTo avoid confirmation bias in A/B testing, it is important to approach experimentation with an open and objective mindset. This involves being willing to challenge preexisting beliefs (Semmelweis) and being open to the possibility that the data may contradict those beliefs. It also involves designing tests in a way that is unbiased and that measures the most relevant and meaningful metrics to evaluate success. Having multiple stakeholders review and evaluate the results of A/B tests can help ensure that decisions are based on objective data, rather than personal biases or beliefs.\n\n### HiPPOs[​](#hippos \"Direct link to HiPPOs\")\n\nHiPPO is an acronym for the \"highest paid person's opinion.\" In less data-driven companies, decisions about what product to build or which products to ship are made by HiPPOs. The problem with HiPPOs is that it turns out their opinions are no more likely to be right than anyone else's opinions, and are therefore often wrong. But due to their status they may resist against experimentation to preserve their status or ego. The HiPPO effect is a common problem in many organizations, and it can lead to poor decision-making and missed opportunities for your product.\n\n### Trustworthiness[​](#trustworthiness \"Direct link to Trustworthiness\")\n\nWhen experiment results challenge existing norms or an individual’s beliefs, it can be easy to blame the data. For this reason, having a trustworthy A/B testing platform is extremely important. There must be ways to audit the results, and look into if there was any systemic or specific problem affecting the results of the experiment. Running A/A tests can help build trust that the platform is working correctly. Trust in an experimentation platform is built over time, and care must be taken to not just dismiss results that are counterintuitive.\n\n### Twyman's Law[​](#twymans-law \"Direct link to Twyman's Law\")\n\nTwyman's law is a principle in statistics that states that any data that is measured and collected will contain some degree of error, and that this error is an inherent part of the data. It is named after the British statistician Maurice G. Kendall Twyman.\n\nIn the context of A/B testing, Twyman's law suggests that there will always be some level of variability or uncertainty in the results of an A/B test due to factors such as random chance, sample size, or measurement error. It is often phrased as:\n\n> Any data or figure that looks interesting or different is usually wrong\n\nIf you notice a particularly large or unusual change in the results of an experiment, it is more likely to be the result of a problem with the data or an implementation than an actual result. Before you share the results, make sure that the effects are not the result of an error.\n\n### Goodhart's Law[​](#goodharts-law \"Direct link to Goodhart's Law\")\n\nGoodhart's law is a concept in economics that states that when a measure becomes a target, it ceases to be a good measure. In other words, once a metric becomes the sole focus of attention and effort, it loses its value as an indicator of the desired outcome.\n\nWhen it comes to A/B testing, Goodhart's law can apply in several ways. For example, if a specific metric such as click-through rate or conversion rate becomes the sole focus of an A/B test, it can lead to unintended consequences such as artificially inflating the metric while neglecting other important aspects of the user experience. This can happen because individuals or teams may optimize for the metric being measured rather than focusing on the broader goals of the A/B test, such as improving user engagement or increasing revenue.\n\nTo avoid the negative effects of Goodhart's law in A/B testing, it is important to choose the right metrics to track and analyze, and to use a variety of metrics to evaluate the effectiveness of the test. It is also important to keep in mind the broader goals of the test and to avoid tunnel vision on any one metric. Goodhart's law is more likely to happen when you are using proxy metrics, instead of the real KPIs you’re trying to improve - an example of this might be items added to a cart being used as a proxy for purchases. Also If the proxy metric is not strongly causally linked to the target metric, pressing hard on the proxy may have no effect on the goal metric, or might actually cause the correlation to break.\n\n### Simpson's Paradox[​](#simpsons-paradox \"Direct link to Simpson's Paradox\")\n\nSimpson's paradox is a statistical phenomenon where a trend or pattern appears in different groups of data but disappears or reverses when the groups are combined. In other words, the overall result may be opposite to what the individual subgroups suggest.\n\nThis paradox can arise when a confounding variable (a variable that affects both the independent and dependent variables) is not taken into account while analyzing the data.\n\nSimpson's paradox was famously observed at the University of California, Berkeley in 1973, where it had implications for gender discrimination in graduate school admissions.\n\nAt the time, it was observed that although the overall admission rate for graduate school was higher for men than for women (44% vs. 35%), when the admission rates were broken down by department, the reverse was true for many of the departments, with women having a higher admission rate than men in each department. In the Department of Education, for example, women had a 77% admission rate compared to men's 62% admission rate.\n\nThe paradox was resolved by examining the application data more closely and considering the impact of an important confounding variable, which was the choice of department. It was discovered that women were more likely to apply to departments that were more competitive and had lower admission rates, while men were more likely to apply to less competitive departments with higher admission rates.\n\nWhen the data was reanalyzed, taking into account the departmental differences in admission rates, it was found that women actually had a slightly higher overall admission rate than men, suggesting that there was no discrimination against women in the admissions process. This case study illustrates how Simpson's paradox can occur due to the influence of confounding variables, and how it can lead to misleading conclusions if not properly accounted for in the analysis. To avoid the Simpson's paradox in experimentation, it is essential to analyze the data by considering all relevant variables and subgroups. It is crucial to ensure that the experimental groups are similar in terms of demographics and behavior, and to use statistical techniques that account for confounding variables.\n\n### Ethical considerations[​](#ethical-considerations \"Direct link to Ethical considerations\")\n\nExperimentation judges the outcome of changes by looking at the impact it has on some set of metrics. But the seeming objectivity of the results can hide problems. The simplest way this can go wrong is if your metrics are tracking the wrong things, in which case you’ll have garbage in and garbage out. But it is also possible for the metrics to not capture harm that is being done to some subsets of your population.\n\nExperimentation results work on averages, and this can hide a lot of systemic biases that may exist. There can be a tendency for algorithmic systems to “learn” or otherwise encode real-world biases in their operation, and then further amplify/reinforce those biases.\n\nProduct design has the potential to differentially benefit some groups of users more than others; It is possible to measure this effect and ensure that results account for these groups. Sparse or poor data quality that leads to objective-setting errors and system designs that lead to suboptimal outcomes for many groups of end users. One company that does this very well is the team at LinkedIn, you can read about their approach [here](https://engineering.linkedin.com/blog/2020/building-inclusive-products-through-a-b-testing).",
  "title": "Where Experimentation goes wrong | GrowthBook Docs",
  "description": "The following contains a list of common pitfalls and mistakes that can happen when running A/B tests.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/using/experimenting",
  "markdown": "# Experimenting in GrowthBook | GrowthBook Docs\n\nThe Experiments section in GrowthBook is all about analyzing raw experiment results in a data source. Before analyzing results, you need to actually run the experiment. This can be done in several ways:\n\n*   Feature Flags (most common)\n*   Running an inline experiment directly with our SDKs\n*   Our Visual Editor (beta)\n*   Your own custom variation assignment / bucketing system\n\nWhen you go to add an experiment in GrowthBook, it will first look in your data source for any new experiment ids and prompt you to import them. If none are found, you can enter the experiment settings yourself.\n\n## Experiment Splits[​](#experiment-splits \"Direct link to Experiment Splits\")\n\nWhen you run an experiment, you need to choose who will get the experiment, and what percentage those users should get each variation. In GrowthBook, we allow you to pick overall exposure percentage, as well as customize the split per variation. Yor can also target an experiment at just some attribute values.\n\nGrowthBook uses deterministic hashing to do the assignment. That means that each user’s hashing attribute (usually user id), and the experiment name, are hashed together to get a number from 0 to 1. This number will always be the same for the same set of inputs.\n\nThere is quite often a need to de-risk a new A/B test by running the control at a higher percentage of users than the new variation, for example, 80% of users get the control, and 20% get the new variation. To solve this case, we recommend keeping the experiment spits equal, and adjusting the overall exposure (ie, 20% exposure, 50/50 on each variation, so each variation gets 10%). This way the overall exposure can be ramped up (or down) without having any users potentially switch variations.\n\n## Metric selection[​](#metric-selection \"Direct link to Metric selection\")\n\nGrowthBook lets you choose goal metrics and guardrail metrics. Goal metrics are the metrics you’re trying to improve or measure the impact of the change of your experiment. Guardrail metrics are metrics you’re not necessarily trying to improve, but you don’t want to hurt. With goal metrics we show full statistical changes on the metrics. Guardrail metrics we only show the chance of that metric being worse- if there is a significant chance that the guard rail metric is worse, it will be shown in red, otherwise it will be green.\n\n![GrowthBook Metric Selector](https://docs.growthbook.io/images/using/metrics-modal.png)\n\nIt is best to pick metrics for your experiment that are as close to your treatment as possible, and, if possible, the event itself. For example, if you’re trying to improve a signup rate, you can add product review metrics that are close to that event, like \"signup modal open rate\", and \"signup conversion rate\". You can add as many metrics as you like to your experiment, but we suggest each experiment have only a few primary metrics that are used for making the shipping decision. Adding all your metrics is not recommended, as this can lead to false positives caused by random variations (see [Multiple testing problem](https://docs.growthbook.io/using/experimentation-problems#multiple-testing-problem))\n\nBefore you being a test, you should have selected a primary metric or set of metrics that you are trying to improve. These metrics are often called the OEC for Overall Evaluation Criterion. It is important to have this decided ahead of time so when you look at your experiment results you're not just shopping for metrics that confirm your bias (see [confirmation bias](https://docs.growthbook.io/using/experimentation-problems#confirmation-bias)).\n\nWith GrowthBook, Goal and guardrail metrics can be added retroactively to experiments, as long as the data exists in your data warehouse. This allows you to reprocess old experiments if you add new metrics or redefine a metric.\n\n## Activation metrics[​](#activation-metrics \"Direct link to Activation metrics\")\n\nAssigning your audience to the experiment should happen as close to the test as possible to reduce noise and increase power. However, there are times when running an experiment requires that users be bucketed into variations before knowing that they are actually being exposed to the variation. One common example of this is with website modals, where the modal code needs to be loaded on the page with the experiment variations, but you’re not sure if each user will actually see the modal. With activation metrics you can specify a metric that needs to be present to filter the list of exposed users to just those with that event.\n\n## Sample sizes[​](#sample-sizes \"Direct link to Sample sizes\")\n\nWhen running an experiment you select your goal metrics. Getting enough samples depends on the size of the effect you’re trying to detect. If you think the experiment will have a large effect, the smaller total number of events you need to collect. GrowthBook allows users to set a minimum sample size for each metric where we will hide results before that threshold is reached to avoid premature peeking.\n\n## Test Duration[​](#test-duration \"Direct link to Test Duration\")\n\nWe recommend running an experiment for at least 1 or 2 weeks to capture variations in your traffic. Before a test is significant, GrowthBook will give you an estimated time remaining before it reaches the minimum thresholds. Traffic to your product is likely not uniform, and there may be differences\n\n## Metric Windows[​](#metric-windows \"Direct link to Metric Windows\")\n\nA lot can happen between when a user is exposed to an experiment, and when a metric event is triggered. How you want to attribute that conversion event to the experiment is adjustable within GrowthBook using metric and experiment level settings.\n\nAt the metric level, you can pick three different metric windows:\n\n*   None - uses as much data as possible from the user's exposure until the end of the experiment.\n*   Conversion - uses only data in some window after a user's first exposure. If the metric's conversion window is set to 72 hours, any conversion that happens after that is ignored.\n*   Lookback - uses only data in the last window before an experiment ends.\n\nHere's a representation of how these metric windows work for a hypothetical user: ![Metric Windows](https://docs.growthbook.io/assets/images/metric-windows-024e6a7e756c8cd43f0d35ee221cc089.png)\n\nHere's a second example for a hypothetical User 2, who joins the experiment late. Notice that the conversion window can extend beyond the experiment end date. ![Metric Windows (User 2)](https://docs.growthbook.io/assets/images/metric-windows-user-2-dac5ae6d7345e2211ec13dd5f8869954.png)\n\nYou can override all Conversion windows to be No window at the experiment level using the \"Conversion Window Override\" in the Experiment Analysis Settings.\n\n## Understanding results[​](#understanding-results \"Direct link to Understanding results\")\n\n### Bayesian Results[​](#bayesian-results \"Direct link to Bayesian Results\")\n\nIn GrowthBook the experiment results will look like this.\n\n![GrowthBook Results](https://docs.growthbook.io/assets/images/experiment-results-bayesian-9795c6f96f84948810be08d4fc1e422c.png)\n\nEach row of this table is a different metric. This is a simplified overview of the data. If you want to see the full data, including 'risk', mouse over any of the results.\n\n![GrowthBook Results](https://docs.growthbook.io/assets/images/experiment-results-bayesian-details2-6467b6c748328e614a5b879ef8a12437.png)\n\nRisk tells you how much you are predicted to lose if you choose the selected variation as the winner and you are wrong. You can specify upper risk thresholds (designed to flag high-risk outcomes) and lower risk thresholds (designed to flag low-risk outcomes) in Behavior on the Metrics tab. Red indicates that the treatment variation has risk above the high-risk threshold. Yellow indicates that your risk is between the two thresholds. You can use the dropdown to see the risk of choosing a different winner if you have multiple variations.\n\nValue is the conversion rate or average value per user. In small print you can see the raw numbers used to calculate this.\n\n**Chance to Beat Control** tells you the probability that the variation is better. If you are familiar with Frequentist statistics, you can consider this value 1 - the p value. Anything above the threshold (which by default is set to 95%) is highlighted green indicating a very clear winner. Anything below the threshold (5% by default) is highlighted red, indicating a very clear loser. Anything in between is gray indicating it's inconclusive. If that's the case, there's either no measurable difference or you haven't gathered enough data yet.\n\n**Percent Change** shows how much better/worse the variation is compared to the control. It is a probability density graph and the thicker the area, the more likely the true percent change will be there. As you collect more data, the tails of the graphs will shorten, indicating more certainty around the estimates.\n\n### Frequentist Results[​](#frequentist-results \"Direct link to Frequentist Results\")\n\nYou can also choose to analyze results using a Frequentist engine that conducts simple t-tests for differences in means and displays the commensurate p-values and confidence intervals. If you selected the \"Frequentist\" engine, when you navigate to the results tab to view and update the results, you will see the following results:\n\n![GrowthBook Results - Frequentist](https://docs.growthbook.io/assets/images/experiment-results-frequentist-b5e8df21a43c3e63521999a80206bbbf.png)\n\nEverything is the same as above except for three key changes:\n\n*   There is no longer a risk value, as the concept is not easily replicated in frequentist statistics.\n*   The Chance to Beat Control column has been replaced with the P-value column. The p-value is the probability that the percent change for a variant would have been observed if the true percent change were zero. When the p-value is less than the threshold (default to 0.05) and the percent change is in the preferred direction, we highlight the cell green, indicating it is a clear winner. When the p-value is less than the threshold and the percent change is opposite the preferred direction, we highlight the cell red, indicating the variant is a clear loser on this metric.\n*   We now present a 95% confidence interval rather than a posterior probability density plot.\n\n## Data quality checks[​](#data-quality-checks \"Direct link to Data quality checks\")\n\nGrowthBook performs automatic data quality checks to ensure the statistical inferences are valid and ready for interpretation. You can see all check and monitor the health of your experiments on the experiment **health page**.\n\n### Health Page[​](#health-page \"Direct link to Health Page\")\n\nGrowthBook automatically does data quality checks on all experiments and shows the results on the our _Health Page_.\n\n![Experiment Health Page](https://docs.growthbook.io/images/using/health-page.png)\n\nThis page shows experiment exposure over time, and also all the other health checks we do.\n\n### Sample Ratio Mismatch (SRM)[​](#sample-ratio-mismatch-srm \"Direct link to Sample Ratio Mismatch (SRM)\")\n\nEvery experiment automatically checks for a Sample Ratio Mismatch and will warn you if found. This happens when you expect a certain traffic split (e.g. 50/50) but you see something significantly different (e.g. 46/54). We only show this warning if the p-value is less than 0.001, which means it's extremely unlikely to occur by chance. We will show this warning on the results page, and also on our experiment health page.\n\n![Sample Ratio Mismatch](https://docs.growthbook.io/images/using/srm-check-health-page.png)\n\nLike the warning says, you shouldn't trust the results since they are likely misleading. Instead, find and fix the source of the bug and restart the experiment. You can find more information about potential sources of the problems in our [troubleshooting guide](https://docs.growthbook.io/kb/experiments/troubleshooting-experiments).\n\n### Multiple Exposures[​](#multiple-exposures \"Direct link to Multiple Exposures\")\n\nWe also automatically check each experiment to make sure that too many users have not been exposed to multiple variations of a single experiment. This can happen if the hashing attribute is different from the assignment id used in the report, or for implementation problems.\n\n### Minimum Data Thresholds[​](#minimum-data-thresholds \"Direct link to Minimum Data Thresholds\")\n\nYou can set thresholds per metric to make sure people viewing the results aren’t drawing conclusions too early (e.g. when it’s 5 vs 2 conversions)\n\n### Variation Id Mismatch[​](#variation-id-mismatch \"Direct link to Variation Id Mismatch\")\n\nGrowthBook can detect missing or improperly-tagged rows in your data warehouse. The most common way this can happen if you assign with one parameter, but send a different ID to your warehouse from the trackingCallback call. It may indicate that your variation assignment tracking is not working properly.\n\n### Suspicious Uplift Detection[​](#suspicious-uplift-detection \"Direct link to Suspicious Uplift Detection\")\n\nYou can set thresholds per metric for a maximum percent change. When a metric results is above this, GrowthBook will show an alert. Large uplifts may indicate a bug - see [Twymans Law](https://docs.growthbook.io/using/experimentation-problems#twymans-law).\n\n### Guardrails[​](#guardrails \"Direct link to Guardrails\")\n\nmetrics are ones that you want to keep an eye on, but aren't trying to specifically improve with your experiment. For example, if you are trying to improve page load times, you may add revenue as a guardrail since you don't want to inadvertently harm it.\n\nGuardrail results show up beneath the main table of goal metrics. The full statistics are shown like goal metrics, and similarly they are colored based on \"Chance to Beat Control\". If guardrail metrics become significant, you may want to consider ending the experiment.\n\n![Guardrail Results](https://docs.growthbook.io/assets/images/guardrail-metrics-52c56135d12db6cd370dcfffecdc2951.png)\n\nIf you select the frequentist engine, we instead use yellow to represent a metric moving in the wrong direction at all (regardless of statistical significance), red to represent a metric moving in the wrong direction with a two-sided t-test p-value below 0.05, and green to represent a metric moving in the right direction with a p-value below 0.05. Otherwise the cell is unshaded if the metric is moving in the right direction but not statistically significant at the 0.05 level.\n\n## Digging deeper[​](#digging-deeper \"Direct link to Digging deeper\")\n\nGrowthBook lets you dig into the results to get a better understanding of the likely effect of your change.\n\n### Segmentation[​](#segmentation \"Direct link to Segmentation\")\n\nSegments are applied to experiment results to only show users that match a particular attribute. For example, you might have “country” as a dimension, and create a segment for just “US visitors”. In the experiment you can configure the experiment to just look at one particular segment of users. Segments can be created with SQL from the \"Data and Metrics → Segments\" page.\n\n![Segments](https://docs.growthbook.io/assets/images/segments-page-17eb191d453041d9f79d291d05ec3eed.png)\n\nThere are two ways you can use segments in your experiment results. The first is to use edit the experiment's 'analytics settings' and add one of the segments. The other way is to create a custom ad-hoc reports, and then click on 'customize' and select a segment to apply to the results.\n\n### Dimensions[​](#dimensions \"Direct link to Dimensions\")\n\nGrowthBook lets you break down results by any dimension you know about your users. We automatically let you break down by date, and any additional dimensions can be added either with the exposure query, or with custom SQL from the dimension menu. Some examples of common dimensions are “Browser” or “location”. You can read more about [dimensions here](https://docs.growthbook.io/app/dimensions).\n\n![Dimension Selector](https://docs.growthbook.io/assets/images/dimension-selector-fae643d610ac41d989b24ad64e229d29.png)\n\nIt can be very helpful to look into how specific dimensions of your users are affected by the experiment. For example, you may discover that a specific browser is underperforming compared to the rest, and this may indicate a bug, or something to investigate further. The more metrics and dimensions you look at, the more likely you are to see a false positive. If you find something that looks surprising, it's often worth a dedicated follow-up experiment to verify that it's real.\n\n### Ad-hoc reports[​](#ad-hoc-reports \"Direct link to Ad-hoc reports\")\n\nExperiment reports have a lot of configuration, and sometimes it can be useful to want to adjust these configurations without changing the original report. GrowthBook supports Ad-hoc reports, which are essentially copies of the original report, where you can adjust any of the configuration parameters, such as segments, dates, metrics, even custom SQL to remove outliers.\n\n![Ad-hoc Reports Menu](https://docs.growthbook.io/assets/images/ad-hoc-menu-eab86c8ac6e19aa4bd41d34b81b373ef.png)\n\nAll ad hoc reports created can be shared publicly and live at the bottom of the report, to make sure you capture any derived results.\n\n![Ad-hoc Reports and Publishing](https://docs.growthbook.io/assets/images/ad-hoc-report-saving-9365c19e4e93fae964b6cd231025a304.png)\n\n## Deciding A/B test results[​](#deciding-ab-test-results \"Direct link to Deciding A/B test results\")\n\nHopefully you are analysing your experiment results with your OEC already documented. Even so, when to stop, and how to interpret results may not be straight forward.\n\n### When to stop an experiment[​](#when-to-stop-an-experiment \"Direct link to When to stop an experiment\")\n\nWhen using the Bayesian statistic engine, there are a few methods you can use when stopping a test.\n\n*   significance reached on your primary metrics\n*   metric risk drop below your risk thresholds\n*   guardrail metrics are not affected\n*   test duration reached\n\nIt all depends on what you’re trying to do with the experiment. For example, if you’d like to know what impact your change has, you should use the first method. If you’re doing a design change, and want to make sure you haven’t broken anything on your product, you can use the risk or guard rail approach. You should also make sure that the experiment has run for your minimum test duration (typically 1 or 2 weeks), so that you’re not looking at highly skewed sampling.\n\nFor Frequentist statistics, you should determine the running time of the experiment and stop the test at that fixed horizon to ensure accurate results (see [Peeking](https://docs.growthbook.io/using/experimentation-problems#peeking)) or use Sequential analysis.\n\n### Interpreting results[​](#interpreting-results \"Direct link to Interpreting results\")\n\nIt is quite common to have experiment results with mixed results. Deciding on the results of an experiment in these cases may require some interpretation. As a general rule, you should have one goal metric that is the primary metric you’re trying to improve, and if this metric is up significantly it is generally straightforward to declare a result. If you have a mix and up and down metrics, the decisions are less clear.\n\nOnce you have reached a decision with your experiment, you can click the “mark as finished” link towards the top of the results. This will open a modal where you can document the results, including the result, and observations.\n\nThis creates a card on the top of the experiment results with your conclusion. Please note that currently this marking a test as finished does not stop the test from running. If you are using feature flags to run the experiment, you should also go to the feature and turn off the experiment.\n\n### Inconclusive results[​](#inconclusive-results \"Direct link to Inconclusive results\")\n\nSometimes you may have an experiment that is inconclusive. Generally it is a good idea to have a policy of what to do in these cases. We suggest that your policy should be to revert to the control variant in these cases, unless the new version unlocks some new features.",
  "title": "Experimenting in GrowthBook | GrowthBook Docs",
  "description": "The Experiments section in GrowthBook is all about analyzing raw experiment results in a data source.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/using/growthbook-best-practices",
  "markdown": "# GrowthBook Best Practices | GrowthBook Docs\n\n## Organization[​](#organization \"Direct link to Organization\")\n\nAs you scale up your usage of GrowthBook and start running many experiments, keeping everything organized and easy to find is essential. GrowthBook includes a number of organizational structures to help you scale.\n\n### Organizations[​](#organizations \"Direct link to Organizations\")\n\nThe organization is the highest level structure within GrowthBook. An organization contains everything within your GrowthBook instance: users, data sources, metrics, features, etc. For both cloud and self-hosted users, it is possible for users to join multiple organizations. Users can belong to multiple organizations, but each organization is otherwise entirely independent of the others. For some, complete isolation of the teams or subdivisions within the company may be desired. For example, if your company has two or more largely independent products (e.g., Google has Search and Google Docs), you can set up multiple organizations per product.\n\nFor self-hosted enterprise users, we support multi-organization mode, which also comes with a super-admin account type that can manage users across organizations.\n\n### Environments[​](#environments \"Direct link to Environments\")\n\nIn GrowthBook, you can create as many environments as you need for the feature flags and override rules. Environments are meant to separate how your feature flags and override rules are deployed. Each environment can have one or more SDK API endpoints specified when you create the SDK, allowing you to differentiate the override rules. For example, you might have environments for “Staging”, “QA”, and “Production”. While testing the feature, you can set specific rules to on the \"development\" or \"QA\" environment, and when you're ready, you can move applicable rules to the \"production\" environment.\n\nYou can add an arbitrary number of environments from the SDK Connections → Environments page.\n\n![Environments Page](https://docs.growthbook.io/assets/images/environments-page-604601ebe249b0931dfe040447157633.png)\n\n### Projects[​](#projects \"Direct link to Projects\")\n\nWithin an organization, you can create projects. Projects can help isolate the view of GrowthBook to just the sections that apply for that GrowthBook user. Projects are a great way to organizationally separate features, metrics, experiments, and even data sources by team or product feature. For example, you could have a project “front-end” and one for “back-end”, or by team like “Growth” and “API”. Unlike separate organizations, projects can share data. Projects are managed from the Settings → Projects page.\n\n![Projects Page](https://docs.growthbook.io/assets/images/projects-page-f0374689d7f4e39f1eaa9df350d47431.png)\n\nA use case for using projects is if you have divisions within your product but a centralized data source. We typically see projects used per team or per project within your organization. For example, if you have a mobile app and a website that shares users, but the code bases are different, you will want to create two projects: a _mobile_ project and a _web_ project.\n\nEach of the items within GrowthBook can be assigned to multiple projects. You can have a data source that is part of the ‘mobile’ and ‘web’ projects but not to a ‘marketing’ project. That data source will not be available for users in the 'marketing' project.\n\nTo help keep feature payloads smaller, the SDK endpoint where the feature definitions are returned can be scoped to each project. If using Projects based on features or area of your product, you can use this feature to only return features that pertain to that area. For example, with our “mobile” and “website” example, you can add the project scope to only return features for the project as these are likely to use different code than the other, and you don’t want to expose features unnecessarily.\n\nOne advantage of using projects is that you can adjust permissions and even some statistical settings per project- users can have no access to a project or, inversely, have no general permissions but add a project permission so they can work within their project. If a team prefers to use a frequentist statistical model, this can be adjusted per project.\n\n### Tags[​](#tags \"Direct link to Tags\")\n\nAnother way to organize GrowthBook is with _tags_. With tags, you can quickly filter lists, and select metrics. For example, if you tagged all experiments to do with your checkout flow with the tag “checkout”, you can quickly see this in the list by clicking on ‘filter by tags’ on the experiment list. Tags can be color-coded and managed from our Settings → Tags page. You can add multiple tags per item you are tagging.\n\n![Tags Page](https://docs.growthbook.io/assets/images/tags-page-1af987220eb5c4668698e8ab7d230a5e.png)\n\nMetrics with tags can be used to quickly add all those metrics to an experiment. When creating an experiment or editing the metrics, there is a section titled “Select metric by tag” which will let you add all the metrics by the tag name to both guardrail and goal metrics. This is useful if you want to use a standard set of goal metrics or guardrail metrics for your experiments.\n\nTags are often used to mark sub-features of your product; for example, if you have an e-commerce website, you might want to tag features or experiments with the area they affect, like ‘_pricing_,’ ‘_product page_,’ or ‘_checkout_.’\n\n![Experiments filtered by tag](https://docs.growthbook.io/assets/images/experiments-filtered-by-tag-39ea1da83577ea267a0e3d49147c7000.png)\n\n### Naming[​](#naming \"Direct link to Naming\")\n\nAnother organizing principle you can use is the naming of your experiments and features. Because GrowthBook makes it easy to quickly search the list of features and flags, using naming conventions can be an effective way to organize your project.\n\nWe’ve seen several strategies be successful here, but as a general rule, you’ll want to be as specific as possible with naming features and experiments. For example, you can use <project scope>\\_<project name> or the year, quarter, or section plus the name of the experiment, e.g.: “23-Q4 New user registration modal“ or “23-Team3 Simplified checkout flow”. This lets you quickly see when the experiment was run or which team worked on it.\n\n### Hygiene & Archiving[​](#hygiene--archiving \"Direct link to Hygiene & Archiving\")\n\nAs the number of features and experiments grows, you will want to remove past items that are no longer relevant. Within GrowthBook you can archive and delete. **Deleting** something will permanently remove items from GrowthBook. **Archived** items in GrowthBook won’t be deleted, but they are removed from the main part of the UI and not available for adding to new experiments (for archived metrics). Archived items can also be restored at any time. These methods help you keep your UI clean and relevant.\n\n### Source of Truth[​](#source-of-truth \"Direct link to Source of Truth\")\n\nIf you run an experimentation program for a long enough time, you’ll find yourself with an experiment idea that seems really familiar, and people will wonder, “Didn’t we already test this?” If you don’t have a central repository for all your experiment results, it can be difficult to find if you did test this previously, and even if you did, if what you tested was similar enough to the new idea not to have to test it again.\n\nGrowthBook is designed to help with this by creating a central source for the features you’ve launched and the experiments you’ve run. To help facilitate this, GrowthBook has created a number of features to help you capture meta information.\n\n### Meta Information[​](#meta-information \"Direct link to Meta Information\")\n\nFeatures and experiments can all have metadata attached to them. The purpose of this is to help capture all the meta-information around a feature or experiment that might help contextualize it for posterity and help capture the institutional knowledge that your program generates. This is also very helpful when new members join your team, so they don’t just suggest ideas you’ve run many times already.\n\nFor experiments, you should capture the original idea, any screenshots of similar products, and, most importantly, capture images/screenshots of the control and variants for the experiment. Quite often, someone will suggest an idea you’ve run previously. In these cases, it is vital to be able to find out what exactly you tested previously - it's possible that the new idea is slightly different, or you may decide that it is the same and try testing another idea, or you could decide that your product is substantially different, and the same idea may be worth testing again. To make this decision, it is essential to capture not just the experiment results but the broader context of what your product looked like at the time and the test variants.\n\nGetting your team to document is always a challenge. GrowthBook takes two approaches to help with this. The first is to make it super easy to add documentation directly in the platform you’re already using for the experiment. Secondly, we added launch checklists, which can require that certain files be filled before your team is able to start an experiment.\n\n## Searching[​](#searching \"Direct link to Searching\")\n\nGrowthBook has a powerful search feature that allows you to quickly find the feature, experiment, or metrics. By default, text searches with this search input will search based on the name, description, and other meta information. You can also search using syntax search to search for specific fields.\n\n### Syntax Search[​](#syntax-search \"Direct link to Syntax Search\")\n\nSyntax search allows you to search for specific fields in GrowthBook. The syntax search allows for exact matching, starts with, greater, less, and contains. You can also negate any of the operators using !. Syntax searches are constructed in the format of `[field]:[operator][value]`. You can also combine multiple fields using the same syntax. For example, `name:~pricing status:running` will search for all running experiments with the name containing the string \"pricing\".\n\n| Syntax operator | Description |\n| --- | --- |\n| :   | exact match |\n| :=  | exact match |\n| :~  | contains |\n| :^  | starts with |\n| :>  | greater than |\n| :<  | less than |\n| :!  | negated (exclude matches) |\n| :!= | negated (exclude matches) |\n| :!~ | does not contain |\n| :!^ | does not starts with |\n| :!> | not greater than |\n| :!< | not less than |\n\nYou can also add quotes to search for fields that contain spaces. For example, `name:\"New Feature\"` will search for the name field that contains the text “New Feature”.\n\n### Experiments Syntax Fields[​](#experiments-syntax-fields \"Direct link to Experiments Syntax Fields\")\n\nSyntax fieldDescriptionnameThe experiment name (eg: name:~pricing)key or idThe experiment's tracking key (eg: key:^banner)statusExperiment status, can be one of \"stopped\", \"running\", \"draft\", \"archived\" (eg: status:running)ownerThe creator of the experiment (eg: owner:pat)tagExperiments tagged with this tagprojectThe experiment's projectfeatureThe experiment is linked to the specified featuremetricExperiments that contain the metric specified (eg: metric:~revenue)resultThe experiment result (won, inconclusive, lost, unfinished)variationThe experiment contains a variant with the name specifiedvariationsSearch for the number of variantscreatedThe experiment's creation date, in UTC. The date entered is parsed so supports most formatsupdatedThe date the experiment was updated, in UTC. The date entered is parsed so supports most formatsvariationsSearch for the number of variantsissupports searching on the experiment status, results, and other current states. Supported fields\n\n|     |     |\n| --- | --- |\n| archived | If the experiment is archived |\n| draft | The experiment is in draft status |\n| running | The experiment is running |\n| stopped | The experiment is stopped |\n| won | The experiment been marked as won |\n| lost | The experiment has been maked as lost |\n| inconclusive | The experiment has been marked as inconclusive |\n| visual | The experiment has variants made with the visual editor |\n| redirect | The experiment has a URL redirect experiment |\n\nhassupports searching on the experiment states. Supported fields\n\n|     |     |\n| --- | --- |\n| project | The experiment belongs to at least one project |\n| visualChange | The experiment has a visual editor change |\n| redirect/redirects | The experiment has a URL redirect |\n| feature/features | The experiment has features attached |\n| hypothesis | The experiment has a hypothesis |\n| description | The experiment has a description |\n| screenshots | The experiment has at least one screenshot |\n\n#### Examples[​](#examples \"Direct link to Examples\")\n\n```\nname:~pricing status:running\n```\n\nShow all running experiments with the name containing the string \"pricing\"\n\n```\ntag:checkout result:won updated:>2024-06-05\n```\n\nShow all experiments tagged with \"checkout\" that have been marked as won and were updated after June 5th, 2024\n\n```\nis:archived has:visualChange variations:>2\n```\n\nShow all archived experiments that have a visual change and have more than 2 variations in the experiment\n\n```\nowner:patty has:!hypothesis\n```\n\nShow all experiments owned by Patty that do not have a hypothesis\n\n```\ncreated:<\"dec 22nd, 2023\" has:redirect metrics:~revenue\n```\n\nShow all experiments that have a redirect and were created before December 22nd, 2023 and contain a metric name containing \"revenue\"\n\n### Features Syntax Fields[​](#features-syntax-fields \"Direct link to Features Syntax Fields\")\n\nSyntax fieldDescriptionkeyThe feature's key (name)ownerThe creator of the feature (eg: owner:abby)rulesMatches based on the number of rules (eg: rules:>2)tagFeatures tagged with this tagprojectThe feature's projectversion or revisionThe feature's revision numberexperimentThe feature is linked to the specified experimentcreatedThe feature's creation date, in UTC. Date entered is parsed so supports most formats.\n\n(eg: created:>\"2024-06-05\" or created:<\"dec 22nd, 2023\")\n\nupdatedThe date the feature was updated, in UTC. Date entered is parsed so supports most formatsonShows features that are on for a specific environment (on:production)offShows features that are off for a specific environment (off:dev)issupports searching on the feature status, results, and other current states. Supported fields\n\n|     |     |\n| --- | --- |\n| archived | If the feature is archived |\n| draft | The feature is in draft status |\n| stale | The feature is stale |\n\nhassupports searching on the feature states. Supported fields\n\n|     |     |\n| --- | --- |\n| project | The feature belongs to at least one project |\n| draft or drafts | The feature has a draft |\n| prerequisites or prereqs | The feature has at least one prerequisite flags |\n| validation or schema or jsonSchema | The feature has a JSON schema attached |\n| rule or rules | The feature has at least one rule |\n| experiment or experiments | The feature has at least one experiment rule |\n| rollout or percent | The feature has at least one precentage rollout rule |\n| force or targeting | The feature has at least one force rule |\n\n#### Examples[​](#examples-1 \"Direct link to Examples\")\n\n```\nkey:~pricing on:production\n```\n\nShow all features with the key containing the string \"pricing\" that are `on` in the production environment\n\nShow all features tagged with \"checkout\" that are stale\n\n```\nis:archived has:prerequisites\n```\n\nShow all archived features that have prerequisites\n\n```\nowner:abby has:draft rules:0\n```\n\nShow all features owned by Abby that have a draft and have no rules\n\n```\nupdated:>\"2024-06-05\" has:experiment\n```\n\nShow all features that have experiment rules and were updated after June 5th, 2024",
  "title": "GrowthBook Best Practices | GrowthBook Docs",
  "description": "Organization",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/using/security",
  "markdown": "# Security | GrowthBook Docs\n\nGrowthBook is built with security in mind, and we have made architectural decisions to ensure that your GrowthBook instance can be as secure as possible. You can read about some of our internal security practices [here](https://www.growthbook.io/security) and on out [GitHub](https://github.com/growthbook/growthbook/blob/main/SECURITY.md). This document covers some of the security considerations for administrators when setting up and using GrowthBook.\n\n## Data Security[​](#data-security \"Direct link to Data Security\")\n\nGrowthBook only stores account information for your users with GrowthBook accounts (email and name). For feature flagging, evaluations typically happen within the SDK, so none of your user’s information is sent to GrowthBook. For experiment reporting, we connect to your data warehouse to pull the assignment/exposure and metric information. This data remains in your data warehouse; GrowthBook only stores the aggregate results, such as the total number of users exposed to each variation and other statistical information. No PII is stored or transferred to GrowthBook with the experimentation reports.\n\nThere are some ways where personal information may be stored or exposed with GrowthBook. If you are using GrowthBook on the client side of your application, the rules about how each feature will be exposed to your users are publicly accessible by inspecting network requests. Usually, these rules contain no personal information, but if you are targeting a specific user or set of users, then this information may be visible to malicious users. If you use GrowthBook on the server side, this information is not exposed to the client. For these reasons, targeting based on PII when using GrowthBook client side is not recommended.\n\nIf you have to target based on PII on the client side, GrowthBook has some ways to make this secure. You can use hashed attributes, where the values are hashed before sending, or you can use encrypted attributes, where the payload is encrypted before sending to the client. Keep in mind that encrypted SDK endpoints will have to decrypt the payload before use, and that means if you are using GrowthBook client side, a malicious actor can see the decrypted payload. You can enable encryption when setting up the SDK, and you can select an attribute as 'hashed' when creating the attribute.\n\nFinally, to avoid these issues, you can also use 'remote evaluations' to evaluate flags based on sensitive information without exposing it, even on the client side. With remote evaluations, the SDK will send the user attribute to your server (or ours), and then that attribute is matched against the rules, and then the state of the feature is returned without revealing the targeting rules to the client. The downside of this approach is that each evaluation requires a network request to evaluate the feature, which can slow down your application.\n\n## Data Access[​](#data-access \"Direct link to Data Access\")\n\nGrowthBook requires read-only access to your data warehouse. This connection information is kept encrypted. You can use permissions to help protect access to your data warehouse through the GrowthBook UI. You can assign users who can edit the connection info, SQL queries for the assignment, or metric queries.\n\nData sources can also be scoped to projects to help isolate access to your data warehouse. You can adjust the permissions so that only users who have access to the project and have the proper permission levels can edit those queries. If you require more separation of your data and metrics within GrowthBook, you can create separate cloud organizations, or run GrowthBook in multi-tenant mode (available when self-hosting as part of GrowthBook Enterprise). With this, you can have separate GrowthBook organizations running from one GrowthBook instance. Each organization will have its own data source, metrics, and users. There is a super-admin account type that can manage users across organizations.\n\n## Infrastructure Security[​](#infrastructure-security \"Direct link to Infrastructure Security\")\n\nGrowthBook Cloud is hosted on AWS, in a multi-tenant environment. We use industry-standard security to ensure that your data is secure. If you require additional security, we also offer self-hosted options. When you self-host, no data leaves your infrastructure. We do have anonymous usage tracking enabled by default, but this can be disabled (see [self-hosted](https://docs.growthbook.io/self-host)).\n\n## Self-hosted deployments[​](#self-hosted-deployments \"Direct link to Self-hosted deployments\")\n\nGrowthBook can be self-hosted on your own infrastructure. If self-hosting, we recommend that you keep GrowthBook behind a firewall, and accessible via a VPN. See [self-hosting](https://docs.growthbook.io/self-host) for more information. GrowthBook should also be regularly updated to ensure that you are running the latest version with the latest security patches. GrowthBook updates are backward compatible and can be easily applied with a single command. See [updating GrowthBook](https://docs.growthbook.io/self-host#updating-to-latest)\n\nBefore deploying GrowthBook in production, we recommend that you make sure you've configured GrowthBook correctly:\n\n*   Change the `JWT_SECRET` environment variable. This is used to sign the JWT tokens used for authentication, and needs to be changed from the default.\n*   Change the `ENCRYPTION_KEY` environment variable. This is used to encrypt sensitive data, and should be set to a long random string.\n*   Set the `NODE_ENV` environment variable to `production`. This will enable add additional optimizations and disable some debugging features.\n\n## Audit logs[​](#audit-logs \"Direct link to Audit logs\")\n\nGrowthBook keeps an audit log of all actions taken on the platform. The audit logs is useful if you need to determine what actions as user has done. You can access this page from the Settings → Log in the left navigation. You can read more about audit logs [here](https://docs.growthbook.io/account/audit-logs).",
  "title": "Security | GrowthBook Docs",
  "description": "GrowthBook is built with security in mind, and we have made architectural decisions to ensure that your",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/using/programs",
  "markdown": "# Experimentation Programs | GrowthBook Docs\n\n“Experimentation”, or being more “data driven” can mean a lot of different things for different companies. It can be anything from running 1 test a quarter, to running 10s of thousands of experiments simultaneously. This difference of experimentation sophistication can be thought of with the crawl, walk, run, fly framework (From “Trustworthy Online Controlled Experiments: A Practical Guide to A/B Testing”, Ron Kohavi, Diane Tang, Ya Xu).\n\n**CRAWL - Basic Analytics** Companies at this stage have added some basic event tracking and are starting to get some visibility into their users behavior. They are not running experiments, but the data is used to come up with insights and potential project ideas.\n\n**WALK - Optimizations** After implementing comprehensive event tracking, focus now turns to starting to optimize the user experience on some parts of the product. At this stage, A/B tests may be run manually, limiting the number of possible experiments that can be run. Typically at this stage, depending on the amount of traffic you have, you may be running 1 to 4 tests per month.\n\n**RUN - Common Experimentation** As a company realizes that experimentation is really the only way to causally determine the impact of the work they are doing, they will start to ramp up their ability to run A/B tests. This means adopting or building an experimentation platform. With this, all larger changes made to their product are tested, as well they may have a Growth Team that is focused on optimizing parts of their product. At this stage, a company will be running 5 - 100 A/B Tests/Month. This may also include hiring a data team to help with setting up and interpreting the results.\n\n**FLY - Ubiquitous Experimentation** For companies that make it to the flying stage, A/B testing becomes the default for every feature. Product teams develop success metrics for all new features, and then they are run as an A/B test to determine if they were successful. At this point, A/B tests are able to be run by anyone in the product and engineering organization. Companies at this stage of ubiquitous experimentation can run anywhere from 100 to 10,000+ A/B Tests/Month.\n\n## Making the case for experimentation[​](#making-the-case-for-experimentation \"Direct link to Making the case for experimentation\")\n\nIf your organization doesn't yet experiment often, you may need to make the case for why you should. The best way, when you are working on a project, is to ask your team \"what does success look like for this project?\" and \"How would we measure that success?\" In this case, two things will happen, either they'll give an answer that is not statistically rigorous, like looking at the metrics before and after, or they will say some variation of \"We don't know\". Once you're team realizes that A/B testing is a controlled way to determine causal impact, they'll wonder how they ever built products without it.\n\nThe next pushback you may get is that A/B testing is too hard, or that it will slow down development. This is where you can make the case for GrowthBook. GrowthBook is designed to make A/B testing easy, and to make it so that you can run experiments without slowing down development. We are warehouse native, so we use whatever data you already are tracking, and our SDKs are extremely light weight and developer friendly. The goal at GrowthBook is to make it so easy and cost efficient to run experiments you'll test far more often.\n\nYou can watch a video of making the case for AB testing here:\n\n### Why AB test?[​](#why-ab-test \"Direct link to Why AB test?\")\n\n*   **Quantify Impact** You can determine the impact of any product change you make. There is a big difference between \"we launched feature X on time\" and \"we launched feature X on time and it raised revenue by Y\".\n*   **De-risking** You can de-risk any product change you make with A/B testing. You can test any change you make to your product, and if it doesn't work, you can roll it back. Typically new projects, if they are going to fail, will fail in 3 ways: The project has errors, the project has bugs that unexpectedly effect your metrics/business, or the project has no bugs or errors, but still negatively effects your business. A/B testing will catch all of these issues, and allows you to roll out to a small set of users to limit the impact of a bad feature.\n*   **Limiting investment on bad ideas** As we discussed in our HAMM section - When you focus on building the smallest testable MVP (or MTP) of a product, you can save a lot of time and effort put into a bad idea. You build the MVP and get real users testing it, and if it turns out that you cannot validate the hypothesis behind the idea, then you can move on to other projects, and limit the time spent on ideas that don't work or that will have a negative impact on your business.\n*   **Learning** If you have a well-designed experiment, you can determine causality. If you limit the number of variables that your test has, you can know the exact change drove that change in behavior, and apply these learnings to future projects.\n\n### Why A/B testing programs fail[​](#why-ab-testing-programs-fail \"Direct link to Why A/B testing programs fail\")\n\n*   **Lack of buy-in** If you don't have buy-in from the top, it can be hard to get the resources you need to run a successful experimentation program. You'll need to make the case for why you should experiment, and why you need the resources to do so.\n*   **High cost** Many experimentation systems, especially legacy ones, can be expensive to run or maintain. When the costs are high, you can end up running fewer experiments, and with fewer experiments, the impact is lower. Eventually, a program in this state can atrophy and die.\n*   **Cognitive Dissonance** As you're often getting counter-intuitive results with A/B testing, team members can start to question the platform itself, and may prefer to listen to their gut over the data. This is why building trust in your platform is so important.\n*   **No visibility into the program's impact** Without some measure of the impact of your experimentation program, it can be hard to justify the expense of running it. You'll want to make sure you have a way to measure the impact of your experimentation program.\n\n## Measuring Experiment Program Success[​](#measuring-experiment-program-success \"Direct link to Measuring Experiment Program Success\")\n\nOnce you have added an experimentation program, teams often look for a way to measure the success of that program. There are a few ways you can use to measure the success of your experimentation program, such as universal holdouts, win rate, experimentation frequency and learning rate. Each of these has their own advantages and disadvantages.\n\n### Universal Holdouts[​](#universal-holdouts \"Direct link to Universal Holdouts\")\n\nUniversal holdouts is a method for keeping a certain percentage of your total traffic from seeing any new features or experiments. Users in a universal holdout will continue to get the control version of every test for an extended period of time, even after an experiment is declared, and then those users are compared to users who are getting all the new features and changes. This effectively gives you a cohort of users that are getting your product as it was, say 6 months ago, and comparing it to all the work you’ve done since. This is the gold standard for determining the cumulative impact of every change and experiment, however, it has a number of issues.\n\nTo make universal holdouts work, you need to keep the code that delivers the old versions running and working on your app. This is often very hard to do. Some changes can have a non zero maintenance cost, block larger migrations, or limit other features until the holdout ends. Also, any bugs that arise that only affect one side of the holdouts (either control or in the variations), can bias the results. Finally, due to the typically smaller size of the universal holdout group, it can take longer for these holdout experiments to reach significant values, unless you have a lot of traffic.\n\nGiven the complexity of running universal holdouts, many companies and teams look for other proxy metrics or KPIs to use for measuring experimentation program success.\n\n### Win Rate[​](#win-rate \"Direct link to Win Rate\")\n\nIt can be very tempting to want to measure the experimentation win rate, the number of A/B tests that win over the total number of tests, and optimize your program for the highest win rate possible. However, using this as the KPI for your experiment program will encourage users to not run high risk experiments and creates a perverse incentive for more potentially impactful results (see Goodhart’s Law). Win rate can also hide the benefits of not launching a “losing” test, which is also a “win”.\n\n### Experimentation Frequency[​](#experimentation-frequency \"Direct link to Experimentation Frequency\")\n\nA more useful measure than win rate is optimizing for the number of experiments that are run. This encourages your team to run a lot of tests which increases the chances of any one test producing meaningful results. It may, however, encourage you to run smaller experiments over larger ones, which may not be optimal for producing the best outcomes.\n\n### Learning Rate[​](#learning-rate \"Direct link to Learning Rate\")\n\nSome teams try to optimize for a “learning rate” which is the rate at which you learn something about your product or users through A/B testing. This does not have the frequency or win rate biases, but also is nebulously defined. How do you define learning? Are there different qualities of what you learn?\n\n### KPI Effect[​](#kpi-effect \"Direct link to KPI Effect\")\n\nIf you can pick a few KPIs for your experimentation program, you should be able see the effects of the experiments you run against this. You may not be able to see causality precisely due to the natural variability in the data, and typically small improvements from an A/B test, but by aligning by the graph of this metric to experiments that are run, you may start to see cumulative effects. This is what GrowthBook shows with our North Star metric feature.\n\n## Prioritization[​](#prioritization \"Direct link to Prioritization\")\n\nGiven the typical success rates of experiments, all prioritization frameworks should be taken with a grain of salt. Our preference at GrowthBook is to add as little process as possible and to maximize for a good mix of iterative and innovative ideas.\n\n### Iteration vs Innovation[​](#iteration-vs-innovation \"Direct link to Iteration vs Innovation\")\n\nIt is useful to think of experiment ideas on a graph with one axis being the effort required and the potential impact on the other. If you divide the ideas into two for high effort/impact and low effort/ impact, you’ll end up with the following quadrant.\n\n|     | Low impact | High impact |\n| --- | --- | --- |\n| **High effort** | Danger | Prioritize |\n| **Low effort** | Prioritize | Run now |\n\nThe low effort, high impact ideas you should be running immediately, and similarly the high effort, low impact ideas you may not want to run at all. But this leaves the other two, low effort but low impact (smaller tests), and high effort high impact ideas (big bets). If you over index for smaller test ideas, you can increase your experimentation frequency, but risk not getting larger gains. If you over index for bigger bets, you decrease your experimentation frequency at the hope of larger returns, at the risk of not achieving the smaller wins which can stack up. You can also consider the smaller tests as being “iterative” and the bigger bets as “innovative”.\n\nFinding a good mix of small, iterative tests and bigger bets/innovative tests is the best strategy. What constitutes “good” is up to the team. Some companies will bucket their ideas into these two groups, and then ensure that they are pulling some percentage of ideas from both lists. A healthy mix of large and small ideas are important to a successful experimentation program.\n\n### Prioritization frameworks[​](#prioritization-frameworks \"Direct link to Prioritization frameworks\")\n\nIn the world of A/B testing, figuring out what to test can be particularly challenging. Often prioritization requires a degree of gut instinct which is often incorrect (see success rates). To solve this, some recommend prioritization frameworks, such as ICE and PIE.\n\nnote\n\nNote: Please keep in mind that while these frameworks may be helpful, they can work to give the appearance of objectivity to subjective opinions.\n\n#### ICE[​](#ice \"Direct link to ICE\")\n\nThe ICE prioritization framework is a simple and popular method for prioritizing A/B testing ideas based on their potential impact, confidence, and ease of implementation. Each idea is evaluated on each of these factors and scored on a scale of 1 to 10 and then averaged to determine the overall score for that idea. Here's a brief explanation of the factors:\n\n*   **Impact**: This measures the potential impact of the testing idea on the key metrics or goals of the business. The impact score should reflect the expected magnitude of the effect, as well as the relevance of the metric to the business objectives.\n*   **Confidence**: This measures the level of confidence that the testing idea will have the expected impact. The confidence score should reflect the quality and quantity of the available evidence, as well as any potential risks or uncertainties.\n*   **Ease**: This measures the ease or difficulty of implementing the testing idea. The ease score should reflect the expected effort, time, and resources required to implement the idea. To calculate the ICE score for each testing idea, simply add up the scores for Impact, Confidence, and Ease, and divide by 3:\n\n> ICE score = (Impact + Confidence + Ease) / 3\n\nOnce all testing ideas have been scored using the ICE framework, they can be ranked in descending order based on their ICE score. The highest-ranked ideas are typically considered the most promising and prioritized for implementation.\n\n#### PIE[​](#pie \"Direct link to PIE\")\n\nLike the ICE Framework, the PIE framework is a method for prioritizing A/B testing ideas based on their potential impact, importance to the business, and ease of implementation. Each score is ranked on a 10 point scale.\n\n*   **Potential**: This measures the potential impact of the testing idea on the key metrics or goals of the business. The potential score should reflect the expected magnitude of the effect, as well as the relevance of the metric to the business objectives.\n*   **Importance**: This measures the importance of the testing idea to the business. The importance score should reflect the degree to which the testing idea aligns with the business goals and objectives, and how critical the metric is to achieving those goals.\n*   **Ease**: This measures the ease or difficulty of implementing the testing idea. The ease score should reflect the expected effort, time, and resources required to implement the idea. To calculate the PIE score for each testing idea, simply multiply the scores for Potential, Importance, and Ease together:\n\n> PIE score = Potential x Importance x Ease\n\nOnce all testing ideas have been scored using the PIE framework, they can be ranked in descending order based on their PIE score. The highest-ranked ideas are typically considered the most promising and prioritized for implementation.\n\n### Bias in prioritization[​](#bias-in-prioritization \"Direct link to Bias in prioritization\")\n\nRegardless of what prioritization method you choose, it's quite common to develop a bias for a particular types of ideas within a team. Make sure you're open to ideas that may not fit your preconceived notions of what will work (see [Semmelweis Effect](https://docs.growthbook.io/using/experimentation-problems#semmelweis-effect)). Be mindful of when you're saying \"no\" to an idea if it's based on data or opinion. The goal, in the end, is to improve your business by producing the best product.\n\n## Experimentation Culture[​](#experimentation-culture \"Direct link to Experimentation Culture\")\n\nAdopting experimentation as a key part of being a more data-driven organization has numerous benefits to culture. Specifically around areas of alignment, speed, humility, and collaboration.\n\n### Alignment[​](#alignment \"Direct link to Alignment\")\n\nAdopting a north star metric or KPI that would drive our business success removes a lot of ambiguity about projects because we had clear success metrics. By making sure you have defined success metrics at the start of your planning cycle, you achieve alignment around your goals. This helps reduce the invariable scope creep and pet features from inserting themselves — or at least gives you a framework to say “yes, but not now.” Knowing what success means also allows developers to start integrating the tracking needed to know if the project would be successful from the beginning, which can often be forgotten or only done as an afterthought.\n\n### Speed[​](#speed \"Direct link to Speed\")\n\nWhen adopting an experimentation mindset, the default answer to a difference of opinion becomes “let’s test it” instead of long drawn out ego bruising meetings. This helps reduce personal opinions or bias affecting decisions. Quite often decisions in companies without this mindset are made by whomever is the loudest, or the HiPPOs (Highest Paid Person’s Opinion). By focusing on which metrics defined success, and defaulting to running an experiment, you can remove the ego from the decision process, and move quickly.\n\nExperimentation can also help increase your product velocity by minimizing the time it takes to determine if your new product or feature has product market fit. Most big ideas can be broken down into a small set of assumptions that, if true, would mean your larger idea may be successful. If you can prove or disprove these ideas, you can move more quickly and not waste time on failing ideas (loss avoidance).\n\n### Intellectual humility[​](#intellectual-humility \"Direct link to Intellectual humility\")\n\nAB testing shows us that, in most of the cases, people are bad at predicting user behaviors. When you realize that your opinions may not be correct, you can start to channel your inner Semmelweis and be open to new ideas that challenge any deeply held entrenched norms or beliefs. Having an open mind and intellectual humility for new ideas can make your workplace a more collaborative environment, and produce better products.\n\n### Team collaboration[​](#team-collaboration \"Direct link to Team collaboration\")\n\nWhen you are open to new ideas, you can remove the silos that prevent teams from collaborating well. The goal is to produce the best product as measured by a specific set of metrics. With this alignment, and the openness to new ideas, you can dramatically increase collaboration as good ideas come from anywhere.\n\n## Driving Experimentation Culture[​](#driving-experimentation-culture \"Direct link to Driving Experimentation Culture\")\n\nDeveloping a culture of experimentation can be hard, especially in a company where it has never existed. It requires a lot of buy-in from the top down, and/or a lot of evangelism from the bottom up.\n\n### Top down[​](#top-down \"Direct link to Top down\")\n\nThis is often the easiest way to drive experimentation culture. If the CEO or CTO or CPO says that they want more experimentation, they can make it happen. In these situations, picking the right platform and educating your team becomes the hardest part. You'll want to pick a platform that the developers like to use, that doesn't add unnecessary effort per experiment, and that brings the incremental cost per experiment close to zero. These are some of the reasons we built GrowthBook. If you do decide on GrowthBook, we can also help with educating your team.\n\n### Bottom up[​](#bottom-up \"Direct link to Bottom up\")\n\nIf you don't have buy-in from the top, you can still drive experimentation culture from the bottom up. Typically this starts with one team that wants to start experimenting. They may start with a simple test. Experimentation like this can be contagious, and other teams may start to see the benefits of running experiments. It's important with this approach to make sure that you are sharing your results, both good and bad, and that you are evangelizing the benefits of experimentation.\n\n### Sharing[​](#sharing \"Direct link to Sharing\")\n\nOne great way to get fresh ideas and to help experimentation culture is to share your experiment ideas and results. Our preferred way to present your results is with an experiment review meeting. The premise behind these is to talk about the experiment without revealing the results, and to have people guess about the outcome. Specifically, you talk about the hypothesis and observations as to what and why you are testing, and then talk about the metrics you’re testing against, and then show screen shots of the variations (if applicable). You can have people vote simply by raising their hand. Once you’ve had people guess, you reveal the actual results. This is a great way to help build intellectual humility and also collect new ideas.\n\nGrowthBook has built experiment review meetings directly into the platform. You can create presentation from the management left navigation. You can then share the presentation with your team, and they can vote on the results.\n\n## Organizational Structures[​](#organizational-structures \"Direct link to Organizational Structures\")\n\nAs you start to scale your experimentation program, you’ll want to think about how you want to organize your teams to ensure high frequency and high quality. There are a number of different ways to organize your teams, and we’ll go through some of the most common ones we’ve seen.\n\n### Isolated teams,[​](#isolated-teams \"Direct link to Isolated teams,\")\n\nWhen companies first start experimenting with experimenting, they often start with isolated teams. This can even be one individual on a team.\n\nOne of the problems with this approach is that as an individual, it is hard to have good ideas to test continually, and you may suffer from idea bias, where your experiences and expertise limit the number and type of ideas you test. Another issue is that successes and failures are not shared. As is typical of experiment programs, if you present ideas that are failing at a 60%+ rate, people may think that the team is doing something wrong.\n\nThese isolated teams can be critical in helping grow awareness of experimentation-driven development. However, the isolated team does not scale well, and running the frequency of experiments to see large impacts will be hard. If the team and leadership like the results, you’ll want to expand to one of the other structures.\n\n### Decentralized Teams[​](#decentralized-teams \"Direct link to Decentralized Teams\")\n\nAs awareness of the ease of and insights gained through experimentation, more teams may start experimenting. This is great and increases the frequency of experimentation that you can run. Each team is empowered to design and start their own experiments- this is sometimes referred to as experimentation democratization.\n\nThere can be some downsides with this approach. It can end up like the Wild West, where best practices, data, metrics, and tooling may not be shared from team to team. This can make it hard for teams to ensure consistent quality and trustworthiness of the results.\n\n### Center of Excellence[​](#center-of-excellence \"Direct link to Center of Excellence\")\n\nTo compensate for the problems of decentralized experimentation programs, many companies will switch to a center-of-excellence approach. With this structure, a central experimentation team ensures that experiments follow best practices, have a testable hypothesis, and have selected the right metrics before launching. This team can also ensure that the data looks right as it comes in and that the results are interpreted correctly.\n\nOne of the issues with the center-of-excellence approach is that it can easily become a bottleneck of excellence and limit the number of experiments that are run.\n\n### Hybrid[​](#hybrid \"Direct link to Hybrid\")\n\nCombining the best of the decentralized teams and center-of-excellence is one of the best ways we’ve seen to run experimentation programs. The Hybrid approach involves an experimentation team that oversees the experiments that are run but don’t directly gatekeep the launching of experiments. In this role, the experimentation team serves as advisors to the teams that are running experiments, helps them improve the quality of experiments, and can also help look into any issues that appear. They can also ensure that the platform, metrics, and data are following their standards. This approach aims to have the experimentation team help educate the product teams on best practices and common pitfalls with running experiments.",
  "title": "Experimentation Programs | GrowthBook Docs",
  "description": "“Experimentation”, or being more “data driven” can mean a lot of different things for different",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/app/experiment-configuration",
  "markdown": "# Experiments (Setup) | GrowthBook Docs\n\nThe Experiments section in GrowthBook is all about analyzing raw experiment results in a data source.\n\nBefore [analyzing results](https://docs.growthbook.io/app/experiment-results), you need to actually run the experiment. This can be done in several ways:\n\n*   [Feature Flags](https://docs.growthbook.io/feature-flag-experiments) (most common)\n*   Running an inline experiment directly with our [SDKs](https://docs.growthbook.io/lib)\n*   [URL Redirects](https://docs.growthbook.io/app/url-redirects)\n*   Our [Visual Editor](https://docs.growthbook.io/app/visual)\n*   Your own custom variation assignment / bucketing system\n\nWhen you go to add an experiment in GrowthBook, it will first look in your [data source](https://docs.growthbook.io/warehouses) for any new experiment ids and prompt you to import them. If none are found, you can enter the experiment settings yourself.\n\n## Adding an Experiment[​](#adding-an-experiment \"Direct link to Adding an Experiment\")\n\nYou can add an experiment analysis to GrowthBook in a few ways.\n\n**Starting an Experiment Analysis from a Feature**\n\nThis is the easiest way to start a new analysis if you have a Feature set up. Navigate to the Feature of interest and click \"View results\" in the Experiment Rule of the Feature. Read more about running feature experiments [here](https://docs.growthbook.io/feature-flag-experiments).\n\n**Importing an Experiment Analysis from your Data Source**\n\nYou can also import an analysis directly from your Data Source using your configured Experiment Assignment Source. If you navigate to the Experiment page in the left toolbar and click Add Experiment, you'll see the following panel.\n\n![Experiment Import Modal](https://docs.growthbook.io/images/import-experiment-modal.png)\n\nOn this modal you can either create an experiment using some metadata that we infer from your metric source using the Import buttons on the right hand side. You can also manually create an experiment from scratch.\n\n## Experiment Configuration[​](#experiment-configuration \"Direct link to Experiment Configuration\")\n\nThere are several different ways to configure your experiment analysis.\n\n### Experiment Metadata[​](#experiment-metadata \"Direct link to Experiment Metadata\")\n\nOn the experiment page in the \"Overview\" tab near the top of the page, you can see the experiment name, tags description, hypothesis, and variation metadata. You can edit these fields as you see fit to help describe and categorize your experiment.\n\n### Experiment Targeting and Traffic[​](#experiment-targeting-and-traffic \"Direct link to Experiment Targeting and Traffic\")\n\nYou can also configure targeting and traffic to your experiment's linked feature flags or visual editor changes. These settings do not have any effect on an experiment that is performing analysis only (with the exception of \"experiment key\"). On the \"Overview\" tab, you will see a section called \"Targeting and Traffic\" which allows you to modify these settings, such as:\n\n**Experiment Key** (tracking key) - This is the key that will be used when filtering your experiment assignment source to query experiment exposure data.\n\n**Hashing attribute** - This is the attribute that will be used to hash the user id to determine which variation they will be bucketed into.\n\n**Fallback attribute** (Sticky Bucketing enabled only) - The Fallback attribute be used when the hash attribute is missing or empty. For example falling back to an anonymous cookie identifier instead of a logged-in user id. Which ever attribute is first used to bucket the user into a variation will \"stick\". For example, if the user is logged out when they first view an experiment, it would use the fallback device id. If the user later logs in, it will continue using the bucket from their device id, even though they now have a logged-in id as well.\n\n**Targeting** - Create matching conditions using attributes and saved groups or target by namespaces.\n\n**Traffic** - Choose the percentage of traffic (coverage) and set the relative weights of each variation.\n\n### Analysis Settings[​](#analysis-settings \"Direct link to Analysis Settings\")\n\nHere is where much of your experiment analysis is configured. Many of the fields here have some text explaining how they affect your analysis. Here are a few of them in more detail:\n\n**Experiment Key**\n\n**Activation Metric** - A binomial metric that will filter the users in your analysis to only those who have converted on this binomial metric. This should only be used if activation is expected to be independent of experiment assignment. If an experiment affects the activation metric directly, then there is the potential for bias in your analysis.\n\n**Metric Conversion Windows** - Some of your metrics may have \"conversion windows\" defined for them. For those metrics, we build a window for each user based on when they were first exposed to the experiment. If a user's first exposure to an experiment was recent (for a running experiment) or or near the end of a stopped experiment, they may not have had the full window to convert before the analysis window closes. You may exclude these users with \"In-Progress Conversions\" if you want your experiment averages to only include those who have had the full window to convert.\n\n**Conversion Override**\n\nPreviously called \"Attribution Model\" in the UI, this setting lets you use an experiment level override to disable all conversion windows and instead use the exposure period for a user (from their first exposure until the end of the experiment) as the metric window. You can read more about Metric Windows on the [Metric documentation page](https://docs.growthbook.io/app/metrics).\n\n*   **Respect Conversion Windows** - This setting ensures that all conversion windows on your metrics are respected.\n*   **Ignore Conversion Windows** - This setting overrides all metrics to be as if they had no conversion windows. Lookback windows will not be overriden by this setting.\n\nFor those familiar with he \"Experiment Duration\" attribution model, choosing \"Ignore Conversion Windows\" will work the same way, and you should know that you can now specify the metric window behavior on a metric-by-metric basis (see the [Metric documentation page](https://docs.growthbook.io/app/metrics)).\n\n### Experiment Metrics[​](#experiment-metrics \"Direct link to Experiment Metrics\")\n\nYou can add metrics as goal metrics, guardrail metrics, or both. You also can add \"Metric Overrides\" which provide experiment-specific controls for metrics, allowing you to override the metric's defaults for, for example, metric windows and risk thresholds.\n\n### Experiment Phases[​](#experiment-phases \"Direct link to Experiment Phases\")\n\nExperiment Phases can help you filter the dates used in the experiment analysis. Be very careful using phases. If you move the start date of the phase to past the start date of the experiment (and users were not re-randomized across phases), then your analysis could suffer from [carryover bias](https://docs.growthbook.io/kb/experiments/carryover-bias). It is best to always look at the full history of an experiment if possible.\n\n### Making Changes While Running[​](#making-changes-while-running \"Direct link to Making Changes While Running\")\n\nRead our dedicated guide on [making changes to running experiments](https://docs.growthbook.io/app/making-experiment-changes).",
  "title": "Experiments (Setup) | GrowthBook Docs",
  "description": "Add and configure your experiments.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/kb/experiments/holdouts",
  "markdown": "# Holdout Experiments in GrowthBook | GrowthBook Docs\n\n## What are holdout experiments?[​](#what-are-holdout-experiments \"Direct link to What are holdout experiments?\")\n\nHoldout experiments (holdouts) are an approach to measuring the long term impact of one feature or a set of features. Essentially, you take some set of users and keep them from seeing new features; you then use them as a control group to measure against some other set of users who are getting all of the features you have launched.\n\nWho uses holdouts?\n\nLarge tech companies often use them to measure both the long-term impact of individual features as well as the general evolution of a product that some team owns. We advocate that everyone uses holdouts at some level, even if only to test the long-term impacts of a single feature every now and then, to begin to understand how they work and what they say about the persistence of experiment effects at your company.\n\nWhy would I want to run a holdout?\n\n*   Holdouts are a great way to measure long-term impact. The impact of features changes over time, as does user behavior, and running an experiment for an extended period can help you understand these effects.\n*   Holdouts can help you measure the impact of multiple features at once. Experiments can interact with each other in unexpected ways and these interactions can change as time goes on.\n\nWhy wouldn't I want to run a holdout?\n\n*   Holdouts require you to keep a certain set of users behind the rest in terms of functionality.\n*   Holdouts require you to maintain feature flags in your codebase for their duration.\n*   Holdouts work best for logged-in experimentation, but can still be useful with anonymous traffic.\n\n## Can I run a holdout experiment in GrowthBook?[​](#can-i-run-a-holdout-experiment-in-growthbook \"Direct link to Can I run a holdout experiment in GrowthBook?\")\n\n**Yes!**\n\nHoldouts are a special class of experiment. While the GrowthBook team plans to build dedicated support for holdouts to make them even easier to run, this document will show you how to run them today.\n\n## How to run a holdout experiment in GrowthBook[​](#how-to-run-a-holdout-experiment-in-growthbook \"Direct link to How to run a holdout experiment in GrowthBook\")\n\n### Background[​](#background \"Direct link to Background\")\n\nFor this tutorial, we will assume the following goals:\n\n*   You want to hold out 5% of users from some time period from seeing a set of features (the 5% is customizable)\n*   You want to measure the impact of launching one or more features to the general population\n\nTo achieve these goals we will essentially split our traffic into 2 groups:\n\n1.  10% of traffic: your **holdout** population, split into two sub-groups\n    1.  A **`holdout control`** group here - 5% of global traffic that will never see new features and serves as our holdout control\n    2.  A **`holdout treatment`** group - 5% of global traffic that sees all new features _but only once they are released, not while they are being experimented/tested._\n2.  Our **`general population`** - 90% of traffic that gets experimented on and released to\n\n### 1\\. Create a Holdout Experiment[​](#1-create-a-holdout-experiment \"Direct link to 1. Create a Holdout Experiment\")\n\n1.  Create an experiment called, for example, ”Global Holdout Q1 2024”.\n2.  **Splits:** Set coverage to 10% and then use a 50/50 split (again to achieve our 10% holdout test population, which you can customize).\n\n![Traffic Splits for an Example Holdout Experiment](https://docs.growthbook.io/images/statistics/holdout-splits.png)\n\n3.  **Metrics:** Likely you do not want to use conversion windows with a holdout experiment. Users are going to get exposed to the holdout experiment as soon as you start testing the feature, so conversion windows may expire before you ever actually expose the **holdout treatment** group to the experiment. There are two solutions:\n    1.  Use your regular metrics and set **Conversion Window Override** to **Ignore Conversion Windows** in your Experiment Analysis settings\n    2.  Use metrics that have no conversion window OR use a Lookback Window to only measure the last X days of the holdout. For example, if you want to run a holdout for 2 months, but only measure effects in the last month, you can use metrics with 30 day Lookback Windows (you can use metric overrides within the experiment to do this, or create versions of your metrics that use Lookback Windows).\n4.  Start the experiment, even though it doesn't have any linked features.\n\n### 2\\. Add Holdout Experiment to All Future Features[​](#2-add-holdout-experiment-to-all-future-features \"Direct link to 2. Add Holdout Experiment to All Future Features\")\n\n1.  Create a feature that you want to add to your holdout. Before testing or launching the feature, add the above Holdout Experiment as an experiment rule ABOVE any feature experiment. This will ensure your holdout population never gets the feature until you choose to release it to them.\n2.  Ensure that the `holdout control` and `holdout feature` group get the **same value** as one another, and that this value is the same as the default/control behavior for your feature test in the `general population`.\n3.  To then test your new feature, add an experiment rule to your feature, where the control is getting the same value as the holdout groups.\n\nSee image below for an example of the state the test feature (here called \"New Checkout Flow\") should be in now:\n\n![Feature Rules for an Example Feature Experiment with Holdout](https://docs.growthbook.io/images/statistics/holdout-rules.png)\n\n### 3\\. Launch Features[​](#3-launch-features \"Direct link to 3. Launch Features\")\n\nOnce you are ready to launch your feature, you have to take two steps:\n\n1.  Release the feature in the `general population` as you would normally. You can do this by enabling “Temporary rollout” in your feature experiment (navigate to the experiment, click “Stop Experiment” and then pick the winning variation with temporary rollout enabled) or by editing the feature experiment rule to roll it out to all users more manually.\n2.  Update the holdout experiment rule manually to roll out the winning variation to the **holdout feature group.** Just update the feature flag value that the **holdout feature** group is getting. Then, you'll be in the state below.\n\n![Feature Rules for an Rolled Out Feature with Holdout](https://docs.growthbook.io/images/statistics/holdout-rollout-rules.png)\n\n### 4\\. Monitor your Holdout Experiment![​](#4-monitor-your-holdout-experiment \"Direct link to 4. Monitor your Holdout Experiment!\")\n\nThat's it! Initially, your holdout population will be seeing the same version of the app, so this experiment will show no differences. As you begin rolling out features, you should begin to see differences in the two groups. At a high-level, here's how this set-up would look for one quarter where you ran three tests and rolled out two features:\n\n![Timeline of an Example Holdout Experiment](https://docs.growthbook.io/images/statistics/holdout-overview.png)\n\nA couple of notes:\n\n*   As you can see that double blue and orange shaded region will serve as the full test of both shipped features together. You may even want to extend the measurement period beyond the quarter (where you don't add any new features) in order to let all features be in the holdout test group for a period.\n*   You'll also note that the `holdout feature` group is only getting features once they are released to everyone. This helps keep the measurement of the impact of the features clean, as you are not measuring the impact of the feature being tested with different settings, but rather the impact of the final feature being released. That said, the alternative is also interesting, where you compare `general population` to your `holdout control` group, but that isn't currently supported in GrowthBook.",
  "title": "Holdout Experiments in GrowthBook | GrowthBook Docs",
  "description": "Holdout Experiments",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/app/metrics",
  "markdown": "# Metrics | GrowthBook Docs\n\nMetrics are what your experiments are trying to improve (or at least not hurt). GrowthBook has a very flexible and powerful way to define metrics.\n\ninfo\n\nThere's a brand new way to define metrics in GrowthBook using **Fact Tables**. [Check out the docs](https://docs.growthbook.io/app/fact-tables)\n\n## Conversion Types[​](#conversion-types \"Direct link to Conversion Types\")\n\nMetrics can have different units and statistical distributions. Below are the ones GrowthBook supports:\n\n| Conversion Type | Description | Example | Default aggregation (SQL) |\n| --- | --- | --- | --- |\n| binomial | A simple yes/no conversion | Created Account | 1/0 per unit |\n| count | Sums conversion values per user | Pages per Visit | `SUM(value)` per unit |\n| duration | How much time something takes | Time on Site | `SUM(value)` per unit |\n| revenue | The revenue gained/lost | Revenue per User | `SUM(value)` per unit |\n\nFor experiment analysis, each of these metric types uses some aggregation (often defaulting to `SUM`) per user and then takes an average with respect to the total number of users. In the case of SQL metrics, the only meaningful difference between count, duration, and revenue is how we render the units in the metric and experiment results pages.\n\nnote\n\nRevenue Metrics are displayed in USD by default. You can change your display currency under **Settings** → **General** → **Metric Settings**\n\n## Query settings[​](#query-settings \"Direct link to Query settings\")\n\nFor metrics to work, you need to tell GrowthBook how to query the data from your data source. There are a few ways to do this depending on your data source.\n\n### 1\\. SQL (recommended)[​](#1-sql-recommended \"Direct link to 1. SQL (recommended)\")\n\nIf your data source supports SQL, this is the preferred way to define metrics. You can use joins, subselects, or anything else supported by your SQL dialect.\n\nYour SELECT statement should return one row per \"conversion event\". This may be a page view, a purchase, a session, or something else. The end result should look like this:\n\n| user\\_id | timestamp | value |\n| --- | --- | --- |\n| 123 | 2021-08-23 12:45:14 | 10  |\n| 456 | 2021-08-23 12:45:15 | 5.25 |\n\nMetrics can support one or more types of identifiers. The above example assumes the metric only supports a single id type called `user_id`, but you would add additional columns if you need to support other ones.\n\n#### Non-binomial metrics[​](#non-binomial-metrics \"Direct link to Non-binomial metrics\")\n\nFor count, revenue, and duration metrics metric types, the value represents the count, duration, or revenue from that single conversion event. In the case of multiple rows for a single user, the values will be summed together or we will use a custom aggregation that you can specify.\n\nTherefore a `count` metric can really be any arbitrary metric whose `value` you want to sum at the user level before taking an average per variation.\n\nIf you use Segment to populate your data warehouse, the SQL for a `Revenue per User` metric might look like this:\n\n```\nSELECT  -- Assuming you support 2 identifier types - 'user_id' and 'anonymous_id'  user_id as user_id,  anon_id as anonymous_id,  received_at as timestamp,  grand_total as valueFROM  purchases\n```\n\nIf you wanted to count the number of conversion rows per user, you can simply set `1 as value` in your SQL query and then the default SUM aggregation will count the number of rows per user.\n\n#### Binomial metrics[​](#binomial-metrics \"Direct link to Binomial metrics\")\n\nBinomial metrics don't need a `value` column (the existence of a row means the user converted). You would only need to return the following columns, representing users and when they \"converted\" on this binomial metric:\n\n| user\\_id | timestamp |\n| --- | --- |\n| 789 | 2022-08-23 12:45:14 |\n| 111 | 2022-08-23 12:45:15 |\n\nWhen we go to conduct experiment analysis, any `user_id` that has a conversion in the appropriate time window will be counted as a `1`, while all other users will be counted as a `0`. Then we can compute the proportion of users in an experiment variation who converted.\n\n#### SQL Templates[​](#sql-templates \"Direct link to SQL Templates\")\n\nWe use {{[Handlebars](https://handlebarsjs.com/guide/#language-features)}} to compile the sql into what is actually called to your database. This allows you to create template metrics that can be copied and reused by changing the variable values associate with the metrics.\n\nYou can use the following user configurable variables within SQL templates:\n\n*   **eventName** - The event name associated with this metric. This can then be referenced in your sql template as `{{eventName}}`. Depending upon how your data is structured you can then incorporate it as part of the table name, if each event has its own table, or as part of a where clause limiting the rows returned to where a certain column equals the eventName.\n*   **valueColumn** - The column in your datawarehouse table with the metric data. This can then be referenced in your sql template as `{{valueColumn}}`. For example you might have `{{valueColumn}} as value` to extract out the value from the table.\n\nYou can also use any of the in-built variables that Growthbook automatically sets:\n\n*   **startDate** - `yyyy-MM-dd HH:mm:ss` of the earliest data that needs to be included\n*   **startDateISO** - `yyyy-MM-dd'T'HH:mm:ss.SSS'Z'` of the startDate in ISO format. This can then be used with the `date` helper to achieve whatever [format](#dateformat) you like (ex. `{{date startDateISO \"yyyyMMdd\"}}`)\n*   **endDate** - `yyyy-MM-dd HH:mm:ss` of the latest data that needs to be included\n*   **endDateISO** - `yyyy-MM-dd'T'HH:mm:ss.SSS'Z'` of the endDate in ISO format. This can then be used with the `date` helper to achieve whatever [format](#dateformat) you like (ex. `{{date endDateISO \"yyyyMMdd\"}}`)\n*   **experimentId** - Either a specific experiment id OR `%` if you should include all experiments\n\nYou can also use any of the in-built helper functions:\n\n*   **camelcase \\[str\\]** - ex. `{{camelcase \"My database\"}}` compiles to `myDatabase`.\n*   **dotcase \\[str\\]** - ex. `{{dotcase \"My database\"}}` compiles to `my.database`.\n*   **kebabcase \\[str\\]** - ex. `{{kebabcase \"My database\"}}` compiles to `my-database`.\n*   **lowercase \\[str\\]** - ex. `{{lowercase \"My database\"}}` compiles to `my database`.\n*   **pascalcase \\[str\\]** - ex. `{{pascalcase \"My database\"}}` compiles to `MyDatabase`.\n*   **replace \\[str\\] \\[pattern\\] \\[replacement\\]** - Replace all occurences of a regular expression with something else. ex. `{{replace \"My%%%Database!\" \"\\[^a-zA-Z\\]\" \"\"}}` compiles to `MyDatabase`\n*   **snakecase \\[str\\]** - ex. `{{pascalcase \"My database\"}}` compiles to `my_database`.\n*   **uppercase \\[str\\]** - ex. `{{uppercase \"My database\"}}` compiles to `MY DATABASE`.\n*   **date \\[date\\] \\[format\\]** - Format an ISO date according to this [format](https://date-fns.org/v2.29.3/docs/format), being careful not to mix up months (MM) and minutes (mm). ex. `{{date startDateISO \"yyyyMMdd\"}}` might compile to `20230130`. The most common codes are:\n\n| code | meaning |\n| --- | --- |\n| yyyy | year |\n| MM  | month |\n| dd  | day |\n| HH  | hour |\n| mm  | minutes |\n| ss  | seconds |\n| t   | timestamp |\n\nFor example you could have the following reusable sql template that could be used for many metrics, with only needing to change the valueColumn and eventName variables that will appear within the UI form:\n\n```\nSELECT  user_id as user_id,  received_at as timestamp,  {{valueColumn}} as valueFROM  database.{{snakecase eventName}}WHERE  received_at BETWEEN '{{ startDate }}' AND '{{ endDate }}'\n```\n\nnote\n\nThe inserted values do not have surrounding quotes, so you must add those yourself (e.g. use `'{{&nbsp;startDate&nbsp;}}'` instead of just `{{&nbsp;startDate&nbsp;}}`\n\n#### Denominator (Ratio / Funnel Metrics)[​](#denominator-ratio--funnel-metrics \"Direct link to Denominator (Ratio / Funnel Metrics)\")\n\nBy default, metrics are evaluated against all users in an experiment: `(# users who converted) / (# users in experiment)`\n\nYou can instead choose another metric to use as the denominator.\n\n##### Funnel Metrics[​](#funnel-metrics \"Direct link to Funnel Metrics\")\n\nWhen the denominator is a simple binomial (conversion) metric, then it acts just like an \"activation metric\" in an experiment. It filters the users who are included in the analysis to those who first convert on this denominator metric.\n\nFor example, if you want to look at what percent of users checkout after viewing a cart, it can be described as `% checkout / % viewed cart`. This requires creating two metrics:\n\n1.  `Viewed Cart` - selects all users who viewed a cart\n2.  `Viewed Cart -> Checkout` - selects all users who checked out and picks `Viewed Cart` as the denominator.\n\n##### Ratio Metrics[​](#ratio-metrics \"Direct link to Ratio Metrics\")\n\nWhen the denominator is a count metric, then things are a little different. Instead of acting like a filter, we calculate both metrics and treat the value as a ratio.\n\n*   The mean is `sum(metric) / sum(denominator)`\n*   The standard deviation is calculated using the **Delta method**\n\nFor example, if you want to look at the Average Order Value (AOV), what you're really looking for is `total revenue / number of orders`. This also requires creating two metrics:\n\n1.  `Orders per User` - selects the count of orders for each user\n2.  `AOV` - selects total revenue per user and picks `Orders per User` as the denominator.\n\n##### Quantile Metrics[​](#quantile-metrics \"Direct link to Quantile Metrics\")\n\n[Quantile Metrics](https://docs.growthbook.io/statistics/quantile) are available only as Fact Tables, as described [here](https://docs.growthbook.io/app/fact-tables).\n\n### 2\\. Javascript (Mixpanel only)[​](#2-javascript-mixpanel-only \"Direct link to 2. Javascript (Mixpanel only)\")\n\nWe query Mixpanel data sources using their proprietary JQL language based on Javascript. This allows for extreme flexibility when defining metrics.\n\nAll metrics at minimum need to specify an **Event Name** which must exactly match what is used in Mixpanel. You can use `OR` to match against multiple events. For example `viewed_cart OR purchased`\n\nYou can optionally add **Conditions** which filters the events further based on properties. For example, if Event Name is `Page view`, you can add a condition `path = \"/blog\"`.\n\nCount, duration, and revenue metrics have two additional steps. We first extract all event values for a user into an array and then reduce that array down to a single number, which is the final metric value for the user.\n\n#### Conditions[​](#conditions \"Direct link to Conditions\")\n\nConditions in Mixpanel are very powerful. They consist of a **Property**, an **Operator**, and a **Value**. Multiple conditions are joined with an AND.\n\nThe **Property** can either be the name of an event property or a javascript expression. Some examples:\n\n*   `amount`, equivalent to `event.properties.amount`\n*   `event.time`\n*   `event.properties.city + \", \" + event.properties.country`\n\nThe **Operator** is one of the following:\n\n*   equals\n*   does not equal\n*   is greater than\n*   is greater than or equal to\n*   is less than\n*   is less than or equal to\n*   matches the regex\n*   does not match the regex\n*   custom javascript\n\nThe `custom javascript` operator is special. The **Value** is a javascript expression that evaluates to either `true` or `false` (access the property value with the `value` variable). It lets you do arbitrarily complex filtering. For example:\n\nFor all other operators, the condition should read like an English sentence. For example:\n\n```\n// property operator valuecountry equals US// Will render asevent.properties.country == \"US\"\n```\n\n#### Event Value[​](#event-value \"Direct link to Event Value\")\n\nFor count, revenue, and duration metrics, we need to know what the \"value\" of the event is.\n\nThe **Event Value** is a Javascript expression to extract a value from a raw Mixpanel event. If you are just extracting a single property as-is, you can just enter the property name as a shortcut. Otherwise, you can reference the `event` variable in your expression.\n\nHere are some example Event Value expressions:\n\n*   `grand_total`, equivalent to `event.properties.grand_total`\n*   `1` (hard-code the value to a specific number)\n*   `(event.properties.endTime - event.properties.startTime) / (60 * 60)` (difference in hours between two unix timestamps)\n*   `new Date(event.time).toISOString().substr(0, 10)` (event timestamp in YYYY-MM-DD format)\n\nFor count metrics, you can leave Event Value blank and it will default to hard-coding the value to `1`, which is perfect for when you just want to count the number of events and don't care about specific properties.\n\n#### User Value Aggregation[​](#user-value-aggregation \"Direct link to User Value Aggregation\")\n\nFor count, revenue, and duration metrics, we need to know how to aggregate the event values together, in case a single user has multiple matching events.\n\nThe **User Value Aggregation** is another Javascript expression that reduces an array of Event Values to a single number (or null if the user did not convert). Reference the variable `values` in your expression. There are a few built-in helper functions:\n\n*   `count(values)`\n*   `countDistinct(values)`\n*   `sum(values)`\n*   `min(values)`\n*   `max(values)`\n*   `avg(values)`\n*   `median(values)`\n*   `percentile(values, p)` (p is a number between `0` and `100`)\n\nYou can use your own custom expression too if you want. For example, this is the equivalent of `sum(values)`:\n\n```\nvalues.reduce((sum, n) => sum + n, 0);\n```\n\nIf the aggregation is left blank, we do `sum(values)` by default.\n\n### 3\\. SQL Query Builder (legacy)[​](#3-sql-query-builder-legacy \"Direct link to 3. SQL Query Builder (legacy)\")\n\nThe query builder prompts you for things such as table/column names and constructs a SQL query behind the scenes.\n\nWe only recommend this for extremely simple metrics. Inputting raw SQL is far more flexible.\n\n## Behavior[​](#behavior \"Direct link to Behavior\")\n\nThe behavior tab lets you tweak how the metric is used in experiments. Depending on the metric type and datasource you chose, some or all of the following will be available:\n\n### What is the Goal?[​](#what-is-the-goal \"Direct link to What is the Goal?\")\n\nFor the vast majority of metrics, the goal is to increase the value. But for some metrics like \"Bounce Rate\" and \"Page Load Time\", lower is actually better.\n\nSetting this to \"decrease\" basically inverts the \"Chance to Beat Control\" value in experiment results so that \"beating\" the control means decreasing the value. This will also reverse the red and green coloring on graphs.\n\n### Capped Value[​](#capped-value \"Direct link to Capped Value\")\n\nLarge outliers can have an outsized effect on experiment results. For example, if your normal revenue per user $40 and someone happens to make a $5000 order, whatever variation that person is in will be much more likely \"win\" any experiment because that one order is an outlier.\n\nCapping (also known as winsorization) works by ensuring that all aggregate unit (e.g. user) values are no more than some value. So in the above example, if the cap was $100, the $5000 purchase will still be counted, but the aggregated value for that user will be capped at $100 and will have a much smaller effect on the results. It will still give a boost to whatever variation the person is in, but it won't completely dominate all of the other orders and is unlikely to make a winner just on its own. Another way to think about this is that you are slightly biasing your results by truncating large values, but you are reducing variance to prevent the outsized effect of outliers.\n\nThere are two ways to cap metric values in GrowthBook:\n\n**1\\. Absolute capping** - if set above zero, all aggregated user values will be capped at exactly this value. For example, if the cap is $100 on total revenue per user, then after we sum all of a users orders up, any user with an aggregate sum of greater than $100 will be set to $100.\n\n**2\\. Percentile capping** - when this is set to between 0 and 1, it uses that percentile to select a cap based on the data in your experiment so far. This cap is therefore specific to each experiment and specific to each analysis run in that experiment if new data has come in. It works like so: after we calculate the unit-level aggregate values for all units (e.g. users) during an experiment analysis, we find the specified percentile of these unit-level aggregates and then cap these aggregated values at this percentile. Using the above example, if you were to specify percentile capping with a value of `0.95`, then we find the 95th percentile of total revenue per users (say this turns out to be $135). We then cap those user-level aggregates at $135.\n\nYou can additionally choose to ignore zeros, which will compute the percentile without including any user aggregated zero values. This is useful if you have a lot of zero values and you don't want to have to fine tune the percentile to avoid setting the cap too low.\n\nBecause the percentile cap depends on the data in your experiment, it can be different from experiment to experiment, or even analysis to analysis. To find out what value was actually used for capping you can do the following: on the Experiment Results tab, click the three dot menu in the top right and select \"View Queries\". Each percentile capped metric will have a column with the `main_cap_value` that was used to cap that metric and represents the computed percentile of unit-level aggregate values.\n\n### Metric Windows[​](#metric-windows \"Direct link to Metric Windows\")\n\nWhen used in an experiment, we only consider rows of a Metric where the timestamp is greater than or equal to the first time the user was exposed to the experiment. In other words, if someone purchases something before seeing your experiment, it won't be included in the analysis. This behavior is ideal for the vast majority of metrics, but you can change it with the Metric Delay setting if desired (see below).\n\nThere are three window settings one can use to configure the metric date window. Each of them defines the lower and upper date range of the metric to use for each user:\n\n*   **None** (default)\n    *   Lower bound: user's first exposure plus the metric delay\n    *   Upper bound: experiment end date\n*   **Conversion Window**\n    *   Lower bound: user's first exposure plus the metric delay\n    *   Upper bound: the lower bound + the length of the conversion window\n*   **Lookback Window**\n    *   Lower bound: the experiment end date minus the lookback window OR the user's first exposure plus the metric delay, whichever is later\n    *   Upper bound: experiment end date\n\nHere's a graphical representation of these three window types for a hypothetical User 1: ![Metric Windows](https://docs.growthbook.io/assets/images/metric-windows-024e6a7e756c8cd43f0d35ee221cc089.png)\n\nHere's a second example for a hypothetical User 2, who joins the experiment late. Notice that the conversion window can extend beyond the experiment end date.\n\n![Metric Windows (User 2)](https://docs.growthbook.io/assets/images/metric-windows-user-2-dac5ae6d7345e2211ec13dd5f8869954.png)\n\nWhy might you choose one window over another?\n\n**None** - The simplest. Use all data available. This is useful for using as much data associated with users in your experiment and will combine any behavior that is right after experiment exposure as well as long run behavior within the experiment time frame.\n\n**Conversion window** - Conversion windows allow you to only look at events that are tied to the first exposure to an experiment. This can help if, for example, you are tracking purchases and you only want to measure the effect of an experiment in a checkout flow on purchases made soon after seeing that checkout flow. Using a conversion window can reduce the noise from user behavior not related to an experiment. However, if you set the window too short, you may not capture users that return a few days later and were influenced by the experiment.\n\n**Lookback window** - Lookback windows are good for capturing long run impacts of an experiment on regular behavior like user log ins or page views. They have two main advantages:\n\n(1) You can mitigate the novelty effect of an experiment; if you are testing a new recommendation algorithm, at first users may react a certain way to the experiment, but eventually they may adjust and so may their behavior. In these cases, you may just want to look at the last 14 days of an experiment.\n\n(2) Lookback windows help you focus on the long run effects of an experiment. Much of experimentation is about building a better product; by focusing on impact of an experiment after it has been live for a week or two, you may get a better picture of the long run impact of launching the experiment.\n\nLarger companies who measure long run logged in behavior want to ensure their experiments have lasting effects and often rely on lookback windows to make shipping decisions However, lookback windows may not be right if you are testing a feature on logged-out or anonymous users and are measuring simple purchase conversions or something similar. In these cases, you might end up with many logged-out users who, in the long run, simply have no metric data associated with them.\n\n### Metric Delay[​](#metric-delay \"Direct link to Metric Delay\")\n\nConversions within the first X hours of being put into an experiment are ignored (default = `0`). This is useful for metrics like \"day 2 retention\". In that case, if your underlying table reports whether a user is retained on any given day, you could set a metric delay to `24` hours.\n\n#### Negative metric delays[​](#negative-metric-delays \"Direct link to Negative metric delays\")\n\nThe metric delay can also be negative to include some conversions **before** a user is put into an experiment. For example, a value of `-2` would mean conversions up to 2 hours before will be included. You might be wondering when this would ever be useful.\n\nImagine the average person stays on your site for 60 seconds and your experiment can trigger at any time.\n\nIf you just look at the average time spent after the experiment, the numbers will lose a lot of meaning. A value of `20 seconds` might be horrible if it happened to someone after only 5 seconds on your site since they are staying a lot less time than average. But, that same `20 seconds` might be great if it happened to someone after 55 seconds since their visit is a lot longer than usual. Over time, these things will average out and you can eventually see patterns, but you need an enormous amount of data to get to that point.\n\nIf you set the metric delay to something negative, say `-0.5` (30 minutes), you can reduce the amount of data you need to see patterns. For example, you may see your average go from 60 seconds to 65 seconds.\n\nKeep in mind, these two things are answering slightly different questions. `How much longer do people stay after viewing the experiment?` vs `How much longer is an average session that includes the experiment?`. The first question is more direct and often a more strict test of your hypothesis, but it may not be worth the extra running time.\n\n### Bayesian Priors[​](#bayesian-priors \"Direct link to Bayesian Priors\")\n\nYour organization can set default priors for Bayesian analyses that are used by all metrics.\n\nHowever, you can also set metric specific priors by opening the Edit Metric modal from the Metric page, clicking on Advanced Settings, and turning on the metric override. This will allow you to set a custom prior for that metric.\n\nAdditionally, you can use experiment metric overrides to further customize these priors for each experiment.\n\nYou can read more about Bayesian priors on [our statistical details page](https://docs.growthbook.io/statistics/details).\n\n## Auto Generate Metrics[​](#auto-generate-metrics \"Direct link to Auto Generate Metrics\")\n\nWhen using GrowthBook with certain event trackers, we may be able to generate metrics for you automatically by identifying the unique events tracked by your event tracker. This is currently only supported for a few event trackers (listed below), but we are working to expand this list.\n\nIf you are using one of the supported event trackers and would like to see what metrics we can create for you, head to the `Metrics` page in GrowthBook and select the `Discover Metrics` button.\n\nnote\n\nWhen querying your datasource to identify unique events, we're currently only looking at events in the last 7 days.\n\n### Supported Event Trackers[​](#supported-event-trackers \"Direct link to Supported Event Trackers\")\n\n*   Segment\n*   Rudderstack\n*   Google Analytics 4 (GA4)\n\n## Examples[​](#examples \"Direct link to Examples\")\n\nLet's walk through some examples of creating binomial, count, and retention metrics with GrowthBook. For all of the metrics below, let's pretend we have some table called `events`, which has one row per event tracked to your warehouse. For each row we have the following columns:\n\n*   `user_id` - the id of the user\n*   `timestamp` - the time the event was counted\n*   `event_name` - the name of the event, we'll focus on 'purchase' as a key event types\n*   `value` - the total value of the event, in this case the total value of a purchase\n\nFrom this table, we can build many different metrics:\n\n| Name | Metric Type | SQL | Aggregation | Denominator | Metric Delay | Metric Window |\n| --- | --- | --- | --- | --- | --- | --- |\n| Any Purchase | Binomial | SELECT user\\_id, timestamp FROM events WHERE event\\_name = 'purchase' | n/a |     | 0   |     |\n| Number of Purchases | Count | SELECT user\\_id, timestamp, 1 as value FROM events WHERE event\\_name = 'purchase' | default (SUM) |     | 0   |     |\n| Order Value | Revenue | SELECT user\\_id, timestamp, value FROM events WHERE event\\_name = 'purchase' | default (SUM) |     | 0   |     |\n| Average Order Value | Revenue (ratio) | SELECT user\\_id, timestamp, value FROM events WHERE event\\_name = 'purchase' | default (SUM) | Number of Purchases | 0   |     |\n| 7-Day Retention | Binomial | SELECT user\\_id, timestamp FROM events | n/a |     | 24\\*7=144 hours |     |\n| Active User Last 14d | Binomial | SELECT user\\_id, timestamp FROM events | n/a |     | 0   | Lookback - 14 day |\n\nIf you wanted to only count purchases and purchase values made in the 72 hours after a user's first exposure to an experiment, then you could set the metric window to a conversion window of 72 hours. If you wanted to just count any user who made a purchase any time after experiment exposure, then set the metric window to none.",
  "title": "Metrics | GrowthBook Docs",
  "description": "Learn about defining the metrics you will use in your A/B test results",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/statistics/overview",
  "markdown": "# GrowthBook Statistics | GrowthBook Docs\n\nGrowthBook provides both Bayesian and frequentist approaches to experiment analysis. We default to Bayesian statistics because they provide a more intuitive framework for decision making for most customers, but we provide ample tools to select between both approaches based on your experimentation needs. You can choose between the two statistics engines at the Organization or Project level.\n\n## Bayesian Statistics[​](#bayesian-statistics \"Direct link to Bayesian Statistics\")\n\nBayesian methods provides a few key advantages over frequentist approaches.\n\nFirst, they provide more intuitive results. Instead of p-values and confidence intervals, you get probabilities and distributions of likely outcomes. These values allow you to make statements like _\"there’s a 95% chance this new button is better and a 5% chance it’s worse\"_ while there is no direct analog in a frequentist framework.\n\nSecond, Bayesian methods allow you to write down your prior knowledge about experiment effects to ensure that you do not over-interpret small sample sizes and to benefit from old knowledge to reduce uncertainty in new experiments.\n\nThird, Bayesian results are still valid even if you stop an experiment early. While they can suffer from the same \"peeking\" problems as frequentist statistics, at least the main probabilities and statistical results that you see are not invalidated by stopping early. However, this is something of a difference without a distinction, as the decision to stop an experiment early can still result in inflated false positive rates.\n\nHowever, they can require a bit more fine-tuning to get right; however, in GrowthBook both engines are very similar under the hood so picking one can come largely down to personal preference and familiarity. In fact, tools like CUPED are available for both engines.\n\n### Priors and Posteriors[​](#priors-and-posteriors \"Direct link to Priors and Posteriors\")\n\nAt GrowthBook, we default to an improper, uninformative prior. This means that we do not use prior information to impact your experiment results by default. We do this to ensure that people who want to use the Bayesian engine to the fullest are able to enable proper priors and reap their benefits, but without automatically affecting results when experimenters first begin experimenting with GrowthBook.\n\nA prior works by providing additional information to your analysis for what kinds of results are likely based on past evidence. Our statistics engine will combine it with the actual results from your experiment to come up with our final distribution (our \"posterior\"). This represents the most likely outcomes of your experiment combining prior knowledge and the experiment data. Priors can be very helpful in reducing uncertainty in small sample sizes and in ensuring that you do not over-interpret results that are unlikely to be reliable.\n\nYou can easily turn on proper priors by visiting the organization settings, going to the Bayesian engine settings, and turning on the \"Proper Prior\". By default, we use a Normal distribution with mean 0 and standard deviation 0.3. This prior implies that about 68% of effects are between -30% and 30%, 95% of effects are between -60% and 60%, and the average effect is 0%. In effect, it will shrink positive and negative results towards 0, but eventually will be overcome as more data is collected.\n\nThe choice of 0 and 0.3 corresponds roughly to the distribution of effects that we have actually observed on GrowthBook and is both:\n\n1.  Weak enough to not shrink experiments with large sample sizes\n2.  Strong enough to ensure that experiments with small sample sizes are not over-interpreted\n\nYou can read more about how we use the prior and your experiment data to produce experiment results in our [detailed documentation](https://docs.growthbook.io/statistics/details).\n\n### Inferential Statistics[​](#inferential-statistics \"Direct link to Inferential Statistics\")\n\nGrowthBook uses fast estimation techniques to quickly generate inferential statistics at scale for every metric in an experiment - Chance to Win, Relative Uplift, and Risk (or expected loss).\n\n**Chance to Win** is straight forward. It is simply the probability that a variation is better. You typically want to wait until this reaches 95% (or 5% if it's worse).\n\n**Relative Uplift** is similar to a frequentist Confidence Interval. Instead of showing a fixed 95% interval, we show the full probability distribution using a violin plot:\n\n![Violin plot of a metrics change](data:image/png;base64,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)\n\nWe have found this tends to lead to more accurate interpretations. For example, instead of just reading the above as _\"it’s 17% better\"_, people tend to factor in the error bars (_\"it’s about 17% better, but there’s a lot of uncertainty still\"_).\n\n**Risk** (or expected loss) can be interpreted as _“If I stop the test now and choose X and it’s actually worse, how much am I expected to lose?”_. This is shown as a relative percent change - so if your baseline metric value is $5/user, a 10% risk equates to losing $0.50/user. You can specify your risk tolerance thresholds on a per-metric basis within GrowthBook.\n\nGrowthBook gives the human decision maker everything they need to weigh the results against external factors to determine when to stop an experiment and which variation to declare the winner.\n\n## Frequentist Statistics[​](#frequentist-statistics \"Direct link to Frequentist Statistics\")\n\nFrequentist statistics are are familiar to many practitioners, power much of our statistics engine, and have certain advantages. Their widespread adoption has spurred important developments in variance reduction, heterogeneous treatment effect detection, and indeed corrections to peeking issues (e.g. sequential testing) that make frequentist statistics less problematic and, at times, more valuable.\n\nThe current frequentist engine computes two-sample t-tests for relative percent change; you can reduce variance (via [CUPED](https://docs.growthbook.io/statistics/cuped)) and you can enable [sequential testing](https://docs.growthbook.io/statistics/sequential) to mitigate concerns with peeking.\n\nYou can read more in our [detailed documentation](https://docs.growthbook.io/statistics/details).\n\n## Data Quality Checks[​](#data-quality-checks \"Direct link to Data Quality Checks\")\n\nIn addition, GrowthBook performs automatic data quality checks to ensure the statistical inferences are valid and ready for interpretation. We currently run a number of checks and plan to add even more in the future.\n\n1.  **Sample Ratio Mismatch** (SRM) detects when the traffic split doesn't match what you are expecting (e.g. a 48/52 split when you expect it to be 50/50)\n2.  **Multiple Exposures** which alerts you if too many users were exposed to multiple variations of a single experiment (e.g. someone saw both A and B)\n3.  **Guardrail Metrics** help ensure an experiment isn't inadvertently hurting core metrics like error rate or page load time\n4.  **Minimum Data Thresholds** so you aren't drawing conclusions too early (e.g. when it's 5 vs 2 conversions)\n5.  **Variation Id Mismatch** which can detect missing or improperly-tagged rows in your data warehouse\n6.  **Suspicious Uplift Detection** which alerts you when a metric changes by too much in a single experiment, indicating a likely bug\n\nMany of these checks are customizeable at a per-metric level. So you can, for example, have stricter quality checks for revenue than you have for less important metrics.\n\n## Dimensional Analysis[​](#dimensional-analysis \"Direct link to Dimensional Analysis\")\n\nThere is often a desire to drill down into results to see how segments or dimensions of your users were affected by an A/B test variation. This is especially useful for finding bugs (e.g. if Safari is down, but the other browsers are up) and for identifying ideas for follow-up experiments (e.g. \"European countries seem to be responding really well to this test, let's try a dedicated variation for them\").\n\nHowever, too much slicing and dicing of data can lead to what is known as the Multiple Testing Problem. If you look at the data in enough ways, one of them will look significant just by random chance.\n\nGrowthBook only provides multiple testing corrections for the frequentist engine, but we have a few guardrails at the metric level to ensure that results are only shown when there's at least enough data to reliably learn about a specific dimension.\n\nIn addition, we apply automatic grouping to very high-cardinality dimensions. In the country example, only the top 20 countries will be shown individually. The rest will be lumped together into an `(other)` category.\n\nWe have found this to be a good trade-off between false positives and false negatives.\n\n## Conclusion[​](#conclusion \"Direct link to Conclusion\")\n\nGrowthBook utilizes a combination of Bayesian and frequentist statistics, fast estimation techniques, and data quality checks to robustly analyze A/B tests at scale and provide intuitive results to decision makers. The implementation is fully open source under an MIT license and available on GitHub.",
  "title": "GrowthBook Statistics | GrowthBook Docs",
  "description": "GrowthBook Statistics",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/features/targeting",
  "markdown": "# Feature Flag Targeting | GrowthBook Docs\n\nGrowthBook lets you target a specific feature value or experiment to a subset of your users. This is accomplished with **Attributes**, **Conditions**, **Saved Groups**, and **Prerequisites**.\n\n## Attributes[​](#attributes \"Direct link to Attributes\")\n\nIn order for targeting to work, you must pass attributes into the GrowthBook SDK and also list them in the GrowthBook App.\n\nAttributes are passed into your SDKs as key-value pairs. The keys you use are completely custom and there are no requirements or restrictions. Use whatever makes sense for your application.\n\nHere's an example from our JavaScript SDK:\n\n```\ngrowthbook.setAttributes({  id: \"123\",  email: \"hello@growthbook.io\",  country: \"US\",  url: window.location.href,  userAgent: navigator.userAgent,  admin: true,  age: 50,});\n```\n\nIn addition to passing attributes into the SDK, you also must update the GrowthBook App with these same attribute keys. You can do this under **SDK Connections** → **Attributes**:\n\n![List of targeting attributes](https://docs.growthbook.io/assets/images/edit-targeting-attributes-47e2000d60f8e83e2fcc4a5fafc0236f.png)\n\nnote\n\nThe actual values of the targeting attributes (e.g. the user ids, emails, etc.) are never sent to GrowthBook. They are only stored in memory locally within the SDK. This architecture eliminates huge potential security holes and keeps your user's PII safe and secure.\n\nEach attribute has 4 parts:\n\n*   The **attribute name** itself. This is how the attribute will be referenced in the SDK.\n*   The **data type** of the attribute\n*   Whether it's an **identifier**. Identifiers are attributes which uniquely identify something - typically either a person, account, company, or device- and are used for experiment assignments.\n*   The **projects** that the attribute is associated with. This is useful if some attributes are only relevant to certain projects. If no projects are selected, the attribute will be available for all projects.\n\n### Attribute Data Types[​](#attribute-data-types \"Direct link to Attribute Data Types\")\n\nGrowthBook supports the following attribute data types:\n\n*   Boolean - true or false\n*   Number - Floats or integers\n*   String - freeform text\n*   Enum - When there are only a small list of pre-defined values it could take\n*   Secure String - Like a string, but the values will be hashed before passing to the SDK\n*   Array of Strings - useful for things like \"tags\"\n*   Array of Numbers - useful anytime you have multiple numeric values\n*   Array of Secure Strings - an array of secure strings useful for passing multiple values that you want to keep secure\n\n#### Semantic Version Targeting[​](#semantic-version-targeting \"Direct link to Semantic Version Targeting\")\n\nIn version 2.2, we introduced support for semantic version string comparisons. Without this, the string `1.0.9` will be seen as \"greater\" than `1.0.10`.\n\nTo leverage this feature, you first need to create a version string attribute. Navigate to **SDK Configurations → Attributes** and create or edit a String attribute. In the format dropdown, select: **Version string.**\n\n![Version string attribute](https://docs.growthbook.io/assets/images/targeting-semantic-versions-6b2b834c4e5b39d79b78fea4dff27686.png)\n\nAfter saving, the targeting operators (e.g. `is greater than`) will automatically start using a version-safe comparison function.\n\nnote\n\nThis is only supported in some of our SDKs. Check the release notes for the specific SDK you are using to make sure you have a compatible version installed.\n\n## Targeting Conditions[​](#targeting-conditions \"Direct link to Targeting Conditions\")\n\nGrowthBook provides a nice UI for defining simple targeting conditions using your attributes.\n\n![Simple targeting conditions](https://docs.growthbook.io/assets/images/targeting-simple-f5410567050c007d1838f8522d3e120c.png)\n\n### Advanced Mode[​](#advanced-mode \"Direct link to Advanced Mode\")\n\nIf you need support for something more advanced you can enter targeting conditions with JSON instead by clicking the \"Advanced Mode\" link.\n\nThe JSON structure is inspired by the MongoDB Query syntax. Multiple conditions are always joined with `AND` (except when explicitly using `$or`/`$nor`). Below are all of the supported operators with examples.\n\n*   Key/value pairs for simple equality\n    \n    ```\n    {  \"attribute1\": \"value1\",  \"attribute2\": 123,  \"attribute3\": false}\n    ```\n    \n*   Basic comparison operators for string/number attributes\n    \n    *   `$eq` (equals)\n    *   `$ne` (not equals)\n    *   `$lt` (less than)\n    *   `$lte` (less than or equal to)\n    *   `$gt` (greater than)\n    *   `$gte` (greater than or equal to)\n    *   `$regex` (regular expression match, string attributes only)\n    *   `$in` (in array)\n    *   `$nin` (not in array)\n    \n    ```\n    {  \"foo\": {    \"$gt\": 10,    \"$lte\": 99  },  \"bar\": {    \"$in\": [\"a\",\"b\",\"c\"]  },  \"baz\": {    \"$regex\": \"^test-([0-9]+)$\"  }}\n    ```\n    \n*   Comparison operators for semantic version strings (semver):\n    \n    *   `$veq` (equals)\n    *   `$vne` (not equals)\n    *   `$vlt` (less than)\n    *   `$vlte` (less than or equal to)\n    *   `$vgt` (greater than)\n    *   `$vgte` (greater than or equal to)\n    \n    ```\n    {  \"appVersion\": {    \"$vgt\": \"1.5.6\",    \"$vlte\": \"5.4.0\"  }}\n    ```\n    \n*   Operators for array attributes\n    \n    *   `$elemMatch` (at least one element must match the specified condition)\n    *   `$all` (all of the specified values must exist in the array)\n    *   `$size` (array length must match the specified condition)\n    \n    ```\n    {  \"emails\": {    \"$elemMatch\": {      \"$regex\": \"@gmail.com$\"    }  },  \"hobies\": {    \"$all\": [\"hiking\",\"tennis\",\"chess\"]  },  \"tags\": {    \"$size\": {      \"$gt\": 5    }  }}\n    ```\n    \n*   Misc operators\n    \n    *   `$exists` (tests if the attribute value is null or not)\n    *   `$type` (tests if the attribute's type matches the type specified)\n    *   `$not` (inverts a nested condition)\n    \n    ```\n    {  \"alternateEmail\": {    \"$exists\": true  },  \"foo\": {    \"$type\": \"string\"  },  \"name\": {    \"$not\": {      \"$regex\": \"^J\"    }  }}\n    ```\n    \n*   Logical operators with arbitrary nesting levels\n    \n    *   `$or`\n    *   `$nor`\n    *   `$and`\n    *   `$not`\n    \n    ```\n    {  \"$or\": [    {      \"$not\": {        \"foo\": \"abc\"      }    },    {      \"$and\": [        {\"bar\": true},        {\"baz\": 123}      ]    }  ]}\n    ```\n    \n\nnote\n\nWe use the MongoDB query syntax because it is easy to read and write and is well documented. The conditions are never actually executed against a database. Instead, our SDKs include a light-weight interpreter for this syntax that runs entirely locally.\n\n## Saved Groups[​](#saved-groups \"Direct link to Saved Groups\")\n\nIn addition to targeting by attributes, GrowthBook has also the concept of **Saved Groups**, which makes it easy to target the same group of users across multiple features/experiments.\n\nOnce you define your Saved Groups, you can easily reference them from any Feature rule or Experiment. Updates to saved groups apply immediately and will be instantly propagated to all matching Features and Experiments.\n\n![Saved Group Targeting](https://docs.growthbook.io/assets/images/saved-groups-targeting-6dd14aaec48817bef6fed2cb50df0562.png)\n\nThere are two types of Saved Groups:\n\n*   **ID Lists** - Pick an attribute and define a list of values directly within the GrowthBook UI. For example, you can make an `Admin` group and add the `userId` of all of your admins.\n*   **Condition Groups** - Configure advanced targeting rules based on a user's attributes. For example, \"all users located in the US on a mobile device\".\n\nnote\n\nID Lists are currently limited to a maximum of **100 values**. These values are included directly in the payload sent to your SDKs and large payloads can slow down your application. Support for largers lists is coming soon!\n\n![Saved Groups UI](https://docs.growthbook.io/assets/images/saved-groups-5051a7b6ca99b952e0bfc3c18e957434.png)\n\nnote\n\nGrowthBook 2.7 introduced a naming change. \"Inline Groups\" were renamed to \"ID Lists\". \"Runtime Groups\" were renamed to \"Condition Groups\" and now support arbitrary targeting conditions.\n\nOnly ID Lists can be referenced in the **Target by Attribute** field. Both types of Saved Groups can be referenced with the newer **Saved Group Targeting** field.\n\n## Prerequisite Targeting[​](#prerequisite-targeting \"Direct link to Prerequisite Targeting\")\n\nYou can add prerequisite targeting to any feature or experiment. For more information, see the [Prerequisite Features](https://docs.growthbook.io/features/prerequisites#inline-prerequisite-targeting) page.",
  "title": "Feature Flag Targeting | GrowthBook Docs",
  "description": "Learn about how to target with GrowthBook",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/app/dimensions",
  "markdown": "# Dimensions | GrowthBook Docs\n\nDimensions let you drill down into experiment results. For example, if you define a `browser` dimension, you can see how Safari users behaved vs Chrome.\n\nBe careful, the more dimensions and metrics you look at for an experiment, the more likely you are to see false positives - something that looks significant when it really isn't. For example, if you break out results by country, it's pretty likely that at least one of the 100+ countries in your dataset will be significantly different just by random chance.\n\nIt's best to treat dimensions as an exploratory tool and not something to directly draw conclusions from. The two best use cases are identfying bugs (the `browser` example) and getting ideas for dedicated follow-up experiments.\n\nDimensions are supported for both Mixpanel and SQL data sources.\n\n## SQL[​](#sql \"Direct link to SQL\")\n\nThere are two types of dimensions for SQL data sources: Experiment Dimensions and User Dimensions. Experiment dimensions are more reliable for producing unbiased experiment analyses because we can always know the dimension that is associated with the first experiment exposure for a unit. Using dimension data that could be affected by the experiment (e.g. that is collected _after_ the first experiment exposure) could bias dimension drill-downs. Therefore, use user dimensions with caution, and we suggest using immutable dimensions as your user dimensions (e.g. the first client the user ever used, or the first country the user ever logged in from).\n\nFor all experiment analyses, we only ever choose one dimension per user, to avoid the aforementioned issues with potential bias. For Experiment Dimensions, we select the dimension associated with the user's first exposure event for the experiment. For User Dimensions, we strongly suggest only having one dimension value per user, as we cannot discern what dimension a user had before the experiment. Instead, we simply choose the `MAX(value)` for the user dimension.\n\n### Experiment Dimensions[​](#experiment-dimensions \"Direct link to Experiment Dimensions\")\n\nThese are attributes that are specific to the point-in-time that a user was put into an experiment. For example, `browser` or `referrer`.\n\nInstead of a standalone SQL query, experiment dimensions are simply extra columns you return from the Experiment assignment query defined for your data source.\n\nAs an example, if you set the following as your experiment assignment query:\n\n```\nSELECT  user_id,  received_at as timestamp,  experiment_id,  variation_id,  browserFROM  experiment_viewed\n```\n\nThe first 4 columns are standard, but `browser` is a custom one that can be used as an Experiment Dimension.\n\n#### Configuring Experiment Dimensions[​](#configuring-experiment-dimensions \"Direct link to Configuring Experiment Dimensions\")\n\nTo power the health tab and future automatic dimension results analysis (coming in 2024), you need to configure your Experiment Dimensions. You can do this by clicking the \"Configure Dimensions\" button in the kebab menu next to the exposure query where the Experiment Dimensions are defined:\n\n![Configure Dimensions Option](https://docs.growthbook.io/images/configure-dimensions.png)\n\nIn the modal that pops up, you can run a query to find the top 20 dimension slices for your Experiment Dimensions and save them for use on the health tab.\n\nIf you want to have more control over the pre-defined slices, the best way to do so is to modify the Exposure Query SQL to include a `CASE` statement that defines the dimension slices. For example, if you wanted to have a `browser` dimension with slices for `Chrome`, `Safari`, and `Other`, you could do something like this:\n\n```\nSELECT  user_id,  received_at as timestamp,  experiment_id,  variation_id,  CASE    WHEN browser LIKE '%Chrome%' THEN 'Chrome'    WHEN browser LIKE '%Safari%' THEN 'Safari'    ELSE 'Other'  END as browserFROM  experiment_viewed\n```\n\n### User Dimensions[​](#user-dimensions \"Direct link to User Dimensions\")\n\nThese are attributes of your users that are relatively stable over time, and ideally, do not change over the course of an experiment. For example, `cohort`, `initial age group`, or `first client used`.\n\nA user dimension is defined by a simple SQL query that returns two columns: an identifier and `value`. The name of the identifier column depends on which identifier type the dimension is using. Remember, when using these for analysis, we will pick the `MAX(value)` for each user, and therefore it is best to only have one value per user.\n\nHere's an example SQL:\n\n```\n-- Assumes identifier type is \"user_id\"SELECT  user_id,  plan_type as valueFROM  subscriptions\n```\n\nIt's best to keep the number of unique values for a dimension small if possible to avoid the False Positive issues discussed above. We automatically cap the number at 20, but you can do it yourself if you want more control. Here's an example for a \"country\" dimension:\n\n```\nSELECT  user_id,  (    CASE WHEN country = 'us' THEN 'US'    WHEN country = 'uk' THEN 'UK'    ELSE 'Other' END  ) as valueFROM  users\n```\n\ntip\n\nYou can use SQL template variables in dimension queries just like you can with metrics (excluding metric specific template variables like `eventName` and `valueColumn`). See the [SQL Template Variables](https://docs.growthbook.io/app/metrics#sql-templates) page for more details.\n\n## Mixpanel[​](#mixpanel \"Direct link to Mixpanel\")\n\nFor mixpanel, there is just a single type of dimension that is based on event properties (at this time Mixpanel user properties are not supported).\n\nFor simple dimensions, you can just put the event property name directly. For example: `$browser`.\n\nWe also support complex javascript expressions. For example:\n\n```\nevent.properties.$browser.match(/chrome/i) ? \"Chrome\" : \"Other\"\n```\n\nFor more complex expressions, you can wrap your code in an anonymous function:\n\n```\n(() => {  // ...some complex logic  return dimensionValue})()\n```\n\nYou can also reference the experiment start/end date in your javascript expression. For example, if you add a super event called `userRegistrationDate` that stores a unix timestamp, you could make a `New vs Existing` dimension like this:\n\n```\nevent.properties.userRegistrationDate >= {{ startDateUnix }} ? \"new\" : \"existing\"\n```\n\nThe variables you can reference are:\n\n*   **startDate** - `YYYY-MM-DD HH:mm:ss` of the earliest data that needs to be included\n*   **startYear** - Just the `YYYY` of the startDate\n*   **startMonth** - Just the `MM` of the startDate\n*   **startDay** - Just the `DD` of the startDate\n*   **startDateUnix** - Unix timestamp of the startDate (seconds since Jan 1, 1970)\n*   **endDate** - `YYYY-MM-DD HH:mm:ss` of the latest data that needs to be included\n*   **endYear** - Just the `YYYY` of the endDate\n*   **endMonth** - Just the `MM` of the endDate\n*   **endDay** - Just the `DD` of the endDate\n*   **endDateUnix** - Unix timestamp of the endDate (seconds since Jan 1, 1970)\n*   **experimentId** - Either a specific experiment id OR `%` if you should include all experiments",
  "title": "Dimensions | GrowthBook Docs",
  "description": "Drill down into experiment results",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/features/rules",
  "markdown": "# Feature Flag Override Rules | GrowthBook Docs\n\n## Rules (Force, Rollout, Experimentation)\n\nEvery feature has a default value that is served to all users. The real power comes when you define **override rules** that let you run experiments and/or change the value for specific users.\n\n![Feature override rules UI](https://docs.growthbook.io/images/features/feature-override-rules.png)\n\nOverride rules are defined separately for each environment (e.g. dev and production). This way you can, for example, test an experiment rule in dev first before deploying it to production.\n\nThe first matching rule for a user will be applied, so order matters. If there are no matching rules, the default value will be used.\n\n## Targeting Conditions[​](#targeting-conditions \"Direct link to Targeting Conditions\")\n\nAny rule can specify conditions to limit which users the rule applies to. These conditions are evaluated against the attributes passed into the SDK.\n\nLearn more about [targeting here](https://docs.growthbook.io/features/targeting).\n\n![Rule conditions UI](https://docs.growthbook.io/assets/images/rule-conditions-08cff979d8c5b2b4534d1c73bb137cf7.png)\n\n## Forced Value[​](#forced-value \"Direct link to Forced Value\")\n\nThe simplest type of override rule is a \"Forced Value\" rule. This forces everyone who matches the targeting condition to get a specific value. For example, you could have a feature default to OFF and use force rules to turn it ON for a specific list of countries.\n\n![Force rule UI](https://docs.growthbook.io/images/features/feature-force-rule.png)\n\n## Percentage Rollout[​](#percentage-rollout \"Direct link to Percentage Rollout\")\n\nPercentage Rollout rules let you gradually release a feature value to a random sample of your users.\n\n![Rollout rule UI](https://docs.growthbook.io/images/features/feature-rollout-rule.png)\n\nRollouts are most useful when you want to make sure a new feature doesn't break your app or site. You start by releasing to maybe 10% of users. Then after a while if your metrics look ok, you increase to 30% and so on.\n\nFor rollout rules, you choose a user attribute to use for the random sample. Users with the same attribute value will be treated the same (either included or not included in the rollout). For example, if you choose a \"company\" attribute, then multiple employees in the same company will get the same experience.\n\nnote\n\nPercentage Rollouts do not fire any tracking calls so there's no way to precisely correlate the rollout to changes in your application's metrics. If this is a concern, we recommend Experiment rules (below) instead.\n\n## Experiments[​](#experiments \"Direct link to Experiments\")\n\nThe last type of rule is an Experiment. This randomly splits users into buckets, assigns them different values, and tracks that assignment in your data warehouse or analytics tool.\n\nExperiments are most useful when you aren't sure which value to assign yet.\n\nHere's what an Experiment rule looks like in the GrowthBook UI:\n\n![Experiment rule UI](https://docs.growthbook.io/images/features/feature-experiment-rules.png)\n\nIn the vast majority of cases, you want to split traffic based on either a logged-in user id or some sort of anonymous identifier like a device id or session cookie. As long as the user has the same value for this attribute, they will always get assigned the same variation. In rare cases, you may want to use an attribute such as company or account instead, which ensures all users in a company will see the same thing.\n\nYou can control both the percent of users included and the traffic split between the variations. For example, if you include 50% of users and do a 40/60 split, then 20% will see the first variation, 30% will see the 2nd variation, and the remaining 50% will skip the rule entirely and move onto the next rule (or the default value if there are no more matching rules).\n\nWhen a user is placed in an experiment via the experiment override rule, the SDK will track the experiment assignment in your data warehouse or analytics tool, via the `trackingCallback` method.\n\nYou can analyze the result of a Feature Experiment rule the same way you would any experiment in GrowthBook.\n\n### Namespaces[​](#namespaces \"Direct link to Namespaces\")\n\nIf you have multiple experiments that may conflict with each other (e.g. background color and text color), you can use **namespaces** to make the conflicting experiments mutually exclusive.\n\nUsers are randomly assigned a value from 0 to 1 for each namespace. Each experiment in a namespace has a range of values that it includes. Users are only part of an experiment if their value falls within the experiment's range. So as long as two experiment ranges do not overlap, users will only ever be in at most one of them.\n\n![Namespaces](https://docs.growthbook.io/assets/images/namespaces-373302a7546bd8f44fb1f75fbbee67cb.png)\n\nIn order to use namespaces, simply create a new namespace or modify an existing one in _SDK Configuration → Namespaces_ in the GrowthBook UI's left navigation bar.\n\n## Testing Rules[​](#testing-rules \"Direct link to Testing Rules\")\n\nYou can test your rules in the GrowthBook UI by clicking on the \"Test Feature Rules\" under the rules. This will open a form that will allow you to adjust user attributes and see in real time how the rules will be applied, and what value they'll get. User attributes can also added as JSON objects, by clicking on the JSON tab. You can also expand the results to see more debug information about why each rule was or wasn't applied.\n\n![Test Feature Rules](https://docs.growthbook.io/assets/images/feature-test-rules-7c293b8137a369e7ba50a041e79bd896.gif)\n\n### Archetype[​](#archetype \"Direct link to Archetype\")\n\nArchetypes are a way you can save preset user attributes to see how your if the rules will apply to them. This is useful if you have specific sets of users who you frequently want to target features to. They are automatically shown along with the feature values at the top of the test rules form. Mouse over any value to see more debug information about why that value was returned. Archetypes are part of the GrowthBook Enterprise plan.\n\n![Archetypes](https://docs.growthbook.io/assets/images/feature-archetypes-381713763a216429089bb94e6012d279.png)\n\nFrom the testing form, you can click on the _Save Archetype_ button to open the _Create Archetype_ modal to create new archetypes.",
  "title": "Feature Flag Override Rules | GrowthBook Docs",
  "description": "Learn about feature flag override rules",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/feature-flag-experiments",
  "markdown": "# Feature Flag Experiments | GrowthBook Docs\n\nGrowthBook allows you to run experiments using feature flags. This method of running experiments allows any feature to be released as an A/B test. It is ideal for more complex experiments requiring multiple code changes, or for companies that want to have an experimentation development culture, and determining the impact on your metrics of any feature or code change.\n\n## Running Experiments with Feature Flags[​](#running-experiments-with-feature-flags \"Direct link to Running Experiments with Feature Flags\")\n\nFeature flag experiments are created with an experiment override rule. This experiment rule will randomly assign variations to your users based on the configurations you select. When a user is placed in an experiment via an experiment override rule, the assignment will be tracked in your data warehouse using the `trackingCallback` defined in the SDK implementation.\n\nHere's what an Experiment rule looks like in the GrowthBook UI:\n\n![Experiment rule UI](https://docs.growthbook.io/images/features/feature-experiment-rules.png)\n\nThis modal window allows for a great deal of flexibility and customization in how you run your experiments. Let's go through each of the options:\n\n### Experiment Targeting Conditions[​](#experiment-targeting-conditions \"Direct link to Experiment Targeting Conditions\")\n\nExperiment rules can be targeted at specific user or client attributes. Only users who match the targeting condition will be included in experiment. You can add multiple targeting conditions per rule, and you can add multiple rules per feature, this gives you great flexibility in targeting and customizing your experiment to specific audiences. You can read more about [targeting](https://docs.growthbook.io/features/targeting). By default, all users will be included.\n\n### Tracking Key[​](#tracking-key \"Direct link to Tracking Key\")\n\nThe tracking key used to identify this experiment in the SDK. It is used, along with the user hashing attribute in the persistent hashing algorithm to ensure the users always get randomized into the same treatment group. It is also what is passed to the tracking callback to be tracked in your data warehouse. By default, the tracking key is the same as the feature name, but can be any string. If you change the experiment tracking key users will re-bucketed. The tracking key can be set to the same values in different features or experiment rules to allow for one experiment to have multiple features.\n\n### Assign Variations Based on Attribute[​](#assign-variations-based-on-attribute \"Direct link to Assign Variations Based on Attribute\")\n\nThe value you select here will be hashed along with tracking key to determine which variation the user will be assigned. Only attributes marked as **identifiers** can be used here. In the vast majority of cases, you want to split traffic based on either a logged-in user id or some sort of anonymous identifier like a device id or session cookie. As long as the user has the same value for this attribute, they will always get assigned the same variation.\n\nThe values available here are defined in the GrowthBook UI under the _SDK Configuration → Attributes_ section. Like all attributes in GrowthBook, the users value for this attribute must be defined in the SDK implementation. You can read more about targeting attributes [here](https://docs.growthbook.io/features/targeting).\n\n### Exposure, Variations, and Weights[​](#exposure-variations-and-weights \"Direct link to Exposure, Variations, and Weights\")\n\nHere you can choose the overall traffic you want to see the experiment as well as any custom split percentages. If you assign to less than 100% of the users, the remaining users will skip the rule and fall through to the next matching one (or the default value) instead.\n\nYou may want to run an experiment at a split percentages that weights the control group in order to de-risk the new feature (say 90% control, 10% new treatment). It is best practice in such cases to keep the splits the same, and adjust the overall exposure (ie, 20% overall exposure, 50/50 split for the variations).\n\nMultiple variations can be added to an experiment from this section as well, as long as the feature is not a boolean.\n\nThe bar at the bottom shows the traffic allocation for this experiment.\n\nEach user will have the **tracking key** and **hashing attribute** hashed together to determine which variation they will be assigned. The algorithm is deterministic, and always returns the same value (a number from 0 to 1) as long as the inputs are the same. Changing the split percentages mid-experiment risks having a user switch variations, and could cause multiple exposure warnings. Changing the overall exposure percentage is completely safe.\n\n### Namespaces[​](#namespaces \"Direct link to Namespaces\")\n\nIf you have multiple experiments that may conflict with each other (e.g. background color and text color), you can use **namespaces** to make the conflicting experiments mutually exclusive.\n\nUsers are randomly assigned a value from 0 to 1 for each namespace. Each experiment in a namespace has a range of values that it includes. Users are only part of an experiment if their value falls within the experiment's range. So as long as two experiment ranges do not overlap, users will only ever be in at most one of them.\n\n![Namespaces](https://docs.growthbook.io/assets/images/namespaces-373302a7546bd8f44fb1f75fbbee67cb.png)\n\nBefore you can use namespaces, you must configure them under _SDK Configuration → Namespaces_.\n\n## Experiment Results[​](#experiment-results \"Direct link to Experiment Results\")\n\nOnce you have the experiment rule saved and published the feature will start to apply these settings and randomize your users into the experiment. The results will flow into your data warehouse, as defined by your `trackingCallback`. There is a link to view experiment results on the bottom of each experiment override rule. Read more about [experiment results](https://docs.growthbook.io/app/experiment-results).",
  "title": "Feature Flag Experiments | GrowthBook Docs",
  "description": "Run experiments using feature flags",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/features/prerequisites",
  "markdown": "# Prerequisite Features | GrowthBook Docs\n\nPrerequisite features allow you to control the state of other features, rules, and experiments based on the state of a prerequisite feature.\n\nSome common use cases include:\n\n*   Grouping multiple related features under a single release feature (ex: `release-2.8`) and toggling them all at once\n*   Creating a hierarchy of features which depend on each other and safely enabling them in the correct order, per environment\n*   Only enabling a set of features if the user was bucketed into \"variant 1\" of an experiment\n\nThere are two types of prerequisite features in GrowthBook: **Top-level Prerequisites** (feature gating) and **Inline Prerequisite Targeting** (rule-level and experiment-level gating).\n\n## Top-Level Prerequisites[​](#top-level-prerequisites \"Direct link to Top-Level Prerequisites\")\n\nTop-level prerequisites are defined per dependent feature. They function similarly to a feature's kill switches: if the prerequisite feature is not serving `true` then the dependent feature will not be enabled.\n\nnote\n\n**Top-level Prerequisites** is a GrowthBook Pro and Enterprise feature.\n\n![Top-level prerequisites](https://docs.growthbook.io/images/features/feature-top-level-prerequisites.png)\n\nAdd one or more top-level prerequisites by clicking the \"Add Prerequisite Feature\" button on the feature page and then selecting the feature you want to use as a prerequisite.\n\nIn order for a feature to be eligible to be a top-level prerequisite, it must be a boolean (true/false). Also, it must be in the same project as the dependent feature.\n\n### Prerequisite states and values[​](#prerequisite-states-and-values \"Direct link to Prerequisite states and values\")\n\nA summary of the prerequisite state and value will show while adding or editing a prerequisite, as well as on the dependent feature page.\n\n*   **Deterministic** states (**live** and **not live**) are applied to your features within GrowthBook.\n    *   **Live** prerequisites which are serving `true` will allow their dependent features to be enabled\n    *   **Live** prerequisites which are serving `false` will still block their dependent features (`false` ≠ `true`)\n    *   **Not live** prerequisites will always block their dependent features (they evaluate to `null`, and `null` ≠ `true`)\n\ninfo\n\nPrerequisites with deterministic states work \"out of the box\" regardless of SDK version support.\n\nAny feature that is always \"not live\" will not be seen by the SDK. Any feature that is always \"live\" will no longer reference its prerequisites in the SDK. This means that no SDK-level evaluation of prerequisites is needed (these prerequisites work irrespective of SDK version support).\n\n*   **Schrödinger** state means that the prerequisite's state cannot be determined in advance. It may depend on user attributes or other non-deterministic factors. (This is homage to the physicist Erwin Schrödinger who proposed a thought experiment involving a cat in a box that is both alive and dead at the same time.)\n\ninfo\n\nPrerequisites with a Schrödinger state must be evaluated at runtime in the SDK. Prerequisite evaluation is currently supported in the following SDK versions:\n\n*   JavaScript: `0.34.0+`\n*   React: `0.24.0+`\n\n## Inline Prerequisite Targeting[​](#inline-prerequisite-targeting \"Direct link to Inline Prerequisite Targeting\")\n\nInline prerequisite targeting allows finer-grained control over prerequisite behavior than top-level prerequisites.\n\n1.  Inline prerequisites can be applied at a feature's [override rule](https://docs.growthbook.io/features/rules) level, and can be environment-specific. This comes with the added benefits of feature draft releases and approvals.\n2.  Inline prerequisites can be applied to individual experiments which may not be linked to a specific feature (such as visual experiments).\n3.  Inline prerequisite targeting is not limited to boolean features. You can specify any evaluation condition you'd like (ex: prerequisite value is: greater than 3, in a list of allowed values, or matches a regex pattern). You can even do advanced targeting with JSON.\n\nnote\n\n**Inline Prerequisite Targeting** is a GrowthBook Enterprise feature only.\n\nTo create an inline prerequisite within a feature, simply add prerequisiting targeting to an existing override rule or create a new rule with prerequisite targeting. You can specify one or more prerequisite features within the same project and give each a custom evaluation condition. A similar flow exists while editing the targeting rules of an experiment.\n\n![Inline prerequisite targeting](https://docs.growthbook.io/images/features/feature-inline-prerequisite-targeting.png)\n\n### Inline prerequisite states and values[​](#inline-prerequisite-states-and-values \"Direct link to Inline prerequisite states and values\")\n\nThe same **deterministic** and **Schrödinger** states apply to inline prerequisites as they do to top-level prerequisites ([see above](#prerequisite-states-and-values)). Below is a summary of how they apply to inline prerequisites:\n\n*   **Deterministic** states (**live** and **not live**) are calculated using your evaluation condition, which is **_not_** limited to `is true`. As before, no run-time evaluation of prerequisites is required in the SDK.\n    \n    *   **Live** prerequisites which pass the evaluation condition will allow their dependent rules or experiments to be enabled.\n    *   **Live** prerequisites which fail the evaluation condition will still block their dependent rules or experiments.\n    *   **Not live** prerequisites will generally block the dependent rule or experiment, unless the evaluation condition specifically checks for this (e.g. `is not live`)\n*   **Schrödinger** state prerequisites must be evaluated at runtime in the SDK, and thus a compatible SDK version is required.\n    \n\n## Limitations[​](#limitations \"Direct link to Limitations\")\n\nThere are a few limitations and guardrails within GrowthBook when configuring prerequisites:\n\n1.  Prerequisite features must be in the same project as the dependent feature or experiment.\n2.  You cannot select a prerequisite that would lead to a circular dependency.\n3.  If you don't have an SDK which supports prerequisite evaluation, then you cannot select a prerequisite that is in a Schrödinger state.\n4.  Once a feature has been used as a prerequisite for other features or experiments, you are blocked from deleting, archiving, or changing its projects. To perform these actions, you must first remove the feature from all dependent features and experiments. You can see a list of dependencies on the feature page:\n\n![Prerequisite dependents](https://docs.growthbook.io/images/features/feature-prerequisite-dependents.png)",
  "title": "Prerequisite Features | GrowthBook Docs",
  "description": "Gate features, rules, and experiments by a prerequisite feature",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/features/basics",
  "markdown": "# Feature Flag Basics | GrowthBook Docs\n\n## Basics of Feature Flags\n\n## Feature Keys[​](#feature-keys \"Direct link to Feature Keys\")\n\nEvery feature is defined by a unique **key**. This is what the engineering team will reference in their code when they check the value of a feature. Feature keys **cannot** be changed after they are created, so take care when choosing one. If you make a mistake, you can always delete the feature and create a new one.\n\n![Create Feature](https://docs.growthbook.io/images/features/feature-create-feature-1.png)\n\nFeature keys must only include letters, numbers, hyphens, and underscores.\n\nSome examples of good feature keys:\n\n*   `onboarding-checklist` - ON/OFF flag for a feature\n*   `checkout_button_color` - The color of the checkout button\n*   `resultsPerPage` - Number of search results to show per page\n\n## Default Values[​](#default-values \"Direct link to Default Values\")\n\nEach feature has a default value that is used when there are no matching rules for the user. A feature that is enabled on an environment, with no rules, will use the default value. The default values also depend on the feature type.\n\nUsing features in your code is easy. Here's an example from our Javascript SDK:\n\n```\n// For boolean featuresif (growthbook.isOn(\"my-feature\")) {  // ... Do something}// For number, string, and JSON featuresconst value = growthbook.getFeatureValue(\"other-feature\", \"fallback\");\n```\n\nGrowthBook also supports multiple environments, so you can, for example, have a feature enabled in **dev** but not **production**.\n\nYou can also change the value of a feature with **Override Rules**. The following types of rules are supported:\n\n## Override Rules[​](#override-rules \"Direct link to Override Rules\")\n\nDefault values are overridden by **override rules**. Override rules are used to target specific users or groups of users, or when launching A/B tests.\n\nThere are three kinds of rules we support:\n\n*   [**Forced Value**](https://docs.growthbook.io/features/rules#forced-value) - use targeting attributes to assign a subset of users the same value\n*   [**Percentage Rollout**](https://docs.growthbook.io/features/rules#percentage-rollout) - use random sampling to roll out a feature to a percent of users\n*   [**A/B Experiment**](https://docs.growthbook.io/features/rules#experiments) - run a randomized A/B test between 2 or more feature values\n\nFor more information, see our page on [override rules](https://docs.growthbook.io/features/rules).\n\n## Feature Types[​](#feature-types \"Direct link to Feature Types\")\n\nFeatures can be a simple ON/OFF flag or a more complex data type (strings, numbers or JSON) which can be used for remote configuration. The type of feature you select depends on your use case.\n\nGrowthBook supports 4 types of features:\n\n*   **Boolean (on/off)**\n*   **Number**\n*   **String**\n*   **JSON**\n\n### Boolean (ON/OFF) Flags[​](#boolean-onoff-flags \"Direct link to Boolean (ON/OFF) Flags\")\n\nON/OFF flags can support any of the following use cases:\n\n*   Decouple code deploys and releases\n*   Kill switch for production\n*   Gradual rollout of features\n*   Complex targeting and segmentation of features\n*   Validating feature releases with A/B tests\n\nBoolean feature flags may only have two values, on and off, so they are best used for simple use cases. Boolean feature flags are limited to 2 variations with A/B tests for this reason.\n\nFor example, if you have a checkout button that is currently blue, you could use an boolean flag called `new-button-color` that sets it to red when ON. This is pretty limiting since you can't easily try other colors in the future without changing the code. You may want to use one of the other feature types.\n\n### Number Flags[​](#number-flags \"Direct link to Number Flags\")\n\nSimilar to string flags, number flags support sending arbitrary numeric values to your application.\n\n### String Flags[​](#string-flags \"Direct link to String Flags\")\n\nString flag types support sending arbitrary string values to your application. This is useful for remote configuration, and also for multivariate A/B testing. For our previous example, you could use a string flag named `button-color` where you can easily set the value to 'blue', 'red', 'green', or any other color without changing your code.\n\n### JSON Flags[​](#json-flags \"Direct link to JSON Flags\")\n\nJSON flags support sending arbitrary JSON objects to your application. This is useful for remote configuration, and also when you want to send multiple values down to the SDK or code.\n\nJSON feature flags also support JSON validation, which allows you to validate the JSON object against a JSON schema. This feature is useful for validating the structure of the JSON object before sending it to your application to eliminate chances of typos. Currently, JSON validation is part of our enterprise plan.\n\n## Publishing Changes[​](#publishing-changes \"Direct link to Publishing Changes\")\n\nWhen you make changes to a feature's definition (default value or override rules), a new draft revision of the feature is created automatically. This draft revision is unpublished and is only visible within the GrowthBook UI, not to your users.\n\nYou can continue adding changes to this draft and when you are ready, publish them all at once with an optional commit message.\n\n![Draft Modal](https://docs.growthbook.io/assets/images/feature-publishing-8d4608d720dbe3e47d59e7524e76c42b.png)\n\n### Revisions[​](#revisions \"Direct link to Revisions\")\n\nOnce a draft revision has been published, it becomes locked and you can no longer make changes to it.\n\nIf you need to undo changes and revert back to a previous state, you can do so easily. Use the Revision dropdown to select the version you want to revert to and then click the Revert link. This will let you review the changes that will applied before submitting.\n\n![Feature Revisions](https://docs.growthbook.io/assets/images/revision-dropdown-3ac3d0324a26ba18a1ead20391849427.png)\n\n### Merge Conflicts[​](#merge-conflicts \"Direct link to Merge Conflicts\")\n\nIt's possible to get into a state where your draft has diverged from the live version of a feature. Some changes we are able to merge automatically (e.g. if you change a rule in \"dev\" and someone else changes a rule in \"production\"). For changes that we cannot resolve automatically, you will have to fix the conflicts first before you are able to publish your draft.\n\nWe use a similar process to Version Control Systems like git. For each conflict, you will be shown a diff of the conflict and given a choice of how to proceed.\n\nIn the example below, the Default Value was set to `foo` when you first created your draft. In your draft, you changed the value to `bar`. At the same time, someone else published a new version, changing the value to `hi!!`. So, now you have to choose which change you want to keep.\n\n![Resolve Conflicts](https://docs.growthbook.io/assets/images/resolve-conflicts-3de8879365103c0e01659d30210c7619.png)",
  "title": "Feature Flag Basics | GrowthBook Docs",
  "description": "Learn about the basics of feature flags.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/guide/GA4-google-analytics",
  "markdown": "# GrowthBook and Google Analytics GA4\n\n## A/B Testing with Google Analytics 4 (GA4) and GrowthBook\n\nThis guide walks you through using GrowthBook with Google Analytics 4 (GA4) for A/B testing. There are a few parts to this, connecting GA4 to BigQuery, connecting GrowthBook to BigQuery, and then configuring GrowthBook to track correctly with GA4.\n\ninfo\n\nYou can watch a video version of this guide, largely focused on Google Optimize replacement, here:\n\n## Configuring GrowthBook to use Google Analytics GA4 as a data source[​](#configuring-growthbook-to-use-google-analytics-ga4-as-a-data-source \"Direct link to Configuring GrowthBook to use Google Analytics GA4 as a data source\")\n\nGrowthBook connects to Google Analytics (GA4) via BigQuery. This process is straight forward, and outlined below. You can also find Google's documentation on how to create this link [here](https://support.google.com/analytics/answer/9823238).\n\n### 1\\. Create a BigQuery Project (if you don't have one)[​](#1-create-a-bigquery-project-if-you-dont-have-one \"Direct link to 1. Create a BigQuery Project (if you don't have one)\")\n\nIf you don't have a BigQuery project, you'll need to create one. Go to your [Google Cloud Console](https://console.cloud.google.com/) and create a new project:\n\n![GA4 - BigQuery create project](https://docs.growthbook.io/images/guides/GA4-1-project-list.png)\n\nClick on **_Create new project_** from the right and give your project a name.\n\n![GA4 - BigQuery create project](https://docs.growthbook.io/images/guides/GA4-2-create-project.png)\n\nOnce created, you'll be redirected to the BigQuery dashboard.\n\n![GA4 BigQuery new project dashboard](https://docs.growthbook.io/images/guides/GA4-3-new-project.png)\n\nIf you created a new project, the BigQuery API is automatically enabled. Otherwise, you'll need to enable it manually [here](https://console.cloud.google.com/flows/enableapi?apiid=bigquery)\n\nnote\n\nIf you are just testing GrowthBook with GA4 out, you can use the sandbox project that Google provides for free. When you create a new cloud project the sandbox should be automatically enabled. You can find more information about the sandbox [here](https://cloud.google.com/bigquery/docs/sandbox).\n\n### 2\\. Connect Google Analytics to BigQuery[​](#2-connect-google-analytics-to-bigquery \"Direct link to 2. Connect Google Analytics to BigQuery\")\n\nLog into your Google Analytics account and navigate to the Admin section. From there, make sure you have selected the right property, and scroll down to **_Product Links_** section. Click on the menu named **_BigQuery Links_**\n\n![GA4 BigQuery new project dashboard](https://docs.growthbook.io/images/guides/GA4-4-link-to-bigquery-1.png)\n\nClick on the **_Link_** button. This will open a menu that allows you select the project. Select on the **_Choose a BigQuery Project_** link.\n\n![GA4 BigQuery new project dashboard](https://docs.growthbook.io/images/guides/GA4-5-link-to-bigquery-2.png)\n\nSelect the project you wish to send your GA4 data to:\n\n![GA4 BigQuery connect to project](https://docs.growthbook.io/images/guides/GA4-5-link-to-bigquery-3.png)\n\nThen click **_next_**\n\n![GA4 BigQuery connected to project](https://docs.growthbook.io/images/guides/GA4-5-link-to-bigquery-4.png)\n\nOn the next step you'll be presented with some options about the connection.\n\n![GA4 BigQuery link options](https://docs.growthbook.io/images/guides/GA4-5-link-to-bigquery-5.png)\n\nHere you can choose the frequency of data updates, either daily or streaming. To use Streaming, you'll need a BigQuery account with billing info added. Depending on your use case, daily updates may be sufficient.\n\nOn the final step you'll be asked to confirm your choices. When finished, you should see something like this, verifying that the connection was successful.\n\n![GA4 BigQuery successfully connected](https://docs.growthbook.io/images/guides/GA4-5-link-to-bigquery-6.png)\n\nAnd then your BigQuery link will show up on the listing page:\n\n![GA4 BigQuery successfully connected](https://docs.growthbook.io/images/guides/GA4-5-link-to-bigquery-7.png)\n\nnote\n\nIf you are loading Google Analytics via Google Tag Manager (GTM), you may need to add the custom event to GTM to ensure the data is passed to GA4 from the datalayer. You can add the custom event by following this [section from the GTM guide](https://docs.growthbook.io/guide/google-tag-manager-and-growthbook#tracking-via-datalayer-and-gtm).\n\n### 3\\. Configure BigQuery for GrowthBook[​](#3-configure-bigquery-for-growthbook \"Direct link to 3. Configure BigQuery for GrowthBook\")\n\nYou'll need to give GrowthBook permissions to your BigQuery project so that we can access the data. We have created a guide just for this, which you can find [here](https://docs.growthbook.io/guide/bigquery)\n\n### 4\\. Connect GrowthBook to BigQuery[​](#4-connect-growthbook-to-bigquery \"Direct link to 4. Connect GrowthBook to BigQuery\")\n\nWithin GrowthBook, navigate to the **_Analysis_** section, and then click on the **_Data Sources_** page. Add a new data source, and select **_Google Analytics (GA4)_**.\n\n![GrowthBook connect to GA4](https://docs.growthbook.io/images/guides/GA4-6-add-GA4-datasource.png) ![GrowthBook connect to GA4](https://docs.growthbook.io/images/guides/GA4-6-add-GA4-datasource2.png)\n\nThen add your BigQuery connection info. GrowthBook will pre-populate the SQL queries required to use your GA4 data. You can also add a custom SQL query if you want to use a different table or filter the data in some way as you like.\n\nnote\n\nWhile GrowthBook will pre-populate the SQL queries for you, you may need to adjust the experiment query to match your data depending on the way you are tracking your experiments (see the **_trackingCallback_** below).\n\nOnce connected, you can add any additional metrics or dimensions, and then you can use your GA4 data for your experiments. You can use all your existing events and tracking- GrowthBook only requires one additional tracking call when a user is exposed to an experiment.\n\n## Running experiments with GrowthBook and GA4[​](#running-experiments-with-growthbook-and-ga4 \"Direct link to Running experiments with GrowthBook and GA4\")\n\nWith the data source connected, you can integrate the GrowthBook SDK into your application to run A/B tests. Once implemented, the SDK will do the random assignments and send the experiment exposure event to GA4 based on the settings in the GrowthBook UI.\n\ninfo\n\nWe do have a visual editor for creating experiments as part of our Pro plan. Our visual editor is meant for simple experiments. Experiments that are more complex are best created by writing code with feature flags.\n\n### SDK integration for GA4[​](#sdk-integration-for-ga4 \"Direct link to SDK integration for GA4\")\n\nThe easiest and recommended way to integrate GrowthBook is by using our [Script Tag SDK](https://docs.growthbook.io/lib/script-tag). This SDK will work out-of-the-box with GA4 without any configuration required.\n\nnote\n\nIf your experiment is not firing the `trackingCallback` you can use our [Chrome developer tool](https://chrome.google.com/webstore/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia) to help you debug and make sure the user attributes are being set correctly.\n\nImplementing the experiment variations can be done with code with inline experiments, using the feature flags, or by using our visual editor.",
  "title": "GrowthBook and Google Analytics GA4 | GrowthBook Docs",
  "description": "This guide walks you through using GrowthBook with Google Analytics 4 (GA4) to track your experiments and measure their impact on your business.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/app/visual",
  "markdown": "# Visual Editor | GrowthBook Docs\n\nWith the Visual Editor, users can design A/B tests on their site directly in their browser, run them in production, and analyze results, all without writing a single line of code. To use the Visual Editor, a software developer will need to integrate GrowthBook's [JavaScript](https://docs.growthbook.io/lib/js) SDK, [ReactJS](https://docs.growthbook.io/lib/react) SDK, or [HTML](https://docs.growthbook.io/lib/script-tag) SDK with your application.\n\nIn March 2023, we released version 2.0 of our Visual Editor, which had many improvements.\n\nnote\n\nThe Visual Editor may not work optimally on client-side rendered apps (e.g. React.js, Vue.js). Consider using [Feature Flags](https://docs.growthbook.io/app/features) instead for smoother integration. Contact [support@growthbook.io](mailto:support@growthbook.io) if you have any questions.\n\n## Requirements[​](#requirements \"Direct link to Requirements\")\n\nAll you need to get started is the [GrowthBook Chrome Extension](https://chrome.google.com/webstore/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia) installed on your Chrome Browser.\n\nThe application you want to experiment on **must be a front-end web application viewed in a browser**. Our Visual Editor does not work for mobile apps (Native or ReactNative) or desktop apps (e.g. Electron). For unsupported platforms, we recommend using [Feature Flags](https://docs.growthbook.io/app/features) instead to implement your changes in code.\n\nOnce you've create your first experiment and are ready to deploy to production, there are some additional steps required (see **Deploying to Production** below).\n\n## Creating a Visual Experiment[​](#creating-a-visual-experiment \"Direct link to Creating a Visual Experiment\")\n\nTo use the visual editor, first add a new Experiment. This can be done under **Experiments** in the left nav.\n\n![Design a new experiment](https://docs.growthbook.io/assets/images/add-experiment-modal-15681f50cca71852a1723562ee4bd078.png)\n\nSelect the option to design a new experiment. Then, you'll have a series of fields to fill out (hypothesis, variation names, goal metrics, etc.). Don't worry, these can all be changed later.\n\nOnce you created an experiment, you should be prompted to open the Visual Editor.\n\n### URL Targeting[​](#url-targeting \"Direct link to URL Targeting\")\n\nGrowthBook needs to know what page(s) of your site the experiment should run on.\n\nnote\n\nFor URL Targeting to work, you must pass the `url` targeting attribute into the GrowthBook SDK and also list it in the GrowthBook App. See [Targeting Attributes](https://docs.growthbook.io/features/targeting) to learn more about targeting users with certain attributes.\n\nIf your experiment is going to be on a single static page, enter the full URL and submit (e.g. `https://www.example.com/pricing`).\n\nIf your experiment is going to be on a page with a dynamic URL (e.g. all pages that start with `/post/`), click on the \"Advanced Mode\" link.\n\nYou'll need to enter 2 different URLs.\n\n1.  A single representative URL you want to load in the Visual Editor (e.g. `https://www.example.com/post/my-first-post`)\n2.  A URL targeting pattern to match all of your dynamic URLs\n\nThe targeting pattern supports wildcards (`*`), so for this example, you could enter `/post/*`.\n\ntip\n\nWe recommend sticking with \"Simple\" URL targeting rules (don't be fooled by the name, it's actually really powerful). The other option (Regex) can be useful for really advanced use cases, but it is much harder to write and more error prone.\n\n#### Simple Targeting[​](#simple-targeting \"Direct link to Simple Targeting\")\n\nOur \"simple\" URL targeting option supports the vast majority of use cases and is easy to use. It supports the following features:\n\n*   Match based on full URLs (e.g. `https://www.example.com/pricing`)\n*   Match based on path (e.g. `/pricing`)\n*   Match based on query strings (e.g. `/pricing?utm_source=email`)\n*   Match based on hashes/anchors (e.g. `/pricing#more-info`)\n*   Wildcards (e.g. `/posts/*` will match `/posts/123` AND `/posts/2023/03/30/my-post`)\n*   Ignores leading and trailing slashes (e.g. `pricing`, `/pricing`, and `/pricing/` are identical)\n*   Ignores the protocol (e.g. `https://...` will also match `http://...`)\n*   Ignores extra query string parameters (e.g. `/pricing/?plan=pro` will match `/pricing/?utm_source=email&plan=pro&logged-in=true`)\n\n#### Regex Targeting[​](#regex-targeting \"Direct link to Regex Targeting\")\n\nOur \"regex\" URL targeting option supports full regular expressions. Writing regular expressions for URLs is very error prone, so be careful and make sure you escape all special characters you don't want to be interpreted. Here's a full example:\n\n```\nhttps?:\\/\\/(www\\.)?example\\.com\\/pricing\\/?\n```\n\nYou can also match on just the path:\n\n```\n^\\/pricing\\/(pro|enterprise)\n```\n\n### The Visual Editor[​](#the-visual-editor \"Direct link to The Visual Editor\")\n\nThere are a number of different tools in the Visual Editor.\n\n![The Visual Editor UI](https://docs.growthbook.io/assets/images/visual-editor-ui-6068a707867e0c5c85a962b5bbc49b4f.png)\n\nAt the top is a dropdown where you can select which variation you are currently editing.\n\nBelow that is your toolbar. It has the following tools in order from left to right:\n\n1.  **Interactive Mode** - Click around your site normally\n2.  **Selection Mode** - Point and click to select an element on your site to edit. This is the most common way to make changes.\n3.  **Global CSS** - Inject global CSS styles into the page. Use this to control things like page background color or font size.\n4.  **Custom JavaScript** - Inject Javascript into the page. Use this to create complex variations.\n5.  **Change List** - See a summary of all of the changes you've made to the page so far\n\nWhen you're using the Element Selector, after you pick an element to edit, you'll be able to modify the Inner HTML (i.e. the copy), any attributes (e.g. a link HREF), and the list of CSS classes.\n\nWhen you're finished making changes, click the **Done Editing** button to be taken back to GrowthBook.\n\n### Custom JavaScript[​](#custom-javascript \"Direct link to Custom JavaScript\")\n\nCustom JavaScript is executed as quickly as possible, often times before the page has fully loaded. This gives you the most flexibility in how to implement your experiment.\n\nIf you are making changes to elements on the page, make sure you wait until they exist. Below is a small helper function you can add to the top of your Custom JavaScript to help with this:\n\n```\nfunction waitFor(selector) {  return new Promise(resolve => {    const el = document.querySelector(selector);    if (el) return resolve(el);    const observer = new MutationObserver(() => {        const el = document.querySelector(selector);        if (el) { observer.disconnect(); resolve(el)}    });    observer.observe(document, {childList: true, subtree: true});  });}\n```\n\nThen, you can use it like so:\n\n```\nwaitFor(\".my-element\").then((el) => {  el.innerHTML = \"Hello World!\";});\n```\n\n### Drag and Drop[​](#drag-and-drop \"Direct link to Drag and Drop\")\n\nWhen in Selection Mode, you can select an element and click to **drag and drop** it positionally on the page.\n\n#### Drag and Drop Handle[​](#drag-and-drop-handle \"Direct link to Drag and Drop Handle\")\n\nWhen an element is selected, you will see a floating handle to move it positionally. Alternatively, you can click anywhere on the selected element to move it as well.\n\n![Visual Editor Drag and Drop Handle](https://docs.growthbook.io/assets/images/visual-editor-move-handle-8ec559bb6de95ee475c2c8a1e1f64561.png)\n\nOnce dragging, the cursor will highlight an edge where the dragged element will land. When you release the cursor the element will move to the indicated spot. If you want to undo the move, click the 'Undo' button that is available for elements that have been dragged.\n\n![Visual Editor Drag and Drop Example](https://docs.growthbook.io/assets/images/visual-editor-drag-and-drop-1b1f0fb1762ca3af53c8b7fff1fd85e4.gif)\n\n### Debug Panel[​](#debug-panel \"Direct link to Debug Panel\")\n\nThe Visual Editor now comes with a Debug Panel to help diagnose any issues with your SDK configuration and URL Targeting rules. Use this to help diagnose your own errors, or provide a screenshot to our Support team when reaching out to help provide context.\n\n![Debug Panel](https://docs.growthbook.io/images/visual-editor-debug-panel.png)\n\n## Deploying to Production[​](#deploying-to-production \"Direct link to Deploying to Production\")\n\nBefore you start your first experiment, you will first need to generate a **Client Key** in GrowthBook. You can get this by creating a new SDK Connection (under **SDK Configuration** in the left navigation).\n\n**Important**: Make sure to enable the \"Include Visual Experiments\" toggle. If you forget this step, Visual Editor experiments will not be sent to your application.\n\n![Enable the Visual Editor in your SDK Connection](https://docs.growthbook.io/assets/images/sdk-connection-visual-editor-2b6d4d437c6e8c5f2fd511f52d6905fa.png)\n\nYou can also optionally include Draft Experiments (see below).\n\nOnce you create an SDK Connection, you need to follow the steps to integrate GrowthBook into your website.\n\nThe easiest and recommended way to do this is with our [Script Tag SDK](https://docs.growthbook.io/lib/script-tag), which works out-of-the-box and doesn't require any configuration for most websites. It's also possible to use either our [JavaScript](https://docs.growthbook.io/lib/js) or [ReactJS](https://docs.growthbook.io/lib/react) SDKs, although these do require more up-front work to integrate into your application.\n\nnote\n\nIf you've already been using our front-end SDKs for feature flagging, make sure you:\n\n1.  Update to the latest SDK version\n2.  Follow the \"Visual Editor\" instructions in the SDK docs\n\n### Content Security Policy (CSP) Changes[​](#content-security-policy-csp-changes \"Direct link to Content Security Policy (CSP) Changes\")\n\nIf your website uses a Content Security Policy (CSP), there are some additional changes you'll need to make. This applies to both SDK and pre-build script tag integration.\n\n#### script-src[​](#script-src \"Direct link to script-src\")\n\nChanging the `script-src` directive in your CSP is only required if you are writing custom JavaScript in the Visual Editor. If you are only changing styles or copy using the point-and-click editor, this is not required and you can skip this section.\n\nIf you have the `script-src` directive defined in your website's CSP, you'll need to enable `'unsafe-inline'` and `'unsafe-eval'` in order to leverage the Global JavaScript injection feature of the Visual Editor:\n\n```\nContent-Security-Policy: script-src 'self' 'unsafe-inline' 'unsafe-eval';\n```\n\n##### Using Script Nonces[​](#using-script-nonces \"Direct link to Using Script Nonces\")\n\nAs an alternative to allowing `unsafe-inline`, we support \"nonces\", although this requires some very technical and custom configuration to hook up.\n\nFirst, you will need to generate a unique nonce value for every request and add it to your CSP header. This can be done on the edge such as with a Cloudflare Worker.\n\nThen, you will need to pass this nonce into your GrowthBook SDK as `jsInjectionNonce`.\n\nFor example, if you are using our [Script Tag SDK](https://docs.growthbook.io/lib/script-tag), you can add the following into your page's `<head>` BEFORE you load the GrowthBook snippet. Replace all instances of `$NONCE` with the unique nonce value you generated.\n\n```\n<script nonce=\"$NONCE\">window.growthbook_config = window.growthbook_config || {};window.growthbook_config.jsInjectionNonce = \"$NONCE\";</script>\n```\n\nYou will still need to allow `unsafe-eval`.\n\n## Drafts and QA[​](#drafts-and-qa \"Direct link to Drafts and QA\")\n\nWhile the experiment is still a draft, you can preview variations by adding a querystring to your URL.\n\nnote\n\nThis requires turning on the \"Include Drafts\" toggle for your SDK Connection in GrowthBook.\n\nTo build the QA preview URL, you'll need the **Experiment Id** (viewable on the right side of the experiment page under Settings). You'll also need the variation number you want to preview. `0` is the control, `1` is the 1st variation, etc..\n\nNow, just join these together with an equals sign (e.g. `my-experiment-id=1`). This needs to go in the Querystring part of the URL (after a question mark). Here's a full example:\n\n`https://www.example.com/pricing?my-experiment-id=1`\n\nUntil an experiment is moved out of the \"draft\" phase and started, this is the only way to view it on your site.\n\n## Stopping an Experiment[​](#stopping-an-experiment \"Direct link to Stopping an Experiment\")\n\nWhen your experiment is finished, you can click on the `Stop Experiment` link at the top of results. This will prompt you for several bits of information about why you're stopping and what the conclusion was.\n\nIf your variation won, you can optionally enable a `Temporary Rollout` when stopping. This will continue running your experiment with the same targeting conditions, but send 100% of traffic to the winning variation and disable the `trackingCallback` from being called.\n\nThe reason it's called a \"Temporary\" Rollout is because you don't want to rely on our SDK to implement the winning variation forever. It's best practice to have your engineering team re-implement the changes directly in your site's code. This is for a number of reasons:\n\n1.  Changes implemented in code are rendered quicker, so your site will load faster\n2.  Changes in code will be picked up for SEO\n3.  Changes applied through the visual editor require the SDK to download data from GrowthBook. Although lightweight, these stopped experiments can add up over time and further slow down your site.\n4.  Reduce the chance of conflicts. If two visual editor experiments try to change the same element at the same time, it will not always work as expected. Moving the winning variation to code will avoid this issue.",
  "title": "Visual Editor | GrowthBook Docs",
  "description": "Learn about our visual editor",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/app/datasources",
  "markdown": "# Data Source Configuration | GrowthBook Docs\n\n## Overview[​](#overview \"Direct link to Overview\")\n\nData Sources are how GrowthBook connects to your data warehouse so that it can pull those aggregated statistics in order to compute metrics and experiment results. Each Data Source defines how to connect to your data, what version of SQL to use when querying your data, and can provide templates for what the SQL to connect to your Data Source should look like depending upon which event tracker software you use. GrowthBook works with your existing SQL data, no matter where it is located and no matter what shape or format it is in, whether you have a strongly normalized schema, a single “events” table with JSON fields, or something in between.\n\n## Supported Event Schemas[​](#supported-event-schemas \"Direct link to Supported Event Schemas\")\n\nWhen adding a new Data Source in Growthbook from /datasources page we first guide you to select what event tracker software you use, or you can choose custom if you don't use any of the popular third party event trackers that we support. Telling us which event tracker you use, gives us an idea on the likely shape of your data. This will help us generate the correct sql to extract out the aggregated statistics from your site with as little modification on your end as possible. Here is Growthbook's current list of event trackers that we support with links for more details on how to set them up with GrowthBook:\n\n*   [Amplitude](https://docs.growthbook.io/event-trackers/amplitude)\n*   [CleverTap](https://docs.growthbook.io/event-trackers/clevertap)\n*   [Firebase](https://docs.growthbook.io/event-trackers/firebase)\n*   [Freshpaint](https://docs.growthbook.io/event-trackers/freshpaint)\n*   [Fullstory](https://docs.growthbook.io/event-trackers/fullstory)\n*   [Google Analytics 4 (BigQuery only)](https://docs.growthbook.io/guide/GA4-google-analytics)\n*   [Heap Analytics](https://docs.growthbook.io/event-trackers/heap)\n*   [Jitsu](https://docs.growthbook.io/event-trackers/jitsu)\n*   [Keen IO](https://docs.growthbook.io/event-trackers/keenio)\n*   [Matomo](https://docs.growthbook.io/guide/matomo)\n*   [Mixpanel](https://docs.growthbook.io/guide/mixpanel)\n*   [MParticle](https://docs.growthbook.io/event-trackers/mparticle)\n*   [RudderStack](https://docs.growthbook.io/guide/rudderstack)\n*   [Segment](https://docs.growthbook.io/event-trackers/segment)\n*   [Snowplow](https://docs.growthbook.io/event-trackers/snowplow)\n\nIf you do not use any of those you choose [Custom Data Source](https://docs.growthbook.io/event-trackers/custom) and define some of the sql yourself.\n\n## Configuration Settings[​](#configuration-settings \"Direct link to Configuration Settings\")\n\nOnce you have chosen your event tracker and data source type and successfully connected, you will be given an opportunity to modify your configuration settings. For many applications Growthbook will have choosen the correct configuration settings straight out of the box based upon which event tracker you choose. In some instances, you may need to tweak them slightly, or in the case of using a custom datasource, define them more explicitly.\n\n### Identifier Types[​](#identifier-types \"Direct link to Identifier Types\")\n\nThese are all of the types of identifiers you use to split traffic in an experiment and track metric conversions. Common examples are `user_id`, `anonymous_id`, `device_id`, and `ip_address`.\n\nThere are some cases where a single database column isn't enough to uniquely identify a subject. For example, you might need the combination of `company` and `user_id`. In this case, we recommend creating a synthetic identifier by concatenating all of the fields together. For example, you can create a `company_user` identifier and then in your SQL, select it as follows: `CONCAT(company, user_id) as company_user`.\n\n### Experiment Assignment Queries[​](#experiment-assignment-queries \"Direct link to Experiment Assignment Queries\")\n\nAn experiment assignment query returns which users were part of which experiment, what variation they saw, and when they saw it. Each assignment query is tied to a single identifier type (defined above). You can also have multiple assignment queries if you store that data in different tables, for example, one from your email system and one from your back-end.\n\ntip\n\nAssignment queries are one-half of the queries that are used to generate experiment results, the other being metric queries. Assignment queries can be edited from the `Metrics and Data` → `Data Sources` page.\n\nThe end result of the query should return data like this:\n\n| user\\_id | timestamp | experiment\\_id | variation\\_id |\n| --- | --- | --- | --- |\n| 123 | 2021-08-23-10:53:04 | my-button-test | 0   |\n| 456 | 2021-08-23 10:53:06 | my-button-test | 1   |\n\nThe above assumes the identifier type you are using is `user_id`. If you are using a different identifier, you would use a different column name.\n\nHere's an example query you might use:\n\n```\nSELECT  user_id,  received_at as timestamp,  experiment_id,  variation_idFROM  eventsWHERE  event_type = 'viewed experiment'\n```\n\nMake sure to return the exact column names that GrowthBook is expecting. If your table’s columns use a different name, add an alias in the SELECT list (e.g. `SELECT original_column as new_column`).\n\n#### Duplicate Rows[​](#duplicate-rows \"Direct link to Duplicate Rows\")\n\nIf a user sees an experiment multiple times, you should return multiple rows in your assignment query, one for each time the user was exposed to the experiment.\n\nThis helps us detect when users were exposed to more than one variation, and eventually may be useful in helping build interesting time series.\n\n#### Experiment Dimensions[​](#experiment-dimensions \"Direct link to Experiment Dimensions\")\n\nIn addition to the standard 4 columns above, you can also select additional dimension columns. For example, `browser` or `referrer`. These extra columns can be used to drill down into experiment results.\n\n#### Identifier Join Tables[​](#identifier-join-tables \"Direct link to Identifier Join Tables\")\n\nIf you have multiple identifier types and want to be able to auto-merge them together during analysis, you also need to define identifier join tables. For example, if your experiment is assigned based on `device_id`, but the conversion metric only has a `user_id` column.\n\nThese queries are very simple and just need to return columns for each of the identifier types being joined. For example:\n\n```\nSELECT user_id, device_id FROM logins\n```\n\n#### SQL Templates[​](#sql-templates \"Direct link to SQL Templates\")\n\nWe use {{[Handlebars](https://handlebarsjs.com/guide/#language-features)}} to compile the assignment sql, identity queries, etc. into what is actually called to your database.\n\nYou can use any of the in-built variables that Growthbook automatically sets:\n\n*   **startDate** - `yyyy-MM-dd HH:mm:ss` of the earliest data that needs to be included\n*   **startDateISO** - `yyyy-MM-dd'T'HH:mm:ss.SSS'Z'` of the startDate in ISO format. This can then be used with the `date` helper to achieve whatever [format](#dateformat) you like (ex. `{{date startDateISO \"yyyyMMdd\"}}`)\n*   **endDate** - `yyyy-MM-dd HH:mm:ss` of the latest data that needs to be included\n*   **endDateISO** - `yyyy-MM-dd'T'HH:mm:ss.SSS'Z'` of the endDate in ISO format. This can then be used with the `date` helper to achieve whatever [format](#dateformat) you like (ex. `{{date endDateISO \"yyyyMMdd\"}}`)\n*   **experimentId** - Either a specific experiment id OR `%` if you should include all experiments\n\nYou can also use any of the in-built helper functions:\n\n*   **camelcase \\[str\\]** - ex. `{{camelcase \"My database\"}}` compiles to `myDatabase`.\n*   **dotcase \\[str\\]** - ex. `{{dotcase \"My database\"}}` compiles to `my.database`.\n*   **kebabcase \\[str\\]** - ex. `{{kebabcase \"My database\"}}` compiles to `my-database`.\n*   **lowercase \\[str\\]** - ex. `{{lowercase \"My database\"}}` compiles to `my database`.\n*   **pascalcase \\[str\\]** - ex. `{{pascalcase \"My database\"}}` compiles to `MyDatabase`.\n*   **replace \\[str\\] \\[pattern\\] \\[replacement\\]** - Replace all occurences of a regular expression with something else. ex. `{{replace \"My%%%Database!\" \"\\[^a-zA-Z\\]\" \"\"}}` compiles to `MyDatabase`\n*   **snakecase \\[str\\]** - ex. `{{pascalcase \"My database\"}}` compiles to `my_database`.\n*   **uppercase \\[str\\]** - ex. `{{uppercase \"My database\"}}` compiles to `MY DATABASE`.\n*   **date \\[date\\] \\[format\\]** - Format an ISO date according to this [format](https://date-fns.org/v2.29.3/docs/format), being careful not to mix up months (MM) and minutes (mm). ex. `{{date startDateISO \"yyyyMMdd\"}}` might compile to `20230130`. The most common codes are:\n\n| code | meaning |\n| --- | --- |\n| yyyy | year |\n| MM  | month |\n| dd  | day |\n| HH  | hour |\n| mm  | minutes |\n| ss  | seconds |\n| t   | timestamp |\n\nFor example:\n\n```\nSELECT  user_id,  anonymous_id,  received_at as timestamp,  experiment_id,  variation_idFROM  events_*WHERE  _TABLE_SUFFIX BETWEEN '{{date startDateISO \"yyyyMMdd\"}}' AND '{{date endDateISO \"yyyyMMdd\"}}'  AND event_name = 'experiment_viewed'  AND experiment_id LIKE '{{ experimentId }}'\n```\n\nnote\n\nThe inserted values do not have surrounding quotes, so you must add those yourself (e.g. use `'{{&nbsp;startDate&nbsp;}}'` instead of just `{{&nbsp;startDate&nbsp;}}`)\n\n### Jupyter Notebook Query Runner[​](#jupyter-notebook-query-runner \"Direct link to Jupyter Notebook Query Runner\")\n\nThis setting is only required if you want to export experiment results as a Jupyter Notebook.\n\nThere is no one standard way to store credentials or run SQL queries from Jupyter notebooks, so GrowthBook lets you define your own Python function.\n\nIt needs to be called `runQuery`, accept a single string argument named `sql`, and return a pandas data frame.\n\nHere's an example for a Postgres (or Redshift) data source:\n\n```\nimport osimport psycopg2import pandas as pdfrom sqlalchemy import create_engine, text# Use environment variables or similar for passwords!password = os.getenv('POSTGRES_PW')connStr = f'postgresql+psycopg2://user:{password}@localhost'dbConnection = create_engine(connStr).connect();def runQuery(sql):  return pd.read_sql(text(sql), dbConnection)\n```\n\n**Note:** This python source is stored as plain text in the database. Do not hard-code passwords or sensitive info. Use environment variables (shown above) or another credential store instead.\n\n## Schema Browser[​](#schema-browser \"Direct link to Schema Browser\")\n\nWhen you connect a supported data source to GrowthBook, we automatically generate metadata that is used by our Schema Browser. The Schema Browser is a user-friendly interface that makes writing queries easier as you can easily explore information about the datasource such as databases, schemas, tables, columns, and data types.\n\n![GrowthBook Schema Browser](https://docs.growthbook.io/assets/images/growthbook-schema-browser-40e388a5759c12afef54296d9c0c1980.png)\n\nBelow are the data sources that currently support the Schema Browser:\n\n*   AWS Athena - _Requires a Default Catalog_\n*   BigQuery - _Requires a Project Name and Default Dataset_\n*   ClickHouse\n*   Databricks - _Currently only supported on version 10.2 and above with a Unity Catalog_\n*   MsSQL/SQL Server\n*   MySQL/MariaDB\n*   Postgres\n*   PrestoDB (and Trino) - _Requires a Default Catalog_\n*   Redshift\n*   Snowflake\n\nnote\n\nIf you added a supported data source prior to GrowthBook v2.0, you can generate the schema manually by clicking \"Data Sources\" on the left-nav, selecting the data source, and then clicking the \"View Schema Browser\" button and following the on-screen prompt.",
  "title": "Data Source Configuration | GrowthBook Docs",
  "description": "This document outlines how to configure data source",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/features/environments",
  "markdown": "# Environments | GrowthBook Docs\n\nGrowthBook comes with one environment by default (**production**), but you can add as many as you need on the [Environments page](https://app.growthbook.io/environments) located within the **SDK Configuration** menu.\n\nFeature flags can be enabled and disabled on a per-environment basis. You can also set the default feature state for any new environment. Additionally, you can scope environments to only be available in specific projects, allowing for further control and segmentation over feature delivery.\n\n![A list of environments](https://docs.growthbook.io/assets/images/feature-environments-1-4255235035807c067eca714cfa959cd6.png)\n\nWhen a feature is disabled in an environment, the feature will not be returned via the SDK, and that feature will always evaluate to `null` and ignore any other targeting or override rules.\n\n## Environments and SDKs[​](#environments-and-sdks \"Direct link to Environments and SDKs\")\n\nWhen you configure your SDK endpoint you will be asked which environment you want to use. Each SDK endpoint will have a unique SDK key. When this endpoint is called from the code, a JSON file containing all the features and rules by which they should be shown is returned. Scoping SDKs to environments allows you to easily separate, for example, your production and development environments.\n\nTo use multiple environments in the same code base, you can use environment variables to set a dynamic key, e.g. `GROWTHBOOK_CLIENT_KEY='sdk-abc123'` and then reference that environment variable in your code base. Depending on the framework you're using, some environment variables are not exposed by default on the front-end unless provided an appropriate prefix, e.g. `NEXT_GROWTHBOOK_CLIENT_KEY='sdk-abc123'` in order to access environment variables in Next.js client code.\n\nnote\n\nIt's possible for a feature to be enabled for an environment and still be considered \"off\". This happens when its value is set to `false`, `null`, `0`, or an empty string.",
  "title": "Environments | GrowthBook Docs",
  "description": "Define multiple environments to control which features are enabled in each.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/app/fact-tables",
  "markdown": "# Fact Tables | GrowthBook Docs\n\nWith Fact Tables, you write SQL once for an event (e.g. `SELECT * FROM orders`) and from that you can quickly and easily create a bunch of related metrics - for example, `Revenue per User`, `Average Order Value`, and `Items per Order`.\n\nThese metrics can be used as Goals and Guardrails in Experiments.\n\n## Fact Table SQL[​](#fact-table-sql \"Direct link to Fact Table SQL\")\n\nFirst, you have to write SQL that transforms your event data into a format that GrowthBook understands. The following column names are required:\n\n*   `timestamp` - The date the event happened\n*   One column per supported identifier type (e.g. `user_id` and `anonymous_id`). The possible identifier types depend on your data source settings.\n\nAny other columns you return can be used to create metrics or used as a filter.\n\nHere's a full example:\n\n```\nSELECT  -- Required columns  purchase_date as timestamp,  user_id,  anonymous_id,  -- Additional columns (depends on your event)  amount,  coupon_code,  device_typeFROM  ordersWHERE  status = 'completed'\n```\n\n### Columns[​](#columns \"Direct link to Columns\")\n\nWhen you create a Fact Table, we query the first few rows and inspect the returned data to determine which columns you've selected and what data types they are.\n\nThis process isn't perfect. For example, if the first few rows happen to have `null` as the value of a column, we can't tell if it's supposed to be a number, string, etc.. When this happens, we will show you a warning and you can manually specify the type.\n\nAny column can be used to create filters, but only numeric columns can be used as a metric value.\n\n#### Number Formats[​](#number-formats \"Direct link to Number Formats\")\n\nFor numeric columns, you can also specify a number format, which controls how the metric is displayed on the front-end. Possible values are `currency` and `time:seconds`.\n\nnote\n\nThe default display currency is USD, but you can change it under **Settings** → **General** → **Metric Settings**\n\n## Filters[​](#filters \"Direct link to Filters\")\n\nFilters are reusable SQL snippets to filter the rows in the Fact Table. These let you easily create metric variants. For example, `Purchase`, `Mobile Purchase`, and `Desktop Purchase`\n\nHere's an example Filter SQL:\n\nIf a metric uses this Filter, GrowthBook will add it to the WHERE clause automatically. If there are multiple Filters, they will be ANDed together.\n\n## Metrics[​](#metrics \"Direct link to Metrics\")\n\nThere are 4 types of supported Fact Table metrics today - **Proportion**, **Mean**, **Ratio**, and **Quantile**.\n\n| Metric Type | Description | Example | User Aggregation | Variation Aggregation |\n| --- | --- | --- | --- | --- |\n| Proportion | Percentage of users | Created Account | 1 or 0 | Proportion of users in variation |\n| Mean | Average of user totals | Revenue per User | `SUM(value)` | Average across users in variation |\n| Ratio | Ratio of two totals | Average Order Value | `SUM(value)` for both numerator and denominator | Sum of user numerators / sum of user denominators |\n| Quantile (event) | Quantile of row values | P95 Latency | None | Quantile across all values |\n| Quantile (per user) | Quantile of user totals | P90 Total User Revenue | `SUM(value)` | Quantile across user totals |\n\n### Proportion Metrics[​](#proportion-metrics \"Direct link to Proportion Metrics\")\n\nProportion Metrics measure the percent of users in an experiment who exist in a Fact Table. The number of rows the user has doesn't matter - we just care whether or not they have at least 1 row.\n\nFor example, if you have an Orders Fact Table, you can create a Proportion Metric to see what percent of users purchased something. Whether a user made 1 purchase or 10 purchases, it will just count as 1 conversion.\n\nYou can optionally add Filters to limit which rows are considered. For example, adding a `Mobile` filter, you can see what percent of users completed a purchase on a mobile device.\n\n### Mean Metrics[​](#mean-metrics \"Direct link to Mean Metrics\")\n\nMean Metrics are useful when there are more than 2 possible states a user can be in. For example, instead of just purchase/not purchase, you might care about the average number of orders a user makes, or the average revenue you earned per user in an experiment.\n\nFor the metric value, there are 2 types of aggregations you can do - `COUNT(*)` and `SUM(column)`. For `SUM`, you will be able to choose any numeric column in your Fact Table.\n\nFor example, an **Orders per User** metric would use `COUNT(*)` since you want to count the total number of rows. A **Revenue per User** metric would use `SUM` and select the column where the order total is stored.\n\nThe denominator for Mean Metrics is always the number of users in an experiment variation. So, even though you may be doing `SUM(revenue)` as the aggregation, it will be divided by number of users and you will actually end up with an average value per user, not an overall sum for the variation.\n\n### Ratio Metrics[​](#ratio-metrics \"Direct link to Ratio Metrics\")\n\nRatio Metrics let you pick a custom denominator and allow for metrics such as **Average Order Value** (denominator is number of orders) or **Session Duration** (denominator is number of sessions).\n\nFor both the numerator and denominator, you can select a Fact Table, an aggregation, and optional filters. GrowthBook allows the numerator and denominator to have different Fact Tables, which can open up some really advanced use cases.\n\nThe types of aggregations supported for ratio metrics are:\n\n*   `COUNT(*)` - Number of rows in the Fact Table\n*   `COUNT(DISTINCT 'User Identifier')` - Sample size of the experiment variation\n*   `SUM(column)` - Total of a numeric column in the Fact Table\n\nUnder the hood, GrowthBook uses the Delta Method to accurately determine the variance.\n\nFor example, to create a **Session Duration** metric, you would do the following:\n\n*   Numerator: `SUM(duration)` from a `Sessions` fact table\n*   Denominator: `COUNT(*)` from a `Sessions` fact table\n\n### Quantile Metrics[​](#quantile-metrics \"Direct link to Quantile Metrics\")\n\nQuantile Metrics are useful when you care about comparing variations at a quantile (e.g. latency at P99) rather than the mean. Learn more about when to use Quantile Metrics [here](https://docs.growthbook.io/statistics/quantile).\n\nOne key consideration is `Group by Experiment User before taking quantile?`. We provide a more complete description [here](https://docs.growthbook.io/app/fact-tables#quantile-metrics). In short, if you often think about your metric at the user level, you should aggregate. If you think about your metric at the event level, do not aggregate.\n\nFor the metric value, the only aggregation available is `SUM(column)`. For `SUM`, you will be able to choose any numeric column in your Fact Table.\n\nYou have the option to `Ignore Zeros`. For event-level analysis, ignoring zeros entails removing all events from the analysis with value equal to 0. Similarly, for a user-level analysis, removing zeros entails removing all rows corresponding to user-level aggregations that have value 0.\n\nWhen picking `Quantile` you have several default options or can select `Custom`. If you select `Custom` you must input a number between 0 and 1. For example, inputting 0.75 will compare the 75th75^{\\\\text{th}} percentiles across variations.\n\n### Metric Windows[​](#metric-windows \"Direct link to Metric Windows\")\n\nWhen used in an experiment, we only consider rows of a Metric where the timestamp is greater than or equal to the first time the user was exposed to the experiment. In other words, if someone purchases something before seeing your experiment, it won't be included in the analysis. This behavior is ideal for the vast majority of metrics, but you can change it with the Metric Delay setting if desired (see below).\n\nThere are three window settings one can use to configure the metric date window. Each of them defines the lower and upper date range of the metric to use for each user:\n\n*   **None** (default)\n    *   Lower bound: user's first exposure plus the metric delay\n    *   Upper bound: experiment end date\n*   **Conversion Window**\n    *   Lower bound: user's first exposure plus the metric delay\n    *   Upper bound: the lower bound + the length of the conversion window\n*   **Lookback Window**\n    *   Lower bound: the experiment end date minus the lookback window OR the user's first exposure plus the metric delay, whichever is later\n    *   Upper bound: experiment end date\n\nHere's a graphical representation of these three window types for a hypothetical User 1: ![Metric Windows](https://docs.growthbook.io/assets/images/metric-windows-024e6a7e756c8cd43f0d35ee221cc089.png)\n\nHere's a second example for a hypothetical User 2, who joins the experiment late. Notice that the conversion window can extend beyond the experiment end date. ![Metric Windows (User 2)](https://docs.growthbook.io/assets/images/metric-windows-user-2-dac5ae6d7345e2211ec13dd5f8869954.png)\n\nWhy might you choose one window over another?\n\n**None** - The simplest. Use all data available. This is useful for using as much data associated with users in your experiment and will combine any behavior that is right after experiment exposure as well as long run behavior within the experiment time frame.\n\n**Conversion window** - Conversion windows allow you to only look at events that are tied to the first exposure to an experiment. This can help if, for example, you are tracking purchases and you only want to measure the effect of an experiment in a checkout flow on purchases made soon after seeing that checkout flow. Using a conversion window can reduce the noise from user behavior not related to an experiment. However, if you set the window too short, you may not capture users that return a few days later and were influenced by the experiment.\n\n**Lookback window** - Lookback windows are good for capturing long run impacts of an experiment on regular behavior like user log ins or page views. They have two main advantages:\n\n(1) You can mitigate the novelty effect of an experiment; if you are testing a new recommendation algorithm, at first users may react a certain way to the experiment, but eventually they may adjust and so may their behavior. In these cases, you may just want to look at the last 14 days of an experiment.\n\n(2) Lookback windows help you focus on the long run effects of an experiment. Much of experimentation is about building a better product; by focusing on impact of an experiment after it has been live for a week or two, you may get a better picture of the long run impact of launching the experiment.\n\nLarger companies who measure long run logged in behavior want to ensure their experiments have lasting effects and often rely on lookback windows to make shipping decisions However, lookback windows may not be right if you are testing a feature on logged-out or anonymous users and are measuring simple purchase conversions or something similar. In these cases, you might end up with many logged-out users who, in the long run, simply have no metric data associated with them.\n\n### Advanced Settings[​](#advanced-settings \"Direct link to Advanced Settings\")\n\n#### What is the Goal?[​](#what-is-the-goal \"Direct link to What is the Goal?\")\n\nFor the vast majority of metrics, the goal is to increase the value. But for some metrics like \"Bounce Rate\" and \"Page Load Time\", lower is actually better.\n\nSetting this to \"decrease\" basically inverts the \"Chance to Beat Control\" value in experiment results so that \"beating\" the control means decreasing the value. This will also reverse the red and green coloring on graphs.\n\n#### Capped Value[​](#capped-value \"Direct link to Capped Value\")\n\nLarge outliers can have an outsized effect on experiment results. For example, if your normal revenue per user $40 and someone happens to make a $5000 order, whatever variation that person is in will be much more likely \"win\" any experiment because that one order is an outlier.\n\nCapping (also known as winsorization) works by ensuring that all aggregate unit (e.g. user) values are no more than some value. So in the above example, if the cap was $100, the $5000 purchase will still be counted, but the aggregated value for that user will be capped at $100 and will have a much smaller effect on the results. It will still give a boost to whatever variation the person is in, but it won't completely dominate all of the other orders and is unlikely to make a winner just on its own. Another way to think about this is that you are slightly biasing your results by truncating large values, but you are reducing variance to prevent the outsized effect of outliers.\n\nThere are two ways to cap metric values in GrowthBook:\n\n**1\\. Absolute capping** - if set above zero, all aggregated user values will be capped at exactly this value. For example, if the cap is $100 on total revenue per user, then after we sum all of a users orders up, any user with an aggregate sum of greater than $100 will be set to $100.\n\n**2\\. Percentile capping** - when this is set to between 0 and 1, it uses that percentile to select a cap based on the data in your experiment so far. This cap is therefore specific to each experiment and specific to each analysis run in that experiment if new data has come in. It works like so: after we calculate the unit-level aggregate values for all units (e.g. users) during an experiment analysis, we find the specified percentile of these unit-level aggregates and then cap these aggregated values at this percentile. Using the above example, if you were to specify percentile capping with a value of `0.95`, then we find the 95th percentile of total revenue per users (say this turns out to be $135). We then cap those user-level aggregates at $135.\n\nYou can additionally choose to ignore zeros, which will compute the percentile without including any user aggregated zero values. This is useful if you have a lot of zero values and you don't want to have to fine tune the percentile to avoid setting the cap too low.\n\nBecause the percentile cap depends on the data in your experiment, it can be different from experiment to experiment, or even analysis to analysis. To find out what value was actually used for capping you can do the following: on the Experiment Results tab, click the three dot menu in the top right and select \"View Queries\". Each percentile capped metric will have a column with the `main_cap_value` that was used to cap that metric and represents the computed percentile of unit-level aggregate values.\n\n#### Metric Delay[​](#metric-delay \"Direct link to Metric Delay\")\n\nConversions within the first X hours of being put into an experiment are ignored (default = `0`). This is useful for metrics like \"day 2 retention\". In that case, if your underlying table reports whether a user is retained on any given day, you could set a metric delay to `24` hours.\n\n##### Negative metric delays[​](#negative-metric-delays \"Direct link to Negative metric delays\")\n\nThe metric delay can also be negative to include some conversions **before** a user is put into an experiment. For example, a value of `-2` would mean conversions up to 2 hours before will be included. You might be wondering when this would ever be useful.\n\nImagine the average person stays on your site for 60 seconds and your experiment can trigger at any time.\n\nIf you just look at the average time spent after the experiment, the numbers will lose a lot of meaning. A value of `20 seconds` might be horrible if it happened to someone after only 5 seconds on your site since they are staying a lot less time than average. But, that same `20 seconds` might be great if it happened to someone after 55 seconds since their visit is a lot longer than usual. Over time, these things will average out and you can eventually see patterns, but you need an enormous amount of data to get to that point.\n\nIf you set the metric delay to something negative, say `-0.5` (30 minutes), you can reduce the amount of data you need to see patterns. For example, you may see your average go from 60 seconds to 65 seconds.\n\nKeep in mind, these two things are answering slightly different questions. `How much longer do people stay after viewing the experiment?` vs `How much longer is an average session that includes the experiment?`. The first question is more direct and often a more strict test of your hypothesis, but it may not be worth the extra running time.\n\n#### Bayesian Priors[​](#bayesian-priors \"Direct link to Bayesian Priors\")\n\nYour organization can set default priors for Bayesian analyses that are used by all metrics.\n\nHowever, you can also set metric specific priors by opening the Edit Metric modal from the Metric page, clicking on Advanced Settings, and turning on the metric override. This will allow you to set a custom prior for that metric.\n\nAdditionally, you can use experiment metric overrides to further customize these priors for each experiment.\n\nYou can read more about Bayesian priors on [our statistical details page](https://docs.growthbook.io/statistics/details).\n\n## Fact Table Query Optimization[​](#fact-table-query-optimization \"Direct link to Fact Table Query Optimization\")\n\nGrowthBook Enterprise customers can enable Fact Table Query Optimization for faster, more efficient queries.\n\nIf multiple metrics from the same Fact Table are added to an experiment, they will be combined into a single SQL query. For data sourcees with usage-based billing, this can result in dramatic cost savings.\n\nThere are some restrictions that limit when this optimization can be performed:\n\n*   Ratio metrics where the numerator and denominator are part of different Fact Tables are always excluded from this optimization\n*   If `Exclude In-Progress Conversions` is set for an experiment, optimization is disabled for all metrics\n*   If you are using MySQL and a metric has percentile capping, it will be excluded from optimization\n\nIn all other cases, this optimization is enabled by default for all Enterprise customers. It can be disabled under **Settings → General → Experiment Settings**. When disabled, a separate SQL query will always be run for every individual metric.\n\n## Migrating Existing Metrics to Fact Tables[​](#migrating-existing-metrics-to-fact-tables \"Direct link to Migrating Existing Metrics to Fact Tables\")\n\nFact Tables are brand new to GrowthBook, first launching in October 2023. Eventually, we see Fact Tables completely replacing the existing way of defining metrics. Right now though, Fact Tables are still in early preview mode and there are some rough edges.\n\nIf you'd like to get an early start migrating your existing metrics, there are a few differences to be aware of:\n\n### Reusable Definitions[​](#reusable-definitions \"Direct link to Reusable Definitions\")\n\nMetric definitions have been split up into a few different reusable pieces. It's a couple more steps to create your first metric, but it should drastically simplify adding subsequent ones and building out your metric library.\n\n*   The SQL and supported user identifiers are defined in the **Fact Table**\n*   The display formatting (e.g. currency vs duration) is attached to a Fact Table **Column**\n*   Any WHERE clauses for metrics are defined as **Filters** (e.g. `device_type = 'mobile'`)\n\nOnce these pieces are in place, defining Metrics is now much easier. The form went from 13+ steps down to just 4 and no longer requires any specialized SQL or database knowledge.\n\n### Metric SQL[​](#metric-sql \"Direct link to Metric SQL\")\n\nBefore, SQL for a metric would select at most 1 numeric column and it had to be named `value`. With Fact Tables, you can have as many numeric columns as you want and there are no naming restrictions. This allows you to have 1 complex SQL definition be re-used across many related metrics.\n\nAlso, Custom aggregations are no longer supported. Fact Tables only support a few pre-defined aggregations - `COUNT` and `SUM` (we may add more in the future). Using these pre-defined aggregations greatly simplifies the queries we run and enables advanced performance and cost optimizations.\n\n### Metric Types[​](#metric-types \"Direct link to Metric Types\")\n\nMetric types have changed.\n\n*   Binomial Metrics have been renamed to **Proportion Metrics**\n*   Count, Duration, and Revenue are all now just **Mean Metrics** (the display formatting is controlled by the Fact Table columns now)\n*   Instead of just adding a denominator to any metric, there is now a dedicated type for **Ratio Metrics**.\n\n### Ratio Metrics[​](#ratio-metrics-1 \"Direct link to Ratio Metrics\")\n\nThere are a lot of changes to how Ratio Metrics are defined and how they behave.\n\nRatio metrics are now self-contained. Previously, the denominator would just be a pointer to an entirely separate metric. This allowed some weird edge cases like the denominator itself being a ratio metric with it's own denominator. With Fact Tables, you define both the numerator and denominator in one flow and these nested denominator edge cases are no longer supported.\n\nDuring analysis, Ratio metrics used to behave like a Funnel - the denominator had to happen first before the numerator. This was unintuitive for many people, so With Fact Tables, we changed them to act like true ratios - we calculate the numerator and denominator independently and then divide them. We plan to add a dedicated Funnel metric type in the future to support this use case.\n\nLastly, Ratio metrics now have a single metric window and capping behavior. Previously, this would be controlled separately for the numerator and denominator. Because of this change, only \"percentile\" capping is allowed for ratio metrics.",
  "title": "Fact Tables | GrowthBook Docs",
  "description": "Learn about defining Fact Tables and using them to create a library of Metrics",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/app/experiment-results",
  "markdown": "# Experiments (Results) | GrowthBook Docs\n\nOnce your experiment is up and running, you will be able to track how it is performing in the Experiment Results tab. This can be found on any Experiment page under the Results tab at the top.\n\nThere, you can update your analysis, configure how you want your analysis to run, and see the impact of your experiment on your metrics.\n\n## Experiment Results Table[​](#experiment-results-table \"Direct link to Experiment Results Table\")\n\nThe heart of the experiment results page is the table of results. What you will see will depend a little bit on whether you are using our Bayesian or our Frequentist engine, as well as whether your experiment has 2 variations or if it has 3+, but in either case the first two data columns will look the same, and each row will represent one comparison between baseline and variation for one metric.\n\n![Results Table](https://docs.growthbook.io/assets/images/results-table-781167fd137533b109a3d111851125bf.png)\n\nIn both engines, the first two data columns are:\n\n**Baseline** - the average value of the metric in the baseline variation; either a percentage of users in that variation (for proportion metrics) or an average value for mean or ratio metrics. **Variation** the average value of the metric in the comparison variation.\n\nFor both columns, the raw data in grey underneath shows the numerator and denominator totals.\n\n### Bayesian Engine[​](#bayesian-engine \"Direct link to Bayesian Engine\")\n\n**Chance to Win** tells you the probability that the variation is better. Anything above 95% (a customizable threshold set at the organization level) is highlighted green indicating a very clear winner. Anything below 5% is highlighted red, indicating a very clear loser. Anything in between is grayed out indicating it's inconclusive. If that's the case, there's either no measurable difference or you haven't gathered enough data yet.\n\nFurthermore, we include tooltips for **Risk**, which captures the average loss in a metric if the variation were actually to be worse than control. We use this tooltip to let you know about \"risky\" cases. For example, in cases like in the screenshot above, the chance to win is above 50% for a few metrics, but the average loss if the baseline was actually better is above the risk threshold, indicating that shipping the variation still has substantial risk. More information about risk is available in a tooltip when you mouseover the result:\n\n![Results Tooltip](https://docs.growthbook.io/images/results-tooltip.png)\n\nThe graph and the **% Change** column show you how much better/worse the variation is compared to the baseline. It is a probability density graph and the thicker the area, the more likely the true percent change will be there. As you collect more data, the tails of the graphs will shorten, indicating more certainty around the estimates.\n\n### Frequentist Engine[​](#frequentist-engine \"Direct link to Frequentist Engine\")\n\nIf you select the \"Frequentist\" engine, when you navigate to the results tab to view and update the results, you will see the following results table:\n\n![Results Table (Frequentist)](https://docs.growthbook.io/assets/images/results-table-frequentist-e1b1ec1e35beb85d08b660b7d6766c3d.png)\n\nThe **P-value** column is the probability that the experiment effect for a varitopm would have been observed if the true effect was zero. When the p-value is less than 0.05 (a customizable threshold set at the organization level) and the experiment effect is in the preferred direction, we highlight the cell green, indicating it is a clear winner. When the p-value is less than 0.05 and the experiment effect is _opposite_ the preferred direction, we highlight the cell red, indicating the variant is a clear loser on this metric.\n\nThe graph now represents a 95% confidence interval (or 100\\*(1 - α\\\\alpha)% confidence interval if you have a custom significance threshold other than 0.05).\n\nThe _% Change_ column is unaffected, although we now also represent the width of the confidence interval in grey.\n\n## Guardrails[​](#guardrails \"Direct link to Guardrails\")\n\nIn the new results view (as of GrowthBook 2.4), guardrail metrics are treated much like regular metrics, but they are placed in a separate part of the results view, have an additional tooltip warning if they are trending in the wrong direction, and are not part of any p-value corrections in the frequentist engine (in other words, even with p-value corrections applied, these results will be more sensitive to negative or positive trends).\n\n## Results Table Settings[​](#results-table-settings \"Direct link to Results Table Settings\")\n\nThere are several settings at the top of the results table that allow you to control your results.\n\n### Variations[​](#variations \"Direct link to Variations\")\n\nThis option allows you to filter which variations are shown in the results table, in the case that you have 3+ variations in your experiment.\n\n### Baseline Variation[​](#baseline-variation \"Direct link to Baseline Variation\")\n\nThis option allows you to change which variation is the baseline variation. This is particularly useful in the case when you have one control and two treatment variations. In this case, our result defaults to showing you the statistics comparing each treatment variation versus the baseline variation, but you may want to additionally analyze how the treatment variations compare to one another.\n\nIn that case, you can switch the baseline to be one of the treatment variations to directly compare treatment 1 to treatment 2.\n\n### Difference Types[​](#difference-types \"Direct link to Difference Types\")\n\nA \"difference type\" is the way we measure the difference in variations. There are three difference types that you can select from\"\n\n*   `Relative` - The default, this is the relative change or \"uplift\" of your variation when compared to the baseline. Specifically, the `Relative` change is 100%∗μt−μcμc100\\\\% \\* \\\\frac{\\\\mu\\_t - \\\\mu\\_c}{\\\\mu\\_c} where mutmu\\_t and μc\\\\mu\\_c are the averages in the treatment and baseline variations respectively. Effects here tell you that the average user value in the variation was X% greater than the average user value in treatment. For example, if your metric is Revenue and your baseline average is 10.00 and your variation average is 10.31, then your `Relative` change is 3.1%.\n*   `Absolute` - This is simply the difference in average values across your variations --- μt−μc\\\\mu\\_t - \\\\mu\\_c. This can help you understand the raw difference in average values, e.g. the treatment leads to an increase in revenue of $0.31 per user in the above example.\n*   `Scaled Impact` - This helps you understand the daily total (as opposed to average) effect that your experiment would have had if 100% of users that would have been exposed to your treatment variation had gotten that treatment variation. It is computed as (μt−μc)∗(Nt/pt)∗(1/d)(\\\\mu\\_t - \\\\mu\\_c) \\* (N\\_t / p\\_t) \\* (1 / d), where NtN\\_t is the number of users that are in your treatment variation, ptp\\_t is the percent of all traffic that is in that variation, and dd is the number of days in the current phase used for the results. So if your experiment ran on 10% of traffic for 20 days, with 5% going to the treatment variation, and there were 5,000 users in your treatment variation, the scaled impact would be 0.31∗5,000/0.05/20\\=1,5500.31 \\* 5,000 / 0.05 / 20 = 1,550 dollars per day. This implies that this experiment would have lead to a 1,5501,550 increase in total revenue per day if every user that could have been exposed the variation had been exposed to the variation.\n\nThese difference types can have slightly different statistics because for Relative effects we need to account for the uncertainty in estimating μc\\\\mu\\_c (which forces us to use a delta method derived variance to properly handle). For more details, see the [Statistical Details](https://docs.growthbook.io/statistics/details).\n\nFurthermore, with CUPED enabled, you may find that the changes are not exactly the same as the difference in raw variation averages, due to CUPED adjusting those averages under the hood to reduce variance.\n\n### Dimensions[​](#dimensions \"Direct link to Dimensions\")\n\nDimensions allow you to slice and dice your data, but require additional queries to compute.\n\n#### User or Experiment[​](#user-or-experiment \"Direct link to User or Experiment\")\n\nIf you have defined dimensions for your data source, you can use the **Dimension** dropdown to drill down into your results. For SQL integrations (e.g. non-MixPanel) GrowthBook enforces one dimension per user to prevent statistical bias and to simplify analyses. For more on how GrowthBook picks a dimension when more than one are present for a user, see the [Dimensions documentation](https://docs.growthbook.io/app/dimensions). This is very useful for debugging (e.g. if Safari is down, but the other browsers are fine, you may have an implementation bug) or for better understanding your experiment effects.\n\nBe careful. The more metrics and dimensions you look at, the more likely you are to see a false positive. If you find something that looks surprising, it's often worth a dedicated follow-up experiment to verify that it's real.\n\n#### Date[​](#date \"Direct link to Date\")\n\nThe date dimension shows a time series of the count of users _first_ exposed to an experiment, as well as effects when comparing users _first_ bucketed on each day.\n\nTake the following results, for example.\n\n![Experiment Date Results](https://docs.growthbook.io/images/experiment-date-results.png)\n\nIn the first graph, we see the number of users who were first exposed to the experiment on that day.\n\nIn the second graph, we see the uplift for the two variations relative to the control _for all users first bucketed on that day_. That means that the values on October 7 show that users first exposed to the experiment on October 7 had X% uplift relative to control, when pooling all of the data in their relevant metric window. It does not mean show the difference in conversions across variations on October 7 for all previously bucketed users.\n\nThat analysis, and other time series analyses, are on GrowthBook's roadmap.\n\n## Experiment Health[​](#experiment-health \"Direct link to Experiment Health\")\n\nBy default, GrowthBook runs several health checks on your experiment to help you diagnose if there are any issues with the configuration.\n\nHealth checks appear in two places in the app:\n\n1.  On the results tab -- we insert Experiment Balance and Multiple Exposures warnings for all experiments that might be untrustworthy right into your results tab\n2.  On the health tab -- if you have health traffic queries enabled, we can run additional queries to further dig into any experiment health issues\n\n### Experiment Balance (SRM)[​](#experiment-balance-srm \"Direct link to Experiment Balance (SRM)\")\n\nEvery experiment automatically checks for a Sample Ratio Mismatch (SRM) and will warn you if found. This happens when you expect a certain traffic split (e.g. 50/50) but you see something significantly different (e.g. 46/54). We only show this warning if the p-value is less than `0.001` (customizable in your Organization Settings), which means it's extremely unlikely to occur by chance.\n\n![SRM Warning](data:image/png;base64,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)\n\nLike the warning says, you shouldn't trust the results since they are likely misleading. Instead, find and fix the source of the bug and restart the experiment. You can find more information about potential sources of the problems in our [troubleshooting guide](https://docs.growthbook.io/kb/experiments/troubleshooting-experiments).\n\nUnder the hood, we are conducting a standard chi-squared test for Sample Ratio Mismatch, which compares the distribution of observed units to the expected units and computes a p-value for the probability of observing this traffic split if the traffic split were truly unbiased.\n\n### Multiple Exposures[​](#multiple-exposures \"Direct link to Multiple Exposures\")\n\nThis alert indicates that there a substantial number of users (or other unit) in your experiment that have been exposed to multiple variations. At its core, this means that your Experiment Assignment Query is returning data that has rows that look like the following:\n\n| user\\_id | timestamp | experiment\\_id | variation\\_id |\n| --- | --- | --- | --- |\n| 123 | 2022-08-23-10:53:04 | my-button-test | 0   |\n| 123 | 2022-08-23 10:53:06 | my-button-test | 1   |\n\nThis indicates that for some reason your identifier type (in this case `user_id`) is being tracked with multiple values of `variation_id` and it is impossible to tell which variation to assign to that user. This can happen if:\n\n*   Your SDK is misaligned with GrowthBook's identifier types for some reason. For example, it's possible that the identifier type you're using as the hash attribute in the SDK is different from the one you're firing in the `trackingCallback` to your warehouse. Ensure that the id you're using to hash users is the same one that you see in your data warehouse for a given user.\n*   If you're using something other than GrowthBook for experiment assignment, there are many possible reasons for this issue:\n    *   A bug with the third party solution's hashing algorithm\n    *   A mismatch between the identifier type that you have set up in GrowthBook and the ID that is being used to assign variations in that third-party solution\n    *   A mistaken in your Experiment Assignment Query that is returning the wrong `variation_id` or identifier type for a given experiment.\n\n### Health Tab[​](#health-tab \"Direct link to Health Tab\")\n\ntip\n\nTo get access to the health tab, you need to enable us to run one additional query per experiment analysis. You can do this on a health tab for any experiment if you have the requisite permissions to run queries.\n\nThe health tab provides you with more insights on the traffic to your experiment over time and across dimensions.\n\n![Experiment Health Tab](https://docs.growthbook.io/images/health-tab.png)\n\n**Experiment Traffic** - A plot of experiment units by the first date they were exposed to the experiment. You can look at daily traffic or cumulative traffic. If you have your experiment dimensions configured with pre-defined slices, we will also return traffic splits by dimension in this tab. For example, if you have a `browser` dimension with pre-defined slices, we will show you the traffic splits by browser.\n\n**Experiment Balance Check** - A table with information on the actual number of experiment units, the expected number, and the differences between the percent traffic allocated to each bucket.\n\nWe also provide you with checks by any pre-defined dimension slices you have configured for your experiment dimensions.\n\n#### Adding Dimensions to Health Tab[​](#adding-dimensions-to-health-tab \"Direct link to Adding Dimensions to Health Tab\")\n\nYour health tab shows dimension breakdowns only for Experiment Dimensions which have pre-defined slices.\n\nWhen setting up the health tab, you will be prompted to configure your Experiment Dimensions to have pre-defined slices that can be used in the health tab. This is optional, but we require pre-defined slices for your experiment dimensions to compute dimension traffic and health checks so that we can run only one additional query per analysis and get reliable results.\n\nIf you want to refresh your dimension slices or change your dimension definitions, you should do so via the Data Source page for the related data source. You can read more about that [here](https://docs.growthbook.io/app/dimensions#experiment-dimensions).",
  "title": "Experiments (Results) | GrowthBook Docs",
  "description": "Analyze your experiment results from your data source.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/features/scheduling",
  "markdown": "# Scheduling Features | GrowthBook Docs\n\n![Feature Scheduling](https://docs.growthbook.io/assets/images/feature-scheduling-cf430204529618ffbb61543bdbf6b92c.png)\n\nIf you have a Pro or Enterprise plan, you can schedule features to turn on or off at a specific date and time. This is useful for things like turning features on or off for holidays or special promotions.\n\nScheduling features is currently supported with all override rule types, including force rules, rollout rules, and experiment rules - and just like non-scheduled override rules, they will override the default value when all conditions are met.",
  "title": "Scheduling Features | GrowthBook Docs",
  "description": "Scheduling features flags",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/features/stale-detection",
  "markdown": "# Stale Feature Flag Detection | GrowthBook Docs\n\n## Overview[​](#overview \"Direct link to Overview\")\n\nFeature flags are a crucial part of software development, allowing for controlled rollouts and A/B testing. However, managing these flags, especially in large systems, can be challenging. Over time, some flags may become \"stale\" - no longer actively used or relevant.\n\nStale flags can clutter your system, lead to confusion, and obscure the status of your features. GrowthBook introduces the Stale Feature Flag Detection feature to address this issue, ensuring your feature flag ecosystem remains clean and efficient.\n\n## Why Stale Feature Flag Detection?[​](#why-stale-feature-flag-detection \"Direct link to Why Stale Feature Flag Detection?\")\n\n*   Reduce Clutter: Identifies and flags feature flags that are no longer active, helping to declutter your dashboard.\n    \n*   Improve Clarity: Enhances visibility into which feature flags are currently significant and in use.\n    \n*   Streamline Management: Makes it easier to manage a large number of feature flags, improving operational efficiency.\n    \n\n## Accessing and Using the Feature[​](#accessing-and-using-the-feature \"Direct link to Accessing and Using the Feature\")\n\n### Viewing Stale Flags[​](#viewing-stale-flags \"Direct link to Viewing Stale Flags\")\n\nTo view features that have been marked stale, navigate to the main feature flag table in GrowthBook. Look for the 'Stale' column which indicates whether a flag is considered stale.\n\n![Stale Flag Column](https://docs.growthbook.io/assets/images/stale-ff-01-0989ccff0120dfe772a2c213271f1f31.png)\n\nYou can also navigate to a particular feature and see the stale indicator marked next to the feature name.\n\n![Stale Flag Indicator](https://docs.growthbook.io/assets/images/stale-ff-02-cf6680a12b90f5619de8b3c0f2c0ad7a.png)\n\n### Understanding Stale Status[​](#understanding-stale-status \"Direct link to Understanding Stale Status\")\n\nHover over the Warning icon next to a flagged item.\n\nA tooltip will provide the reason for its staleness, based on the set heuristics.\n\n#### Heuristics Used:[​](#heuristics-used \"Direct link to Heuristics Used:\")\n\nA flag is stale if not updated in two weeks and meets certain criteria (e.g., no active environments, or one-sided rules).\n\n### Toggling Stale Detection:[​](#toggling-stale-detection \"Direct link to Toggling Stale Detection:\")\n\nYou can enable or disable stale detection from the feature details page. From the features table, stale detection can only be disabled.\n\n![Stale Flag Toggle](https://docs.growthbook.io/assets/images/stale-ff-03-57cd68e20eedfe9894f8880f81c8ed5b.gif)\n\nYou can also re-enable stale feature flag detection by navigating to the menu in the top right of the feature details page.\n\n![Stale Flag Toggle](https://docs.growthbook.io/assets/images/stale-ff-04-6d41ad886f26e4bb7286da539fe61430.gif)",
  "title": "Stale Feature Flag Detection | GrowthBook Docs",
  "description": "Overview",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/self-host/proxy",
  "markdown": "# GrowthBook Proxy | GrowthBook Docs\n\nThe GrowthBook Proxy server sits between your application and GrowthBook (both Cloud or Self-hosted instances). It turbocharges your GrowthBook implementation by providing **speed**, **scalability**, **security**, and **real-time** feature rollouts.\n\n## Features[​](#features \"Direct link to Features\")\n\n*   **Caching** - Significantly faster feature lookups!\n    *   In-memory cache plus an optional distributed layer (Redis or MongoDB)\n    *   Automatic cache invalidation when features change in GrowthBook (using WebHooks)\n*   **Streaming** - Updates your application in real-time as features are changed or toggled in GrowthBook (Javascript and React only)\n*   **Remote Evaluation** - Hide your features' business logic in insecure environments\n*   **Security** - Private-key authentication between GrowthBook and GrowthBook Proxy\n*   **Scalability** - Support millions of concurrent users\n\n## Installation[​](#installation \"Direct link to Installation\")\n\n### Using docker-compose[​](#using-docker-compose \"Direct link to Using docker-compose\")\n\nIf you are already using `docker-compose` to run GrowthBook, we have a pre-configured setup that includes a GrowthBook Proxy instance.\n\nJust run\n\n```\ndocker-compose -f docker-compose.proxy.yml up -d\n```\n\nThis will start the proxy server on port 3300. Check `http://localhost:3300/healthcheck` to ensure it's working correctly.\n\n### Standalone[​](#standalone \"Direct link to Standalone\")\n\nYou can also run the GrowthBook Proxy as a standalone Docker container.\n\nFirst, pull the latest image\n\n```\ndocker pull growthbook/proxy:latest\n```\n\nThen, run a GrowthBook Proxy instance on port 3300\n\n```\ndocker run -d -p 3300:3300 \\  -e \"GROWTHBOOK_API_HOST=https://growthbook-api.example.com\" \\  -e \"SECRET_API_KEY=something_secret\" \\  --name gbproxy growthbook/proxy\n```\n\nCheck `http://localhost:3300/healthcheck` to ensure it's running correctly.\n\n### Authentication[​](#authentication \"Direct link to Authentication\")\n\nYou will need to create a \"readonly\" secret API key in GrowthBook by going to **Settings → API Keys** (you can also use a Personal Access Token if preferred). Or you can use a custom `SECRET_API_KEY` of your choosing. Whichever method you choose, this key will be used to authenticate your proxy server with the GrowthBook app.\n\nLastly, for self-hosted customers, add environment variables your main GrowthBook API server to enable the proxy:\n\n```\nPROXY_ENABLED=1PROXY_HOST_PUBLIC=https://growthbook-proxy.example.com# OPTIONAL: You can either create the secret key in the GrowthBook UI or define one here orSECRET_API_KEY=something_secret\n```\n\nNote: Setting `PROXY_HOST_PUBLIC` is not strictly required, but is considered a best practice. Setting it enables faster rollouts by allowing GrowthBook to push updates to your proxy whenever feature definitions change.\n\n### Cloud Customers[​](#cloud-customers \"Direct link to Cloud Customers\")\n\nFor cloud customers who self-host a proxy server, you must configure each SDK Connection to use the proxy server.\n\nYou may optionally enter your proxy server's public host URL. This enables faster rollouts by allowing GrowthBook to push updates to your proxy whenever your feature definitions change. If you do not provide a proxy host URL, your proxy server the proxy will fall back to a pull-based stale-while-revalidate caching strategy.\n\nGo to **SDK Configuration → SDK Connections** in the GrowthBook app to configure the proxy server per each connection.\n\n## Using with the SDKs[​](#using-with-the-sdks \"Direct link to Using with the SDKs\")\n\nThe GrowthBook Proxy has the same public feature endpoints as GrowthBook, so all you need to do is change the API host your SDK clients connect to:\n\n```\n// Beforeconst gb = new GrowthBook({  apiHost: \"https://growthbook-api.example.com\",  clientKey: \"sdk-abc123\"});// After (clientKey remains the same)const gb = new GrowthBook({  apiHost: \"https://growthbook-proxy.example.com\",  clientKey: \"sdk-abc123\"});\n```\n\n## Configuration[​](#configuration \"Direct link to Configuration\")\n\nThe GrowthBook Proxy supports a number of configuration options available via environment variables. Some of the more common options are:\n\n*   `GROWTHBOOK_API_HOST` - Set this to the host and port of your GrowthBook API instance\n*   `SECRET_API_KEY` - Create a secret API key in GrowthBook by going to **Settings → API Keys**\n*   `NODE_ENV` - Set to \"production\" to hide debug and informational log messages\n*   `CACHE_ENGINE` - One of - `memory`, `redis`, or `mongo`\n*   `CACHE_CONNECTION_URL` - The URL of your redis or mongo cluster (if using)\n*   `CACHE_STALE_TTL` - Number of seconds until a cache entry is considered stale\n*   `CACHE_EXPIRES_TTL` - Number of seconds until a cache entry is expired\n\nYou can also configure the GrowthBook Proxy to handle SSL termination. It supports HTTP/2 by default, which is required for high performance streaming.\n\n*   `USE_HTTP2` - Set to \"true\" or \"1\" to enable\n*   `HTTPS_CERT` - The SSL certificate\n*   `HTTPS_KEY` - The SSL key\n\nFor more complete configuration documentation, please see the GrowthBook Proxy GitHub page: [https://github.com/growthbook/growthbook-proxy](https://github.com/growthbook/growthbook-proxy)\n\n## Best Practices[​](#best-practices \"Direct link to Best Practices\")\n\nIn high-traffic production scenarios, there are a few best practices to follow\n\n*   Auto-scale GrowthBook Proxy instances based on number of active connections or memory\n*   Run the instances in the same region as your application servers for the lowest latency\n*   Add a load balancer in-front that supports HTTP/2 and streaming responses (AWS ALB, HAProxy, etc.)\n*   Use Redis (or MongoDB) as the cache engine for more consistent feature releases\n*   Use the `/healthcheck` endpoint to determine if the instances are running correctly",
  "title": "GrowthBook Proxy | GrowthBook Docs",
  "description": "Turbocharge your GrowthBook deployment with the GrowthBook Proxy server",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/features/features/approval-flows",
  "markdown": "# Approval Flows | GrowthBook Docs\n\nnote\n\nApproval Flows is a GrowthBook Enterprise feature.\n\nWith Approval flows, you can require approval before publishing any change to an existing feature flag. Approval flows help reduce errors by making sure changes to features have been viewed and approved by someone else in your organization.\n\n## Settings page[​](#settings-page \"Direct link to Settings page\")\n\nApproval flows can be enabled for your organization on the settings page. You are able to select the environments which require approvals, or leave the field blank to require approvals on all environments. If you would like to force reset the review when a change is made after it is approved, toggle on the `Reset review on changes`.\n\n![approvals-org-settings.png](https://docs.growthbook.io/assets/images/approvals-org-settings-df2393063873a78f353add8422b9cf44.png)\n\n## Approval Flow[​](#approval-flow \"Direct link to Approval Flow\")\n\n### Draft[​](#draft \"Direct link to Draft\")\n\nA Draft is created whenever you make changes to an existing Feature and save it. If you have not turned on approval flows, you can directly publish your changes. When you turn on Approval Flows for Features, you have to request a review before publishing changes.\n\n![approvals-approve-flow-1.png](https://docs.growthbook.io/assets/images/approvals-approve-flow-1-5305e4a237f3b9abe1dd954a914da84d.png)\n\n### Requesting a Review[​](#requesting-a-review \"Direct link to Requesting a Review\")\n\nRequesting a review is changing the status on your draft to tell other people in your organization that your feature is ready to publish and you need someone to review to ensure that you have no errors before publishing. Before requesting a review, make sure that you add a detailed comment describing the changes that you have made so everyone can understand the intent of your request.\n\nWhen a request is made it will show up in the Drafts tab on your Features overview page. The status will be set to `Pending Review` when you have requested a review. You will be able to sort by date updated to see your newly requested change at the top of the list.\n\n![approvals-see-list.png](https://docs.growthbook.io/assets/images/approvals-see-list-dafbc526ea4d50f43dc12286eabf3350.png)\n\n### Reviewing[​](#reviewing \"Direct link to Reviewing\")\n\nAnyone that has the ability to \"Edit\" or \"Add\" a Feature Flag (see [Permissions](https://docs.growthbook.io/account/user-permissions)) can serve as a reviewer, besides the user who created the request.\n\nAfter clicking on the feature, you will be able to open the review modal by clicking `Review and Approve`.\n\n![approvals-approve-flow-4.5-request.png](https://docs.growthbook.io/assets/images/approvals-approve-flow-4.5-request-30d44e20d8012b4a150b587193e490bd.png)\n\nFrom here, you can see the diff between the currently published changes as well as the comments.\n\n![approvals-approve-flow-3-review.png](https://docs.growthbook.io/assets/images/approvals-approve-flow-3-review-09dabf255ad3512807442f44a1db2bcc.png)\n\nAfter clicking next you are able to write your review in the comment box and select the correct status you want. The statuses are:\n\n*   `Comment` - which is mainly used if you are wanting to say something without reviewing the changes\n*   `Request Changes` - use this status if you think that there needs to be changes made\n*   `Approve` - if everything look correct\n\n![approvals-approve-flow-4.png](https://docs.growthbook.io/assets/images/approvals-approve-flow-4-ddabc5c40ac5eb6e26270a437ff88ea6.png)\n\nOnce the changes are `Approved`, the changes will be able to be published.\n\n![approvals-approve-flow-3.5.png](https://docs.growthbook.io/assets/images/approvals-approve-flow-3.5-84410c8bccaad5b5d15ed6d94c6b73d3.png)\n\n### Publishing[​](#publishing \"Direct link to Publishing\")\n\nAny one with permission to Add or Edit Feature flags will be able to publish the changes once they are marked as `Approved`. Admins are able to publish features without requiring a review, by clicking the box at the top of the modal to bypass the review.\n\n![approvals-approve-flow-5.5.png](https://docs.growthbook.io/assets/images/approvals-approve-flow-5.5-816de85fe09f95ea97c7679479bce648.png)\n\nOnce the changes are published you'll see a green bar indicating that the version is live.\n\n![approvals-approve-flow-5-done.png](https://docs.growthbook.io/assets/images/approvals-approve-flow-5-done-7bb3c0e7eb7457da24521f2fda0cde5a.png)",
  "title": "Approval Flows | GrowthBook Docs",
  "description": "Learn about how Approval flows work on feature flags",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/app/url-redirects",
  "markdown": "# URL Redirect Testing | GrowthBook Docs\n\nURL Redirect tests are an alternative to using the Visual Editor and are ideal for testing big changes or complete page redesigns.\n\nURL Redirects require a Pro or Enterprise GrowthBook license.\n\n## How it Works[​](#how-it-works \"Direct link to How it Works\")\n\nYou start by specifying an \"Original URL\". Users who visit this URL will be included in the experiment (assuming they meet all of the other targeting conditions).\n\nYou then specify \"Destination URLs\" for each of your variations. You can also turn off redirects for some of your variations if you want to keep the user on the Original URL.\n\nWhen a user visits the Original URL and is included in the experiment, they will be assigned a variation. Then, an \"Experiment Viewed\" event will be sent to your data warehouse. After a short delay (default `100ms`) to allow for the tracking event to finish, the user will be redirected to the destination URL.\n\n## Implementation[​](#implementation \"Direct link to Implementation\")\n\nURL Redirect tests require you to integrate one of our [SDKs](https://docs.growthbook.io/lib) into your application. Currently, URL Redirect tests are only supported in our [Script Tag](https://docs.growthbook.io/lib/script-tag), [Javascript](https://docs.growthbook.io/lib/js), and [ReactJS](https://docs.growthbook.io/lib/js) SDKs. Support for other SDKs are coming soon.\n\n### HTML Script Tag[​](#html-script-tag \"Direct link to HTML Script Tag\")\n\nThe easiest option is to use our [Script Tag](https://docs.growthbook.io/lib/script-tag) SDK. This involves adding a single `<script>` tag to the HEAD of your website. This option fully works out-of-the-box with no configuration required.\n\n### Client-Side JavaScript and React[​](#client-side-javascript-and-react \"Direct link to Client-Side JavaScript and React\")\n\nA more advanced integration involves using our [Javascript](https://docs.growthbook.io/lib/js) or [ReactJS](https://docs.growthbook.io/lib/js) client-side SDKs.\n\nBesides the standard implementation described in the SDK docs, there are 4 additional settings that control the redirect behavior.\n\n*   `navigate` - a callback function to perform the redirect. Defaults to `(url) => window.location.replace(url)`.\n*   `navigateDelay` - the number of milliseconds to wait before redirecting. Use this to give time for your analytics tracking callback to finish. Defaults to `100`\n*   `antiFlicker` - If `true`, a white screen will be shown while the redirect is happening to avoid the user seeing a \"flicker\". Defaults to `false`.\n*   `antiFlickerTimeout` - the maximum number of milliseconds that the anti-flicker white screen will be shown. Defaults to `3500` (3.5 seconds).\n\n#### Single Page Apps (SPAs)[​](#single-page-apps-spas \"Direct link to Single Page Apps (SPAs)\")\n\nIf you have a Single Page App (SPA), it's recommended to use your own `navigate` function to avoid doing full-page redirects. In this case, you also want to set `navigateDelay` to 0. Here's an example in Next.js\n\n```\nimport router from \"next/router\";const gb = new GrowthBook({    navigate: (url) => router.replace(url),    navigateDelay: 0,    // ... other settings});\n```\n\nIt's also super important to update the URL in the GrowthBook instance on every client-side navigation. For example:\n\n```\nrouter.events.on(\"routeChangeComplete\", (url) => {    gb.setURL(url);})\n```\n\n### Node.js / Edge Workers\n\nbeta\n\n[​](#nodejs--edge-workers-beta \"Direct link to nodejs--edge-workers-beta\")\n\nIt's possible to use our [Javascript](https://docs.growthbook.io/lib/js) SDK to perform redirects on the back-end as well, in either a Node.js application or in an edge worker.\n\nReach out to us on Slack or at [hello@growthbook.io](mailto:hello@growthbook.io) if you're interested in helping us beta test this and we can help you get set up.",
  "title": "URL Redirect Testing | GrowthBook Docs",
  "description": "Easily A/B test multiple versions of a page without writing code",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/app/making-experiment-changes",
  "markdown": "# Making Changes to Experiments | GrowthBook Docs\n\nWe allow you make changes to an experiment's targeting while it is running. This is especially useful if you want to start running on a small percent of traffic and then gradually ramp up exposure. To make a change to a running experiment, click the \"Make Changes\" button on the top of the experiment page.\n\nYou will then be asked what sort of change you want to make, with options ranging from targeting changes to traffic and variation weight changes. You may also make multiple changes at once by choosing \"advanced\".\n\nBased on what you are changing, we will provide a list of possible release plans for that change and provide a recommended plan to use. The UI should guide you to make the correct recommended choice in most cases, but you are able to change this if desired.\n\nWhen changing a **single targeting or traffic setting**, your release plan options may include:\n\n*   New phase, re-randomize traffic\n*   Same phase, apply changes to everyone\n*   Same phase, apply changes to new traffic only (Sticky Bucketing enabled only)\n\nNote that potentially unsafe options per your specific changes may be removed (often \"Same phase\" options are unsafe for certain types of changes).\n\nWhen using **\"advanced\"** to make multiple targeting or traffic changes at once, all above options will be made available (including potentially unsafe ones), as well as an additional option:\n\n*   New Phase, re-randomize traffic, block bucketed users (Sticky Bucketing enabled only)\n\nIf you are not making targeting or traffic changes and simply want to **start a new phase**, the release plan options will be:\n\n*   New phase, re-randomize traffic\n*   New phase, do not re-randomize\n\n## Update the existing phase[​](#update-the-existing-phase \"Direct link to Update the existing phase\")\n\nThis modifies the experiment in-place without resetting results or re-randomizing users. This provides the best user experience for your users and you can re-use data that was already collected, which can reduce the time the experiment needs to run.\n\nHowever, if you're not careful, this can introduce significant bias and data quality issues into your results. A few categories of changes are broadly considered \"safe\" and if you are only making these changes, this is the approach we recommend going with. The \"safe\" changes are:\n\n*   Increasing the percent of people included in the experiment\n*   Removing a condition from an experiment (e.g. going from \"US visitors only\" to \"All visitors\")\n*   Removing an experiment from a namespace\n\nAll of these changes have something in common - they are simply increasing the number of users exposed to the experiment. There is no effect on existing users in the experiment.\n\nIf you have Sticky Bucketing enabled, you may also elect to apply changes to new traffic only, leaving already-bucketed users in their existing (sticky) buckets. An example of this scenario could be decreasing the percent of people included in the experiment for all new incoming users, but leaving existing users in their existing buckets.\n\n## Start a new phase[​](#start-a-new-phase \"Direct link to Start a new phase\")\n\nThis creates a brand new phase of the experiment. All data collected until this point is excluded from the analysis and you start fresh (nothing is deleted from your data warehouse, we just hide old data from the results).\n\nIn most cases, you will also want to re-randomize traffic. This will cause everyone - including existing experiment users - to get assigned a new random variation. This can be a disruptive user experience since many people will switch from Control to Treatment (or vice versa).\n\nWhy would you ever want to do this? Some changes you make completely invalidate past results so this lets you cleanly separate the data analysis from before and after you make the change. Re-randomizing traffic can also eliminate [carryover bias](https://docs.growthbook.io/kb/experiments/carryover-bias) and make your results more reliable and accurate.\n\nWe recommend this approach for any change that is not considered \"safe\" (listed above). This can include (but not limited to):\n\n*   Changing the traffic split (weights) between variations\n*   Adding a new targeting condition\n*   Decreasing the percent of people included\n\nBecause of how disruptive this can be, it's best to plan ahead before starting an experiment. It's better to start with more conservative targeting and scale up than the reverse (starting big and scaling back).\n\nAs before, if you have Sticky Bucketing enabled, you have some additional options about how to treat already-bucketed users. By default when starting a new phase, these bucketed users will be reassigned (their sticky bucket will be cleared). You may instead choose to block these users from the experiment going forward (in which case they will still see the control). This strategy is only available in the \"advanced\" mode.",
  "title": "Making Changes to Experiments | GrowthBook Docs",
  "description": "Make targeting and rollout changes to a running experiment",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/app/sticky-bucketing",
  "markdown": "# Sticky Bucketing | GrowthBook Docs\n\nThis article serves two purposes:\n\n*   High level overview of GrowthBook's Sticky Bucketing feature\n*   Technical details on how to implement Sticky Bucketing in your codebase\n\nSticky bucketing ensures users continue to see the same variation when you make changes to a running experiment. GrowthBook's flavor of sticky bucketing has a few additional features:(1) Bucketing based on either a primary hash attribute (i.e. user id) or a secondary attribute (i.e. anonymous id) and (2) the ability to version-control and purge your users' assigned buckets.\n\n## Motivation[​](#motivation \"Direct link to Motivation\")\n\nSo why would you want to use Sticky Bucketing? Let's look at a few examples:\n\n1.  You are managing an experiment rollout and need to slow down enrollment. You decrease the percentage of traffic exposed to the experiment from 50% to 10% but you do not want to alter the experience for users who were already exposed to the experiment. Sticky bucketing allows you to apply the rollout percentage to new users while keeping the old users in their original buckets.\n    \n2.  You discovered a bug in your experiment the day after launching. You fix the bug and want to re-start the experiment, but don't want to include any \"tainted\" users who saw the buggy version since their negative experience might impact the results.\n    \n3.  Your have a cross-platform app and want to ensure a consistent experience as users log in and move between devices.\n    \n\nnote\n\nSticky Bucketing is a GrowthBook Pro and Enterprise feature.\n\n## Setting up Sticky Bucketing[​](#setting-up-sticky-bucketing \"Direct link to Setting up Sticky Bucketing\")\n\nTo use Sticky Bucketing for your experiments, there are a few steps that you need to complete.\n\n### 1\\. Ensure you are using a compatible SDK version[​](#1-ensure-you-are-using-a-compatible-sdk-version \"Direct link to 1. Ensure you are using a compatible SDK version\")\n\nUpdate your codebase to use a compatible SDK. Sticky Bucketing is currently supported in the following SDK versions:\n\n*   Javascript: `0.32.0`\n*   React: `0.22.0`\n\n### 2\\. Pass a Sticky Bucketing Service into your SDK Implementation[​](#2-pass-a-sticky-bucketing-service-into-your-sdk-implementation \"Direct link to 2. Pass a Sticky Bucketing Service into your SDK Implementation\")\n\nYou may use one of our built-in Sticky Bucketing Services or implement your own. We provide common drivers for browser-generated cookies, backend-generated cookies, browser LocalStorage, and Redis stores.\n\nFor more information about setting up Sticky Bucketing at the SDK level, see the appropriate SDK documentation. For instance, see the [Javascript SDK - Sticky Bucketing documentation](https://docs.growthbook.io/lib/js#sticky-bucketing) for more information about setting up Sticky Bucketing in the Javascript SDK.\n\n### 3\\. Update your SDK Connections in the GrowthBook app[​](#3-update-your-sdk-connections-in-the-growthbook-app \"Direct link to 3. Update your SDK Connections in the GrowthBook app\")\n\nWithin the GrowthBook app, ensure that your SDK Connections are configured correctly. You can do this by going to the **SDK Connections** page, clicking into a connection, and clicking the **Edit** button in the top right.\n\nMake sure the connection (1) only has a single language selected and (2) has the correct SDK version specified.\n\n![Setting the SDK Connection Version](https://docs.growthbook.io/assets/images/sdk-connection-version-sb-34f8a06a7b027e265de5eeb898c2a2e2.png)\n\nIn the above example, React is selected and the version is set to the latest `0.22.0`, which supports sticky bucketing.\n\nIf you are using GrowthBook with multiple languages, create a separate SDK Connection for each language.\n\n### 4\\. Enable Sticky Bucketing for your organization[​](#4-enable-sticky-bucketing-for-your-organization \"Direct link to 4. Enable Sticky Bucketing for your organization\")\n\nIn the GrowthBook app, go to **Settings** → **General** → **Experiment Settings** and enable the Sticky Bucketing toggle. This will add new options specific to Sticky Bucketing whenever you make changes to a running experiment. To read more about these options, see [Experiments (setup)](https://docs.growthbook.io/app/experiment-configuration).\n\nOnce Sticky Bucketing is enabled, there is an additional toggle for enabling a **Fallback Attribute**. See below for more information on this feature.\n\n## Fallback Attribute[​](#fallback-attribute \"Direct link to Fallback Attribute\")\n\nUsers are assigned an experiment variation based on a **Hash Attribute**, for example a logged-in `userId`. With Sticky Bucketing, you also have the option of specifying a **Fallback Attribute** for an experiment, for example an anonymous `cookieId`. This fallback will be used if the primary hash attribute is missing or empty.\n\n### Fallback Attribute Example[​](#fallback-attribute-example \"Direct link to Fallback Attribute Example\")\n\nImagine your users tend to sign in on multiple devices. Let's say you want to test changes to the main navigation header of your app, something that is visible to both logged-in and anonymous visitors.\n\nIf you were to only use `userId` to assign variations, signing in could become a jarring experience - users might flip from seeing the control (since their user id is empty) to seeing the variation (once they log in). On the plus side, if users open your app on multiple devices (when logged in), they will always see a consistent experience.\n\nIf instead, you were to only use the anonymous `cookieId` to assign variations, it solves the issue where the UI flips during sign in (since the anonymous id stays the same before and after), but now switching devices could become a jarring experience - the same user might get assigned different variations on different devices, since each device would have its own separate anonymous id.\n\nFallback attributes, when implemented properly with sticky bucketing, lets you have the best of both worlds (with some caveats). Your primary hashing attribute would be the logged-in `userId` and your fallback attribute would be the anonymous `cookieId`.\n\nThe very first variation a user is assigned to will \"stick\" to them and follow them across devices. So if a visitor lands on your website, gets assigned variation B (from their fallback attribute), and then logs in, they will continue seeing variation B, even though they now have a `userId` attribute. If that same user then logs into your app on a new device, they again will continue seeing variation B.\n\nThere are 2 caveats with fallback attributes:\n\n1.  There are still some scenarios where users will get inconsistent experiences. For example, if they are logged out on two devices, there's no way for us to know they are the same person.\n2.  It opens you up to potential bias in your experiment results (see more below).\n\n### Bias Risk[​](#bias-risk \"Direct link to Bias Risk\")\n\nTo understand the risk of bias, lets focus on a user switching devices. During analysis, we will have to use the anonymous `cookieId` as the experimental unit to make sure we capture everyone in the experiment, even those who never logged in. When a user logs in on two devices, they will be seen as two separate \"users\" in the analysis since each device has its own cookie id. Because of the fallback attribute and sticky bucketing, however, they will both get assigned the same variation. This breaks one of the statistical assumptions of A/B testing - that each user is randomly assigned a variation. Let's see how this might play out to cause bias in your results.\n\nImagine your variation causes people to use multiple devices more often than your control does. 200 people land on your website and get split into control and variation - 100 in each. In the control, 20 of them also log in on their phone, but in the variation 60 of them log in on their phone. In your analysis, you have 280 total anonymous ids and you expect them to be split evenly - 140 each. In reality, the control would have 120 ids while the variation has 160. A difference this extreme is easy to spot in the results (GrowthBook runs Sample Ratio Mismatch tests automatically to catch exactly this type of bug), however there are many similar, but more subtle, issues that may fly under the radar.\n\nBottom line: with Fallback Attributes, you can get a more consistent within-session and cross-device user experience at the expense of statistical rigor. With GrowthBook, we let you decide this trade-off for yourself on a per-experiment basis.\n\n## Example Sticky Bucket Implementations[​](#example-sticky-bucket-implementations \"Direct link to Example Sticky Bucket Implementations\")\n\n### Front-end only[​](#front-end-only \"Direct link to Front-end only\")\n\nSuppose your website integrates GrowthBook on the front end only. You would like to implement Sticky Bucketing to protect against variation hopping should targeting or rollout rules change in the future.\n\nIn our JavaScript and React SDKs, we provide 2 different Sticky Bucket Services that make sense in this scenario: `LocalStorageStickyBucketService` and `BrowserCookieStickyBucketService`. You can instantiate either of these services and plug them into the GrowthBook SDK.\n\n### Front-end and Back-end (Node.js)[​](#front-end-and-back-end-nodejs \"Direct link to Front-end and Back-end (Node.js)\")\n\nLet's expand the \"front-end only\" example above so that our back-end controllers also integrate with GrowthBook and can reference the same experiments. In this scenario, we would like both the front-end and back-end to perform bucketing and persist a sticky bucket that reliably crosses the front-end / back-end divide.\n\nOn the front end, you will want to use the `BrowserCookieStickyBucketService` because cookies are easily transportable to and from the back end. Then, assuming we are using an Express (NodeJS) server, we would use the `ExpressCookieStickyBucketService` on the back end. Importantly, if customizing the cookie name, you must ensure that the same name prefix is chosen for both the front-end and back-end cookies.\n\n### Back-end only[​](#back-end-only \"Direct link to Back-end only\")\n\nSuppose that in a server-side context we are interested in persisting a user's bucket both across multiple requests and across other back-end (micro)services that may not have direct access to the incoming user request nor their cookies.\n\nWe could use a Redis instance inside our network and read/write to that for sticky bucket storage. In a NodeJS context, we could use the `RedisStickyBucketService` and pass in an `ioredis` client.\n\n### Hybrid and custom implementations[​](#hybrid-and-custom-implementations \"Direct link to Hybrid and custom implementations\")\n\nYou may wish to employ multiple strategies at once (front-end, back-end, Redis) or write your own sticky bucket connector for a SQL server or DynamoDB cluster. You could write your own custom sticky bucket connector by implementing the `StickyBucketService` interface. Within your connector, you could do things like:\n\n*   Connect to SQL server for sticky bucket reads/writes\n*   GET/POST/RPC to a custom bucketing microservice\n*   Wrap both the `ExpressCookieStickyBucketService` and `RedisStickyBucketService` within your custom service's getter and setter methods\n*   Trigger side effects on bucket reads/writes",
  "title": "Sticky Bucketing | GrowthBook Docs",
  "description": "Ensure users continue to see the same variation when you make changes to a running experiment",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/features/code-references",
  "markdown": "# Code References | GrowthBook Docs\n\n## Overview[​](#overview \"Direct link to Overview\")\n\nCode References allows teams to quickly see instances of feature flags being leveraged in their codebase. By scanning customers’ code bases via a CLI tool and sending results to our application backend, GrowthBook can help surface valuable information such as flagging stale feature flags more accurately, and directing devs to the exact lines of code that need to be cleaned up.\n\n## Getting Started[​](#getting-started \"Direct link to Getting Started\")\n\nFor GitHub users, we provide a streamlined GitHub Action that is easy-to-set up and geting with code references.\n\n*   [GrowthBook Code References GitHub Action](https://github.com/marketplace/actions/growthbook-code-references)\n\nFor non-GitHub users, we provide all the tools you need to get set up with code references with your platform of choice.\n\n*   [Growthbook gb-find-code-refs CLI utility](https://github.com/growthbook/gb-find-code-refs)\n*   [Dockerized version of gb-find-code-refs](https://hub.docker.com/r/growthbook/gb-find-code-refs)\n\n## Enabling Code References in GrowthBook[​](#enabling-code-references-in-growthbook \"Direct link to Enabling Code References in GrowthBook\")\n\nTo enable code references, navigate to your General Settings page, and scroll to **Configure Code References**. You can enable code references here, and access relevant docs to help get set up.\n\n### Branch filtering[​](#branch-filtering \"Direct link to Branch filtering\")\n\nWe provide the option to explicitly specify branch names (comma-separated) to show code references for. By default, we will display all code references received for any branch.\n\nFor example, if your team only needed to see code references from branches `main` and `qa`, this option would be set to `main, qa`.\n\n### Platform links[​](#platform-links \"Direct link to Platform links\")\n\nWe provide direct links to your codebase hosted on either GitHub or GitLab. Use this option to select which platform you use and code references in the app will automatically provide external links to your codebase.\n\nIf you don't see your platform supported, please let us know in the [Slack community](https://slack.growthbook.io/?ref=coderefs)!\n\n## Viewing Code References[​](#viewing-code-references \"Direct link to Viewing Code References\")\n\nOnce enabled, you can view Code References on a specific feature page, under the Code Refs tab.",
  "title": "Code References | GrowthBook Docs",
  "description": "Overview",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/warehouses/athena",
  "markdown": "# Setting up Athena as a data source\n\nSetting up Athena as your datasource requires you set up the proper permissions within AWS for Growthbook to access and then provide the correct credentials to Growthbook make use of those permissions. There are also optional connection data that will help Growthbook create the correct default sql to analyze your data.\n\n## Setting up Permissions in AWS[​](#setting-up-permissions-in-aws \"Direct link to Setting up Permissions in AWS\")\n\nUnlike other database engines with their own user management system, Athena uses IAM for authentication.\n\n### Growthbook Cloud[​](#growthbook-cloud \"Direct link to Growthbook Cloud\")\n\nWe recommend creating a new IAM user with readonly permissions for GrowthBook.\n\nThe managed [AWSQuicksightAthenaAccess](https://docs.aws.amazon.com/athena/latest/ug/managed-policies.html) is a good starting point. You will also need to give it permission to read from the s3 tables that hold your event data, by taking a modified version of `AmazonS3ReadOnlyAccess` policy whose resources are confined to only those tables that hold your event data. For example with the following policy after replacing the `<BUCKET NAME>`:\n\n```\n{    \"Version\": \"2012-10-17\",    \"Statement\": [        {            \"Effect\": \"Allow\",            \"Action\": [                \"s3:Get*\",                \"s3:List*\",                \"s3-object-lambda:Get*\",                \"s3-object-lambda:List*\"            ],            \"Resource\": [                \"arn:aws:s3:::<BUCKET NAME>*\"            ],        }    ]}\n```\n\nIdeally that bucket should only have event data that growthbook needs to calculated its metrics and no other data. You can futher restrict the resources as your security policy requires.\n\nAfterwards your IAM user's permission page might look like:\n\n![Athena permissions](https://docs.growthbook.io/images/guides/athena-permissions.png)\n\n### Self hosted[​](#self-hosted \"Direct link to Self hosted\")\n\nWe recommend creating a new IAM role with the same permissions as for Growthbook Cloud. This role can then be [attached to the ec2 instance](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html#attach-iam-role) that is running Growthbook.\n\n## Providing Credentials to Growthbook[​](#providing-credentials-to-growthbook \"Direct link to Providing Credentials to Growthbook\")\n\n### Growthbook Cloud[​](#growthbook-cloud-1 \"Direct link to Growthbook Cloud\")\n\nIf you are using Growthbook Cloud you will need to create an IAM user that has the above policies attached - either directly or through a group.\n\nYou must then create an access key by clicking on Security Credentials then \"Create Access Key\". You can then choose \"Third-party service\". It will warn you that this is not best practice, but unfortunately this is the only way to give Growthbook access at the moment. We are working on other ways to connect in the future. You can then confirm and click next. You can add a tag if you like and then press \"Create access key\". You should see then see following screen:\n\n![Athena permissions](https://docs.growthbook.io/images/guides/athena-keys1.png)\n\nIn another browser tab open up Growthbook Data Sources tab and choose your event tracker. Select Athena as your data source type. You can then copy the Access Key and Secret Access Key from the AWS browser tab to their corresponding fields.\n\n### Self hosting[​](#self-hosting \"Direct link to Self hosting\")\n\nIf you are self hosting then in addition to the method above you can also pass the credentials in via environmental variables or part of the instance metadata. You can select which method you want in the `Authentication Method` field.\n\n## Remaining Configuration[​](#remaining-configuration \"Direct link to Remaining Configuration\")\n\n`AWS Region` - This should be the AWS Region your Athena database is in. From the AWS console you would see it on the right side of the search bar on the top of the screen next to the account name.\n\n`Workgroup` - This is the workgroup within Athena.\n\n`Default Catalog` - This is that catalog where the event data lives.\n\n`Default Database` - This is the database where the event data lives.\n\n![Extra Fields in Growthbook for setting up Athena](https://docs.growthbook.io/images/guides/athena-extra-fields.png)\n\n`S3 Results URL` - This is the s3 URL where the results to Athena queries get saved. When setting up Athena for the S3 results url, we recommend naming your bucket with the prefix `aws-athena-query-results-` as the AWSQuicksightAthenaAccess gives permission to write to any bucket with this prefix. If Growthbook warns you that it can not write to an s3 location other than the one you select here it is most likely because you have set the [workgroup to override client side settings](https://docs.aws.amazon.com/athena/latest/ug/workgroups-settings-override.html). If that is the case you would either need to change that setting or add the permissions for growthbook to also write to the s3 results url saved there.",
  "title": "Setting up Athena as a data source | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your Athena database to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/guide/bigquery",
  "markdown": "# GrowthBook and BigQuery | GrowthBook Docs\n\n## Configuring GrowthBook to work with BigQuery\n\nThis document outlines the steps needed to add your BigQuery database to GrowthBook.\n\n## 1\\. Create a service account for GrowthBook[​](#1-create-a-service-account-for-growthbook \"Direct link to 1. Create a service account for GrowthBook\")\n\nWithin your [Google Cloud console account](https://console.cloud.google.com/iam-admin/serviceaccounts), create a service account for GrowthBook to use\n\n![Create a new service account in BigQuery](https://docs.growthbook.io/images/guides/bigquery-1-addserviceaccount-for-gb-highlited.png) ![Create a new service account in BigQuery](https://docs.growthbook.io/images/guides/bigquery-2-addserviceaccount-for-gb3.png)\n\nCreate a service account name and account ID. On the next page you need to add 3 specific roles:\n\n![Create a new service account in BigQuery](https://docs.growthbook.io/images/guides/bigquery-3-addserviceaccount-for-gb4-roles.png)\n\nOn the Grant page, add the following three permissions roles for read-only access:\n\n*   BigQuery Data Viewer\n*   BigQuery Metadata Viewer\n*   BigQuery Job User\n\n![Create a new service account in BigQuery](https://docs.growthbook.io/images/guides/bigquery-4-addserviceaccount-for-gb5-roles.png)\n\nOn the final page when creating a service account, you can skip the optional fields.\n\nYou should see the new service account listed, without a `Key ID`. We need to add an access key to this account so the credentials can be added to GrowthBook. Click on actions, and select `Manage Keys`.\n\n![Create a new service account in BigQuery](https://docs.growthbook.io/images/guides/bigquery-5-getjson-key.png)\n\nThere are two ways to provide credentials to GrowthBook:\n\n*   Auto-discovery from environment variables or GCP metadata (only available when self-hosting)\n*   Upload a JSON key file for the service account\n\nWe're going to show how to do the JSON key file method. On the keys page, add a new key, and select JSON.\n\n![Get json key for service account](https://docs.growthbook.io/images/guides/bigquery-6-getjson-key2.png) ![Get json key for service account](https://docs.growthbook.io/images/guides/bigquery-6-getjson-key3.png)\n\nThis will cause the JSON key to be downloaded to your computer.\n\n## 2\\. Connect GrowthBook to BigQuery[​](#2-connect-growthbook-to-bigquery \"Direct link to 2. Connect GrowthBook to BigQuery\")\n\nFrom the Metrics and Data → Data Source page, click on add new data source and select the event tracker you're using. If your event tracker is not listed, or you're using something custom, click on the \"Custom\" button at the bottom.\n\nSelecting an event tracker here will pre-populate the experiment exposure query which is need to determine which user saw which experiment variation. Depending on your needs, you may still need to adjust these queries to match your specific schema.\n\n![Add BigQuery to GrowthBook](https://docs.growthbook.io/images/guides/bigquery-7-add-datasource1.png)\n\nSelect BigQuery as the data source type.\n\n![Add BigQuery to GrowthBook](https://docs.growthbook.io/images/guides/bigquery-7-add-datasource2.png)\n\nAdd the names you'd like to use, and select the JSON key file that was downloaded earlier.\n\nGrowthbook will use the `Project Id` and `Dataset` you enter as the default ones when creating queries. You can get the value for these fields from the [Google Cloud explorer](https://console.cloud.google.com/bigquery). You will see the top level project id, and when expanded, find the dataset which has your experiment exposure table (which will be `experiment_viewed` if you use Segment or Rudderstack).\n\n![Get default project id and default dataset](https://docs.growthbook.io/images/guides/bigquery-8-getdefault-names.png)\n\nWhen you click save, GrowthBook will test the connection to make sure the credentials are correct. If the connection is successful, you should see a success message on the next page.\n\n## Enabling Data Pipeline Mode (Enterprise)[​](#enabling-data-pipeline-mode-enterprise \"Direct link to Enabling Data Pipeline Mode (Enterprise)\")\n\nEnterprise customers can enable pipeline mode, which can reduce query costs if you grant the GrowthBook service account write permissions in your data warehouse.\n\n[More details can be found here.](https://docs.growthbook.io/app/data-pipeline)\n\n## Monitoring GrowthBook query cost[​](#monitoring-growthbook-query-cost \"Direct link to Monitoring GrowthBook query cost\")\n\nWhenever we query your BigQuery database we add `{ integration: \"growthbook\" }` as a label to the query job to make it easy for you to monitor cost or filter GrowthBook query jobs by label for other use cases.\n\nRead more about how to [group by label value for a specific key here.](https://cloud.google.com/billing/docs/how-to/bq-examples#group_by_label_value_for_a_specific_key)",
  "title": "GrowthBook and BigQuery | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your BigQuery database to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/warehouses/clickhouse",
  "markdown": "# Setting up Clickhouse as a data source\n\nConnecting to Clickhouse is very straightforward. You just need to provide the connection string and credentials. If you are using something like Clickhouse Cloud, you can find the connection string in the UI.\n\n![](https://docs.growthbook.io/images/guides/guide-clickhouse-1.png)\n\nIf you are making connection credentials just for GrowthBook, you can give it read-only access to the database.\n\nIf you are using GrowthBook Cloud (app.growthbook.io), make sure to whitelist the ip address 52.70.79.40 if applicable.",
  "title": "Setting up Clickhouse as a data source | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your Clickhouse database to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/js",
  "markdown": "# Javascript SDK | GrowthBook Docs\n\nSupports both browser and NodeJS environments.\n\n## Installation[​](#installation \"Direct link to Installation\")\n\nInstall with a package manager\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save @growthbook/growthbook\n```\n\n## Quick Usage[​](#quick-usage \"Direct link to Quick Usage\")\n\n### Step 1: Configure your app[​](#step-1-configure-your-app \"Direct link to Step 1: Configure your app\")\n\n```\nimport { GrowthBook } from \"@growthbook/growthbook\";// Create a GrowthBook instanceconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  // Targeting attributes  attributes: {    id: \"123\",    country: \"US\"  },  // Only required for A/B testing  // Called every time a user is put into an experiment  trackingCallback: (experiment, result) => {    console.log(\"Experiment Viewed\", {      experimentId: experiment.key,      variationId: result.key,    });  },});// Download features and experiments from the CDN// Also, start running any Visual Editor or URL Redirect experimentsawait gb.init();\n```\n\n### Step 2: Start Feature Flagging![​](#step-2-start-feature-flagging \"Direct link to Step 2: Start Feature Flagging!\")\n\nThere are 2 main methods for evaluating features: `isOn` and `getFeatureValue`:\n\n```\n// Simple boolean (on/off) feature flagif (gb.isOn(\"my-feature\")) {  console.log(\"Feature enabled!\");}// Get the value of a string/JSON/number feature with a fallbackconst color = gb.getFeatureValue(\"button-color\", \"blue\");\n```\n\n## OpenFeature Provider[​](#openfeature-provider \"Direct link to OpenFeature Provider\")\n\nIf you are using OpenFeature, we have created a [GrowthBook Provider](https://github.com/open-feature/js-sdk-contrib/tree/main/libs/providers/growthbook-client) that you can use client-side. Simply import our package and set `GrowthbookClientProvider` as the provider for your OpenFeature client. Similarly to using our SDK directly, you'll want to pass in GrowthBook `Context` into the new provider instance as well as any `InitOptions`.\n\n```\nimport { GrowthBook, Context, InitOptions } from '@growthbook/growthbook';import { GrowthbookClientProvider } from '@openfeature/growthbook-client-provider';/* * Configure your GrowthBook instance with GrowthBook context * @see https://docs.growthbook.io/lib/js#step-1-configure-your-app */const gbContext: Context = {  apiHost: 'https://cdn.growthbook.io',  clientKey: 'sdk-abc123',  // Only required if you have feature encryption enabled in GrowthBook  decryptionKey: 'key_abc123',};/* * optional init options * @see https://docs.growthbook.io/lib/js#switching-to-init */const initOptions: InitOptions = {  timeout: 2000,  streaming: true,};OpenFeature.setProvider(new GrowthbookClientProvider(gbContext, initOptions));\n```\n\n## Node.js[​](#nodejs \"Direct link to Node.js\")\n\nThe GrowthBook SDK officially supports Node v18 and above.\n\nIn browser environments, you typically want a single global GrowthBook instance.\n\nIn server environments, you instead want a separate GrowthBook instance for every incoming request. Here's an example middleware you can use:\n\n```\n// Example using Expressapp.use(function(req, res, next) {  // Create a GrowthBook instance and store in the request  req.growthbook = new GrowthBook({    apiHost: \"https://cdn.growthbook.io\",    clientKey: \"sdk-abc123\"  });  // Clean up at the end of the request  res.on('close', () => req.growthbook.destroy());  // Wait for features to load (will be cached in-memory for future requests)  req.growthbook.init({timeout: 1000}).then(() => next())});\n```\n\nThen, you can access the GrowthBook instance from any route:\n\n```\napp.get(\"/\", (req, res) => {  const gb = req.growthbook;  // ...})\n```\n\n## Loading Features and Experiments[​](#loading-features-and-experiments \"Direct link to Loading Features and Experiments\")\n\nIn order for the GrowthBook SDK to work, it needs to have feature and experiment definitions from the GrowthBook API. There are a few ways to get this data into the SDK.\n\n### Built-in Fetching and Caching[​](#built-in-fetching-and-caching \"Direct link to Built-in Fetching and Caching\")\n\nIf you pass an `apiHost` and `clientKey` into the GrowthBook constructor, it will handle the network requests, caching, retry logic, etc. for you automatically. If your feature payload is encrypted, you can also pass in a `decryptionKey`.\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  // Only required if you have feature encryption enabled in GrowthBook  decryptionKey: \"key_abc123\",});// Wait for features to be downloaded with a timeout (in ms)await gb.init({  timeout: 2000,});\n```\n\nUntil features are loaded, all features will evaluate to `null`. If you're ok with a potential flicker in your application (features going from `null` to their real value), you can call `init` without awaiting the result.\n\nIf you want to refresh the features at any time (e.g. when a navigation event occurs), you can call `gb.refreshFeatures()`.\n\n#### Error Handling[​](#error-handling \"Direct link to Error Handling\")\n\nIn the case of network issues, the `init` call will not throw an error. Instead, it will stay in the default state where every feature evaluates to `null`.\n\nYou can still get access to the error if needed:\n\n```\nconst res = await gb.init({  timeout: 1000});console.log(res);\n```\n\nThe return value has 3 properties:\n\n*   **status** - `true` if the GrowthBook instance was populated with features/experiments. Otherwise `false`\n*   **source** - Where this result came from. One of the following values: `network`, `cache`, `init`, `error`, or `timeout`\n*   **error** - If status is `false`, this will contain an `Error` object with more details about the error\n\n### Custom Integration[​](#custom-integration \"Direct link to Custom Integration\")\n\nIf you prefer to handle the network and caching logic yourself, you can pass in a full JSON \"payload\" directly into the SDK. For example, you might store features in Postgres and send it down to your front-end as part of your app's initial bootstrap API call.\n\n```\nawait gb.init({  payload: {    features: {      \"feature-1\": {...},      \"feature-2\": {...},      \"another-feature\": {...},    }  }})\n```\n\nThe data structure for \"payload\" is exactly the same as what is returned by the GrowthBook SDK endpoints and webhooks.\n\nYou can update the payload at any time by calling `setPayload(newPayloadJSON)` and there are also `getPayload()` and `getDecryptedPayload()` methods, which are useful in hybrid apps where you want to hydrate the client with data from the server.\n\nNote: you don't need to specify `clientKey` or `apiHost` on your GrowthBook instance unless you want to enable streaming (see below) or call `refreshFeatures()` later.\n\n#### Synchronous Init[​](#synchronous-init \"Direct link to Synchronous Init\")\n\nThere is a alternate synchronous version of init named `initSync`, which can be useful in some environments. There are some restrictions/differences:\n\n*   You MUST pass in `payload`\n*   The `payload` MUST NOT have encrypted features or experiments\n*   If you use sticky bucketing, you MUST pass `stickyBucketAssignmentDocs` into your GrowthBook constructor\n*   The return value is the GrowthBook instance to enable easy method chaining\n\n## Streaming Updates[​](#streaming-updates \"Direct link to Streaming Updates\")\n\nThe GrowthBook SDK supports streaming with Server-Sent Events (SSE). When enabled, changes to features within GrowthBook will be streamed to the SDK in realtime as they are published. This is only supported on GrowthBook Cloud or if running a GrowthBook Proxy Server.\n\n### Streaming in Browser Environments[​](#streaming-in-browser-environments \"Direct link to Streaming in Browser Environments\")\n\nSSE is supported on all major browsers, so enabling streaming is as easy as passing `streaming: true` into your `init` call:\n\n```\ngb.init({  streaming: true,  // Other settings...})\n```\n\nYou may also differentiate your streaming host URL from your API host by setting the `streamingHost` property in the GrowthBook constructor (ex: Remote Evaluation is done on a CDN edge worker while Streaming is done through a GrowthBook Proxy server).\n\n### Streaming in Node.js[​](#streaming-in-nodejs \"Direct link to Streaming in Node.js\")\n\nNode.js does not natively support SSE, but there is a small library you can install:\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save eventsource\n```\n\nInstead of enabling streaming separately for every GrowthBook instance, we recommend opening a single shared stream at app startup instead:\n\n```\nconst { setPolyfills, prefetchPayload } = require(\"@growthbook/growthbook\");// Configure GrowthBook to use the eventsource librarysetPolyfills({  EventSource: require(\"eventsource\"),});// Start a streaming connectionprefetchPayload({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  streaming: true}).then(() => console.log(\"Streaming connection open!\"))\n```\n\nThis will work as long as you use the exact same `apiHost` and `clientKey` when creating GrowthBook instances in your middleware.\n\n## Remote Evaluation[​](#remote-evaluation \"Direct link to Remote Evaluation\")\n\nWhen used in a front-end context, the JS SDK may be run in Remote Evaluation mode. This mode brings the security benefits of a backend SDK to the front end by evaluating feature flags exclusively on a private server. Using Remote Evaluation ensures that any sensitive information within targeting rules or unused feature variations are never seen by the client. Note that Remote Evaluation should not be used in a backend context.\n\nYou must enable Remote Evaluation in your SDK Connection settings. Cloud customers are also required to self-host a GrowthBook Proxy Server or custom remote evaluation backend.\n\nTo use Remote Evaluation, add the `remoteEval: true` property to your SDK instance. A new evaluation API call will be made any time a user attribute or other dependency changes. You may optionally limit these API calls to specific attribute changes by setting the `cacheKeyAttributes` property (an array of attribute names that, when changed, trigger a new evaluation call).\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://gb-proxy.mydomain.io/\",  clientKey: \"sdk-abc123\",  // Enable remote evaluation  remoteEval: true,  // Optional: only trigger a new evaluation call when the `id` and `email` attribute changes  cacheKeyAttributes: [\"id\", \"email\"],});\n```\n\nnote\n\nIf you would like to implement Sticky Bucketing while using Remote Evaluation, you must configure your remote evaluation backend to support Sticky Bucketing. In the case of the GrowthBook Proxy Server, this means implementing a Redis database for sticky bucketing use. You will not need to provide a StickyBucketService instance to the client side SDK.\n\n## Caching[​](#caching \"Direct link to Caching\")\n\nThe JavaScript SDK has 2 caching layers:\n\n1.  In-memory cache (available on all platforms)\n2.  Persistent localStorage cache (only available in browsers by default)\n\nThere are a number of cache settings you can configure within GrowthBook. This must be done BEFORE creating a GrowthBook instance.\n\nBelow are all of the default values. You can call `configureCache` with a subset of these fields and the rest will keep their default values.\n\n```\nimport { configureCache } from \"@growthbook/growthbook\";configureCache({  // The localStorage key the cache will be stored under  cacheKey: \"gbFeaturesCache\",  // Consider features stale after this much time (60 seconds default)  staleTTL: 1000 * 60,  // Cached features older than this will be ignored (24 hours default)  maxAge: 1000 * 60 * 60 * 24,  // For Remote Eval only - limit the number of cache entries (~1 entry per user)  maxEntries: 10,  // When `false`, we add a `visibilitychange` listener to disable SSE when the page is idle  disableIdleStreams: false,  // Consider a page \"idle\" when it is hidden for this long (default 20 seconds)  idleStreamInterval: 20000,  // Set to `true` to completely disable both in-memory and persistent caching  disableCache: false,})\n```\n\n### Polyfilling localStorage[​](#polyfilling-localstorage \"Direct link to Polyfilling localStorage\")\n\nOutside of a browser environment, you can still use persistent caching. You just need to provide an implementation of the localStorage interface.\n\nHere's an example of using Redis in Node.js:\n\n```\nconst { setPolyfills } = require(\"@growthbook/growthbook\");setPolyfills({  localStorage: {    // Example using Redis    getItem: (key) => redisClient.get(key),    setItem: (key, value) => redisClient.set(key, value),  }});\n```\n\nThis must be done BEFORE you call either `prefetchPayload` or create the first GrowthBook instance.\n\n## Re-rendering When Features Change[​](#re-rendering-when-features-change \"Direct link to Re-rendering When Features Change\")\n\nWhen features change (e.g. by calling `gb.refreshFeatures()`), you need to re-render your app so that all of your feature flag checks can be re-evaluated. You can specify your own custom rendering function for this purpose:\n\n```\n// Callback to re-render your app when feature flag values changegb.setRenderer(() => {  // TODO: re-render your app});\n```\n\n## Experimentation (A/B Testing)[​](#experimentation-ab-testing \"Direct link to Experimentation (A/B Testing)\")\n\nIn order to run A/B tests, you need to set up a tracking callback function. This is called every time a user is put into an experiment and can be used to track the exposure event in your analytics system (Segment, Mixpanel, GA, etc.).\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  trackingCallback: (experiment, result) => {    // Example using Segment    analytics.track(\"Experiment Viewed\", {      experimentId: experiment.key,      variationId: result.key,    });  },});\n```\n\nThis same tracking callback is used for both feature flag experiments and Visual Editor experiments.\n\n### Feature Flag Experiments[​](#feature-flag-experiments \"Direct link to Feature Flag Experiments\")\n\nThere is nothing special you have to do for feature flag experiments. Just evaluate the feature flag like you would normally do. If the user is put into an experiment as part of the feature flag, it will call the `trackingCallback` automatically in the background.\n\n```\n// If this has an active experiment and the user is included,// it will call trackingCallback automaticallyconst newLogin = gb.isOn(\"new-signup-form\");\n```\n\nIf the experiment came from a feature rule, `result.featureId` in the trackingCallback will contain the feature id, which may be useful for tracking/logging purposes.\n\n### Visual Editor Experiments[​](#visual-editor-experiments \"Direct link to Visual Editor Experiments\")\n\nExperiments created through the GrowthBook Visual Editor will run automatically as soon as their targeting conditions are met.\n\n**Note**: Visual Editor experiments are only supported in a web browser environment. They will not run in Node.js, Mobile apps, or Desktop apps.\n\nIf you are using this SDK in a Single Page App (SPA), you will need to let the GrowthBook instance know when the URL changes so the active experiments can update accordingly.\n\n```\n// Call this every time a navigation event happens in your SPAfunction onRouteChange() {  gb.setURL(window.location.href);}\n```\n\nVisual Editor experiments are enabled by default, but can be disabled with various GrowthBook constructor settings:\n\n*   **disableVisualExperiments** - If true, all visual editor experiments will be skipped\n*   **disableJsInjection** - If true, any visual editor experiment that injects custom javascript will be skipped.\n\n#### Content Security Policy[​](#content-security-policy \"Direct link to Content Security Policy\")\n\nIf you plan to use the Custom Javascript feature of the Visual Editor and you have a Content Security Policy on your site, there are two options:\n\n1.  Enable `unsafe-inline` script-src\n2.  OR generate a unique nonce value, add it to your script-src directive, and pass it into the GrowthBook constructor as `jsInjectionNonce`\n\n### URL Redirect Experiments[​](#url-redirect-experiments \"Direct link to URL Redirect Experiments\")\n\nSimilarly to Visual Editor experiments, URL redirect tests will run automatically if targetting conditions are met.\n\nIf you are using this SDK in a Single Page App (SPA), you'll want to pass in a custom navigation function into the SDK (as default navigation for URL Redirects uses `window.location.replace(url)`) and set the `navigateDelay` to 0.\n\n```\n// Example in Next.jsimport router from \"next/router\";const gb = new GrowthBook({    navigate: (url) => router.replace(url),    navigateDelay: 0,    // ... other settings});\n```\n\nFor SPA's you will also need to let the GrowthBook instance know when the URL changes so the active experiments can update accordingly.\n\n```\n// Call this every time a navigation event happens in your SPAfunction onRouteChange() {  gb.setURL(window.location.href);}\n```\n\nURL Redirect experiments are enabled by default, but can be disabled with various GrowthBook constructor settings:\n\n*   **disableUrlRedirectExperiments** - If true, all URL Redirect experiments will be skipped\n*   **disableCrossOriginUrlRedirectExperiments** - If true, any URL Redirect with a destination pointing to a different origin will be skipped.\n\n### Deferred Tracking[​](#deferred-tracking \"Direct link to Deferred Tracking\")\n\nSometimes, your analytics tracker is loaded after GrowthBook. In that case, you should not specify a `trackingCallback` in the constructor and instead use `setTrackingCallback` later when ready. When you do this, the GrowthBook instance will queue up tracking calls and then fire them all at once when you set the callback.\n\nThere are some scenarios where you need to queue up tracking calls in one GrowthBook instance and fire them in another. For example, if your analytics tracker is only available on the front-end, but you are running experiments in Node.js.\n\nExport the queue tracking calls with the `getDeferredTrackingCalls()` method. The result is a serializable JSON object:\n\n```\nconst tracks = gb.getDeferredTrackingCalls();\n```\n\nThen, import with `setDeferredTrackingCalls`. This does not fire them automatically. You must call `fireDeferredTrackingCalls` after.\n\n```\ngb2.setDeferredTrackingCalls(tracks);gb2.fireDeferredTrackingCalls();\n```\n\n### Sticky Bucketing[​](#sticky-bucketing \"Direct link to Sticky Bucketing\")\n\nSticky bucketing ensures that users see the same experiment variant, even when user session, user login status, or experiment parameters change. See the [Sticky Bucketing docs](https://docs.growthbook.io/app/sticky-bucketing) for more information. If your organization and experiment supports sticky bucketing, you must implement an instance of the `StickyBucketService` to use Sticky Bucketing. The JS SDK exports several implementations of this service for common use cases, or you may build your own:\n\n*   `LocalStorageStickyBucketService` — For simple bucket persistence using the browser's LocalStorage (can be polyfilled for other environments).\n    \n*   `BrowserCookieStickyBucketService` — For simple bucket persistence using browser cookies, which are transportable to the back end. Assumes `js-cookie` is implemented (can be polyfilled). Cookie attributes can also be configured.\n    \n*   `ExpressCookieStickyBucketService` — For NodeJS/Express controller-level bucket persistence using browser cookies; intended to be interoperable with `BrowserCookieStickyBucketService`. Assumes `cookie-parser` is implemented (can be polyfilled). Cookie attributes can also be configured.\n    \n*   `RedisStickyBucketService` — For NodeJS Redis-based bucket persistence. Requires an `ioredis` Redis client instance to be passed in.\n    \n*   Build your own — Implement the abstract `StickyBucketService` class and connect to your own data store, or custom wrap multiple service implementations (ex: read/write to both cookies and Redis).\n    \n\nImplementing most StickyBucketService implementations is straightforward and works with minimal setup. For instance, to use the `BrowserCookieStickyBucketService`:\n\n```\nimport { BrowserCookieStickyBucketService } from \"@growthbook/growthbook\";import Cookies from 'js-cookie';const gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  stickyBucketService: new BrowserCookieStickyBucketService({    jsCookie: Cookies,  }),  // ...});\n```\n\n## TypeScript[​](#typescript \"Direct link to TypeScript\")\n\nWhen used in a TypeScript project, GrowthBook includes basic type inference out of the box:\n\n```\n// Type will be `string` based on the fallback provided (\"blue\")const color = gb.getFeatureValue(\"button-color\", \"blue\");// You can manually specify types as well// feature.value will be type `number`const feature = gb.evalFeature<number>(\"font-size\");console.log(feature.value);// Experiments will use the variations to infer the return value// result.value will be type \"string\"const result = gb.run({  key: \"my-test\",  variations: [\"blue\", \"green\"],});\n```\n\n### Strict Typing[​](#strict-typing \"Direct link to Strict Typing\")\n\nIf you want to enforce stricter types in your application, you can do that when creating the GrowthBook instance:\n\n```\n// Define all your feature flags and types hereinterface AppFeatures {  \"button-color\": string;  \"font-size\": number;  \"newForm\": boolean;}// Pass into the GrowthBook instanceconst gb = new GrowthBook<AppFeatures>({  ...});\n```\n\nNow, all feature flag methods will be strictly typed.\n\n```\n// feature.value will by type `number`const feature = gb.evalFeature(\"font-size\");console.log(feature.value);// Typos will cause compile-time errorsgb.isOn(\"buton-color\"); // \"buton\" instead of \"button\"\n```\n\nInstead of defining the `AppFeatures` interface manually like above, you can auto-generate it from your GrowthBook account using the [GrowthBook CLI](https://docs.growthbook.io/tools/cli).\n\n## Updating[​](#updating \"Direct link to Updating\")\n\nAs a general philosophy, we aim to keep the SDK 100% backwards compatible at all times. View the [Changelog](https://github.com/growthbook/growthbook/blob/main/packages/sdk-js/CHANGELOG.md) for a complete list of all SDK changes.\n\n### Updating to 1.0.0[​](#updating-to-100 \"Direct link to Updating to 1.0.0\")\n\nUpdating from a **0.X.X** release to **1.0.0** is still backwards compatible for the vast majority of use cases, although there are a few minor changes:\n\n*   The `enableDevMode: true` setting previously also disabled cache as a side-effect. This is no longer the case in 1.0.0, and you must explicitly also set `disableCache: true`\n*   Previously, a network request to fetch features was started immediately upon creating a GrowthBook instance. Starting in 1.0.0, it waits until you call `loadFeatures` (or the new `init` method) before starting the network request. As a replacement, there is now a standalone `prefetchPayload` function that you can use to kick off a network request outside of the context of a GrowthBook instance.\n\n#### Switching to init[​](#switching-to-init \"Direct link to Switching to init\")\n\nGrowthBook 1.0.0 introduced a new `init` (and `initSync`) method.\n\nWe recommend everyone starts using this in their implementation. It solves many pain points including easier error handling and more control over caching and streaming.\n\nFor those currently using `loadFeatures`, `init` is a direct replacement. The only difference is that streaming is now opt-in instead of on-by-default.\n\n```\n// Previousawait gb.loadFeatures({ timeout: 1000 });// Newawait gb.init({ timeout: 1000, streaming: true });\n```\n\nFor those currently NOT using `loadFeatures` and passing features/experiments directly into the GrowthBook constructor, `init` and `initSync` can be used instead. The code below assumes you have a `payload` variable with the contents from the SDK Connection Endpoint.\n\n```\n// Previousconst gb = new GrowthBook({  features: payload.features,  experiments: payload.experiments});// New (async)const gb = new GrowthBook();await gb.init({ payload: payload });// New (non-async)const gb = (new GrowthBook()).initSync({ payload: payload });\n```\n\n## GrowthBook Instance (reference)[​](#growthbook-instance-reference \"Direct link to GrowthBook Instance (reference)\")\n\n### Attributes[​](#attributes \"Direct link to Attributes\")\n\nYou can specify attributes about the current user and request. These are used for two things:\n\n1.  Feature targeting (e.g. paid users get one value, free users get another)\n2.  Assigning persistent variations in A/B tests (e.g. user id \"123\" always gets variation B)\n\nThe following are some commonly used attributes, but use whatever makes sense for your application.\n\n```\nnew GrowthBook({  attributes: {    id: \"123\",    loggedIn: true,    deviceId: \"abc123def456\",    company: \"acme\",    paid: false,    url: \"/pricing\",    browser: \"chrome\",    mobile: false,    country: \"US\",  },});\n```\n\n#### Updating Attributes[​](#updating-attributes \"Direct link to Updating Attributes\")\n\nIf attributes change, you can call `setAttributes()` to update. This will completely overwrite any existing attributes. To do a partial update, use the following pattern:\n\n```\ngb.setAttributes({  // Only update the `url` attribute, keep the rest the same  ...gb.getAttributes(),  url: \"/new-page\"})\n```\n\n#### Secure Attributes[​](#secure-attributes \"Direct link to Secure Attributes\")\n\nWhen _secure attribute hashing_ is enabled, all targeting conditions in the SDK payload referencing attributes with datatype `secureString` or `secureString[]` will be anonymized via SHA-256 hashing. This allows you to safely target users based on sensitive attributes. You must enable this feature in your SDK Connection for it to take effect.\n\nIf your SDK Connection has secure attribute hashing enabled, you will need to manually hash any `secureString` or `secureString[]` attributes that you pass into the GrowthBook SDK.\n\nTo hash an attribute, use a cryptographic library with SHA-256 support, and compute the SHA-256 hashed value of your attribute _plus_ your organization's secure attribute salt.\n\n```\nconst salt = \"f09jq3fij\"; // Your organization's secure attribute salt (see Organization Settings)// hashing a secureString attributeconst userEmail = sha256(salt + user.email);// hashing an secureString[] attributeconst userTags = user.tags.map(tag => sha256(salt + tag));gb.setAttributes({  id: user.id,  loggedIn: true,  email: userEmail,  tags: userTags,});await gb.init();// In this example, we are using Node.js's built-in crypto libraryfunction sha256(str) {  return crypto.createHash(\"sha256\").update(str).digest(\"hex\");}\n```\n\nNote that in a browser context, we will not be able to natively access the Node.js crypto library. In modern browsers `window.crypto.subtle` is available, although calls are asynchronous. You would need to await all attribute hashing to complete before calling `gb.setAttributes()`.\n\n```\nasync function sha256(str) {  const buffer = await crypto.subtle.digest(\"SHA-256\", new TextEncoder().encode(str));  const hashArray = Array.from(new Uint8Array(buffer));  return hashArray.map(byte => byte.toString(16).padStart(2, \"0\")).join(\"\");}\n```\n\nAlternatively, CryptoJS ([https://www.npmjs.com/package/crypto-js](https://www.npmjs.com/package/crypto-js)) provides a synchronous API:\n\n```\nimport sha256 from 'crypto-js/sha256';const userEmail = sha256(salt + user.email);\n```\n\n### Feature Usage Callback[​](#feature-usage-callback \"Direct link to Feature Usage Callback\")\n\nGrowthBook can fire a callback whenever a feature is evaluated for a user. This can be useful to update 3rd party tools like NewRelic or DataDog.\n\n```\nnew GrowthBook({  onFeatureUsage: (featureKey, result) => {    console.log(\"feature\", featureKey, \"has value\", result.value);  },});\n```\n\nThe `result` argument is the same thing returned from `gb.evalFeature`.\n\nNote: If you evaluate the same feature multiple times (and the value doesn't change), the callback will only be fired the first time.\n\n### Dev Mode[​](#dev-mode \"Direct link to Dev Mode\")\n\nThere is a [GrowthBook Chrome DevTools Extension](https://chrome.google.com/webstore/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia) that can help you debug and test your feature flags in development.\n\nIn order for this to work, you must explicitly enable dev mode when creating your GrowthBook instance:\n\n```\nconst gb = new GrowthBook({  enableDevMode: true,});\n```\n\nTo avoid exposing all of your internal feature flags and experiments to users, we recommend setting this to `false` in production in most cases.\n\n### evalFeature[​](#evalfeature \"Direct link to evalFeature\")\n\nIn addition to the `isOn` and `getFeatureValue` helper methods, there is the `evalFeature` method that gives you more detailed information about why the value was assigned to the user.\n\n```\n// Get detailed information about the feature evaluationconst result = gb.evalFeature(\"my-feature\");// The value of the feature (or `null` if not defined)console.log(result.value);// Why the value was assigned to the user// One of: `override`, `unknownFeature`, `defaultValue`, `force`, or `experiment`console.log(result.source);// The string id of the rule (if any) which was usedconsole.log(result.ruleId);// Information about the experiment (if any) which was usedconsole.log(result.experiment);// The result of the experiment (or `undefined`)console.log(result.experimentResult);\n```\n\n### Inline Experiments[​](#inline-experiments \"Direct link to Inline Experiments\")\n\nInstead of declaring all features up-front in the context and referencing them by ids in your code, you can also just run an experiment directly. This is done with the `gb.run` method:\n\n```\n// These are the only required optionsconst { value } = gb.run({  key: \"my-experiment\",  variations: [\"red\", \"blue\", \"green\"],});\n```\n\n#### Customizing the Traffic Split[​](#customizing-the-traffic-split \"Direct link to Customizing the Traffic Split\")\n\nBy default, this will include all traffic and do an even split between all variations. There are 2 ways to customize this behavior:\n\n```\n// Option 1: Using weights and coveragegb.run({  key: \"my-experiment\",  variations: [\"red\", \"blue\", \"green\"],  // Only include 10% of traffic  coverage: 0.1,  // Split the included traffic 50/25/25 instead of the default 33/33/33  weights: [0.5, 0.25, 0.25],});// Option 2: Specifying rangesgb.run({  key: \"my-experiment\",  variations: [\"red\", \"blue\", \"green\"],  // Identical to the above  // 5% of traffic in A, 2.5% each in B and C  ranges: [    [0, 0.05],    [0.5, 0.525],    [0.75, 0.775],  ],});\n```\n\n#### Hashing[​](#hashing \"Direct link to Hashing\")\n\nWe use deterministic hashing to assign a variation to a user. We hash together the user's id and experiment key, which produces a number between `0` and `1`. Each variation is assigned a range of numbers, and whichever one the user's hash value falls into will be assigned.\n\nYou can customize this hashing behavior:\n\n```\ngb.run({  key: \"my-experiment\",  variations: [\"A\", \"B\"],  // Which hashing algorithm to use  // Version 2 is the latest and the one we recommend  hashVersion: 2,  // Use a different seed instead of the experiment key  seed: \"abcdef123456\",  // Use a different user attribute (default is `id`)  hashAttribute: \"device_id\",});\n```\n\n**Note**: For backwards compatibility, if no `hashVersion` is specified, it will fall back to using version `1`, which is deprecated. In the future, version `2` will become the default. We recommend specifying version `2` now for all new experiments to avoid migration issues down the line.\n\n#### Meta Info[​](#meta-info \"Direct link to Meta Info\")\n\nYou can also define meta info for the experiment and/or variations. These do not affect the behavior, but they are passed through to the `trackingCallback`, so they can be used to annotate events.\n\n```\ngb.run({  key: \"results-per-page\",  variations: [10, 20],  // Experiment meta info  name: \"Results per Page\",  phase: \"full-traffic\"  // Variation meta info  meta: [    {      key: \"control\",      name: \"10 Results per Page\",    },    {      key: \"variation\",      name: \"20 Results per Page\",    },  ]})\n```\n\n#### Mutual Exclusion[​](#mutual-exclusion \"Direct link to Mutual Exclusion\")\n\nSometimes you want to run multiple conflicting experiments at the same time. You can use the `filters` setting to run mutually exclusive experiments.\n\nWe do this using deterministic hashing to assign users a value between 0 and 1 for each filter.\n\n```\n// Will include 60% of users - ones with a hash between 0 and 0.6gb.run({  key: \"experiment-1\",  variation: [0, 1],  filters: [    {      seed: \"pricing\",      attribute: \"id\",      ranges: [[0, 0.6]]    }  ]});// Will include the other 40% of users - ones with a hash between 0.6 and 1gb.run({  key: \"experiment-2\",  variation: [0, 1],  filters: [    {      seed: \"pricing\",      attribute: \"id\",      ranges: [[0.6, 1.0]]    }  ]});\n```\n\n**Note** - If a user is excluded from an experiment due to a filter, the rule will be skipped and the next matching rule will be used instead.\n\n#### Holdout Groups[​](#holdout-groups \"Direct link to Holdout Groups\")\n\nTo use global holdout groups, use a nested experiment design:\n\n```\n// The value will be `true` if in the holdout group, otherwise `false`const holdout = gb.run({  key: \"holdout\",  variations: [true, false],  // 10% of users in the holdout group  weights: [0.1, 0.9]});// Only run your main experiment if the user is NOT in the holdoutif (!holdout.value) {  const res = gb.run({    key: \"my-experiment\",    variations: [\"A\", \"B\"]  })}\n```\n\n#### Targeting Conditions[​](#targeting-conditions \"Direct link to Targeting Conditions\")\n\nYou can also define targeting conditions that limit which users are included in the experiment. These conditions are evaluated against the `attributes` passed into the GrowthBook context. The syntax for conditions is based on the MongoDB query syntax and is straightforward to read and write.\n\nFor example, if the attributes are:\n\n```\n{  \"id\": \"123\",  \"browser\": {    \"vendor\": \"firefox\",    \"version\": 94  },  \"country\": \"CA\"}\n```\n\nThe following condition would evaluate to `true` and the user would be included in the experiment:\n\n```\ngb.run({  key: \"my-experiment\",  variation: [0, 1],  condition: {    \"browser.vendor\": \"firefox\",    \"country\": {      \"$in\": [\"US\", \"CA\", \"IN\"]    }  }})\n```\n\n#### Inline Experiment Return Value[​](#inline-experiment-return-value \"Direct link to Inline Experiment Return Value\")\n\nA call to `gb.run(experiment)` returns an object with a few useful properties:\n\n```\nconst {  value,  key,  name,  variationId,  inExperiment,  hashUsed,  hashAttribute,  hashValue,} = gb.run({  key: \"my-experiment\",  variations: [\"A\", \"B\"],});// If user is included in the experimentconsole.log(inExperiment); // true or false// The index of the assigned variationconsole.log(variationId); // 0 or 1// The value of the assigned variationconsole.log(value); // \"A\" or \"B\"// The key and name of the assigned variation (if specified in `meta`)console.log(key); // \"0\" or \"1\"console.log(name); // \"\"// If the variation was randomly assigned by hashingconsole.log(hashUsed);// The user attribute that was hashedconsole.log(hashAttribute); // \"id\"// The value of that attributeconsole.log(hashValue); // e.g. \"123\"\n```\n\nThe `inExperiment` flag will be false if the user was excluded from being part of the experiment for any reason (e.g. failed targeting conditions).\n\nThe `hashUsed` flag will only be true if the user was randomly assigned a variation. If the user was forced into a specific variation instead, this flag will be false.\n\n## Feature Definitions (reference)[​](#feature-definitions-reference \"Direct link to Feature Definitions (reference)\")\n\nThe feature definition JSON file contains information about all of the features in your application.\n\nEach feature consists of a unique key, a list of possible values, and rules for how to assign those values to users.\n\n```\n{  \"feature-1\": {...},  \"feature-2\": {...},  \"another-feature\": {...},}\n```\n\n### Basic Feature[​](#basic-feature \"Direct link to Basic Feature\")\n\nAn empty feature always has the value `null`:\n\n#### Default Values[​](#default-values \"Direct link to Default Values\")\n\nYou can change the default assigned value with the `defaultValue` property:\n\n```\n{  \"my-feature\": {    defaultValue: \"green\"  }}\n```\n\n### Override Rules[​](#override-rules \"Direct link to Override Rules\")\n\nYou can override the default value with **rules**.\n\nRules give you fine-grained control over how feature values are assigned to users. There are 2 types of feature rules: `force` and `experiment`. Force rules give the same value to everyone. Experiment rules assign values to users randomly.\n\n#### Rule Ids[​](#rule-ids \"Direct link to Rule Ids\")\n\nRules can specify a unique identifier with the `id` property. This can help with debugging and QA by letting you see exactly why a specific value was assigned to a user.\n\n#### Rule Conditions[​](#rule-conditions \"Direct link to Rule Conditions\")\n\nRules can optionally define targeting conditions that limit which users the rule applies to. These conditions are evaluated against the `attributes` passed into the GrowthBook context. The syntax for conditions is based on the MongoDB query syntax and is straightforward to read and write.\n\nFor example, if the attributes are:\n\n```\n{  \"id\": \"123\",  \"browser\": {    \"vendor\": \"firefox\",    \"version\": 94  },  \"country\": \"CA\"}\n```\n\nThe following condition would evaluate to `true`:\n\n```\n{  \"browser.vendor\": \"firefox\",  \"country\": {    \"$in\": [\"US\", \"CA\", \"IN\"]  }}\n```\n\nIf a condition evaluates to `false`, the rule will be skipped. This means you can chain rules together with different conditions to support even the most complex use cases.\n\n#### Force Rules[​](#force-rules \"Direct link to Force Rules\")\n\nForce rules do what you'd expect - force a specific value for the feature\n\n```\n// Firefox users in the US or Canada get \"green\"// Everyone else gets the default \"blue\"{  \"button-color\": {    defaultValue: \"blue\",    rules: [      {        id: \"rule-123\",        condition: {          browser: \"firefox\",          country: {            $in: [\"US\", \"CA\"]          }        },        force: \"green\"      }    ],  }}\n```\n\n##### Gradual Rollouts[​](#gradual-rollouts \"Direct link to Gradual Rollouts\")\n\nYou can specify a `range` for your rule, which determines what percent of users will get the rule applied to them. Users who do not get the rule applied will fall through to the next matching rule (or default value). You can also specify a `seed` that will be used for hashing.\n\nIn order to figure out if a user is included or not, we use deterministic hashing. By default, we use the user attribute `id` for this, but you can override this by specifying `hashAttribute` for the rule:\n\nThis is useful for gradually rolling out features to users (start with a small range and slowly increase).\n\n```\n{  \"new-feature\": {    defaultValue: false,    rules: [      {        force: true,        hashAttribute: \"device-id\",        seed: 'new-feature-rollout-abcdef123',        // 20% of users        range: [0, 0.2]        // Increase to 40%:        // range: [0, 0.4]      }    ]  }}\n```\n\n#### Experiment Rules[​](#experiment-rules \"Direct link to Experiment Rules\")\n\nExperiment rules let you adjust the percent of users who get randomly assigned to each variation. This can either be used for hypothesis-driven A/B tests or to simply mitigate risk by gradually rolling out new features to your users.\n\n```\n// Each variation gets assigned to a random 1/3rd of users{  \"image-size\": {    rules: [      {        variations: [\"small\", \"medium\", \"large\"]      }    ]  }}\n```\n\n##### Customizing the Traffic Split[​](#customizing-the-traffic-split-1 \"Direct link to Customizing the Traffic Split\")\n\nBy default, an experiment rule will include all traffic and do an even split between all variations. There are 2 ways to customize this behavior:\n\n```\n// Option 1: Using weights and coverage{  variations: [\"red\", \"blue\", \"green\"],  // Only include 10% of traffic  coverage: 0.1,  // Split the included traffic 50/25/25 instead of the default 33/33/33  weights: [0.5, 0.25, 0.25]}// Option 2: Specifying ranges{  variations: [\"red\", \"blue\", \"green\"],  // Identical to the above  // 5% of traffic in A, 2.5% each in B and C  ranges: [    [0, 0.05],    [0.5, 0.525],    [0.75, 0.775]  ]}\n```\n\nA user is assigned a number from 0 to 1 and whichever variation's range includes their number will be assigned to them.\n\n##### Variation Meta Info[​](#variation-meta-info \"Direct link to Variation Meta Info\")\n\nYou can use the `meta` setting to provide additional info about the variations such as name.\n\n```\n{  \"image-size\": {    rules: [      {        variations: [\"sm\", \"md\", \"lg\"],        ranges: [          [0, 0.5],          [0.5, 0.75],          [0.75, 1.0]        ],        meta: [          {            key: \"control\",            name: \"Small\",          },          {            key: \"v1\",            name: \"Medium\",          },          {            key: \"v2\",            name: \"Large\",          }        ]      }    ]  }}\n```\n\n##### Tracking Key and Name[​](#tracking-key-and-name \"Direct link to Tracking Key and Name\")\n\nWhen a user is assigned a variation, we call the `trackingCallback` function so you can record the exposure with your analytics event tracking system. By default, we use the feature id to identify the experiment, but this can be overridden if needed with the `key` setting. You can also optionally provide a human-readable name.\n\n```\n{  \"feature-1\": {    rules: [      {        // Use \"my-experiment\" as the key instead of \"feature-1\"        key: \"my-experiment\",        name: \"My Experiment\",        variations: [\"A\", \"B\"]      }    ]  },}\n```\n\n##### Hash Attribute[​](#hash-attribute \"Direct link to Hash Attribute\")\n\nWe use deterministic hashing to make sure the same user always gets assigned the same value. By default, we use the attribute `id`, but this can be overridden with the `hashAttribute` setting:\n\n```\nconst gb = new GrowthBook({  attributes: {    id: \"123\",    company: \"acme\",  },  features: {    \"my-feature\": {      rules: [        // All users with the same \"company\" value        // will be assigned the same variation        {          variations: [\"A\", \"B\"],          hashAttribute: \"company\",        },        // If \"company\" is empty for the user (e.g. if they are logged out)        // The experiment will be skipped and fall through to this next rule        {          force: \"A\",        },      ],    },  },});\n```\n\n##### Filters[​](#filters \"Direct link to Filters\")\n\nSometimes you want to run multiple conflicting experiments at the same time. You can use the `filters` setting to run mutually exclusive experiments.\n\nWe do this using deterministic hashing to assign users a value between 0 and 1 for each filter.\n\n```\n{  \"feature1\": {    rules: [      // Will include 60% of users - ones with a hash between 0 and 0.6      {        variations: [false, true],        filters: [          {            seed: \"pricing\",            attribute: \"id\",            ranges: [[0, 0.6]]          }        ]      }    ]  },  \"feature2\": {    rules: [      // Will include the other 40% of users - ones with a hash between 0.6 and 1      {        variations: [false, true],        filters: [          {            seed: \"pricing\",            attribute: \"id\",            ranges: [[0.6, 1.0]]          }        ]      },    ]  }}\n```\n\n**Note** - If a user is excluded from an experiment due to a filter, the rule will be skipped and the next matching rule will be used instead.\n\n## Examples[​](#examples \"Direct link to Examples\")\n\n*   [Typescript example app with strict typing](https://github.com/growthbook/examples/tree/main/vanilla-typescript) .",
  "title": "Javascript SDK | GrowthBook Docs",
  "description": "GrowthBook SDK for Javascript",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/react",
  "markdown": "# React SDK | GrowthBook Docs\n\n## ReactJS\n\nThis is a thin wrapper on top of the [Javascript Library](https://docs.growthbook.io/lib/js), so you might want to view those docs first to familiarize yourself with the basic classes and methods.\n\nThis SDK supports both ReactJS and ReactNative environments.\n\n**Important**: Starting in version 1.0.0, you must always pass a GrowthBook instance into the GrowthBookProvider. In previous versions, you were allowed to pass `null` as well.\n\n## Installation[​](#installation \"Direct link to Installation\")\n\nInstall with a package manager\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save @growthbook/growthbook-react\n```\n\n## Quick Usage[​](#quick-usage \"Direct link to Quick Usage\")\n\n### Step 1: Configure your app[​](#step-1-configure-your-app \"Direct link to Step 1: Configure your app\")\n\n```\nimport { useEffect } from \"react\";import { GrowthBook, GrowthBookProvider } from \"@growthbook/growthbook-react\";// Create a GrowthBook instanceconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  enableDevMode: true,  // Only required for A/B testing  // Called every time a user is put into an experiment  trackingCallback: (experiment, result) => {    console.log(\"Experiment Viewed\", {      experimentId: experiment.key,      variationId: result.key,    });  },});gb.init({  // Optional, enable streaming updates  streaming: true})export default function App() {  useEffect(() => {    // Set user attributes for targeting (from cookie, auth system, etc.)    gb.setAttributes({      id: user.id,      company: user.company,    });  }, [user])  return (    <GrowthBookProvider growthbook={gb}>      <OtherComponent />    </GrowthBookProvider>  );}\n```\n\n### Step 2: Start feature flagging![​](#step-2-start-feature-flagging \"Direct link to Step 2: Start feature flagging!\")\n\nThere are a few ways to use feature flags in GrowthBook:\n\n## OpenFeature Provider[​](#openfeature-provider \"Direct link to OpenFeature Provider\")\n\nIf you are using OpenFeature, we have created a [GrowthBook Provider](https://github.com/open-feature/js-sdk-contrib/tree/main/libs/providers/growthbook-client) that you can use client-side. Simply import our package and set `GrowthbookClientProvider` as the provider for your OpenFeature client. Similarly to using our SDK directly, you'll want to pass in GrowthBook `Context` into the new provider instance as well as any `InitOptions`.\n\n```\nimport { OpenFeature, OpenFeatureProvider, useFlag } from \"@openfeature/react-sdk\";import { GrowthBook, Context, InitOptions } from '@growthbook/growthbook';import { GrowthbookClientProvider } from '@openfeature/growthbook-client-provider';OpenFeature.setProvider(  new GrowthbookClientProvider(context, { streaming: true }));function Page() {  const { value: showNewMessage } = useFlag(\"new-message\", true);  const gbContext: Context = {    apiHost: 'https://cdn.growthbook.io',    clientKey: 'sdk-abc123',    // Only required if you have feature encryption enabled in GrowthBook    decryptionKey: 'key_abc123',  };  return (    <div className='App'>      <header className='App-header'>        <div>OpenFeature Testing React App</div>      </header>      <p>        {showNewMessage ? (          <p>Welcome to this OpenFeature enabled React app!</p>        ) : (          <p>Welcome to this React app.</p>        )}      </p>    </div>  );}\n```\n\n#### Feature Hooks[​](#feature-hooks \"Direct link to Feature Hooks\")\n\n```\nimport { useFeatureValue, useFeatureIsOn } from \"@growthbook/growthbook-react\";export default function OtherComponent() {  // Boolean on/off features  const newLogin = useFeatureIsOn(\"new-login-form\");  // String/Number/JSON features with a fallback value  const buttonColor = useFeatureValue(\"login-button-color\", \"blue\");  if (newLogin) {    return <NewLogin color={buttonColor} />;  } else {    return <Login color={buttonColor} />;  }}\n```\n\n#### Feature Wrapper Components[​](#feature-wrapper-components \"Direct link to Feature Wrapper Components\")\n\n```\nimport { IfFeatureEnabled, FeatureString } from \"@growthbook/growthbook-react\";export default function OtherComponent() {  return (    <div>      <h1>        <FeatureString feature=\"site-h1\" default=\"My Site\"/>      </h1>      <IfFeatureEnabled feature=\"welcome-message\">        <p>Welcome to our site!</p>      </IfFeatureEnabled>    </div>  );}\n```\n\n#### useGrowthBook hook[​](#usegrowthbook-hook \"Direct link to useGrowthBook hook\")\n\nIf you need low-level access to the GrowthBook instance for any reason, you can use the `useGrowthBook` hook.\n\nOne example is updating targeting attributes when a user logs in:\n\n```\nimport { useGrowthBook } from \"@growthbook/growthbook-react\";export default function Auth() {  const growthbook = useGrowthBook();  const user = useUser();  useEffect(() => {    if (!user) return;    growthbook.setAttributes({      loggedIn: true,      id: user.id,      company: user.company,      isPro: user.plan === \"pro\"    })  }, [user, growthbook])  ...}\n```\n\n## Loading Features[​](#loading-features \"Direct link to Loading Features\")\n\nIn order for the GrowthBook SDK to work, it needs to have feature definitions from the GrowthBook API. There are 2 ways to get this data into the SDK.\n\n### Built-in Fetching and Caching[​](#built-in-fetching-and-caching \"Direct link to Built-in Fetching and Caching\")\n\nIf you pass an `apiHost` and `clientKey` into the GrowthBook constructor, it will handle the network requests, caching, retry logic, etc. for you automatically. If your feature payload is encrypted, you can also pass in a `decryptionKey`.\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  // Only required if you have feature encryption enabled in GrowthBook  decryptionKey: \"key_abc123\",});await gb.init({  // If the network request takes longer than this (in milliseconds), continue  // Default: `0` (no timeout)  timeout: 2000,})\n```\n\nUntil features are loaded, all features will evaluate to `null`. If you're ok with a potential flicker in your application (features going from `null` to their real value), you can call `init` without awaiting the result.\n\nIf you want to refresh the features at any time (e.g. when a navigation event occurs), you can call `gb.refreshFeatures()`.\n\n#### Error Handling[​](#error-handling \"Direct link to Error Handling\")\n\nIn the case of network issues, the `init` call will not throw an error. Instead, it will stay in the default state where every feature evaluates to `null`.\n\nYou can still get access to the error if needed:\n\n```\nconst res = await gb.init({  timeout: 1000});console.log(res);\n```\n\nThe return value has 3 properties:\n\n*   **status** - `true` if the GrowthBook instance was populated with features/experiments. Otherwise `false`\n*   **source** - Where this result came from. One of the following values: `network`, `cache`, `init`, `error`, or `timeout`\n*   **error** - If status is `false`, this will contain an `Error` object with more details about the error\n\n### Custom Integration[​](#custom-integration \"Direct link to Custom Integration\")\n\nIf you prefer to handle the network and caching logic yourself, you can pass in a full JSON \"payload\" directly into the SDK. For example, you might store features in Postgres and send it down to your front-end as part of your app's initial bootstrap API call.\n\n```\nawait gb.init({  payload: {    features: {      \"feature-1\": {...},      \"feature-2\": {...},      \"another-feature\": {...},    }  }})\n```\n\nThe data structure for \"payload\" is exactly the same as what is returned by the GrowthBook SDK endpoints and webhooks.\n\nYou can update the payload at any time by calling `setPayload(newPayloadJSON)` and there are also `getPayload()` and `getDecryptedPayload()` methods, which are useful in hybrid apps where you want to hydrate the client with data from the server.\n\nNote: you don't need to specify `clientKey` or `apiHost` on your GrowthBook instance unless you want to enable streaming (see below) or call `refreshFeatures()` later.\n\n#### Synchronous Init[​](#synchronous-init \"Direct link to Synchronous Init\")\n\nThere is a alternate synchronous version of init named `initSync`, which can be especially useful in SSR to prevent hydration mismatches. There are some restrictions/differences:\n\n*   You MUST pass in `payload`\n*   The `payload` MUST NOT have encrypted features or experiments\n*   If you use sticky bucketing, you MUST pass `stickyBucketAssignmentDocs` into your GrowthBook constructor\n*   The return value is the GrowthBook instance to enable easy method chaining\n\n## Waiting for Features to Load[​](#waiting-for-features-to-load \"Direct link to Waiting for Features to Load\")\n\nThere is a helper component `<FeaturesReady>` that lets you render a fallback component until features are done loading. This works for both built-in fetching and custom integrations.\n\n```\n<FeaturesReady timeout={500} fallback={<LoadingSpinner/>}>  <ComponentThatUsesFeatures/></FeaturesReady>\n```\n\n*   `timeout` is the max time you want to wait for features to load (in ms). The default is `0` (no timeout).\n*   `fallback` is the component you want to display before features are loaded. The default is `null`.\n\nIf you want more control, you can use the `useGrowthBook()` hook and the `ready` flag:\n\n```\nconst gb = useGrowthBook();if (gb.ready) {  // Do something}\n```\n\n## Streaming Updates[​](#streaming-updates \"Direct link to Streaming Updates\")\n\nThe GrowthBook SDK supports streaming with Server-Sent Events (SSE). When enabled, changes to features within GrowthBook will be streamed to the SDK in realtime as they are published. This is only supported on GrowthBook Cloud or if running a GrowthBook Proxy Server.\n\n### Streaming in Browser Environments[​](#streaming-in-browser-environments \"Direct link to Streaming in Browser Environments\")\n\nSSE is supported on all major browsers, so enabling streaming is as easy as passing `streaming: true` into your `init` call:\n\n```\ngb.init({  streaming: true,  // Other settings...})\n```\n\nYou may also differentiate your streaming host URL from your API host by setting the `streamingHost` property in the GrowthBook constructor (ex: Remote Evaluation is done on a CDN edge worker while Streaming is done through a GrowthBook Proxy server).\n\n### Streaming on the Server[​](#streaming-on-the-server \"Direct link to Streaming on the Server\")\n\nNode.js does not natively support SSE, but there is a small library you can install:\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save eventsource\n```\n\nInstead of enabling streaming separately for every GrowthBook instance, we recommend opening a single shared stream at app startup instead:\n\n```\nconst { setPolyfills, prefetchPayload } = require(\"@growthbook/growthbook\");// Configure GrowthBook to use the eventsource librarysetPolyfills({  EventSource: require(\"eventsource\"),});// Start a streaming connectionprefetchPayload({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  streaming: true}).then(() => console.log(\"Streaming connection open!\"))\n```\n\nThis will work as long as you use the exact same `apiHost` and `clientKey` when creating GrowthBook instances in your middleware.\n\n### Streaming in ReactNative[​](#streaming-in-reactnative \"Direct link to Streaming in ReactNative\")\n\nSimilar to Node.js, you need to install a polyfill for SSE to use streaming in a ReactNative application:\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save eventsource\n```\n\nThe, tell GrowthBook to use this polyfill:\n\n```\nconst { setPolyfills } = require(\"@growthbook/growthbook\");// Configure GrowthBook to use the eventsource librarysetPolyfills({  EventSource: require(\"eventsource\"),});\n```\n\nAnd finally, you can simply pass `streaming: true` into your init calls:\n\n```\ngb.init({  streaming: true,  // Other options...})\n```\n\n## Remote Evaluation[​](#remote-evaluation \"Direct link to Remote Evaluation\")\n\nWhen used in a front-end context, the React SDK may be run in Remote Evaluation mode. This mode brings the security benefits of a backend SDK to the front end by evaluating feature flags exclusively on a private server. Using Remote Evaluation ensures that any sensitive information within targeting rules or unused feature variations are never seen by the client. Note that Remote Evaluation should not be used in a backend context (Hybrid SSR/CSR is also not supported).\n\nYou must enable Remote Evaluation in your SDK Connection settings. Cloud customers are also required to self-host a GrowthBook Proxy Server or custom remote evaluation backend.\n\nTo use Remote Evaluation, add the `remoteEval: true` property to your SDK instance. A new evaluation API call will be made any time a user attribute or other dependency changes. You may optionally limit these API calls to specific attribute changes by setting the `cacheKeyAttributes` property (an array of attribute names that, when changed, trigger a new evaluation call).\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://gb-proxy.mydomain.io/\",  clientKey: \"sdk-abc123\",  // Enable remote evaluation  remoteEval: true,  // Optional: only trigger a new evaluation call when the `id` and `email` attribute changes  cacheKeyAttributes: [\"id\", \"email\"],});\n```\n\nnote\n\nIf you would like to implement Sticky Bucketing while using Remote Evaluation, you must configure your remote evaluation backend to support Sticky Bucketing. In the case of the GrowthBook Proxy Server, this means implementing a Redis database for sticky bucketing use. You will not need to provide a StickyBucketService instance to the client side SDK.\n\n## Caching[​](#caching \"Direct link to Caching\")\n\nThe JavaScript SDK has 2 caching layers:\n\n1.  In-memory cache (available on all platforms)\n2.  Persistent localStorage cache (only available in browsers by default)\n\nThere are a number of cache settings you can configure within GrowthBook. This must be done BEFORE creating a GrowthBook instance.\n\nBelow are all of the default values. You can call `configureCache` with a subset of these fields and the rest will keep their default values.\n\n```\nimport { configureCache } from \"@growthbook/growthbook\";configureCache({  // The localStorage key the cache will be stored under  cacheKey: \"gbFeaturesCache\",  // Consider features stale after this much time (60 seconds default)  staleTTL: 1000 * 60,  // Cached features older than this will be ignored (24 hours default)  maxAge: 1000 * 60 * 60 * 24,  // For Remote Eval only - limit the number of cache entries (~1 entry per user)  maxEntries: 10,  // When `false`, we add a `visibilitychange` listener to disable SSE when the page is idle  disableIdleStreams: false,  // Consider a page \"idle\" when it is hidden for this long (default 20 seconds)  idleStreamInterval: 20000,  // Set to `true` to completely disable both in-memory and persistent caching  disableCache: false,})\n```\n\n### Polyfilling localStorage[​](#polyfilling-localstorage \"Direct link to Polyfilling localStorage\")\n\nOutside of a browser environment, you can still use persistent caching. You just need to provide an implementation of the localStorage interface.\n\nHere's an example of using Redis in Node.js:\n\n```\nconst { setPolyfills } = require(\"@growthbook/growthbook\");setPolyfills({  localStorage: {    // Example using Redis    getItem: (key) => redisClient.get(key),    setItem: (key, value) => redisClient.set(key, value),  }});\n```\n\nThis must be done BEFORE you call either `prefetchPayload` or create the first GrowthBook instance.\n\n## Experimentation (A/B Testing)[​](#experimentation-ab-testing \"Direct link to Experimentation (A/B Testing)\")\n\nIn order to run A/B tests, you need to set up a tracking callback function. This is called every time a user is put into an experiment and can be used to track the exposure event in your analytics system (Segment, Mixpanel, GA, etc.).\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  trackingCallback: (experiment, result) => {    // Example using Segment    analytics.track(\"Experiment Viewed\", {      experimentId: experiment.key,      variationId: result.key,    });  },});\n```\n\nThis same tracking callback is used for both feature flag experiments and Visual Editor experiments.\n\n### Feature Flag Experiments[​](#feature-flag-experiments \"Direct link to Feature Flag Experiments\")\n\nThere is nothing special you have to do for feature flag experiments. Just evaluate the feature flag like you would normally do. If the user is put into an experiment as part of the feature flag, it will call the `trackingCallback` automatically in the background.\n\n```\n// If this has an active experiment and the user is included,// it will call trackingCallback automaticallyuseFeatureIsOn(\"new-signup-form\")\n```\n\nIf the experiment came from a feature rule, `result.featureId` in the trackingCallback will contain the feature id, which may be useful for tracking/logging purposes.\n\n### Visual Editor Experiments[​](#visual-editor-experiments \"Direct link to Visual Editor Experiments\")\n\nExperiments created through the GrowthBook Visual Editor will run automatically as soon as their targeting conditions are met.\n\n**Note**: Visual Editor experiments are only supported in a web browser environment. They will not run in React Native or during Server Side Rendering (SSR).\n\nIf you are using this SDK in a Single Page App (SPA), you will need to let the GrowthBook instance know when the URL changes so the active experiments can update accordingly.\n\nFor example, in Next.js, you could do this:\n\n```\nfunction updateGrowthBookURL() {  gb.setURL(window.location.href);}export default function MyApp() {  // Subscribe to route change events and update GrowthBook  const router = useRouter();  useEffect(() => {    router.events.on(\"routeChangeComplete\", updateGrowthBookURL);    return () => router.events.off(\"routeChangeComplete\", updateGrowthBookURL);  }, []);  // ...}\n```\n\n### URL Redirect Experiments[​](#url-redirect-experiments \"Direct link to URL Redirect Experiments\")\n\nSimilarly to Visual Editor experiments, URL redirect tests will run automatically if targetting conditions are met.\n\nIf you are using this SDK in a Single Page App (SPA), you'll want to pass in a custom navigation function into the SDK (as default navigation for URL Redirects uses `window.location.replace(url)`) and set the `navigateDelay` to 0.\n\n```\n// Example in Next.jsimport router from \"next/router\";const gb = new GrowthBook({    navigate: (url) => router.replace(url),    navigateDelay: 0,    // ... other settings});\n```\n\nFor SPA's you will also need to let the GrowthBook instance know when the URL changes so the active experiments can update accordingly.\n\n```\n// Call this every time a navigation event happens in your SPAfunction onRouteChange() {  gb.setURL(window.location.href);}\n```\n\n### Sticky Bucketing[​](#sticky-bucketing \"Direct link to Sticky Bucketing\")\n\nSticky bucketing ensures that users see the same experiment variant, even when user session, user login status, or experiment parameters change. See the [Sticky Bucketing docs](https://docs.growthbook.io/app/sticky-bucketing) for more information. If your organization and experiment supports sticky bucketing, you must implement an instance of the `StickyBucketService` to use Sticky Bucketing. The JS SDK exports several implementations of this service for common use cases, or you may build your own:\n\n*   `LocalStorageStickyBucketService` — For simple bucket persistence using the browser's LocalStorage (can be polyfilled for other environments).\n    \n*   `BrowserCookieStickyBucketService` — For simple bucket persistence using browser cookies, which are transportable to the back end. Assumes `js-cookie` is implemented (can be polyfilled). Cookie attributes can also be configured.\n    \n*   `ExpressCookieStickyBucketService` — For NodeJS/Express controller-level bucket persistence using browser cookies; intended to be interoperable with `BrowserCookieStickyBucketService`. Assumes `cookie-parser` is implemented (can be polyfilled). Cookie attributes can also be configured.\n    \n*   `RedisStickyBucketService` — For NodeJS Redis-based bucket persistence. Requires an `ioredis` Redis client instance to be passed in.\n    \n*   Build your own — Implement the abstract `StickyBucketService` class and connect to your own data store, or custom wrap multiple service implementations (ex: read/write to both cookies and Redis).\n    \n\nImplementing most StickyBucketService implementations is straightforward and works with minimal setup. For instance, to use the `BrowserCookieStickyBucketService`:\n\n```\nimport { BrowserCookieStickyBucketService } from \"@growthbook/growthbook\";import Cookies from 'js-cookie';const gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  stickyBucketService: new BrowserCookieStickyBucketService({    jsCookie: Cookies,  }),  // ...});\n```\n\n## Next.js[​](#nextjs \"Direct link to Next.js\")\n\nIf you are using Next.js, checkout our example apps for [Next with App Router](https://github.com/growthbook/examples/tree/main/next-js) and [Next with Pages Router](https://github.com/growthbook/examples/tree/main/next-js-pages).\n\nThe examples above show how to use GrowthBook with a number of different rendering strategies and app setups and the App Router example has been updated to support the latest features in Next 14.\n\n## Server Side Rendering (SSR)[​](#server-side-rendering-ssr \"Direct link to Server Side Rendering (SSR)\")\n\nThis SDK fully supports server side rendering with React.\n\n### React Server Components[​](#react-server-components \"Direct link to React Server Components\")\n\nIf your framework supports the new React Server Components (RSC), welcome to the future! GrowthBook works great with modern React.\n\nFirst, if you are running experiments with GrowthBook, you will need to fire analytics tracking calls to record which variation a user is assigned. Analytics tools are often only supported client-side, so you can create a small Client Component first:\n\n```\n\"use client\";import { TrackingData } from \"@growthbook/growthbook-react\";// Helper component to track experiment views from server componentsexport default function GrowthBookTracking({ data }: { data: TrackingData[] }) {  useEffect(() => {    data.forEach(({ experiment, result }) => {      console.log(\"Viewed Experiment\", {        experimentId: experiment.key,        variationId: result.key      });    });  }, [data])  return null;}\n```\n\nThe React SDK relies on client-side Context, so for Server Components, you need to import our Javascript SDK `@growthbook/growthbook` instead.\n\n```\nimport { GrowthBook } from \"@growthbook/growthbook\";import GrowthBookTracking from \"./GrowthBookTracking\";export default async function MyServerPage() { // Create and initialize a GrowthBook instance  const gb = new GrowthBook({    apiHost: process.env.NEXT_PUBLIC_GROWTHBOOK_API_HOST,    clientKey: process.env.NEXT_PUBLIC_GROWTHBOOK_CLIENT_KEY,    decryptionKey: process.env.NEXT_PUBLIC_GROWTHBOOK_DECRYPTION_KEY,  });  await gb.init({ timeout: 1000 });  // Set targeting attributes for the user/page  await gb.setAttributes({    // TODO: get this from cookies, headers, etc.    id: cookies().get(\"my_uuid\")?.value || \"\",  });  // Evaluate any feature flags  const showBanner = gb.isOn(\"showBanner\");  const title = gb.getFeatureValue(\"title\", \"My Site\");  // If the above features ran any experiments, get the tracking call data  // This is passed into the <GrowthBookTracking> client component below  const trackingData = gb.getDeferredTrackingCalls();  // Cleanup  gb.destroy();  return (    <div>      <h1>{title}</h1>      {showBanner && (        <div className=\"sale\">There's a Sale!</div>      )}      <GrowthBookTracking data={trackingData} />    </div>  );}\n```\n\n#### Hydrating Client Components From the Server[​](#hydrating-client-components-from-the-server \"Direct link to Hydrating Client Components From the Server\")\n\nThe best part about React Server Components, is that you can easily share feature definitions with your Client Components. By doing this, you avoid any network requests from the browser and any flickering that goes along with that.\n\nLet's first create a GrowthBookWrapper wrapper that takes a `payload` prop and uses it to initialize a GrowthBook instance:\n\n```\n\"use client\";import {  GrowthBook,  GrowthBookProvider,  GrowthBookPayload} from \"@growthbook/growthbook-react\";import { PropsWithChildren, useMemo } from \"react\";import Cookies from \"js-cookie\";export default function GrowthBookWrapper({  payload,  children,}: PropsWithChildren<{ payload: GrowthBookPayload }>) {  // Create a singleton GrowthBook instance for this page  const gb = useMemo(    () =>      new GrowthBook({        apiHost: process.env.NEXT_PUBLIC_GROWTHBOOK_API_HOST,        clientKey: process.env.NEXT_PUBLIC_GROWTHBOOK_CLIENT_KEY,        decryptionKey: process.env.NEXT_PUBLIC_GROWTHBOOK_DECRYPTION_KEY,        trackingCallback: (experiment, result) => {          console.log(\"Viewed Experiment\", {            experimentId: experiment.key,            variationId: result.key          });        },        // Targeting attributes        attributes: {          id: Cookies.get(\"my_uuid\"),        },      }).initSync({        payload,        // Optional, enable streaming updates        streaming: true,      }),    [payload]  );  return <GrowthBookProvider growthbook={gb}>{children}</GrowthBookProvider>;}\n```\n\nNow we'll make a really simple client component using the GrowthBook React SDK:\n\n```\n\"use client\";import { useFeatureIsOn } from \"@growthbook/growthbook-react\";export default function OtherComponent() {  const clientFeature = useFeatureIsOn(\"client-feature\");  return (    <p>Client feature: {clientFeature ? \"ON\" : \"OFF\"}</p>  )}\n```\n\nNow, we can render these from our server component:\n\n```\nimport { GrowthBook } from \"@growthbook/growthbook\";import GrowthBookWrapper from \"./GrowthBookWrapper\";import OtherComponent from \"./OtherComponent\";import GrowthBookTracking from \"./GrowthBookTracking\";export default async function MyServerPage() {  // Create and initialize a GrowthBook instance  const gb = new GrowthBook({    apiHost: process.env.NEXT_PUBLIC_GROWTHBOOK_API_HOST,    clientKey: process.env.NEXT_PUBLIC_GROWTHBOOK_CLIENT_KEY,    decryptionKey: process.env.NEXT_PUBLIC_GROWTHBOOK_DECRYPTION_KEY,  });  await gb.init({ timeout: 1000 });  // Set targeting attributes for the user  gb.setAttributes({    id: cookies().get(\"my_uuid\")?.value || \"\",  });  // Evaluate any feature flags  const serverFeature = gb.isOn(\"server-feature\");  // If the above features ran any experiments, get the tracking call data  // This is passed into the <GrowthBookTracking> client component below  const trackingData = gb.getDeferredTrackingCalls();  // Get the payload to hydrate the client-side GrowthBook instance  // We need the decrypted payload so the initial client-render can be synchronous  const payload = gb.getDecryptedPayload();  // Cleanup your GrowthBook instance  gb.destroy();  return (    <div>      <p>Server feature: {serverFeature ? \"ON\" : \"OFF\"}</p>      <GrowthBookWrapper payload={payload}>        <OtherComponent>      </GrowthBookWrapper>      <GrowthBookTracking data={trackingData} />    </div>  );}\n```\n\n### Traditional SSR[​](#traditional-ssr \"Direct link to Traditional SSR\")\n\nBefore React Server Components, each framework implemented their own way to do data fetching and SSR. This example uses Next.js `getServerSideProps` method, but other frameworks should be similar.\n\nWith this approach, feature flags are evaluated once when the page is rendered. If a feature flag changes, the user would need to refresh the page to see it.\n\n```\nexport const getServerSideProps = async (context) => {  // Create and initialize a GrowthBook instance  const gb = new GrowthBook({    apiHost: process.env.GROWTHBOOK_API_HOST,    clientKey: process.env.GROWTHBOOK_CLIENT_KEY,    decryptionKey: process.env.GROWTHBOOK_DECRYPTION_KEY,  });  await gb.init({ timeout: 1000 });  // Set targeting attributes for the user  await gb.setAttributes({    id: context?.cookies?.my_uuid || \"\",  });  // Evaluate any feature flags  const showBanner = gb.isOn(\"show-banner\");  const title = gb.getFeatureValue(\"title\", \"My Site\");  // If the above features ran any experiments, get the tracking call data  // This is passed into the <GrowthBookTracking> client component below  const trackingData = gb.getDeferredTrackingCalls();  // Cleanup  gb.destroy();  // Pass the result into your component  return {    props: {      showBanner,      title,      trackingData    }  }}export default function MyPage({ title, showBanner, trackingData }) {  useEffect(() => {    trackingData?.forEach(({experiment, result}) => {      // TODO: Track in your analytics tool      console.log(\"Viewed Experiment\", {        experimentId: experiment.key,        variationId: result.key      });    });  }, [trackingData])  return (    <div>      <h1>{title}</h1>      {showBanner && (        <div className=\"sale\">There's a Sale!</div>      )}    </div>  )}\n```\n\n#### Hybrid (SSR + Client-side)[​](#hybrid-ssr--client-side \"Direct link to Hybrid (SSR + Client-side)\")\n\nInstead of passing the result of individual feature flags to your component, you can also pass the entire payload. By doing this, you get the benefits of client-side rendering (interactivity, realtime feature flag updates) plus the benefits of SSR (no flickering, improved SEO).\n\n```\nexport const getServerSideProps = async (context) => {  // Create and initialize a GrowthBook instance  const gb = new GrowthBook({    apiHost: process.env.NEXT_PUBLIC_GROWTHBOOK_API_HOST,    clientKey: process.env.NEXT_PUBLIC_GROWTHBOOK_CLIENT_KEY,    decryptionKey: process.env.NEXT_PUBLIC_GROWTHBOOK_DECRYPTION_KEY,  });  await gb.init({ timeout: 1000 });  // Get the payload to hydrate the client-side GrowthBook instance  // We need the decrypted payload so the initial client-render can be synchronous  const payload = gb.getDecryptedPayload();  // Cleanup  gb.destroy();  // Pass the result into your component  return {    props: {      payload    }  }}export default function MyPage({ payload }) {  // Create a singleton GrowthBook instance for this page  const gb = useMemo(    () =>      new GrowthBook({        apiHost: process.env.NEXT_PUBLIC_GROWTHBOOK_API_HOST,        clientKey: process.env.NEXT_PUBLIC_GROWTHBOOK_CLIENT_KEY,        decryptionKey: process.env.NEXT_PUBLIC_GROWTHBOOK_DECRYPTION_KEY,        trackingCallback: (experiment, result) => {          console.log(\"Viewed Experiment\", {            experimentId: experiment.key,            variationId: result.key          });        },        attributes: {          id: Cookies.get(\"my_uuid\"),        },      }).initSync({        payload,        // Optional, enable streaming updates        streaming: true,      }),    [payload]  );  return <GrowthBookProvider growthbook={gb}><MyComponent></GrowthBookProvider>;}\n```\n\nThen, within `MyComponent`, you can use any of the normal client-side hooks or helper components - `useFeatureIsOn`, `useFeatureValue`, etc.\n\n## API Reference[​](#api-reference \"Direct link to API Reference\")\n\nThere are a number of configuration options and settings that control how GrowthBook behaves.\n\n### Attributes[​](#attributes \"Direct link to Attributes\")\n\nYou can specify attributes about the current user and request. These are used for two things:\n\n1.  Feature targeting (e.g. paid users get one value, free users get another)\n2.  Assigning persistent variations in A/B tests (e.g. user id \"123\" always gets variation B)\n\nThe following are some commonly used attributes, but use whatever makes sense for your application.\n\n```\nnew GrowthBook({  attributes: {    id: \"123\",    loggedIn: true,    deviceId: \"abc123def456\",    company: \"acme\",    paid: false,    url: \"/pricing\",    browser: \"chrome\",    mobile: false,    country: \"US\",  },});\n```\n\n#### Updating Attributes[​](#updating-attributes \"Direct link to Updating Attributes\")\n\nIf attributes change, you can call `setAttributes()` to update. This will completely overwrite any existing attributes. To do a partial update, use the following pattern:\n\n```\ngb.setAttributes({  // Only update the `url` attribute, keep the rest the same  ...gb.getAttributes(),  url: \"/new-page\"})\n```\n\n#### Secure Attributes[​](#secure-attributes \"Direct link to Secure Attributes\")\n\nWhen _secure attribute hashing_ is enabled, all targeting conditions in the SDK payload referencing attributes with datatype `secureString` or `secureString[]` will be anonymized via SHA-256 hashing. This allows you to safely target users based on sensitive attributes. You must enable this feature in your SDK Connection for it to take effect.\n\nIf your SDK Connection has secure attribute hashing enabled, you will need to manually hash any `secureString` or `secureString[]` attributes that you pass into the GrowthBook SDK.\n\nTo hash an attribute, use a cryptographic library with SHA-256 support, and compute the SHA-256 hashed value of your attribute _plus_ your organization's secure attribute salt.\n\n```\nconst salt = \"f09jq3fij\"; // Your organization's secure attribute salt (see Organization Settings)// hashing a secureString attributeconst userEmail = sha256(salt + user.email);// hashing an secureString[] attributeconst userTags = user.tags.map(tag => sha256(salt + tag));gb.setAttributes({  id: user.id,  loggedIn: true,  email: userEmail,  tags: userTags,});await gb.init();// In this example, we are using Node.js's built-in crypto libraryfunction sha256(str) {  return crypto.createHash(\"sha256\").update(str).digest(\"hex\");}\n```\n\nNote that in a browser context, we will not be able to natively access the Node.js crypto library. In modern browsers `window.crypto.subtle` is available, although calls are asynchronous. You would need to await all attribute hashing to complete before calling `gb.setAttributes()`.\n\n```\nasync function sha256(str) {  const buffer = await crypto.subtle.digest(\"SHA-256\", new TextEncoder().encode(str));  const hashArray = Array.from(new Uint8Array(buffer));  return hashArray.map(byte => byte.toString(16).padStart(2, \"0\")).join(\"\");}\n```\n\nAlternatively, CryptoJS ([https://www.npmjs.com/package/crypto-js](https://www.npmjs.com/package/crypto-js)) provides a synchronous API:\n\n```\nimport sha256 from 'crypto-js/sha256';const userEmail = sha256(salt + user.email);\n```\n\n### Feature Usage Callback[​](#feature-usage-callback \"Direct link to Feature Usage Callback\")\n\nGrowthBook can fire a callback whenever a feature is evaluated for a user. This can be useful to update 3rd party tools like NewRelic or DataDog.\n\n```\nnew GrowthBook({  onFeatureUsage: (featureKey, result) => {    console.log(\"feature\", featureKey, \"has value\", result.value);  },});\n```\n\nNote: If you evaluate the same feature multiple times (and the value doesn't change), the callback will only be fired the first time.\n\n### Dev Mode[​](#dev-mode \"Direct link to Dev Mode\")\n\nThere is a [GrowthBook Chrome DevTools Extension](https://chrome.google.com/webstore/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia) that can help you debug and test your feature flags in development.\n\nIn order for this to work, you must explicitly enable dev mode when creating your GrowthBook instance:\n\n```\nconst gb = new GrowthBook({  enableDevMode: true,});\n```\n\nTo avoid exposing all of your internal feature flags and experiments to users, we recommend setting this to `false` in production in most cases.\n\n### Inline Experiments[​](#inline-experiments \"Direct link to Inline Experiments\")\n\nDepending on how you configure feature flags, they may run A/B tests behind the scenes to determine which value gets assigned to the user.\n\nSometimes though, you want to run an inline experiment without going through a feature flag first. For this, you can use either the `useExperiment` hook or the Higher Order Component `withRunExperiment`:\n\nView the [Javascript SDK Docs](https://docs.growthbook.io/lib/js) for all of the options available for inline experiments\n\n#### useExperiment hook[​](#useexperiment-hook \"Direct link to useExperiment hook\")\n\n```\nimport { useExperiment } from \"@growthbook/growthbook-react\";export default function OtherComponent() {  const { value } = useExperiment({    key: \"new-headline\",    variations: [\"Hello\", \"Hi\", \"Good Day\"]  });  return <h1>{value}</h1>;}\n```\n\n#### withRunExperiment (class components)[​](#withrunexperiment-class-components \"Direct link to withRunExperiment (class components)\")\n\n**Note:** This library uses hooks internally, so still requires React 16.8 or above.\n\n```\nimport { withRunExperiment } from \"@growthbook/growthbook-react\";class OtherComponent extends React.Component {  render() {    // The `runExperiment` prop is identical to the `useExperiment` hook    const { value } = this.props.runExperiment({      key: \"headline-test\",      variations: [\"Hello World\", \"Hola Mundo\"]    });    return <h1>{value}</h1>;  }}// Wrap your component in `withRunExperiment`export default withRunExperiment(OtherComponent);\n```\n\n## TypeScript support[​](#typescript-support \"Direct link to TypeScript support\")\n\nSome hooks are available in type-safe versions. These require you to pass in your generated types as the generic argument.\n\nSee the [GrowthBook CLI](https://docs.growthbook.io/tools/cli) documentation for more information on generating type definitions and [JavaScript → TypeScript → Scrict Typing](https://docs.growthbook.io/lib/js#strict-typing) for how to use them.\n\n### useGrowthBook<T>()[​](#usegrowthbookt \"Direct link to useGrowthBook<T>()\")\n\nA type-safe version of the `useGrowthBook()` hook is available. Everywhere you use `useGrowthBook()`, pass the generated features as the generic argument:\n\n```\nconst growthbook = useGrowthBook<AppFeatures>()\n```\n\nIn that case, the hook will return `GrowthBook<AppFeatures> | undefined`.\n\nYou can reduce this boilerplate by creating your own hook, e.g.:\n\n```\n// ./src/utils/growthbook.tsimport { useGrowthBook as _useGrowthBook } from \"@growthbook/growthbook-react\";export const useGrowthBook = (): GrowthBook<AppFeatures> | undefined =>  _useGrowthBook<AppFeatures>();\n```\n\nYou can now reference the hook you created instead of the one from the official package:\n\n```\nimport { useGrowthBook } from \"@/src/utils/growthbook\"const growthbook = useGrowthBook();growthbook.getFeatureValue(knownKey, defaultValueOfValidType)\n```\n\n### useFeatureIsOn<T>()[​](#usefeatureisont \"Direct link to useFeatureIsOn<T>()\")\n\nThe React SDK also provides access to a type-safe `useFeatureIsOn<AppFeatures>()` hook.\n\n```\nconst isDarkModeOn = useFeatureIsOn<AppFeatures>(\"dark_mode\");\n```\n\nThis will only allow you to pass known keys to the hook.\n\nYou can reduce the boilerplate for this hook by creating your own and using that instead:\n\n```\n// ./src/utils/growthbook.tsimport { useFeatureIsOn as _useFeatureIsOn } from \"@growthbook/growthbook-react\";export const useFeatureIsOn = (id: keyof AppFeatures & string): boolean =>  _useFeatureIsOn<AppFeatures>(id);\n```\n\nAnd then reference the hook you created instead of the one from the official package:\n\n```\nimport { useFeatureIsOn } from \"@/src/utils/growthbook\"const isDarkModeOn = useFeatureIsOn(\"dark_mode\");\n```\n\n## Examples[​](#examples \"Direct link to Examples\")\n\n*   [Next.js](https://github.com/growthbook/examples/tree/main/next-js)\n*   [React Native](https://github.com/growthbook/examples/tree/main/react-native-cli)\n*   [Typescript example app with strict typing](https://github.com/growthbook/examples/tree/main/vanilla-typescript) .",
  "title": "React SDK | GrowthBook Docs",
  "description": "GrowthBook SDK for React",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/warehouses/databricks",
  "markdown": "# Setting up Databricks as a data source\n\nTo connect to Databricks, you need to provide GrowthBook with the connection details and access token to the SQL Warehouse you use within Databricks.\n\n## 1\\. Find the connection details for your SQL Warehouse[​](#1-find-the-connection-details-for-your-sql-warehouse \"Direct link to 1. Find the connection details for your SQL Warehouse\")\n\nIn your Databricks instance, navigate to the SQL Warehouses, select your SQL Warehouse that stores the data you want GrowthBook to access, and the click Connection Details. You should see the following page, which contains most of the fields needed to connect GrowthBook to your Databricks SQL Warehouse.\n\n![Finding SQL Warehouse Connection Details in Databricks](https://docs.growthbook.io/images/guides/databricks-connection.png)\n\n## 2\\. Create an access token for GrowthBook[​](#2-create-an-access-token-for-growthbook \"Direct link to 2. Create an access token for GrowthBook\")\n\nThere are two kinds of access tokens that will work to connect GrowthBook to Databricks:\n\n*   A personal access token for a user account\n*   A personal access token for a service principal\n\nWhichever path you choose, ensure the service principal or the user has permission to execute SQL queries against your SQL Warehouse.\n\nFollow these instructions to create a service principal and create an access token for the service principal: [https://docs.databricks.com/en/dev-tools/service-principals.html](https://docs.databricks.com/en/dev-tools/service-principals.html)\n\nAlternatively, you can create a personal access token for a Databricks workspace user following these instructions: [https://docs.databricks.com/en/dev-tools/auth.html#pat](https://docs.databricks.com/en/dev-tools/auth.html#pat)\n\n## 3\\. Add credentials to GrowthBook[​](#3-add-credentials-to-growthbook \"Direct link to 3. Add credentials to GrowthBook\")\n\nNow that you have the connection details and an access token, you can enter the Connection Details and Access Token to GrowthBook when when creating a Data Source!\n\nClick \"Add a Datasource\" from the Data Sources page under Metrics and Data and either select your event tracker or click \"custom data source\". Then you can select Databricks as your data warehouse and enter the above credentials.\n\nNote: We only use the event tracker (e.g. Snowplow, Segment) to help us build queries for you. This information **does not** impact how or whether we are able to connect to Databricks.",
  "title": "Setting up Databricks as a data source | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your Databricks database to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/warehouses/mixpanel",
  "markdown": "# Setting up Mixpanel as a data source\n\ntip\n\nYou can find a more detailed walk through for setting up Mixpanel [here](https://docs.growthbook.io/guide/mixpanel)\n\nYou must first create a Service Account in Mixpanel under your [Project Settings](https://mixpanel.com/settings/project#serviceaccounts).\n\nTo add the datasource in GrowthBook, you will need:\n\n1.  The service account username\n2.  The service account secret\n3.  Your project id (found on the Project Settings Overview page)",
  "title": "Setting up Mixpanel as a data source | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your Mixpanel database to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/warehouses/ms-sql-or-sql-server",
  "markdown": "# Setting up MS SQL or SQL Server as a data source\n\nWhen setting up MS SQL or SQL Server to work with Growthbook, remember it's important to create read-only users with minimal permissions, ideally granting only read access to the relevant data tables that need to be aggregated.\n\nIf you are using GrowthBook Cloud (app.growthbook.io), make sure to whitelist the ip address `52.70.79.40` if applicable.\n\nUnfortunately there isn't a specific guide for setting up MS SQL or SQL Server for Growthbook yet. However, if you encounter any difficulties while setting up your data source, you can seek assistance from our active developer community on [Slack](https://slack.growthbook.io/?ref=docs-datasource-ms-sql-or-sql-server). They can help you troubleshoot and ensure your implementation is successful. Once you've successfully set up MS SQL or SQL Server according to best practices, we encourage you to contributing to the community by [creating improved documentation for MS SQL or SQL Server](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs). Your contribution will benefit other users in the future.",
  "title": "Setting up MS SQL or SQL Server as a data source | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your MS SQL or SQL Server database to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/warehouses/mysql-or-mariadb",
  "markdown": "# Setting up MySQL or MariaDB as a data source\n\nWhen setting up MySQL or MariaDB to work with Growthbook, remember it's important to create read-only users with minimal permissions, ideally granting only read access to the relevant data tables that need to be aggregated.\n\nIf you are using GrowthBook Cloud (app.growthbook.io), make sure to whitelist the ip address `52.70.79.40` if applicable.\n\nUnfortunately there isn't a specific guide for setting up MySQL or MariaDB for Growthbook yet. However, if you encounter any difficulties while setting up your data source, you can seek assistance from our active developer community on [Slack](https://slack.growthbook.io/?ref=docs-datasource-mysql-or-mariadb). They can help you troubleshoot and ensure your implementation is successful. Once you've successfully set up MySQL or MariaDB according to best practices, we encourage you to contributing to the community by [creating improved documentation for MySQL or MariaDB](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs). Your contribution will benefit other users in the future.",
  "title": "Setting up MySQL or MariaDB as a data source | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your MySQL or MariaDB database to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/warehouses/postgres",
  "markdown": "# Setting up Postgres as a data source\n\nWhen setting up Postgres to work with Growthbook, remember it's important to create read-only users with minimal permissions, ideally granting only read access to the relevant data tables that need to be aggregated.\n\nIf you are using GrowthBook Cloud (app.growthbook.io), make sure to whitelist the ip address `52.70.79.40` if applicable.\n\nUnfortunately there isn't a specific guide for setting up Postgres for Growthbook yet. However, if you encounter any difficulties while setting up your data source, you can seek assistance from our active developer community on [Slack](https://slack.growthbook.io/?ref=docs-datasource-postgres). They can help you troubleshoot and ensure your implementation is successful. Once you've successfully set up Postgres according to best practices, we encourage you to contributing to the community by [creating improved documentation for Postgres](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs). Your contribution will benefit other users in the future.",
  "title": "Setting up Postgres as a data source | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your Postgres database to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/warehouses/prestodb-or-trino",
  "markdown": "# Setting up Prestodb or Trino as a data source\n\nWhen setting up Prestodb or Trino to work with Growthbook, remember it's important to create read-only users with minimal permissions, ideally granting only read access to the relevant data tables that need to be aggregated.\n\nIf you are using GrowthBook Cloud (app.growthbook.io), make sure to whitelist the ip address `52.70.79.40` if applicable.\n\nUnfortunately there isn't a specific guide for setting up Prestodb or Trino for Growthbook yet. However, if you encounter any difficulties while setting up your data source, you can seek assistance from our active developer community on [Slack](https://slack.growthbook.io/?ref=docs-datasource-prestodb-or-trino). They can help you troubleshoot and ensure your implementation is successful. Once you've successfully set up Prestodb or Trino according to best practices, we encourage you to contributing to the community by [creating improved documentation for Prestodb or Trino](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs). Your contribution will benefit other users in the future.",
  "title": "Setting up Prestodb or Trino as a data source | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your Prestodb or Trino database to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/warehouses/redshift",
  "markdown": "# Setting up Redshift as a data source\n\nWhen setting up Redshift to work with Growthbook, remember it's important to create read-only users with minimal permissions, ideally granting only read access to the relevant data tables that need to be aggregated.\n\nIf you are using GrowthBook Cloud (app.growthbook.io), make sure to whitelist the ip address `52.70.79.40` if applicable.\n\nUnfortunately there isn't a specific guide for setting up Redshift for Growthbook yet. However, if you encounter any difficulties while setting up your data source, you can seek assistance from our active developer community on [Slack](https://slack.growthbook.io/?ref=docs-datasource-redshift). They can help you troubleshoot and ensure your implementation is successful. Once you've successfully set up Redshift according to best practices, we encourage you to contributing to the community by [creating improved documentation for Redshift](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs). Your contribution will benefit other users in the future.",
  "title": "Setting up Redshift as a data source | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your Redshift database to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/app/data-pipeline",
  "markdown": "# Data Pipeline | GrowthBook Docs\n\nnote\n\nPipeline mode is only available for Enterprise customers and is currently only available for BigQuery, Snowflake, and Databricks Data Sources.\n\nFor experimenters who have multiple metrics per experiment and have large experiment assignment sources, GrowthBook can greatly improve the performance of your queries if you enable **Pipeline Mode**, writing some intermediate tables back to your warehouse with short retention and re-using those across metric analyses in an experiment. This depends a bit on your datasource cost structure, but if you are billed by rows scanned, pipeline mode will almost certainly provide substantial savings.\n\nWith **Pipeline Mode** enabled, whenever an experiment analysis is run, GrowthBook dedupes your experiment assignment source, joins any relevant activation or dimension data, and then stores that deduped experiment assignment table to be re-used by the individual metric analyses.\n\nThe only change from enabling pipeline mode is that we materialize one intermediate table per experiment analysis that will have the number of rows equal to the number of experiment units in that experiment. Enabling pipeline mode has no impact on any of your analysis settings or experiment results and we do not access any more data than if pipeline mode is disabled.\n\nTo enable Pipeline Mode, follow the steps for your data warehouse:\n\n### BigQuery[​](#bigquery \"Direct link to BigQuery\")\n\n1.  (strongly recommended, but optional) Create a dedicated dataset to which GrowthBook will write temporary tables. This will keep your data warehouse clean and ensure that we are only writing to a dedicated space.\n2.  Grant permissions to create tables to the role connecting GrowthBook to your warehouse. You can do this by granting your GrowthBook Service Account the `BigQuery Data Editor` role on the new datahouse. You can also give only BigQuery table reading and writing permissions on that dataset if you want to be more restrictive.\n3.  Navigate to your BigQuery Data Source in GrowthBook and scroll down to \"Data Pipeline Settings\"\n4.  Click \"Edit\" and enable pipeline mode, set the destination dataset to your new dedicated GrowthBook dataset from step 1, and set the number of hours you will retain our temporary tables. We recommend at least 6 hours and the default is 24.\n\n### Snowflake[​](#snowflake \"Direct link to Snowflake\")\n\n1.  (strongly recommended, but optional) Create a dedicated schema to which GrowthBook will write temporary tables. This will keep your data warehouse clean and ensure that we are only writing to a dedicated space.\n2.  Grant permissions to create tables to the role connecting GrowthBook to your warehouse. The Snowflake role attached to GrowthBook will need `CREATE TABLE`, `SELECT - FUTURE TABLE`, and `USAGE` on the schema created in step 1.\n3.  Navigate to your Snowflake Data Source in GrowthBook and scroll down to \"Data Pipeline Settings\"\n4.  Click \"Edit\" and enable pipeline mode, set the destination schema to your new dedicated GrowthBook schema from step 1, and set the number of hours you will retain our temporary tables. For Snowflake, we recommend leaving the value at 24 as Snowflake's retention is set in days and we will round up to the nearest day.\n\n### Databricks[​](#databricks \"Direct link to Databricks\")\n\nDatabricks works slightly differently. Instead of creating a temporary table, we create a regular table for the deduped units assignment and then `DROP` that table when analysis is completed.\n\nnote\n\nUsing pipeline mode in Databricks requires either granting DROP permissions to the Databricks account that GrowthBook uses, or leaving many tables in your schema you have to manually delete later! For this reason we strongly recommend a standalone schema for GrowthBook to use to write tables to.\n\n1.  (strongly recommended, but optional) Create a dedicated schema to which GrowthBook will write temporary tables. This will keep your data warehouse clean and ensure that we are only writing to and dropping from a dedicated space.\n2.  Grant permissions to your user account or service principal that already has read permission in your warehouse. That user/service principle will need to be able to `USE SCHEMA`, `CREATE TABLE`, `DROP TABLE`, and to `SELECT` and `EXECUTE` in the schema.\n3.  Navigate to your Databricks Data Source in GrowthBook and scroll down to \"Data Pipeline Settings\"\n4.  Click \"Edit\" and enable pipeline mode, set the destination schema to your new dedicated GrowthBook schema from step 1, and whether you want the table to be deleted (we recommend you leave this setting on as we will not re-use these tables at a later date). If this setting is off, you'll need to manually delete the tables that GrowthBook creates.",
  "title": "Data Pipeline | GrowthBook Docs",
  "description": "Learn about enabling Pipeline Mode and improving query efficiency",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/warehouses/snowflake",
  "markdown": "# Setting up Snowflake as a data source\n\nWe support multiple [account identifier](https://docs.snowflake.com/en/user-guide/admin-account-identifier.html) formats when connecting to Snowflake. An example account identifier is `xy12345.us-east-2.aws`.\n\nIf you are self-hosting GrowthBook, you can send queries to Snowflake through an Authenticated Proxy.\n\nTo enable this, set a `SNOWFLAKE_PROXY` environment variable in your GrowthBook container. Here is an example:\n\n```\nSNOWFLAKE_PROXY=http://username:password@proxyserver.company.com:80\n```\n\nEnterprise customers can enable pipeline mode, which can reduce query costs if you grant the GrowthBook service account write permissions in your data warehouse.",
  "title": "Setting up Snowflake as a data source | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your Snowflake database to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/php",
  "markdown": "# PHP SDK | GrowthBook Docs\n\nThe GrowthBook PHP SDK requires PHP version 7.1 or greater.\n\n## Installation[​](#installation \"Direct link to Installation\")\n\nGrowthBook is available on Composer:\n\n```\ncomposer require growthbook/growthbook\n```\n\n## Quick Usage[​](#quick-usage \"Direct link to Quick Usage\")\n\n```\n// Create a GrowthBook instance$growthbook = Growthbook\\Growthbook::create()  ->withAttributes([    // Targeting attributes    'id' => $userId,    'someCustomAttribute' => true  ]);// Load feature flags from the GrowthBook API// Make sure to use caching in production! (see 'Loading Features' below)$growthbook->loadFeatures(\"sdk-abc123\", \"https://cdn.growthbook.io\");// Feature gatingif ($growthbook->isOn(\"my-feature\")) {  echo \"It's on!\";} else {  echo \"It's off :(\";}// Remote configuration with fallback$color = $growthbook->getValue(\"button-color\", \"blue\");echo \"<button style='color:${color}'>Click Me!</button>\";\n```\n\nSome of the feature flags you evaluate might be running an A/B test behind the scenes which you'll want to track in your analytics system.\n\nAt the end of the request, you can loop through all experiments and track them however you want to:\n\n```\n$impressions = $growthbook->getViewedExperiments();foreach($impressions as $impression) {  // Whatever you use for event tracking  Segment::track([    \"userId\" => $userId,    \"event\" => \"Experiment Viewed\",    \"properties\" => [      \"experimentId\" => $impression->experiment->key,      \"variationId\" => $impression->result->key    ]  ]);}\n```\n\n### Loading Features[​](#loading-features \"Direct link to Loading Features\")\n\nThere are 2 ways to load features into the SDK. You can use `loadFeatures` with a Client Key and API Host. Or, you can manually fetch and cache feature flags and pass them in with the `withFeatures` method.\n\n#### loadFeatures method[​](#loadfeatures-method \"Direct link to loadFeatures method\")\n\nThe `loadFeatures` method can fetch features from the GrowthBook API for you.\n\nBy default, there is no caching enabled. You can enable it by passing any PSR16-compatible instance into the `withCache` method.\n\n**Caching is required for production usage**\n\n```\n// Any psr-16 library will workuse Cache\\Adapter\\Apcu\\ApcuCachePool;$cache = new ApcuCachePool();$growthbook = Growthbook\\Growthbook::create()  ->withCache($cache);// You can optionally pass in a TTL (default 60s)$growthbook = Growthbook\\Growthbook::create()  ->withCache($cache, 120); // Cache for 120s instead\n```\n\nTo load features, we require a PSR-17 (HttpClient) and PSR-18 (RequestFactoryInterface) compatible library like Guzzle to be installed.\n\nWe will auto-discover most HTTP libraries without any configuration required, but if you prefer to specify it explicitly, you can use the `withHttpClient` method. Note - you'll need to specify both an `HttpClient` and a `RequestFactoryInterface` implementation.\n\nThe `loadFeatures` method takes 3 arguments:\n\n*   `$clientKey` (required) - Get this from your SDK Connection in GrowthBook.\n*   `$apiHost` (optional) - Defaults to `https://cdn.growthbook.io`. If self-hosting GrowthBook, set this to your API host.\n*   `$decryptionKey` (optional) - Only required if you've enabled encryption for your SDK Connection.\n\n#### withFeatures method[​](#withfeatures-method \"Direct link to withFeatures method\")\n\nIf you prefer to have full control over the fetching/caching behavior, you can use the `withFeatures` method instead to pass an associative array of features into the SDK.\n\n```\n// From the GrowthBook API, a custom cache layer, or somewhere else$featuresJSON = '{\"my-feature\":{\"defaultValue\":true}}';// Decode into an associative array$features = json_decode($featuresJSON, true);// Pass into the Growthbook instance$growthbook = Growthbook\\Growthbook::create()  ->withFeatures($features);\n```\n\n## The Growthbook Class[​](#the-growthbook-class \"Direct link to The Growthbook Class\")\n\nThe `Growthbook` class has a number of properties. These can be set using a Fluent interface or can be passed into a constructor using an associative array. Every property also has a getter method if needed. Here's an example:\n\n```\n// Using the fluent interface$growthbook = Growthbook\\Growthbook::create()  ->withFeatures($features)  ->withAttributes($attributes);// Using the constructor$growthbook = new Growthbook\\Growthbook([  'features' => $features,  'attributes' => $attributes]);// Getter methodsprint_r($growthbook->getFeatures());print_r($growthbook->getAttributes());\n```\n\nNote: you can also use the fluent methods (e.g. `withFeatures`) at any point to update properties.\n\n### Attributes[​](#attributes \"Direct link to Attributes\")\n\nYou can specify attributes about the current user and request. These are used for two things:\n\n1.  Feature targeting (e.g. paid users get one value, free users get another)\n2.  Assigning persistent variations in A/B tests (e.g. user id \"123\" always gets variation B)\n\nAttributes can be any JSON data type - boolean, integer, float, string, or array.\n\n```\n$attributes = [  'id' => \"123\",  'loggedIn' => true,  'deviceId' => \"abc123def456\",  'age' => 21,  'tags' => [\"tag1\", \"tag2\"],  'account' => [    'age' => 90  ]];\n```\n\nIf you want to update attributes later, please note that the `withAttributes` method completely overwrites the attributes object. You can use `array_merge` if you only want to update a subset of fields:\n\n```\n// Only update the url attribute$growthbook->withAttributes(array_merge(  $growthbook->getAttributes(),  [    'url' => '/checkout'  ]));\n```\n\n### Tracking Experiments[​](#tracking-experiments \"Direct link to Tracking Experiments\")\n\nAny time an experiment is run to determine the value of a feature, you want to track that event in your analytics system.\n\nYou can either do this via a callback function:\n\n```\n$trackingCallback = function (  Growthbook\\InlineExperiment $experiment,  Growthbook\\ExperimentResult $result) {  // Segment.io example  Segment::track([    \"userId\" => $userId,    \"event\" => \"Experiment Viewed\",    \"properties\" => [      \"experimentId\" => $experiment->key,      \"variationId\" => $result->key    ]  ]);};// Fluent interface$growthbook = Growthbook\\Growthbook::create()  ->withTrackingCallback($callback);// Using the constructor$growthbook = new Growthbook([  'trackingCallback' => $trackingCallback]);// Getter method$trackingCallback = $growthbook->getTrackingCallback();\n```\n\nOr track all events at the end of the request by looping through an array:\n\n```\n$impressions = $growthbook->getViewedExperiments();foreach($impressions as $impression) {  // Segment.io example  Segment::track([    \"userId\" => $userId,    \"event\" => \"Experiment Viewed\",    \"properties\" => [      \"experimentId\" => $impression->experiment->key,      \"variationId\" => $impression->result->key    ]  ]);}\n```\n\nOr, you can pass the impressions onto your front-end and fire analytics events from there. To do this, simply add a block to your template (shown here in plain PHP, but similar idea for Twig, Blade, etc.).\n\n```\n<script><?php foreach($growthbook->getViewedExperiments() as $impression): ?>  // tracking code goes here<?php endforeach; ?></script>\n```\n\nBelow are examples for a few popular front-end tracking libraries:\n\n#### Google Analytics[​](#google-analytics \"Direct link to Google Analytics\")\n\n```\nga('send', 'event', 'experiment',  \"<?= $impression->experiment->key ?>\",  \"<?= $impression->result->variationId ?>\",  {    // Custom dimension for easier analysis    'dimension1': \"<?=      $impression->experiment->key.':'.$impression->result->key    ?>\"  });\n```\n\n#### Segment[​](#segment \"Direct link to Segment\")\n\n```\nanalytics.track(\"Experiment Viewed\", <?=json_encode([  \"experimentId\" => $impression->experiment->key,  \"variationId\" => $impression->result->key])?>);\n```\n\n#### Mixpanel[​](#mixpanel \"Direct link to Mixpanel\")\n\n```\nmixpanel.track(\"Experiment Viewed\", <?=json_encode([  'Experiment name' => $impression->experiment->key,  'Variant name' => $impression->result->key])?>);\n```\n\n### Logging[​](#logging \"Direct link to Logging\")\n\nGrowthBook can output log messages to help you debug your feature flags and experiments.\n\nWe support any PSR-3 comaptible logger. We implement a fluent interface (`withLogger`) as well as the standard LoggerAware interface (`setLogger`).\n\n```\n// Fluent interface$growthbook  ->withLogger($logger)  ->with...;// Setter$growthbook->setLogger($logger);\n```\n\n## Using Features[​](#using-features \"Direct link to Using Features\")\n\nThere are 3 main methods for interacting with features.\n\n*   `$growthbook->isOn(\"feature-key\")` returns true if the feature is on\n*   `$growthbook->isOff(\"feature-key\")` returns false if the feature is on\n*   `$growthbook->getValue(\"feature-key\", \"default\")` returns the value of the feature with a fallback\n\nIn addition, you can use `$growthbook->getFeature(\"feature-key\")` to get back a `FeatureResult` object with the following properties:\n\n*   **value** - The JSON-decoded value of the feature (or `null` if not defined)\n*   **on** and **off** - The JSON-decoded value cast to booleans\n*   **source** - Why the value was assigned to the user. One of `unknownFeature`, `defaultValue`, `force`, or `experiment`\n*   **experiment** - Information about the experiment (if any) which was used to assign the value to the user\n*   **experimentResult** - The result of the experiment (if any) which was used to assign the value to the user\n\n## Inline Experiments[​](#inline-experiments \"Direct link to Inline Experiments\")\n\nInstead of declaring all features up-front and referencing them by ids in your code, you can also just run an experiment directly. This is done with the `$growthbook->runInlineExperiment` method:\n\n```\n$exp = Growthbook\\InlineExperiment::create(  \"my-experiment\",  [\"red\", \"blue\", \"green\"]);// Either \"red\", \"blue\", or \"green\"echo $growthbook->runInlineExperiment($exp)->value;\n```\n\nAs you can see, there are 2 required parameters for experiments, a string key, and an array of variations. Variations can be any data type, not just strings.\n\nThere are a number of additional settings to control the experiment behavior. The methods are all chainable. Here's an example that shows all of the possible settings:\n\n```\n$exp = Growthbook\\InlineExperiment::create(\"my-experiment\", [\"red\",\"blue\"])  // Run a 40/60 experiment instead of the default even split (50/50)  ->withWeights([0.4, 0.6])  // Only include 20% of users in the experiment  ->withCoverage(0.2)  // Targeting conditions using a MongoDB-like syntax  ->withCondition([    'country' => 'US',    'browser' => [      '$in' => ['chrome', 'firefox']    ]  ])  // Use an alternate attribute for assigning variations (default is 'id')  ->withHashAttribute(\"sessionId\")  // Namespaces are used to run mutually exclusive experiments  // Another experiment in the \"pricing\" namespace with a non-overlapping range  //   will be mutually exclusive (e.g. [0.5, 1])  ->withNamespace(\"pricing\", 0, 0.5);\n```\n\n### Inline Experiment Return Value[​](#inline-experiment-return-value \"Direct link to Inline Experiment Return Value\")\n\nA call to `runInlineExperiment` returns an `ExperimentResult` object with a few useful properties:\n\n```\n$result = $growthbook->runInlineExperiment($exp);// If user is part of the experimentecho($result->inExperiment); // true or false// The index of the assigned variationecho($result->variationId); // e.g. 0 or 1// The key used to identify this variation when tracking the eventecho($result->key); // e.g. \"control\"// The value of the assigned variationecho($result->value); // e.g. \"A\" or \"B\"// If the variations was randomly assigned based on a hashecho($result->hashUsed); // true or false// The user attribute that was hashedecho($result->hashAttribute); // \"id\"// The value of that attributeecho($result->hashValue); // e.g. \"123\"\n```\n\nThe `inExperiment` flag will be false if the user was excluded from being part of the experiment for any reason (e.g. failed targeting conditions).\n\nThe `hashUsed` flag will only be true if the user was randomly assigned a variation. If the user was forced into a specific variation instead, this flag will be false.",
  "title": "PHP SDK | GrowthBook Docs",
  "description": "GrowthBook SDK for PHP",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/python",
  "markdown": "# Python SDK | GrowthBook Docs\n\n_Requires **Python 3.6** or above_\n\n## Installation[​](#installation \"Direct link to Installation\")\n\n## Quick Usage[​](#quick-usage \"Direct link to Quick Usage\")\n\n```\nfrom growthbook import GrowthBook# User attributes for targeting and experimentationattributes = {  \"id\": \"123\",  \"customUserAttribute\": \"foo\"}def on_experiment_viewed(experiment, result):  # Use whatever event tracking system you want  analytics.track(attributes[\"id\"], \"Experiment Viewed\", {    'experimentId': experiment.key,    'variationId': result.key  })# Create a GrowthBook instancegb = GrowthBook(  attributes = attributes,  on_experiment_viewed = on_experiment_viewed,  api_host = \"https://cdn.growthbook.io\",  client_key = \"sdk-abc123\")# Load features from the GrowthBook API with cachinggb.load_features()# Simple on/off feature gatingif gb.is_on(\"my-feature\"):  print(\"My feature is on!\")# Get the value of a feature with a fallbackcolor = gb.get_feature_value(\"button-color-feature\", \"blue\")\n```\n\n### Web Frameworks (Django, Flask, etc.)[​](#web-frameworks-django-flask-etc \"Direct link to Web Frameworks (Django, Flask, etc.)\")\n\nFor web frameworks, you should create a new `GrowthBook` instance for every incoming request and call `destroy()` at the end of the request to clean up resources.\n\nIn Django, for example, this is best done with a simple middleware:\n\n```\nfrom growthbook import GrowthBookdef growthbook_middleware(get_response):    def middleware(request):        request.gb = GrowthBook(          # ...        )        request.gb.load_features()        response = get_response(request)        request.gb.destroy() # Cleanup        return response    return middleware\n```\n\nThen, you can easily use GrowthBook in any of your views:\n\n```\ndef index(request):    feature_enabled = request.gb.is_on(\"my-feature\")    # ...\n```\n\n## Loading Features[​](#loading-features \"Direct link to Loading Features\")\n\nThere are two ways to load feature flags into the GrowthBook SDK. You can either use the built-in fetching/caching logic or implement your own custom solution.\n\n### Built-in Fetching and Caching[​](#built-in-fetching-and-caching \"Direct link to Built-in Fetching and Caching\")\n\nTo use the built-in fetching and caching logic, in the `GrowthBook` constructor, pass in your GrowthBook `api_host` and `client_key`. If you have encryption enabled for your GrowthBook endpoint, you also need to pass the `decryption_key` into the constructor.\n\nThen, call the `load_features()` method to initiate the HTTP request with a cache layer.\n\nHere's a full example:\n\n```\ngb = GrowthBook(  api_host = \"https://cdn.growthbook.io\",  client_key = \"sdk-abc123\",  # How long to cache features in seconds (Optional, default 60s)  cache_ttl = 60,)gb.load_features()\n```\n\n#### Caching[​](#caching \"Direct link to Caching\")\n\nGrowthBook comes with a custom in-memory cache. If you run Python in a multi-process mode, the different processes cannot share memory, so you likely want to switch to a distributed cache system like Redis instead.\n\nHere is an example of using Redis:\n\n```\nfrom redis import Redisimport jsonfrom growthbook import GrowthBook, AbstractFeatureCache, feature_repoclass RedisFeatureCache(AbstractFeatureCache):  def __init__(self):    self.r = Redis(host='localhost', port=6379)    self.prefix = \"gb:\"  def get(self, key: str):    data = self.r.get(self.prefix + key)    # Data stored as a JSON string, parse into dict before returning    return None if data is None else json.loads(data)  def set(self, key: str, value: dict, ttl: int) -> None:    self.r.set(self.prefix + key, json.dumps(value))    self.r.expire(self.prefix + key, ttl)# Configure GrowthBook to use your custom cache classfeature_repo.set_cache(RedisFeatureCache())\n```\n\n### Custom Implementation[​](#custom-implementation \"Direct link to Custom Implementation\")\n\nIf you prefer to handle the entire fetching/caching logic yourself, you can just pass in a `dict` of features from the GrowthBook API directly into the constructor:\n\n```\n# From the GrowthBook APIfeatures = {'my-feature':{'defaultValue':False}}gb = GrowthBook(  features = features)\n```\n\nNote: When doing this, you do not need to specify your `api_host` or `client_key` and you don't need to call `gb.load_features()`.\n\n## GrowthBook class[​](#growthbook-class \"Direct link to GrowthBook class\")\n\nThe GrowthBook constructor has the following parameters:\n\n*   **enabled** (`bool`) - Flag to globally disable all experiments. Default true.\n*   **attributes** (`dict`) - Dictionary of user attributes that are used for targeting and to assign variations\n*   **url** (`str`) - The URL of the current request (if applicable)\n*   **qa\\_mode** (`boolean`) - If true, random assignment is disabled and only explicitly forced variations are used.\n*   **on\\_experiment\\_viewed** (`callable`) - A function that takes `experiment` and `result` as arguments.\n*   **api\\_host** (`str`) - The GrowthBook API host to fetch feature flags from. Defaults to `https://cdn.growthbook.io`\n*   **client\\_key** (`str`) - The client key that will be passed to the API Host to fetch feature flags\n*   **decryption\\_key** (`str`) - If the GrowthBook API endpoint has encryption enabled, specify the decryption key here\n*   **cache\\_ttl** (`int`) - How long to cache features in-memory from the GrowthBook API (seconds, default `60`)\n*   **features** (`dict`) - Feature definitions from the GrowthBook API (only required if `client_key` is not specified)\n*   **forced\\_variations** (`dict`) - Dictionary of forced experiment variations (used for QA)\n\nThere are also getter and setter methods for features and attributes if you need to update them later in the request:\n\n```\ngb.set_features(gb.get_features())gb.set_attributes(gb.get_attributes())\n```\n\n### Attributes[​](#attributes \"Direct link to Attributes\")\n\nYou can specify attributes about the current user and request. These are used for two things:\n\n1.  Feature targeting (e.g. paid users get one value, free users get another)\n2.  Assigning persistent variations in A/B tests (e.g. user id \"123\" always gets variation B)\n\nAttributes can be any JSON data type - boolean, integer, float, string, list, or dict.\n\n```\nattributes = {  'id': \"123\",  'loggedIn': True,  'age': 21.5,  'tags': [\"tag1\", \"tag2\"],  'account': {    'age': 90  }}# Pass into constructorgb = GrowthBook(attributes = attributes)# Or set latergb.set_attributes(attributes)\n```\n\n### Tracking Experiments[​](#tracking-experiments \"Direct link to Tracking Experiments\")\n\nAny time an experiment is run to determine the value of a feature, you want to track that event in your analytics system.\n\nYou can use the `on_experiment_viewed` option to do this:\n\n```\nfrom growthbook import GrowthBook, Experiment, Resultdef on_experiment_viewed(experiment: Experiment, result: Result):  # Use whatever event tracking system you want  analytics.track(attributes[\"id\"], \"Experiment Viewed\", {    'experimentId': experiment.key,    'variationId': result.key  })# Pass into constructorgb = GrowthBook(  on_experiment_viewed = on_experiment_viewed)\n```\n\n## Using Features[​](#using-features \"Direct link to Using Features\")\n\nThere are 3 main methods for interacting with features.\n\n*   `gb.is_on(\"feature-key\")` returns true if the feature is on\n*   `gb.is_off(\"feature-key\")` returns false if the feature is on\n*   `gb.get_feature_value(\"feature-key\", \"default\")` returns the value of the feature with a fallback\n\nIn addition, you can use `gb.evalFeature(\"feature-key\")` to get back a `FeatureResult` object with the following properties:\n\n*   **value** - The JSON-decoded value of the feature (or `None` if not defined)\n*   **on** and **off** - The JSON-decoded value cast to booleans\n*   **source** - Why the value was assigned to the user. One of `unknownFeature`, `defaultValue`, `force`, or `experiment`\n*   **experiment** - Information about the experiment (if any) which was used to assign the value to the user\n*   **experimentResult** - The result of the experiment (if any) which was used to assign the value to the user\n\n## Sticky Bucketing[​](#sticky-bucketing \"Direct link to Sticky Bucketing\")\n\n**Available starting in version 1.1.0**\n\nBy default GrowthBook does not persist assigned experiment variations for a user. We rely on deterministic hashing to ensure that the same user attributes always map to the same experiment variation. However, there are cases where this isn't good enough. For example, if you change targeting conditions in the middle of an experiment, users may stop being shown a variation even if they were previously bucketed into it.\n\nSticky Bucketing is a solution to these issues. You can provide a Sticky Bucket Service to the GrowthBook instance to persist previously seen variations and ensure that the user experience remains consistent for your users.\n\nA sample `InMemoryStickyBucketService` implementation is provided for reference, but in production you will definitely want to implement your own version using a database, cookies, or similar for persistence.\n\nSticky Bucket documents contain three fields\n\n*   `attributeName` - The name of the attribute used to identify the user (e.g. `id`, `cookie_id`, etc.)\n*   `attributeValue` - The value of the attribute (e.g. `123`)\n*   `assignments` - A dictionary of persisted experiment assignments. For example: `{\"exp1__0\":\"control\"}`\n\nThe attributeName/attributeValue combo is the primary key.\n\nHere's an example implementation using a theoretical `db` object:\n\n```\nfrom growthbook import AbstractStickyBucketService, GrowthBookclass MyStickyBucketService(AbstractStickyBucketService):    # Lookup a sticky bucket document    def get_assignments(self, attributeName: str, attributeValue: str) -> Optional[Dict]:        return db.find({          \"attributeName\": attributeName,          \"attributeValue\": attributeValue        })    def save_assignments(self, doc: Dict) -> None:        # Insert new record if not exists, otherwise update        db.upsert({            \"attributeName\": doc[\"attributeName\"],            \"attributeValue\": doc[\"attributeValue\"]        }, {          \"$set\": {            \"assignments\": doc[\"assignments\"]          }        })# Pass in an instance of this service to your GrowthBook constructorgb = GrowthBook(  sticky_bucket_service = MyStickyBucketService())\n```\n\n## Inline Experiments[​](#inline-experiments \"Direct link to Inline Experiments\")\n\nInstead of declaring all features up-front and referencing them by ids in your code, you can also just run an experiment directly. This is done with the `run` method:\n\n```\nfrom growthbook import Experimentexp = Experiment(  key = \"my-experiment\",  variations = [\"red\", \"blue\", \"green\"])# Either \"red\", \"blue\", or \"green\"print(gb.run(exp).value)\n```\n\nAs you can see, there are 2 required parameters for experiments, a string key, and an array of variations. Variations can be any data type, not just strings.\n\nThere are a number of additional settings to control the experiment behavior:\n\n*   **key** (`str`) - The globally unique tracking key for the experiment\n*   **variations** (`any[]`) - The different variations to choose between\n*   **seed** (`str`) - Added to the user id when hashing to determine a variation. Defaults to the experiment `key`\n*   **weights** (`float[]`) - How to weight traffic between variations. Must add to 1.\n*   **coverage** (`float`) - What percent of users should be included in the experiment (between 0 and 1, inclusive)\n*   **condition** (`dict`) - Targeting conditions\n*   **force** (`int`) - All users included in the experiment will be forced into the specified variation index\n*   **hashAttribute** (`string`) - What user attribute should be used to assign variations (defaults to \"id\")\n*   **hashVersion** (`int`) - What version of our hashing algorithm to use. We recommend using the latest version `2`.\n*   **namespace** (`tuple[str,float,float]`) - Used to run mutually exclusive experiments.\n\nHere's an example that uses all of them:\n\n```\nexp = Experiment(  key=\"my-test\",  # Variations can be a list of any data type  variations=[0, 1],  # If this changes, it will re-randomize all users in the experiment  seed=\"abcdef123456\",  # Run a 40/60 experiment instead of the default even split (50/50)  weights=[0.4, 0.6],  # Only include 20% of users in the experiment  coverage=0.2,  # Targeting condition using a MongoDB-like syntax  condition={    'country': 'US',    'browser': {      '$in': ['chrome', 'firefox']    }  },  # Use an alternate attribute for assigning variations (default is 'id')  hashAttribute=\"sessionId\",  # Use the latest hashing algorithm  hashVersion=2,  # Includes the first 50% of users in the \"pricing\" namespace  # Another experiment with a non-overlapping range will be mutually exclusive (e.g. [0.5, 1])  namespace=(\"pricing\", 0, 0.5),)\n```\n\n### Inline Experiment Return Value[​](#inline-experiment-return-value \"Direct link to Inline Experiment Return Value\")\n\nA call to `run` returns a `Result` object with a few useful properties:\n\n```\nresult = gb.run(exp)# If user is part of the experimentprint(result.inExperiment) # True or False# The string key of the assigned variationprint(result.key) # e.g. \"0\" or \"1\"# The value of the assigned variationprint(result.value) # e.g. \"A\" or \"B\"# If the variation was randomly assigned by hashing user attributesprint(result.hashUsed) # True or False# The user attribute used to assign a variationprint(result.hashAttribute) # \"id\"# The value of that attributeprint(result.hashValue) # e.g. \"123\"\n```\n\nThe `inExperiment` flag will be false if the user was excluded from being part of the experiment for any reason (e.g. failed targeting conditions).\n\nThe `hashUsed` flag will only be true if the user was randomly assigned a variation. If the user was forced into a specific variation instead, this flag will be false.\n\n### Example Experiments[​](#example-experiments \"Direct link to Example Experiments\")\n\n3-way experiment with uneven variation weights:\n\n```\ngb.run(Experiment(  key = \"3-way-uneven\",  variations = [\"A\",\"B\",\"C\"],  weights = [0.5, 0.25, 0.25]))\n```\n\nSlow rollout (10% of users who match the targeting condition):\n\n```\n# User is marked as being in \"qa\" and \"beta\"gb = GrowthBook(  attributes = {    \"id\": \"123\",    \"beta\": True,    \"qa\": True,  },)gb.run(Experiment(  key = \"slow-rollout\",  variations = [\"A\", \"B\"],  coverage = 0.1,  condition = {    'beta': True  }))\n```\n\nComplex variations\n\n```\nresult = gb.run(Experiment(  key = \"complex-variations\",  variations = [    (\"blue\", \"large\"),    (\"green\", \"small\")  ],))# Either \"blue,large\" OR \"green,small\"print(result.value[0] + \",\" + result.value[1])\n```\n\nAssign variations based on something other than user id\n\n```\ngb = GrowthBook(  attributes = {    \"id\": \"123\",    \"company\": \"growthbook\"  })# Users in the same company will always get the same variationgb.run(Experiment(  key = \"by-company-id\",  variations = [\"A\", \"B\"],  hashAttribute = \"company\"))\n```\n\n## Logging[​](#logging \"Direct link to Logging\")\n\nThe GrowthBook SDK uses a Python logger with the name `growthbook` and includes helpful info for debugging as well as warnings/errors if something is misconfigured.\n\nHere's an example of logging to the console\n\n```\nimport logginglogger = logging.getLogger('growthbook')logger.setLevel(logging.DEBUG)handler = logging.StreamHandler()formatter = logging.Formatter('%(asctime)s %(name)s %(levelname)s %(message)s')handler.setFormatter(formatter)logger.addHandler(handler)\n```",
  "title": "Python SDK | GrowthBook Docs",
  "description": "GrowthBook SDK for Python",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/ruby",
  "markdown": "# Ruby SDK | GrowthBook Docs\n\nView the full source code at [https://github.com/growthbook/growthbook-ruby](https://github.com/growthbook/growthbook-ruby).\n\n## Requirements[​](#requirements \"Direct link to Requirements\")\n\nThe Ruby SDK requires Ruby version 2.5.0 or higher.\n\n## Installation[​](#installation \"Direct link to Installation\")\n\nInstall the gem:\n\n## Quick start[​](#quick-start \"Direct link to Quick start\")\n\n```\nrequire 'growthbook'# Fetch features from a GrowthBook instance# You should cache this in Redis or similar in productionfeatures_repository = Growthbook::FeatureRepository.new(  endpoint: 'https://cdn.growthbook.io/api/features/MY_API_KEY',  decryption_key: nil)features = features_repository.fetch# Create a context for the current user/requestgb = Growthbook::Context.new(  features: features,  # User attributes for targeting / variation assignment  attributes: {    id: '123',    country: 'US'  })# Use a boolean feature flagif gb.on? :my_feature_key  puts 'My feature is on!'end# Get the value of a multivariate feature with a fallbackbtn_color = gb.feature_value(:signup_btn_color, 'pink')\n```\n\n## Tracking[​](#tracking \"Direct link to Tracking\")\n\n### Track experiment impressions[​](#track-experiment-impressions \"Direct link to Track experiment impressions\")\n\nWhen a feature's value is determined by an experiment (A/B test), you typically want to track that assignment event for later analysis.\n\nThere are two ways to do this. First is by accessing all impressions at the end of a request:\n\n```\ngb.impressions.each do |key, result|  puts \"Assigned variation #{result.variation_id} in experiment #{key}\"end\n```\n\nSecond is by using a listener to get alerted in realtime as users are put into experiments:\n\n```\nclass MyImpressionListener  def on_experiment_viewed(experiment, result)    puts \"Assigned variation #{result.variation_id} in experiment #{experiment.key}\"  endendgb.listener = MyImpressionListener.new\n```\n\n### Track feature usage[​](#track-feature-usage \"Direct link to Track feature usage\")\n\nGrowthBook can fire a callback whenever a feature is evaluated for a user. This can be useful to update 3rd party tools like NewRelic or DataDog.\n\nProvide a receiver that can receive `def on_feature_usage: (String _feature_key, FeatureResult _result) -> void`. There's a convenience class `FeatureUsageCallback` with a method you can override but you can provide your own.\n\n```\nclass MyFeatureUsageCallback < FeatureUsageCallback  def on_feature_usage(feature_key, feature_result)    puts \"on_feature_usage_called with key: #{feature_key} and result #{feature_result}\"  endendon_feature_usage = MyFeatureUsageCallback.new# you can pass it into the contextgb = Growthbook::Context.new({  attributes: {    id: 'user-abc123'  },  features: feature_repository.fetch || {},  on_feature_usage: on_feature_usage,})# or assign it afterwardsgb.on_feature_usage = on_feature_usage\n```\n\n## Using with Rails[​](#using-with-rails \"Direct link to Using with Rails\")\n\nYou can use the provided `Growthbook::FeatureRepository` class along with the Rails cache to fetch features periodically within your usage limits. Here is a controller concern you can use:\n\n```\nrequire 'growthbook'module GrowthbookSdk  def growthbook    @growthbook ||= Growthbook::Context.new(      features: growthbook_features_json,      attributes: {},    )  end  # use this as a before_action on your controller  def init_feature_flags    return if current_user.nil?    # TODO: Change this to get your user attributes as a hash in a way that works for your app    growthbook.attributes = current_user.as_json  end  private  def growthbook_features_json    Rails.cache.fetch(\"growthbook_features\", expires_in: 1.hour) do      puts \"🌎 Fetching GrowthBook features from the network\"      repo = Growthbook::FeatureRepository.new(        endpoint: 'https://cdn.growthbook.io/api/features/java_NsrWldWd5bxQJZftGsWKl7R2yD2LtAK8C8EUYh9L8',        decryption_key: nil,      )      repo.fetch || {}    end  endend\n```\n\nAnd in your `ApplicationController`:\n\n```\nclass ApplicationController < ActionController::API  include Authentication # your own auth strategy  include GrowthbookSdk # the controller concern code above  before_action :authenticate!  before_action :init_feature_flags # call this once you have a user from which to get attributesend\n```\n\nThe above code exposes the following methods on your application controller:\n\n*   `growthbook`: an instance of the GrowthBook SDK for the request\n*   `init_feature_flags`: a method intended to be used as a `before_action` hook, e.g. `before_action :init_feature_flags`\n\nIt assumes you have a method `current_user` that returns the currently-authenticated user, and that it responds to `as_json` to return a hash of the targeting attributes.\n\nHow this works:\n\n1.  With each request, the `init_feature_flags` method is called. This creates a new instance of `Growthbook::Context`\n2.  When creating the context for the first time, features are fetched and cached in the Rails cache. Subsequent calls use the cached version until the cache expires.\n3.  Developers can call methods on `growthbook` in their controllers to use the GrowthBook SDK, e.g. `growthbook.on?(:dark_mode)`.\n\nYou can see the Rails example linked in the [Code examples below](#code-examples).\n\n## Dev and QA helpers[​](#dev-and-qa-helpers \"Direct link to Dev and QA helpers\")\n\nFor dev/QA it's often useful to force specific feature values.\n\n```\n# These take precedence over everything else when determining a feature's valuegb.forced_features = {  my_feature: true,  other_feature: \"new value\"}# Will always be truegb.is_on?(:my_feature)# Will always be \"new value\"gb.feature_value(:other_feature)\n```\n\nFor more predictability during QA, you can also globally disable all random assignment in experiments from running:\n\n## Sticky Bucketing[​](#sticky-bucketing \"Direct link to Sticky Bucketing\")\n\n**Available starting in version 1.3.0**\n\nBy default GrowthBook does not persist assigned experiment variations for a user. We rely on deterministic hashing to ensure that the same user attributes always map to the same experiment variation. However, there are cases where this isn't good enough. For example, if you change targeting conditions in the middle of an experiment, users may stop being shown a variation even if they were previously bucketed into it.\n\nSticky Bucketing is a solution to these issues. You can provide a Sticky Bucket Service to the GrowthBook instance to persist previously seen variations and ensure that the user experience remains consistent for your users.\n\nA sample `InMemoryStickyBucketService` implementation is provided for reference, but in production you will definitely want to implement your own version using a database, cookies, or similar for persistence.\n\nSticky Bucket documents contain three fields\n\n*   `attributeName` - The name of the attribute used to identify the user (e.g. `id`, `cookie_id`, etc.)\n*   `attributeValue` - The value of the attribute (e.g. `123`)\n*   `assignments` - A hash of persisted experiment assignments. For example: `{\"exp1__0\":\"control\"}`\n\nThe attributeName/attributeValue combo is the primary key.\n\nHere's an example implementation using a theoretical `db` object:\n\n```\nrequire 'growthbook'class MyStickyBucketService < Growthbook::StickyBucketService  def get_assignments(attribute_name, attribute_value)    db.find({      attributeName: attribute_name,      attributeValue: attribute_value    })  end  def save_assignments(doc)    # Insert new record if not exists, otherwise update    db.upsert({        attributeName: doc[\"attributeName\"],        attributeValue: doc[\"attributeValue\"]    }, {      \"$set\": {        assignments: doc[\"assignments\"]      }    })  endend# Pass in an instance of this service to your GrowthBook constructorgb = Growthbook::Context.new(  sticky_bucket_service: MyStickyBucketService.new)\n```\n\n## Inline experiments[​](#inline-experiments \"Direct link to Inline experiments\")\n\nIt's also possible to directly run an experiment directly in code without going through a feature flag.\n\n```\n# Simple 50/50 experimentresult = gb.run(Growthbook::InlineExperiment.new(  key: \"my-experiment-key\",  variations: [\"red\", \"green\"]))# Whether or not the user was included in the experiment (either true or false)puts(result.in_experiment ? 'included' : 'excluded')# The value of the assigned variation (either \"red\" or \"green\")puts(result.value)# The variation index (either 0 or 1)puts(result.variation_id)\n```\n\nThere are lots of additional options when running inline experiments:\n\n```\ngb.run(Growthbook::InlineExperiment.new(  key: \"my-experiment-key\",  variations: [\"red\", \"green\"],  # Filter by context attributes  condition: {    country: {      \"$in\": [\"US\", \"CA\"]    }  },  # Adjust variation weights from the default 50/50 split  weights: [0.8, 0.2],  # Run for a subset of traffic (0 to 1, default = 1)  coverage: 0.5,  # Use a different context attribute for assigning a variation (default = \"id\")  hash_attribute: \"device_id\",  # Use a namespace to run mutually exclusive experiments  namespace: [\"pricing-page\", 0, 0.25]))\n```\n\n## Working with Encrypted features[​](#working-with-encrypted-features \"Direct link to Working with Encrypted features\")\n\nYou can learn more about [SDK Connection Endpoint Encryption](https://docs.growthbook.io/app/api#encryption).\n\nCreate a `GrowthBook::Context` with an encrypted payload and a decryption key:\n\n```\n# TODO: Replace these values with your own:Growthbook::Context.new(  encrypted_features: 'm5ylFM6ndyOJA2OPadubkw==.Uu7ViqgKEt/dWvCyhI46q088PkAEJbnXKf3KPZjf9IEQQ+A8fojNoxw4wIbPX3aj',  decryption_key: 'Zvwv/+uhpFDznZ6SX28Yjg==',  attributes: {    id: '456',    country: 'CA'  })\n```\n\nWhen fetching features from the GrowthBook SDK endpoint, the encrypted features are available on a property `encryptedFeatures` instead of plain text on the property `features`. Here's an example with networking:\n\n```\nuri = URI('https://cdn.growthbook.io/api/features/MY_API_KEY')res = Net::HTTP.get_response(uri)encrypted_features = res.is_a?(Net::HTTPSuccess) ? JSON.parse(res.body)['encryptedFeatures'] : nilGrowthbook::Context.new(  encrypted_features: encrypted_features,  decryption_key: '<key-for-decrypting>',  attributes: {    id: '456',    country: 'CA'  })\n```\n\n## Code Examples[​](#code-examples \"Direct link to Code Examples\")\n\n*   [Ruby on Rails example](https://github.com/growthbook/examples/tree/main/acme_donuts_rails)\n\n## Further Reading[​](#further-reading \"Direct link to Further Reading\")\n\n*   [Generated class docs](https://growthbook.github.io/growthbook-ruby/)",
  "title": "Ruby SDK | GrowthBook Docs",
  "description": "GrowthBook SDK for Ruby",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/vue",
  "markdown": "# Vue.js | GrowthBook Docs\n\nThis page includes example implementations for Vue 3 (composition API) and Vue 2 (options API).\n\nThe Vue.js implementations are a light wrapper around the [JavaScript library](https://docs.growthbook.io/lib/js), so you may want to view those docs first to familiarize yourself with the basic classes and methods.\n\n## Installation[​](#installation \"Direct link to Installation\")\n\nAdd the `@growthbook/growthbook` package to your project.\n\nWith Yarn:\n\n```\nyarn add @growthbook/growthbook\n```\n\nWith NPM:\n\n```\nnpm i --save @growthbook/growthbook\n```\n\nWith unpkg:\n\n```\n<script type=\"module\">  import { GrowthBook } from \"https://unpkg.com/@growthbook/growthbook/dist/bundles/esm.min.js\";  //...</script>\n```\n\n## Vue 3 → Composition API[​](#vue-3--composition-api \"Direct link to Vue 3 → Composition API\")\n\n### Create a provider[​](#create-a-provider \"Direct link to Create a provider\")\n\nFirst, we're going to create a provider that can be injected in your app.\n\nCreate a file `./src/utils/growthbook/growthbook.ts` and add the following code:\n\n./src/utils/growthbook/growthbook.ts\n\n```\nimport type { App, InjectionKey } from \"vue\";import { GrowthBook } from \"@growthbook/growthbook\";/** * Configuration for the options passed to the app.use() call */export type GrowthBookVuePluginConfig = {  /**   * The endpoint that your features are hosted on. Get this from the Environments → SDK Endpoints section   */  featuresEndpoint: string;  /**   * Allows you to use the Chrome DevTools Extension to test/debug.   * Learn more: https://docs.growthbook.io/tools/chrome-extension   */  enableDevMode: boolean;};/** * The provided GrowthBook would be null in the event that the API call to the features endpoint fails. */type GrowthBookProvider = {  init: () => Promise<GrowthBook | null>;};export const growthBookKey = Symbol() as InjectionKey<GrowthBookProvider>;const getFeaturesJson = async (  featuresEndpoint: string): Promise<Record<string, any>> => {  const response = await fetch(featuresEndpoint);  return await response.json();};export const growthBookPlugin = {  install(    app: App,    { featuresEndpoint, enableDevMode = false }: GrowthBookVuePluginConfig  ) {    let growthBook: GrowthBook | null = null;    const init = async (): Promise<GrowthBook | null> => {      if (growthBook) {        return growthBook;      }      try {        const json = await getFeaturesJson(featuresEndpoint);        growthBook = new GrowthBook({          enableDevMode,        });        growthBook.setFeatures(json.features);        return growthBook;      } catch (e) {        console.error(\"GrowthBook Vue plugin error\", e);        return null;      }    };    app.provide<GrowthBookProvider>(growthBookKey, {      init,    });  },};\n```\n\n### Add the provider to your app[​](#add-the-provider-to-your-app \"Direct link to Add the provider to your app\")\n\nNext, in the `./src/main.ts` file of your app, use this new plugin we just created:\n\n./src/main.ts\n\n```\nimport { growthBookPlugin } from \"@/utils/growthbook/growthbook\";const app = createApp(App);app.use(router);// Use the new GrowthBook plugin like other pluginsapp.use(growthBookPlugin, {  featuresEndpoint: \"https://cdn.growthbook.io/api/features/:env_key\",  enableDevMode: true,});app.mount(\"#app\");\n```\n\nYou can find your features endpoint on the [Environments → SDK Endpoints page](https://app.growthbook.io/environments) .\n\n### Use GrowthBook in your components[​](#use-growthbook-in-your-components \"Direct link to Use GrowthBook in your components\")\n\nNext, to use the GrowthBook SDK in our components, we will need to inject it, initialize the SDK with user attributes, and then check features.\n\n<script setup lang='ts'>\n\n```\nimport { inject, onMounted, ref } from \"vue\";import { growthBookKey } from \"@/utils/growthbook/growthbook\";const growthBookInjectable = inject(growthBookKey);const bannerText = ref<string>(\"\");onMounted(() => {  growthBookInjectable?.init().then((growthBook) => {    if (!growthBook) {      console.error(\"GrowthBook failed to initialize\");      return;    }    growthBook.setAttributes({      loggedIn: true,      country: \"canada\",      employee: true,      id: \"user-employee-123456789\",    });    const evaluatedBannerText = growthBook.getFeatureValue(\"banner_text\", \"\");    if (typeof evaluatedBannerText !== \"undefined\") {      bannerText.value = evaluatedBannerText;    }  });});\n```\n\nThe above code will allow you to use the dynamic `{{bannerText}}` value in your template.\n\n## Vue 2 → Options API[​](#vue-2--options-api \"Direct link to Vue 2 → Options API\")\n\n### Create a provider[​](#create-a-provider-1 \"Direct link to Create a provider\")\n\nFirst, we're going to create a provider that can be injected in your app.\n\nCreate a file `./src/utils/growthbook/growthbook.js` and add the following code:\n\n./src/utils/growthbook/growthbook.ts\n\n```\nimport { GrowthBook } from \"@growthbook/growthbook\";const getFeaturesJson = (featuresEndpoint) => {  return fetch(featuresEndpoint)    .then((response) => {      return response.json()    })}export const GrowthBookVuePlugin = {  install: function (Vue, { featuresEndpoint, enableDevMode = false }) {    let growthBook = null;    Vue.prototype.initGrowthBook = function initGrowthBook() {      if (growthBook) {        return Promise.resolve(growthBook);      }      return getFeaturesJson(featuresEndpoint)        .then((json) => {          growthBook = new GrowthBook({            enableDevMode,          });          growthBook.setFeatures(json.features);          return growthBook;        })        .catch((error) => {          console.error(\"GrowthBook Vue plugin initialization error\", error);          return null;        })    }  }}\n```\n\n### Add the provider to your app[​](#add-the-provider-to-your-app-1 \"Direct link to Add the provider to your app\")\n\nNext, in the `./src/main.js` file of your app, use this new plugin we just created:\n\n./src/main.js\n\n```\nimport Vue from 'vue'import App from './App.vue'import { GrowthBookVuePlugin } from './utils/growthbook/growthbook'Vue.config.productionTip = falseVue.use(GrowthBookVuePlugin, {  featuresEndpoint: \"https://cdn.growthbook.io/api/features/:feature_key\",  enableDevMode: true,})new Vue({  render: h => h(App),}).$mount('#app')\n```\n\nYou can find your features endpoint on the [Environments → SDK Endpoints page](https://app.growthbook.io/environments) .\n\n### Use GrowthBook in your components[​](#use-growthbook-in-your-components-1 \"Direct link to Use GrowthBook in your components\")\n\nNext, to use the GrowthBook SDK in our components, we will need to inject it, initialize the SDK with user attributes, and then check features.\n\n<script>\n\n```\nexport default {  name: 'PublicPage',  props: {},  mounted() {    this      .initGrowthBook()      .then((growthBook) => {        if (!growthBook) {          console.warn('GrowthBook failed to initialize. Feature flags and experiments not active.')          return        }        growthBook.setAttributes({          loggedIn: true,          country: \"france\",          employee: false,          id: \"user-abc123\",        });        const evaluatedBannerText = growthBook.getFeatureValue(\"banner_text\", \"\");        if (typeof evaluatedBannerText !== \"undefined\") {          this.bannerText = evaluatedBannerText;        }      })      .catch((error) => {        console.error('Unknown Error', error)      })      .finally(() => {        this.loading = false      })  },  data() {    return {      bannerText: '',    }  }}\n```\n\nThe above code will allow you to use the dynamic `{{bannerText}}` value in your template.\n\n## Examples[​](#examples \"Direct link to Examples\")\n\n*   [Vue 3 composition API example](https://github.com/growthbook/examples/tree/main/javascript-vue-composition)\n*   [Vue 2 options API example](https://github.com/growthbook/examples/tree/main/javascript-vue-options)",
  "title": "Vue.js | GrowthBook Docs",
  "description": "GrowthBook SDK for Vue.js",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/go",
  "markdown": "# Go SDK | GrowthBook Docs\n\n## Installation[​](#installation \"Direct link to Installation\")\n\n```\ngo get github.com/growthbook/growthbook-golang\n```\n\n## Quick Usage[​](#quick-usage \"Direct link to Quick Usage\")\n\nThe main public API for the SDK is provided through the `Context` and `GrowthBook` types. The `Context` type provides a means to pass settings to the main `GrowthBook` type, while the `GrowthBook` type provides a `Feature` method for accessing feature values, and a `Run` method for running inline experiments.\n\n```\n// GBFeaturesResponse// GrowthBook features responsetype GBFeaturesResponse struct {\tStatus            int             `json:\"status\"`\tFeatures          json.RawMessage `json:\"features\"`\tEncryptedFeatures string          `json:\"encryptedFeatures,omitempty\"` // Not yet supported in the Go SDK\tDateUpdated       time.Time       `json:\"dateUpdated\"`}// Get JSON from GrowthBook and deserialize it into GBFeaturesResponse structres, err := http.Get(\"https://cdn.growthbook.io/api/features/<environment_key>\")if err != nil {\tfmt.Printf(\"Error fetching features from GrowthBook: %s \\n\", err)\tos.Exit(1)}var featuresResponse GBFeaturesResponseerr = json.NewDecoder(res.Body).Decode(&featuresResponse)if err != nil {\tfmt.Printf(\"Error decoding JSON: %s \\n\", err)\tos.Exit(1)}features := growthbook.ParseFeatureMap(featuresResponse.Features)// Optional tracking callback// This will get called when the font_colour experiment below is evaluated// See \"Tracking and subscriptions\" section belowtrackingCallback := func(experiment *growthbook.Experiment, result *growthbook.ExperimentResult) {\tfmt.Printf(\"Experiment Viewed: %s - Variation index: %d - Value: %s \\n\", experiment.Key, result.VariationID, result.Value)}// Set up user attributes - See Attributes below for more infouserAttributes := growthbook.Attributes{\t\"id\": \"user-abc123\",\t\"country\": \"canada\",}// Create a growthbook.Context instance with the features and attributescontext := growthbook.NewContext().\tWithFeatures(features).\tWithAttributes(userAttributes).\tWithTrackingCallback(trackingCallback)// Create a growthbook.GrowthBook instancegb := growthbook.New(context)// Get a string valuebannerText := gb.Feature(\"banner_text\").GetValueWithDefault(\"(unknown banner text)\")// Perform feature test.if gb.Feature(\"dark_mode\").On {\t// ...}// Evaluate an inline experiment and cast the result to a string (or the known type)experiment := growthbook.\tNewExperiment(\"font_colour\").\tWithVariations(\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"purple\")result := gb.Run(experiment)var fontColour = result.Value.(string)fmt.Println(fontColour)experiment2 :=  growthbook.NewExperiment(\"complex-experiment\").    WithVariations(      map[string]string{\"color\": \"blue\", \"size\": \"small\"},      map[string]string{\"color\": \"green\", \"size\": \"large\"},    ).    WithWeights(0.8, 0.2).    WithCoverage(0.5)result2 := gb.Run(experiment2)fmt.Println(result2.Value.(map[string]string)[\"color\"],  result2.Value.(map[string]string)[\"size\"])\n```\n\n## The GrowthBook Context[​](#the-growthbook-context \"Direct link to The GrowthBook Context\")\n\nA new `Context` is created using the `NewContext` function and its fields can be set using the `WithEnabled`, `WithAttributes`, `WithURL`, `WithFeatures`, `WithForcedVariations`, `WithQAMode` and `WithTrackingCallback` methods. These `With...` methods return a `Context` pointer to enable call chaining. Context details can alternatively be parsed from JSON data (see [JSON data representations](#json-data-representations)). The fields in a `Context` include information about the user for whom feature results will be evaluated (the `Attributes`), the features that are defined, plus some additional values to control forcing of feature results under some circumstances.\n\nGiven a `Context` value, a new `GrowthBook` value can be created using the `New` function. The `GrowthBook` type has some getter and setter methods (setters are methods with names of the form `With...`) for fields of the associated `Context`. As well as providing access to the underlying Context and exposing the main `Feature` and `Run` methods, the `GrowthBook` type also keeps track of the results of experiments that are performed, in order to implement tracking and experiment subscription callbacks.\n\nFor example, assuming that the `growthbook` package is imported with name \"`growthbook`\", the following code will create a `Context` and `GrowthBook` value using features parsed from JSON data and some fixed attributes:\n\n```\n// Parse feature map from JSON.features := growthbook.ParseFeatureMap(featureJSON)// Create context and main GrowthBook object.context := growthbook.NewContext().  WithFeatures(features).  WithAttributes(growthbook.Attributes{    \"country\": \"US\",    \"browser\": \"firefox\",  })gb := growthbook.New(context)\n```\n\n### Features[​](#features \"Direct link to Features\")\n\nThe `WithFeatures` method of `Context` takes a `FeatureMap` value, which is defined as `map[string]*Feature`, and which can be created from JSON data using the `ParseFeatureMap` function (see [JSON data representations](#json-data-representations)). You can pass a feature map generated this way to the `WithFeatures` method of `Context` or `GrowthBook`:\n\n```\nfeatureMap := ParseFeatureMap([]byte(  `{ \"feature-1\": {...},     \"feature-2\": {...},     \"another-feature\": {...}   }`))gb := NewContext().WithFeatures(featureMap)\n```\n\nIf you need to load feature definitions from a remote source like an API or database, you can update the context at any time with `WithFeatures`.\n\nIf you use the GrowthBook App to manage your features, you don't need to build this JSON file yourself -- it will auto-generate one for you and make it available via an API endpoint.\n\nIf you prefer to build this file by hand or you want to know how it works under the hood, check out the detailed [Feature Definitions](#feature-definitions) section below.\n\n### Attributes[​](#attributes \"Direct link to Attributes\")\n\nYou can specify attributes about the current user and request. These are used for two things:\n\n*   Feature targeting (e.g. paid users get one value, free users get another);\n*   Assigning persistent variations in A/B tests (e.g. user id \"123\" always gets variation B).\n\nAttributes can be any JSON data type -- boolean, integer, string, array, or object and are represented by the `Attributes` type, which is an alias for the generic `map[string]interface{}` type that Go uses for JSON objects. If you know them up front, you can pass them into `Context` or `GrowthBook` using `WithAttributes`:\n\n```\ngb := growthbook.New(context).  WithAttributes(Attributes{    \"id\":       \"123\",    \"loggedIn\": true,    \"deviceId\": \"abc123def456\",    \"company\":  \"acme\",    \"paid\":     false,    \"url\":      \"/pricing\",    \"browser\":  \"chrome\",    \"mobile\":   false,    \"country\":  \"US\",  })\n```\n\nYou can also set or update attributes asynchronously at any time with the `WithAttributes` method. This will completely overwrite the attributes object with whatever you pass in. If you want to merge attributes instead, you can get the existing ones with `Attributes`:\n\n```\nattrs := gb.Attributes()attrs[\"url\"] = \"/checkout\"gb.WithAttributes(attrs)\n```\n\nBe aware that changing attributes may change the assigned feature values. This can be disorienting to users if not handled carefully. A common approach is to only refresh attributes on navigation, when the window is focused, and/or after a user performs a major action like logging in.\n\n### Tracking Callback[​](#tracking-callback \"Direct link to Tracking Callback\")\n\nAny time an experiment is run to determine the value of a feature, we can run a callback function so you can record the assigned value in your event tracking or analytics system of choice.\n\n```\ncontext.WithTrackingCallback(func(experiment *growthbook.Experiment,  result *growthbook.ExperimentResult) {    // Example using Segment.io    client.Enqueue(analytics.Track{      UserId: context.Attributes()[\"id\"],      Event: \"Experiment Viewed\",      Properties: analytics.NewProperties().        Set(\"experimentId\", experiment.Key).        Set(\"variationId\", result.VariationID)    })  })\n```\n\n## Error handling[​](#error-handling \"Direct link to Error handling\")\n\nThe GrowthBook public API does not return errors under any normal circumstances. The intention is for developers to be able to use the SDK in both development and production smoothly. To this end, error reporting is provided by a configurable logging interface.\n\nFor development use, the `DevLogger` type provides a suitable implementation of the logging interface: it prints all logged messages to standard output, and exits on errors.\n\nFor production use, a logger that directs log messages to a suitable centralised logging facility and ignores all errors would be suitable. The logger can of course also signal error and warning conditions to other parts of the program in which it is used.\n\nTo be specific about this:\n\n*   None of the functions that create or update `Context`, `GrowthBook` or `Experiment` values return errors.\n    \n*   The main `GrowthBook.Feature` and `GrowthBook.Run` methods never return errors.\n    \n*   None of the functions that create values from JSON data return errors.\n    \n\nFor most common use cases, this means that the GrowthBook SDK can be used transparently, without needing to care about error handling. Your server code will never crash because of problems in the GrowthBook SDK. The only effect of error conditions in the inputs to the SDK may be that feature values and results of experiments are not what you expect.\n\n## Using Features[​](#using-features \"Direct link to Using Features\")\n\nThe main method, `GrowthBook.Feature(key)`, takes a feature key and uses the stored feature definitions and attributes to evaluate the feature value. It returns a `FeatureResult` value with the following fields:\n\n*   `Value`: the JSON value of the feature (or null if not defined), as a `FeatureValue` value (which is just an alias for `interface{}`, using Go's default behavior for handling JSON values);\n*   `On` and `Off`: the JSON value cast to booleans (to make your code easier to read);\n*   `Source`: a value of type `FeatureResultSource`, telling why the value was assigned to the user. One of `UnknownFeatureResultSource`, `DefaultValueResultSource`, `ForceResultSource`, or `ExperimentResultSource`.\n*   `Experiment`: information about the experiment (if any) which was used to assign the value to the user.\n*   `ExperimentResult`: the result of the experiment (if any) which was used to assign the value to the user.\n\nHere's an example that uses all of them:\n\n```\nresult := gb.Feature(\"my-feature\")// The JSON value (might be null, string, boolean, number, array, or// object).fmt.Println(result.Value)if result.On {  // Feature value is truthy (in a Javascript sense)}if result.Off {  // Feature value is falsy}// If the feature value was assigned as part of an experimentif result.Source == growthbook.ExperimentResultSource {  // Get all the possible variations that could have been assigned  fmt.Println(result.Experiment.Variations)}\n```\n\nDefaulting of the values of feature results is assisted by the `GetValueWithDefault` method on the `FeatureResult` type. For example, this code evaluates the result of a feature and returns the feature value, defaulting to \"blue\" if the feature has no value:\n\n```\ncolor := gb.Feature(\"signup-button-color\").GetValueWithDefault(\"blue\")\n```\n\n## Feature Definitions[​](#feature-definitions \"Direct link to Feature Definitions\")\n\nFor details of the JSON format used for feature definitions, consult the documentation for the [GrowthBook Javascript SDK](https://docs.growthbook.io/lib/js). The Go SDK uses exactly the same logic for processing features, and can ingest the same JSON feature definitions as are used by the Javascript SDK (see [JSON data representations](#json-data-representations)).\n\nIt is possible to create `Feature` values in the Go SDK by hand, simply by creating Go values of the appropriate types (`Feature`, `FeatureValue`, `FeatureRule`), but the most common use case is likely to be ingesting feature definitions from JSON data using the `ParseFeatureMap` function.\n\n## Inline Experiments[​](#inline-experiments \"Direct link to Inline Experiments\")\n\nExperiments can be defined and run using the `Experiment` type and the `Run` method of the `GrowthBook` type. Experiment definitions can be created directly as values of the `Experiment` type, or parsed from JSON definitions using the `ParseExperiment` function. Passing an `Experiment` value to the `Run` method of the `GrowthBook` type will run the experiment, returing an `ExperimentResult` value that contains the resulting feature value. This allows users to run arbitrary experiments without providing feature definitions up-front.\n\n```\nexperiment :=  growthbook.NewExperiment(\"my-experiment\").    WithVariations(\"red\", \"blue\", \"green\")result := gb.Run(experiment)\n```\n\nAll other experiment settings (weights, hash attribute, coverage, namespace, condition) are supported when using inline experiments: the `Experiment` type has `With...` methods that allow these fields to be set easily (i.e. `WithWeights`, `WithHashAttribute`, `WithCoverage`, `WithNamespace`, `WithCondition`).\n\nIn addition, there are a few other settings that only really make sense for inline experiments:\n\n*   `Force` can be set to one of the variation array indexes. Everyone will be immediately assigned the specified value.\n*   `Active` can be set to `false` to disable the experiment and return the control for everyone.\n\n### Inline Experiment Return Value[​](#inline-experiment-return-value \"Direct link to Inline Experiment Return Value\")\n\nA call to `GrowthBook.Run(experiment)` returns a value of type `*ExperimentResult`:\n\n```\nexperiment := growthbook.NewExperiment(\"my-experiment\").  WithVariations(\"A\", \"B\")result := gb.Run(experiment)// If user is part of the experimentfmt.Println(result.InExperiment) // true or false// The index of the assigned variationfmt.Println(result.VariationID) // 0 or 1// The value of the assigned variationfmt.Println(result.Value) // \"A\" or \"B\"// The user attribute used to assign a variationfmt.Println(result.HashAttribute) // \"id\"// The value of that attributefmt.Println(result.HashValue) // e.g. \"123\"\n```\n\nThe `InExperiment` flag is only set to true if the user was randomly assigned a variation. If the user failed any targeting rules or was forced into a specific variation, this flag will be false.\n\n## JSON data representations[​](#json-data-representations \"Direct link to JSON data representations\")\n\nFor interoperability of the GrowthBook Go SDK with versions of the SDK in other languages, the core \"input\" values of the SDK (in particular, `Context` and `Experiment` values and maps of feature definitions) can be created by parsing JSON data.\n\nA common use case is to download the feature definition from the GrowthBook SDK endpoints, and parse them into a feature map that can be passed into the GrowthBook `Context`.\n\nThe shape of the GrowthBook response can use the following struct:\n\n```\n// GBFeaturesResponse// GrowthBook features responsetype GBFeaturesResponse struct {\tStatus            int             `json:\"status\"`\tFeatures          json.RawMessage `json:\"features\"`\tEncryptedFeatures string          `json:\"encryptedFeatures,omitempty\"` // Not yet supported in the Go SDK\tDateUpdated       time.Time       `json:\"dateUpdated\"`}\n```\n\nNext, get JSON from GrowthBook and deserialize it into GBFeaturesResponse struct.\n\n```\nres, err := http.Get(\"https://cdn.growthbook.io/api/features/<environment_key>\")if err != nil {\tfmt.Printf(\"Error fetching features from GrowthBook: %s \\n\", err)\tos.Exit(1)}var featuresResponse GBFeaturesResponseerr = json.NewDecoder(res.Body).Decode(&featuresResponse)if err != nil {\tfmt.Printf(\"Error decoding JSON: %s \\n\", err)\tos.Exit(1)}features := growthbook.ParseFeatureMap(featuresResponse.Features)// Create a growthbook.Context instance with the features and attributescontext := growthbook.NewContext().\tWithFeatures(features).\tWithAttributes(userAttributes)// Create a growthbook.GrowthBook instancegb := growthbook.New(context)\n```\n\nThe functions that implement this JSON processing functionality have names like `ParseContext`, `BuildContext`, and so on. Each `Parse...` function process raw JSON data (as a `[]byte` value), while the `Build...` functions process JSON objects unmarshalled to Go values of type `map[string]interface{}`. This provides flexibility in ingestion of JSON data.\n\n## Tracking and subscriptions[​](#tracking-and-subscriptions \"Direct link to Tracking and subscriptions\")\n\nThe `Context` value supports a \"tracking callback\", which is a function that is called any time an experiment is run to determine the value of a feature, so that users can record the assigned value in an external event tracking or analytics system.\n\nIn addition to the tracking callback, the `GrowthBook` type also supports more general \"subscriptions\", which are callback functions that are called any time `Run` is called, irrespective of whether or not a user is included in an experiment. The subscription system ensures that subscription callbacks are only called when the result of an experiment changes, or a new experiment is run.\n\n## Code Examples[​](#code-examples \"Direct link to Code Examples\")\n\n*   [Go server example that fetches from the GrowthBook API](https://github.com/growthbook/examples/tree/main/go-example)\n*   [Go CLI app that ingests features from file](https://github.com/ian-ross/growthbook-golang-example)\n\n## Further Reading[​](#further-reading \"Direct link to Further Reading\")\n\n*   [godoc](https://growthbook.github.io/growthbook-golang)",
  "title": "Go SDK | GrowthBook Docs",
  "description": "GrowthBook SDK for Golang",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/csharp",
  "markdown": "# C# SDK | GrowthBook Docs\n\nView the full documentation on [GitHub](https://github.com/growthbook/growthbook-c-sharp).\n\n[![nuget badge for growthbook](https://img.shields.io/nuget/v/growthbook-c-sharp?style=flat-square)](https://www.nuget.org/packages/growthbook-c-sharp)\n\n## Installation[​](#installation \"Direct link to Installation\")\n\n```\n    dotnet add package growthbook-c-sharp\n```\n\n## Quick Usage[​](#quick-usage \"Direct link to Quick Usage\")\n\nThis library is based on the [GrowthBook SDK specs](https://docs.growthbook.io/lib/build-your-own) and should be compatible with the usage examples in the [GrowthBook docs](https://docs.growthbook.io/).\n\nDown below you'll find two basic examples on how the package works.\n\n### Basic[​](#basic \"Direct link to Basic\")\n\n1.  Declare features\n    \n    ```\n    var staticFeatures = new Dictionary<string, Feature>{    {\"firstFeature\", new Feature{ DefaultValue = true}},    {\"secondFeature\", new Feature{ DefaultValue = false}}};\n    ```\n    \n2.  Create a context and add the features\n    \n    ```\n    var context = new Context{    Enabled = true,    Url = \"\",    Features = staticFeatures};\n    ```\n    \n3.  Create the `GrowthBook` object with the context\n    \n    ```\n    using GrowthBook;//...var GrowthBook = new GrowthBook.GrowthBook(context);\n    ```\n    \n4.  Check whether a feature is enabled\n    \n    ```\n    GrowthBook.IsOn(\"firstFeature\") // trueGrowthBook.IsOn(\"secondFeature\") // false\n    ```\n    \n\n### Loading feature definitions from an API[​](#loading-feature-definitions-from-an-api \"Direct link to Loading feature definitions from an API\")\n\nBecause feature definitions are typically loaded from API calls or cache, [Json.NET](https://www.nuget.org/packages/Newtonsoft.Json/13.0.2-beta1) objects are used to represent arbitrary document types such as Attributes, Conditions, and Feature values.\n\nTo load your features from the GrowthBook API use the following example:\n\n1.  Create a result model for the API response\n    \n    ```\n    public class FeaturesResult{    public HttpStatusCode Status { get; set; }    public IDictionary<string, Feature>? Features { get; set; }    public DateTimeOffset? DateUpdated { get; set; }}\n    ```\n    \n2.  call the endpoint and deserialize result\n    \n    ```\n    var url = \"YOUR_GROWTHBOOK_URL/api/features/YOUR_API_KEY\";var response = await client.GetAsync(url);if (response.IsSuccessStatusCode){    var content = await response.Content.ReadAsStringAsync();    var featuresResult = JsonConvert.DeserializeObject<FeaturesResult>(content);}\n    ```\n    \n3.  Construct a context and initialize GrowthBook\n    \n    ```\n    var GrowthBook = new GrowthBook.GrowthBook(    new Context {        Enabled = true,        Url = \"\",        Features = featuresResult.Features,    });\n    ```\n    \n\n#### Generic getters[​](#generic-getters \"Direct link to Generic getters\")\n\nTo make it easier to deal with Feature values, generic getter functions are provided for the following:\n\n*   Experiment:\n    *   `GetVariations<T>()`\n*   ExperimentResult:\n    *   `GetValue<T>()`\n*   Feature:\n    *   `GetDefaultValue<T>()`\n*   FeatureResult:\n    *   `GetValue<T>()`\n*   Feature Rule:\n    *   `GetVariations<T>()`\n*   GrowthBook:\n    *   `GetFeatureValue<T>(string key, T fallback)`",
  "title": "C# SDK | GrowthBook Docs",
  "description": "GrowthBook SDK for C#",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/elixir",
  "markdown": "# Elixir SDK | GrowthBook Docs\n\nThis SDK follows the guidelines set out in [GrowthBook's documentation](https://docs.growthbook.io/lib/build-your-own), and the API is tested on conformance with the test cases from the JS SDK.\n\nTo ensure an Elixir-friendly API, the implementation deviates from the official SDK in the following ways:\n\n```\n# Create a context, which can be reused for multiple usersfeatures_config = Jason.decode!(\"\"\"{  \"features\": {    \"send-reminder\": {      \"defaultValue\": false,      \"rules\": [{ \"condition\": { \"browser\": \"chrome\" }, \"force\": true }]    },    \"add-to-cart-btn-color\": {      \"rules\": [{ \"variations\": [{ \"color\": \"red\" }, { \"color\": \"green\" }] }]    }  }}\"\"\")features = GrowthBook.Config.features_from_config(features_config)context = %GrowthBook.Context{  enabled?: true,  features: features,  attributes: %{    \"id\" => \"12345\",    \"country_code\" => \"NL\",    \"browser\" => \"chrome\"  }}# Use a feature toggleif GrowthBook.feature(context, \"send-reminder\").on? do  Logger.info(\"Sending reminder\")end# Use a feature's valuecolor = GrowthBook.feature(context, \"add-to-cart-btn-color\").value[\"color\"]Logger.info(\"Color: \" <> color)# Run an inline experimentif GrowthBook.run(context, %GrowthBook.Experiment{  key: \"checkout-v2\",  active?: true,  coverage: 1,  variations: [1, 2]}).in_experiment? do  Logger.info(\"In experiment\")end\n```",
  "title": "Elixir SDK | GrowthBook Docs",
  "description": "GrowthBook SDK for Elixir",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/java",
  "markdown": "# Java SDK | GrowthBook Docs\n\nThis supports Java applications using Java version 1.8 and higher.\n\nNew\n\nThe GrowthBook Java SDK is a brand new feature. If you experience any issues, let us know either on [Slack](https://slack.growthbook.io/) or [create an issue](https://github.com/growthbook/growthbook-sdk-java/issues).\n\n## Installation[​](#installation \"Direct link to Installation\")\n\n[![](https://jitpack.io/v/growthbook/growthbook-sdk-java.svg)](https://jitpack.io/#growthbook/growthbook-sdk-java)\n\n### Gradle[​](#gradle \"Direct link to Gradle\")\n\nTo install in a Gradle project, add Jitpack to your repositories, and then add the dependency with the latest version to your project's dependencies.\n\n*   Groovy\n*   Kotlin\n\nbuild.gradle\n\n```\nallprojects {    repositories {        maven { url 'https://jitpack.io' }    }}dependencies {    implementation 'com.github.growthbook:growthbook-sdk-java:0.5.0'}\n```\n\n### Maven[​](#maven \"Direct link to Maven\")\n\nTo install in a Maven project, add Jitpack to your repositories:\n\n```\n<repositories>    <repository>        <id>jitpack.io</id>        <url>https://jitpack.io</url>    </repository></repositories>\n```\n\nNext, add the dependency with the latest version to your project's dependencies:\n\n```\n<dependency>    <groupId>com.github.growthbook</groupId>    <artifactId>growthbook-sdk-java</artifactId>    <version>0.5.0</version></dependency>\n```\n\n## Usage[​](#usage \"Direct link to Usage\")\n\nThere are 2 steps to initializing the GrowthBook SDK:\n\n1.  Create a GrowthBook context `GBContext` with the features JSON and the user attributes\n2.  Create the `GrowthBook` SDK class with the context\n\n### GrowthBook context[​](#growthbook-context \"Direct link to GrowthBook context\")\n\nThe GrowthBook context `GBContext` can be created either by implementing the builder class, available at `GBContext.builder()`, or by using the `GBContext` constructor.\n\n| Field name | Type | Description |\n| --- | --- | --- |\n| `attributesJson` | `String` | The user attributes JSON. See [Attributes](#attributes). |\n| `featuresJson` | `String` | The features JSON served by the GrowthBook API (or equivalent). See [Features](#features). |\n| `enabled` | `Boolean` | Whether to enable the functionality of the SDK (default: `true`) |\n| `isQaMode` | `Boolean` | Whether the SDK is in QA mode. Not for production use. If true, random assignment is disabled and only explicitly forced variations are used (default: `false`) |\n| `url` | `String` | The URL of the current page. Useful when evaluating features and experiments based on the page URL. |\n| `forcedVariationsMap` | `Map<String, Integer>` | Force specific experiments to always assign a specific variation (used for QA) |\n| `trackingCallback` | `TrackingCallback` | A callback that will be invoked with every experiment evaluation where the user **is** included in the experiment. See [TrackingCallback](#tracking-callback). To subscribe to all evaluated events regardless of whether the user is in the experiment, see [Subscribing to experiment runs](#subscribing-to-experiment-runs-with-the-experimentruncallback). |\n| `featureUsageCallback` | `FeatureUsageCallback` | A callback that will be invoked every time a feature is viewed. See [FeatureUsageCallback](#feature-usage-callback) |\n\n#### Using the GBContext builder[​](#using-the-gbcontext-builder \"Direct link to Using the GBContext builder\")\n\nThe builder is the easiest to use way to construct a `GBContext`, allowing you to provide as many or few arguments as you'd like. All fields mentioned above are available via the builder.\n\n*   Java\n*   Kotlin\n\n```\n// Fetch feature definitions from the GrowthBook API// We recommend adding a caching layer in production// Get your endpoint in the Environments tab -> SDK Endpoints: https://app.growthbook.io/environmentsURI featuresEndpoint = new URI(\"https://cdn.growthbook.io/api/features/<environment_key>\");HttpRequest request = HttpRequest.newBuilder().uri(featuresEndpoint).GET().build();HttpResponse<String> response = HttpClient.newBuilder().build()    .send(request, HttpResponse.BodyHandlers.ofString());String featuresJson = new JSONObject(response.body()).get(\"features\").toString();// JSON serializable user attributesString userAttributesJson = user.toJson();// Initialize the GrowthBook SDK with the GBContextGBContext context = GBContext    .builder()    .featuresJson(featuresJson)    .attributesJson(userAttributesJson)    .build();GrowthBook growthBook = new GrowthBook(context);\n```\n\nNote\n\nThe above example uses `java.net.http.HttpClient` which, depending on your web framework, may not be the best option, in which case it is recommended to use a networking library more suitable for your implementation.\n\n#### Using the GBContext constructor[​](#using-the-gbcontext-constructor \"Direct link to Using the GBContext constructor\")\n\nYou can also use `GBContext` constructor if you prefer, which will require you to pass all arguments explicitly.\n\n*   Java\n*   Kotlin\n\n```\n// Fetch feature definitions from the GrowthBook API// We recommend adding a caching layer in production// Get your endpoint in the Environments tab -> SDK Endpoints: https://app.growthbook.io/environmentsURI featuresEndpoint = new URI(\"https://cdn.growthbook.io/api/features/<environment_key>\");HttpRequest request = HttpRequest.newBuilder().uri(featuresEndpoint).GET().build();HttpResponse<String> response = HttpClient.newBuilder().build()    .send(request, HttpResponse.BodyHandlers.ofString());String featuresJson = new JSONObject(response.body()).get(\"features\").toString();// JSON serializable user attributesString userAttributesJson = user.toJson();boolean isEnabled = true;boolean isQaMode = false;String url = null;Map<String, Integer> forcedVariations = new HashMap<>();TrackingCallback trackingCallback = new TrackingCallback() {    @Override    public <ValueType> void onTrack(Experiment<ValueType> experiment, ExperimentResult<ValueType> experimentResult) {        // TODO: Something after it's been tracked    }};// Initialize the GrowthBook SDK with the GBContextGBContext context = new GBContext(    userAttributesJson,    featuresJson,    isEnabled,    isQaMode,    url,    forcedVariations,    trackingCallback);GrowthBook growthBook = new GrowthBook(context);\n```\n\nFor complete examples, see the [Examples](#code-examples) section below.\n\n#### Features[​](#features \"Direct link to Features\")\n\nThe features JSON is equivalent to the `features` property that is returned from the SDK Connection endpoint.\n\n*   You can read more [about features here](https://docs.growthbook.io/app/features)\n*   You can see an [example features JSON here](https://docs.growthbook.io/app/api#sdk-connection-endpoints)\n\n#### Attributes[​](#attributes \"Direct link to Attributes\")\n\nAttributes are a JSON string. You can specify attributes about the current user and request. Here's an example:\n\n*   Java\n*   Kotlin\n\n```\nString userAttributes = \"{\\\"country\\\": \\\"canada\\\", \\\"id\\\": \\\"user-abc123\\\"}\";\n```\n\nIf you need to set or update attributes asynchronously, you can do so with `Context#attributesJson` or `GrowthBook#setAttributes`. This will completely overwrite the attributes object with whatever you pass in. Also, be aware that changing attributes may change the assigned feature values. This can be disorienting to users if not handled carefully.\n\n#### Tracking Callback[​](#tracking-callback \"Direct link to Tracking Callback\")\n\nAny time an experiment is run to determine the value of a feature, we may call this callback so you can record the assigned value in your event tracking or analytics system of choice.\n\n**The tracking callback is only called when the user is in the experiment**. If they are not in the experiment, this will not be called. If you'd like to subscribe to all evaluations, regardless of experiment result, see [Subscribing to experiment runs](#subscribing-to-experiment-runs-with-the-experimentruncallback).\n\n*   Java\n*   Kotlin\n\n```\nTrackingCallback trackingCallback = new TrackingCallback() {    @Override    public <ValueType> void onTrack(        Experiment<ValueType> experiment,        ExperimentResult<ValueType> experimentResult    ) {        // TODO: Something after it's been tracked    }};GBContext context = GBContext    .builder()    .featuresJson(featuresJson)    .attributesJson(userAttributesJson)    .trackingCallback(trackingCallback)    .build();\n```\n\n#### Feature usage callback[​](#feature-usage-callback \"Direct link to Feature usage callback\")\n\nAny time a feature is viewed, this callback is called with the feature key and result.\n\n*   Java\n*   Kotlin\n\n```\nString featuresJson = featuresRepository.getFeaturesJson();String userAttributesJson = user.toJson();FeatureUsageCallback featureUsageCallback = new FeatureUsageCallback() {    @Override    public <ValueType> void onFeatureUsage(String featureKey, FeatureResult<ValueType> result) {        // TODO: Something with the feature result    }};GBContext context = GBContext    .builder()    .featuresJson(featuresJson)    .featureUsageCallback(featureUsageCallback)    .attributesJson(userAttributesJson)    .build();GrowthBook growthBook = new GrowthBook(context);\n```\n\n### Using Features[​](#using-features \"Direct link to Using Features\")\n\nEvery feature has a \"value\" which is assigned to a user. This value can be any JSON data type. If a feature doesn't exist, the value will be `null`.\n\nThere are 4 main methods for evaluating features.\n\n| Method | Return type | Description |\n| --- | --- | --- |\n| **`isOn(String)`** | `Boolean` | Returns true if the value is a truthy value |\n| **`isOff(String)`** | `Boolean` | Returns true if the value is a falsy value |\n| **`getFeatureValue(String)`** | generic `T` (nullable) | Returns the value cast to the generic type. Type is inferred based on the `defaultValue` argument provided. |\n| **`evalFeature(String)`** | `FeatureResult<T>` | Returns a feature result with a value of generic type `T`. The value type needs to be specified in the generic parameter. |\n\n*   Java\n*   Kotlin\n\n```\nif (growthBook.isOn(\"dark_mode\")) {    // value is truthy}if (growthBook.isOff(\"dark_mode\")) {    // value is falsy}Float featureValue = growthBook.getFeatureValue(\"donut_price\", 5.0f);FeatureResult<Float> featureResult = growthBook.<Float>evalFeature(\"donut_price\");\n```\n\n#### isOn() / isOff()[​](#ison--isoff \"Direct link to isOn() / isOff()\")\n\nThese methods return a boolean for truthy and falsy values.\n\nOnly the following values are considered to be \"falsy\":\n\n*   `null`\n*   `false`\n*   `\"\"`\n*   `0`\n\nEverything else is considered \"truthy\", including empty arrays and objects.\n\nIf the value is \"truthy\", then `isOn()` will return true and `isOff()` will return false. If the value is \"falsy\", then the opposite values will be returned.\n\n#### getFeatureValue(featureKey, defaultValue)[​](#getfeaturevaluefeaturekey-defaultvalue \"Direct link to getFeatureValue(featureKey, defaultValue)\")\n\nThis method has a variety of overloads to help with casting values to primitive and complex types.\n\nIn short, the type of the `defaultValue` argument will determine the return type of the function.\n\n| Return type | Method | Additional Info |\n| --- | --- | --- |\n| `Boolean` | **`getFeatureValue(String featureKey, Boolean defaultValue)`** |     |\n| `Double` | **`getFeatureValue(String featureKey, Double defaultValue)`** |     |\n| `Float` | **`getFeatureValue(String featureKey, Float defaultValue)`** |     |\n| `Integer` | **`getFeatureValue(String featureKey, Integer defaultValue)`** |     |\n| `String` | **`getFeatureValue(String featureKey, String defaultValue)`** |     |\n| `<ValueType> ValueType` | **`getFeatureValue(String featureKey, ValueType defaultValue, Class<ValueType> gsonDeserializableClass)`** | Internally, the SDK uses Gson. You can pass any class that does not require a custom deserializer. |\n| `Object` | **`getFeatureValue(String featureKey, Object defaultValue)`** | Use this method if you need to cast a complex object that uses a custom deserializer, or if you use a different JSON serialization library than Gson, and cast the type yourself. |\n\n[See the Java Docs](https://growthbook.github.io/growthbook-sdk-java/growthbook/sdk/java/GrowthBook.html) for more information.\n\n[See the unit tests](https://github.com/growthbook/growthbook-sdk-java/blob/main/lib/src/test/java/growthbook/sdk/java/GrowthBookTest.java#L220) for example implementations including type casting for all above-mentioned methods.\n\n#### evalFeature(String)[​](#evalfeaturestring \"Direct link to evalFeature(String)\")\n\nThe `evalFeature` method returns a `FeatureResult<T>` object with more info about why the feature was assigned to the user. The `T` type corresponds to the value type of the feature. In the above example, `T` is `Float`.\n\n`FeatureResult<T>` It has the following getters.\n\n| Method | Return type | Description |\n| --- | --- | --- |\n| **`getValue()`** | generic `T` (nullable) | The evaluated value of the feature |\n| **`getSource()`** | `enum FeatureResultSource` (nullable) | The reason/source for the evaluated feature value. |\n| **`getRuleId()`** | `String` (nullable) | ID of the rule that was used to assign the value to the user. |\n| **`getExperiment()`** | `Experiment<T>` (nullable) | The experiment details, available only if the feature evaluates due to an experiment. |\n| **`getExperimentResult()`** | `ExperimentResult<T>` (nullable) | The experiment result details, available only if the feature evaluates due to an experiment. |\n\nAs expected in Kotlin, you can access these getters using property accessors.\n\n### Inline Experiments[​](#inline-experiments \"Direct link to Inline Experiments\")\n\nInstead of declaring all features up-front in the context and referencing them by IDs in your code, you can also just run an experiment directly. This is done with the `growthbook.run(Experiment<T>)` method.\n\n*   Java\n*   Kotlin\n\n```\nExperiment<Float> donutPriceExperiment = Experiment    .<Float>builder()    .conditionJson(\"{\\\"employee\\\": true}\")    .build();ExperimentResult<Float> donutPriceExperimentResult = growthBook.run(donutPriceExperiment);Float donutPrice = donutPriceExperimentResult.getValue();\n```\n\n#### Inline experiment return value ExperimentResult[​](#inline-experiment-return-value-experimentresult \"Direct link to Inline experiment return value ExperimentResult\")\n\nAn `ExperimentResult<T>` is returned where `T` is the generic value type for the experiment.\n\nThere's also a number of methods available.\n\n| Method | Return type | Description |\n| --- | --- | --- |\n| **`getValue()`** | generic `T` (nullable) | The evaluated value of the feature |\n| **`getVariationId()`** | `Integer` (nullable) | Index of the variation used, if applicable |\n| **`getInExperiment()`** | `Boolean` | If the user was in the experiment. This will be false if the user was excluded from being part of the experiment for any reason (e.g. failed targeting conditions). |\n| **`getHashAttribute()`** | `String` | User attribute used for hashing, defaulting to `id` if not set. |\n| **`getHashValue()`** | `String` (nullable) | The hash value used for evaluating the experiment, if applicable. |\n| **`getFeatureId()`** | `String` | The feature key/ID |\n| **`getHashUsed()`** | `Boolean` | If a hash was used to evaluate the experiment. This flag will only be true if the user was randomly assigned a variation. If the user was forced into a specific variation instead, this flag will be false. |\n\nAs expected in Kotlin, you can access these getters using property accessors.\n\n### Tracking feature usage and experiment impressions[​](#tracking-feature-usage-and-experiment-impressions \"Direct link to Tracking feature usage and experiment impressions\")\n\n#### Subscribing to experiment runs with the ExperimentRunCallback[​](#subscribing-to-experiment-runs-with-the-experimentruncallback \"Direct link to Subscribing to experiment runs with the ExperimentRunCallback\")\n\nYou can subscribe to experiment run evaluations using the `ExperimentRunCallback`.\n\n*   Java\n*   Kotlin\n\n```\nString featuresJson = featuresRepository.getFeaturesJson();String userAttributesJson = user.toJson();ExperimentRunCallback experimentRunCallback = new ExperimentRunCallback() {    @Override    public void onRun(ExperimentResult experimentResult) {        // TODO: something with the experiment result    }};GBContext context = GBContext    .builder()    .featuresJson(featuresJson)    .attributesJson(userAttributesJson)    .build();GrowthBook growthBook = new GrowthBook(context);growthBook.subscribe(experimentRunCallback);\n```\n\nEvery time an experiment is evaluated when calling `growthBook.run(Experiment)`, the callbacks will be called.\n\nYou can subscribe with as many callbacks as you like:\n\n*   Java\n*   Kotlin\n\n```\nGrowthBook growthBook = new GrowthBook(context);growthBook.subscribe(experimentRunCallback1);growthBook.subscribe(experimentRunCallback2);growthBook.subscribe(experimentRunCallback3);\n```\n\n**The experiment run callback is called for every experiment run, regardless of experiment result**. If you would like to subscribe only to evaluations where the user falls into an experiment, see [TrackingCallback](#tracking-callback).\n\n#### Subscribing to feature usage events with the FeatureUsageCallback[​](#subscribing-to-feature-usage-events-with-the-featureusagecallback \"Direct link to Subscribing to feature usage events with the FeatureUsageCallback\")\n\nYou can subscribe to feature usage events by providing an implementation of the `FeatureUsageCallback` interface to the `GBContext`.\n\n*   Java\n*   Kotlin\n\n```\nString featuresJson = featuresRepository.getFeaturesJson();String userAttributesJson = user.toJson();FeatureUsageCallback featureUsageCallback = new FeatureUsageCallback() {    @Override    public <ValueType> void onFeatureUsage(String featureKey, FeatureResult<ValueType> result) {        // TODO: Something with the feature result    }};GBContext context = GBContext    .builder()    .featuresJson(featuresJson)    .featureUsageCallback(featureUsageCallback)    .attributesJson(userAttributesJson)    .build();GrowthBook growthBook = new GrowthBook(context);\n```\n\n### Working with Encrypted features[​](#working-with-encrypted-features \"Direct link to Working with Encrypted features\")\n\nAs of version 0.3.0, the Java SDK supports decrypting encrypted features. You can learn more about [SDK Connection Endpoint Encryption](https://docs.growthbook.io/app/api#encryption).\n\nThe main difference is you create a `GBContext` by passing an encryption key (`.encryptionKey()` when using the builder) and using the encrypted payload as the features JSON (`.featuresJson()` for the builder).\n\n*   Java\n*   Kotlin\n\n```\n// Fetch feature definitions from the GrowthBook API// We recommend adding a caching layer in production// Get your endpoint in the Environments tab -> SDK Endpoints: https://app.growthbook.io/environmentsURI featuresEndpoint = new URI(\"https://cdn.growthbook.io/api/features/<environment_key>\");HttpRequest request = HttpRequest.newBuilder().uri(featuresEndpoint).GET().build();HttpResponse<String> response = HttpClient.newBuilder().build()    .send(request, HttpResponse.BodyHandlers.ofString());String encryptedFeaturesJson = new JSONObject(response.body()).get(\"encryptedFeatures\").toString();// JSON serializable user attributesString userAttributesJson = user.toJson();// You can store your encryption key as an environment variable rather than hardcoding in plain text in your codebaseString encryptionKey = \"<key-for-decrypting>\";// Initialize the GrowthBook SDK with the GBContext and the encryption keyGBContext context = GBContext    .builder()    .featuresJson(encryptedFeaturesJson)    .encryptionKey(encryptionKey)    .attributesJson(userAttributesJson)    .build();GrowthBook growthBook = new GrowthBook(context);\n```\n\n### Fetching, Cacheing, and Refreshing features with GBFeaturesRepository[​](#fetching-cacheing-and-refreshing-features-with-gbfeaturesrepository \"Direct link to Fetching, Cacheing, and Refreshing features with GBFeaturesRepository\")\n\nAs of version 0.4.0, the Java SDK provides an optional `GBFeaturesRepository` class which will manage networking for you in the following ways:\n\n*   Fetching features from the SDK endpoint when `initialize()` is called\n*   Decrypting encrypted features when provided with the client key, e.g. `.builder().encryptionKey(clientKey)`\n*   Cacheing features (in-memory)\n*   Refreshing features\n\nIf you wish to manage fetching, refreshing, and cacheing features on your own, you can choose to not implement this class.\n\nRecommendation\n\nThis class should be implemented as a singleton class as it includes caching and refreshing functionality.\n\nIf you have more than one SDK endpoint you'd like to implement, you can extend the `GBFeaturesRepository` class with your own class to make it easier to work with dependency injection frameworks. Each of these instances should be singletons.\n\n#### Fetching the features[​](#fetching-the-features \"Direct link to Fetching the features\")\n\nYou will need to create a singleton instance of the `GBFeaturesRepository` class either by implementing its `.builder()` or by using its constructor.\n\nThen, you would call `myGbFeaturesRepositoryInstance.initialize()` in order to make the initial (blocking) request to fetch the features. Then, you would call `myGbFeaturesRepositoryInstance.getFeaturesJson()` and provided that to the `GBContext` initialization.\n\n*   Java\n*   Kotlin\n\n```\nGBFeaturesRepository featuresRepository = GBFeaturesRepository    .builder()    .apiHost(\"https://cdn.growthbook.io\")    .clientKey(\"<environment_key>\") // replace with your client key    .encryptionKey(\"<client-key-for-decrypting>\") // optional, nullable    .refreshStrategy(FeatureRefreshStrategy.SERVER_SENT_EVENTS) // optional; options: STALE_WHILE_REVALIDATE, SERVER_SENT_EVENTS (default: STALE_WHILE_REVALIDATE)    .build();// Optional callback for getting updates when features are refreshedfeaturesRepository.onFeaturesRefresh(new FeatureRefreshCallback() {    @Override    public void onRefresh(String featuresJson) {        System.out.println(\"Features have been refreshed\");        System.out.println(featuresJson);    }});try {    featuresRepository.initialize();} catch (FeatureFetchException e) {    // TODO: handle the exception    e.printStackTrace();}// Initialize the GrowthBook SDK with the GBContext and featuresGBContext context = GBContext    .builder()    .featuresJson(featuresRepository.getFeaturesJson())    .attributesJson(userAttributesJson)    .build();GrowthBook growthBook = new GrowthBook(context);\n```\n\nFor more references, see the [Examples](#code-examples) below.\n\n#### Cacheing and refreshing behaviour[​](#cacheing-and-refreshing-behaviour \"Direct link to Cacheing and refreshing behaviour\")\n\nAs of version 0.9.0, there are 2 refresh strategies available.\n\n##### Stale While Revalidate[​](#stale-while-revalidate \"Direct link to Stale While Revalidate\")\n\nThis is the default strategy but can be explicitly stated by passing `FeatureRefreshStrategy.STALE_WHILE_REVALIDATE` as the refresh strategy option to the `GBFeaturesRepository` builder or constructor.\n\nThe `GBFeaturesRepository` will automatically refresh the features when the features become stale. Features are considered stale every 60 seconds. This amount is configurable with the `ttlSeconds` option.\n\nWhen you fetch features and they are considered stale, the stale features are returned from the `getFeaturesJson()` method and a network call to refresh the features is enqueued asynchronously. When that request succeeds, the features are updated with the newest features, and the next call to `getFeaturesJson()` will return the refreshed features.\n\n##### Server-Sent Events[​](#server-sent-events \"Direct link to Server-Sent Events\")\n\nThis is a new strategy that can be enabled by passing `FeatureRefreshStrategy.SERVER_SENT_EVENTS` as the refresh strategy option to the `GBFeaturesRepository` builder or constructor.\n\nIf you're using [GrowthBook Cloud](https://app.growthbook.io/) , this is ready for you to use. If you are self-hosting, you will need to set up the [GrowthBook Proxy](https://docs.growthbook.io/self-host/proxy) to enable it.\n\n## Overriding Feature Values[​](#overriding-feature-values \"Direct link to Overriding Feature Values\")\n\nThe Java SDK allows you to override feature values and experiments using the URL.\n\n### Force Experiment Variations[​](#force-experiment-variations \"Direct link to Force Experiment Variations\")\n\nYou can force an experiment variation by passing the experiment key and variation index as query parameters in the URL you set on the `GBContext`. For example, if you add `?my-experiment-id=2` to the URL, users will be forced into the variation at index 2 in the variations list when evaluating the experiment with key `my-experiment-id`.\n\n### Force Feature Values via the URL[​](#force-feature-values-via-the-url \"Direct link to Force Feature Values via the URL\")\n\nYou can force a value for a feature by passing the key, prefixed by `gb~`, and the URI-encoded value in the URL's query parameters. You must also set `allowUrlOverrides` to true when building your `GBContext` in order to enable this feature as it is not enabled by default.\n\n```\nGBContext context = GBContext    .builder()    .url(\"http://localhost:8080/url-feature-force?gb~dark_mode=true&gb~donut_price=3.33&gb~banner_text=Hello%2C%20everyone!%20I%20hope%20you%20are%20all%20doing%20well!\")    .allowUrlOverrides(true)    .build();\n```\n\nThe above code sample sets the following:\n\n*   `dark_mode`: `true`\n*   `banner_text`: `\"Hello, everyone! I hope you are all doing well!\"`\n*   `donut_price`: `3.33`\n\n#### Supported types[​](#supported-types \"Direct link to Supported types\")\n\n| Type | Value |\n| --- | --- |\n| `String` | A URI-encoded string value |\n| `Float` | A float value, e.g. `3.33` |\n| `Double` | A double value, e.g. `3.33` |\n| `Integer` | An integer value, e.g. `1337` |\n| `Boolean` | A boolean value, e.g. `true` or `false`. You can also represent boolean values with on/off state as `on` or `off` or binary values `1` or `0`. |\n| JSON as `Gson`\\-deserializable | A class that can be deserialized using Gson and that does not have any dependencies on custom type adapters. |\n| JSON as `String` | A URI-encoded string value that should be a valid JSON string that you can deserialize with your own JSON deserialization implementation. |\n\nThe value passed in the URL is cast at runtime based on the generic type argument passed in when evaluating the feature. This means that when you call `<ValueType>getFeatureValue()`, what you pass into the URL must successfully cast as `ValueType` otherwise the value in the URL will be ignored.\n\nAll keys must be prefixed with `gb~`.\n\n## Using with Proguard and R8[​](#using-with-proguard-and-r8 \"Direct link to Using with Proguard and R8\")\n\nMany Android projects use code-shrinking and obfuscation tools like Proguard and R8 in production.\n\nIf you are experiencing unexpected feature evaluation results with your release Android builds that do not occur in your debug builds, it's most likely related to this.\n\nYou will need to add the following to your `proguard-rules.pro` file to ensure that all of the GrowthBook SDK classes are kept so that your features are evaluated properly in projects that use Proguard and R8:\n\n```\n# Growthbook Java SDK classes-keep class growthbook.sdk.java.** { *; }\n```\n\n## Code Examples[​](#code-examples \"Direct link to Code Examples\")\n\n*   [JVM with Spring Web example](https://github.com/growthbook/examples/tree/main/jvm-spring-web)\n*   [JVM example in Kotlin with Ktor](https://github.com/growthbook/examples/tree/main/jvm-kotlin-ktor-example)\n*   [Android Java example](https://github.com/growthbook/examples/tree/main/android-example)\n\n## Further Reading[​](#further-reading \"Direct link to Further Reading\")\n\n*   [JavaDoc class documentation](https://growthbook.github.io/growthbook-sdk-java/)",
  "title": "Java SDK | GrowthBook Docs",
  "description": "GrowthBook SDK for Java",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/swift",
  "markdown": "# Swift SDK | GrowthBook Docs\n\n## Swift (iOS)\n\nThis SDK supports the following platforms and versions:\n\n*   iOS 12 and above\n*   Apple TvOS 12 and above\n*   Apple WatchOS 5.0 and above\n\n## Installation[​](#installation \"Direct link to Installation\")\n\n### CocoaPods[​](#cocoapods \"Direct link to CocoaPods\")\n\nAdd the following to your podfile:\n\n```\nsource 'https://github.com/CocoaPods/Specs.git'target 'MyApp' do  pod 'GrowthBook-IOS'end\n```\n\nThen, install:\n\n### Swift Package Manager (SPM)[​](#swift-package-manager-spm \"Direct link to Swift Package Manager (SPM)\")\n\nAdd GrowthBook to your `Package.swift` file:\n\n```\ndependencies: [  .package(url: \"https://github.com/growthbook/growthbook-swift.git\")]\n```\n\n## Quick Usage[​](#quick-usage \"Direct link to Quick Usage\")\n\n```\n// First, create a GrowthBook instance using your unique features endpointvar gb: GrowthBookSDK = GrowthBookBuilder(  // Your GrowthBook feature flag endpoint  url: \"https://cdn.growthbook.io/api/features/sdk-abc123\").initializer()// Then, add targeting attributes so you can control the release of your features// TODO: Replace with your real targeting attributesvar attrs = [  \"id\": \"12345\",  \"deviceId\": \"abc123\",  \"loggedIn\": true,  \"country\": \"US\"]gb.setAttributes(attrs)// Finally, start feature flagging!// Boolean (On/Off) Feature Flagif (gb.isOn(\"feature-usage-code\")) {  // Feature is enabled!}// String/Number/JSON Feature Flag with a fallbackvar value = gb.getFeatureValue(\"button-color\", \"blue\")print(value)\n```\n\n## Loading Features[​](#loading-features \"Direct link to Loading Features\")\n\nIn order for the GrowthBook SDK to work, it needs to have feature definitions from the GrowthBook API. There are 2 ways to get this data into the SDK.\n\n### Built-in Fetching and Caching[​](#built-in-fetching-and-caching \"Direct link to Built-in Fetching and Caching\")\n\nIf you pass a `url` into GrowthBookBuilder, it will handle the network requests, caching, retry logic, etc. for you automatically. If your feature payload is encrypted, you can also pass in an `encryptionKey` and it will decrypt feature flags automatically.\n\n```\nvar gb: GrowthBookSDK = GrowthBookBuilder(  // Your feature flag endpoint  url: \"https://cdn.growthbook.io/api/features/sdk-abc123\",  // View your encryption key on the Features → SDKs page  encryptionKey: \"abcdef98765\").initializer()\n```\n\nIf you want to refresh the features at any time (e.g. when a navigation event occurs), you can call `gb.refreshCache()`.\n\n### Custom Integration[​](#custom-integration \"Direct link to Custom Integration\")\n\nIf you prefer to handle the network and caching logic yourself, you can instead pass in a features JSON object directly. For example, you might store features in Postgres on your back-end and send it down to your app as part of an initial bootstrap API call.\n\n```\nvar gb: GrowthBookSDK = GrowthBookBuilder(  features: [    \"feature1\": Feature(defaultValue: true)  ]).initializer()\n```\n\n## Experimentation (A/B Testing)[​](#experimentation-ab-testing \"Direct link to Experimentation (A/B Testing)\")\n\nIn order to run A/B tests on your feature flags, you need to set up a tracking callback function. This is called every time a user is put into an experiment and can be used to track the exposure event in your analytics system (Segment, Mixpanel, GA, etc.).\n\n```\nvar gb: GrowthBookSDK = GrowthBookBuilder(  // Your feature flag endpoint  url: \"https://cdn.growthbook.io/api/features/sdk-abc123\",  // Called whenever someone is put into an experiment  trackingCallback: { experiment, experimentResult in    // TODO: Track in your real analytics system    print(\"Viewed Experiment\")    print(\"Experiment Id: \", experiment.key)    print(\"Variation Id: \", experimentResult.variationId)  }).initializer()\n```\n\n## Reference[​](#reference \"Direct link to Reference\")\n\nView detailed docs on the [GitHub Repo](https://github.com/growthbook/growthbook-swift)",
  "title": "Swift SDK | GrowthBook Docs",
  "description": "GrowthBook SDK for Swift - iOS",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/flutter",
  "markdown": "# Flutter SDK | GrowthBook Docs\n\nThis SDK supports the following versions:\n\n*   **Android version 21 & above**\n*   **iOS version 12 & Above**\n*   **Apple TvOS version 13 & Above**\n*   **Apple WatchOS version 7 & Above**\n\n## Installation[​](#installation \"Direct link to Installation\")\n\nAdd this to your `pubspec.yaml` file\n\n```\ngrowthbook_sdk_flutter: ^1.0.0\n```\n\n## Quick Usage[​](#quick-usage \"Direct link to Quick Usage\")\n\nTo create a GrowthBook SDK instance, use `GBSDKBuilderApp`. Then, you can evaluate feature flags or run experiments.\n\n```\n// User attributes for targeting and assigning users to experiment variationsval attrs = HashMap<String, Any>()attrs.put(\"id\", \"123\")attrs.put(\"env\", \"dev\")attrs.put(\"betaUser\", true)final GrowthBookSDK sdkInstance = GBSDKBuilderApp(  apiKey: \"<API_KEY>\",  attributes: {    attrs  },  growthBookTrackingCallBack: (gbExperiment, gbExperimentResult) {},  hostURL: '<GrowthBook_URL>',).initialize();if (gb.feature(\"my-feature\").on) {  // Feature is enabled!}\n```\n\n## Using Features[​](#using-features \"Direct link to Using Features\")\n\nThe `feature` method takes a String feature name and returns a `GBFeatureResult` object with a few useful properties:\n\n*   **value** (`dynamic`) - The assigned value of the feature\n*   **on** (`bool`) - The value cast to a boolean\n*   **off** (`bool`) - The value cast to a boolean and then negated\n*   **source** (`String`) - Why the value was assigned to the user. One of \"unknownFeature\", \"defaultValue\", \"force\", or \"experiment\"\n\nWhen the source is \"experiment\", there are 2 additional properties that tell you which experiment was used and more details about the result of the experiment:\n\n*   **experiment** (`GBExperiment`)\n*   **experimentResult** (`GBExperimentResult`)\n\nHere are some examples:\n\n```\nGBFeatureResult feature = gb.feature(\"my-feature\")// Do something if feature is truthyif (feature.on) { }// Do something if feature is falsyif (feature.off) { }// Print the actual value of the feature// (depending on the feature, might be a string, number, boolean, etc.)Println(feature.value)// Print the experiment id used to assign the feature valueif (feature.source == \"experiment\") {  Println(feature.experiment.key)}\n```\n\n## Running Inline Experiments[​](#running-inline-experiments \"Direct link to Running Inline Experiments\")\n\nInstead of just using features defined in the GrowthBook API, you can run an experiment directly. This is done with the `run` method, which takes a `GBExperiment` object as an argument and returns a `GBExperimentResult` object:\n\n```\nvar exp = GBExperiment()exp.key = \"my-experiment\"exp.variations = List.of(\"control\", \"variation\")var result = gb.run(exp)// Either \"control\" or \"variation\"Println(result.value)\n```\n\nThe `GBExperiment` class has two required properties - `key` and `variations`. There are also a number of optional properties:\n\n*   **key** (`String`) - The unique identifier for this experiment\n*   **variations** (`dynamic[]`) - Array of variations to decide between\n*   **weights** (`double[]`) - How to weight traffic between variations. Must add to 1.\n*   **active** (`bool`) - If set to false, always return the control (first variation)\n*   **coverage** (`double`) - What percent of users should be included in the experiment (between 0 and 1, inclusive)\n*   **condition** (`GBCondition`) - Optional targeting condition\n*   **namespace** (`[String, int, int]`) - Adds the experiment to a namespace\n*   **force** (`int`) - All users included in the experiment will be forced into the specific variation index\n*   **hashAttribute** (`String`) - What user attribute should be used to assign variations (defaults to `id`)\n\nThe `GBExperimentResult` object returns the following properties:\n\n*   **inExperiment** (`bool`)\n*   **variationId** (`int`) - The array index of the assigned variation\n*   **value** (`dynamic`) - The value of the assigned variation\n*   **hashAttribute** (`String`) - The user attribute used to assign a variation\n*   **hashValue** (`String`) - The value of the attribute used to assign a variation\n\n## More Documentation[​](#more-documentation \"Direct link to More Documentation\")\n\nThe GitHub repo for this SDK has more detailed class and method documentation - [https://github.com/growthbook/growthbook-flutter](https://github.com/growthbook/growthbook-flutter)",
  "title": "Flutter SDK | GrowthBook Docs",
  "description": "Flutter SDK for GrowthBook",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/tools/cli",
  "markdown": "# GrowthBook Command Line Interface (CLI)\n\nThe GrowthBook command-line interface (CLI) is a tool for working with the GrowthBook A/B testing, feature flagging, and experimentation platform.\n\nRequires Node.js version 16+.\n\nNew\n\nThe GrowthBook CLI is a brand new tool. If you experience any issues, let us know either on [Slack](https://slack.growthbook.io/) or [create an issue](https://github.com/growthbook/growthbook-cli/issues).\n\n## CLI Features[​](#cli-features \"Direct link to CLI Features\")\n\n### Generating Types[​](#generating-types \"Direct link to Generating Types\")\n\nThe GrowthBook CLI enables you to generate TypeScript types for working with the SDK.\n\nRun `growthbook features generate-types --help` for more info.\n\nSee the [JavaScript SDK documentation](https://docs.growthbook.io/lib/js#strict-typing) for more information on working with typed features.\n\n### Profile management[​](#profile-management \"Direct link to Profile management\")\n\nIf you have multiple GrowthBook organizations or accounts, you can easily switch between profiles when running individual commands.\n\nRun `growthbook auth --help` for more info.\n\n## Usage[​](#usage \"Direct link to Usage\")\n\n### Installing the CLI[​](#installing-the-cli \"Direct link to Installing the CLI\")\n\nYou can install the CLI to your project with the following command:\n\nnpm install growthbook --save\n\nOr if you use `yarn` you can do:\n\nyarn add growthbook\n\nYou can also install it globally so you can use it with multiple projects and outside of projects:\n\nnpm install -g growthbook\n\nThe `growthbook` executable should now be available in your project. You should now be able to run commands, e.g.:\n\ngrowthbook --help\n\n### Adding your API secret[​](#adding-your-api-secret \"Direct link to Adding your API secret\")\n\nBefore using the GrowthBook CLI you will need to authenticate yourself. You will need to get an API key, which you can do [here](https://app.growthbook.io/settings/keys) .\n\nNext, use the `growthbook auth login --apiKey XXX` command to set your token for the default profile.\n\nRun `growthbook auth login --help` for more info and options.\n\n### Generating Types[​](#generating-types-1 \"Direct link to Generating Types\")\n\nYou can also add it to your `package.json` file of the project that will use the types, e.g.:\n\n```\n{  \"scripts\": {    \"type-gen\": \"growthbook features generate-types --output ./types\"  }}\n```\n\nIt should now be available for use when you run `npm run type-gen` or `yarn type-gen`.\n\n### Usage on CI/CD[​](#usage-on-cicd \"Direct link to Usage on CI/CD\")\n\nIf you'd like to use the CLI in continuous integration/continuous deployment environments, instead of running the `growthbook auth login` command, we recommend creating the following file at `~/.growthbook/config.toml` with your secret and API base URL:\n\n```\n[default]growthbook_secret = \"secret_abc123\"api_base_url = \"https://api.growthbook.io\" # replace this with your API URL if self-hosted\n```\n\nYou can also store multiple profiles and refer to them with the `--profile` flag in supported commands:\n\n```\n[default]growthbook_secret = \"secret_abc123\"api_base_url = \"https://api.growthbook.io\"[acme_donuts]growthbook_secret = \"secret_xyz987\"api_base_url = \"http://localhost:3100\"\n```\n\n### Detailed Command Usage[​](#detailed-command-usage \"Direct link to Detailed Command Usage\")\n\nSee the generated [GrowthBook CLI command documentation on Github](https://github.com/growthbook/growthbook-cli#commands) .\n\n### Examples[​](#examples \"Direct link to Examples\")\n\n*   [Example implementation of a TypeScript project that uses the GrowthBook CLI](https://github.com/growthbook/examples/tree/main/vanilla-typescript)",
  "title": "GrowthBook Command Line Interface (CLI) | GrowthBook Docs",
  "description": "The GrowthBook command-line interface (CLI) for working with the GrowthBook A/B testing, feature flagging, and experimentation platform",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/react-native",
  "markdown": "# React Native SDK | GrowthBook Docs\n\nThis is a thin wrapper on top of the [Javascript Library](https://docs.growthbook.io/lib/js), so you might want to view those docs first to familiarize yourself with the basic classes and methods.\n\n## Installation[​](#installation \"Direct link to Installation\")\n\nInstall with a package manager\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save @growthbook/growthbook-react\n```\n\n## Quick Usage[​](#quick-usage \"Direct link to Quick Usage\")\n\n### Step 1: Configure your app[​](#step-1-configure-your-app \"Direct link to Step 1: Configure your app\")\n\n```\nimport { useEffect } from \"react\";import { GrowthBook, GrowthBookProvider } from \"@growthbook/growthbook-react\";// Create a GrowthBook instanceconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  // Only required for A/B testing  // Called every time a user is put into an experiment  trackingCallback: (experiment, result) => {    console.log(\"Experiment Viewed\", {      experimentId: experiment.key,      variationId: result.key,    });  },});gb.init()export default function App() {  useEffect(() => {    // TODO: Set user attributes for targeting    gb.setAttributes({      id: user.id,      company: user.company,    });  }, [user])  return (    <GrowthBookProvider growthbook={gb}>      <OtherComponent />    </GrowthBookProvider>  );}\n```\n\n### Step 2: Start feature flagging![​](#step-2-start-feature-flagging \"Direct link to Step 2: Start feature flagging!\")\n\nThere are a few ways to use feature flags in GrowthBook:\n\n#### Feature Hooks[​](#feature-hooks \"Direct link to Feature Hooks\")\n\n```\nimport { useFeatureValue, useFeatureIsOn } from \"@growthbook/growthbook-react\";export default function OtherComponent() {  // Boolean on/off features  const newLogin = useFeatureIsOn(\"new-login-form\");  // String/Number/JSON features with a fallback value  const buttonColor = useFeatureValue(\"login-button-color\", \"blue\");  if (newLogin) {    return <NewLogin color={buttonColor} />;  } else {    return <Login color={buttonColor} />;  }}\n```\n\n#### Feature Wrapper Components[​](#feature-wrapper-components \"Direct link to Feature Wrapper Components\")\n\n```\nimport { IfFeatureEnabled, FeatureString } from \"@growthbook/growthbook-react\";export default function OtherComponent() {  return (    <View>      <Text style={heading}>        <FeatureString feature=\"app-title\" default=\"My App\"/>      </Text>      <IfFeatureEnabled feature=\"welcome-message\">        <Text>Welcome to our app!</Text>      </IfFeatureEnabled>    </View>  );}\n```\n\n#### useGrowthBook hook[​](#usegrowthbook-hook \"Direct link to useGrowthBook hook\")\n\nIf you need low-level access to the GrowthBook instance for any reason, you can use the `useGrowthBook` hook.\n\nOne example is updating targeting attributes when a user logs in:\n\n```\nimport { useGrowthBook } from \"@growthbook/growthbook-react\";export default function Auth() {  const growthbook = useGrowthBook();  const user = useUser();  useEffect(() => {    if (!user) return;    growthbook.setAttributes({      loggedIn: true,      id: user.id,      company: user.company,      isPro: user.plan === \"pro\"    })  }, [user, growthbook])  ...}\n```\n\n## Loading Features[​](#loading-features \"Direct link to Loading Features\")\n\nIn order for the GrowthBook SDK to work, it needs to have feature definitions from the GrowthBook API. There are 2 ways to get this data into the SDK.\n\n### Built-in Fetching and Caching[​](#built-in-fetching-and-caching \"Direct link to Built-in Fetching and Caching\")\n\nIf you pass an `apiHost` and `clientKey` into the GrowthBook constructor, it will handle the network requests, caching, retry logic, etc. for you automatically. If your feature payload is encrypted, you can also pass in a `decryptionKey`.\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",});await gb.init({  // If the network request takes longer than this (in milliseconds), continue  // Default: `0` (no timeout)  timeout: 2000,})\n```\n\nUntil features are loaded, all features will evaluate to `null`. If you're ok with a potential flicker in your application (features going from `null` to their real value), you can call `init` without awaiting the result.\n\nIf you want to refresh the features at any time (e.g. when a navigation event occurs), you can call `gb.refreshFeatures()`.\n\n#### Error Handling[​](#error-handling \"Direct link to Error Handling\")\n\nIn the case of network issues, the `init` call will not throw an error. Instead, it will stay in the default state where every feature evaluates to `null`.\n\nYou can still get access to the error if needed:\n\n```\nconst res = await gb.init({  timeout: 1000});console.log(res);\n```\n\nThe return value has 3 properties:\n\n*   **status** - `true` if the GrowthBook instance was populated with features/experiments. Otherwise `false`\n*   **source** - Where this result came from. One of the following values: `network`, `cache`, `init`, `error`, or `timeout`\n*   **error** - If status is `false`, this will contain an `Error` object with more details about the error\n\n### Custom Integration[​](#custom-integration \"Direct link to Custom Integration\")\n\nIf you prefer to handle the network and caching logic yourself, you can pass in a full JSON \"payload\" directly into the SDK. For example, you might store features in Postgres and send it down as part of your app's initial bootstrap API call.\n\n```\nawait gb.init({  payload: {    features: {      \"feature-1\": {...},      \"feature-2\": {...},      \"another-feature\": {...},    }  }})\n```\n\nThe data structure for \"payload\" is exactly the same as what is returned by the GrowthBook SDK endpoints and webhooks.\n\nYou can update the payload at any time by calling `setPayload(newPayloadJSON)`.\n\nNote: you don't need to specify `clientKey` or `apiHost` on your GrowthBook instance unless you want to enable streaming (see below) or call `refreshFeatures()` later.\n\n#### Synchronous Init[​](#synchronous-init \"Direct link to Synchronous Init\")\n\nThere is a alternate synchronous version of init named `initSync`, which can be especially useful in SSR to prevent hydration mismatches. There are some restrictions/differences:\n\n*   You MUST pass in `payload`\n*   The `payload` MUST NOT have encrypted features or experiments\n*   If you use sticky bucketing, you MUST pass `stickyBucketAssignmentDocs` into your GrowthBook constructor\n*   The return value is the GrowthBook instance to enable easy method chaining\n\n## Waiting for Features to Load[​](#waiting-for-features-to-load \"Direct link to Waiting for Features to Load\")\n\nThere is a helper component `<FeaturesReady>` that lets you render a fallback component until features are done loading. This works for both built-in fetching and custom integrations.\n\n```\n<FeaturesReady timeout={500} fallback={<LoadingSpinner/>}>  <ComponentThatUsesFeatures/></FeaturesReady>\n```\n\n*   `timeout` is the max time you want to wait for features to load (in ms). The default is `0` (no timeout).\n*   `fallback` is the component you want to display before features are loaded. The default is `null`.\n\nIf you want more control, you can use the `useGrowthBook()` hook and the `ready` flag:\n\n```\nconst gb = useGrowthBook();if (gb.ready) {  // Do something}\n```\n\n## Streaming Updates[​](#streaming-updates \"Direct link to Streaming Updates\")\n\nThe GrowthBook SDK supports streaming with Server-Sent Events (SSE). When enabled, changes to features within GrowthBook will be streamed to the SDK in realtime as they are published. This is only supported on GrowthBook Cloud or if running a GrowthBook Proxy Server.\n\nReact Native does not support SSE out-of-the-box, but there is a small helper library you can install:\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save react-native-sse\n```\n\nThe, tell GrowthBook to use this polyfill:\n\n```\nimport { setPolyfills } from \"@growthbook/growthbook\";import EventSource from \"react-native-sse\";// Configure GrowthBook to use the eventsource librarysetPolyfills({  EventSource: EventSource});\n```\n\nAnd finally, you can simply pass `streaming: true` into your init calls:\n\n```\ngb.init({  streaming: true,})\n```\n\n## Remote Evaluation[​](#remote-evaluation \"Direct link to Remote Evaluation\")\n\nThe React Native SDK may be run in Remote Evaluation mode. This mode brings the security benefits of a backend SDK to mobile by evaluating feature flags exclusively on a private server. Using Remote Evaluation ensures that any sensitive information within targeting rules or unused feature variations are never seen by the client.\n\nYou must enable Remote Evaluation in your SDK Connection settings. Cloud customers are also required to self-host a GrowthBook Proxy Server or custom remote evaluation backend.\n\nTo use Remote Evaluation, add the `remoteEval: true` property to your SDK instance. A new evaluation API call will be made any time a user attribute or other dependency changes. You may optionally limit these API calls to specific attribute changes by setting the `cacheKeyAttributes` property (an array of attribute names that, when changed, trigger a new evaluation call).\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://gb-proxy.mydomain.io/\",  clientKey: \"sdk-abc123\",  // Enable remote evaluation  remoteEval: true,  // Optional: only trigger a new evaluation call when the `id` and `email` attribute changes  cacheKeyAttributes: [\"id\", \"email\"],});\n```\n\nnote\n\nIf you would like to implement Sticky Bucketing while using Remote Evaluation, you must configure your remote evaluation backend to support Sticky Bucketing. In the case of the GrowthBook Proxy Server, this means implementing a Redis database for sticky bucketing use. You will not need to provide a StickyBucketService instance to the client side SDK.\n\n## Caching[​](#caching \"Direct link to Caching\")\n\nThe React Native SDK has 2 caching layers:\n\n1.  In-memory cache (enabled by default)\n2.  Persistent localStorage cache (disabled by default, requires configuration)\n\n### Configuring Local Storage[​](#configuring-local-storage \"Direct link to Configuring Local Storage\")\n\nIn order to use persistent storage, you must provide a polyfill with the same method signature as browser's localStorage.\n\nHere's an example using AsyncStorage\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save @react-native-async-storage/async-storage\n```\n\n```\nimport AsyncStorage from '@react-native-async-storage/async-storage';import { setPolyfills } from \"@growthbook/growthbook\";setPolyfills({  localStorage: {    // Example using Redis    getItem: (key) => JSON.parse(AsyncStorage.getItem(key) || \"null\")    setItem: (key, value) => AsyncStorage.setItem(key, JSON.stringify(value))  }});\n```\n\n### Cache Settings[​](#cache-settings \"Direct link to Cache Settings\")\n\nThere are a number of cache settings you can configure within GrowthBook. This must be done BEFORE creating a GrowthBook instance.\n\nBelow are all of the default values. You can call `configureCache` with a subset of these fields and the rest will keep their default values.\n\n```\nimport { configureCache } from \"@growthbook/growthbook\";configureCache({  // The localStorage key the cache will be stored under  cacheKey: \"gbFeaturesCache\",  // Consider features stale after this much time (60 seconds default)  staleTTL: 1000 * 60,  // Cached features older than this will be ignored (24 hours default)  maxAge: 1000 * 60 * 60 * 24,  // For Remote Eval only - limit the number of cache entries (~1 entry per user)  maxEntries: 10,  // Set to `true` to completely disable both in-memory and persistent caching  disableCache: false,})\n```\n\n## Experimentation (A/B Testing)[​](#experimentation-ab-testing \"Direct link to Experimentation (A/B Testing)\")\n\nIn order to run A/B tests, you need to set up a tracking callback function. This is called every time a user is put into an experiment and can be used to track the exposure event in your analytics system (Segment, Mixpanel, GA, etc.).\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  trackingCallback: (experiment, result) => {    // Example using Segment    analytics.track(\"Experiment Viewed\", {      experimentId: experiment.key,      variationId: result.key,    });  },});\n```\n\nThis same tracking callback is used for both feature flag experiments and Visual Editor experiments.\n\n### Feature Flag Experiments[​](#feature-flag-experiments \"Direct link to Feature Flag Experiments\")\n\nThere is nothing special you have to do for feature flag experiments. Just evaluate the feature flag like you would normally do. If the user is put into an experiment as part of the feature flag, it will call the `trackingCallback` automatically in the background.\n\n```\n// If this has an active experiment and the user is included,// it will call trackingCallback automaticallyuseFeatureIsOn(\"new-signup-form\")\n```\n\nIf the experiment came from a feature rule, `result.featureId` in the trackingCallback will contain the feature id, which may be useful for tracking/logging purposes.\n\n### Visual Editor Experiments[​](#visual-editor-experiments \"Direct link to Visual Editor Experiments\")\n\nVisual Editor experiments are not supported in React Native at this time.\n\n### URL Redirect Experiments[​](#url-redirect-experiments \"Direct link to URL Redirect Experiments\")\n\nURL Redirect experiments are no supported in React Native at this time.\n\n### Sticky Bucketing[​](#sticky-bucketing \"Direct link to Sticky Bucketing\")\n\nSticky bucketing ensures that users see the same experiment variant, even when user session, user login status, or experiment parameters change. See the [Sticky Bucketing docs](https://docs.growthbook.io/app/sticky-bucketing) for more information. If your organization and experiment supports sticky bucketing, you must implement an instance of the `StickyBucketService` to use Sticky Bucketing.\n\nThe JS SDK exports several implementations of this service for reference, although you will need to build your own to work in a React Native environments.\n\nImplement the abstract `StickyBucketService` class and connect to your own data store, or custom wrap multiple service implementations.\n\n```\nimport Cookies from 'js-cookie';const gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  stickyBucketService: new MyStickyBucketService(),  // ...});\n```\n\n## API Reference[​](#api-reference \"Direct link to API Reference\")\n\nThere are a number of configuration options and settings that control how GrowthBook behaves.\n\n### Attributes[​](#attributes \"Direct link to Attributes\")\n\nYou can specify attributes about the current user and request. These are used for two things:\n\n1.  Feature targeting (e.g. paid users get one value, free users get another)\n2.  Assigning persistent variations in A/B tests (e.g. user id \"123\" always gets variation B)\n\nThe following are some commonly used attributes, but use whatever makes sense for your application.\n\n```\nnew GrowthBook({  attributes: {    id: \"123\",    loggedIn: true,    deviceId: \"abc123def456\",    company: \"acme\",    paid: false,    url: \"/pricing\",    browser: \"chrome\",    mobile: false,    country: \"US\",  },});\n```\n\n#### Updating Attributes[​](#updating-attributes \"Direct link to Updating Attributes\")\n\nIf attributes change, you can call `setAttributes()` to update. This will completely overwrite any existing attributes. To do a partial update, use the following pattern:\n\n```\ngb.setAttributes({  // Only update the `url` attribute, keep the rest the same  ...gb.getAttributes(),  url: \"/new-page\"})\n```\n\n#### Secure Attributes[​](#secure-attributes \"Direct link to Secure Attributes\")\n\nWhen _secure attribute hashing_ is enabled, all targeting conditions in the SDK payload referencing attributes with datatype `secureString` or `secureString[]` will be anonymized via SHA-256 hashing. This allows you to safely target users based on sensitive attributes. You must enable this feature in your SDK Connection for it to take effect.\n\nIf your SDK Connection has secure attribute hashing enabled, you will need to manually hash any `secureString` or `secureString[]` attributes that you pass into the GrowthBook SDK.\n\nTo hash an attribute, use a cryptographic library with SHA-256 support, and compute the SHA-256 hashed value of your attribute _plus_ your organization's secure attribute salt.\n\n```\nconst salt = \"f09jq3fij\"; // Your organization's secure attribute salt (see Organization Settings)// hashing a secureString attributeconst userEmail = sha256(salt + user.email);// hashing an secureString[] attributeconst userTags = user.tags.map(tag => sha256(salt + tag));gb.setAttributes({  id: user.id,  loggedIn: true,  email: userEmail,  tags: userTags,});await gb.init();// In this example, we are using Node.js's built-in crypto libraryfunction sha256(str) {  return crypto.createHash(\"sha256\").update(str).digest(\"hex\");}\n```\n\nNote that in a browser context, we will not be able to natively access the Node.js crypto library. In modern browsers `window.crypto.subtle` is available, although calls are asynchronous. You would need to await all attribute hashing to complete before calling `gb.setAttributes()`.\n\n```\nasync function sha256(str) {  const buffer = await crypto.subtle.digest(\"SHA-256\", new TextEncoder().encode(str));  const hashArray = Array.from(new Uint8Array(buffer));  return hashArray.map(byte => byte.toString(16).padStart(2, \"0\")).join(\"\");}\n```\n\nAlternatively, CryptoJS ([https://www.npmjs.com/package/crypto-js](https://www.npmjs.com/package/crypto-js)) provides a synchronous API:\n\n```\nimport sha256 from 'crypto-js/sha256';const userEmail = sha256(salt + user.email);\n```\n\n### Feature Usage Callback[​](#feature-usage-callback \"Direct link to Feature Usage Callback\")\n\nGrowthBook can fire a callback whenever a feature is evaluated for a user. This can be useful to update 3rd party tools like NewRelic or DataDog.\n\n```\nnew GrowthBook({  onFeatureUsage: (featureKey, result) => {    console.log(\"feature\", featureKey, \"has value\", result.value);  },});\n```\n\nNote: If you evaluate the same feature multiple times (and the value doesn't change), the callback will only be fired the first time.\n\n### Dev Mode[​](#dev-mode \"Direct link to Dev Mode\")\n\nThere is a [GrowthBook Chrome DevTools Extension](https://chrome.google.com/webstore/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia) that can help you debug and test your feature flags in development.\n\nIn order for this to work, you must explicitly enable dev mode when creating your GrowthBook instance:\n\n```\nconst gb = new GrowthBook({  enableDevMode: true,});\n```\n\nTo avoid exposing all of your internal feature flags and experiments to users, we recommend setting this to `false` in production in most cases.\n\n### Inline Experiments[​](#inline-experiments \"Direct link to Inline Experiments\")\n\nDepending on how you configure feature flags, they may run A/B tests behind the scenes to determine which value gets assigned to the user.\n\nSometimes though, you want to run an inline experiment without going through a feature flag first. For this, you can use either the `useExperiment` hook or the Higher Order Component `withRunExperiment`:\n\nView the [Javascript SDK Docs](https://docs.growthbook.io/lib/js) for all of the options available for inline experiments\n\n#### useExperiment hook[​](#useexperiment-hook \"Direct link to useExperiment hook\")\n\n```\nimport { useExperiment } from \"@growthbook/growthbook-react\";export default function OtherComponent() {  const { value } = useExperiment({    key: \"new-headline\",    variations: [\"Hello\", \"Hi\", \"Good Day\"]  });  return <h1>{value}</h1>;}\n```\n\n#### withRunExperiment (class components)[​](#withrunexperiment-class-components \"Direct link to withRunExperiment (class components)\")\n\n**Note:** This library uses hooks internally, so still requires React 16.8 or above.\n\n```\nimport { withRunExperiment } from \"@growthbook/growthbook-react\";class OtherComponent extends React.Component {  render() {    // The `runExperiment` prop is identical to the `useExperiment` hook    const { value } = this.props.runExperiment({      key: \"headline-test\",      variations: [\"Hello World\", \"Hola Mundo\"]    });    return <h1>{value}</h1>;  }}// Wrap your component in `withRunExperiment`export default withRunExperiment(OtherComponent);\n```\n\n## TypeScript support[​](#typescript-support \"Direct link to TypeScript support\")\n\nSome hooks are available in type-safe versions. These require you to pass in your generated types as the generic argument.\n\nSee the [GrowthBook CLI](https://docs.growthbook.io/tools/cli) documentation for more information on generating type definitions and [JavaScript → TypeScript → Scrict Typing](https://docs.growthbook.io/lib/js#strict-typing) for how to use them.\n\n### useGrowthBook<T>()[​](#usegrowthbookt \"Direct link to useGrowthBook<T>()\")\n\nA type-safe version of the `useGrowthBook()` hook is available. Everywhere you use `useGrowthBook()`, pass the generated features as the generic argument:\n\n```\nconst growthbook = useGrowthBook<AppFeatures>()\n```\n\nIn that case, the hook will return `GrowthBook<AppFeatures> | undefined`.\n\nYou can reduce this boilerplate by creating your own hook, e.g.:\n\n```\n// ./src/utils/growthbook.tsimport { useGrowthBook as _useGrowthBook } from \"@growthbook/growthbook-react\";export const useGrowthBook = (): GrowthBook<AppFeatures> | undefined =>  _useGrowthBook<AppFeatures>();\n```\n\nYou can now reference the hook you created instead of the one from the official package:\n\n```\nimport { useGrowthBook } from \"@/src/utils/growthbook\"const growthbook = useGrowthBook();growthbook.getFeatureValue(knownKey, defaultValueOfValidType)\n```\n\n### useFeatureIsOn<T>()[​](#usefeatureisont \"Direct link to useFeatureIsOn<T>()\")\n\nThe React SDK also provides access to a type-safe `useFeatureIsOn<AppFeatures>()` hook.\n\n```\nconst isDarkModeOn = useFeatureIsOn<AppFeatures>(\"dark_mode\");\n```\n\nThis will only allow you to pass known keys to the hook.\n\nYou can reduce the boilerplate for this hook by creating your own and using that instead:\n\n```\n// ./src/utils/growthbook.tsimport { useFeatureIsOn as _useFeatureIsOn } from \"@growthbook/growthbook-react\";export const useFeatureIsOn = (id: keyof AppFeatures & string): boolean =>  _useFeatureIsOn<AppFeatures>(id);\n```\n\nAnd then reference the hook you created instead of the one from the official package:\n\n```\nimport { useFeatureIsOn } from \"@/src/utils/growthbook\"const isDarkModeOn = useFeatureIsOn(\"dark_mode\");\n```\n\n## Examples[​](#examples \"Direct link to Examples\")\n\n*   [React Native](https://github.com/growthbook/examples/tree/main/react-native-cli)\n*   [Typescript example app with strict typing](https://github.com/growthbook/examples/tree/main/vanilla-typescript) .",
  "title": "React Native SDK | GrowthBook Docs",
  "description": "GrowthBook SDK for React Native",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/guide/google-tag-manager-and-growthbook",
  "markdown": "# GrowthBook and Google Tag Manager\n\n## Using GrowthBook with Google Tag Manager (GTM)\n\nNow customers who are familiar with feature management using Google Tag Manager (GTM), yet may lack the engineering resources or capability to implement changes in their codebase, may easily use GrowthBook with GTM to power their AB tests. This setup is commonly used by marketing teams and CRO agencies.\n\nnote\n\nGrowthBook also offers a [visual editor](https://docs.growthbook.io/app/visual) for lightweight, no-code UI changes. This approach is compatible with GTM and the examples provided on this page as long you enable the \"Include Visual Experiments\" toggle within your SDK Connection.\n\nIn this guide, we will assume familiarity with the GTM platform.\n\n## Create an SDK Connection within GrowthBook[​](#create-an-sdk-connection-within-growthbook \"Direct link to Create an SDK Connection within GrowthBook\")\n\nFirst, you need to add a new SDK Connection within GrowthBook. Choose the \"Generic HTML\" option when setting this up.\n\nAfter you create the connection, you will be shown a script tag that contains your unique client id. Copy this script tag since you will need it for the following step.\n\n## Creating a GTM tag for the GrowthBook SDK[​](#creating-a-gtm-tag-for-the-growthbook-sdk \"Direct link to Creating a GTM tag for the GrowthBook SDK\")\n\nNext, create a new tag in your desired GTM workspace. We will choose \"Custom HTML\" as the tag type. We can give it the name \"GrowthBook SDK\" or similar. Also, be sure to set the firing triggers to target the specific pages where we need to instrument our feature changes and experiments (or just choose \"All Pages\").\n\nPaste in the script tag from your SDK Connection in the previous step. It will look something like the following. Refer to our [Script Tag SDK docs](https://docs.growthbook.io/lib/script-tag) for more info.\n\n```\n<script async  data-client-key=\"YOUR_CLIENT_KEY_HERE\"  src=\"https://cdn.jsdelivr.net/npm/@growthbook/growthbook/dist/bundles/auto.min.js\"></script>\n```\n\nTo publish the SDK tag, submit our workspace changes (the blue \"Submit\" button on the top of the GTM application), Then ensure \"Publish and Create version\" is selected and click the blue \"Publish\" button – or use whichever GTM release strategy you are already using.\n\n### Use Feature Flags[​](#use-feature-flags \"Direct link to Use Feature Flags\")\n\nThis step is optional. If you are planning to mainly use the Visual Editor to implement experiments, you can skip ahead to the next section.\n\nTo use feature flags, create another \"Custom HTML\" tag in your workspace, with a name like \"GrowthBook Feature Flags\" and set the firing trigger to the page you want to run this on.\n\nYou can use the following example as a starting point:\n\n```\n<script>// Wait for the GrowthBook SDK to load before runningwindow.growthbook_queue = window.growthbook_queue || [];window.growthbook_queue.push((gb) => {  // Function that uses feature flags to make changes to the page  const applyFeatureFlags = () => {    if(gb.isOn(\"dark-mode\")) {      document.documentElement.classList.add(\"dark\");    } else {      document.documentElement.classList.remove(\"dark\");    }  }  // Call your function initially plus whenever new data is received  applyFeatureFlags();  document.addEventListener(\"growthbookdata\", applyFeatureFlags)});</script>\n```\n\nThe above example shows using a single feature flag called `dark-mode` and using it to modify the class name of the `<html>` element. Replace the contents of the `applyFeatureFlags` function with your own logic.\n\nYou can add multiple tags like this if needed, each with their own triggering logic.\n\n## Tracking via DataLayer and GTM[​](#tracking-via-datalayer-and-gtm \"Direct link to Tracking via DataLayer and GTM\")\n\nThe GrowthBook SDK implementation above will send an event to the DataLayer that looks like the following whenever the user views an experiment:\n\n```\n{  \"event\": \"experiment_viewed\",  \"experiment_id\": \"...\",  \"variation_id\": \"...\"}\n```\n\nThis event can be forwarded on to your analytics tool of choice. The following steps show an example of sending this to Google Analytics v4:\n\n### Step 1: Add a new Tag[​](#step-1-add-a-new-tag \"Direct link to Step 1: Add a new Tag\")\n\n![Step 1](https://docs.growthbook.io/assets/images/gtm-ga4-1-05aa43364639866da51c77ac6e6771dc.png)\n\nClick “Tag Configuration”\n\n![Step 2](https://docs.growthbook.io/assets/images/gtm-ga4-2-33339325678729ffcc0cc167fe3d2d09.png)\n\nChoose “Google Analytics”\n\n![Step 3](https://docs.growthbook.io/assets/images/gtm-ga4-3-9631f8842cba811b4bb4ba883f8b0a91.png)\n\nThen, choose “Google Analytics: GA4 Event”\n\n### Step 2: Start Configuring the Tag[​](#step-2-start-configuring-the-tag \"Direct link to Step 2: Start Configuring the Tag\")\n\nYou will be presented with the following screen:\n\n![Step 4](https://docs.growthbook.io/assets/images/gtm-ga4-4-ec1a2cf39654b39560ab70ecda10f8a7.png)\n\nFill out the following fields:\n\n*   Measurement ID: Your GA4 measurement id (find it in the GA4 admin settings)\n*   Event Name: `experiment_viewed`\n\nAlso, add 2 parameters, but only fill out the name. Leave the value empty for now\n\n*   `experiment_id`\n*   `variation_id`\n\n![Step 5](https://docs.growthbook.io/assets/images/gtm-ga4-5-32620e5ce17e49aa3a55b2cd9bb233f4.png)\n\n### Step 3: Add Variables for Experiment and Variation Ids[​](#step-3-add-variables-for-experiment-and-variation-ids \"Direct link to Step 3: Add Variables for Experiment and Variation Ids\")\n\nThese steps will be repeated for both the `experiment_id` and `variation_id` parameters. We will start with `experiment_id`:\n\nClick the \\[+\\] icon in the Value input for `experiment_id`\n\n![Step 6](https://docs.growthbook.io/assets/images/gtm-ga4-6-b85155eab51a16f4341d92742dcc8b0c.png)\n\nClick the blue “+” in the top right corner to add a new variable\n\n![Step 7](https://docs.growthbook.io/assets/images/gtm-ga4-7-02d6add5cf27a2255644bcd7dd53bb6c.png)\n\nClick on “Variable Configuration”:\n\n![Step 8](https://docs.growthbook.io/assets/images/gtm-ga4-8-4f3840fb5143698a6e12d36083a9ef51.png)\n\nSelect “Data Layer Variable” and enter `experiment_id` as the Data Layer Variable Name.\n\nAlso, add a descriptive name for your variable in the top left where it says “Untitled Variable” (”Experiment Id” shown below)\n\n![Step 9](https://docs.growthbook.io/assets/images/gtm-ga4-9-5cd9d6e4cb31696fdf54f2067cb617fe.png)\n\nClick the blue “Save” button.\n\n**Repeat the above steps for the `variation_id` variable**\n\n### Step 4: Add a Trigger[​](#step-4-add-a-trigger \"Direct link to Step 4: Add a Trigger\")\n\nYou should be left with the following configuration. Add a descriptive name in the top left for your tag if you haven’t already - “GA4 - Experiment Viewed Event” shown here.\n\n![Step 10](https://docs.growthbook.io/assets/images/gtm-ga4-10-f662adc8e4b2ea3be364654a4a97ab2d.png)\n\nClick the “Triggering” section\n\n![Step 11](https://docs.growthbook.io/assets/images/gtm-ga4-11-fd03868049ce6ce93b63b71a05a37097.png)\n\nClick the blue “+” in the top right to add a new trigger. Enter a descriptive name in the top left (”Experiment Viewed Event” shown here)\n\n![Step 12](https://docs.growthbook.io/assets/images/gtm-ga4-12-ffa8eedec38b16fc70a09a6e0025086e.png)\n\nClick “Trigger Configuration”\n\n![Step 13](https://docs.growthbook.io/assets/images/gtm-ga4-13-37a6d1c0ae536d0059aad5cb899236bc.png)\n\nClick “Custom Event”:\n\n![Step 14](https://docs.growthbook.io/assets/images/gtm-ga4-14-f662adc8e4b2ea3be364654a4a97ab2d.png)\n\nEnter `experiment_viewed` as the Event name and click the blue “Save” button.\n\nBelow is the end result of your tag configuration. Click the blue “Save” button to finish.\n\n![Step 15](https://docs.growthbook.io/assets/images/gtm-ga4-15-b4c4ac0de83e85aad0fc91881e4fb61b.png)\n\n### Step 5: Publish Your Changes[​](#step-5-publish-your-changes \"Direct link to Step 5: Publish Your Changes\")\n\nFinally, publish your changes in Google Tag Manager and you’re done!\n\n## Viewing Results[​](#viewing-results \"Direct link to Viewing Results\")\n\nOnce your analytics tool is successfully tracking your experiment events, the next step is to connect GrowthBook to your data warehouse and view results.\n\nIf you are using Google Analytics v4, we have a dedicated guide for [Connecting GrowthBook to GA4 with BigQuery](https://docs.growthbook.io/guide/GA4-google-analytics).\n\nFor other analytics tools, refer to our general guide on [Connecting to your Data Warehouse](https://docs.growthbook.io/warehouses).",
  "title": "GrowthBook and Google Tag Manager | GrowthBook Docs",
  "description": "This guide walks you through using GrowthBook with Google Tag Manager (GTM) to track your experiments and measure their impact on your business.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/edge/fastly",
  "markdown": "# Fastly Compute Edge App & SDK\n\n## Overview[​](#overview \"Direct link to Overview\")\n\nGrowthBook currently supports two levels of integration with most edge workers, including Fastly:\n\n1.  Our turnkey Edge App\n    \n    *   Automatically run server-side or hybrid [Visual Experiments](https://docs.growthbook.io/app/visual) without redraw flicker.\n    *   Automatically run server-side or hybrid [URL Redirect Experiments](https://docs.growthbook.io/app/url-redirects) without flicker or delay.\n    *   Optionally inject the JavaScript SDK with hydrated payload, allowing the front-end to pick up where the edge left off without any extra network requests. We use an enhanced version of our [HTML Script Tag](https://docs.growthbook.io/lib/script-tag) for this purpose.\n2.  Support for edge apps using our JavaScript SDK\n    \n    *   Enhanced support and examples for using our JavaScript SDK in an edge environment\n\nRegardless of your use case, our Fastly integration makes easy to synchronize feature and experiment values between GrowthBook and Fastly's KV store. This eliminates the network request to the GrowthBook API, unlocking blazingly fast edge-side and client-side SDK performance.\n\n## References[​](#references \"Direct link to References\")\n\n*   Our Fastly Compute SDK repository, which supports the above use cases, is [here](https://github.com/growthbook/growthbook-proxy/tree/main/packages/lib/edge-fastly)\n*   A turnkey implementation of the Edge App (compatible with Viceroy) is [here](https://github.com/growthbook/growthbook-proxy/tree/main/packages/lib/edge-fastly/example)\n*   You may find it useful to review our [JavaScript SDK](https://docs.growthbook.io/lib/js). Many of the concepts which apply to both on-edge and injected frontend SDKs are based on our JS SDK.\n\n## Worker Configuration[​](#worker-configuration \"Direct link to Worker Configuration\")\n\ntip\n\nThis tutorial assumes some familiarity with building and deploying Fastly Compute applications. You can quickly get up to speed by following the Fastly Compute [Developer guide](https://www.fastly.com/documentation/guides/compute/) .\n\nYou may either use our turnkey Edge App for Fastly Compute or build your own app from scratch using our JavaScript and Fastly SDKs.\n\n## Turnkey Edge App[​](#turnkey-edge-app \"Direct link to Turnkey Edge App\")\n\nOur Edge App runs as a smart proxy layer between your application and your end users. In absence of Visual or URL Redirect experiments, the Edge App will simply proxy the user request to your site and return the response, optionally injecting a fully-bootstrapped JavaScript SDK onto the rendered HTML page. If the request URL matches an Visual or URL Redirect experiment and the targeting conditions are satisfied, the Edge App may also perform one or more URL redirects behind the scenes (the public-facing URL does not change) and/or mutate the DOM for Visual Experiments.\n\nURL Redirects on edge\n\nThe Edge App defaults to running URL Redirect Experiments in the browser only. This is because edge redirects load a separate page's content without altering the URL. After the redirect, some sites may experience problems with loading assets or endpoints with relative paths.\n\nYou can enable URL Redirects on edge by setting environment variable `RUN_URL_REDIRECT_EXPERIMENTS` ([see below](#environment-variables)).\n\n  \n\nVisual Experiments and CPU\n\nBy default, Fastly allows 50ms of CPU time per request. When running Visual Experiments on edge with Fastly, it is common to see CPU time exceed the allotted 50ms. If your responses exceed 50ms and you receive a **503** error, you have a few options:\n\n1.  Upgrade your Fastly Compute account to support longer CPU time.\n2.  Or set the environment variable `RUN_VISUAL_EDITOR_EXPERIMENTS=\"browser\"`. Users will still receive a flicker-free experience because the bootstrapped SDK and DOM mutations are injected into the page `<head>` and triggered immediately on page load.\n\nSetting up our turnkey Edge App is simple. Assuming that you have a basic Fastly Compute service set up, simply install the SDK and implement our custom request handler. Or if you prefer, you may pull down our fully-functional [example implementation](https://github.com/growthbook/growthbook-proxy/tree/main/packages/lib/edge-fastly/example) and follow along.\n\n### Install the SDK[​](#install-the-sdk \"Direct link to Install the SDK\")\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save @growthbook/edge-fastly\n```\n\n### Implement the Edge App request handler[​](#implement-the-edge-app-request-handler \"Direct link to Implement the Edge App request handler\")\n\nA basic implementation of our Edge App only requires a few lines of code:\n\n```\n/// <reference types=\"@fastly/js-compute\" />import { ConfigStore } from \"fastly:config-store\";import { gbHandleRequest, getConfigEnvFromStore } from \"@growthbook/edge-fastly\";addEventListener(\"fetch\", (event) => event.respondWith(handleRequest(event)));async function handleRequest(event) {  const envVarsStore = new ConfigStore(\"env_vars\");  const env = getConfigEnvFromStore(envVarsStore);  const config = {    apiHostBackend: \"api_host\",  // Name of Fastly backend pointing to your GrowthBook API Endpoint    backends: { \"https://internal.mysite.io\": \"my_site\" },  // Map of proxy origins to named Fastly backends  };  return await gbHandleRequest(event.request, env, config);}\n```\n\nNotice a few references to backends. We will define these in the Fastly Dashboard in the subsequent doc section.\n\n### Set up backends (origins)[​](#set-up-backends-origins \"Direct link to Set up backends (origins)\")\n\nUnless your have requested open proxy behavior on your Fastly account, Fastly requires that you define backends for each origin server that your Compute application fetches from. In order to use our Edge app, you will need to create a backend for your GrowthBook API Host (which we'll call `api_host`), and one or more backends for your origin site using the Fastly dashboard (called \"Origins\" in your Compute service configuration).\n\nEach backend is defined as an _origin_ URL. Example: `https://internal.mysite.io` or `https://internal.mobile.mysite.io`; but not full URLs like `https//internal.mysite.io/features/widget`.\n\n*   In Fastly, create a backend called `api_host` pointing to your GrowthBook API Host. For GrowthBook Cloud customers, this will be `https://cdn.growthbook.io`. Link this backend to your Compute service.\n*   In Fastly, create one or more backends pointing to your site origins. This includes both your main site origin URL as well as any origin URLs that you may redirect to in any URL Redirect experiments. Link these backends to your Compute service.\n\nIn your request handler, you must pass these backends via the **config** parameter, as shown in the example code in the [previous doc section](#implement-the-edge-app-request-handler).\n\n*   The API Host backend should be set via `config.apiHostBackend = \"api_host\"`.\n*   The site origin backends are defined as an object mapping each origin URL to its corresponding backend name. They should be set via `config.backends = { \"https://internal.mysite.io\": \"my_site\" }`.\n\n### Configure the Edge App[​](#configure-the-edge-app \"Direct link to Configure the Edge App\")\n\nUse a combination of environment variables and optional runtime configuration to add required fields and to customize the Edge App behavior.\n\n#### Environment variables[​](#environment-variables \"Direct link to Environment variables\")\n\nWe suggest using a [Fastly Config store](https://docs.fastly.com/en/guides/working-with-config-stores) to set your environment variables. Create a Config store called `env_vars` from the Fastly dashboard and link it to your Compute service. Then, at minimum, add these required key/value pairs:\n\n```\nPROXY_TARGET=\"https://internal.mysite.io\"  # The non-edge URL to your websiteGROWTHBOOK_API_HOST=\"https://cdn.growthbook.io\"GROWTHBOOK_CLIENT_KEY=\"sdk-abc123\"GROWTHBOOK_DECRYPTION_KEY=\"key_abc123\"  # Only include for encrypted SDK Connections\n```\n\nYou may want to further customize the app. Here is a list of common customization variables:\n\n```\n# Disable or change the rendering behavior of Visual Experiments:# ==========RUN_VISUAL_EDITOR_EXPERIMENTS=\"everywhere\"|\"edge\"|\"browser\"|\"skip\"  # default: \"everywhere\"# URL Redirect Experiments are disabled on edge by default. Because the URL does not change, some sites# may experience problems with loading assets or endpoints with relative paths:# ==========RUN_URL_REDIRECT_EXPERIMENTS=\"everywhere\"|\"edge\"|\"browser\"|\"skip\"  # default: \"browser\"RUN_CROSS_ORIGIN_URL_REDIRECT_EXPERIMENTS=\"everywhere\"|\"edge\"|\"browser\"|\"skip\"  # default: \"browser\"# Mutate browser URL via window.history.replaceState() to reflect the new URL:INJECT_REDIRECT_URL_SCRIPT=\"true\"  # default \"true\".# Do not inject a bootstrapped JavaScript SDK onto the page:# ==========DISABLE_INJECTIONS=\"true\"  # default \"false\"# Customize the edge or injected browser SDK behavior:# ==========ENABLE_STREAMING=\"true\"  # default \"false\". Streaming SSE updates on browser.ENABLE_STICKY_BUCKETING=\"true\"  # default \"false\". Use cookie-based sticky bucketing on edge and browser.\n```\n\n#### Runtime configuration[​](#runtime-configuration \"Direct link to Runtime configuration\")\n\nYou may want to provide context to your edge app at runtime rather than using environment variables. For example, if you have additional [targeting attributes](https://docs.growthbook.io/lib/js#attributes) available, you may inject them by modifying your request handler code:\n\n```\n/// <reference types=\"@fastly/js-compute\" />import { ConfigStore } from \"fastly:config-store\";import { gbHandleRequest, getConfigEnvFromStore } from \"@growthbook/edge-fastly\";addEventListener(\"fetch\", (event) => event.respondWith(handleRequest(event)));async function handleRequest(event) {  const envVarsStore = new ConfigStore(\"env_vars\");  const env = getConfigEnvFromStore(envVarsStore);  const cookie = parse(event.request.headers.get(\"Cookie\") || \"\");  const config = {    // custom targeting attributes:    attributes: {      userType: cookie[\"userId\"] ? \"logged in\" : \"anonymous\"    },    // backends:    apiHostBackend: \"api_host\",  // Name of Fastly backend pointing to your GrowthBook API Endpoint    backends: { \"https://internal.mysite.io\": \"my_site\" },  // Map of proxy origins to named Fastly backends  };  return await gbHandleRequest(event.request, env, config);}\n```\n\n#### More customization options[​](#more-customization-options \"Direct link to More customization options\")\n\nFor a full list of customizations, view our vendor-agnostic [Edge Utility repository](https://github.com/growthbook/growthbook-proxy/tree/main/packages/lib/edge-utils) .\n\n### Set up a Payload Cache[​](#set-up-a-payload-cache \"Direct link to Set up a Payload Cache\")\n\nYou can configure GrowthBook payload caching by using a [Fastly KV](https://docs.fastly.com/en/guides/working-with-kv-stores) store. This eliminates network requests from your edge to GrowthBook which speeds up page delivery while reducing network costs.\n\nYou may configure the Fastly Edge App to use either webhook-based or just-in-time payload caching (or both) depending on how you've set up your KV namespaces and SDK Webhooks.\n\nMore information about setting up your payload cache can be found in the [Payload Caching with Fastly KV Store](#payload-caching-with-fastly-kv-store) doc section below.\n\n### Tracking Experiment Views[​](#tracking-experiment-views \"Direct link to Tracking Experiment Views\")\n\nRunning A/B tests requires a [tracking callback](https://docs.growthbook.io/lib/js#experimentation-ab-testing). Our turnkey Edge App defaults to using built-in front-end tracking. The tracking call automatically integrates with Segment.io, GA4, and Google Tag Manager by using the mechanism outlined in our [HTML Script Tag](https://docs.growthbook.io/lib/script-tag#tracking-experiment-views). In order to do this, the app keeps track of tracking calls triggered on edge and injects them into the front-end SDK to be automatically triggered on page load.\n\nYou may wish to either customize front-end tracking or switch to edge tracking (or use both concurrently if running hybrid edge + front-end experiments).\n\nWhy might you be interested in tracking on edge? Tracking on an edge or backend environment allows you to ensure the callback is fired before any differentiation across variations, eliminating experimental bias. While not eliminating this risk, the default injected front-end tracking introduced by our Edge App does reduce this risk relative to solely using a front-end SDK.\n\nTo change the front-end tracking callback, set the `GROWTHBOOK_TRACKING_CALLBACK` to your custom tracking JS code:\n\n```\n# todo: replace with your own tracking libraryGROWTHBOOK_TRACKING_CALLBACK=\"(experiment, results) => { console.log('browser tracking callback', {experiment, results}); }\"\n```\n\nTo track on edge, you must inject your own tracking callback into the edge request handler code. Any experiments that run on edge will use the edge tracking callback and not the front-end callback (hybrid edge + front-end experiments being an exception):\n\n```\n/// <reference types=\"@fastly/js-compute\" />import { ConfigStore } from \"fastly:config-store\";import { gbHandleRequest, getConfigEnvFromStore } from \"@growthbook/edge-fastly\";addEventListener(\"fetch\", (event) => event.respondWith(handleRequest(event)));async function handleRequest(event) {  const envVarsStore = new ConfigStore(\"env_vars\");  const env = getConfigEnvFromStore(envVarsStore);  const config = {    edgeTrackingCallback: (experiment, results) => {      // todo: replace with your tracking library      console.log('edge tracking callback', {experiment, results});    },    // backends:    apiHostBackend: \"api_host\",  // Name of Fastly backend pointing to your GrowthBook API Endpoint    backends: { \"https://internal.mysite.io\": \"my_site\" },  // Map of proxy origins to named Fastly backends  };  return await gbHandleRequest(event.request, env, config);}\n```\n\n### Targeting Attributes[​](#targeting-attributes \"Direct link to Targeting Attributes\")\n\nThe following targeting attributes are set automatically by the Edge App.\n\n*   `id` - creates a long-lived `gbuuid` cookie if it doesn't exist already\n*   `url`\n*   `path`\n*   `host`\n*   `query`\n*   `pageTitle`\n*   `deviceType` - either `mobile` or `desktop`\n*   `browser` - one of `chrome`, `edge`, `firefox`, `safari`, or `unknown`\n*   `utmSource`\n*   `utmMedium`\n*   `utmCampaign`\n*   `utmTerm`\n*   `utmContent`\n\nYou can customize both the primary identifier name (`id`) and cookie name (`gbuuid`) by setting the `UUID_KEY` and `UUID_COOKIE_NAME` environment variables respectively.\n\nAs shown in the [runtime configuration](#runtime-configuration) section above, you can also pass custom attributes via runtime config. You can also skip automatic attribute generation and rely solely on custom attributes by setting the environment variable `SKIP_AUTO_ATTRIBUTES=\"true\"`.\n\n### Routing[​](#routing \"Direct link to Routing\")\n\nBy default, the Edge App will process all `GET` requests (other HTTP verbs are proxied through without running through our app logic).\n\nThere may be situations when you will need to provide fine-grained routing / URL targeting rules within our Edge App. You will need to include a JSON encoded string of route rules in your `ROUTES` environment variable.\n\nFor instance, you may want to do a proxy pass-through (do not process) for `mysite.io/account/*` or `mysite.io/settings/*`. Your routes may look like this:\n\n```\nROUTES='[{ \"pattern\":\"mysite.io/account/*\", \"behavior\":\"proxy\" }, { \"pattern\":\"mysite.io/settings/*\", \"behavior\":\"proxy\" }]'\n```\n\nA route uses the following interface, with many of the properties being optional:\n\n```\n{  pattern: string;  type?: \"regex\" | \"simple\";  // default: \"simple\"  behavior?: \"intercept\" | \"proxy\" | \"error\";  // default: \"intercept\"  includeFileExtensions?: boolean;  // Include requests to filenames like \"*.jpg\". default: false (pass-through).  statusCode?: number; // Alter the status code (default is 404 when using \"error\")  body?: string; // Alter the body (for setting an error message body)}\n```\n\nWhen multiple routes are included in your `ROUTES` array, only the first match is used.\n\n### Cookie Policy and GDPR[​](#cookie-policy-and-gdpr \"Direct link to Cookie Policy and GDPR\")\n\nBy default, the Edge App will persist a random unique identifier in a first-party cookie named `gbuuid`. Its purpose is to provide a consistent user experience to your visitors by preventing them from being re-bucketed into different A/B test variations. It follows the same mechanism as discussed in our [HTML Script Tag docs](https://docs.growthbook.io/lib/script-tag#cookie-policy-and-gdpr).\n\n#### Delay Storing the Cookie Until Consent is Granted[​](#delay-storing-the-cookie-until-consent-is-granted \"Direct link to Delay Storing the Cookie Until Consent is Granted\")\n\nIf you must delay persisting the `gbuuid` cookie until a user consents, you can set the environment variable `NO_AUTO_COOKIES=\"true\"`.\n\nThis will still generate a UUID for the user, but will not persist it. That means, if the user refreshes the page, they will have a new random UUID generated.environment\n\nYou have the option to manually persist this cookie at any time, for example when a user grants consent on your cookie banner. All you need to do is fire this custom event from javascript on the rendered page:\n\n```\ndocument.dispatchEvent(new CustomEvent(\"growthbookpersist\"));\n```\n\nnote\n\nIf you are using Sticky Bucketing, a persistent sticky bucket assignments cookie will automatically be generated. If you require user permission before writing cookies, you should:\n\n*   Either do not enable Sticky Bucketing on edge (do not use `ENABLE_STICKY_BUCKETING`)\n*   Or only enable Sticky Bucketing per each user via runtime configuration. (only pass `config.enableStickyBucketing: true` if user has consented — identifiable by checking for presence of the `gbuuid` cookie).\n\n## Manual SDK Integration on Edge[​](#manual-sdk-integration-on-edge \"Direct link to Manual SDK Integration on Edge\")\n\nYou may be interested in building your own edge application using the GrowthBook SDK and not using our turnkey Edge App. Or you may want to do custom feature flagging on specific routes while running our Edge App on other routes.\n\nTo use the GrowthBook on edge, simply include our standard [JavaScript SDK](https://docs.growthbook.io/lib/js) (`@growthbook/growthbook` NPM package). You will likely need to monkey-patch our SDK's built-in fetch calls in order to specify a Fastly backend.\n\nIn our `@growthbook/edge-fastly` NPM package, we export a few Fastly-specific utility functions to simplify SDK payload caching (we discuss payload caching strategies in the subsequent doc section).\n\n```\n/// <reference types=\"@fastly/js-compute\" />import { KVStore } from \"fastly:kv-store\";import { GrowthBook, setPolyfills, helpers } from \"@growthbook/growthbook\";import { getPayloadFromKV, getKVLocalStoragePolyfill } from \"@growthbook/edge-fastly\";addEventListener(\"fetch\", (event) => event.respondWith(handleRequest(event)));async function handleRequest(event) {  // 1. Monkey-patch the GrowthBook SDK to support Fastly backends  helpers.fetchFeaturesCall = ({ host, clientKey, headers }) => fetch(    `${host}/api/features/${clientKey}`,    { headers, backend: config.apiHostBackend }  );  // 2. Init the GrowthBook SDK and choose an optional caching strategy  // A. Use the KV as a managed payload store to eliminate SDK requests to the GrowthBook API entirely.  // Requires setting up an SDK Webhook.  const payloadKVStore = new KVStore(\"gb_payload\");  const payload = await getPayloadFromKV(payloadKVStore);  const growthbook = new GrowthBook(gbContext);  await growthbook.init({ payload: payload });  // B. Or provide a KV cache layer so that the GrowthBook SDK doesn't need to make as many requests  // to the GrowthBook API. No SDK Webhook needed.  const cacheKVStore = new KVStore(\"gb_cache\");  const localStoragePolyfill = getKVLocalStoragePolyfill(cacheKVStore);  setPolyfills({ localStorage: localStoragePolyfill });  await growthbook.init();  // 3. Start feature flagging  if (growthbook.isOn(\"my-feature\")) {    return new Response(\"<h1>foo</h1>\");  }  return new Response(\"<h1>bar</h1>\");}\n```\n\n## Payload Caching with Fastly KV Store[​](#payload-caching-with-fastly-kv-store \"Direct link to Payload Caching with Fastly KV Store\")\n\nBy default, the Edge App will make a network request to the GrowthBook API on each user request in order to fetch the current feature and experiment values. This is a blocking call that delays page delivery. There is an in-memory short-lived cache layer on this call, but it won't always protect you.\n\nConvenient solutions this problem are realized through [Fastly KV](https://docs.fastly.com/en/guides/working-with-kv-stores) , an on-edge key-val store which we can leverage for persistent payload caching. There are 2 levels of KV integration available:\n\n1.  You can either completely eliminate the blocking call to the GrowthBook API by implementing a GrowthBook-to-Fastly-KV push model via **SDK Webhooks**.\n2.  Alternatively, you can eliminate most of these network requests by using Fastly KV as a just-in-time payload cache.\n\nYou can also use either of these strategies in your own manual SDK integration via the `getPayloadFromKV` and `getKVLocalStoragePolyfill` utility functions.\n\n### Configuring the KV store[​](#configuring-the-kv-store \"Direct link to Configuring the KV store\")\n\nCreate a Fastly KV store for your worker to interface with.\n\nUsing the Fastly dashboard, create a Fastly KV store for either push-based or just-in-time payload cache (or use both if you like). By convention, we suggest naming a push-based KV store as `gb_payload` and naming a just-in-time KV store as `gb_cache`. Link your KV store(s) to your Compute service.\n\nIf you are using our turnkey Edge App, you simply need to instantiate your KVStore(s) and pass them into your request handler via the **config** parameter. The Edge App will automatically use these KV stores as persistent cache if present.\n\n```\n/// <reference types=\"@fastly/js-compute\" />import { ConfigStore } from \"fastly:config-store\";import { KVStore } from \"fastly:kv-store\";import { gbHandleRequest, getConfigEnvFromStore } from \"@growthbook/edge-fastly\";addEventListener(\"fetch\", (event) => event.respondWith(handleRequest(event)));async function handleRequest(event) {  const envVarsStore = new ConfigStore(\"env_vars\");  const env = getConfigEnvFromStore(envVarsStore);  const config = {    apiHostBackend: \"api_host\",    backends: { \"https://internal.mysite.io\": \"my_site\" },    gbCacheStore: new KVStore(\"gb_cache\"),  // just-in-time payload cache    gbPayloadStore: new KVStore(\"gb_payload\"),  // push-based payload cache  };  return await gbHandleRequest(event.request, env, config);}\n```\n\n### Configuring a SDK Webhook[​](#configuring-a-sdk-webhook \"Direct link to Configuring a SDK Webhook\")\n\nFor KV stored payloads (1), we eliminate network requests from edge to GrowthBook by using a GrowthBook SDK Webhook to push the SDK payload to the KV store on change.\n\n1.  Create an [SDK Webhook](https://docs.growthbook.io/app/webhooks/sdk-webhooks) on the same SDK Connection that you are using for edge integration. You do not need to worry about the receiving end of the webhook (verifying GrowthBook signatures, etc).\n2.  Set the **Endpoint URL** to the Fastly's REST API endpoint for KV. At the time of writing, it follows this format:\n\n```\nhttps://api.fastly.com/resources/stores/kv/{store_id}/keys/gb_payload\n```\n\n3.  Change the **Method** to `PUT`.\n4.  Add appropriate authorization header:\n\n```\n{  \"Fastly-Key\": \"YOUR_FASTLY_REST_API_TOKEN\"}\n```\n\n5.  Set the **Payload format** to \"SDK Payload only\".\n\nNow whenever feature and experiment values change, your Fastly worker will have immediate access to the latest values. You can also test the webhook by using the \"Test Webhook\" button on the SDK Connection page.",
  "title": "Fastly Compute Edge App & SDK | GrowthBook Docs",
  "description": "GrowthBook SDK for Fastly Compute",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/statistics/power",
  "markdown": "# Power Analysis | GrowthBook Docs\n\nnote\n\nPower analysis is currently in alpha (version 2.9+ required). To enable power analysis, go to your organizational settings, and toggle \"Enable Power Calculator\" in \"Experiment Settings.\" Currently GrowthBook offers only frequentist power analysis. Bayesian power analysis is coming soon.\n\n## What is power analysis?[​](#what-is-power-analysis \"Direct link to What is power analysis?\")\n\nPower analysis helps you estimate required experimental duration. Power is the probability of observing a statistically significant result, given your feature has some effect on your metric.\n\n## When should I run power analysis?[​](#when-should-i-run-power-analysis \"Direct link to When should I run power analysis?\")\n\nYou should run power analysis before your experiment starts, to determine how long you should run your experiment. The longer the experiment runs, the more users are in the experiment (i.e., your sample size increases). Increasing your sample size lowers the uncertainty around your estimate, which makes it likelier you achieve a statistically significant result.\n\n## What is a minimum detectable effect, and how do I interpret it?[​](#what-is-a-minimum-detectable-effect-and-how-do-i-interpret-it \"Direct link to What is a minimum detectable effect, and how do I interpret it?\")\n\nRecall that your relative effect size (which we often refer to as simply the effect size), is the percentage improvement in your metric caused by your feature. For example, suppose that average revenue per customer under control is $100, while under treatment you expect that it will be 102.Thiscorrespondstoa(102\\. This corresponds to a (102-100)/100)/100 = 2% effect size. Effect size is often referred to as lift.\n\nGiven the sample variance of your metric and the sample size, the minimum detectable effect (MDE) is the smallest effect size for which your power will be at least 80%.\n\nGrowthBook includes both power and MDE results to ensure that customers comfortable with either tool can use them to make decisions. The MDE can be thought of as the smallest effect that you will be able to detect most of the time in your experiment. We want to be able to detect subtle changes in metrics, so smaller MDEs are better.\n\nFor example, suppose your MDE is 2%. If you feel like your feature could drive a 2% improvement, then your experiment is high-powered. If you feel like your feature will probably only drive something like .5% improvement (which can still be huge!), then you need to add users to detect this effect.\n\n## How do I run a power analysis?[​](#how-do-i-run-a-power-analysis \"Direct link to How do I run a power analysis?\")\n\n1.  From the GrowthBook home page, click \"Experiments\" on the left tab. In the top right, click \"+ Power Calculation.\"\n2.  Select “New Calculation”.\n3.  On the first page you:\n\n*   Select your metrics (maximum of 5). Currently binomial, count, duration, and revenue metrics are supported, while ratio and quantile metrics are unsupported.\n*   Select your \"Estimated users per week.\" This is the average number of **new** users your experiment will add each week. See [FAQ](#faq) below for a couple of simple estimation approaches.\n*   click \"Next\".\n\n4.  On the second page you:\n\n*   enter the \"Effect Size\" for each metric. Effect size is the percentage improvement in your metric (i.e., the lift) you anticipate your feature will cause. Inputting your effect size can require care - see [here](#how-should-i-pick-my-effect-size).\n*   for binomial metrics, enter the conversion rate.\n*   for other metrics, enter the metric mean and metric standard deviation. These means and standard deviations occur across users in your experimental population.\n*   click \"Next\".\n\n5.  Now you have results! Please see the results interpretation [here](#how-do-i-interpret-power-analysis-results).\n6.  By clicking \"Edit\" in the \"Analysis Settings\" box, you can toggle [sequential testing](https://docs.growthbook.io/statistics/sequential) on and off to compare power. Enabling sequential testing decreases power.\n7.  You can alter the number of variations in your experiment. Increased variations result in smaller sample sizes per variation, resulting in lower power.\n8.  If you want to modify your inputs, click the \"Edit\" button next to \"New Calculation\" in the top right corner.\n\n## How do I interpret power analysis results?[​](#how-do-i-interpret-power-analysis-results \"Direct link to How do I interpret power analysis results?\")\n\nIn this section we run through an example power analysis. After starting power analysis, you will need to select metrics and enter estimated users per week.\n\n![metric and users input](https://docs.growthbook.io/assets/images/power_1-72e0be3502e3404db18b15c46dc40a75.png)\n\nIn our example, we choose a binomial metric (Retention - \\[1, 14) Days) and a revenue metric (Purchases - Total Revenue (72 hour window)). We refer to these metrics as \"retention\" and \"revenue\" respectively going forward. We estimate that 500,000 new users per week visit our website.\n\nYou then input your effect sizes, which are the best guesses for your expected metric improvements due to your feature.\n\n![metric and users input](https://docs.growthbook.io/assets/images/power_2-826f9b68404396d3f40a5acfdf89b17b.png)\n\nWe provide guidance for effect size selection [here](#how-should-i-pick-my-effect-size). For our feature we anticpate a 2% improvement in retention. For retention, the conversion rate is 10%. This 10% number should come from an offline query that measures your conversion rate on your experimental population. We expect a 1% improvement in revenue, which has a mean of 0.10andastandarddeviationof0.10 and a standard deviation of 0.22 (as with conversion rate, the mean and standard deviation come from an offline query that you run on your population). We then submit our data.\n\nNow we can see the results! ![metric and users input](https://docs.growthbook.io/assets/images/power_3-5464a7f63686338e67aa709399b08edd.png)\n\nAt the top of the page is a box called Analysis Settings. The summary here says, \"Run experiment for 4 weeks to achieve 80% power for all metrics.\" This is the most important piece of information from power analysis. If running your experiment for 4 weeks is compatible with your business constraints, costs, and rollout timeframe, then you do not need to dive into the numbers below this statement. If you want to rerun power results with number of variations greater than 2, then click \"# of Variations\" and then click \"Update\". The total traffic divided by number of variations should equal the smallest sample size in the experiment you plan to run. If you want to toggle on or off \"Sequential Testing\", then press the \"Edit\" button and select the appropriate option. Enabling sequential testing reduces power.\n\nBelow \"Analysis Settings\" is \"Calculated Sample Size and Runtime\", which contains the number of weeks (or equivalently the number of users) needed to run your experiment to achieve 80% power by metric. Clicking on a row in the table causes the information in the box to the right to change. We expect 80% power for retention if we run the experiment for 2 weeks. For revenue, we need to run the experiment for 4 weeks to achieve at least 80% power.\n\nBeneath \"Calculated Sample Size and Runtime\" is \"Power Over Time\", which contains power estimates by metric.\n\n![metric and users input](https://docs.growthbook.io/assets/images/power_4-adebe7d2802c8b2dbcab2d2f742825c9.png)\n\nThe columns in Power Over Time correspond to different weeks. For example, in the first week power for retention is 65%. The highlighted column in week 4 is the first week where at least 80% power is achieved for all metrics. As expected, power increases over time, as new users are added to the experiment.\n\nBeneath Power Over Time is Minimum Detectable Effect Over Time.\n\n![metric and users input](https://docs.growthbook.io/assets/images/mde-1c0b304a1a99ddfaba03a2db44f98fcf.png)\n\nMinimum Detectable Effect Over Time is structured the same as Power Over Time, except it contains MDEs rather than power estimates. The Week 1 revenue MDE is 2%. This means that if your true lift is 2%, after 1 week you will have at least 80% chance of observing a statistically significant result. As expected, MDEs decrease over time, as new users are added to the experiment.\n\nIf you see `N/A` in your MDE results, this means that you need to increase your number of weekly users, as the MDE calculation failed.\n\nIt can be helpful to see power estimates at different effect sizes, different estimates of weekly users, etc. To modify your inputs, click the \"Edit\" button next to \"New Calculation\" in the top right corner.\n\n## How should I pick my effect size?[​](#how-should-i-pick-my-effect-size \"Direct link to How should I pick my effect size?\")\n\nSelecting your effect size for power analysis requires careful thought. Your effect size is your anticipated metric lift due to your feature. Obviously you do not have complete information about the true lift, otherwise you would not be running the experiment!\n\nWe advocate running power analysis for multiple effect sizes. The following questions may elicit helpful effect sizes:\n\n1.  What is your best guess for the potential improvement due to your feature? Are there similar historical experiments, or pilot studies, and if so, what were their lifts?\n2.  Suppose your feature is amazing - what do you think the lift would be?\n3.  Suppose your feature impact is smaller than you think - how small could it be?\n\nIdeally your experiment has high power (see [here](#what-is-a-high-powered-experiment)) across a range of effect sizes.\n\n## What is a high-powered experiment?[​](#what-is-a-high-powered-experiment \"Direct link to What is a high-powered experiment?\")\n\nIn clinical trials, the standard is 80%. This means that if you were to run your clinical trial 100 times with different patients and different randomizations each time, then you would observe statistically significant results in at least roughly 80 of those trials. When calculating MDEs, we use this default of 80%.\n\nThat being said, running an experiment with less than 80% power can still help your business. The purpose of an experiment is to learn about your business, not simply to roll out features that achieve statistically significant improvement. The biggest cost to running low-powered experiments is that your results will be noisy. This usually leads to ambiguity in the rollout decision.\n\n## How do I run Bayesian power analysis?[​](#how-do-i-run-bayesian-power-analysis \"Direct link to How do I run Bayesian power analysis?\")\n\nFor Bayesian power analysis, you specify the prior distribution of the treatment effect (see [here](https://docs.growthbook.io/statistics/details#bayesian-engine)) for guidance regarding prior selection). We then estimate Bayesian power, which is the probability that the (1−α)(1 - \\\\alpha) credible interval does not contain 0.\n\nIf your organizational default is Bayesian, then Bayesian will be your default power analysis. You can switch to and from frequentist and Bayesian power calculations by toggling \"Statistics Engine\" under \"Settings\" on the Power Results page.\n\nYour default prior for each metric will be your organizational default. To change a prior for a metric, go to \"Settings\", and make sure that \"Statistics Engine\" is toggled to \"Bayesian.\" Then choose \"Prior Specification\", and update prior means and standard deviations for your metric(s). Remember that these priors are on the relative scale, so a prior mean of 0.1 represents a 10% lift.\n\n## FAQ[​](#faq \"Direct link to FAQ\")\n\nFrequently asked questions:\n\n1.  How do I pick the number for Estimated Users Per Week? If you know your number of daily users, you can multiply that by 7. If traffic varies by day of the week, you may want to do something like (5 \\_ average weekday traffic + 2 \\_ average weekend traffic) / 7.\n2.  How can I increase my experimental power? You can increase experimental power by increasing the number of daily users, perhaps by either expanding your population to new segments, or by including a larger percentage of user traffic in your experiment. Similarly, if you have more than 2 variations, reducing the number of variations increases power.\n3.  What if my experiment is low-powered? Should I still run it? The biggest cost to running a low-powered experiment is that your results will probably be noisy, and you will face ambiguity in your rollout/rollback decision. That being said, you will probably still have learnings from your experiment.\n4.  What does \"N/A\" mean for my MDE result? It means there is no solution for the MDE, given the current number of weekly users, control mean, and control variance. Increase your number of weekly users or reduce your number of treatment variations.\n\n## GrowthBook implementation[​](#growthbook-implementation \"Direct link to GrowthBook implementation\")\n\nFor both Bayesian and frequentist engines, we produce two key estimates:\n\n1.  Power - After running the experiment for a given number of weeks and for a hypothesized effect size, what is the probability of a statistically significant result?\n2.  Minimum Detectable Effect (MDE) - After running an experiment for a given number of weeks, what is the smallest effect that we can detect as statistically significant 80% of the time?\n\nEach engine arrives at these values differently. Below we describe high-level technical details of our implementation. All technical details can be found [here](https://docs.growthbook.io/statistics/power-technical).\n\n### Frequentist implementation[​](#frequentist-implementation \"Direct link to Frequentist implementation\")\n\nBelow we define frequentist power.\n\nDefine:\n\n1.  the false positive rate as α\\\\alpha (GrowthBook default is α\\=0.05\\\\alpha=0.05).\n2.  the critical values Z1−α/2\\=Φ−1(1−α/2)Z\\_{1- \\\\alpha / 2}= \\\\Phi^{-1}(1-\\\\alpha/2) and Z1−α\\=Φ−1(1−α)Z\\_{1-\\\\alpha}= \\\\Phi^{-1}(1-\\\\alpha) where Φ\\\\Phi is the inverse cumulative distribution function of the standard normal distribution.\n\nWe make the following assumptions:\n\n1.  equal sample sizes across control and treatment variations. If unequal sample sizes are used in the experiment, use the smaller of the two sample sizes. This will produce conservative power estimates.\n2.  equal variance across control and treatment variations;\n3.  observations across users are independent and identically distributed; and\n4.  all metrics have finite variance.\n5.  you are running a two-sample t-test. If in practice you use [CUPED](https://docs.growthbook.io/statistics/cuped), your power will be higher. Use CUPED!\n\nFor a 2-sided test (all GrowthBook tests are 2-sided), power is the probability of rejecting the null hypothesis of no effect, given that a nonzero effect exists.  \nMathematically, **frequentist power** equals\n\nπ\\=1−Φ(Z1−α/2−Δσ^Δ)+Φ(Zα/2−Δσ^Δ)\\\\pi = 1 - \\\\Phi\\\\left(Z\\_{1-\\\\alpha/2}-\\\\frac{\\\\Delta}{\\\\hat{\\\\sigma}\\_{\\\\Delta}}\\\\right) + \\\\Phi(Z\\_{\\\\alpha/2} - \\\\frac{\\\\Delta}{\\\\hat{\\\\sigma}\\_{\\\\Delta}}).\n\nThe MDE is the smallest effect size for which nominal power (i.e., 80%) is achieved. In the 2-sided case there is no closed form solution. The **frequentist MDE** is the solution for Δ\\\\Delta when solving for π\\\\pi in the equation below:\n\nπ\\=1−Φ(Z1−α/2−Δσ^Δ).\\\\pi = 1 - \\\\Phi\\\\left(Z\\_{1-\\\\alpha/2}-\\\\frac{\\\\Delta}{\\\\hat{\\\\sigma}\\_{\\\\Delta}}\\\\right).\n\nInverting this equation requires some care, as the uncertainty estimate σ^Δ\\\\hat{\\\\sigma}\\_{\\\\Delta} depends upon Δ\\\\Delta. Details can be found [here](https://docs.growthbook.io/statistics/power-technical).\n\nTo estimate power under [sequential testing](https://docs.growthbook.io/statistics/sequential), we adjust the variance term σ^Δ2\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2} to account for sequential testing, and then input this adjusted variance into our power formula. We assume that you look at the data only once, so our power estimate below is a lower bound for the actual power under sequential testing. Otherwise we would have to make assumptions about the temporal correlation of the data generating process.\n\n### Bayesian implementation[​](#bayesian-implementation \"Direct link to Bayesian implementation\")\n\nFor Bayesian power analysis, we let users specify the prior distribution of the treatment effect (see [here](https://docs.growthbook.io/statistics/details#bayesian-engine) for guidance regarding prior selection). We then estimate Bayesian power, which is the probability that the (1−α)(1 - \\\\alpha) credible interval does not contain 0.\n\nAt GrowthBook, **Bayesian power** is\n\nπ\\=1−Φ(σ^Δ2\\[(1σprior2+1σ^Δ2)1/2Z1−α/2−μpriorσprior2\\]−Δσ^Δ2)+Φ(−σ^Δ2\\[(1σprior2+1σ^Δ2)1/2Z1−α/2−μpriorσprior2\\]−Δσ^Δ2).\\\\begin{align} \\\\begin{split} \\\\pi &= 1-\\\\Phi\\\\left( \\\\frac{ \\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}\\\\left\\[\\\\left(\\\\frac{1}{\\\\sigma\\_{prior}^{2}} + \\\\frac{1}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)^{1/2} Z\\_{1-\\\\alpha/2} - \\\\frac{\\\\mu\\_{prior}}{\\\\sigma\\_{prior}^{2}}\\\\right\\]-\\\\Delta} {\\\\sqrt{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}} \\\\right) \\\\\\\\&+\\\\Phi\\\\left( \\\\frac{ -\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}\\\\left\\[\\\\left(\\\\frac{1}{\\\\sigma\\_{prior}^{2}} + \\\\frac{1}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)^{1/2} Z\\_{1-\\\\alpha/2} - \\\\frac{\\\\mu\\_{prior}}{\\\\sigma\\_{prior}^{2}}\\\\right\\]-\\\\Delta} {\\\\sqrt{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}} \\\\right). \\\\end{split} \\\\end{align}\n\nConstructing the MDE is less straightforward, as MDEs are not well defined in Bayesian literature. We provide MDEs in Bayesian power analysis for customers that are used to conceptualizing MDEs and want to be able to leverage prior information in their analysis. We define the MDE as the minimum value of Δ\\\\Delta such that at least π\\\\pi power is achieved.\n\nThe **Bayesian MDE** is the solution for Δ\\\\Delta when solving for π\\\\pi in Equation 1. To find Δ\\\\Delta, we use a grid search.",
  "title": "Power Analysis | GrowthBook Docs",
  "description": "Power Analysis",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/self-host/env",
  "markdown": "# Environment Variables | GrowthBook Docs\n\nThe default configuration in GrowthBook is optimized for trying things out quickly on a local dev machine. Beyond that, you can customize behavior with Environment Variables.\n\n## Domains and Ports[​](#domains-and-ports \"Direct link to Domains and Ports\")\n\nThis is used to generate links to GrowthBook and enable CORS access to the API.\n\n*   **APP\\_ORIGIN** - default [http://localhost:3000](http://localhost:3000/)\n*   **API\\_HOST** - default [http://localhost:3100](http://localhost:3100/)\n\nIf you want to run GrowthBook on a different host than localhost, you need to add the above environment variables to your `docker-compose.yml` file.\n\n```\ngrowthbook:  ...  environment:    - APP_ORIGIN=http://<my ip>:3000    - API_HOST=http://<my ip>:3100\n```\n\nUnique ports on the same domain\n\nThe back-end and the front-end **must run on unique ports if on the same domain**.\n\nThe front-end has its own set of `/api` routes so currently we do not support running both the API and the front-end on the same port on the same domain.\n\nImportant\n\nIn order for authentication cookies to work correctly, both the app and api domains must be considered the \"same site\". They can be on different subdomains or ports, but the root domain must be the same.\n\n*   **Works:** `gb.example.com` and `gb-api.example.com`\n    \n*   **Breaks:** `gb.frontend.com` and `gb.backend.com`\n    \n\nIf you need to change the ports on your local dev environment (e.g. if `3000` is already being used), you need to update the above variables AND change the port mapping in `docker-compose.yml`:\n\n```\ngrowthbook:  ports:    - \"4000:3000\" # example: use 4000 instead of 3000 for the app    - \"4100:3100\" # example: use 4100 instead of 3100 for the api  ...  environment:    - APP_ORIGIN=http://<my ip or url>:4000    - API_HOST=http://<my ip or url>:4100\n```\n\n### Production Settings[​](#production-settings \"Direct link to Production Settings\")\n\n*   **NODE\\_ENV** - Set to \"production\" to turn on additional optimizations and API request logging\n*   **MONGODB\\_URI** - The full MongoDB connection string. Alternatively you can specify the following environment variables from which we will compose the full connection string like so `mongodb://${MONGODB_USERNAME}:${MONGODB_PASSWORD}@${MONGODB_HOSTNAME}:${MONGODB_PORT}/${MONGODB_DBNAME}${MONGODB_EXTRA_ARGS}`:\n    *   **MONGODB\\_USERNAME** - Username for MongoDB\n    *   **MONGODB\\_PASSWORD** - Password for MongoDB\n    *   **MONGODB\\_HOST** - Host name of MongoDB excluding port, e.g. `some.host.com`\n    *   **MONGODB\\_PORT** - Port to use for MongoDB (defaults to `27017`)\n    *   **MONGODB\\_DBNAME** - Database name of growthbook database (defaults to `growthbook`)\n    *   **MONGODB\\_EXTRA\\_ARGS** - Optional set of extra arguments for MongoDB connection string (defaults to `?authSource=admin`)\n*   **JWT\\_SECRET** - Auth signing key (use a long random string)\n*   **ENCRYPTION\\_KEY** - Data source credential encryption key (use a long random string)\n\nIf you change the `ENCRYPTION_KEY`, you will need to migrate any existing data sources using the following script:\n\n```\n# If you didn't have an ENCRYPTION_KEY before, leave OLD_KEY blank belowdocker-compose run growthbook yarn migrate-encryption-key OLD_KEY\n```\n\nImportant\n\nWhen using GrowthBook in production, it is important to change the\n\n`NODE_ENV` to to \"production\" and change the `JWT_SECRET` to a random string. Using the `production` node environment and the default `JWT_SECRET` will throw an error.\n\n## Email SMTP Settings[​](#email-smtp-settings \"Direct link to Email SMTP Settings\")\n\nThis is required in order to send experiment alerts, team member invites, and reset password emails.\n\n*   **EMAIL\\_ENABLED** (\"true\" or \"false\")\n*   **EMAIL\\_HOST**\n*   **EMAIL\\_PORT**\n*   **EMAIL\\_HOST\\_USER**\n*   **EMAIL\\_HOST\\_PASSWORD**\n*   **EMAIL\\_FROM**\n\n## Google OAuth Settings[​](#google-oauth-settings \"Direct link to Google OAuth Settings\")\n\nOnly required if using Google Analytics as a data source\n\n*   **GOOGLE\\_OAUTH\\_CLIENT\\_ID**\n*   **GOOGLE\\_OAUTH\\_CLIENT\\_SECRET**\n\n## File Uploads[​](#file-uploads \"Direct link to File Uploads\")\n\nThe **UPLOAD\\_METHOD** environment variable controls where to store uploaded files and screenshots. The supported values are `local`, `s3`, and `google-cloud`.\n\n### local[​](#local \"Direct link to local\")\n\nThis is the default value. Uploads are stored in the GrowthBook docker container at `/usr/local/src/app/packages/back-end/uploads`. In production, you should mount a volume here to persist uploads across container restarts.\n\n### s3[​](#s3 \"Direct link to s3\")\n\nStore uploads in an AWS S3 bucket.\n\n*   **S3\\_BUCKET**\n*   **S3\\_REGION** (defaults to `us-east-1`)\n*   **S3\\_DOMAIN** (defaults to `https://${S3_BUCKET}.s3.amazonaws.com/`)\n*   **AWS\\_ACCESS\\_KEY\\_ID** (not required when deployed to AWS with an instance role)\n*   **AWS\\_SECRET\\_ACCESS\\_KEY** (not required when deployed to AWS with an instance role)\n*   **USE\\_FILE\\_PROXY** set this to true for access to uploads to proxy through your self hosted server allowing you to keep the bucket private.\n\n### google-cloud[​](#google-cloud \"Direct link to google-cloud\")\n\nStore uploads in a Google Cloud Storage bucket.\n\n*   **GCS\\_BUCKET\\_NAME**\n*   **GCS\\_DOMAIN** (defaults to `https://storage.googleapis.com/${GCS_BUCKET_NAME}/`)\n*   **GOOGLE\\_APPLICATION\\_CREDENTIALS** (not required when deployed to GCP with an instance service account)\n*   **USE\\_FILE\\_PROXY** set this to true for access to uploads to proxy through your self hosted server allowing you to keep the bucket private.\n\n## Enterprise Settings[​](#enterprise-settings \"Direct link to Enterprise Settings\")\n\nSome features in self-hosted GrowthBook are only available with a commercial license key. You can get a trial Enterprise key from your self-hosted version of GrowthBook, or reach out to [sales@growthbook.io](mailto:sales@growthbook.io) to learn more.\n\n### License Keys[​](#license-keys \"Direct link to License Keys\")\n\nIf you have a license key, you can activate it in GrowthBook two different ways:\n\n1.  Navigate to **Settings** → **General** and look for the License section of the page. There you can input or edit your license key string. (Recommended)\n2.  Alternately, set the environment variable `LICENSE_KEY` to your license key string. If using Docker, go to _docker-compose.yml_ and add the variable to the _growthbook_ → _environment_ section.\n\nnote\n\nIf you are running your application behind a firewall you will need to whitelist `75.2.109.47` to be able to have your license verified. If this is an issue, contact [sales@growthbook.io](mailto:sales@growthbook.io) for an air-gapped license.\n\nThe GrowthBook app will check with the license server daily to get the latest license information. When doing so, it will send the following data to our license server:\n\n*   **A hash of each user's email** - this is used to deduplicate users across multiple installations (dev, prod, etc.) in order to figure out how many seats are being used.\n*   **The git sha and date of the installation** - this is used to determine when GrowthBook can delete deprecated features, determine who to send upgrade notices to, provides helpful information for debugging, etc.\n*   **A list of which data source types are being used, a list of which event trackers are being used, and a list of SDK languages being used** - these help GrowthBook know how much usage the various data sources, event trackers, and sdk languages are getting so we can prioritize work.\n\nIf you recently upgraded your license and do not want to wait a day to get the new license information you can go to **Settings** → **General** and look for the License section of the page and click the Refresh button. If you have a multi-org installation and are a super admin you must instead navigate to the **Settings** → **Admin** page, find the license section and click the refresh button there.\n\n### Enterprise SSO[​](#enterprise-sso \"Direct link to Enterprise SSO\")\n\nTo enable SSO on your self-hosted GrowthBook instance, you will need an active license key (see above section), and then you may add the SSO settings for your provider. You can find the instructions on how to setup SSO for GrowthBook with most common providers on our [SSO instructions page](https://docs.growthbook.io/sso). The JSON object with the settings will need to be JSON encoded and then set to the environment variable `SSO_CONFIG`.\n\n### Multi-org[​](#multi-org \"Direct link to Multi-org\")\n\nIf your company has two or more largely independent products (e.g. Google has Search and Google Docs), you can set up multiple [organizations](https://docs.growthbook.io/using/growthbook-best-practices#organizations) per product. The following env vars control multi-org settings:\n\n*   **IS\\_MULTI\\_ORG** - This defaults to `false`. Set this to true if you want to enable multiple organizations.\n*   **ALLOW\\_SELF\\_ORG\\_CREATION** - This defaults to `false`. Set this to true to allow any users to create new organizations.\n*   **SHOW\\_MULTI\\_ORG\\_SELF\\_SELECTOR** - This defaults to `true`. It allows all users to see a list of all organizations they can join. Upon selecting an organization, users will either automatically join it (if using SSO and [self-join](https://docs.growthbook.io/account/user-permissions#self-registering-and-automatic-approvals) is enabled for that organization) or require an admin's approval.\n\n## Observability (OpenTelemetry)[​](#observability-opentelemetry \"Direct link to Observability (OpenTelemetry)\")\n\nThe GrowthBook API is instrumented with OpenTelemetry to publish observability metrics, traces, and logs.\n\nTo enable, you must change the Docker CMD from the default `yarn start` to `yarn start:with-tracing`.\n\nThe standard [OTEL\\_\\* Environment Variables](https://opentelemetry.io/docs/concepts/sdk-configuration/) are supported, such as `OTEL_SERVICE_NAME` and `OTEL_EXPORTER_OTLP_ENDPOINT`.\n\n## Other Settings[​](#other-settings \"Direct link to Other Settings\")\n\n*   **EXPERIMENT\\_REFRESH\\_FREQUENCY** - Default update schedule for experiment results. Update when stale for X hours (default `6`).\n*   **QUERY\\_CACHE\\_TTL\\_MINS** - How long (in minutes) to cache and re-use SQL query results (default `60`)\n*   **DEFAULT\\_CONVERSION\\_WINDOW\\_HOURS** - How many hours after being put into an experiment does a user have to convert. Can be overridden on a per-metric basis. (default `72`)\n*   **DISABLE\\_TELEMETRY** - We collect anonymous telemetry data to help us improve GrowthBook. Set to \"true\" to disable.\n*   **STORE\\_SEGMENTS\\_IN\\_MONGO** - If using the config.yml file, set to `true` if you want to store segments in Mongo. This is also useful if you have existing segments stored in Mongo that you need to access. When set, GrowthBook will ignore segments in the config.yml file and only use Segments stored in Mongo.\n*   **CDN\\_HOST** - When set, this will update the implementation instructions within GrowthBook to override the `API_HOST` in cases where a CDN is used.\n*   **EXPRESS\\_TRUST\\_PROXY\\_OPTS** - Express' [trust proxy](https://expressjs.com/en/5x/api.html#trust.proxy.options.table) setting value. Supports boolean (true/false), string values, and integer values for trusting the _n_th hop from the front-facing proxy server as the client. Leavy empty or specify `false` to use Express' default behavior. If you are running GrowthBook behind a proxy or load balancer, this is required to track the correct user IP for audit log events.",
  "title": "Environment Variables | GrowthBook Docs",
  "description": "Learn how to set environment variables for your self hosted version of GrowthBook",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/edge/lambda",
  "markdown": "# Lambda@Edge Edge App & SDK\n\nalpha\n\nOur Lambda@Edge implementation is in **alpha**. If you experience any issues, let us know either on [Slack](https://slack.growthbook.io/) or [create an issue](https://github.com/growthbook/growthbook-proxy/issues).\n\n## Overview[​](#overview \"Direct link to Overview\")\n\nGrowthBook currently supports two levels of integration with most edge workers, including Lambda@Edge:\n\n1.  Our turnkey Edge App\n    \n    *   Automatically run server-side or hybrid [Visual Experiments](https://docs.growthbook.io/app/visual) without redraw flicker.\n    *   Automatically run server-side or hybrid [URL Redirect Experiments](https://docs.growthbook.io/app/url-redirects) without flicker or delay.\n    *   Optionally inject the JavaScript SDK with hydrated payload, allowing the front-end to pick up where the edge left off without any extra network requests. We use an enhanced version of our [HTML Script Tag](https://docs.growthbook.io/lib/script-tag) for this purpose.\n2.  Support for edge apps using our JavaScript SDK\n    \n\n## References[​](#references \"Direct link to References\")\n\n*   Our Lambda@Edge SDK repository, which supports the above use cases, is [here](https://github.com/growthbook/growthbook-proxy/tree/main/packages/lib/edge-lambda)\n*   You may find it useful to review our [JavaScript SDK](https://docs.growthbook.io/lib/js). Many of the concepts which apply to both on-edge and injected frontend SDKs are based on our JS SDK.\n\n## Worker Configuration[​](#worker-configuration \"Direct link to Worker Configuration\")\n\ntip\n\nThis tutorial assumes some familiarity with building and deploying AWS Lambda@Edge applications. You can get up to speed by following the AWS [Tutorial: Create a basic Lambda@Edge function](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-edge-how-it-works-tutorial.html) guide.\n\nNote that our Edge App responds directly to a `viewer-request` without forwarding to an origin; interaction with CloudFront is minimal (Step 2 in the AWS tutorial).\n\nYou may either use our turnkey Edge App for Lambda@Edge or build your own app from scratch using our JavaScript SDK.\n\n## Turnkey Edge App[​](#turnkey-edge-app \"Direct link to Turnkey Edge App\")\n\nOur Edge App runs as a smart proxy layer between your application and your end users. In absence of Visual or URL Redirect experiments, the Edge App will simply proxy the user request to your site and return the response, optionally injecting a fully-bootstrapped JavaScript SDK onto the rendered HTML page. If the request URL matches an Visual or URL Redirect experiment and the targeting conditions are satisfied, the Edge App may also perform one or more URL redirects behind the scenes (the public-facing URL does not change) and/or mutate the DOM for Visual Experiments.\n\nURL Redirects on edge\n\nThe Edge App defaults to running URL Redirect Experiments in the browser only. This is because edge redirects load a separate page's content without altering the URL. After the redirect, some sites may experience problems with loading assets or endpoints with relative paths.\n\nYou can enable URL Redirects on edge by setting environment variable `RUN_URL_REDIRECT_EXPERIMENTS` ([see below](#environment-variables)).\n\nWe will assume that you have a basic Lambda@Edge application set up, and that it is configured to respond to viewer requests. Note that our Edge App will not attempt to reach your CF cache nor origin and instead will fetch/proxy to your web server during the _viewer request / response_ lifecycle. Therefore a minimal CloudFront setup is advised.\n\nOnce your application is set up, simply install the SDK and implement our custom request handler.\n\n### Install the SDK[​](#install-the-sdk \"Direct link to Install the SDK\")\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save @growthbook/edge-lambda\n```\n\n### Implement the Edge App request handler[​](#implement-the-edge-app-request-handler \"Direct link to Implement the Edge App request handler\")\n\nA basic implementation of our Edge App only requires a few lines of code:\n\n```\nimport { handleRequest } from \"@growthbook/edge-lambda\";export async function handler(event, ctx, callback) {  // Manually build your environment:  const env = buildEnv();  // Specify additional edge endpoint information:  env.host = \"www.mysite.io\";  // Uncomment for ease of testing locally - returns response instead of using callback():  // env.returnResponse = true;  handleRequest(event, callback, env);}function buildEnv() {  // todo: define environment variables here}\n```\n\n### Configure the Edge App[​](#configure-the-edge-app \"Direct link to Configure the Edge App\")\n\nUse a combination of environment variables and optional runtime configuration to add required fields and to customize the Edge App behavior.\n\n#### Environment variables[​](#environment-variables \"Direct link to Environment variables\")\n\nUnfortunately Lambda@Edge does not have native support for environment variables. You will need to implement your own mechanism to build an `Env` environment (a TypeScript interface is exported in `\"@growthbook/edge-lambda\"`). You will need to inject your environment variables into the handler either directly into your codebase or at compile time. Our `buildEnv()` method is a placeholder for your preferred mechanism.\n\nTip (for a subset of use cases)\n\nWe do offer a utility function called `mapHeadersToConfigEnv(req, originType=\"custom\", prefix=\"x-env-\")` (exported from `\"@growthbook/edge-lambda\"`) that can build a valid `Env` environment from custom CF origin headers. However this is only useful if your app is set up to reach your origin server through CF (this is not the default behavior of our Edge App).\n\nAdd these required fields, at minimum, to your environment variables:\n\n```\nfunction buildEnv() {  return {    // required fields:    PROXY_TARGET: \"https://internal.mysite.io\",  // The non-edge URL to your website    GROWTHBOOK_API_HOST: \"https://cdn.growthbook.io\",    GROWTHBOOK_CLIENT_KEY: \"sdk-abc123\",    GROWTHBOOK_DECRYPTION_KEY: \"key_abc123\",  // Only include for encrypted SDK Connections  };}\n```\n\nYou may want to further customize the app. Here is a list of common customization variables:\n\n```\n# Disable or change the rendering behavior of Visual Experiments:# ==========RUN_VISUAL_EDITOR_EXPERIMENTS=\"everywhere\"|\"edge\"|\"browser\"|\"skip\"  # default: \"everywhere\"# URL Redirect Experiments are disabled on edge by default. Because the URL does not change, some sites# may experience problems with loading assets or endpoints with relative paths:# ==========RUN_URL_REDIRECT_EXPERIMENTS=\"everywhere\"|\"edge\"|\"browser\"|\"skip\"  # default: \"browser\"RUN_CROSS_ORIGIN_URL_REDIRECT_EXPERIMENTS=\"everywhere\"|\"edge\"|\"browser\"|\"skip\"  # default: \"browser\"# Mutate browser URL via window.history.replaceState() to reflect the new URL:INJECT_REDIRECT_URL_SCRIPT=\"true\"  # default \"true\".# Do not inject a bootstrapped JavaScript SDK onto the page:# ==========DISABLE_INJECTIONS=\"true\"  # default \"false\"# Customize the edge or injected browser SDK behavior:# ==========ENABLE_STREAMING=\"true\"  # default \"false\". Streaming SSE updates on browser.ENABLE_STICKY_BUCKETING=\"true\"  # default \"false\". Use cookie-based sticky bucketing on edge and browser.\n```\n\n#### Runtime configuration[​](#runtime-configuration \"Direct link to Runtime configuration\")\n\nYou may want to provide context to your edge app at runtime rather than using environment variables. For example, if you have additional [targeting attributes](https://docs.growthbook.io/lib/js#attributes) available, you may inject them by modifying your request handler code:\n\n```\nimport { handleRequest } from \"@growthbook/edge-lambda\";import { getCookies } from \"./helpers\";export async function handler(event, ctx, callback) {  const env = buildEnv();  env.host = \"www.mysite.io\";  // example getCookies method  const cookie = getCookies(event);  const config = {    attributes: {      userType: cookie[\"userId\"] ? \"logged in\" : \"anonymous\"    }  };  handleRequest(event, callback, env, config);}\n```\n\n#### More customization options[​](#more-customization-options \"Direct link to More customization options\")\n\nFor a full list of customizations, view our vendor-agnostic [Edge Utility repository](https://github.com/growthbook/growthbook-proxy/tree/main/packages/lib/edge-utils) .\n\n### Tracking Experiment Views[​](#tracking-experiment-views \"Direct link to Tracking Experiment Views\")\n\nRunning A/B tests requires a [tracking callback](https://docs.growthbook.io/lib/js#experimentation-ab-testing). Our turnkey Edge App defaults to using built-in front-end tracking. The tracking call automatically integrates with Segment.io, GA4, and Google Tag Manager by using the mechanism outlined in our [HTML Script Tag](https://docs.growthbook.io/lib/script-tag#tracking-experiment-views). In order to do this, the app keeps track of tracking calls triggered on edge and injects them into the front-end SDK to be automatically triggered on page load.\n\nYou may wish to either customize front-end tracking or switch to edge tracking (or use both concurrently if running hybrid edge + front-end experiments).\n\nWhy might you be interested in tracking on edge? Tracking on an edge or backend environment allows you to ensure the callback is fired before any differentiation across variations, eliminating experimental bias. While not eliminating this risk, the default injected front-end tracking introduced by our Edge App does reduce this risk relative to solely using a front-end SDK.\n\nTo change the front-end tracking callback, set the `GROWTHBOOK_TRACKING_CALLBACK` to your custom tracking JS code:\n\n```\n# todo: replace with your own tracking libraryGROWTHBOOK_TRACKING_CALLBACK=\"(experiment, results) => { console.log('browser tracking callback', {experiment, results}); }\"\n```\n\nTo track on edge, you must inject your own tracking callback into the edge request handler code. Any experiments that run on edge will use the edge tracking callback and not the front-end callback (hybrid edge + front-end experiments being an exception):\n\n```\nimport { handleRequest } from \"@growthbook/edge-lambda\";export async function handler(event, ctx, callback) {  const env = buildEnv();  env.host = \"www.mysite.io\";  const config = {    edgeTrackingCallback: (experiment, results) => {      // todo: replace with your tracking library      console.log('edge tracking callback', {experiment, results});    }  };  handleRequest(event, callback, env, config);}\n```\n\n### Targeting Attributes[​](#targeting-attributes \"Direct link to Targeting Attributes\")\n\nThe following targeting attributes are set automatically by the Edge App.\n\n*   `id` - creates a long-lived `gbuuid` cookie if it doesn't exist already\n*   `url`\n*   `path`\n*   `host`\n*   `query`\n*   `pageTitle`\n*   `deviceType` - either `mobile` or `desktop`\n*   `browser` - one of `chrome`, `edge`, `firefox`, `safari`, or `unknown`\n*   `utmSource`\n*   `utmMedium`\n*   `utmCampaign`\n*   `utmTerm`\n*   `utmContent`\n\nYou can customize both the primary identifier name (`id`) and cookie name (`gbuuid`) by setting the `UUID_KEY` and `UUID_COOKIE_NAME` environment variables respectively.\n\nAs shown in the [runtime configuration](#runtime-configuration) section above, you can also pass custom attributes via runtime config. You can also skip automatic attribute generation and rely solely on custom attributes by setting the environment variable `SKIP_AUTO_ATTRIBUTES=\"true\"`.\n\n### Routing[​](#routing \"Direct link to Routing\")\n\nBy default, the Edge App will process all `GET` requests (other HTTP verbs are proxied through without running through our app logic).\n\nIt is generally preferable to configure your routing rules outside of our Edge App when possible. For instance, you may only want to invoke the Edge App at `https://yourdomain.io/landing-page`.\n\nThere may be situations when you will need to provide finer-grained routing / URL targeting rules within our Edge App. You will need to include a JSON encoded string of route rules in your `ROUTES` environment variable.\n\nFor instance, you may want to do a proxy pass-through (do not process) for `mysite.io/account/*` or `mysite.io/settings/*`. Your routes may look like this:\n\n```\nROUTES='[{ \"pattern\":\"mysite.io/account/*\", \"behavior\":\"proxy\" }, { \"pattern\":\"mysite.io/settings/*\", \"behavior\":\"proxy\" }]'\n```\n\nA route uses the following interface, with many of the properties being optional:\n\n```\n{  pattern: string;  type?: \"regex\" | \"simple\";  // default: \"simple\"  behavior?: \"intercept\" | \"proxy\" | \"error\";  // default: \"intercept\"  includeFileExtensions?: boolean;  // Include requests to filenames like \"*.jpg\". default: false (pass-through).  statusCode?: number; // Alter the status code (default is 404 when using \"error\")  body?: string; // Alter the body (for setting an error message body)}\n```\n\nWhen multiple routes are included in your `ROUTES` array, only the first match is used.\n\n### Cookie Policy and GDPR[​](#cookie-policy-and-gdpr \"Direct link to Cookie Policy and GDPR\")\n\nBy default, the Edge App will persist a random unique identifier in a first-party cookie named `gbuuid`. Its purpose is to provide a consistent user experience to your visitors by preventing them from being re-bucketed into different A/B test variations. It follows the same mechanism as discussed in our [HTML Script Tag docs](https://docs.growthbook.io/lib/script-tag#cookie-policy-and-gdpr).\n\n#### Delay Storing the Cookie Until Consent is Granted[​](#delay-storing-the-cookie-until-consent-is-granted \"Direct link to Delay Storing the Cookie Until Consent is Granted\")\n\nIf you must delay persisting the `gbuuid` cookie until a user consents, you can set the environment variable `NO_AUTO_COOKIES=\"true\"`.\n\nThis will still generate a UUID for the user, but will not persist it. That means, if the user refreshes the page, they will have a new random UUID generated.environment\n\nYou have the option to manually persist this cookie at any time, for example when a user grants consent on your cookie banner. All you need to do is fire this custom event from javascript on the rendered page:\n\n```\ndocument.dispatchEvent(new CustomEvent(\"growthbookpersist\"));\n```\n\nnote\n\nIf you are using Sticky Bucketing, a persistent sticky bucket assignments cookie will automatically be generated. If you require user permission before writing cookies, you should:\n\n*   Either do not enable Sticky Bucketing on edge (do not use `ENABLE_STICKY_BUCKETING`)\n*   Or only enable Sticky Bucketing per each user via runtime configuration. (only pass `config.enableStickyBucketing: true` if user has consented — identifiable by checking for presence of the `gbuuid` cookie).\n\n## Manual SDK Integration on Edge[​](#manual-sdk-integration-on-edge \"Direct link to Manual SDK Integration on Edge\")\n\nYou may be interested in building your own edge application using the GrowthBook SDK and not using our turnkey Edge App. Or you may want to do custom feature flagging on specific routes while running our Edge App on other routes.\n\nTo use the GrowthBook on edge, simply include our standard [JavaScript SDK](https://docs.growthbook.io/lib/js) (`@growthbook/growthbook` NPM package).\n\n```\nimport { GrowthBook, setPolyfills } from \"@growthbook/growthbook\";export async function handler(event, ctx, callback) {  // 1. Init the GrowthBook SDK and choose an optional caching strategy  // A. Use the KV as a managed payload store to eliminate SDK requests to the GrowthBook API entirely.  // Requires setting up an SDK Webhook.  const payload = await getPayloadFromProvider(); // not implemented, build your own  const growthbook = new GrowthBook(gbContext);  await growthbook.init({ payload: payload });  // B. Or provide a KV cache layer so that the GrowthBook SDK doesn't need to make as many requests  // to the GrowthBook API. No SDK Webhook needed.  const localStoragePolyfill = getLocalStoragePolyfill(env); // not implemented, build your own  setPolyfills({ localStorage: localStoragePolyfill });  await growthbook.init();  // 2. Start feature flagging  if (growthbook.isOn(\"my-feature\")) {    const resp = { status: \"200\", body: \"<h1>foo</h1>\" };    callback(null, resp);  } else {    const resp = { status: \"200\", body: \"<h1>bar</h1>\" };    callback(null, resp);  }}\n```\n\n## Payload Caching via edge datastore[​](#payload-caching-via-edge-datastore \"Direct link to Payload Caching via edge datastore\")\n\nBy default, the Edge App will make a network request to the GrowthBook API on each user request in order to fetch the current feature and experiment values. This is a blocking call that delays page delivery. There is an in-memory short-lived cache layer on this call, but it won't always protect you.\n\nIf you have access to a distributed key-value store such as DynamoDB, you can likely overcome this problem. There are 2 levels of key-value integration available:\n\n1.  You can either completely eliminate the blocking call to the GrowthBook API by implementing a GrowthBook-to-edge-keyval push model via **SDK Webhooks**.\n2.  Alternatively, you can eliminate most of these network requests by using an edge key-val store as a just-in-time payload cache.\n\nYou can also use these strategies in your own manual SDK integration.\n\nWe are unable to offer specific guidance about how to configure or connect to your key-val store because there are many possible network configurations and data stores within an AWS edge application.\n\n### Configuring a SDK Webhook[​](#configuring-a-sdk-webhook \"Direct link to Configuring a SDK Webhook\")\n\nFor key-val stored payloads (1), we eliminate network requests from edge to GrowthBook by using a GrowthBook SDK Webhook to push the SDK payload to the key-val store on change.\n\n1.  Create an [SDK Webhook](https://docs.growthbook.io/app/webhooks/sdk-webhooks) on the same SDK Connection that you are using for edge integration.\n2.  Set the **Endpoint URL** to your key-val store's REST API endpoint, if available. You may need to build your own private Lambda endpoint to handle the webhook, in which case webhook verification may be important.\n3.  Change the **Method** to `PUT` (or whichever verb is required by your endpoint).\n4.  Set the **Payload format** to \"SDK Payload only\".\n\nNow whenever feature and experiment values change, your edge worker will have immediate access to the latest values. You can also test the webhook by using the \"Test Webhook\" button on the SDK Connection page.",
  "title": "Lambda@Edge Edge App & SDK | GrowthBook Docs",
  "description": "GrowthBook SDK for Lambda@Edge",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/lib/edge/other",
  "markdown": "# GrowthBook Edge App for other edge providers\n\n## Overview[​](#overview \"Direct link to Overview\")\n\nGrowthBook currently supports two levels of integration with most edge workers:\n\n1.  Our turnkey Edge App\n    \n    *   Automatically run server-side or hybrid [Visual Experiments](https://docs.growthbook.io/app/visual) without redraw flicker.\n    *   Automatically run server-side or hybrid [URL Redirect Experiments](https://docs.growthbook.io/app/url-redirects) without flicker or delay.\n    *   Optionally inject the JavaScript SDK with hydrated payload, allowing the front-end to pick up where the edge left off without any extra network requests. We use an enhanced version of our [HTML Script Tag](https://docs.growthbook.io/lib/script-tag) for this purpose.\n2.  Support for edge apps using our JavaScript SDK\n    \n\n## References[​](#references \"Direct link to References\")\n\n*   Our base Edge App repository, which supports the above use cases, is [here](https://github.com/growthbook/growthbook-proxy/tree/main/packages/lib/edge-utils)\n*   You may find it useful to review our [JavaScript SDK](https://docs.growthbook.io/lib/js). Many of the concepts which apply to both on-edge and injected frontend SDKs are based on our JS SDK.\n\n## Turnkey Edge App[​](#turnkey-edge-app \"Direct link to Turnkey Edge App\")\n\nOur Edge App runs as a smart proxy layer between your application and your end users. In absence of Visual or URL Redirect experiments, the Edge App will simply proxy the user request to your site and return the response, optionally injecting a fully-bootstrapped JavaScript SDK onto the rendered HTML page. If the request URL matches an Visual or URL Redirect experiment and the targeting conditions are satisfied, the Edge App may also perform one or more URL redirects behind the scenes (the public-facing URL does not change) and/or mutate the DOM for Visual Experiments.\n\nURL Redirects on edge\n\nThe Edge App defaults to running URL Redirect Experiments in the browser only. This is because edge redirects load a separate page's content without altering the URL. After the redirect, some sites may experience problems with loading assets or endpoints with relative paths.\n\nYou can enable URL Redirects on edge by setting environment variable `RUN_URL_REDIRECT_EXPERIMENTS` ([see below](#environment-variables)).\n\nSetting up our turnkey Edge App is usually simple for most JavaScript-based edge workers.\n\nIn this guide we do not discuss bootstrapping your project, but rather how to implement our Edge App once you have a basic edge worker environment set up.\n\n### Install the SDK[​](#install-the-sdk \"Direct link to Install the SDK\")\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save @growthbook/edge-utils\n```\n\n### Implement the Edge App request handler[​](#implement-the-edge-app-request-handler \"Direct link to Implement the Edge App request handler\")\n\nA basic implementation of our Edge App only requires a few lines of code. Your implementation however will be vendor specific:\n\n```\nimport { edgeApp, getConfig, defaultContext } from \"@growthbook/edge-utils\";// Build a request handler// note: we assume availability of `env` (environment variables)export async function handler(request, env) {  const context = await init(env);  return edgeApp(context, request);}// Build context for the appfunction init(env) {  // Automatically parse environment variables into app context  const context = defaultContext;  context.config = getConfig(env);  context.helpers = {    // define utility functions for request/response manipulation  };  return context;}\n```\n\nYou will need to write our own set of helper methods (`context.helpers`) that correspond to how your edge provider handles various request and response utilities.\n\n### Define helper methods[​](#define-helper-methods \"Direct link to Define helper methods\")\n\nYou will need to build helper methods based on the following interfaces:\n\n```\n{  // Get the full URL from the user request  getRequestURL?: (req: Req) => string;  // Get the request method (GET, POST, etc)  getRequestMethod?: (req: Req) => string;  // Get a specific header from the request  getRequestHeader?: (req: Req, key: string) => string | undefined;  // Construct or prepare a response for sending to the client  // note: For many vendors, this function should build a new response object  sendResponse?: (    ctx: Context<Req, Res>,    res?: Res, // Only needed for engines where res already exists    headers?: Record<string, any>,    body?: string,    cookies?: Record<string, string>, // Optionally use ctx.helpers.setCookie(resp, key, cookies[key]) to assign.    status?: number,  ) => unknown;  // Fetch an external resource from the edge app  // note: For many vendors, you can ignore ctx  fetch?: (ctx: Context<Req, Res>, url: string) => Promise<Res>;  // For sending a pass-through response without Edge App interception  // note: For many vendors, this will map directly to helpers.fetch  proxyRequest?: (    ctx: Context<Req, Res>,    req: Req,    res?: Res,    next?: any,  ) => Promise<unknown>;  // Get cookie from request (for UUID and StickyBucketing persistence)  getCookie?: (req: Req, key: string) => string;  // Set a cookie on response (unused unless you choose to persist on edge)  setCookie?: (res: Res, key: string, value: string) => void;}\n```\n\nYou may reference example implementations of these methods in our [Cloudflare repository](https://github.com/growthbook/growthbook-proxy/tree/main/packages/lib/edge-cloudflare/src/helpers.ts) .\n\n### Configure the Edge App[​](#configure-the-edge-app \"Direct link to Configure the Edge App\")\n\nUse a combination of environment variables and optional runtime configuration to add required fields and to customize the Edge App behavior.\n\n#### Environment variables[​](#environment-variables \"Direct link to Environment variables\")\n\nAdd these required fields, at minimum, to your environment variables:\n\n```\nPROXY_TARGET=\"https://internal.mysite.io\"  # The non-edge URL to your websiteGROWTHBOOK_API_HOST=\"https://cdn.growthbook.io\"GROWTHBOOK_CLIENT_KEY=\"sdk-abc123\"GROWTHBOOK_DECRYPTION_KEY=\"key_abc123\"  # Only include for encrypted SDK Connections\n```\n\nYou may want to further customize the app. Here is a list of common customization variables:\n\n```\n# Disable or change the rendering behavior of Visual Experiments:# ==========RUN_VISUAL_EDITOR_EXPERIMENTS=\"everywhere\"|\"edge\"|\"browser\"|\"skip\"  # default: \"everywhere\"# URL Redirect Experiments are disabled on edge by default. Because the URL does not change, some sites# may experience problems with loading assets or endpoints with relative paths:# ==========RUN_URL_REDIRECT_EXPERIMENTS=\"everywhere\"|\"edge\"|\"browser\"|\"skip\"  # default: \"browser\"RUN_CROSS_ORIGIN_URL_REDIRECT_EXPERIMENTS=\"everywhere\"|\"edge\"|\"browser\"|\"skip\"  # default: \"browser\"# Mutate browser URL via window.history.replaceState() to reflect the new URL:INJECT_REDIRECT_URL_SCRIPT=\"true\"  # default \"true\".# Do not inject a bootstrapped JavaScript SDK onto the page:# ==========DISABLE_INJECTIONS=\"true\"  # default \"false\"# Customize the edge or injected browser SDK behavior:# ==========ENABLE_STREAMING=\"true\"  # default \"false\". Streaming SSE updates on browser.ENABLE_STICKY_BUCKETING=\"true\"  # default \"false\". Use cookie-based sticky bucketing on edge and browser.\n```\n\n#### Runtime configuration[​](#runtime-configuration \"Direct link to Runtime configuration\")\n\nYou may want to provide context to your edge app at runtime rather than using environment variables. For example, if you have additional [targeting attributes](https://docs.growthbook.io/lib/js#attributes) available, you may inject them by modifying your request handler code:\n\n```\nimport { edgeApp, getConfig } from \"@growthbook/edge-utils\";export async function handler(request, env) {  const context = await init(env);  const userId = context.helpers.getCookie(request, \"userId\");  context.config.attributes.userType = userId ? \"logged in\" : \"anonymous\";  return edgeApp(context, request);}\n```\n\n#### More customization options[​](#more-customization-options \"Direct link to More customization options\")\n\nFor a full list of customizations, view our [Edge Utility repository](https://github.com/growthbook/growthbook-proxy/tree/main/packages/lib/edge-utils) .\n\n### Tracking Experiment Views[​](#tracking-experiment-views \"Direct link to Tracking Experiment Views\")\n\nRunning A/B tests requires a [tracking callback](https://docs.growthbook.io/lib/js#experimentation-ab-testing). Our turnkey Edge App defaults to using built-in front-end tracking. The tracking call automatically integrates with Segment.io, GA4, and Google Tag Manager by using the mechanism outlined in our [HTML Script Tag](https://docs.growthbook.io/lib/script-tag#tracking-experiment-views). In order to do this, the app keeps track of tracking calls triggered on edge and injects them into the front-end SDK to be automatically triggered on page load.\n\nYou may wish to either customize front-end tracking or switch to edge tracking (or use both concurrently if running hybrid edge + front-end experiments).\n\nWhy might you be interested in tracking on edge? Tracking on an edge or backend environment allows you to ensure the callback is fired before any differentiation across variations, eliminating experimental bias. While not eliminating this risk, the default injected front-end tracking introduced by our Edge App does reduce this risk relative to solely using a front-end SDK.\n\nTo change the front-end tracking callback, set the `GROWTHBOOK_TRACKING_CALLBACK` to your custom tracking JS code:\n\n```\n# todo: replace with your own tracking libraryGROWTHBOOK_TRACKING_CALLBACK=\"(experiment, results) => { console.log('browser tracking callback', {experiment, results}); }\"\n```\n\nTo track on edge, you must inject your own tracking callback into the edge request handler code. Any experiments that run on edge will use the edge tracking callback and not the front-end callback (hybrid edge + front-end experiments being an exception):\n\n```\nimport { edgeApp, getConfig } from \"@growthbook/edge-utils\";export async function handler(request, env) {  const context = await init(env);  context.config.edgeTrackingCallback = (experiment, results) => {    // todo: replace with your tracking library    console.log('edge tracking callback', {experiment, results});  }  return edgeApp(context, request);}\n```\n\n### Targeting Attributes[​](#targeting-attributes \"Direct link to Targeting Attributes\")\n\nThe following targeting attributes are set automatically by the Edge App.\n\n*   `id` - creates a long-lived `gbuuid` cookie if it doesn't exist already\n*   `url`\n*   `path`\n*   `host`\n*   `query`\n*   `pageTitle`\n*   `deviceType` - either `mobile` or `desktop`\n*   `browser` - one of `chrome`, `edge`, `firefox`, `safari`, or `unknown`\n*   `utmSource`\n*   `utmMedium`\n*   `utmCampaign`\n*   `utmTerm`\n*   `utmContent`\n\nYou can customize both the primary identifier name (`id`) and cookie name (`gbuuid`) by setting the `UUID_KEY` and `UUID_COOKIE_NAME` environment variables respectively.\n\nAs shown in the [runtime configuration](#runtime-configuration) section above, you can also pass custom attributes via runtime config. You can also skip automatic attribute generation and rely solely on custom attributes by setting the environment variable `SKIP_AUTO_ATTRIBUTES=\"true\"`.\n\n### Routing[​](#routing \"Direct link to Routing\")\n\nBy default, the Edge App will process all `GET` requests (other HTTP verbs are proxied through without running through our app logic).\n\nIt is generally preferable to configure your routing rules outside of our Edge App. For instance, you may only want to invoke the Edge App at `https://yourdomain.io/landing-page`.\n\nThere may be situations when you will need to provide finer-grained routing / URL targeting rules within our Edge App. You will need to include a JSON encoded string of route rules in your `ROUTES` environment variable.\n\nFor instance, you may want to do a proxy pass-through (do not process) for `mysite.io/account/*` or `mysite.io/settings/*`. Your routes may look like this:\n\n```\nROUTES='[{ \"pattern\":\"mysite.io/account/*\", \"behavior\":\"proxy\" }, { \"pattern\":\"mysite.io/settings/*\", \"behavior\":\"proxy\" }]'\n```\n\nA route uses the following interface, with many of the properties being optional:\n\n```\n{  pattern: string;  type?: \"regex\" | \"simple\";  // default: \"simple\"  behavior?: \"intercept\" | \"proxy\" | \"error\";  // default: \"intercept\"  includeFileExtensions?: boolean;  // Include requests to filenames like \"*.jpg\". default: false (pass-through).  statusCode?: number; // Alter the status code (default is 404 when using \"error\")  body?: string; // Alter the body (for setting an error message body)}\n```\n\nWhen multiple routes are included in your `ROUTES` array, only the first match is used.\n\n### Cookie Policy and GDPR[​](#cookie-policy-and-gdpr \"Direct link to Cookie Policy and GDPR\")\n\nBy default, the Edge App will persist a random unique identifier in a first-party cookie named `gbuuid`. Its purpose is to provide a consistent user experience to your visitors by preventing them from being re-bucketed into different A/B test variations. It follows the same mechanism as discussed in our [HTML Script Tag docs](https://docs.growthbook.io/lib/script-tag#cookie-policy-and-gdpr).\n\n#### Delay Storing the Cookie Until Consent is Granted[​](#delay-storing-the-cookie-until-consent-is-granted \"Direct link to Delay Storing the Cookie Until Consent is Granted\")\n\nIf you must delay persisting the `gbuuid` cookie until a user consents, you can set the environment variable `NO_AUTO_COOKIES=\"true\"`.\n\nThis will still generate a UUID for the user, but will not persist it. That means, if the user refreshes the page, they will have a new random UUID generated.environment\n\nYou have the option to manually persist this cookie at any time, for example when a user grants consent on your cookie banner. All you need to do is fire this custom event from javascript on the rendered page:\n\n```\ndocument.dispatchEvent(new CustomEvent(\"growthbookpersist\"));\n```\n\nnote\n\nIf you are using Sticky Bucketing, a persistent sticky bucket assignments cookie will automatically be generated. If you require user permission before writing cookies, you should:\n\n*   Either do not enable Sticky Bucketing on edge (do not use `ENABLE_STICKY_BUCKETING`)\n*   Or only enable Sticky Bucketing per each user via runtime configuration. (only pass `config.enableStickyBucketing: true` if user has consented — identifiable by checking for presence of the `gbuuid` cookie).\n\n## Manual SDK Integration on Edge[​](#manual-sdk-integration-on-edge \"Direct link to Manual SDK Integration on Edge\")\n\nYou may be interested in building your own edge application using the GrowthBook SDK and not using our turnkey Edge App. Or you may want to do custom feature flagging on specific routes while running our Edge App on other routes.\n\nTo use the GrowthBook on edge, simply include our standard [JavaScript SDK](https://docs.growthbook.io/lib/js) (`@growthbook/growthbook` NPM package).\n\n```\nimport { GrowthBook, setPolyfills } from \"@growthbook/growthbook\";export default {  async fetch(request) {    // 1. Init the GrowthBook SDK and choose an optional caching strategy    // A. Use the KV as a managed payload store to eliminate SDK requests to the GrowthBook API entirely.    // Requires setting up an SDK Webhook.    const payload = await getPayloadFromProvider(env); // not implemented, build your own    const growthbook = new GrowthBook(gbContext);    await growthbook.init({ payload: payload });    // B. Or provide a KV cache layer so that the GrowthBook SDK doesn't need to make as many requests    // to the GrowthBook API. No SDK Webhook needed.    const localStoragePolyfill = getLocalStoragePolyfill(env); // not implemented, build your own    setPolyfills({ localStorage: localStoragePolyfill });    await growthbook.init();    // 2. Start feature flagging    if (growthbook.isOn(\"my-feature\")) {      return new Response(\"<h1>foo</h1>\");    }    return new Response(\"<h1>bar</h1>\");  }}\n```\n\n## Payload Caching via edge datastore[​](#payload-caching-via-edge-datastore \"Direct link to Payload Caching via edge datastore\")\n\nBy default, the Edge App will make a network request to the GrowthBook API on each user request in order to fetch the current feature and experiment values. This is a blocking call that delays page delivery. There is an in-memory short-lived cache layer on this call, but it won't always protect you.\n\nIf you have access to a distributed key-val store on your edge, you can likely overcome this problem. There are 2 levels of key-val integration available:\n\n1.  You can either completely eliminate the blocking call to the GrowthBook API by implementing a GrowthBook-to-edge-keyval push model via **SDK Webhooks**.\n2.  Alternatively, you can eliminate most of these network requests by using an edge key-val store as a just-in-time payload cache.\n\nYou can also use these strategies in your own manual SDK integration.\n\nWe are unable to offer specific guidance about how to configure or connect to your key-val store because the details vary heavily by vendor. For inspiration, you can see how we've addressed key-val implementation with Cloudflare Workers in our [Cloudflare docs](https://docs.growthbook.io/lib/edge/cloudflare#payload-caching-with-cloudflare-kv-store).\n\n### Configuring a SDK Webhook[​](#configuring-a-sdk-webhook \"Direct link to Configuring a SDK Webhook\")\n\nFor key-val stored payloads (1), we eliminate network requests from edge to GrowthBook by using a GrowthBook SDK Webhook to push the SDK payload to the key-val store on change.\n\n1.  Create an [SDK Webhook](https://docs.growthbook.io/app/webhooks/sdk-webhooks) on the same SDK Connection that you are using for edge integration.\n2.  Set the **Endpoint URL** to your key-val provider's REST API endpoint. However, not all edge vendors will have a public REST endpoint for setting the key-val cache. You may need to build your own endpoint to handle the webhook, in which case webhook verification may be important.\n3.  Change the **Method** to `PUT` (or whichever verb is required by your vendor or endpoint).\n4.  Add any vendor-specific authorization headers. This may not be required depending on your specific vendor:\n\n```\n{  \"Authorization\": \"Bearer YOUR_REST_API_TOKEN\"}\n```\n\n5.  Set the **Payload format** to \"SDK Payload only\".\n\nNow whenever feature and experiment values change, your edge worker will have immediate access to the latest values. You can also test the webhook by using the \"Test Webhook\" button on the SDK Connection page.",
  "title": "GrowthBook Edge App for other edge providers | GrowthBook Docs",
  "description": "GrowthBook SDK for other edge providers",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/self-host/config",
  "markdown": "# Config.yml | GrowthBook Docs\n\nIn order to use GrowthBook, you need to connect to a data source and define metrics (and optionally dimensions and segments). There are two ways to do this.\n\nThe default way to define these is by filling out forms in the GrowthBook UI, which persists them to MongoDB.\n\nThe other option is to create a `config.yml` file. In the Docker container, this file must be placed at `/usr/local/src/app/config/config.yml`. Below is an example file:\n\n```\ndatasources:  warehouse:    type: postgres    name: Main Warehouse    # Connection params (different for each type of data source)    params:      host: localhost      port: 5432      user: root      password: ${POSTGRES_PW} # use env for secrets      database: growthbook    # How to query the data (same for all SQL sources)    settings:      userIdTypes:        - userIdType: user_id          description: Logged-in user id        - userIdType: anonymous_id          description: Anonymous visitor id      queries:        exposure:          - id: user_id            name: Logged-in user experiments            userIdType: user_id            query: >              SELECT                user_id,                received_at as timestamp,                experiment_id,                variation_id,                context_location_country as country              FROM                experiment_viewed            dimensions:              - country        identityJoins:          - ids: [\"user_id\", \"anonymous_id\"]            query: SELECT user_id, anonymous_id FROM identifiesmetrics:  signups:    type: binomial    name: Sign Ups    userIdType: user_id    datasource: warehouse    sql: SELECT user_id, anonymous_id, received_at as timestamp FROM signupsdimensions:  country:    name: Country    userIdType: user_id    datasource: warehouse    sql: SELECT user_id, country as value from userssegments:  visitors:    name: Visitors in the US    datasource: warehouse    sql: |-      SELECT userid as user_id, timestamp as date      FROM users      WHERE country='US'    userIdType: user_id\n```\n\n### Data Source Connection Params[​](#data-source-connection-params \"Direct link to Data Source Connection Params\")\n\nThe contents of the `params` field for a data source depends on the type.\n\nAs seen in the example above, you can use environment variable interpolation for secrets (e.g. `${POSTGRES_PW}`).\n\n#### Redshift, ClickHouse, Postgres, and Mysql (or MariaDB)[​](#redshift-clickhouse-postgres-and-mysql-or-mariadb \"Direct link to Redshift, ClickHouse, Postgres, and Mysql (or MariaDB)\")\n\n```\ntype: postgres # or \"redshift\" or \"mysql\" or \"clickhouse\"params:  host: localhost  port: 5432  user: root  password: password  database: growthbook\n```\n\nRedshift and Postgres also support optional params to force an SSL connection:\n\n```\ntype: postgresparams:  ...  ssl: true  # Omit the below fields to use the default trusted CA from Mozilla  caCert: \"-----BEGIN CERTIFICATE-----\\n...\"  clientCert: \"-----BEGIN CERTIFICATE-----\\n...\"  clientKey: \"-----BEGIN CERTIFICATE-----\\n...\"\n```\n\n#### Snowflake[​](#snowflake \"Direct link to Snowflake\")\n\n```\ntype: snowflakeparams:  account: abc123.us-east-1  username: user  password: password  database: GROWTHBOOK  schema: PUBLIC  role: SYSADMIN  warehouse: COMPUTE_WH\n```\n\n#### BigQuery[​](#bigquery \"Direct link to BigQuery\")\n\nYou must first create a Service Account in Google with the following roles:\n\n*   Data Viewer\n*   Metadata Viewer\n*   Job User\n\nIf you want GrowthBook to auto-discover credentials from environment variables or GCP metadata, use the following:\n\n```\ntype: bigqueryparams:  authType: auto\n```\n\nIf you prefer to pass in credentials directly, you can use this format instead:\n\n```\ntype: bigqueryparams:  projectId: my-project  clientEmail: growthbook@my-project.iam.gserviceaccount.com  privateKey: -----BEGIN PRIVATE KEY-----\\nABC123\\n-----END PRIVATE KEY-----\\n\n```\n\n#### Presto and TrinoDB[​](#presto-and-trinodb \"Direct link to Presto and TrinoDB\")\n\n```\ntype: prestoparams:  engine: presto # or \"trino\"  host: localhost  port: 8080  username: user  password: password  catalog: growthbook  schema: growthbook\n```\n\n#### Databricks[​](#databricks \"Direct link to Databricks\")\n\n```\ntype: databricksparams:  host: dbc-123-abc.cloud.databricks.com  port: 443  path: /sql/1.0/warehouses/abc123  token: dapi123abc\n```\n\n#### AWS Athena[​](#aws-athena \"Direct link to AWS Athena\")\n\nIf you want GrowthBook to auto-discover credentials from environment variables or instance metadata, use the following format:\n\n```\ntype: athenaparams:  authType: auto  region: us-east-1  database: growthbook  bucketUri: aws-athena-query-results-growthbook  workGroup: primary\n```\n\nIf you prefer to specify access key and secret directly instead, use the following format:\n\n```\ntype: athenaparams:  accessKeyId: AKIA123  secretAccessKey: AB+cdef123  region: us-east-1  database: growthbook  bucketUri: aws-athena-query-results-growthbook  workGroup: primary\n```\n\n#### Mixpanel[​](#mixpanel \"Direct link to Mixpanel\")\n\nMixpanel access requires a service account.\n\n```\ntype: mixpanelparams:  username: growthbook  secret: abc123  projectId: my-project\n```\n\n#### Google Analytics[​](#google-analytics \"Direct link to Google Analytics\")\n\nUnfortunately at this time there is no way to connect to Google Analytics in `config.yml`. You must connect via the GrowthBook UI, where we use OAuth and a browser redirect.\n\n### Data Source Settings[​](#data-source-settings \"Direct link to Data Source Settings\")\n\nThe settings tell GrowthBook how to query your data.\n\n#### SQL Data Sources[​](#sql-data-sources \"Direct link to SQL Data Sources\")\n\nFor data sources that support SQL, there are a couple queries you need to define plus an optional Python script to run queries from inside a Jupyter notebook:\n\n```\ntype: postgresparams: ...settings:  # The different types of supported identifiers  userIdTypes:    - userIdType: user_id      description: Logged-in user id    - userIdType: anonymous_id      description: Anonymous visitor id  queries:    # These queries returns experiment variation assignment info    # One row every time a user was put into an experiment    exposure:      - id: user_id        name: Logged-in user experiments        userIdType: user_id        query: >          SELECT            user_id,            received_at as timestamp,            experiment_id,            variation_id,            context_location_country as country          FROM            experiment_viewed        # List additional columns you selected in your experimentsQuery        # Can use these to drill down into experiment results        dimensions:          - country    # These optional queries map between different types of identifiers    identityJoins:      - ids: [\"user_id\", \"anonymous_id\"]        query: SELECT user_id, anonymous_id FROM identifies  # Used when exporting experiment results to a Jupyter notebook  # Define a `runQuery(sql)` function that returns a pandas data frame  notebookRunQuery: >    import os    import psycopg2    import pandas as pd    from sqlalchemy import create_engine, text    # Use environment variables or similar for passwords!    password = os.getenv('POSTGRES_PW')    connStr = f'postgresql+psycopg2://user:{password}@localhost'    dbConnection = create_engine(connStr).connect();    def runQuery(sql):      return pd.read_sql(text(sql), dbConnection)\n```\n\n#### Mixpanel[​](#mixpanel-1 \"Direct link to Mixpanel\")\n\nMixpanel does not support SQL, so we query the data using JQL instead. In order to do this, we just need to know a few event names and properties:\n\n```\ntype: mixpanelparams: ...settings:  events:    experimentEvent: Viewed Experiment    experimentIdProperty: experiment_id    variationIdProperty: variation_id\n```\n\n### Metrics[​](#metrics \"Direct link to Metrics\")\n\nMetrics are what your experiments are trying to improve (or at least not hurt).\n\nBelow is an example of all the possible settings with comments:\n\n```\nname: Revenue per User# Required. The data distribution and unittype: revenue # or \"binomial\" or \"count\" or \"duration\"# Required. Must match one of the datasources defined in config.ymldatasource: warehouse# Description supports full markdowndescription: This metric is **super** important# For inverse metrics, the goal is to DECREASE the value (e.g. \"page load time\")inverse: false# When ignoring nulls, only users who convert are included in the denominator# Setting to true here would change from \"Revenue per User\" to \"Average Order Value\"ignoreNulls: false# Which identifier types are supported for this metricuserIdTypes:  - user# Any user with a higher metric amount will be capped at this value# In this case, if someone bought a $10,000 order, it would only be counted as $100# Note: you can also specify `type: percentile` and a `value` between 0 and 1# for percentile based cappingcappingSettings:  type: absolute  value: 100# Control the date window for your metricswindowSettings:  type: conversion  # Ignore all conversions within the first X hours of being put into an experiment.  delayHours: 0  # After the conversion delay (if any), wait this many hours for a conversion event.  windowValue: 72  windowUnit: hours# The risk thresholds for the metric.# If risk < $winRisk, it is highlighted green.# If risk > $loseRisk, it is highlighted red.# Otherwise, it's highlighted yellow.winRisk: 0.0025loseRisk: 0.0125# Min number of conversions for an experiment variation before we reveal resultsminSampleSize: 150# The \"suspicious\" threshold. If the percent change for a variation is above this,#   we hide the result and label it as suspicious.# Default 0.5 = 50% changemaxPercentChange: 0.50# The minimum change required for a result to considered a win or loss. If the percent# change for a variation is below this threshold, we will consider an otherwise conclusive# test a draw.# Default 0.005 = 0.5% changeminPercentChange: 0.005# Overrides for  Regression Adjustment (CUPED) at the metric level. To enforce these fields# you must set regressionAdjustmentOverride to true.# Leave the settings out of your config file to accept your organization level settings; or# set regressionAdjustmentOverride to false.regressionAdjustmentOverride: trueregressionAdjustmentEnabled: trueregressionAdjustmentDays: 14# Arbitrary tags used to group related metricstags:  - revenue  - core\n```\n\nIn addition to all of those settings, you also need to tell GrowthBook how to query the metric.\n\n#### SQL Data Sources[​](#sql-data-sources-1 \"Direct link to SQL Data Sources\")\n\nFor SQL data sources, you just need to specify a single query. Depending on the other settings, the columns you need to select may differ slightly:\n\n*   `timestamp` - always required\n*   `value` - required unless type is set to \"binomial\"\n\nPlus, you need to select a column for each identifier type the metric supports.\n\nA full example:\n\n```\ntype: durationuserIdTypes:  - user_id  - anonymous_idsql: >  SELECT    created_at as timestamp,    user_id,    anonymous_id,    duration as value  FROM    requests\n```\n\nAnd a simple binomial metric that only supports logged-in users:\n\n```\ntype: binomialuserIdTypes:  - usersql: SELECT user_id, timestamp FROM orders\n```\n\nBy default, if a user has more than 1 non-binomial metric row during an experiment, we sum the values together. You can override this behavior with the `aggregation` setting:\n\n```\ntype: durationuserIdTypes:  - user_idsql: >  SELECT    created_at as timestamp,    user_id,    duration as value  FROM    requestsaggregation: MAX(value) # use MAX instead of the default SUM\n```\n\n#### Mixpanel[​](#mixpanel-2 \"Direct link to Mixpanel\")\n\nFor Mixpanel, instead of SQL we just need some info about what events and properties to use.\n\nHere's a simple binomial metric:\n\n```\ntype: binomial# The event nametable: Purchased\n```\n\nAny metric can have optional conditions as well:\n\n```\ntype: binomial# The event nametable: Purchased# Only include events which pass these conditionsconditions:  - column: category # property    operator: \"=\" # \"=\", \"!=\", \">\", \"<\", \"<=\", \">=\", \"~\", \"!~\"    value: clothing\n```\n\nFor count, duration, and revenue metrics, it will count the number of events per user by default:\n\n```\ntype: count# Event name to counttable: Page views\n```\n\nYou can instead specify a javascript expression for the value of the event. By default, it will sum these values for each user:\n\n```\n# A \"Revenue per user\" metrictype: revenue# The event nametable: Purchases# The metric value that will be summedcolumn: event.properties.grand_total\n```\n\nIf you don't want to sum, you can also provide a custom aggregation method that reduces an array of `values` into a single number (or null). For example, here's a metric that counts the number of unique files downloaded per user\n\n```\ntype: count# The event nametable: PDF Downloads# The \"value\" of the metric (the file name)column: event.properties.filename# The aggregation operation (number of unique values)aggregation: new Set(values).size\n```\n\n#### Allow Creating Metrics in the UI[​](#allow-creating-metrics-in-the-ui \"Direct link to Allow Creating Metrics in the UI\")\n\nBy default, when using `config.yml`, it's not possible to create metrics via the GrowthBook UI. Everything must be done directly in the `config.yml` file.\n\nThere is an optional environment variable you can specify to change this behavior:\n\n```\nALLOW_CREATE_METRICS=true\n```\n\nThis will let you create new metrics via the UI. Metrics defined in `config.yml` will be marked as \"Official\" and not editable, while ones defined via the UI will be editable.\n\n### Dimensions[​](#dimensions \"Direct link to Dimensions\")\n\nDimensions let you drill down into your experiment results. They are currently only supported for SQL data sources.\n\nDimensions only have 4 properties: name, datasource, userIdType, and SQL. The SQL query must return two columns: the identifier type and `value`.\n\nExample:\n\n```\nname: Country# Must match one of the datasources defined in config.ymldatasource: warehouseuserIdType: user_idsql: SELECT user_id, country as value FROM users\n```\n\n### Segments[​](#segments \"Direct link to Segments\")\n\nSegments define important groups of users - for example, \"annual subscribers\" or \"left-handed people from France.\" They are currently only supported for SQL data sources.\n\nSegments only have 4 properties: name, datasource, userIdType, and SQL. The SQL query must return two columns: the identifier type and `date`.\n\nExample:\n\n```\nname: US Page Visitors# Must match one of the datasources defined in config.ymldatasource: warehouseuserIdType: user_idsql: SELECT user_id, timestamp as date FROM pages WHERE country='US'\n```\n\nSegment support for the config.yml was added in February 2023. If you are using the config.yml file and have previously created segments stored in MongoDB, in order to access, you will need to add the environment variable `STORE_SEGMENTS_IN_MONGO` or update your config.yml file to include these segments.\n\n### Organization Settings[​](#organization-settings \"Direct link to Organization Settings\")\n\nIn addition to the above, you can also control some organization settings from `config.yml`.\n\nBelow are all of the currently supported settings:\n\n```\norganization:  settings:    # Enable creating experiments using the Visual Editor (beta).  Default `false`    visualEditorEnabled: true    # Minimum experiment length (in days) when importing past experiments. Default `6`    pastExperimentsMinLength: 3    # Number of days of historical data to use when analyzing metrics    # (must be between 1 and 400, default `90`)    metricAnalysisDays: 90    # The min percent of users exposed to multiple variations in an    # experiment before we start warning you (between 0 and 1, defaults to `0.01`)    multipleExposureMinPercent: 0.01    # Whether Regression Adjustment (CUPED) should be on or off by default how many    # days to use. Can be overridden in your metric definitions if you wish.    regressionAdjustmentEnabled: true    regressionAdjustmentDays: 14    # When we should auto-update experiment results    updateSchedule:      type: stale      hours: 6\n```\n\nThe `updateSchedule` setting has 3 types of values:\n\n*   Never update automatically\n    \n    ```\n    updateSchedule:  type: never\n    ```\n    \n*   Update if data is X hours stale\n    \n    ```\n    updateSchedule:  type: stale  hours: 6\n    ```\n    \n*   Update on a fixed Cron schedule\n    \n    ```\n    updateSchedule:  type: cron  cron: \"0 */6 * * *\"\n    ```",
  "title": "Config.yml | GrowthBook Docs",
  "description": "Adjust the configuration of the GrowthBook platform through Config.yml",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/app/webhooks/sdk-webhooks",
  "markdown": "# SDK Webhooks | GrowthBook Docs\n\nGrowthBook has SDK-based webhooks that trigger a script on your server whenever something changes within GrowthBook which will affect that SDK.\n\n## Adding a Webhook[​](#adding-a-webhook \"Direct link to Adding a Webhook\")\n\nWhen logged into GrowthBook as an admin, navigate to **SDK Connections** .\n\nUnder the SDK Webhooks section you can add a webhook endpoint and select with method you would like to be notified with `POST, PUT, GET, DELETE, PURGE`.\n\nOnce a SDK webhook is created you will be able to view the secret and when the last time it was fired as well as if there was an error.\n\n### VPCs and Firewalls[​](#vpcs-and-firewalls \"Direct link to VPCs and Firewalls\")\n\nIf your webhook endpoint is behind a firewall and you are using GrowthBook Cloud, make sure to whitelist the ip address `52.70.79.40`.\n\n## Verify Signatures[​](#verify-signatures \"Direct link to Verify Signatures\")\n\nSDK Webhook payloads are signed with a shared secret so you can verify they actually came from GrowthBook.\n\n### Standard Webhooks[​](#standard-webhooks \"Direct link to Standard Webhooks\")\n\nWe follow the [Standard Webhooks](https://www.standardwebhooks.com/) specification, so you can use any of their SDKs to verify our webhook signatures.\n\n```\nimport { Webhook } from \"standardwebhooks\"const wh = new Webhook(base64_secret);wh.verify(webhook_body, webhook_headers);\n```\n\n### Custom Verification[​](#custom-verification \"Direct link to Custom Verification\")\n\nWebhook requests sent to your endpoint include 3 headers:\n\n*   `webhook-id` - The unique id for this event\n*   `webhook-timestamp` - The unix integer timestamp of the event\n*   `webhook-signature` - The signature (format described below)\n\nTo create the signature, we concatenate the `webhook-id`, the `webhook-timestamp`, and the body contents, all separated by dots (`.`). Then, we create an HMAC SHA-256 hash of this using the shared secret.\n\nWhat we set in the `webhook-signature` header is the hashing algorithm identifier for HMAC SHA-256 (`v1`), followed by a comma (`,`), followed by the base64-encoded hash from above. For example:\n\n```\nv1,K5oZfzN95Z9UVu1EsfQmfVNQhnkZ2pj9o9NDN/H/pI4=\n```\n\nYou can find the shared secret via **SDK Configuration → SDK Connections**, choosing the connection, and viewing your webhook's details.\n\nHere is example code in NodeJS for verifying the signature. Other languages should be similar:\n\n```\nconst crypto = require(\"crypto\");const express = require(\"express\");const bodyParser = require(\"body-parser\");// Retrieve from GrowthBook SDK connection settingsconst GROWTHBOOK_WEBHOOK_SECRET = \"wk_123A5341464B3A13\";const port = 1337;const app = express();app.post(  \"/webhook\",  bodyParser.raw({ type: \"application/json\" }),  (req, res) => {    // If there is no body sent, use an empty string to compute the signature    const body = req.body || \"\";    // Get the request headers    const id = req.get(\"webhook-id\");    const timestamp = req.get(\"webhook-timestamp\");    const rawSignature = req.get(\"webhook-signature\") || \"\";    // Remove the \"v1,\" prefix from the signature for comparison    const signature = rawSignature.split(\",\")[1];    if (id && timestamp && signature) {      // Base64 encode the secret      const base64_secret = btoa(GROWTHBOOK_WEBHOOK_SECRET);      // Compute the signature      const computed = crypto        .createHmac(\"sha256\", base64_secret)        .update(`${id}.${timestamp}.${body}`)        .digest(\"base64\");      if (!crypto.timingSafeEqual(Buffer.from(computed), Buffer.from(signature))) {        throw new Error(\"Invalid signature\");      }    } else {      throw new Error(\"Missing signature headers\");    }    const parsedBody = JSON.parse(body);    const payload = parsedBody.data.payload;    // TODO: Do something with the webhook data    // Make sure to respond with a 200 status code    res.status(200).send(\"\");  });app.listen(port, () => {  console.log(`Webhook endpoint listening on port ${port}`);});\n```\n\n## Errors and Retries[​](#errors-and-retries \"Direct link to Errors and Retries\")\n\nIf your endpoint returns any HTTP status besides `200`, the webhook will be considered failed.\n\nWebhooks are retried up to 2 additional times with an exponential back-off between attempts.\n\nYou can view the status of your webhooks in the GrowthBook app under **SDK Connections**.\n\n## Supported HTTP Methods[​](#supported-http-methods \"Direct link to Supported HTTP Methods\")\n\n*   **GET**\n*   **POST**\n*   **PUT**\n*   **DELETE**\n*   **PURGE**\n\n## Payload Format[​](#payload-format \"Direct link to Payload Format\")\n\nFor all methods other than `GET`, you may send a payload body. By default, webhooks will send in the \"Standard\" format.\n\n### Standard[​](#standard \"Direct link to Standard\")\n\nFollows the **Standard Webhooks** specification. Inludes a JSON-encoded SDK Payload in the `data.payload` field.\n\nExample payload:\n\n```\n{  \"type\": \"payload.changed\",  \"timestamp\": \"2024-04-03T01:54:20.449Z\",  \"data\": {    \"payload\": \"{\\\"features\\\":{\\\"my-feature\\\":{\\\"defaultValue\\\":true}}}\"  }}\n```\n\nThe `data.payload` object contains the exact JSON format that our SDKs are expecting. For example, you can pass this directly into the JavaScript SDK:\n\n```\nconst payload = JSON.parse(parsedBody.data.payload);const gb = new GrowthBook();await gb.init({  payload: payload});\n```\n\n### Standard (no SDK Payload)[​](#standard-no-sdk-payload \"Direct link to Standard (no SDK Payload)\")\n\nSame as above, but without the `data.payload` field.\n\nExample payload:\n\n```\n{  \"type\": \"payload.changed\",  \"timestamp\": \"2024-04-03T01:54:20.449Z\",}\n```\n\n### SDK Payload[​](#sdk-payload \"Direct link to SDK Payload\")\n\nSends the raw SDK Payload using the same format as our SDK features endpoint. This is usually the correct format if you are using the webhook to set a cache value or assigning key/value storage.\n\nExample payload:\n\n```\n{\"features\":{\"my-feature\":{\"defaultValue\":true}}}\n```",
  "title": "SDK Webhooks | GrowthBook Docs",
  "description": "SDK Webhooks trigger every time your SDK Payload changes.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/app/webhooks/global-sdk-webhooks",
  "markdown": "# Global SDK Webhooks | GrowthBook Docs\n\nnote\n\nGlobal SDK Webhooks are only available for self-hosted GrowthBook installations.\n\nGlobal SDK Webhooks are just like [SDK Webhooks](https://docs.growthbook.io/app/webhooks/sdk-webhooks), but configured via environment variables instead of the GrowthBook UI.\n\nWhen any SDK Connection payloads changes in any organization, all of your Global SDK Webhooks will be triggered.\n\n## Setup[​](#setup \"Direct link to Setup\")\n\nDefine a `WEBHOOKS` environment variable as a JSON string of an array of global webhook objects.\n\nThe only required field for a global webhook is **`url`**. Here's a minimal example:\n\n```\n[{\"url\":\"https://example.com\"}]\n```\n\nThere are additional fields you can specify:\n\n*   **`signingKey`** (string) - Will be used to add a signature header that enables you to verify the webhook origin\n*   **`method`** (string) - One of `GET`, `PUT`, `POST`, `PURGE`, or `DELETE`. Defaults to `POST` if omitted\n*   **`headers`** (object) - Additional headers to add to the webhook request. Useful for adding auth headers for example. Default `{}`.\n*   **`payloadFormat`** (string) - How to format the body (ignored when method = \"GET\"). One of `standard`, `standard-no-payload`, `sdkPayload` or `none`. Defaults to `standard`. Read more about the different formats in the SDK Webhooks [Payload Format docs](https://docs.growthbook.io/app/webhooks/sdk-webhooks#payload-format).\n\n_Deprecated:_\n\n*   **`sendPayload`** (boolean) - Whether or not to include the full SDK Payload in the body. `true` maps to `payloadFormat = standard`; false maps to `payloadFormat = standard-no-payload`.\n\nHere's a full example using all of the fields:\n\n```\n[{\"url\":\"https://example.com\",\"signingKey\":\"abc123\",\"method\":\"PUT\",\"headers\":{\"X-Custom-Header\":\"foo\"},\"payloadFormat\":\"sdkPayload\"}]\n```\n\n## Verify Signatures[​](#verify-signatures \"Direct link to Verify Signatures\")\n\nIf you define a `signingKey`, you can use it to verify that webhooks are coming from GrowthBook.\n\n**See: [SDK Webhooks - Verify Signatures](https://docs.growthbook.io/app/webhooks/sdk-webhooks#verify-signatures)**\n\n## Using Webhook Payloads[​](#using-webhook-payloads \"Direct link to Using Webhook Payloads\")\n\nGlobal SDK Webhooks always include a special header (`webhook-sdk-key`), which contains the clientKey of the SDK Connection that triggered the payload.\n\nIf you specify `sendPayload: true`, you will also receive an SDK payload in the body. See [SDK Webhooks -> Sending Payload](https://docs.growthbook.io/app/webhooks/sdk-webhooks#sending-payload)\n\n## Errors and Retries[​](#errors-and-retries \"Direct link to Errors and Retries\")\n\nUnlike normal SDK Webhooks, Global SDK Webhooks are NOT retried on error.\n\nOn failure, they will output container logs as well as save them to the Mongo `sdkwebhooklogs` collection.",
  "title": "Global SDK Webhooks | GrowthBook Docs",
  "description": "Global SDK Webhooks capture SDK Payload changes across all SDK Connections.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/self-host/production",
  "markdown": "# Production | GrowthBook Docs\n\n## Production Best Practices\n\nWhen properly configured, a self-hosted GrowthBook deployment can scale to billions of requests per month.\n\nThe default settings in the `docker-compose` file are meant to get you up and running quickly on a local dev machine. There are a few things to keep in mind when deploying GrowthBook securely at scale in production.\n\n## Security[​](#security \"Direct link to Security\")\n\nThere are a number of best practices to keep your GrowthBook deployment secure.\n\n### Encryption Keys and Secrets[​](#encryption-keys-and-secrets \"Direct link to Encryption Keys and Secrets\")\n\nFirst, make sure you pick long, random strings for your encryption keys and secrets. Specifically, there are 3 environment variables that need to be configured:\n\n*   **NODE\\_ENV** - Set to `production` to turn on additional security checks and logging\n*   **JWT\\_SECRET** - Auth signing key (use a long random string)\n*   **ENCRYPTION\\_KEY** - Data source credential encryption key (use a long random string)\n\nIf you change the `ENCRYPTION_KEY`, you will need to migrate any existing data sources using the following script:\n\n```\n# If you didn't have an ENCRYPTION_KEY before, leave OLD_KEY blank belowdocker-compose run growthbook yarn migrate-encryption-key OLD_KEY\n```\n\n### Networking[​](#networking \"Direct link to Networking\")\n\nThe most secure thing you can do is to put your entire GrowthBook deployment behind a firewall and/or corporate VPN. This way, you can restrict access to only those who need to sign into the GrowthBook platform. This can drastically reduce the attack vector and serves as an important first layer of security.\n\nIf you are using GrowthBook to serve feature flags to client-side apps, you will need some way for your end users to download the feature flag payload outside of the firewall or VPN. There are a few secure approaches for this:\n\n1.  Use a [**GrowthBook Proxy**](https://docs.growthbook.io/self-host/proxy) server. This way, your main GrowthBook instance can remain on a private subnet and only the Proxy needs to be exposed to the internet. The Proxy has a very small attack surface compared to the full GrowthBook app.\n2.  Use a **CDN**. If you go this route, it's very important to only allow requests to the `/api/features/*` endpoint in your CDN. If you allow access to other endpoints (e.g. `/auth/*` or other API routes) you lose many of the benefits of a Firewall or VPN.\n3.  Use **SDK Webhooks** to send your feature payload to a publically accessible place (e.g. a public S3 bucket). This switches GrowthBook from a \"pull\" model to a \"push\" model and you no longer need to allow any incoming requests from users at all.\n\n### Authentication and Permissions[​](#authentication-and-permissions \"Direct link to Authentication and Permissions\")\n\nFor our Enterprise customers, we recommend using [SSO](https://docs.growthbook.io/sso) and [SCIM](https://docs.growthbook.io/integrations/scim) to authenticate with GrowthBook and manage permissions. This offloads access control and management to your existing identity management infrastructure and further reduces the possible attack surface.\n\nNo matter which authentication method you use, it's best to follow the **least access** principle. Admins can invite other users and grant permissions, so restrict this role to only the people who really need it. Read more about [permissions](https://docs.growthbook.io/account/user-permissions).\n\nWhen using our REST API, it's best to use **readonly** API keys when possible. When you need write access, using **Personal Access Tokens** is best since it inherits the permissions of the user who created it. Only use admin Secret Access Tokens as a last resort.\n\n### MongoDB[​](#mongodb \"Direct link to MongoDB\")\n\nSecuring MongoDB in production is its own topic entirely and outside the scope of GrowthBook. We recommend using a hosted solution such as [MongoDB Atlas](https://www.mongodb.com/atlas/database), which is secure by default.\n\nIf you do want to host MongoDB yourself in production, they have a [detailed guide](https://www.mongodb.com/docs/manual/administration/production-notes/) on their docs.\n\n## Email SMTP Settings[​](#email-smtp-settings \"Direct link to Email SMTP Settings\")\n\nConfiguring email is required in order to send experiment alerts, team member invites, and reset password emails.\n\n*   **EMAIL\\_ENABLED** (\"true\" or \"false\")\n*   **EMAIL\\_HOST**\n*   **EMAIL\\_PORT**\n*   **EMAIL\\_HOST\\_USER**\n*   **EMAIL\\_HOST\\_PASSWORD**\n*   **EMAIL\\_FROM**\n\n## File Uploads[​](#file-uploads \"Direct link to File Uploads\")\n\nGrowthBook lets users add Markdown comments throughout the app and these support image uploads.\n\nThe **UPLOAD\\_METHOD** environment variable controls where to store uploaded files and screenshots. The supported values are `local`, `s3`, and `google-cloud`.\n\n### local[​](#local \"Direct link to local\")\n\nThis is the default value. Uploads are stored in the GrowthBook docker container at `/usr/local/src/app/packages/back-end/uploads`. In production, you should mount a shared volume here to persist uploads across container restarts and ensure your horizontally scaled GrowthBook instances all share the same uploads directory.\n\n### s3[​](#s3 \"Direct link to s3\")\n\nStore uploads in an AWS S3 bucket.\n\n*   **S3\\_BUCKET**\n*   **S3\\_REGION** (defaults to `us-east-1`)\n*   **S3\\_DOMAIN** (defaults to `https://${S3_BUCKET}.s3.amazonaws.com/`)\n*   **AWS\\_ACCESS\\_KEY\\_ID** (not required when deployed to AWS with an instance role)\n*   **AWS\\_SECRET\\_ACCESS\\_KEY** (not required when deployed to AWS with an instance role)\n*   **USE\\_FILE\\_PROXY** set this to true for access to uploads to proxy through your self hosted server allowing you to keep the bucket private.\n\n### google-cloud[​](#google-cloud \"Direct link to google-cloud\")\n\nStore uploads in a Google Cloud Storage bucket.\n\n*   **GCS\\_BUCKET\\_NAME**\n*   **GCS\\_DOMAIN** (defaults to `https://storage.googleapis.com/${GCS_BUCKET_NAME}/`)\n*   **GOOGLE\\_APPLICATION\\_CREDENTIALS** (not required when deployed to GCP with an instance service account)\n*   **USE\\_FILE\\_PROXY** set this to true for access to uploads to proxy through your self hosted server allowing you to keep the bucket private.\n\n## Scaling[​](#scaling \"Direct link to Scaling\")\n\nGrowthBook instances are stateless and can be horizontally scaled behind a load balancer. We recommend each instance have at least 2GB of RAM and 1vCPU. You should run at least 3 instances at a time for maximum fault tolerance.\n\n### Serving Feature Flags[​](#serving-feature-flags \"Direct link to Serving Feature Flags\")\n\nHitting the GrowthBook instance directly from our SDKs can work fine at a small scale, but we recommend an additional layer for added scalability and fault tolerance. There are a few options for this:\n\n1.  Use a [**GrowthBook Proxy**](https://docs.growthbook.io/self-host/proxy) server. Each Proxy Server instance can easily handle thousands of requests per second. We recommend horizontally scaling these instances and configuring Redis to keep them in sync.\n    \n2.  Use a **CDN** in front of the `/api/features/*` endpoints. The response from GrowthBook contains cache headers by default that most CDNs will recognize without any custom configuration. You can tweak these cache settings with the following environment variables (all in seconds):\n    \n    *   `CACHE_CONTROL_MAX_AGE` (default `30`)\n    *   `CACHE_CONTROL_STALE_WHILE_REVALIDATE` (default `3600` = 1 hour)\n    *   `CACHE_CONTROL_STALE_IF_ERROR` (default `36000` = 10 hours)\n3.  Use **SDK Webhooks** to send your feature payload to a publically accessible place (e.g. an S3 bucket) and point the SDKs there instead. This bypasses the issue by switching GrowthBook from a \"pull\" model to a \"push\" model.\n    \n\n## Observability and Logging[​](#observability-and-logging \"Direct link to Observability and Logging\")\n\nThe GrowthBook API is instrumented with OpenTelemetry to publish observability metrics, traces, and logs.\n\nTo enable, you must change the Docker CMD from the default `yarn start` to `yarn start:with-tracing`.\n\nThe standard [OTEL\\_\\* Environment Variables](https://opentelemetry.io/docs/concepts/sdk-configuration/) are supported, such as `OTEL_SERVICE_NAME` and `OTEL_EXPORTER_OTLP_ENDPOINT`.\n\nIn addition to this, make sure to configure the **EXPRESS\\_TRUST\\_PROXY\\_OPTS** environment variable. It supports boolean (true/false), string values, and integer values for trusting the _n_th hop from the front-facing proxy server as the client. Leavy empty or specify `false` to use Express' default behavior. If you are running GrowthBook behind a proxy or load balancer, this is required to track the correct user IP for audit log events. Read more about this setting in [Express' documentation](https://expressjs.com/en/5x/api.html#trust.proxy.options.table).",
  "title": "Production | GrowthBook Docs",
  "description": "Best practices for running self-hosted GrowthBook securely at scale",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/app/webhooks/event-webhooks",
  "markdown": "# Event Webhooks | GrowthBook Docs\n\nGrowthBook has event-based webhooks that trigger a script on your server whenever something changes within GrowthBook.\n\n## Adding a Webhook[​](#adding-a-webhook \"Direct link to Adding a Webhook\")\n\nWhen logged into GrowthBook as an admin, navigate to **Settings → Webhooks**.\n\nThere you can add a webhook endpoint and select which events you want to be notified about.\n\n## Supported Event Types[​](#supported-event-types \"Direct link to Supported Event Types\")\n\nWe currently support the following event types:\n\n*   **feature.created**\n*   **feature.updated**\n*   **feature.deleted**\n*   **experiment.created**\n*   **experiment.updated**\n*   **experiment.deleted**\n*   **experiment.warning**\n\nThe new webhooks are still in beta and we are always updating the list of supported events.\n\n## HTTP parameters[​](#http-parameters \"Direct link to HTTP parameters\")\n\nWhen creating or updating a webhook, you can select which HTTP method should be used. Available methods are: `POST`, `PUT` or `PATCH`.\n\nYou can also add your own custom headers. The format of custom headers is a JSON object of the form:\n\n```\n{  [Header-Name]: \"Header Value\",  ...}\n```\n\n## Slack notifications[​](#slack-notifications \"Direct link to Slack notifications\")\n\nWebhooks can be used to send notifications to slack channels and users with much less overhead than setting up a whole slack integration!\n\nFirst, you need to follow the instruction from the [slack documentation](https://api.slack.com/messaging/webhooks) to setup your own slack application and webhooks.\n\nOnce you have setup your application on slack, you should be able to copy the application's webhook endpoint. You can then paste it as the endpoint URL of your webhook configuration on GrowthBook.\n\nNext, select the `Slack` payload. That's it, your endpoint is ready to send Slack notifications!\n\n## Discord notifications[​](#discord-notifications \"Direct link to Discord notifications\")\n\nDiscord notifications work the same way as Slack notifications. The only difference is that you need to follow the [discord documentation](https://support.discord.com/hc/en-us/articles/228383668-Intro-to-Webhooks) on how to setup webhook for your discord server.\n\nYou can select which notifications should be sent to your webhook according to projects, tags or environments. When set, your webhook will only fire when events associated with the selected items are triggered. If unset, you webhook will fire on all events regardless of the given item.\n\nFor instance, if your webhook is configured to fire on `feature.created` events with `Project Apollo` as a project filter, only `feature.created` events related to `Project Apollo` (and any other selected project) will trigger your webhook. If the projects filter is empty, your webhook will fire for all `feature.created` events on any project.\n\n## Testing your webhook[​](#testing-your-webhook \"Direct link to Testing your webhook\")\n\nOnce your webhook is configured, you should be able to test it! Look for the `Test` button on the webhook's settings page. When clicked, a test event should be delivered to the configured endpoint.\n\nThis can be quite helpful to debug and confirm that all the webhook's parameters have been set correctly.\n\n## Examples[​](#examples \"Direct link to Examples\")\n\n*   [Web hooks implementation example](https://github.com/growthbook/examples/tree/main/webhooks-impl)\n\n## Errors and Retries[​](#errors-and-retries \"Direct link to Errors and Retries\")\n\nIf your endpoint returns any HTTP status besides `200`, the webhook will be considered failed.\n\nFailed webhooks are tried a total of 3 times using an exponential back-off between attempts.\n\nYou can view the status of your webhooks in the GrowthBook app under **Settings → Webhooks**.\n\n### VPCs and Firewalls[​](#vpcs-and-firewalls \"Direct link to VPCs and Firewalls\")\n\nIf your webhook endpoint is behind a firewall and you are using GrowthBook Cloud, make sure to whitelist the ip address `52.70.79.40`.\n\n## Verify Signatures[​](#verify-signatures \"Direct link to Verify Signatures\")\n\nWebhook payloads are signed with a shared secret so you can verify they actually came from GrowthBook. The signature is passed in a `X-GrowthBook-Signature` header.\n\nYou can find the signature of a given webhook on its settings page. Look for a random string starting with `ewhk_...`.\n\nHere is example code in NodeJS for verifying the signature. Other languages should be similar:\n\n```\nconst crypto = require(\"crypto\");const express = require(\"express\");const bodyParser = require(\"body-parser\");// Retrieve from GrowthBook settingsconst GROWTHBOOK_WEBHOOK_SECRET = \"abc123\";const port = 1337;const app = express();app.post(  \"/webhook\",  bodyParser.raw({ type: \"application/json\" }),  (req, res) => {    const payload = req.body;    const sig = req.get(\"X-GrowthBook-Signature\");    const computed = crypto      .createHmac(\"sha256\", GROWTHBOOK_WEBHOOK_SECRET)      .update(req.body)      .digest(\"hex\");    if (!crypto.timingSafeEqual(Buffer.from(computed), Buffer.from(sig))) {      throw new Error(\"Signatures do not match!\");    }    const data = JSON.parse(payload);    // TODO: Do something with the webhook data    // Make sure to respond with a 200 status code    res.status(200).send(\"\");  });app.listen(port, () => {  console.log(`Webhook endpoint listening on port ${port}`);});\n```\n\n## SDK Webhooks (deprecated)[​](#sdk-webhooks-deprecated \"Direct link to SDK Webhooks (deprecated)\")\n\nGrowthBook has another type of webhook, meant specifically to keep SDKs up-to-date with the latest feature flag states. These have been deprecated in favor of SDK Connections and the GrowthBook Proxy Server. The payload for these legacy webhooks are described below for reference.\n\n### Payload[​](#payload \"Direct link to Payload\")\n\nSDK Webhooks will do a `POST` to the endpoint you provide. The body is a JSON object containing feature definitions in the same format that SDKs are expecting.\n\nHere's an example payload:\n\n```\n{  \"timestamp\": 1625098156,  \"features\": {    \"feature1\": {      \"defaultValue\": true    }  }}\n```\n\nThe `features` field has one entry per feature definition. Features can have the following properties:\n\n*   **defaultValue**\n*   **rules\\[\\]** - Array of feature rules\n    *   **condition** - A JSON condition using MongoDB query syntax\n    *   **force** - Force a specific value, takes precedence over all other rules besides `condition`\n    *   **variations\\[\\]** - Run an experiment and randomly assign one of the specified variations\n    *   **key** - When running an experiment, this is the experiment key that will be passed to the tracking callback function\n    *   **weights\\[\\]** - Determines how traffic is split between variations in an experiment\n    *   **coverage** - Specifies what sampling rate (0 to 1) to use for including users in an experiment. A rate of `1` means everyone is included. A rate of `0` means no one is.",
  "title": "Event Webhooks | GrowthBook Docs",
  "description": "Event Webhooks to help you update your cache or take other actions when the state changes on GrowthBook",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/integrations/github-metrics",
  "markdown": "# GitHub (Metric Definitions) | GrowthBook Docs\n\n## Use GitHub to Version Control Metric Definitions\n\nThis guide walks through how to make GitHub the source-of-truth of your metric definitions in GrowthBook.\n\n## Setting Up GrowthBook[​](#setting-up-growthbook \"Direct link to Setting Up GrowthBook\")\n\nFor this guide, you can either use GrowthBook Cloud at [https://app.growthbook.io](https://app.growthbook.io/) or your own self-hosted deployment.\n\n### Connect to a Data Source[​](#connect-to-a-data-source \"Direct link to Connect to a Data Source\")\n\nThe easiest way to start is to use the built-in sample data in GrowthBook. Go to **Experiments** and in the Setup Steps, select the **View Sample Experiment** option. This will connect to a sample Postgres database and create a few sample metrics and an experiment.\n\nIf you have your own data warehouse, you can use that instead, but you will have to change the SQL queries further in this guide to match your specific data structure.\n\nAfter connecting, you will need to find the data source id. The easiest way to find this is to go to **Metrics and Data** → **Data Sources**, click into the data source and copy the id from the last part of the URL. It will start with `ds_`, for example `ds_abc123`. Keep note of this id since you will need it later.\n\n### Create an API Key[​](#create-an-api-key \"Direct link to Create an API Key\")\n\nGo to **Settings** → **API Keys** and click to create a new Secret Key. Make sure to select the \"Admin\" role since we will need to use it to create metrics.\n\nKeep note of this key (it will start with `secret_admin_`), you will need it later.\n\n## Setting up GitHub[​](#setting-up-github \"Direct link to Setting up GitHub\")\n\nFirst, create an empty GitHub repository. This is where we will define our metrics.\n\n### Create a `metrics.yml` File[​](#create-a-metricsyml-file \"Direct link to create-a-metricsyml-file\")\n\nTo keep things simple, we will store all of our metric definitions in a single YAML file.\n\nWe're going to use Fact Tables to define our metrics. This lets us write SQL once and re-use that across multiple metric definitions. We will create a single Fact Table for `orders` and 2 metrics - `purchased` and `revenue`.\n\nnote\n\nThe format we're using below exactly matches what the GrowthBook API expects. If you want to store metrics in a different format, you will need to transform it first before sending to GrowthBook.\n\nCreate a new file in your GitHub repository called `metrics.yml` with the following contents. Replace `ds_abc123` with the id of your actual data source that you noted earlier.\n\n```\nfactTables:  - id: orders    data:      name: Orders      datasource: ds_abc123      userIdTypes:        - user_id      sql: >        SELECT          userId as user_id,          amount,          received_at as timestamp        FROM ordersfactMetrics:  - id: purchased    data:      name: Purchased      metricType: proportion      numerator:        factTableId: orders  - id: revenue    data:      name: Revenue      metricType: mean      numerator:        factTableId: orders        column: amount\n```\n\n### Creating a Helper Script[​](#creating-a-helper-script \"Direct link to Creating a Helper Script\")\n\nCreate a file named `growthbook_sync.mjs` in your repo with the following contents (make sure to use the `mjs` extension). If you are self-hosting GrowthBook, replace `https://api.growthbook.io` with your self-hosted API host.\n\n```\nimport { parse } from \"yaml\";import fs from \"fs\";// Edit these constants as neededconst FILE_NAME = 'metrics.yml';const API_HOST = 'https://api.growthbook.io';const GB_API_KEY = process.env.GB_API_KEY;// Parse the yaml fileconst file = fs.readFileSync(FILE_NAME, 'utf8');const json = parse(file);// Send to GrowthBookconst res = await fetch(`${API_HOST}/api/v1/bulk-import/facts`, {  method: \"POST\",  headers: {    'Content-Type': 'application/json',    'Authorization': `Bearer ${GB_API_KEY}`  },  body: JSON.stringify(json)});// Handle errors and print the responseconst resJson = await res.json();if (!res.ok) throw new Error(resJson?.message || \"Error syncing\");console.log(\"Success!\", resJson);\n```\n\nThis script does 3 things:\n\n1.  Parse the `metrics.yml` file into JSON\n2.  Send this payload to the GrowthBook API's `/bulk-import/facts` endpoint\n3.  Handle errors and print the response for easier debugging if things go wrong\n\n### Create a GitHub Secret[​](#create-a-github-secret \"Direct link to Create a GitHub Secret\")\n\nThe script above follows best practices by using environment variables to store secrets. For this to work, you need to add a secret to GitHub.\n\nIn your GitHub repository settings, create a new secret called `GB_API_KEY` and for the value, use the API Key you noted earlier (starting with `secret_admin_`).\n\n### Set up GitHub Actions[​](#set-up-github-actions \"Direct link to Set up GitHub Actions\")\n\nWe want the script above to run every time the `metrics.yml` file changes. We can do this using GitHub Actions.\n\nCreate a file in your repository named `.github/workflows/growthbook_sync.yml` with the following contents:\n\n```\nname: Sync to GrowthBookon:  push:    branches:      - mainjobs:  growthbook_sync:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - uses: actions/setup-node@v4        with:          node-version: 20.x      - name: Sync to GrowthBook        run: |          npm install yaml          GB_API_KEY=\"${{secrets.GB_API_KEY}}\" node growthbook_sync.mjs\n```\n\n## Testing it Out[​](#testing-it-out \"Direct link to Testing it Out\")\n\nAfter comitting the above files to your GitHub repo, it should run automatically and you should see your new Orders fact table and 2 new metrics within your GrowthBook account. If it didn't work, look at the output of your GitHub Action to see if there are any error messages.\n\n### Making Changes[​](#making-changes \"Direct link to Making Changes\")\n\nFact Tables and Metrics created via this `bulk-import` endpoint are marked as \"Official\" by default. This means they cannot be edited from within the GrowthBook UI and must be changed within GitHub instead. This helps avoid things getting out-of-sync.\n\nnote\n\nYou can still use the GrowthBook UI to create or edit other fact tables and metrics. Only \"Official\" ones created through this `bulk-import` endpoint will be locked down.\n\nLet's try updating the `metrics.yml` file, maybe by adding a description to the Purchased metric:\n\n```\n# ...    data:      name: Purchased      description: Percent of people who purchased something      metricType: proportion# ...\n```\n\nCommit this change to your `main` branch and GrowthBook's copy of this metric will be updated to match, usually within 30 seconds!\n\n## Next Steps[​](#next-steps \"Direct link to Next Steps\")\n\nRead the API Docs on the [bulk-import/facts endpoint](https://docs.growthbook.io/api#tag/fact-tables/operation/postBulkImportFacts) to see all of the options and fields you can use in your `metrics.yml` file.",
  "title": "GitHub (Metric Definitions) | GrowthBook Docs",
  "description": "Store metric definitions in GitHub and automatically sync them to GrowthBook",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/integrations/datadog",
  "markdown": "# Integrate DataDog with GrowthBook Feature Flag Data\n\nBy harnessing the power of DataDog's monitoring and alerting capabilities, along with GrowthBook's powerful REST API, you can create a dynamic system that automatically toggles GrowthBook Feature Flags when error thresholds surpass predefined thresholds.\n\n## Setup Instructions[​](#setup-instructions \"Direct link to Setup Instructions\")\n\n### 1\\. Instrument DataDog with Feature Flag Data[​](#1-instrument-datadog-with-feature-flag-data \"Direct link to 1. Instrument DataDog with Feature Flag Data\")\n\nDataDog has a number of products that can be used to monitor applications. For this example, we'll focus on how to integrate GrowthBook with [DataDog RUM](https://www.datadoghq.com/product/real-user-monitoring/).\n\nTo get started, you'll first need to instrument DataDog's RUM with their beta [Feature Flag Tracking](https://docs.datadoghq.com/real_user_monitoring/feature_flag_tracking/) feature.\n\nWhen initializing `datadogRum` you can add `enableExperimentalFeatures` and pass in `feature_flags` to get access to the beta feature.\n\n```\ndatadogRum.init({  applicationId: \"sample-application-id\",  clientToken: \"sample-client-token\",  site: \"datadoghq.com\",  service: \"demo-app\",  env: \"dev\",  version: \"1.0.0\",  sessionSampleRate: 100,  sessionReplaySampleRate: 100,  trackUserInteractions: true,  trackResources: true,  trackLongTasks: true,  defaultPrivacyLevel: \"mask-user-input\",// This enables the beta feature flag tracking  enableExperimentalFeatures: [\"feature_flags\"],});datadogRum.startSessionReplayRecording();\n```\n\nThen, you can use the `addFeatureFlagEvaluation` method built in to the `datadogRum` package when evaluating GrowthBook Feature Flags.\n\n```\nimport { datadogRum } from \"@datadog/browser-rum\";import { useFeatureIsOn } from \"@growthbook/growthbook-react\";const welcomeMessage = useFeatureIsOn(\"welcome-message\");datadogRum.addFeatureFlagEvaluation(\"welcome-message\", welcomeMessage);\n```\n\nNote\n\nIf you are using [DataDog APM](https://www.datadoghq.com/product/apm/), you can do something similar by adding Feature Flag data to your traces. DataDog then has a helpful guide on how to [Connect Rum & Traces](https://docs.datadoghq.com/real_user_monitoring/connect_rum_and_traces/?tab=browserrum). This route will enable you do have alerts built around both front-end and back-end errors.\n\n### 2\\. Build a DataDog Dashboard & Monitor[​](#2-build-a-datadog-dashboard--monitor \"Direct link to 2. Build a DataDog Dashboard & Monitor\")\n\nNow that you're passing Feature Flag data to DataDog, you can build monitors and alerts when the error rate between Feature Flags variations cross a specific threshold within a pre-defined time period.\n\n![](https://docs.growthbook.io/assets/images/add-feature-flags-to-dashboard-data-dog-212db748d20a3008a257a58a2e423d09.png)\n\nThe beta Feature Flag Tracking feature allows you to see error rates between the various feature flag states.\n\n![](https://docs.growthbook.io/assets/images/view-feature-flags-error-rates-in-data-dog-d84ee12339692a3b057dd230eb87452c.png)\n\nYou can then save the view to a Dashboard.\n\n![](https://docs.growthbook.io/assets/images/add-feature-flags-to-dashboard-data-dog-212db748d20a3008a257a58a2e423d09.png)\n\nFrom the Dashboard, there is a handy “Create Monitor” option that can seed much of the monitor's search query for you.\n\n![](https://docs.growthbook.io/assets/images/create-data-dog-monitor-from-dashboard-50e9cd5976389729cb0d249430f98791.png)\n\nThis is the out-of-the-box search query created from the Create Monitor link above. You could take it a step further and calculate the difference in error rates between the Feature Flag variations (e.g. error rate when the Feature Flag is enabled vs disabled) and use that value as your alert threshold.\n\n![](https://docs.growthbook.io/assets/images/customize-monitor-query-in-data-dog-4fe4e84dd8046621da956d81ff391e58.png)\n\n### 3\\. Build DataDog Webhook[​](#3-build-datadog-webhook \"Direct link to 3. Build DataDog Webhook\")\n\nOnce you've defined a monitor's search query, you can then build an alert that uses DataDog's Webhooks to invokes a serverless function (e.g. AWS Lambda).\n\nBefore you can call a [Webhook](https://docs.datadoghq.com/integrations/webhooks/) via a monitor alert, you'll need to build the Webhook within DataDog.\n\nYou can do that via the Integrations tab.\n\n![](https://docs.growthbook.io/assets/images/create-datadog-webhook-5af9c8923471bc58b50c3b6588b40898.png)\n\nOnce installed, you can build the Webhook that will invoke the serverless function. In this case, it's an AWS Lambda function that is invoked via a [Function URL](https://docs.aws.amazon.com/lambda/latest/dg/urls-invocation.html).\n\n![](https://docs.growthbook.io/assets/images/customize-webhook-to-hit-aws-url-bc065f6c4ee26330266a6c94da7f3a20.png)\n\nNow that you've built the Webhook, you can go back to the monitor alert and instead of emailing a team member, you can configure the alert to call the Webhook.\n\n![](https://docs.growthbook.io/assets/images/update-datadog-alert-to-post-to-webhook-e56f8ce884f9f74b74497ce0f5c2338a.png)\n\n### 4\\. Update Feature Flag via GrowthBook REST API.[​](#4-update-feature-flag-via-growthbook-rest-api \"Direct link to 4. Update Feature Flag via GrowthBook REST API.\")\n\nThe final step is to build a serverless function that hits the GrowthBook REST API endpoint to toggle status of a feature flag.\n\nThe [GrowthBook REST API](https://docs.growthbook.io/api/#tag/features/operation/toggleFeature) endpoint takes a simple POST request with basic HTTP auth and only requires the feature flag ID (the human-readable string), along with the environments you want to update and the new status of the Feature Flag for each environment.",
  "title": "Integrate DataDog with GrowthBook Feature Flag Data | GrowthBook Docs",
  "description": "By harnessing the power of DataDog's monitoring and alerting capabilities, along with GrowthBook&apos;s powerful REST API, you can create a dynamic system that automatically toggles GrowthBook Feature Flags when error thresholds surpass predefined thresholds.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/integrations/discord",
  "markdown": "# Discord integration | GrowthBook Docs\n\nThe GrowthBook Discord integration allows you to receive alerts for the events that you care about in a Discord channel of your choosing.\n\nNew\n\nThe GrowthBook Discord integration is a brand new feature. If you experience any issues, let us know either on [Slack](https://slack.growthbook.io/) or [create an issue](https://github.com/growthbook/growthbook-sdk-java/issues).\n\n## Making A Discord Webhook[​](#making-a-discord-webhook \"Direct link to Making A Discord Webhook\")\n\nThe first step is to create an event webhook on your discord server:\n\n1.  Open your **Server Settings** and head into the **Integrations** tab:\n2.  Click the **Create Webhook** button to create a new webhook!\n\n![](https://docs.growthbook.io/assets/images/discord-new-webhook-249fdd6f8e94bb19f9609ee4aa411ef6.png)\n\nOnce your discord webhook is configured, you can copy its url:\n\n![](https://docs.growthbook.io/assets/images/discord-copy-webhook-url-02ce290558f9f7f9dc6370ca6f88691f.png)\n\n## Add the Discord integration to GrowthBook[​](#add-the-discord-integration-to-growthbook \"Direct link to Add the Discord integration to GrowthBook\")\n\nNext step is to login to the GrowthBook app and visit the **Webhooks** tab under **Settings**, also available [here](https://app.growthbook.io/settings/webhooks). You will need privileges to manage webhooks in order for this menu item to be available.\n\nClick the **Create an Event Webhook** button. You should see a modal pop up with some fields for configuring the Discord notification webhook.\n\n![](https://docs.growthbook.io/assets/images/new-webhook-dca6a6897052dd9ab4911437a959dab1.png)\n\nThen, configure the following:\n\n*   **Name**: The name of the integration. In case you have multiple integrations, this can help you tell them apart. This will also show in the contextual text alongside the alerts.\n*   **Endpoint URL**: Copy and paste the webhook URL provided by your discord app.\n*   **Payload**: Select the `Discord` payload.\n*   **Event filters**: You can optionally filter by events you care about. For example, if you only care about when features are deleted, you can choose `feature.deleted` from the list. If you care about all events, leave this blank.\n*   **Environment filters**: You can optionally choose to filter by environment. For example, if you only want to hear about events that are for the production environment, you can choose `production` from the list. For all environments, leave this blank.\n*   **Project filters**: You can optionally choose to filter by project. For example, if you have a project named \"Onboarding V2\" and you only want to alert for that project, you can choose that project from the projects list. For all projects, leave this blank.\n*   **Tag filters**: You can optionally choose to filter by tag. For all events regardless of tag, leave this blank.\n\nAfter configuring all the fields, press **Create** to save your new Discord notification webhook.\n\nYou can also edit these fields at any point if you make a mistake.\n\n![](https://docs.growthbook.io/assets/images/edit-webhook-05554ff586071e32557f9044ea6aaba6.png)\n\n### Adding more alerts[​](#adding-more-alerts \"Direct link to Adding more alerts\")\n\nIf you'd like to be alerted in another Discord channel, you can add another Incoming Webhook in Discord.\n\nThen, you can create new integrations in the GrowthBook dashboard, specifying all of the same information except adding your new webhook URL.\n\n## Testing your alerts[​](#testing-your-alerts \"Direct link to Testing your alerts\")\n\nYou are now ready to test your alerts. First, you can hit the `Test` button on the webhook settings page. This should trigger a test notification.\n\nNext, perform one of the actions you're watching if you've added Event filters. If you haven't added any event filters, the quickest way to test it's working is to either create a new test feature (then delete it if it's not needed), or toggle an environment on or off for an existing feature.",
  "title": "Discord integration | GrowthBook Docs",
  "description": "The GrowthBook Discord integration allows you to receive alerts for the events that you care about in a Discord channel of your choosing.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/tools/chrome-extension",
  "markdown": "# Chrome Extension | GrowthBook Docs\n\nGrowthBook has a Chrome Extension that integrates with the JavaScript SDK's.\n\nQA and debug feature flags and experiments from GrowthBook's JavaScript SDK's.\n\nYou can [download it from the Chrome Web Store](https://chrome.google.com/webstore/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia) .",
  "title": "Chrome Extension | GrowthBook Docs",
  "description": "GrowthBook's Chrome Extension",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/tools/vscode-extension",
  "markdown": "# Visual Studio Code Extension | GrowthBook Docs\n\nThe GrowthBook Visual Studio Code extension allows you to see your available feature definitions right in VS Code.\n\nIt can be configured to work with your project in under a minute and makes it easier for developers who use VS Code to work with the GrowthBook SDK by making features browsable and conveniently surfacing common actions.\n\nYou [download it from the Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=GrowthBook.growthbook) .",
  "title": "Visual Studio Code Extension | GrowthBook Docs",
  "description": "GrowthBook's Visual Studio Code Extension",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/guide/nextjs-app-router",
  "markdown": "# GrowthBook and Next.js (App Router)\n\nNote: If you are using the older Next.js Pages Router, check out [our dedicated Pages Router guide](https://docs.growthbook.io/guide/nextjs-and-growthbook) instead.\n\nThis document is a guide on how to add GrowthBook feature flags to your Next.js application. It assumes you are starting from scratch, so if you already have a Next.js application, you can skip to step 2.\n\n## 1\\. Create your Next.js App[​](#1-create-your-nextjs-app \"Direct link to 1. Create your Next.js App\")\n\nLet's start by getting a basic Next.js app running:\n\nThen cd into the newly create directory and run:\n\n```\ncd my-appyarn dev -p 4000\n```\n\nNote: Both GrowthBook and Next.js run on port 3000 by default, so we're making our Next.js app use 4000 instead to avoid conflicts.\n\nVisit `http://localhost:4000` and you should see the application running!\n\n## 2\\. GrowthBook Account[​](#2-growthbook-account \"Direct link to 2. GrowthBook Account\")\n\nYou will need a GrowthBook account. You can either run GrowthBook locally or using the cloud hosted GrowthBook at [https://app.growthbook.io](https://app.growthbook.io/). If you are using the GrowthBook cloud, you can skip to step 3. If you are installing it locally, here is the quick start instructions - or you can follow the [self hosting](https://docs.growthbook.io/self-host) instructions.\n\n```\ngit clone https://github.com/growthbook/growthbook.gitcd growthbookdocker-compose up -d\n```\n\nAfter that, visit `http://localhost:3000` and create your first user account.\n\n![GrowthBook Signup Screen](https://docs.growthbook.io/images/guides/nextjs-1-growthbook-signup-screen.jpeg)\n\n## 3\\. Set Environment Variables in your Next.js App[​](#3-set-environment-variables-in-your-nextjs-app \"Direct link to 3. Set Environment Variables in your Next.js App\")\n\nIn GrowthBook, create a new SDK Connection. After doing this, you should see an API Host and Client Key (and a Decryption Key if you enabled encryption).\n\nCreate the file `.env.local` in your Next.js app if it doesn't exist yet and add this info there:\n\n```\nNEXT_PUBLIC_GROWTHBOOK_API_HOST=https://cdn.growthbook.ioNEXT_PUBLIC_GROWTHBOOK_CLIENT_KEY=# Below is only required if you enabled encryptionNEXT_PUBLIC_GROWTHBOOK_DECRYPTION_KEY=\n```\n\n## 4\\. Create a Feature Flag[​](#4-create-a-feature-flag \"Direct link to 4. Create a Feature Flag\")\n\nBack in the GrowthBook application, let's create our first feature flag. Make a simple ON/OFF feature flag with the the key `welcome-message`. Leave the default value set to OFF. We will turn it on in a future step.\n\n![GrowthBook Create Feature](https://docs.growthbook.io/images/guides/nextjs-3-create-feature.png)\n\n## 5\\. Integrate the GrowthBook SDK into our Next.js app[​](#5-integrate-the-growthbook-sdk-into-our-nextjs-app \"Direct link to 5. Integrate the GrowthBook SDK into our Next.js app\")\n\nNext.js App Router uses Server Components by default, so we need to use the GrowthBook JavaScript SDK, not the React SDK (which only works client-side).\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save @growthbook/growthbook\n```\n\nOur Javascript SDK works out-of-the-box with React Server Components, but we can more deeply integrate it with Next.js by creating a small helper function in `app/growthbookServer.ts` with the following contents:\n\n```\n// app/growthbookServer.tsimport { setPolyfills, configureCache } from \"@growthbook/growthbook\";export function configureServerSideGrowthBook() {  // Tag fetch requests so they can be revalidated on demand  setPolyfills({    fetch: (url: string, init: RequestInit) =>      fetch(url, {        ...init,        next: {          // Cache feature definitions for 10 seconds for dev          // In prod, use a higher value and use WebHooks to revalidate on-demand          revalidate: 10,          tags: [\"growthbook\"],        },      }),  });  // Disable the built-in cache since we're using Next.js's fetch cache instead  configureCache({    disableCache: true,  });}\n```\n\nNow, let's modify our main `app/page.tsx` file.\n\nChange the top of the file to match the following:\n\n```\nimport Image from \"next/image\";import { configureServerSideGrowthBook } from \"./growthbookServer\";import { GrowthBook } from \"@growthbook/growthbook\";export default async function Home() {  configureServerSideGrowthBook();  // Create and initialize a GrowthBook instance  const gb = new GrowthBook({    apiHost: process.env.NEXT_PUBLIC_GROWTHBOOK_API_HOST,    clientKey: process.env.NEXT_PUBLIC_GROWTHBOOK_CLIENT_KEY,    decryptionKey: process.env.NEXT_PUBLIC_GROWTHBOOK_DECRYPTION_KEY,  });  await gb.init({ timeout: 1000 });  // Set targeting attributes for the user  // TODO: get from cookies/headers/db  await gb.setAttributes({    id: \"123\",    employee: true,  });  // Evaluate a feature flag  const welcomeMessage = gb.isOn(\"welcome-message\");  // Cleanup  gb.destroy();\n```\n\nNext Steps And now let's use the feature flag we referenced above. Add the following somewhere on the page so we can see it:\n\n```\n<h2>Welcome Message: {welcomeMessage ? \"ON\" : \"OFF\"}</h2>\n```\n\nThis will render as `OFF` for now.\n\n## 6\\. Turn on for your Team[​](#6-turn-on-for-your-team \"Direct link to 6. Turn on for your Team\")\n\nIn our page, we hard-coded `employee: true` when setting our targeting attributes. Let's use that to turn on the feature for just employees.\n\nCreate a Force Rule for your feature:\n\n![GrowthBook Targeting Rule](https://docs.growthbook.io/images/guides/nextjs-4-employee-rule.png)\n\nPublish the draft and refresh your Next.js app and you should now see the welcome message showing up as ON! (Note: it might take a few seconds for the cache to refresh).\n\nIf you change your targeting attribute to `employee: false` in the page, you should see the welcome message switch back to OFF immediately.\n\nThe best part about targeting attributes in GrowthBook is that they are evaluated entirely locally. Sensitive user data is never sent over the network and there is no performance penalty. Some other libraries require an HTTP request to evaluate a feature for a user and this is often a deal breaker for performance.\n\n## 7\\. Gradually roll out to your users[​](#7-gradually-roll-out-to-your-users \"Direct link to 7. Gradually roll out to your users\")\n\nAfter you test the new feature within your team, you probably want to start rolling it out to real users.\n\nWe can do that with another rule in GrowthBook:\n\n![GrowthBook Rollout Rule](https://docs.growthbook.io/images/guides/nextjs-6-rollout-rule.png)\n\nIn the targeting attributes, make sure you set `employee: false`. That will ensure you skip the first rule we made and fall into the second rollout rule.\n\nnote\n\nThe GrowthBook SDK uses deterministic hashing to figure out whether or not someone is included in a rollout (or A/B test). The SDKs hash together the selected targeting attribute (id) and the feature key (welcome-message) and coverts it to a float between 0 and 1. If that float is less than or equal to the rollout percent, the user is included. This ensures a consistent UX and prevents one user from constantly switching between ON and OFF as they navigate your app.\n\nTry changing the id in the targeting attributes to a few different random strings and see what happens. You should notice about half of the time the welcome message will be ON.\n\n## Conclusion and Next Steps[​](#conclusion-and-next-steps \"Direct link to Conclusion and Next Steps\")\n\nWe showed here how to do a targeted rule, and how to do a rollout rule. It's also just as easy to make an A/B test in the same manner. You will need to set up event tracking and connect GrowthBook to your data source.\n\nWe support many different rendering strategies in Next.js, not just server components. Check out our [example Next.js app](https://github.com/growthbook/examples/tree/main/next-js), which demonstrates static rendering, client components, streaming server components, and more.\n\nOnce you do the initial integration work, it only takes a few seconds to wrap your code in feature flags. Once you realize how easy and stress-free deploys and experimentation can be, there's no going back.",
  "title": "GrowthBook and Next.js (App Router) | GrowthBook Docs",
  "description": "This guide walks you through using GrowthBook with Next.js App Router.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/guide/nextjs-and-growthbook",
  "markdown": "# GrowthBook and Next.js (Pages Router)\n\nNote: If you are using the newer Next.js App Router, check out [our dedicated App Router guide](https://docs.growthbook.io/guide/nextjs-app-router) instead.\n\nThis document is a guide on how to add GrowthBook feature flags to your Next.js application. It assumes you are starting from scratch, so if you already have a Next.js application, you can skip to step 2.\n\nHere is a video version similar to the steps below:\n\n## 1\\. Create your Next.js App[​](#1-create-your-nextjs-app \"Direct link to 1. Create your Next.js App\")\n\nLet's start by getting a basic Next.js app running:\n\nThen cd into the newly create directory and run:\n\n```\ncd my-appyarn dev -p 4000\n```\n\nNote: Both GrowthBook and Next.js run on port 3000 by default, so we're making our Next.js app use 4000 instead to avoid conflicts.\n\nVisit `http://localhost:4000` and you should see the application running!\n\n## 2\\. GrowthBook Account[​](#2-growthbook-account \"Direct link to 2. GrowthBook Account\")\n\nYou will need a GrowthBook account. You can either run GrowthBook locally or using the cloud hosted GrowthBook at [https://app.growthbook.io](https://app.growthbook.io/). If you are using the GrowthBook cloud, you can skip to step 3. If you are installing it locally, here is the quick start instructions - or you can follow the [self hosting](https://docs.growthbook.io/self-host) instructions.\n\n```\ngit clone https://github.com/growthbook/growthbook.gitcd growthbookdocker-compose up -d\n```\n\nAfter that, visit `http://localhost:3000` and create your first user account.\n\n![GrowthBook Signup Screen](https://docs.growthbook.io/images/guides/nextjs-1-growthbook-signup-screen.jpeg)\n\n## 3\\. Integrate the GrowthBook React SDK into our Next.js app[​](#3-integrate-the-growthbook-react-sdk-into-our-nextjs-app \"Direct link to 3. Integrate the GrowthBook React SDK into our Next.js app\")\n\nGrowthBook will generate some integration code for you, including a unique SDK Client Key to load your features from.\n\n![GrowthBook Integration Code](https://docs.growthbook.io/images/guides/nextjs-2-feature-flag-key.png)\n\nCreate the file `.env.local` if it doesn't exist yet and add your generated key there:\n\n```\nNEXT_PUBLIC_GROWTHBOOK_API_HOST=https://cdn.growthbook.ioNEXT_PUBLIC_GROWTHBOOK_CLIENT_KEY=# Below is only required if you enabled encryptionNEXT_PUBLIC_GROWTHBOOK_DECRYPTION_KEY=\n```\n\nWe first need to install the GrowthBook React SDK in our Next.js app:\n\n```\nyarn add @growthbook/growthbook-react\n```\n\nThen we can modify the generated React code to work with the Next.js framework. Modify the file `pages/_app.js` with the following contents:\n\n```\nimport \"../styles/globals.css\";import { GrowthBook, GrowthBookProvider } from \"@growthbook/growthbook-react\";import { useEffect } from \"react\";// Create a GrowthBook instanceconst growthbook = new GrowthBook({  apiHost: process.env.NEXT_PUBLIC_GROWTHBOOK_API_HOST,  clientKey: process.env.NEXT_PUBLIC_GROWTHBOOK_CLIENT_KEY,  decryptionKey: process.env.NEXT_PUBLIC_GROWTHBOOK_DECRYPTION_KEY,  trackingCallback: (experiment, result) => {    console.log(\"Viewed Experiment\", {      experimentId: experiment.key,      variationId: result.key    });  },});// Start downloading feature definitionsgrowthbook.init();export default function MyApp({ Component, pageProps, router }) {  // Refresh features and targeting attributes on navigation  useEffect(() => {    gb.setURL(window.location.href);    growthbook.setAttributes({      id: \"123\",      loggedIn: true,      deviceId: \"abcdef123456\",      employee: true,      company: \"acme\",      country: \"US\",      browser: navigator.userAgent,      url: router.pathname,    });  }, [router.pathname]);  return (    <GrowthBookProvider growthbook={growthbook}>      <Component {...pageProps} />    </GrowthBookProvider>  );}\n```\n\nIn a real application, you would pull some of the targeting attributes from your authentication system or an API, but let's just leave them hard-coded for now.\n\n## 4\\. Create a Feature in GrowthBook[​](#4-create-a-feature-in-growthbook \"Direct link to 4. Create a Feature in GrowthBook\")\n\nBack in the GrowthBook application, we can create a new feature. For this tutorial, we'll make a simple on/off feature flag that determines whether or not we show a welcome banner on our site.\n\n![GrowthBook Create Feature](https://docs.growthbook.io/images/guides/nextjs-3-create-feature.png)\n\nThe key we chose (welcome-message) is what we will reference when using the GrowthBook SDK.\n\nWe can now edit `pages/index.js` and conditionally render a welcome message based on the state of the feature:\n\nAdd an import statement:\n\n```\nimport { IfFeatureEnabled } from \"@growthbook/growthbook-react\";\n```\n\nAnd then put your welcome message somewhere on the page:\n\n```\n<IfFeatureEnabled feature=\"welcome-message\">  <p>I hope you enjoy this site and have a great day!</p></IfFeatureEnabled>\n```\n\nIf you refresh your Next.js app, you'll notice the welcome message is not rendered. This is because when creating the feature, we set the default value to off. At this point, we could safely deploy our change to production and not worry about breaking anything.\n\n## 5\\. Turn on the feature for your team[​](#5-turn-on-the-feature-for-your-team \"Direct link to 5. Turn on the feature for your team\")\n\nNow we can add rules to the feature to turn it on for specific groups of users.\n\nIn the hard-coded targeting attributes we set in pages/\\_app.js, we designated ourselves as an internal employee. Let's use this attribute to turn on the feature for the whole internal team:\n\n![GrowthBook Targeting Rule](https://docs.growthbook.io/images/guides/nextjs-4-employee-rule.png)\n\nRefresh your Next.js app and you should now see the welcome message appearing! (Note: it might take up to 30 seconds for the API cache to refresh).\n\n![Next.js app with feature](https://docs.growthbook.io/images/guides/nextjs-5-nextjs-title.png)\n\nIf you change employee to false in pages/\\_app.js, you should see the welcome message disappear.\n\nThe best part about targeting attributes in GrowthBook is that they are evaluated entirely locally. Sensitive user data is never sent over the network and there is no performance penalty. Some other libraries require an HTTP request to evaluate a feature for a user and this is often a deal breaker.\n\n## 6\\. Gradually roll out to your users[​](#6-gradually-roll-out-to-your-users \"Direct link to 6. Gradually roll out to your users\")\n\nAfter you test the new feature within your team, you probably want to start rolling it out to real users.\n\nWe can do that with another rule in GrowthBook:\n\n![GrowthBook Rollout Rule](https://docs.growthbook.io/images/guides/nextjs-6-rollout-rule.png)\n\nIn the targeting attributes in pages/\\_app.js, make sure employee is set to false. That will ensure you skip the first rule we made and fall into the second rollout rule.\n\nnote\n\nThe GrowthBook SDK uses deterministic hashing to figure out whether or not someone is included in a rollout (or A/B test). The SDKs hash together the selected targeting attribute (id) and the feature key (welcome-message) and coverts it to a float between 0 and 1. If that float is less than or equal to the rollout percent, the user is included. This ensures a consistent UX and prevents one user from constantly switching between ON and OFF as they navigate your app.\n\nTry changing the user id in the targeting attributes in `pages/_app.js` to a few different random strings and see what happens. You should notice about half of the time the welcome message shows up and half of the time it doesn't.\n\n## Conclusion and Next Steps[​](#conclusion-and-next-steps \"Direct link to Conclusion and Next Steps\")\n\nWe showed here how to do a targeted rule, and how to do a rollout rule. It's also just as easy to make an A/B test in the same manner. You will need to set up an event tracking and connect GrowthBook to your data source.\n\nYou can look at the [GrowthBook React SDK](https://docs.growthbook.io/lib/react) docs for more ways to use feature flags in your code besides the `<IfFeatureEnabled>` component. Once you do the initial integration work, it only takes a few seconds to wrap your code in feature flags. Once you realize how easy and stress-free deploys and experimentation can be, there's no going back.",
  "title": "GrowthBook and Next.js (Pages Router) | GrowthBook Docs",
  "description": "This guide walks you through using GrowthBook with Next.js Pages Router.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/guide/create-react-app-and-growthbook",
  "markdown": "# GrowthBook and BigQuery | GrowthBook Docs\n\n## GrowthBook and Create React App\n\n## 1\\. Set up Create React App[​](#1-set-up-create-react-app \"Direct link to 1. Set up Create React App\")\n\nCreate React App is simple to get a new project started. This guide does the standard process with one extra command to install the GrowthBook SDK and the nanoid library:\n\n```\nnpx create-react-app my-appcd my-appnpm install --save @growthbook/growthbook-react nanoidnpm start\n```\n\nThen open `http://localhost:3000/` and make sure the app is working\n\n## 2\\. Set up GrowthBook[​](#2-set-up-growthbook \"Direct link to 2. Set up GrowthBook\")\n\nIn this tutorial assume you are using the cloud-hosted version of GrowthBook, which is free for small teams, but you can also use the open source version and host it yourself if you prefer.\n\nnote\n\nGrowthBook uses the concept of Feature Flagging to run A/B tests. Basically, you wrap the code you want to test in a conditional check\n\nif (feature.on) ...\n\nand then you run an A/B test within GrowthBook to turn the feature on for 50% of users and off for the other 50% (or whatever\n\npercentage you like).\n\nTo start, go to [https://app.growthbook.io](https://app.growthbook.io/) and register a new account. Then there are a couple steps required before you can run an experiment.\n\n## 3\\. Install and configure the SDK[​](#3-install-and-configure-the-sdk \"Direct link to 3. Install and configure the SDK\")\n\nNext, click on Step 1: Install our SDK and you should see API keys for dev/production as well as sample code.\n\nSince you already ran the npm i command at the start, you can skip that part. I'll walk through the different parts below:\n\nFirst, in `src/index.js`, import the GrowthBook SDK and nanoid library:\n\n```\n// ... after existing importsimport { GrowthBook, GrowthBookProvider } from \"@growthbook/growthbook-react\";import { nanoid } from \"nanoid\";\n```\n\nThen you will need to generate an anonymous visitor id, which is used to assign an A/B test variation to a user. In this example we'll persist this id in localStorage so if the user refreshes our app they will get assigned the same variation as before.\n\n```\nlet visitor_id = localStorage.getItem(\"visitor_id\");if (!visitor_id) {  visitor_id = nanoid();  localStorage.setItem(\"visitor_id\", visitor_id);}\n```\n\nThen, you create a GrowthBook instance with our visitor id and a tracking callback when a user is put into an experiment.\n\n```\nconst growthbook = new GrowthBook({  attributes: {    id: visitor_id,  },  trackingCallback: (experiment, result) => {    console.log({      experimentId: experiment.key,      variationId: result.variationId,    });  },});\n```\n\nAfter that, you can fetch the list of features from the GrowthBook API and pass them into the SDK:\n\n```\nconst FEATURES_ENDPOINT = \"https://cdn.growthbook.io/api/features/...\";fetch(FEATURES_ENDPOINT)  .then((res) => res.json())  .then((json) => {    growthbook.setFeatures(json.features);  });\n```\n\nMake sure to swap out the `FEATURES_ENDPOINT` constant above with your own dev API key you see in the GrowthBook application.\n\nLastly, you'll need to wrap the app in a GrowthBookProvider component which will let us run A/B tests from anywhere in the app.\n\n```\nReactDOM.render(<React.StrictMode>  <GrowthBookProvider growthbook={growthbook}>    <App />  </GrowthBookProvider></React.StrictMode>, document.getElementById('root'));\n```\n\n## 4\\. Create and use a feature[​](#4-create-and-use-a-feature \"Direct link to 4. Create and use a feature\")\n\nNow that the SDK is installed and fully integrated in our application, you can finally create the `show-logo` feature.\n\nBack in GrowthBook, Click on Step 2 of the quick start instruction or click on add new feature. Fill in the following info:\n\n*   Feature key: `show-logo`\n*   Dev: toggle on\n*   Prod: toggle off\n*   Value Type: boolean (on/off)\n*   Behavior: A/B Experiment\n*   Tracking Key: `show-logo`\n*   Sample Users based on attribute: `id`\n*   Variations and Weights: leave default (OFF/ON, 50/50 split)\n*   Fallback Value: `OFF`\n\nThere's a lot of fields there, but hopefully it's pretty straight forward what's happening. We setup a new boolean feature called show-logo, that's only enabled in dev and running an A/B test where 50% get ON and 50% get OFF\n\nNow you can switch back to our React app and reference this feature in our code.\n\nIn src/App.js, we currently have the following code:\n\n```\n<img src={logo} className=\"App-logo\" alt=\"logo\" />\n```\n\nLet's add an import at the top of the file:\n\n```\nimport { IfFeatureEnabled } from \"@growthbook/growthbook-react\";\n```\n\nAnd wrap the img element in an IfFeatureEnabled component:\n\n```\n<IfFeatureEnabled feature=\"show-logo\">  <img src={logo} className=\"App-logo\" alt=\"logo\" /></IfFeatureEnabled>\n```\n\nNow, if you refresh your app, the A/B test should be running! If you're part of the lucky 50% that are in the B variation (no logo), it should be pretty obvious. If you happen to be in the A variations, you can verify you're in the test by looking in DevTools for our trackingCallback console.log.\n\nYou can test out different variations by deleting the visitor\\_id from localStorage and refreshing your app. Repeat a few times and you should see each version of the page about half of the time. If you want an easier and faster way to QA the variations, you can download the GrowthBook Chrome DevTools Extension.\n\n## 5\\. Analyze Results[​](#5-analyze-results \"Direct link to 5. Analyze Results\")\n\nBefore you can analyze the results, you will need to connect GrowthBook to the event tracking and a data source. In the trackingCallback in `src/index.js`, instead of doing a `console.log`, you could use [Mixpanel](https://docs.growthbook.io/guide/mixpanel), Rudderstack, Jitsu, Segment or another event tracking system.\n\nThen, throughout your app, you can similarly track events when users do something you care about, like sign up, convert, or buy something.\n\nOnce you do that, GrowthBook can connect to your event tracking system, query the raw data, run it through a stats engine, and show you the results. Follow the directions for the data source you're using.\n\n## Next Steps[​](#next-steps \"Direct link to Next Steps\")\n\nThere's so much more you can do with GrowthBook beyond a simple on/off A/B test...\n\n*   Add complex targeting and override rules for your features\n*   Read the full [React SDK Docs](https://docs.growthbook.io/lib/react) for more details and ways to use feature flags\n*   Install the [Chrome DevTools Extension](https://chrome.google.com/webstore/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia) to test different variations and scenarios\n*   Read about the [powerful statistics engine](https://docs.growthbook.io/statistics/overview) that is used to analyze experiment results.",
  "title": "GrowthBook and BigQuery | GrowthBook Docs",
  "description": "This guide walks you through installing GrowthBook SDK into your Create React App",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/integrations/wordpress",
  "markdown": "# Wordpress Integration | GrowthBook Docs\n\nUnleash the power of experimentation with GrowthBook to supercharge your Wordpress site—no coding skills required!\n\nNote\n\nThis guide walks you through creating experiments using the GrowthBook Visual Editor, which requires a `Pro` subscription. [Learn More](https://www.growthbook.io/pricing).\n\n## Let's Get Started[​](#lets-get-started \"Direct link to Let's Get Started\")\n\n### Step 1: Create a GrowthBook SDK Connection[​](#step-1-create-a-growthbook-sdk-connection \"Direct link to Step 1: Create a GrowthBook SDK Connection\")\n\nTo connect your GrowthBook account to Wordpress, you'll need to create a new SDK Connection and select the `Wordpress` option. Before saving, confirm that you've enabled the toggles for `Include visual experiments in endpoint's response?` and `Include draft experiments`.\n\n![](https://docs.growthbook.io/assets/images/wordpress-sdk-connection-3672690cdd1f8e34628a5b0f731ec595.png)\n\n### Step 2: Add GrowthBook to Your Wordpress Site[​](#step-2-add-growthbook-to-your-wordpress-site \"Direct link to Step 2: Add GrowthBook to Your Wordpress Site\")\n\nOnce the SDK Connection is created, you should see a code snippet that you need to add to your site.\n\nThe easiest way to do this is with the popular [Insert Headers and Footers Plugin](https://wordpress.org/plugins/.insert-headers-and-footers/) by WPCode. Install and activate this plugin if you don't have it already.\n\nOn the left-hand side of your dashboard, navigate to Code Snippets → Header & Footer.\n\nInsert the SDK Connection code snippet into your site's Head:\n\n![Add code to header](https://docs.growthbook.io/assets/images/add-code-to-header-3d9a174e8fba81dcbfebf79f71934473.png)\n\nHere's an example of how it should look:\n\n```\n<script async  data-client-key=\"YOUR_CLIENT_KEY\"  src=\"https://cdn.jsdelivr.net/npm/@growthbook/growthbook/dist/bundles/auto.min.js\"></script>\n```\n\nNote\n\nWhen a user views an experiment, this script will fire an event that tracks which variation the user saw. If you have Google Analytics 4 (GA4) or Segment installed on your site, you don't have to do any additional configuration. If, however, you need to use a different analytics provider, you can follow our guide [here](https://docs.growthbook.io/lib/script-tag).\n\nOnce added, navigate back to GrowthBook.\n\n### Step 3: Install the GrowthBook Chrome Extension[​](#step-3-install-the-growthbook-chrome-extension \"Direct link to Step 3: Install the GrowthBook Chrome Extension\")\n\nThe GrowthBook Chrome Extension allows you to use the Visual Editor to update your Wordpress site's content. It's free, and you can download it [here](https://chromewebstore.google.com/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia).\n\n### Step 4: Create a GrowthBook Visual Editor Experiment[​](#step-4-create-a-growthbook-visual-editor-experiment \"Direct link to Step 4: Create a GrowthBook Visual Editor Experiment\")\n\nNow that GrowthBook is installed on your Wordpress site and you've installed the Chrome Extension, you can create a new experiment using the Visual Editor.\n\nFirst, navigate to \"Experiments\" on the left-hand navigation menu and then click \"Create Experiment\", before selecting \"Design a New Experiment\" and following the on-screen prompts.\n\nOnce you've created your experiment, Add a Visual Editor change and enter the URL of your Wordpress site.\n\nYou'll then be redirected to your site, where you can use the Visual Editor to make changes.",
  "title": "Wordpress Integration | GrowthBook Docs",
  "description": "Unleash the power of experimentation with GrowthBook to supercharge your Wordpress site—no coding skills required!",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/integrations/shopify",
  "markdown": "# Shopify Integration | GrowthBook Docs\n\nUnleash the power of experimentation with GrowthBook to supercharge your Shopify store—no coding skills required!\n\nNote\n\nThis guide walks you through creating experiments using the GrowthBook Visual Editor, which requires a `Pro` subscription. [Learn More](https://www.growthbook.io/pricing).\n\n## Let's Get Started[​](#lets-get-started \"Direct link to Let's Get Started\")\n\n### Step 1: Create a GrowthBook SDK Connection[​](#step-1-create-a-growthbook-sdk-connection \"Direct link to Step 1: Create a GrowthBook SDK Connection\")\n\nTo connect your GrowthBook account to Shopify, you'll need to create a new SDK Connection and select the `Shopify` option. Before saving, confirm that you've enabled the toggles for `Include visual experiments in endpoint's response?` and `Include draft experiments`.\n\n![](https://docs.growthbook.io/assets/images/shopify-sdk-connection-cd28566e1765b63e2677649127df1700.png)\n\n### Step 2: Add GrowthBook to Your Shopify Theme[​](#step-2-add-growthbook-to-your-shopify-theme \"Direct link to Step 2: Add GrowthBook to Your Shopify Theme\")\n\nOnce the SDK Connection is created, you should see a code snippet that you need to add to your store.\n\nLog into your Shopify account, navigate to your online store, and edit your store's code.\n\n![](https://docs.growthbook.io/assets/images/growthbook-shopify-edit-code-f26e82f53104efa715b96662855a70f0.png)\n\nOnce you're in the code editor, locate the `theme.liquid` file and add the snippet exactly as shown just before the closing `</head>` tag. Here's an example of how it should look:\n\n![](https://docs.growthbook.io/assets/images/shopify-theme-editor-01bf614f9426d26f63d9eb765e7dc79b.png)\n\nNote\n\nWhen a user views an experiment, this script will fire an event that tracks which variation the user saw. If you have Google Analytics 4 (GA4) or Segment installed on your store, you don't have to do any additional configuration. If, however, you need to use a different analytics provider, you can follow our guide [here](https://docs.growthbook.io/lib/script-tag).\n\nOnce added, click \"Save\" and navigate back to GrowthBook.\n\n### Step 3: Install the GrowthBook Chrome Extension[​](#step-3-install-the-growthbook-chrome-extension \"Direct link to Step 3: Install the GrowthBook Chrome Extension\")\n\nThe GrowthBook Chrome Extension allows you to use the Visual Editor to update your Shopify store's content. It's free, and you can download it [here](https://chromewebstore.google.com/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia).\n\n### Step 4: Create a GrowthBook Visual Editor Experiment[​](#step-4-create-a-growthbook-visual-editor-experiment \"Direct link to Step 4: Create a GrowthBook Visual Editor Experiment\")\n\nNow that GrowthBook is installed on your Shopify store and you've installed the Chrome Extension, you can create a new experiment using the Visual Editor.\n\nFirst, navigate to \"Experiments\" on the left-hand navigation menu and then click \"Create Experiment\", before selecting \"Design a New Experiment\" and following the on-screen prompts.\n\nOnce you've created your experiment, select \"Visual Editor\" as the editor type and enter the URL of your Shopify store.\n\n![](https://docs.growthbook.io/assets/images/growthbook-shopify-open-visual-editor-f072a9027330bae106caff5a7a062585.png)\n\nYou'll then be redirected to your store, where you can use the Visual Editor to update your store's content.",
  "title": "Shopify Integration | GrowthBook Docs",
  "description": "Unleash the power of experimentation with GrowthBook to supercharge your Shopify store—no coding skills required!",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/guide/rudderstack-and-nextjs-with-growthbook",
  "markdown": "# GrowthBook, Rudderstack, and Next.js | GrowthBook Docs\n\n## A/B Testing with Rudderstack and Next.js\n\nThis document is a guide on how to add GrowthBook feature flags and A/B testing to your existing Next.js application using Rudderstack for event tracking.\n\n## 1\\. Create a GrowthBook Account[​](#1-create-a-growthbook-account \"Direct link to 1. Create a GrowthBook Account\")\n\nYou will need a GrowthBook account. You can either run GrowthBook locally or using the cloud hosted GrowthBook at [https://app.growthbook.io](https://app.growthbook.io/). If you are installing it locally, you can follow the self-hosting quick start instructions here: [self hosting instructions](https://docs.growthbook.io/self-host).\n\n## 2\\. Create a JS source in Rudderstack[​](#2-create-a-js-source-in-rudderstack \"Direct link to 2. Create a JS source in Rudderstack\")\n\nFrom within your Rudderstack account, create a new JS source.\n\n![Add Rudderstack JS source](https://docs.growthbook.io/images/guides/rudderstack-7-create-source.png)\n\nName the source whatever you like, in this example I'm using `GrowthBook JS`. When the source is created, connect it to your BigQuery data warehouse (or whatever destination you're using for GrowthBook experiment data). You can read more about how to connect to your data destination [here](https://docs.growthbook.io/guide/rudderstack).\n\n![Add BigQuery destination](https://docs.growthbook.io/images/guides/rudderstack-8-source-w-destination.png)\n\nOnce you have it connected, copy the write key, as we'll need it for the next step.\n\nUnder connections, you should now see the JS source connected to the BigQuery destination. You will also need the `Data plane URL` which appears near the top of the page.\n\n![Add BigQuery destination](https://docs.growthbook.io/images/guides/rudderstack-9-connected-js.png)\n\n## 3\\. Integrate Rudderstack into your Next.js application[​](#3-integrate-rudderstack-into-your-nextjs-application \"Direct link to 3. Integrate Rudderstack into your Next.js application\")\n\nWhile there is plenty of documentation on how to add Rudderstack to your Next.js application out there, none of those implementations are very Next.js like, and limit the ability of Rudderstack to integrate more deeply into your code- including using GrowthBook. Below is the integration code that we came up with to address these concerns.\n\n### install the Rudderstack Analytics package[​](#install-the-rudderstack-analytics-package \"Direct link to install the Rudderstack Analytics package\")\n\nInstall the javascript SDK for Rudderstack with yarn,\n\nor npm:\n\n```\nnpm install --save rudder-sdk-js\n```\n\n### Create Rudderstack loader[​](#create-rudderstack-loader \"Direct link to Create Rudderstack loader\")\n\nCreate a `rudder.js` file in your Next.js project. This file will load Rudderstack's SDK in a reusable and asynchronous way.\n\n```\nlet rudder;async function getInstance() {  if (!rudder) {    rudder = await import(\"rudder-sdk-js\");    rudder.load(      process.env.NEXT_PUBLIC_RUDDERSTACK_KEY,      process.env.NEXT_PUBLIC_RUDDERSTACK_HOST,      { integrations: { All: true } }    );    await new Promise((resolve) => rudder.ready(resolve));  }  return rudder;}const rudderObj = {  init: getInstance,  track: (...args) => getInstance().then((r) => r.track(...args)),  getAnonymousId: async () => getInstance().then((r) => r.getAnonymousId()),};export default rudderObj;\n```\n\nIf you want to add other methods, like `identify`, you can extend the rudderObj.\n\nYou'll also have to add the Rudderstack Key and Host to your environment variables, or add to your `.env.local` file:\n\n```\nNEXT_PUBLIC_RUDDERSTACK_KEY=<your key>NEXT_PUBLIC_RUDDERSTACK_HOST=https://<rudderstack host>\n```\n\nThe key is the `write key` from the JS source we made in step 2, and the HOST is the `data plane URL`.\n\n### Integrate Rudderstack into your Next.js application[​](#integrate-rudderstack-into-your-nextjs-application \"Direct link to Integrate Rudderstack into your Next.js application\")\n\nIn your `_app.js`, add the Rudderstack integration we just created\n\n```\nimport rudder from \"./rudder\";\n```\n\nThis will allow you add `rudder.track()` in your app anywhere you import rudder.js while sharing the same Rudderstack object.\n\n## 4\\. Integrate the GrowthBook React SDK into our Next.js app[​](#4-integrate-the-growthbook-react-sdk-into-our-nextjs-app \"Direct link to 4. Integrate the GrowthBook React SDK into our Next.js app\")\n\nWe first need to install the GrowthBook React SDK in our Next.js app:\n\n```\nyarn add @growthbook/growthbook-react\n```\n\nGet the API key from GrowthBook (under settings → API or from the top of the implementation instructions) and add to your environment variables (.env.local)\n\n```\nNEXT_PUBLIC_GROWTHBOOK_FEATURES_URL=<GrowthBook API url>\n```\n\nThen we can modify the code to work with GrowthBook. Modify the file `pages/_app.js` to add GrowthBook and Rudderstack. Import GrowthBook (and Rudderstack, if you haven't):\n\n```\nimport {  GrowthBook,  GrowthBookProvider,  useFeature,} from \"@growthbook/growthbook-react\";import rudder from \"./rudder\";\n```\n\nthen create your GrowthBook instance:\n\n```\n// Create a GrowthBook instanceconst growthbook = new GrowthBook({  trackingCallback: (experiment, result) => {    rudder.track(\"Experiment Viewed\", {      experimentId: experiment.key,      variationId: result.variationId,    });  },});\n```\n\nnote\n\nThe names `experiment Viewed`, `experimentId` and `variationId` will be mapped to `experiment_id` and `variation_id` columns in the `experiment_viewed` table within BigQuery\n\nThen add a `useEffect` hook to update Rudderstack and GrowthBook when the page changes.\n\n```\nexport default function MyApp({ Component, pageProps }) {  useEffect(() => {    // Load feature definitions from API    fetch(process.env.NEXT_PUBLIC_GROWTHBOOK_FEATURES_URL)      .then((res) => res.json())      .then((json) => {        growthbook.setFeatures(json.features);      });    // TODO: replace with real targeting attributes    growthbook.setAttributes({      company: \"foo\",      browser: \"foo\",      url: \"foo\",    });    // Add in Rudderstack anonId when loaded    rudder.getAnonymousId().then((id) => {      growthbook.setAttributes({ ...growthbook.getAttributes(), id });    });  }, []);  //...}\n```\n\nThis code adds the `id` with in GrowthBook to the Rudderstack anonymous\\_id. If you want to load user\\_id as well as anonymous\\_id you'll have to add this id to the setAttribute, and also call the `rudder.identify()` with the user\\_id info.\n\nFinally, wrap your Next.js project in the GrowthBookProvider component, so we can use the GrowthBook methods throughout the codebase without doing addition instantiation.\n\n```\nreturn (  <GrowthBookProvider growthbook={growthbook}>    <Component {...pageProps} />  </GrowthBookProvider>);\n```\n\nAll together, your `_app.js` should look something like this:\n\n```\nimport \"../styles/globals.css\";import {  GrowthBook,  GrowthBookProvider,  useFeature,} from \"@growthbook/growthbook-react\";import { useEffect } from \"react\";import rudder from \"./rudder\";// Create a GrowthBook instanceconst growthbook = new GrowthBook({  trackingCallback: (experiment, result) => {    rudder.track(\"Experiment Viewed\", {      experimentId: experiment.key,      variationId: result.variationId,    });  },});export default function MyApp({ Component, pageProps }) {  useEffect(() => {    // Load feature definitions from API    fetch(process.env.NEXT_PUBLIC_GROWTHBOOK_FEATURES_URL)      .then((res) => res.json())      .then((json) => {        growthbook.setFeatures(json.features);      });    // TODO: replace with real targeting attributes    growthbook.setAttributes({      company: \"foo\",      browser: \"foo\",      url: \"foo\",    });    // Add in Rudderstack anonId when loaded    rudder.getAnonymousId().then((id) => {      growthbook.setAttributes({ ...growthbook.getAttributes(), id });    });  }, []);  return (    <GrowthBookProvider growthbook={growthbook}>      <Component {...pageProps} />    </GrowthBookProvider>  );}\n```\n\nOnce you have data flowing into Rudderstack, you can set it up to work with GrowthBook by following the [Rudderstack guide](https://docs.growthbook.io/guide/rudderstack)",
  "title": "GrowthBook, Rudderstack, and Next.js | GrowthBook Docs",
  "description": "Learn how to use GrowthBook with Rudderstack to easily add A/B testing to your application running on Next.js",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/kb/experiments/aa-tests",
  "markdown": "# A/A Testing in GrowthBook | GrowthBook Docs\n\n## What is an A/A Test?[​](#what-is-an-aa-test \"Direct link to What is an A/A Test?\")\n\nA/A tests are a form of A/B test where there is no difference between variations (each \"variation\" is labeled as \"A\"). They are used to test whether your experimentation set up and methodology is working as expected.\n\nUsers who are placed into your A/A test receive the same user experience regardless of which variation they view. Thus, you'll expect to see almost identical results for each \"variation\" since all users are viewing the same thing. This helps to ensure that you've integrated the GrowthBook SDK correctly, that traffic is flowing as expected, and that your Metrics are defined properly, all _before_ you begin experimenting on features that matter!\n\nBecause all users get the same user experience, any variation in traffic flows or Metric values can be attributed either to errors in your experiment or SDK setup, or to random chance. Metric variations in A/A tests are covered in more detail below.\n\n## When should I run an A/A test in GrowthBook?[​](#when-should-i-run-an-aa-test-in-growthbook \"Direct link to When should I run an A/A test in GrowthBook?\")\n\nThere are two scenarios in which it is a good idea to run an A/A test:\n\n**You've set up a new SDK connection.** Once your SDK is connected and you configure the trackingCallback method, you can validate that the experiment data is being sent correctly to your data warehouse.\n\n**There are changes to any part of the GrowthBook integration**, such as changes to your data warehouse, the tracking libraries (Google Analytics \\[GA4\\], Segment, Amplitude, etc.), or changes to the GrowthBook-related code within your application.\n\n## How do I run an A/A test in GrowthBook?[​](#how-do-i-run-an-aa-test-in-growthbook \"Direct link to How do I run an A/A test in GrowthBook?\")\n\nAn A/A test is run just as an A/B test would be run. Follow the usual instructions for creating an experiment and ensure the \"variations\" are serving _the same values_.\n\nThe feature for your A/A test will look something like this:\n\n![A/A Feature Rule](https://docs.growthbook.io/assets/images/aa-feature-rule-e926211d6ee6c61d3930f53ae5ec159f.png)\n\nThen, start your experiment just as you would any other experiment. Wait until it has been live for a few hours or days, depending on how much traffic you get, then take a look at the results.\n\n## What problems can an A/A test reveal?[​](#what-problems-can-an-aa-test-reveal \"Direct link to What problems can an A/A test reveal?\")\n\nA/A tests are a low-risk approach to help ensure that your experiment is set up correctly.\n\n### Problem: No traffic, incorrect metric values, or SRM errors (imbalanced traffic)[​](#problem-no-traffic-incorrect-metric-values-or-srm-errors-imbalanced-traffic \"Direct link to Problem: No traffic, incorrect metric values, or SRM errors (imbalanced traffic)\")\n\nFor these errors, check our [troubleshooting guide](https://docs.growthbook.io/kb/experiments/troubleshooting-experiments).\n\n### Problem: Metrics show statistically significant lifts in the A/A test[​](#problem-metrics-show-statistically-significant-lifts-in-the-aa-test \"Direct link to Problem: Metrics show statistically significant lifts in the A/A test\")\n\nOne goal of an A/A test is to confirm that all of the Metrics appear balanced across the two variations. In an ideal world, there would be no statistically significant Metric movements between the two variations, because if everything is set up correctly the two variations should have produced identical results (or nearly so, due to random chance).\n\nIt's important to remember the uncertainty that underpins all experiments. In order to state that an experiment is a \"winner\" without collecting data forever, we often accept some level of uncertainty when declaring that a Metric is clearly positive or clearly negative.\n\nThe default level of uncertainty that is used in GrowthBook's Bayesian statistics engine is:\n\nnote\n\nThe probability of a variation being higher or lower than the baseline is greater than 95% or less than 5%.\n\nThis means that some percentage of the time, your variations will be identical but still yield statistically significant effects.\n\nIn other words, about 10% of the time, you may see a statistically significant effect in an A/A Metric even if the test is set up correctly. You can lower this value by lowering the \"Chance to Win Threshold\" in your Organization settings, but that just means it will also take longer for actual A/B experiments to reach a significance level.\n\nSo, how do we use this information about statistical significance?\n\n*   If you have an A/A test with 10 Metrics that are different from one another, and 7 of them are different in a statistically significant way, and the differences are large (e.g. not 96% chance to win, but 99.9+), then you can plausibly state that something is wrong and you may want to dig into your set up. Use the general solutions in the trouble shooting guide as hints for where to begin looking for errors.\n*   If you have an A/A test with 10 Metrics and 1 of them is statistically significant, or even 2 of them, then this is very plausibly due to chance and likely can be ignored and deemed a successful A/A test. You can restart your A/A test with re-randomization to confirm this if you want to. You should see a similar number of metrics reaching statistical significance, and they should not always be the same ones.\n*   Things get more complicated when you have 10 Metrics and 3-4 of them show statistically significant differences. In these cases, you should consider whether the Metrics are related to one another. If you have three \"purchase\" Metrics that are highly correlated with one another, then it's plausible that one \"unlucky\" draw caused this statistical significance and the A/A test is working fine. In this situation, you should consider restarting your A/A test to confirm this theory. If all three Metrics are quite different from one another, then it's stronger evidence that something may be wrong in your set up.\n\n## Restarting an A/A test[​](#restarting-an-aa-test \"Direct link to Restarting an A/A test\")\n\nIf you found some issues with your set up and want to re-run your A/A test, or if you had a Metrics imbalance that you are still uncertain about, you should usually restart the A/A test and run it again.\n\nThe easiest way to do this while still guaranteeing you have a clean test is to use the \"Make Changes\" flow in the A/A experiment page.\n\nUse this flow to \"Start a New Phase\" and make sure you \"re-randomize traffic\" to ensure that users returning to your test will be re-randomized into variations.\n\n![New Phase](https://docs.growthbook.io/assets/images/new-phase-23dcf77f0ae9ecdd01184c5386ec73aa.png) ![New Phase, Re-Randomize](data:image/png;base64,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)",
  "title": "A/A Testing in GrowthBook | GrowthBook Docs",
  "description": "A/A Testing in GrowthBook",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/guide/importing",
  "markdown": "# Migrate from LaunchDarkly | GrowthBook Docs\n\nLooking to migrate from LaunchDarkly to GrowthBook? We have a dedicated importer tool that lets you get up and running in minutes.\n\n## Create an API Token for LaunchDarkly[​](#create-an-api-token-for-launchdarkly \"Direct link to Create an API Token for LaunchDarkly\")\n\nGrowthBook uses the LaunchDarkly REST API to access the relevant resources and import them.\n\nYou must create an access token in your [LaunchDarkly account authorization settings](https://app.launchdarkly.com/settings/authorization) .\n\n## Run the Import[​](#run-the-import \"Direct link to Run the Import\")\n\nGo to the [GrowthBook dashboard's Importing section](https://app.growthbook.io/importing) and choose LaunchDarkly.\n\nThen, enter your LaunchDarkly access token and begin the 2-step process.\n\n### Step 1: Fetch from LaunchDarkly[​](#step-1-fetch-from-launchdarkly \"Direct link to Step 1: Fetch from LaunchDarkly\")\n\nThis will fetch all projects, environments, and feature flags from LaunchDarkly. For large accounts with many feature flags, this may take several minutes to complete. If you run into rate limiting issues, you can adjust the default settings in the UI.\n\nWhen this completes, you will see a preview of everything that will be imported. Carefully review this before proceeding to step 2. Only items marked as \"pending\" will be imported when you proceed.\n\nnote\n\nFor feature flags, we do our best to accurately import everything from LaunchDarkly - fallback values, targeting rules, rollouts, and prerequisite features. This should cover most standard use cases, however for advanced set ups, there are likely some scenarios that we won't be able to handle properly.\n\nYou can click the \"open\" link next to a feature flag to view a detailed JSON view of exactly what will be added/updated. Please review these carefully. If something doesn't look right, you can skip importing individual feature flags by clicking the \"skip\" link.\n\n### Step 2: Import to GrowthBook[​](#step-2-import-to-growthbook \"Direct link to Step 2: Import to GrowthBook\")\n\nIn this step, all of the \"pending\" resources will be imported into GrowthBook. This should take about 1 second per feature flag on average, although this can vary greatly. The import window must be left open during the entire process.\n\nIf you are importing a feature that already exists in GrowthBook, a new revision will be created with any changes to the default value or override rules. All of the changes will be published to all environments immediately, bypassing any draft/review process.\n\n## Next Steps[​](#next-steps \"Direct link to Next Steps\")\n\nAfter the import is complete, you will need to replace the LaunchDarkly SDK in your application with the equivalent [GrowthBook SDK](https://docs.growthbook.io/lib).",
  "title": "Migrate from LaunchDarkly | GrowthBook Docs",
  "description": "Import all of your existing LaunchDarkly flags into GrowthBook",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/kb/experiments/carryover-bias",
  "markdown": "# Carryover Bias | GrowthBook Docs\n\n## What is Carryover Bias?\n\nIn most experimentation systems, such as GrowthBook, users are randomly assigned to different variations (A, B, C, etc.) in a way that ensures that past experiments do not affect one variation more than any other.\n\nHowever, if an experimenter creates a new phase of an experiment without re-randomizing user assignment to variations the new phase of the experiment will be affected by **carryover bias**. This happens when restarting an experiment and when creating an analysis using the last few days or weeks of an experiment. In short, without re-randomization, the effects of the first phase of the experiment can contaminate the second phase of the experiment if any users return to the experiment in the second phase.\n\nThe rest of this document provides an example of carryover bias and how to avoid it in GrowthBook.\n\n## Example of Carryover bias[​](#example-of-carryover-bias \"Direct link to Example of Carryover bias\")\n\nImagine an experiment with two variations (A and B) that runs for 3 days before you realize that there is a bug in variation B that is causing users to churn at a high rate. Let's call this Phase 1.\n\nTo mitigate this issue, you fix the bug and now want to restart your experiment. Furthermore, you don't want to re-randomize users because you want returning users in Phase 2 to get the same variation that they saw in Phase 1. So, you restart the experiment without re-randomizing users (let's call this Phase 2).\n\nHowever, **this choice to not re-randomize will lead to carryover bias**!\n\nHow so? Well, consider what will happen after you restart the experiment. Let's say in Phase 2 each variation gets 100 totally new users. However, we also have some users returning to the app who were exposed to the experiment in Phase 1. In variation A, there are 50 returning users and in variation B, where the bug was causing churn, there are 10 returning users.\n\nThen, your experiment has 150 users in A and 110 users in B! This imbalance is caused because the effects of first phase of the experiment is _carrying over_ to the second phase of the experiment.\n\nThe best way to deal with carryover bias is to prevent it from happening in the first place, because this kind of bias can **unpredictably affect your results** and is **hard to detect**.\n\n#### The effects of carryover bias can be unpredictable[​](#the-effects-of-carryover-bias-can-be-unpredictable \"Direct link to The effects of carryover bias can be unpredictable\")\n\nCarryover bias works to affect your results in many different ways:\n\n*   It could cause B to look **better** than it is; if the 10 people that returned in variation B are particularly persistent power users, then B will look good not because of the feature you're testing, but because you're getting power users bucketed into variation B.\n*   It could cause B to look **worse** than it is because the bad taste of the buggy experience from Phase 1 could cause returning users in B to be less engaged. That \"bad taste\" won't be spread across variations in Phase 2 because you did not re-randomize users.\n\n#### Carryover bias can be hard to detect[​](#carryover-bias-can-be-hard-to-detect \"Direct link to Carryover bias can be hard to detect\")\n\nIn the above example, the discrepancy in users in variations B and A will eventually trigger a Sample Ratio Mismatch (SRM) warning, alerting you to some issue with your experiment. However, SRM warnings will not always fire in cases where there is carryover bias, because either (1) the discrepancy is too small or the total user count is too low; or (2) the carryover bias doesn't actually come from differences in user return rates, but comes from other differences in user behavior across variations that was caused by the first phase of the experiment.\n\n## What causes carryover bias and how can I prevent it?[​](#what-causes-carryover-bias-and-how-can-i-prevent-it \"Direct link to What causes carryover bias and how can I prevent it?\")\n\nIn short, anything that causes users in an experiment analysis to not be randomly assigned to a variation can cause bias. For carryover bias specifically, common causes are:\n\n### 1\\. Creating a new \"Phase\" to restart an experiment without re-randomizing[​](#1-creating-a-new-phase-to-restart-an-experiment-without-re-randomizing \"Direct link to 1. Creating a new \"Phase\" to restart an experiment without re-randomizing\")\n\nIn this case, carryover bias is best prevented by re-randomizing users whenever you restart an experiment — either by starting an entirely new experiment or choosing to \"re-randomize\", which is an option we provide in GrowthBook's SDKs. We provide specific guidance on when you should re-randomize users in GrowthBook as part of our [\"Make Changes\" flow](https://docs.growthbook.io/app/making-experiment-changes).\n\n### 2\\. Manually restarting a new experiment with the same experiment key[​](#2-manually-restarting-a-new-experiment-with-the-same-experiment-key \"Direct link to 2. Manually restarting a new experiment with the same experiment key\")\n\nSimilarly, if you also manually restart an experiment with the same experiment key, the randomization from the previous experiment will carry over to the new experiment. It's best in these cases to change the experiment key to ensure users are re-randomized into groups.\n\n### 3\\. Creating a new \"Phase\" for analysis[​](#3-creating-a-new-phase-for-analysis \"Direct link to 3. Creating a new \"Phase\" for analysis\")\n\nSuppose you create a new phase with the last 7 days of an experiment. Doing this will mean that GrowthBook cannot deduplicate users across the full history of the experiment and the users that show up in the last 7 days of an experiment won't be randomly assigned across variations. If any variation causes more return users, then you'll get carryover bias.\n\nIn this case, rather than utilize a \"Phase\" to analyze a particular date range in an experiment, you should instead focus on your **Metric** date windows (not **Experiment** date windows, which are controlled by Phases). There will be more work in the future to make this easier to achieve within GrowthBook, but for now you can:\n\n*   Add a \"metric delay\". You can use the **metric delay** setting in GrowthBook to delay tracking metric data until a number of hours or days after an exposure to prevent novelty effects.\n*   Use a \"lookback window\". In your metric settings, choose a \"lookback window\" and set it to 7 days.",
  "title": "Carryover Bias | GrowthBook Docs",
  "description": "Carryover Bias",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/statistics/quantile",
  "markdown": "# Quantile Testing | GrowthBook Docs\n\nnote\n\nQuantile Testing is a GrowthBook Pro and Enterprise feature. It is incompatible with Mixpanel or MySQL integrations.\n\n## What is a quantile test?[​](#what-is-a-quantile-test \"Direct link to What is a quantile test?\")\n\nQuantile tests compare quantiles across variations. In contrast, standard GrowthBook A/B tests compare means across variations. For example, suppose that treatment increases user spend. Suppose that 90% of users in control spend at most 50pervisit,and9050 per visit, and 90% of users in treatment spend at most 55 per visit. Then the quantile treatment effect at the 90th percentile (i.e., P90) is 55−55 - 50 = $5. Quantiles are commonly used in many applications where very large or small values are of interest (webpage latency, birth weight, blood pressure).\n\n## When should I run quantile tests?[​](#when-should-i-run-quantile-tests \"Direct link to When should I run quantile tests?\")\n\nBelow are two scenarios where you should run quantile tests.\n\nScenario 1: your website has low latency for most users, but for 1% of users it takes a long time for the page to load. You have a potential solution that targets improvements for this small fraction, and run an A/B test to confirm. Mean differences across variations may be noisy and provide uncertain conclusions, as your solution does not improve latency for most users. Running a quantile test at the 99th percentile can be more informative, as it helps detect if users that would have experienced the largest latency had their latency reduced.\n\nScenario 2: you have a new ad campaign designed to increase customer spend. You run an A/B test, and while the lift is positive, it is not statistically significant. Quantile tests can help you deep dive which subpopulations were positively affected by treatment. For example, you may see no improvement at P50, but moderate improvement at P99. This would indicate that the new campaign did not affect most users, but had a strong affect on your top spending users. In summary, quantile tests can complement mean tests.\n\n## How do I interpret quantile test results?[​](#how-do-i-interpret-quantile-test-results \"Direct link to How do I interpret quantile test results?\")\n\nSuppose you are running an A/B test designed to reduce website latency. Your effect estimate and 95% confidence interval (in milliseconds) for latency at P99 is -7 ms (-9 ms, -5 ms). How do you interpret this?\n\nConsider one universe where **all** customers received control (not just the customers assigned to control). In this universe, website latency for 99% of customers is no more than 145 ms. That is, P99 for control is 145 ms.\n\nConsider another universe where **all** customers are assigned to treatment. In the treatment universe, website latency for 99% of customers is no more than 139 ms. So the true effect at P99 is 139 ms - 145 ms = -6 ms.\n\nA quantile test tries to estimate this difference. You interpret the interval above as “There is a 95% chance that the difference in P99 latencies across the groups is in (-9ms, -5ms)”.\n\n## Should I aggregate by experiment user before taking quantile?[​](#should-i-aggregate-by-experiment-user-before-taking-quantile \"Direct link to Should I aggregate by experiment user before taking quantile?\")\n\nBelow we describe how quantile testing differs in event- vs user-level analyses. Suppose that your new feature is designed to lower webpage request times. If you want to reduce the largest request times across all web sessions, then use quantile testing for event-level data. This can help you learn if your new feature reduced the 99th percentile of request times. If you want to reduce total request times for your most frequent customers, then use quantile testing for user-level data. Here GrowthBook sums the total request times for all events within a customer, then compares percentiles of these sums across variations. Sometimes it can be hard to choose whether or not to aggregate.  \nAnother consideration is how the metric is typically conceptualized.  \nAggregation is usually correct if your metric is often conceptualized at the customer level (e.g., customer spend during a week). Aggregation is usually inappropriate if your metric is often conceptualized at the event level (e.g., spend per order).\n\nTo illustrate the mathematics behind the two approaches, consider an experiment where we collected the following data for all users in a variation.\n\n| user\\_id | value |\n| --- | --- |\n| 123 | 0   |\n| 123 | 0   |\n| 456 | 2   |\n| 456 | 3   |\n| 789 | 99  |\n\nDifferent quantile settings would yield different results:\n\n| Quantile Type | Quantile Value | Ignore Zeros? | Result |\n| --- | --- | --- | --- |\n| Event | 0.5 | False | `APPROX_PERCENTILE([0, 0, 2, 3, 99], 0.5) = 2` |\n| Event | 0.5 | True | `APPROX_PERCENTILE([2, 3, 99], 0.5) = 3` |\n| Per-User | 0.5 | False | `APPROX_PERCENTILE([0, 5, 99], 0.5) = 5` |\n| Per-User | 0.5 | True | `APPROX_PERCENTILE([5, 99], 0.5) = 52` |\n\nNotice that for the Per-User quantiles, we sum at the user level first before passing values to the percentile function. `NULL` values will always be ignored.\n\n## How do I run a quantile test in GrowthBook?[​](#how-do-i-run-a-quantile-test-in-growthbook \"Direct link to How do I run a quantile test in GrowthBook?\")\n\nRunning a quantile test is just as easy as running a mean test. Currently, quantile testing is available only for .\n\n1.  Navigate to your [Fact Table](https://docs.growthbook.io/app/fact-tables#quantile-metrics) and select \"Add Metric\".\n2.  Select “Quantile” from “Type of Metric”.\n3.  Toggle “Aggregate by Experiment User before taking quantile” if you want to compare quantiles across variations at the user granularity, after summing row values at the user level. The default is at the event granularity.\n4.  Pick your quantile level from the defaults (p50, p90, p95, p99) or use a custom value. Guidance describing the range of available values is in our [FAQ](#faq).\n5.  Decide whether you want zeros to be included in the analysis (see [FAQ](#faq) below).\n6.  Select your metric window as you would for a mean test.\n7.  Submit!\n\n![User interface for quantile metrics](https://docs.growthbook.io/assets/images/quantile-7db8e19e10b18ddb5afeb074e801d42d.png)\n\n## FAQ[​](#faq \"Direct link to FAQ\")\n\nFrequently asked questions:\n\n1.  Can I pick any quantile level (e.g., P99.999)? No - the maximum range available is \\[0.001, 0.999\\], and that is only for experiments with large sample sizes (i.e., n > 3838). This is because inference can become unreliable for extreme quantile levels and small sample sizes. In general, if you want to compare quantiles at some value p∈(0,1)p \\\\in (0, 1), and you want a 95% confidence interval, your sample size nn must be bigger than 4p/(1−p)4p/(1-p). Similarly, if you want extreme and small quantiles, you need n≥4(1−p)/pn \\\\geq 4(1-p)/p. For p\\=0.99p=0.99 and p\\=0.01p=0.01, this corresponds to n≥380n \\\\geq 380.\n2.  Should I include zeros in my quantile test? This depends upon the population that you care about, and what you want to learn. If zero is a common value for your metric, then P90 including zeros can be much less than P90 without zeros. If your metric is typically conceptualized and reported with zeros included, then it will probably makes sense to include zeros in your quantile test metric. If you are using quantile tests to deep dive mean test results, then use the same configuration for both tests.\n3.  Can I get quantile test results inside of a Bayesian framework? Yes - GrowthBook puts a prior on the quantile treatment effect, and combines this prior with the effect estimate to obtain a posterior distribution for the quantile treatment effect. So “Chance to Win” and other helpful Bayesian concepts are available.\n4.  How does quantile inference connect to mean inference? If you average the quantiles of a distribution, you get the distributional mean. That is, the average of {P1,P2,...,P98,P99}\\\\left\\\\{P1, P2, ..., P98, P99\\\\right\\\\} equals the mean of the distribution. Similarly, the average of the treatment effects at P1, P2, etc. equals the mean treatment effect. So quantile inference can be viewed as a decomposition of mean inference.\n5.  How should I conduct quantile inference in the presence of percentile capping? We have disabled percentile capping for quantile testing. For example, if you picked P99 for your quantile level, then your results could be biased, as capping at P98 ignores all information beyond the 98th percentile. Percentile capping at P98 does not affect estimates at any quantile level below P98 (e.g., P50, P90), so percentile capping will either do nothing or potentially bias quantile test results.\n6.  How does Quantile Testing intersect with [CUPED](https://docs.growthbook.io/statistics/cuped), [Multiple Testing Corrections](https://docs.growthbook.io/statistics/multiple-corrections), and [Sequential Testing](https://docs.growthbook.io/statistics/sequential)? Currently CUPED and Sequential Testing are not implemented for Quantile Testing. Multiple Testing Corrections is implemented for Quantile Testing.\n7.  What is cluster adjustment? Data are clustered when randomization happens at a coarser granularity than the metrics of interest. For example, suppose we are trying to reduce webpage latency. We randomize customers (perhaps due to engineering constraints or testing purposes). A customer may have multiple sessions, i.e., a session is clustered within customer. Latencies for two sessions from the same customer are likelier to be more similar than latencies for two sessions from different customers. Cluster adjustment ensures that we do not overstate the amount of information in the experiment, i.e., uncertainty estimates are valid.\n\n## GrowthBook implementation[​](#growthbook-implementation \"Direct link to GrowthBook implementation\")\n\nHere we describe technical details of our implementation.\n\nGrowthBook implements the approach first introduced in [Deng, Knoblich and Yu (2018)](https://alexdeng.github.io/public/files/kdd2018-dm.pdf). This clever approach has two key advantages. First, it constructs valid confidence intervals for quantiles that uses only sample quantiles, rather than all of the data. This permits estimation using only a single pass through the data. Second, it provides quantile inference for clustered data. This is helpful when randomization occurs at the user level, but our metrics are measured at the session level (described [here](#should-i-aggregate-by-experiment-user-before-taking-quantile)). Our implementation is based upon Algorithm 1 of [Yao, Li and Lu (2024)](https://arxiv.org/pdf/2401.14549.pdf). Define ν∈(0,1)\\\\nu \\\\in (0, 1) as the quantile level of interest. Define α∈(0,1)\\\\alpha \\\\in (0,1) as the false positive rate, and let Z1−α/2Z\\_{1-\\\\alpha/2} be its associated critical value. Without loss of generality we focus on the control variation. Let nn be the control sample size. Define YijY\\_{ij} as the webpage latency for the jthj^{\\\\text{th}} session for the ithi^{\\\\text{th}} user (i.e., cluster) in control, j\\=1,2,…,Nij=1,2,…, N\\_{i}, i\\=1,2,…,Ki=1,2,…,K. Define the observed control outcomes as {Y1,Y2,...,Yn}\\\\left\\\\{Y\\_{1}, Y\\_{2}, ..., Y\\_{n}\\\\right\\\\}, where n\\=∑i\\=1KNin=\\\\sum\\_{i=1}^{K}N\\_{i}. Define the ordered (from smallest to largest) control outcomes as {Y(1),Y(2),...,Y(n)}\\\\left\\\\{Y\\_{(1)}, Y\\_{(2)}, ..., Y\\_{(n)}\\\\right\\\\}.\n\n1.  Compute L, U = n(ν±Z1−α/2ν(1−ν)/n)n\\\\left(\\\\nu \\\\pm Z\\_{1-\\\\alpha/2}\\\\sqrt{\\\\nu(1-\\\\nu)/n} \\\\right).\n2.  Fetch Ynν,YL,YUY\\_{n\\\\nu}, Y\\_{L}, Y\\_{U}.\n3.  Compute Iij\\=1{Yij≤Ynν}I\\_{ij} = 1\\\\left\\\\{Y\\_{ij}\\\\leq Y\\_{n\\\\nu}\\\\right\\\\}. Define Iˉ\\=n−1∑i\\=1K∑j\\=1NiIij\\\\bar{I} = n^{-1}\\\\sum\\_{i=1}^{K}\\\\sum\\_{j=1}^{N\\_{i}}I\\_{ij}.\n4.  Compute σI,iid2\\=ν(1−ν)/n\\\\sigma\\_{I, \\\\text{iid}}^{2} = \\\\nu(1-\\\\nu)/n, an estimate of the variance of Iˉ\\\\bar{I} assuming independent and identically distributed (iid) errors.\n5.  Define σI,c2\\=Var(Iˉ)\\\\sigma\\_{I, c}^{2} = \\\\text{Var}(\\\\bar{I}) using the variance of ratios of means described below.\n6.  Compute σiid2\\=(YU−YL2Z1−α/2)2\\\\sigma\\_{iid}^{2} = \\\\left(\\\\frac{Y\\_{U}-Y\\_{L}}{2Z\\_{1-\\\\alpha/2}}\\\\right)^{2} .\n7.  The cluster-adjusted variance is σiid2(σI,iid2/σI,c2)\\\\sigma\\_{\\\\text{iid}}^{2} \\\\left(\\\\sigma\\_{I,\\\\text{iid}}^{2}/\\\\sigma\\_{I,c}^{2}\\\\right). The term in parentheses adjusts the variance for clustering. If there is no clustering (i.e., inference is at the user level), then use σiid2\\\\sigma\\_{iid}^{2}.\n\nTo further speed this algorithm, instead of finding the exact (L,U)(L, U), which requires pre-computing nn inside of SQL, we instead construct a sequence of logarithmically increasing sample sizes N⋆\\={n1,n2,...nM}N^{\\\\star}=\\\\left\\\\{n\\_{1}, n\\_{2}, ... n\\_{M}\\\\right\\\\} and their associated intervals{(L1,U1),(L2,U2),...,(LM,UM)}\\\\left\\\\{(L\\_{1}, U\\_{1}), (L\\_{2}, U\\_{2}), ..., (L\\_{M}, U\\_{M}) \\\\right\\\\}. We then output the quantiles associated with each interval, as well as nn. We then find n⋆n^{\\\\star}, defined as the largest element of N⋆N^{\\\\star} such that n⋆≤nn^{\\\\star}\\\\leq n. We then adjust the variance outputted by the algorithm above by a factor of n⋆/nn^{\\\\star}/n. Currently we use 20 different values of N⋆N^{\\\\star}, where the kthk^{\\\\text{th}} value is equal to 100∗2k−1100 \\* 2 ^{k-1}.\n\nIn this paragraph we describe the variance of a ratio of means, as described in step 5. above. Additionally, this is the standard formula used to calculate variance of a mean for a variation in GrowthBook t-tests. Here we define the user outcome in terms of random variable XiX\\_{i}, as the formula below can be used for any outcome (e.g., YijY\\_{ij}, IijI\\_{ij}, etc.). For the ithi^{\\\\text{th}} user define the sum of outcomes Si\\=∑j\\=1NiYijS\\_{i} = \\\\sum\\_{j=1}^{N\\_{i}}Y\\_{ij}. Then the mean outcomes across users is Xˉ\\=∑i\\=1KSi∑i\\=1KNi\\\\bar{X}=\\\\frac{\\\\sum\\_{i=1}^{K}S\\_{i}}{\\\\sum\\_{i=1}^{K}N\\_{i}}. Define the mean sum of latencies across users as Sˉ\\=K−1∑i\\=1KSi\\\\bar{S} = K^{-1}\\\\sum\\_{i=1}^{K}S\\_{i}. Define the mean sum of sessions across users as Nˉ\\=K−1∑i\\=1KNi\\\\bar{N} = K^{-1}\\\\sum\\_{i=1}^{K}N\\_{i}. A formula for the variance of Xˉ\\\\bar{X} is\n\nVar(Xˉ)\\=1KNˉ2\\[Var(S)−2SˉNˉCov(S,N)+Sˉ2Nˉ2Var(N)\\]\\\\text{Var}\\\\left(\\\\bar{X}\\\\right) = \\\\frac{1}{K\\\\bar{N}^{2}}\\\\left\\[\\\\text{Var}(S)-2\\\\frac{\\\\bar{S}}{\\\\bar{N}}\\\\text{Cov}(S,N)+\\\\frac{\\\\bar{S}^2}{\\\\bar{N}^2}\\\\text{Var}(N)\\\\right\\].\n\nThis is similar to the delta method approximation of the variance we use for ratio metrics and for relative effects.\n\nLet μ^C,nν\\\\hat{\\\\mu}\\_{C,n\\\\nu} be the νth\\\\nu^{\\\\text{th}} sample quantile for control, and let its associated variance be σ^C,nν2\\\\hat\\\\sigma^2\\_{C,n\\\\nu}. Analogously define μ^T,nν\\\\hat{\\\\mu}\\_{T,n\\\\nu} and σ^C,nν2\\\\hat\\\\sigma^2\\_{C,n\\\\nu} for treatment. These quantities are plugged into our lift estimators as described in the [Statistical Details](https://docs.growthbook.io/statistics/details) page. The result from step 7 is our estimate of the variance and the sample quantile is directly computed in the SQL query.",
  "title": "Quantile Testing | GrowthBook Docs",
  "description": "Quantile Testing",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/statistics/cuped",
  "markdown": "# Regression Adjustment (CUPED) | GrowthBook Docs\n\nnote\n\nRegression Adjustment (CUPED) is a premium feature.\n\nGrowthBook aims to unlock high-velocity, enterprise-scale experimentation. Regression adjustment (also known as CUPED, short for Controlled-experiment Using Pre-Experiment Data) is one way to increase the velocity of experimentation by reducing the uncertainty in estimates of experiment uplift.\n\n### Why use CUPED?[​](#why-use-cuped \"Direct link to Why use CUPED?\")\n\nCUPED decreases the variance of experiment uplift, increasing the accuracy of your experimental results and therefore the speed at which you can see the effects of an experiment. In the right conditions, CUPED can equate to getting 20% or more traffic during your experiment!\n\n*   In 2016, Netflix reported that CUPED reduced variance by rougly ~40% for some key engagment metrics ([source](https://www.kdd.org/kdd2016/papers/files/adp0945-xieA.pdf)).\n*   In 2022, Microsoft reported that, for one product team, CUPED was akin to adding 20% more traffic to analysis of a majority of metrics ([source](https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/deep-dive-into-variance-reduction/)).\n\n### How does it work?[​](#how-does-it-work \"Direct link to How does it work?\")\n\nRegression adjustment (RA) in general uses data correlated with a metric to reduce our uncertainty about that metric and the statistics we compute. Any data correlated with the metric of interest, but uncorrelated with variation assignment can be used. GrowthBook (and many others) use pre-experiment data, as metrics collected before an experiment will not be affected by said experiment. In fact, the very name CUPED embeds this concept of using pre-experiment data. Using this pre-experiment data, we can fit a simple model to predict our outcome metric and use those predictions to adjust our metric. The adjusted metric then tends to have lower variance.\n\nThe more correlated the pre-experiment data is with your metric of interest, the more variance reduction you can achieve. For example, the following plot demonstrates the difference in the distribution of a metric before adjustment (\"Normal\") and after adjustment (\"Adjusted\"). In both panels, the green, adjusted metric is distributed less widely (e.g. it is more tightly spaced out around the mean). However, the adjusted distribution is even tighter in the right plot, showing that variance reduction will be greater the more correlated your pre-experiment data is with your post-experiment data.\n\n![Variance Reduction by Correlation](https://docs.growthbook.io/images/statistics/cuped-corr.png)\n\nIn simpler terms, if we know a particular user tends to buy a lot of products on your website before you launch an experiment, we can use that information to understand whether purchase behavior after an experiment is driven by that customer's innate tendency to buy a lot of products or whether it was due to the experiment.\n\nThe concept of regression adjustment has been around for a long time, but you should feel free to read more in the original CUPED paper ([Deng et al. 2013](https://exp-platform.com/Documents/2013-02-CUPED-ImprovingSensitivityOfControlledExperiments.pdf)), a more general purpose paper on the underpinnings of regression adjustment from a sampling perspective ([Lin 2013](https://projecteuclid.org/journals/annals-of-applied-statistics/volume-7/issue-1/Agnostic-notes-on-regression-adjustments-to-experimental-data--Reexamining/10.1214/12-AOAS583.full)), and any of the many blog posts on the topic (e.g. [Booking.com](https://booking.ai/how-booking-com-increases-the-power-of-online-experiments-with-cuped-995d186fff1d), [Microsoft](https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/deep-dive-into-variance-reduction/)).\n\n## GrowthBook's implementation[​](#growthbooks-implementation \"Direct link to GrowthBook's implementation\")\n\nGrowthBook takes a transparent, simple approach to CUPED.\n\nFor each metric you analyze, we use the metric itself from the pre-exposure period as the correlated data. This tends to be very powerful for metrics that are frequently produced by users (e.g. engagement measures), but can be less powerful if your metric is rare, or if you are measuring behavior for new users. In general, CUPED is more powerful the more you know about your units of interest and the longer they have been able to generate the metric that you are analyzing as a part of your experiment.\n\nWe then use the standard CUPED estimator for each variation mean,\n\nYˉadjusted\\=Yˉpost−θ∗Yˉpre\\\\bar{Y}\\_{adjusted} = \\\\bar{Y}\\_{post} - \\\\theta \\* \\\\bar{Y}\\_{pre}\n\nwhere Yˉpost\\\\bar{Y}\\_{post} is the post-exposure metric average, Yˉpre\\\\bar{Y}\\_{pre} is the pre-exposure metric average, and θ\\\\theta is essentially a regression coefficient from a regression of the post-experiment data on the pre-experiment data (pooled across both the control and treatment variation of interest), θ\\=Cov(Ypre,Ypost)/Var(Ypre)\\\\theta = \\\\text{Cov}(Y\\_{pre}, Y\\_{post}) / \\\\text{Var}(Y\\_{pre}).\n\nAs discussed above, we could use any correlated data instead of YpreY\\_{pre}. For example, we could use some model that includes all pre-exposure metrics added to your experiment, or auxiliary dimension information you have configured per user. However, one downside of these approaches is that your results for metric A will depend on whether or not you add a metric B to your experiment and our analysis pipeline would lose its modularity, where each metric can be processed in parallel. Nonetheless, we anticipate continuing to build methods that leverage additional data to improve variance reduction from CUPED.\n\n### Regression Adjustment lookback window[​](#regression-adjustment-lookback-window \"Direct link to Regression Adjustment lookback window\")\n\nGrowthBook defaults to using 14 days of pre-exposure data, but this is customizable at the organization, metric, and metric-experiment level.\n\nWhy use a longer lookback window?\n\n*   A longer window can be better if your metric is low frequency and a longer window is needed to capture meaningful user behavior that will be correlated across the pre- and post-exposure time periods\n\nWhy use a shorter lookback window?\n\n*   Shorter lookback windows will yield more performant queries (fewer days to scan from your metric source)\n*   Behavior in the days just before a user enters an experiment is likely to be more highly correlated with behavior during an experiment, as users change over time. Of course, this is mostly true for metrics that are observed at a higher frequency (e.g. simple engagement metrics).\n\n### Availability[​](#availability \"Direct link to Availability\")\n\nCUPED works for all metrics except for:\n\n*   Ratio metrics where the denominator is a count metric\n*   Quantile metrics\n*   Metrics with custom user value aggregations\n*   Metrics from a MixPanel data sources\n\n## Configuring CUPED[​](#configuring-cuped \"Direct link to Configuring CUPED\")\n\n### Organization-level settings[​](#organization-level-settings \"Direct link to Organization-level settings\")\n\nYou can turn CUPED on for all analyses under Settings → General. CUPED can be turned on or off by default for all analyses and you can set the default number of days to use for a lookback window. This setting will set the default for all of your metrics, which will then flow through to all analyses that use those metrics.\n\n![Organization-level CUPED Setting](https://docs.growthbook.io/images/statistics/cuped-org.png)\n\n### Metric-level settings[​](#metric-level-settings \"Direct link to Metric-level settings\")\n\nYou can also override these organization-level defaults at the Metric level. When creating or editing a Metric, go to the \"Behavior\" panel, click \"Show advanced options\" and scroll to the bottom. From there, you will see the following settings. These settings will allow you to disable CUPED for a metric, even if it is set at the organization or experiment level.\n\n![Metric-level CUPED Setting](https://docs.growthbook.io/images/statistics/cuped-metric.png)\n\nYou might want to disable CUPED for a particular metric if that metric never collects values for a user before they enter an experiment. You might want to adjust metric-specific lookback windows for any of the reasons listed in the section above.\n\nFinally, you could also, if you wanted, override these metric-level settings for a particular experiment using metric overrides on the experiment page.\n\n### Experiment settings and results[​](#experiment-settings-and-results \"Direct link to Experiment settings and results\")\n\nBy default, each experiment will use your organization-level defaults, unless they are overriden by a metric. However, you can always toggle CUPED on or off using the toggle added to the top of the results table. You may need to re-run your analysis if you change this setting.\n\n*   If the toggle is Off, then CUPED will not be applied to any metrics.\n*   If the toggle is On, then it will be applied for all metrics that:\n    *   (a) it can be applied to\n    *   (b) do not have a metric setting or metric override turning it off\n\nThe following screenshot shows the results with CUPED on. However, you can see that there is an icon showing that CUPED is disabled for Average Order Value (because it is a ratio metric). So even if CUPED is toggled on, we will always show you any metrics for which GrowthBook did not use CUPED using that small CUPED icon with a red x.\n\n![Experiment Results with CUPED toggle](https://docs.growthbook.io/images/statistics/cuped-results.png)\n\nFurthermore, if you mouse over the icon showing CUPED wasn't applied, you will get an explanation why.\n\n![Metric Icon showing CUPED Disabled Reason](https://docs.growthbook.io/images/statistics/cuped-icon.png)\n\nIf you mouse over the metric name itself, you get the final CUPED status for each metric (on/off, number of lookback days).\n\n![Metric Tooltip with CUPED status](https://docs.growthbook.io/images/statistics/cuped-tooltip.png)",
  "title": "Regression Adjustment (CUPED) | GrowthBook Docs",
  "description": "Regression Adjustment (CUPED)",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/statistics/sequential",
  "markdown": "# Sequential Testing | GrowthBook Docs\n\nnote\n\nSequential Testing is only implemented for the Frequentist statistics engine, and is a premium feature.\n\n## Why use sequential testing?[​](#why-use-sequential-testing \"Direct link to Why use sequential testing?\")\n\nSequential testing allows you to look at your experiment results as many times as you like while still keeping the number of false positives below the expected rate. In other words, it is the frequentist solution to the peeking problem in AB testing.\n\nSequential testing not only reduces the risk of false positives in online experimentation; it can also increase the velocity of experimentation. Although sequential testing produces wider confidence intervals than fixed-sample testing, traditional frequentist inference requires an experimenter to wait until a pre-determined sample size is collected. With sequential testing, decisions can be made as soon as significance is reached, without fear of inflating the false positive rate.\n\n### The peeking problem[​](#the-peeking-problem \"Direct link to The peeking problem\")\n\nWhat is peeking? First, some background on frequentist testing.\n\nWhen running a frequentist analysis, the experimenter sets a confidence level, often written as α\\\\alpha. Many people, and GrowthBook, default to using α\\=5%\\\\alpha = 5\\\\% (sometimes it is written as α\\=0.05\\\\alpha = 0.05). These all mean the same thing: for a correctly specified frequentist analysis, you will only reject the null hypothesis 5% of the time when the null hypothesis is true. Usually in online experimentation, our null hypothesis is that metric averages in two variations are the same. In other words, α\\\\alpha controls the _False Positive Rate_.\n\nHowever, experimenters often violate a fundamental assumption underpinning frequentist analysis: that one must wait until for some pre-specified time (or sample size) before looking at and acting upon experiment results. If you violate this assumption, and _peek_ at your results, you will end up with an inflated _False Positive Rate_, far above your nominal 5% level. In other words, if we check an experiment as it runs, we are essentially increasing the number of times we can get a positive, even if there is no experiment effect, just through random noise.\n\nWe have two options:\n\n1.  Stop checking early. This is possible, but in a lot of cases it can make decision making worse! It is powerful to be able to see bad results and shut a feature down early; or conversely to see a great feature do well right away, end the experiment, and ship to everyone.\n2.  Use an estimator that returns our control over false positive rates.\n\nSequential testing provides estimators for the second option; it allows peeking at your results without fear of inflating the false positive rate beyond your specified α\\\\alpha.\n\n## Configuring sequential testing[​](#configuring-sequential-testing \"Direct link to Configuring sequential testing\")\n\nYou can enable or disable sequential testing, as well as select your tuning parameter, both in your organization settings (as a default for all future experiments) or on an individual experiment's page.\n\nYou can also play with the settings in an ad-hoc report.\n\n### Setting the tuning parameter[​](#setting-the-tuning-parameter \"Direct link to Setting the tuning parameter\")\n\nThe tuning parameter (written as N∗N^\\* in the [implementation notes below](#growthbooks-implementation)), should be set to the number of observations at which you tend to make decisions. It can be thought of as an \"estimated sample size\" for the two arms you are comparing. You want to set N∗N^\\* to be the number of observations at which you tend to make decisions, because it is at that sample size that the loss in experiment power from using sequential testing will be smallest relative to the traditional confidence intervals.\n\nThe following figure shows how the increased CI width in sequential analysis is minimized when the sample size is approximately N∗N^\\*. The y-axis is the ratio of the sequential CIs to the regular CIs; all lines are well above 1.0, showing that sequential analysis results in uniformly wider confidence intervals. On the x-axis is the sample size at which the analysis was executed. As you can see, the ratio is lowest when N∗N^\\* is as close to sample size used in the analysis.\n\n![Effect of Tuning Sequential Statistics on CI Width](https://docs.growthbook.io/images/statistics/sequential-tuning.png)\n\nWe default to using 5,000, but the general advice is to set this parameter to the sample size you expect to get when you are most likely to make a decision on this experiment. Note, this number reflects the total sample size across the two variations you are comparing. If you have an experiment with 3 variations, and you want the smallest confidence intervals after 3,000 users in each variation, you should set the tuning parameter to 6,000 following the above logic. This is because while the total number of users will be 9,000, there will be 6,000 total in each comparison of arms (e.g. A vs B, B vs C, and A vs C).\n\nNote that the tuning parameter should remain fixed for an experiment.\n\n### Organizational defaults[​](#organizational-defaults \"Direct link to Organizational defaults\")\n\nTo set the default usage of sequential testing and the tuning parameter for new experiments, navigate to the Organization Settings page and select your preferred defaults.\n\n![Sequential Statistics Organization Settings](https://docs.growthbook.io/images/statistics/sequential-settings.png)\n\n### Experiment settings[​](#experiment-settings \"Direct link to Experiment settings\")\n\nYou can also turn sequential testing on and off for an individual experiment, as well as set a specific tuning parameter for that experiment. Navigate to the Experiment page, click Edit Experiment Settings, and choose your preferred settings.\n\n![Sequential Statistics Experiment Settings](https://docs.growthbook.io/images/statistics/sequential-exp-settings.png)\n\n## GrowthBook's implementation[​](#growthbooks-implementation \"Direct link to GrowthBook's implementation\")\n\nThere are many approaches to sequential testing, several of which are well explained and compared in [this Spotify blogpost](https://engineering.atspotify.com/2023/03/choosing-sequential-testing-framework-comparisons-and-discussions/).\n\nFor GrowthBook, we selected a method that would work for the wide variety of experimenters that we serve, while also providing experimenters with a way to tune the approach for their setting. To that end, we implement Asymptotic Confidence Sequences introduced by [Waudby-Smith et al. (2023)](https://arxiv.org/pdf/2103.06476v7.pdf); these are very similar to the Generalized Anytime Valid Inference confidence sequences described by Spotify in the above post and introduced by [Howard et al. (2022)](https://arxiv.org/pdf/1810.08240.pdf), although the Waudby-Smith et al. approach more transparently applies to our setting.\n\nSpecifically, GrowthBook's confidence sequences, which take the place of confidence intervals, become:\n\n(μ^±σ^∗N∗2(Nρ2+1)N2ρ2log⁡(Nρ2+1α))\\\\left(\\\\hat{\\\\mu} \\\\pm \\\\hat{\\\\sigma}\\*\\\\sqrt{N}\\*\\\\sqrt{\\\\frac{2(N\\\\rho^2 + 1)}{N^{2}\\\\rho^2}\\\\log\\\\left(\\\\frac{\\\\sqrt{N\\\\rho^2 + 1}}{\\\\alpha}\\\\right)}\\\\right)\n\nρ\\=−2log(α)+log(−2log(α)+1)N∗\\\\rho = \\\\sqrt{\\\\frac{-2\\\\text{log}(\\\\alpha) + \\\\text{log}(-2 \\\\text{log}(\\\\alpha) + 1)}{N^\\*}}\n\nIn the above, μ^\\\\hat{\\\\mu} is our estimated uplift, σ^\\\\hat{\\\\sigma} is the estimated standard error of the uplift, α\\\\alpha is our significance level (defaults to 0.05), and NN is the sum of the two variation's sample sizes.\n\nIn the above N∗N^\\* is a tuning parameter that lets us control how tight these confidence sequences are relative to the standard, fixed-time confidence intervals. You can read more about how to set it in the [Configuring Sequential Testing](#setting-the-tuning-parameter) section.",
  "title": "Sequential Testing | GrowthBook Docs",
  "description": "Sequential Testing",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/statistics/aggregation",
  "markdown": "# Aggregate Data | GrowthBook Docs\n\n## Aggregate Data and the Statistics Engine\n\nGrowthBook never collects user-level events or PII. To power our statistics engine, contained within the `gbstats` Python library, GrowthBook works solely with aggregate level data that is sufficient to conduct analyses of interest.\n\n## Working with sums[​](#working-with-sums \"Direct link to Working with sums\")\n\nSpecifically, GrowthBook mostly relies on queries that run on your data warehouse and return data aggregated across users. We aggregate data at the level of the experiment variation (or dimension-variation, if you have dimensions specified). We rely on sums, sums of squares, and sums of cross products to power our statistics engine. These simple quantities allow us to easily re-aggregate over different dimensions while still containing sufficient information to compute experiment statistics.\n\nNote that these are the aggregations at the experiment variation level---they are computed across users. These often follow an aggregation at the user level, which defaults to SUM for non-binomial metrics, or a 1 for binomial metrics. You may have overriden the user-level aggregation in your metric definition with some other function. However, when we then go to aggregate at the variation level, we sum across those user-level aggregations.\n\n### Aggregate fields[​](#aggregate-fields \"Direct link to Aggregate fields\")\n\nYou can view the aggregate data we use for any metric in your experiment by selecting the three dots in the top right of the experiment table and clicking \"View Queries\". There, you can see the actual queries we build and the aggregate results they contain. The following image is an example of those aggregate values.\n\n![View Query - SQL and aggregate statistics](https://docs.growthbook.io/assets/images/view-query-aggregate-3b33717c83055e8d2cb956dc69151a53.png)\n\nThe potential fields the queries will return are as follows, with all sums aggregating at the variation-dimension level:\n\n*   `variation` - the name of the experiment variation\n*   `dimension` - the name of the dimension we aggregate to; defaults to \"All\" if there is no dimensional analysis specified\n*   `users` - the number of users in the variation-dimension that are part of the denominator for that metric; normally this is all users in the variation-dimension, but for ratio metrics or activation metrics it will only include users that are in the ratio denomitor or in the set of activated users.\n*   `count` - deprecated; duplicate of users\n*   `statistic_type` - one of \"mean\" or \"ratio\"; this indicates to the statistics engine how to process the data as the formulae for the variance is different across these statistic types\n*   `main_metric_type` - the metric type of the main metric (e.g. the metric itself or the numerator for ratio metrics)\n*   `main_sum` - the summed value of the user-level main metric\n*   `main_sum_squares` - the sum of the squared values of the user-level main metric\n\nIf the metric is a ratio metric, you will additionally see the following fields:\n\n*   `denominator_metric_type` - the metric type of the denominator metric\n*   `denominator_sum` - the summed value of the user-level denominator metric\n*   `denominator_sum_squares` - the sum of the squared values of the user-level denominator metric\n*   `main_denominator_sum_product` - the sum of the product of the user-level main and denominator metric",
  "title": "Aggregate Data | GrowthBook Docs",
  "description": "Aggregate Data",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/statistics/multiple-corrections",
  "markdown": "# Multiple Testing Corrections | GrowthBook Docs\n\nnote\n\nMultiple testing corrections are only implemented for the Frequentist statistics engine.\n\nIf you test a bunch of things at once, you will naturally get some results that look good, but aren't real! This page explains this problem in detail and how you can control it with GrowthBook.\n\n## What is the multiple testing problem?[​](#what-is-the-multiple-testing-problem \"Direct link to What is the multiple testing problem?\")\n\nIn the frequentist framework, testing more than one hypothesis at a time increases the probability that you find a false positive, beyond the user's specified rate of α\\\\alpha, often 0.05. This is often known as the [multiple testing](https://en.wikipedia.org/wiki/Multiple_comparisons_problem), or multiple comparisons, problem.\n\nIn online AB testing, experimenters will often be running hundreds of tests, if not tens of thousands, of tests, at the same time. In this setting, a \"test\" tends to be the comparison of variation A vs variation B, for one group, for one metric. If you are running 10 experiments with 2 variations, each with 10 metrics, you are running 100 tests at one time. Even if the test had no effect on any metric, having this many tests will dramatically increase the chance of seeing a false positive.\n\n### Error rates[​](#error-rates \"Direct link to Error rates\")\n\nTo understand approaches to solving this issue, let's first define two the False Discovery Rate (FDR) and the Family Wise Error Rate (FWER).\n\nIn plain English, the FDR is proportion of your significant results that are false. If you control your FDR at 0.05 (or 5%), and you get 20 significant results, on average only 1 of these should be a false positive.\n\nThe FWER is the probability of at least one test being a false positive. This tends to be much stricter as the number of tests grows.\n\nWe can write both as follows, where VV is the number of tests that are statistically significant but are false positives and RR are the number of tests that are statistically signficant.\n\nFalse Discovery Rate\\=FDR\\=E\\[VV+R\\]\\\\text{False Discovery Rate} = \\\\text{FDR} = \\\\text{E}\\[\\\\frac{V}{V+R}\\]\n\nFamily-wise Error Rate\\=FWER\\=Pr(V≥1)\\\\text{Family-wise Error Rate} = \\\\text{FWER} = \\\\text{Pr}(V \\\\geq 1)\n\n## Corrections in GrowthBook[​](#corrections-in-growthbook \"Direct link to Corrections in GrowthBook\")\n\n### Statistical methods[​](#statistical-methods \"Direct link to Statistical methods\")\n\nGrowthbook allows you to choose no multiple testing correction, a correction that controls the Family-wise Error Rate (Holm-Bonferroni), and a correction that controls the False Discovery Rate (Benjamini-Hochberg).\n\nWhich you choose depends on your tolerance for false positives, the number of tests you are running, and your comfort with each procedure. General guidance would be that if your analysis is more exploratory, controlling the FDR and having a slightly higher false positive rate may be better, while controlling the FWER will give you more guarantees that your results are reliable. However, with enough tests, controlling the FWER may completely undermine your test power.\n\nYou can set this for your organization in the Organization → Settings page, as seen below:\n\n![Org-level Multiple Testing Correction Settings](https://docs.growthbook.io/images/statistics/pvals-adjustment-org.png)\n\nOnce you make a selection, adjustments will happen on-the-fly in experiment results and reports. For now, these adjusted p-values are only available in the UI or in downloadable CSVs and not exportable via the API.\n\ntip\n\nThe corrections we implement do not have directly analogous confidence intervals. Nonetheless, we do construct confidence intervals in an ad-hoc manner after adjusting p-values. We take the adjusted p-values and we back out what the experiment effect standard deviation would need to be to produce that adjusted p-value. We then construct CIs using this adjusted standard deviation. In this way, adjusted p-values below your p-value threshold should always coincide with confidence intervals that do not cross zero.\n\nSome adjusted p-values are 1, in which case the ad-hoc confidence interval constructed in this way is undefined.\n\nUnadjusted confidence intervals are available in the metric tooltip.\n\n#### Holm-Bonferroni (controlling FWER)[​](#holm-bonferroni-controlling-fwer \"Direct link to Holm-Bonferroni (controlling FWER)\")\n\nTo control the FWER, we implement the [Holm-Bonferroni method](https://en.wikipedia.org/wiki/Holm%E2%80%93Bonferroni_method). This method is an adaptation of the well known Bonferroni method, which simply multiplies p-values by the number of tests in the family.\n\nThe Holm-Bonferroni does just as well as the Bonferroni method to control the FWER, but it is less conservative. The main trade-off is that the implementation is slightly more complex, and one cannot adjust the confidence intervals in a meaningful way. There are other approaches that are even less conservative, but they require making assumptions about the dependence between tests to guarantee FWER control.\n\n#### Benjamini-Hochberg (controlling FDR)[​](#benjamini-hochberg-controlling-fdr \"Direct link to Benjamini-Hochberg (controlling FDR)\")\n\nTo control the FDR, we implement the [Benjamini-Hochberg procedure](https://en.wikipedia.org/wiki/False_discovery_rate#Benjamini%E2%80%93Hochberg_procedure). This method does assume that the tests are independent or positively correlated. There are methods that make fewer assumptions (such as the Benjamini-Yekutieli method), but they can be even more conservative than Bonferroni corrections.\n\nTherefore, in order to provide a reasonably powered approach that controls the FDR in some conditions, and to select an approach that has widespread adoption, we implemented the Benjamini-Hochberg procedure.\n\n### Defining a family of tests[​](#defining-a-family-of-tests \"Direct link to Defining a family of tests\")\n\nControlling for multiple comparisons across all of the tests one can run in GrowthBook, even within the context of one experiment, is impractical and can be prohibitively costly in terms of statistical power. Instead, GrowthBook corrects across all metrics, variations, (and dimension values, if available) in a particular result view.\n\ntip\n\nWe correct using all p-values that you can see on one experiment results page, _excluding guardrail metrics_\n\n#### On overall results[​](#on-overall-results \"Direct link to On overall results\")\n\nOn the _experiment results overall page_, we collect all tests across non-guardrail metrics and variations to be part of a family, and correct within those values. The following image circles the p-values that we collect and adjust for on the overall results page for an experiment.\n\n![Demonstrating Correction in Results](https://docs.growthbook.io/images/statistics/pvals-adjusted.png)\n\n#### Within dimensional slices[​](#within-dimensional-slices \"Direct link to Within dimensional slices\")\n\nIf you look within dimensional slices, to account for the additional increase in tests from dimensional splits, we collect correct within the family of tests across all dimension groups, non-guardrail metrics, and variations. The following video scrolls through a corrected set of dimension results; the ones that are adjusted are the non-guardrail metrics, and we include all adjusted p-values in this video (across dimensions and metrics) in one family for correction.\n\ntip\n\nWe never correct across overall _and_ dimension splits at the same time.",
  "title": "Multiple Testing Corrections | GrowthBook Docs",
  "description": "Multiple Testing Corrections",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/statistics/details",
  "markdown": "# Statistical Details | GrowthBook Docs\n\nBoth our Bayesian and our Frequentist engines begin with a similar foundation for estimating experiment effects. We estimate the experiment effect (either the **relative** lift or the **absolute** effect), and its standard error. We create decision making tools from those estimates (e.g., frequentist confidence intervals and p-values, or Bayesian credible intervals and risks) to help you make rollout/rollback decisions.\n\nOur estimates compare an experimental variation (henceforth the treatment) to some baseline variation (henceforth control). Define μC\\\\mu\\_{C} as the population control mean, and define μT\\\\mu\\_{T} as the population treatment mean.\n\nThe absolute treatment effect is Δa\\=μT−μC\\\\Delta\\_{a} = \\\\mu\\_{T}-\\\\mu\\_{C}.\n\nThe relative treatment effect (or lift) is Δr\\=(μT−μC)/μC\\\\Delta\\_{r} = (\\\\mu\\_{T}-\\\\mu\\_{C})/\\\\mu\\_{C} if μC≠0\\\\mu\\_{C}\\\\ne 0 and is undefined otherwise.\n\nThroughout for any population parameter γ\\\\gamma denote its sample counterpart as γ^\\\\hat{\\\\gamma}. For example, the sample absolute effect is Δ^a\\\\hat{\\\\Delta}\\_{a}.\n\n### Lift (Relative Effects)[​](#lift-relative-effects \"Direct link to Lift (Relative Effects)\")\n\nBy default, we estimate lift (i.e. relative effects or percentage changes) from the control to the treatment variations. No matter which engine we use, the statistics we leverage are\n\nΔ^r\\=μ^T−μ^Cμ^Cσ^Δr2\\=σ^C2μ^T2μ^C4nC+σ^T2μ^C2nT\\\\begin{align} \\\\hat{\\\\Delta}\\_r &= \\\\frac{\\\\hat\\\\mu\\_T - \\\\hat\\\\mu\\_C}{\\\\hat\\\\mu\\_C} \\\\\\\\ \\\\hat{\\\\sigma}^2\\_{\\\\Delta\\_r} &= \\\\frac{\\\\hat\\\\sigma^2\\_C \\\\hat\\\\mu^2\\_T}{\\\\hat\\\\mu^4\\_C n\\_C} + \\\\frac{\\\\hat\\\\sigma^2\\_T}{\\\\hat\\\\mu^2\\_C n\\_T} \\\\end{align}\n\nwhere μ^C\\\\hat\\\\mu\\_C and μ^T\\\\hat\\\\mu\\_T are the estimates of our variation means, σ^C2\\\\hat\\\\sigma^2\\_C and σ^T2\\\\hat\\\\sigma^2\\_T are the estimated variances of those means, and nCn\\_C and nTn\\_T are the sample sizes. The variance σ^Δr2\\\\hat{\\\\sigma}^2\\_{\\\\Delta\\_r} is a delta method estimator, as Δ^r\\\\hat{\\\\Delta}\\_r is a ratio.\n\nWe cover how we estimate the variation means and their standard errors below, depending on metric type.\n\n### Absolute Effects[​](#absolute-effects \"Direct link to Absolute Effects\")\n\nThe math for absolute effects is simpler, as our estimator is no longer a ratio.\n\nΔ^a\\=μ^T−μ^Cσ^Δa2\\=σ^C2nC+σ^T2nT\\\\begin{align} \\\\hat{\\\\Delta}\\_a &= \\\\hat\\\\mu\\_T - \\\\hat\\\\mu\\_C \\\\\\\\ \\\\hat{\\\\sigma}^2\\_{\\\\Delta\\_a} &= \\\\frac{\\\\hat\\\\sigma^2\\_C}{n\\_C} + \\\\frac{\\\\hat\\\\sigma^2\\_T}{n\\_T} \\\\end{align}\n\n## Bayesian Engine[​](#bayesian-engine \"Direct link to Bayesian Engine\")\n\nOur Bayesian engine synthesizes the above estimates with information external to the experiment to estimate lift. This synthesis combines the experimental data with the prior distribution, which contains information about the treatment effect before the experiment began.\n\nWe specify the following prior\n\nΔprior∼N(μprior,σprior2).\\\\Delta\\_{prior} \\\\sim N(\\\\mu\\_{prior}, \\\\sigma\\_{prior}^{2}).\n\nThis information is represented by the prior mean μprior\\\\mu\\_{prior} and the prior variance σprior2\\\\sigma\\_{prior}^{2}. The prior mean is your best guess for the treatment effect before the experiment starts. The prior variance determines your confidence in this best guess. A small prior variance corresponds to high confidence, and vice versa. GrowthBook's default prior is an improper prior (i.e., σprior2\\=∞\\\\sigma\\_{\\\\text{prior}}^{2}=\\\\infty) that has no impact.\n\nAs of GrowthBook 3.0, you can specify a prior that overrides the default. As stated above, the prior distribution represents your knowledge of the treatment effect before the experiment begins. GrowthBook uses priors on lift, as this is often easier to conceptualize (e.g., 95% chance the true lift is between -50% and 50%). This knowledge can be weak or strong, and we outline a few examples below.\n\n1.  Weak knowledge: suppose you have little information about your treatment effect, and do not have past data about treatment effects or experiments for this metric. Then use a weak prior, with mean 0 and large variance (e.g., 0.520.5^ 2 or 1).\n2.  Moderate knowledge: perhaps you have run multiple experiments on this metric. Suppose the average lift for these experiments was 0.01, and the variance of lifts was 0.05. Then a prior with mean 0.01 and variance 0.05 can be appropriate. As another example, suppose you believe that your feature impact will be relatively moderate. A N(0,0.32)N(0, 0.3^2) prior, our default when proper priors are enabled, encodes the prior belief that 68% of all experiments have a lift between -30% and 30%, and 95% of all experiments have a lift between -60% and 60%.\n3.  Strong knowledge: suppose you ran a similar experiment last year on the same feature, or you ran this experiment last quarter on a different segment, and your treatment effect estimate was 0.02 and its variance was 0.01. Then a prior with mean 0.02 and variance 0.01 can be appropriate.\n\nIn summary, picking the right prior can add information to your results. If you use a moderately informative or strongly informative prior, conduct a sensitivity analysis by comparing your results to those using a weak prior, to see how sensitive your results are to prior selection. For any proper prior, the effect of the prior diminishes as the sample size increases.\n\nThese priors are normally distributed and our effect estimates above are asymptotically normally distributed via the Central Limit Theorem. Therefore, combining them to compute our posterior beliefs, which will themselves be normally distributed, we get the following mean and variance for our posterior effect estimates:\n\nΔposterior\\=μpriorσprior2+Δ^σ^Δ21σprior2+1σ^Δ2σposterior2\\=11σprior2+1σ^Δ2\\\\begin{align} \\\\Delta\\_{posterior} &= \\\\frac{ \\\\frac{\\\\mu\\_{prior}}{\\\\sigma\\_{prior}^{2}} + \\\\frac{\\\\hat{\\\\Delta}}{\\\\hat{\\\\sigma}^2\\_{\\\\Delta} }}{ \\\\frac{1}{\\\\sigma^2\\_{prior}} + \\\\frac{1}{\\\\hat{\\\\sigma}^2\\_{\\\\Delta}}} \\\\\\\\ \\\\sigma^2\\_{posterior} &= \\\\frac{1}{\\\\frac{1}{\\\\sigma^2\\_{prior}} + \\\\frac{1}{\\\\hat{\\\\sigma}^2\\_{\\\\Delta}}} \\\\end{align}\n\nFor relative effects, we simply plug in the values for our prior and the Δ^r\\\\hat\\\\Delta\\_r and σ^Δr2\\\\hat{\\\\sigma}^2\\_{\\\\Delta\\_r} values from equations (1) and (2).\n\nFor absolute effects, we first rescale the prior so that your prior beliefs represent the same amount of uncertainty for both relative and absolute effects. So we recompute your prior as the following:\n\nμprior,a\\=μprior∣μ^C∣σprior,a2\\=σprior2μ^C2\\\\begin{align\\*} \\\\mu\\_{prior,a} &= \\\\mu\\_{prior} \\\\left|\\\\hat\\\\mu\\_C\\\\right| \\\\\\\\ \\\\sigma^2\\_{prior,a} &= \\\\sigma^2\\_{prior} \\\\hat\\\\mu^2\\_C \\\\\\\\ \\\\end{align\\*}\n\nwhere μprior,a\\\\mu\\_{prior, a} is the prior mean and σprior,a2\\\\sigma\\_{prior,a}^{2} is the prior variance on the absolute scale.\n\nFrom the posterior, we can compute the following quantities of interest\n\n### Chance To Win[​](#chance-to-win \"Direct link to Chance To Win\")\n\nChance to Win is the percentage of the posterior that is greater than 0 in favor of the treatment variation\n\nCTW\\=100%∗(1−Φposterior(0)),CTW = 100\\\\% \\* (1 - \\\\Phi\\_{p osterior}(0)),\n\nwhere Φposterior\\\\Phi\\_{posterior} is the CDF of the distribution N(Δposterior,σposterior2)N(\\\\Delta\\_{posterior}, \\\\sigma^2\\_{posterior}).\n\n### Confidence Interval[​](#confidence-interval \"Direct link to Confidence Interval\")\n\nOur “confidence interval” in the Bayesian engine is an interval from the 2.5th to the 97.5th percentile of the posterior distribution (e.g. Φposterior−1(0.025)\\\\Phi^{-1}\\_{posterior}(0.025) and Φposterior−1(0.975)\\\\Phi^{-1}\\_{posterior}(0.975)). We plot the posterior between these two points in the GrowthBook UI.\n\n## Frequentist Engine[​](#frequentist-engine \"Direct link to Frequentist Engine\")\n\nIn our frequentist engine, we directly use Δ^a\\\\hat\\\\Delta\\_a, Δ^r\\\\hat\\\\Delta\\_r, and their standard errors.\n\n**Sequential Testing** - if you have sequential testing enabled, we implement Asymptotic Confidence Sequences, which you can read more about in the [sequential testing documentation](https://docs.growthbook.io/statistics/sequential). Enabling sequential testing does not affect the mean Δ^\\\\hat\\\\Delta, but it inflates the standard error.\n\n### p-value[​](#p-value \"Direct link to p-value\")\n\nThe p-value is the probability of observing the value Δ^/σ^Δa\\\\hat{\\\\Delta}/\\\\hat{\\\\sigma}\\_{\\\\Delta\\_{a}}if the true Δ\\\\Delta was zero. We conduct two-tailed tests, so the p-value if\n\np\\=2(1−Ft(∣Δ^σ^Δ∣,ν))p = 2\\\\left(1 - F\\_t\\\\left(\\\\left|\\\\frac{\\\\hat\\\\Delta}{\\\\hat\\\\sigma\\_\\\\Delta}\\\\right|, \\\\nu\\\\right)\\\\right)\n\nwhere FtF\\_t is the CDF t-distribution with degrees of freedom ν\\\\nu estimated via the Welch-Satterthwaite approximation. This converges to using the Normal distribution as sample size increases.\n\n### Confidence Interval[​](#confidence-interval-1 \"Direct link to Confidence Interval\")\n\nWe return 95% confidence intervals. They are\n\n\\[Δ^−Ft−1(0.975,ν)σ^Δ,  Δ^+Ft−1(0.975,ν)σ^Δ\\]\\\\left\\[\\\\hat\\\\Delta - F^{-1}\\_t\\\\left(0.975, \\\\nu\\\\right) \\\\hat\\\\sigma\\_\\\\Delta,\\\\; \\\\hat\\\\Delta + F^{-1}\\_t\\\\left(0.975, \\\\nu\\\\right) \\\\hat\\\\sigma\\_\\\\Delta\\\\right\\]\n\n## Estimating variation means[​](#estimating-variation-means \"Direct link to Estimating variation means\")\n\nOur estimates of variation means and their variances (μC\\\\mu\\_C, μT\\\\mu\\_T, σC2\\\\sigma^2\\_C, and σT2\\\\sigma^2\\_T) are the same for both engines. In the following, we will focus on the control variation for simplicity. The math is the same for the treatment variation.\n\nWhile there is no difference across engines, there is a difference in our estimates depending on the metric type being analyzed.\n\n### Mean metrics[​](#mean-metrics \"Direct link to Mean metrics\")\n\nFor mean metrics (e.g. the average revenue per user) we use standard sample mean estimators. This is used for:\n\n*   Metrics that are of type `revenue`, `duration`, and `count` metrics and do not have denominators\n*   or, Fact Metrics of type `mean`\n\nIn these cases, we have, for both variations\n\nμ^C\\=∑i\\=1nCYinCσ^C2\\=1nC−1(∑i\\=1nCYi2−(∑i\\=1nCYi)2nC)\\\\begin{align} \\\\hat\\\\mu\\_C &= \\\\frac{\\\\sum^{n\\_C}\\_{i=1} {Y\\_{i}}}{n\\_C} \\\\\\\\ \\\\hat\\\\sigma^2\\_C &= \\\\frac{1}{n\\_C - 1}\\\\left(\\\\sum^{n\\_C}\\_{i=1} Y^2\\_i - \\\\frac{\\\\left(\\\\sum^{n\\_C}\\_{i=1} Y\\_i\\\\right)^2}{n\\_C}\\\\right) \\\\end{align}\n\nwhere YiY\\_i is the ithi^{\\\\text{th}} unit in the control variation's total metric value.\n\n### Proportion metrics[​](#proportion-metrics \"Direct link to Proportion metrics\")\n\nProportion metrics (e.g. the % of users who purchased a product) cover the following cases:\n\n*   regular Metrics of type `binomial`\n*   Fact Metrics of type `proportion`\n\nIn these cases, we have\n\nμ^C\\=∑i\\=1nCYinCσ^C2\\=μ^C(1−μ^C)\\\\begin{align} \\\\hat\\\\mu\\_C &= \\\\frac{\\\\sum^{n\\_C}\\_{i=1} {Y\\_{i}}}{n\\_C} \\\\\\\\ \\\\hat\\\\sigma^2\\_C &= \\\\hat\\\\mu\\_C (1 - \\\\hat\\\\mu\\_C) \\\\end{align}\n\nwhere YiY\\_i is either 0 or 1 for a user.\n\n### Ratio metrics[​](#ratio-metrics \"Direct link to Ratio metrics\")\n\nRatio metrics (e.g. the bounce rate for the number of bounced sessions over the number of total session) require a bit more care as the unit of analysis (e.g. the session) is not the same as the unit of randomization (e.g. the user).\n\nRatio metrics in GrowthBook are:\n\n*   regular Metrics with a denominator that is type `revenue`, `duration`, and `count`\n*   Fact Metrics of type `ratio`\n\nIn these cases, we have\n\nμ^C\\=∑i\\=1nCMi∑i\\=1nCDiσ^C2\\=1nCμ^D2(σ^M2−2μ^Mμ^Dσ^MD+σ^D2μ^M2μ^D2)\\\\begin{align} \\\\hat\\\\mu\\_C &= \\\\frac{\\\\sum^{n\\_C}\\_{i=1} {M\\_{i}}}{\\\\sum^{n\\_C}\\_{i=1} {D\\_{i}}} \\\\\\\\ \\\\hat\\\\sigma^2\\_C &= \\\\frac{1}{n\\_{C}\\\\hat\\\\mu^2\\_D}\\\\left(\\\\hat\\\\sigma^2\\_M - 2 \\\\frac{\\\\hat\\\\mu\\_M}{\\\\hat\\\\mu\\_D}\\\\hat\\\\sigma\\_{MD} + \\\\hat\\\\sigma^2\\_D\\\\frac{\\\\hat\\\\mu^2\\_M}{\\\\hat\\\\mu^2\\_D} \\\\right) \\\\end{align}\n\nwhere MiM\\_i and DiD\\_i are the ithi^{\\\\text{th}} units' values for the numerator and denominator of the metric, μ^M\\\\hat\\\\mu\\_M and σ^M2\\\\hat\\\\sigma^2\\_M are the estimated sample mean and variance of that metric, and σ^MD\\\\hat\\\\sigma\\_{MD} is the estimated covariance of M and D in the control variation.\n\n### Quantile metrics[​](#quantile-metrics \"Direct link to Quantile metrics\")\n\nThe statistics for quantile metrics are covered more in detail in the [Quantile documentation](https://docs.growthbook.io/statistics/quantile). But in the end we arrive at both a μ^\\\\hat\\\\mu and σ^2\\\\hat\\\\sigma^2 for the desired quantile and its variance and use those in our lift calculations.",
  "title": "Statistical Details | GrowthBook Docs",
  "description": "Statistical Details",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/event-trackers/firebase",
  "markdown": "# Setting up Firebase as an event tracker\n\nGrowthbook will modify its default sql settings to work as seamlessly as possible with Firebase. After choosing Firebase as your data source and filling in the connection info, you can proceed with any modifications of your [configuration settings.](https://docs.growthbook.io/app/datasources)\n\nUnfortunately a detailed guide for Firebase has not been written yet. However we do have a thriving developer community on [Slack](https://slack.growthbook.io/?ref=docs-event-tracker-firebase) that you can reach out to in order to get your implementation working. Once you get your implementation working please consider contributing back to the community by [creating this page](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs).",
  "title": "Setting up Firebase as an event tracker | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your Firebase to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/event-trackers/clevertap",
  "markdown": "# Setting up CleverTap as an event tracker\n\nGrowthbook will modify its default sql settings to work as seamlessly as possible with CleverTap. After choosing CleverTap as your data source and filling in the connection info, you can proceed with any modifications of your [configuration settings.](https://docs.growthbook.io/app/datasources)\n\nUnfortunately a detailed guide for CleverTap has not been written yet. However we do have a thriving developer community on [Slack](https://slack.growthbook.io/?ref=docs-event-tracker-clevertap) that you can reach out to in order to get your implementation working. Once you get your implementation working please consider contributing back to the community by [creating this page](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs).",
  "title": "Setting up CleverTap as an event tracker | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your CleverTap to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/event-trackers/heap",
  "markdown": "# Setting up Heap as an event tracker\n\nGrowthbook will modify its default sql settings to work as seamlessly as possible with Heap. After choosing Heap as your data source and filling in the connection info, you can proceed with any modifications of your [configuration settings.](https://docs.growthbook.io/app/datasources)\n\nUnfortunately a detailed guide for Heap has not been written yet. However we do have a thriving developer community on [Slack](https://slack.growthbook.io/?ref=docs-event-tracker-heap) that you can reach out to in order to get your implementation working. Once you get your implementation working please consider contributing back to the community by [creating this page](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs).",
  "title": "Setting up Heap as an event tracker | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your Heap to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/event-trackers/amplitude",
  "markdown": "# Setting up Amplitude as an event tracker\n\n## Exposure Tracking[​](#exposure-tracking \"Direct link to Exposure Tracking\")\n\nFor client side testing, you can fire a custom track event from the GrowthBook SDK's `trackingCallback` function, like so:\n\n```\n trackingCallback: (experiment, result) => {    amplitude.track('Experiment Viewed', {experimentId: experiment.key, variantId: result.key});  }\n```\n\nYou can also use Amplitudes own experiment javascript format:\n\n```\n trackingCallback: (experiment, result) => {    amplitude.track('$exposure', {flag_key: experiment.key, variant: result.key});  }\n```\n\nYou can read more about Amplitude's exposure event [here](https://www.docs.developers.amplitude.com/experiment/general/exposure-tracking/)\n\n## Integrating with Amplitude Data[​](#integrating-with-amplitude-data \"Direct link to Integrating with Amplitude Data\")\n\nFor GrowthBook to integrate with Amplitude you first must export your Amplitude data to the data warehouse of your choice. You can read more about it on [Amplitudes help pages](https://www.docs.developers.amplitude.com/data/destinations/).\n\nCurrently, Amplitude supports exporting to Redshift, Snowflake, BigQuery, and S3 (and use Athena). Once you have set up a data export to one of these destinations, you can connect GrowthBook to it.\n\nnote\n\nGrowthBook won't automatically create SQL queries for Amplitude, but you can follow the general instructions below. If you need any help, [reach out to us](https://slack.growthbook.io/) and we can help\n\n## Configuration Settings[​](#configuration-settings \"Direct link to Configuration Settings\")\n\nOnce you have chosen your event tracker and data source type and successfully connected, you will be given an opportunity to modify your configuration settings. For many applications GrowthBook will have chosen the correct configuration settings straight out of the box based upon which event tracker you choose. In some instances you may need to tweak them slightly, or in the case of using a custom datasource, define them more explicitly.\n\n### Identifier Types[​](#identifier-types \"Direct link to Identifier Types\")\n\nThese are all the types of identifiers you use to split traffic in an experiment and track metric conversions. Common examples are `user_id`, `anonymous_id`, `device_id`, and `ip_address`.\n\n### Experiment Assignment Queries[​](#experiment-assignment-queries \"Direct link to Experiment Assignment Queries\")\n\nAn experiment assignment query returns which users were part of which experiment, what variation they saw, and when they saw it. Each assignment query is tied to a single identifier type (defined above). You can also have multiple assignment queries if you store that data in different tables, for example one from your email system and one from your back-end.\n\nThe end result of the query should return data like this:\n\n| user\\_id | timestamp | experiment\\_id | variation\\_id |\n| --- | --- | --- | --- |\n| 123 | 2021-08-23-10:53:04 | my-button-test | 0   |\n| 456 | 2021-08-23 10:53:06 | my-button-test | 1   |\n\nThe above assumes the identifier type you are using is `user_id`. If you are using a different identifier, you would use a different column name.\n\nHere's an example query you might use:\n\n```\nSELECT  user_id,  received_at as timestamp,  experiment_id,  variation_idFROM  eventsWHERE  event_type = 'viewed experiment'\n```\n\nMake sure to return the exact column names that GrowthBook is expecting. If your table’s columns use a different name, add an alias in the SELECT list (e.g. `SELECT original_column as new_column`).\n\n#### Duplicate Rows[​](#duplicate-rows \"Direct link to Duplicate Rows\")\n\nIf a user sees an experiment multiple times, you should return multiple rows in your assignment query, one for each time the user was exposed to the experiment.\n\nThis helps us detect when users were exposed to more than one variation, and eventually may be useful in helping build interesting time series.\n\n#### Experiment Dimensions[​](#experiment-dimensions \"Direct link to Experiment Dimensions\")\n\nIn addition to the standard 4 columns above, you can also select additional dimension columns. For example, `browser` or `referrer`. These extra columns can be used to drill down into experiment results.\n\n#### Identifier Join Tables[​](#identifier-join-tables \"Direct link to Identifier Join Tables\")\n\nIf you have multiple identifier types and want to be able to auto-merge them together during analysis, you also need to define identifier join tables. For example, if your experiment is assigned based on `device_id`, but the conversion metric only has a `user_id` column.\n\nThese queries are very simple and just need to return columns for each of the identifier types being joined. For example:\n\n```\nSELECT user_id, device_id FROM logins\n```\n\n#### SQL Template Variables[​](#sql-template-variables \"Direct link to SQL Template Variables\")\n\nWithin your queries, there are several placeholder variables you can use. These will be replaced with strings before being run based on your experiment. This can be useful for giving hints to SQL optimization engines to improve query performance.\n\nThe variables are:\n\n*   **startDate** - `YYYY-MM-DD HH:mm:ss` of the earliest data that needs to be included\n*   **startYear** - Just the `YYYY` of the startDate\n*   **startMonth** - Just the `MM` of the startDate\n*   **startDay** - Just the `DD` of the startDate\n*   **startDateUnix** - Unix timestamp of the startDate (seconds since Jan 1, 1970)\n*   **endDate** - `YYYY-MM-DD HH:mm:ss` of the latest data that needs to be included\n*   **endYear** - Just the `YYYY` of the endDate\n*   **endMonth** - Just the `MM` of the endDate\n*   **endDay** - Just the `DD` of the endDate\n*   **endDateUnix** - Unix timestamp of the endDate (seconds since Jan 1, 1970)\n*   **experimentId** - Either a specific experiment id OR `%` if you should include all experiments\n\nFor example:\n\n```\nSELECT  user_id,  anonymous_id,  received_at as timestamp,  experiment_id,  variation_idFROM  experiment_viewedWHERE  received_at BETWEEN '{{ startDate }}' AND '{{ endDate }}'  AND experiment_id LIKE '{{ experimentId }}'\n```\n\n**Note:** The inserted values do not have surrounding quotes, so you must add those yourself (e.g. use `'{{ startDate }}'` instead of just `{{ startDate }}`)\n\n### Jupyter Notebook Query Runner[​](#jupyter-notebook-query-runner \"Direct link to Jupyter Notebook Query Runner\")\n\nThis setting is only required if you want to export experiment results as a Jupyter Notebook.\n\nThere is no one standard way to store credentials or run SQL queries from Jupyter notebooks, so GrowthBook lets you define your own Python function.\n\nIt needs to be called `runQuery`, accept a single string argument named `sql`, and return a pandas data frame.\n\nHere's an example for a Postgres (or Redshift) data source:\n\n```\nimport osimport psycopg2import pandas as pdfrom sqlalchemy import create_engine, text# Use environment variables or similar for passwords!password = os.getenv('POSTGRES_PW')connStr = f'postgresql+psycopg2://user:{password}@localhost'dbConnection = create_engine(connStr).connect();def runQuery(sql):  return pd.read_sql(text(sql), dbConnection)\n```\n\n**Note:** This python source is stored as plain text in the database. Do not hard-code passwords or sensitive info. Use environment variables (shown above) or another credential store instead.\n\n## Schema Browser[​](#schema-browser \"Direct link to Schema Browser\")\n\nWhen you connect a supported data source to GrowthBook, we automatically generate metadata that is used by our Schema Browser. The Schema Browser is a user-friendly interface that makes writing queries easier as you can easily explore information about the datasource such as databases, schemas, tables, columns, and data types.\n\n![GrowthBook Schema Browser](https://docs.growthbook.io/assets/images/growthbook-schema-browser-40e388a5759c12afef54296d9c0c1980.png)\n\nBelow are the data sources that currently support the Schema Browser:\n\n*   AWS Athena - _Requires a Default Catalog_\n*   BigQuery - _Requires a Project Name and Default Dataset_\n*   ClickHouse\n*   Databricks - _Currently only supported on version 10.2 and above with a Unity Catalog_\n*   MsSQL/SQL Server\n*   MySQL/MariaDB\n*   Postgres\n*   PrestoDB (and Trino) - _Requires a Default Catalog_\n*   Redshift\n*   Snowflake",
  "title": "Setting up Amplitude as an event tracker | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your Amplitude to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/integrations/webflow",
  "markdown": "# Webflow Integration | GrowthBook Docs\n\nUnleash the power of experimentation with GrowthBook to supercharge your Webflow site—no coding skills required!\n\nNote\n\nThis guide walks you through creating experiments using the GrowthBook Visual Editor, which requires a `Pro` subscription. [Learn More](https://www.growthbook.io/pricing).\n\n## Let's Get Started[​](#lets-get-started \"Direct link to Let's Get Started\")\n\n### Step 1: Create a GrowthBook SDK Connection[​](#step-1-create-a-growthbook-sdk-connection \"Direct link to Step 1: Create a GrowthBook SDK Connection\")\n\nTo connect your GrowthBook account to Webflow, you'll need to create a new SDK Connection and select the `Webflow` option. Before saving, confirm that you've enabled the toggles for `Include visual experiments in endpoint's response?` and `Include draft experiments`.\n\n![](https://docs.growthbook.io/assets/images/webflow-sdk-connection-e862e170a41e8efc1a1496130070b738.png)\n\n### Step 2: Add GrowthBook to Your Webflow Site[​](#step-2-add-growthbook-to-your-webflow-site \"Direct link to Step 2: Add GrowthBook to Your Webflow Site\")\n\nOnce the SDK Connection is created, you should see a code snippet that you need to add to your site.\n\nIn a new window, log into your Webflow account, navigate to your site's settings, and select the `Custom Code` tab.\n\nFind the \"Head Code\" section, and paste in the code snippet from GrowthBook. It should look something like this:\n\n![](https://docs.growthbook.io/assets/images/growthbook-webflow-edit-code-dcc022bdb4a9b08cd5e3935fed740609.png)\n\nNote\n\nWhen a user views an experiment, the code above will fire an event that tracks which variation the user saw. If you have Google Analytics 4 (GA4) or Segment installed on your site, you don't have to do any additional configuration. If, however, you need to use a different analytics provider, you can follow our guide [here](https://docs.growthbook.io/lib/script-tag).\n\nOnce added, save and publish the changes and navigate back to GrowthBook.\n\n### Step 3: Install the GrowthBook Chrome Extension[​](#step-3-install-the-growthbook-chrome-extension \"Direct link to Step 3: Install the GrowthBook Chrome Extension\")\n\nThe GrowthBook Chrome Extension allows you to use the Visual Editor to update your Webflow site's content. It's free, and you can download it [here](https://chromewebstore.google.com/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia).\n\n### Step 4: Create a GrowthBook Visual Editor Experiment[​](#step-4-create-a-growthbook-visual-editor-experiment \"Direct link to Step 4: Create a GrowthBook Visual Editor Experiment\")\n\nNow that GrowthBook is installed on your Webflow site, you can create a new experiment using the Visual Editor.\n\nFirst, navigate to \"Experiments\" on the left-hand navigation menu and then click \"Create Experiment\", before selecting \"Design a New Experiment\" and following the on-screen prompts.\n\nOnce you've created your experiment, select \"Visual Editor\" as the editor type and enter the URL of your Webflow site.\n\n![](https://docs.growthbook.io/assets/images/growthbook-webflow-visual-editor-e79bf1f951f849da241d2dc67611168d.png)\n\nYou'll then be redirected to your site, where you can use the Visual Editor to update your site's content.",
  "title": "Webflow Integration | GrowthBook Docs",
  "description": "Unleash the power of experimentation with GrowthBook to supercharge your Webflow site—no coding skills required!",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/event-trackers/fullstory",
  "markdown": "# Setting up Fullstory as an event tracker\n\nGrowthbook will modify its default sql settings to work as seamlessly as possible with Fullstory. After choosing Fullstory as your data source and filling in the connection info, you can proceed with any modifications of your [configuration settings.](https://docs.growthbook.io/app/datasources)\n\nUnfortunately a detailed guide for Fullstory has not been written yet. However we do have a thriving developer community on [Slack](https://slack.growthbook.io/?ref=docs-event-tracker-fullstory) that you can reach out to in order to get your implementation working. Once you get your implementation working please consider contributing back to the community by [creating this page](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs).",
  "title": "Setting up Fullstory as an event tracker | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your Fullstory to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/event-trackers/freshpaint",
  "markdown": "# Setting up Freshpaint as an event tracker\n\n## Event Tracker Setup[​](#event-tracker-setup \"Direct link to Event Tracker Setup\")\n\nFor JS, you can track the experiment exposure events by adding the following code the `trackingCallback` in the GrowthBook SDK.\n\n```\n trackingCallback: (experiment, result) => {    freshpaint.track('Experiment Viewed', {experimentId: experiment.key, variantId: result.key}); }\n```\n\n## Data Source Setup[​](#data-source-setup \"Direct link to Data Source Setup\")\n\nFreshpaint does not support direct data access, instead, to work with GrowthBook, you'll need to export your data to a data warehouse. You can read about the supported data destinations [here](https://documentation.freshpaint.io/destinations/warehouses). Freshpaint lets you export to BigQuery, Databricks, Postgres, Redshift, and Snowflake.\n\nnote\n\nGrowthBook will attempt automatically create SQL queries for Freshpaint, but this may require adjustments. General instructions for setting up SQL sources are below. If you need any help, [reach out to us](https://slack.growthbook.io/) and we can help\n\n## Configuration Settings[​](#configuration-settings \"Direct link to Configuration Settings\")\n\nOnce you have chosen your event tracker and data source type and successfully connected, you will be given an opportunity to modify your configuration settings. For many applications GrowthBook will have chosen the correct configuration settings straight out of the box based upon which event tracker you choose. In some instances you may need to tweak them slightly, or in the case of using a custom datasource, define them more explicitly.\n\n### Identifier Types[​](#identifier-types \"Direct link to Identifier Types\")\n\nThese are all the types of identifiers you use to split traffic in an experiment and track metric conversions. Common examples are `user_id`, `anonymous_id`, `device_id`, and `ip_address`.\n\n### Experiment Assignment Queries[​](#experiment-assignment-queries \"Direct link to Experiment Assignment Queries\")\n\nAn experiment assignment query returns which users were part of which experiment, what variation they saw, and when they saw it. Each assignment query is tied to a single identifier type (defined above). You can also have multiple assignment queries if you store that data in different tables, for example one from your email system and one from your back-end.\n\nThe end result of the query should return data like this:\n\n| user\\_id | timestamp | experiment\\_id | variation\\_id |\n| --- | --- | --- | --- |\n| 123 | 2021-08-23-10:53:04 | my-button-test | 0   |\n| 456 | 2021-08-23 10:53:06 | my-button-test | 1   |\n\nThe above assumes the identifier type you are using is `user_id`. If you are using a different identifier, you would use a different column name.\n\nHere's an example query you might use:\n\n```\nSELECT  user_id,  received_at as timestamp,  experiment_id,  variation_idFROM  eventsWHERE  event_type = 'viewed experiment'\n```\n\nMake sure to return the exact column names that GrowthBook is expecting. If your table’s columns use a different name, add an alias in the SELECT list (e.g. `SELECT original_column as new_column`).\n\n#### Duplicate Rows[​](#duplicate-rows \"Direct link to Duplicate Rows\")\n\nIf a user sees an experiment multiple times, you should return multiple rows in your assignment query, one for each time the user was exposed to the experiment.\n\nThis helps us detect when users were exposed to more than one variation, and eventually may be useful in helping build interesting time series.\n\n#### Experiment Dimensions[​](#experiment-dimensions \"Direct link to Experiment Dimensions\")\n\nIn addition to the standard 4 columns above, you can also select additional dimension columns. For example, `browser` or `referrer`. These extra columns can be used to drill down into experiment results.\n\n#### Identifier Join Tables[​](#identifier-join-tables \"Direct link to Identifier Join Tables\")\n\nIf you have multiple identifier types and want to be able to auto-merge them together during analysis, you also need to define identifier join tables. For example, if your experiment is assigned based on `device_id`, but the conversion metric only has a `user_id` column.\n\nThese queries are very simple and just need to return columns for each of the identifier types being joined. For example:\n\n```\nSELECT user_id, device_id FROM logins\n```\n\n#### SQL Template Variables[​](#sql-template-variables \"Direct link to SQL Template Variables\")\n\nWithin your queries, there are several placeholder variables you can use. These will be replaced with strings before being run based on your experiment. This can be useful for giving hints to SQL optimization engines to improve query performance.\n\nThe variables are:\n\n*   **startDate** - `YYYY-MM-DD HH:mm:ss` of the earliest data that needs to be included\n*   **startYear** - Just the `YYYY` of the startDate\n*   **startMonth** - Just the `MM` of the startDate\n*   **startDay** - Just the `DD` of the startDate\n*   **startDateUnix** - Unix timestamp of the startDate (seconds since Jan 1, 1970)\n*   **endDate** - `YYYY-MM-DD HH:mm:ss` of the latest data that needs to be included\n*   **endYear** - Just the `YYYY` of the endDate\n*   **endMonth** - Just the `MM` of the endDate\n*   **endDay** - Just the `DD` of the endDate\n*   **endDateUnix** - Unix timestamp of the endDate (seconds since Jan 1, 1970)\n*   **experimentId** - Either a specific experiment id OR `%` if you should include all experiments\n\nFor example:\n\n```\nSELECT  user_id,  anonymous_id,  received_at as timestamp,  experiment_id,  variation_idFROM  experiment_viewedWHERE  received_at BETWEEN '{{ startDate }}' AND '{{ endDate }}'  AND experiment_id LIKE '{{ experimentId }}'\n```\n\n**Note:** The inserted values do not have surrounding quotes, so you must add those yourself (e.g. use `'{{ startDate }}'` instead of just `{{ startDate }}`)\n\n### Jupyter Notebook Query Runner[​](#jupyter-notebook-query-runner \"Direct link to Jupyter Notebook Query Runner\")\n\nThis setting is only required if you want to export experiment results as a Jupyter Notebook.\n\nThere is no one standard way to store credentials or run SQL queries from Jupyter notebooks, so GrowthBook lets you define your own Python function.\n\nIt needs to be called `runQuery`, accept a single string argument named `sql`, and return a pandas data frame.\n\nHere's an example for a Postgres (or Redshift) data source:\n\n```\nimport osimport psycopg2import pandas as pdfrom sqlalchemy import create_engine, text# Use environment variables or similar for passwords!password = os.getenv('POSTGRES_PW')connStr = f'postgresql+psycopg2://user:{password}@localhost'dbConnection = create_engine(connStr).connect();def runQuery(sql):  return pd.read_sql(text(sql), dbConnection)\n```\n\n**Note:** This python source is stored as plain text in the database. Do not hard-code passwords or sensitive info. Use environment variables (shown above) or another credential store instead.\n\n## Schema Browser[​](#schema-browser \"Direct link to Schema Browser\")\n\nWhen you connect a supported data source to GrowthBook, we automatically generate metadata that is used by our Schema Browser. The Schema Browser is a user-friendly interface that makes writing queries easier as you can easily explore information about the datasource such as databases, schemas, tables, columns, and data types.\n\n![GrowthBook Schema Browser](https://docs.growthbook.io/assets/images/growthbook-schema-browser-40e388a5759c12afef54296d9c0c1980.png)\n\nBelow are the data sources that currently support the Schema Browser:\n\n*   AWS Athena - _Requires a Default Catalog_\n*   BigQuery - _Requires a Project Name and Default Dataset_\n*   ClickHouse\n*   Databricks - _Currently only supported on version 10.2 and above with a Unity Catalog_\n*   MsSQL/SQL Server\n*   MySQL/MariaDB\n*   Postgres\n*   PrestoDB (and Trino) - _Requires a Default Catalog_\n*   Redshift\n*   Snowflake",
  "title": "Setting up Freshpaint as an event tracker | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your Freshpaint to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/event-trackers/keenio",
  "markdown": "# Setting up KeenIO as an event tracker\n\nGrowthbook will modify its default sql settings to work as seamlessly as possible with KeenIO. After choosing KeenIO as your data source and filling in the connection info, you can proceed with any modifications of your [configuration settings.](https://docs.growthbook.io/app/datasources)\n\nUnfortunately a detailed guide for KeenIO has not been written yet. However we do have a thriving developer community on [Slack](https://slack.growthbook.io/?ref=docs-event-tracker-keenio) that you can reach out to in order to get your implementation working. Once you get your implementation working please consider contributing back to the community by [creating this page](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs).",
  "title": "Setting up KeenIO as an event tracker | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your KeenIO to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/guide/mixpanel",
  "markdown": "# Using GrowthBook with Mixpanel | GrowthBook Docs\n\ncaution\n\nUsing Mixpanel as a direct datasource is not advised and has been placed in maintenance mode. This is because because Mixpanel has placed JQL, their query language, in [maintenance mode](https://developer.mixpanel.com/reference/jql-overview) themselves. Therefore, our integration is limited and may unexpectedly break as they wind down support for JQL.\n\nIn order to ensure long term compatibility with GrowthBook and to receive the full set of features available in GrowthBook, we suggest you set up an export to a data warehouse following [Mixpanel's documentation](https://developer.mixpanel.com/reference/raw-data-export-api) and then use that separate data warehouse (e.g. Snowflake, BigQuery) as your Data Source in GrowthBook.\n\n## Configuring GrowthBook to work with Mixpanel\n\nGrowthBook supports Mixpanel as a data source for your A/B test reports.\n\n## 1\\. Create a Service Account in Mixpanel[​](#1-create-a-service-account-in-mixpanel \"Direct link to 1. Create a Service Account in Mixpanel\")\n\nTo add Mixpanel to GrowthBook you need to create a service account within Mixpanel.\n\n![Add Mixpanel service account](https://docs.growthbook.io/images/guides/mixpanel-2-add-service-account.png)\n\nClick on the add service account. This account needs at least analysis permissions.\n\n![Add Mixpanel service account specifics](https://docs.growthbook.io/images/guides/mixpanel-3-add-service-account-details.png)\n\nOnce you crete the account, you'll get the username and secret. This is the only time you'll see this information, so it's best to leave this page up while you do the next step to add that connection information to GrowthBook.\n\n![Service account details](https://docs.growthbook.io/images/guides/mixpanel-4-service-account-results.png)\n\n## 2\\. Connect GrowthBook to Mixpanel[​](#2-connect-growthbook-to-mixpanel \"Direct link to 2. Connect GrowthBook to Mixpanel\")\n\nFrom the Analysis → Data source section of the GrowthBook Platform, you can add a data source, and then choose Mixpanel from the avaliable options.\n\n![GrowthBook add Mixpanel data source form](https://docs.growthbook.io/images/new-data-sources-modal.png)\n\nThen you'll be asked to enter your Mixpanel connection information:\n\n![GrowthBook add Mixpanel data source form](https://docs.growthbook.io/images/guides/mixpanel-1-add-data-source.png)\n\nAdd the mixpanel information from the previous step here. The other information you'll need is the `project ID` from Mixpanel. You can find this in the the project settings overview from mixpanel\n\n![Get the Mixpanel project ID](https://docs.growthbook.io/images/guides/mixpanel-5-get-project-id.png)\n\n## 3\\. Experiment Tracking Information[​](#3-experiment-tracking-information \"Direct link to 3. Experiment Tracking Information\")\n\nAfter you successfully connect to mixpanel from GrowthBook you'll be asked to enter the experiment event information. These values need to match the names you choose when sending the experiment exposure information to Mixpanel (see step 4), but can be any values you choose. We suggest you use `$experiment started`, `Experiment name` and `Variant name` as in the example below.\n\n![Experiment event naming for GrowthBook](https://docs.growthbook.io/images/guides/mixpanel-6-add-exp-event-names2.png)\n\nThe naming here has to match the event names you pass with the SDK implementation (see step 4).\n\nWhen you've successfully connected GrowthBook to your Mixpanel account, you'll see the experiment tracking information as well as sample code.\n\n![Successful connection to Mixpanel](https://docs.growthbook.io/images/guides/mixpanel-8-successful-connection2.png)\n\n## 4\\. Implement GrowthBook SDK with Mixpanel[​](#4-implement-growthbook-sdk-with-mixpanel \"Direct link to 4. Implement GrowthBook SDK with Mixpanel\")\n\nWhen implementing the GrowthBook SDK there are two things that are needed that are specific to Mixpanel: tracking to Mixpanel when a user is placed into an experiment, and adding the Mixpanel user ID to the list of user attributes. You can find the implementation of the GrowthBook SDKs in many languages, the implementation is similar for each. Shown below is the typescript version:\n\n```\nimport mixpanel from \"mixpanel-browser\";// Create a GrowthBook instanceconst growthbook = new GrowthBook({  trackingCallback: (experiment, result) => {    mixpanel.track(\"$experiment_started\", {      \"Experiment name\": experiment.key,      \"Variant name\": result.variationId,      $source: \"growthbook\",    });  },});// Add the mixpanel user id to the GrowthBook attributes when it loads:mixpanel.init(\"[YOUR PROJECT TOKEN]\", {  debug: true,  loaded: function (mx) {    growthbook.setAttributes({      ...growthbook.getAttributes(),      id: mx.get_distinct_id(),    });  },});\n```\n\nThe project token can be found in the Mixpanel Project Settings.\n\n![Project Tokens from Mixpanel](https://docs.growthbook.io/images/guides/mixpanel-9-project-token.png)\n\nYou will still need to implement the feature flagging side of GrowthBook, where the feature JSON is fetched and other user attributes defined. This implementation instructions can be found for each specific language.\n\nnote\n\nBy default, Mixpanel stores all events as UTC time, but can be changed per project. If the timezones between GrowthBook and your Mixpanel don't match, it can cause results to not show data for the correct time period.",
  "title": "Using GrowthBook with Mixpanel | GrowthBook Docs",
  "description": "GrowthBook supports Mixpanel as a data source for your A/B test reports.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/guide/rudderstack",
  "markdown": "# GrowthBook and RudderStack | GrowthBook Docs\n\n## Configuring GrowthBook to work with RudderStack\n\nGrowthBook supports RudderStack as an event source for easily adding A/B testing to your application. This document is a how-to guide for setting up RudderStack with your application, connecting RudderStack to BigQuery and then connecting GrowthBook to this data.\n\n## 1\\. Setup RudderStack[​](#1-setup-rudderstack \"Direct link to 1. Setup RudderStack\")\n\nIf you have already set up RudderStack, you can skip this step. RudderStack allows you to send events from your application to any data destination, including BigQuery, which is what we're going to use it for here.\n\nOnce you have a RudderStack account, you need to create a BigQuery bucket for the event data to be stored. You can follow the [directions from RudderStack](https://www.rudderstack.com/docs/destinations/storage-platforms/google-cloud-storage/), but the short version is:\n\n*   From the Google Cloud console for BigQuery, create a new bucket (or you can also use an already existing bucket).\n*   Create a new service account under [IAM & Admin → Service Accounts](https://console.cloud.google.com/iam-admin/serviceaccounts) for RudderStack to connect to this bucket.\n*   Give Storage `Object Admin` role access to the newly created service account.\n*   Under the `actions` menu on the service account you just created, click on manage keys to create a new key. Choose key type as JSON. This will cause a JSON key file to be downloaded to your computer.\n\nWith the bucket created, we can create a RudderStack warehouse destination.\n\n![Add a data warehouse destination for RudderStack](https://docs.growthbook.io/images/guides/rudderstack-1-addwarehouse.png) ![Select BigQuery from the list](https://docs.growthbook.io/images/guides/rudderstack-2-adddestination.png) ![Add the BigQuery account information](https://docs.growthbook.io/images/guides/rudderstack-3-addbucket.png)\n\nThe `Project` and `bucket name` needs to match the values you set up when creating the Google cloud project and bucket.\n\nOnce you've created the destination, you should see it successfully connect\n\n![Successfully added the BigQuery account information](https://docs.growthbook.io/images/guides/rudderstack-4-connection-completed.png)\n\nAnd it will show up as a connected destination on your RudderStack Connect dashboard.\n\n![BigQuery connection in rudderstack](https://docs.growthbook.io/images/guides/rudderstack-4.5-bigQueryDestination.png)\n\n## 2\\. Connect GrowthBook[​](#2-connect-growthbook \"Direct link to 2. Connect GrowthBook\")\n\nNow that we have data flowing into BigQuery, we need to have GrowthBook connect to it. It is best practice to create another service account for GrowthBook to connect to BigQuery. (We have a complete guide on how to do this here: [Setting up BigQuery as a data source](https://docs.growthbook.io/guide/bigquery))\n\nNavigate to Analysis → Data Sources from within GrowthBook and click on 'Add Data Source' Button. From the window that pops up, select RudderStack:\n\n![Choose RudderStack data schema](https://docs.growthbook.io/images/new-data-sources-modal.png)\n\nAfter choosing RudderStack you'll be presented with a connection window to connect to BigQuery.\n\n![Connect to your database](https://docs.growthbook.io/images/guides/rudderstack-add-bigquery.png)\n\nWhen successfully connected, you'll be redirected to the data source page. You'll see all the connection options for BigQuery as well as the queries used. By choosing RudderStack as you added the data source, GrowthBook will pre-populate the experiment exposure query which is need to determine which user saw which experiment variation. Depending on your needs, you may still need to adjust these queries - for instance if you're tracking both `anonymous_id` and `user_id`, you'll need to add the `user_id` query.\n\n## 3\\. Add Metrics[​](#3-add-metrics \"Direct link to 3. Add Metrics\")\n\nGrowthBook needs to know what metrics you want to use in your experiments, and how to query this data from BigQuery. This step depends on your needs as an organization. Keep in mind that metric queries will be generic, returning all users who do an event, but will be joined to the experiment exposure information when determining the impact of experiment results.\n\nMetrics are added from the Analysis → Metrics menu.\n\n![Choose RudderStack data schema](https://docs.growthbook.io/images/guides/metrics-addmetric.png) ![Choose RudderStack data schema](https://docs.growthbook.io/images/guides/metrics-metricoverview.png)",
  "title": "GrowthBook and RudderStack | GrowthBook Docs",
  "description": "Learn how to use GrowthBook with RudderStack to easily add A/B testing to your application",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/event-trackers/jitsu",
  "markdown": "# Setting up Jitsu as an event tracker\n\nGrowthbook will modify its default sql settings to work as seamlessly as possible with Jitsu. After choosing Jitsu as your data source and filling in the connection info, you can proceed with any modifications of your [configuration settings.](https://docs.growthbook.io/app/datasources)\n\nUnfortunately a detailed guide for Jitsu has not been written yet. However we do have a thriving developer community on [Slack](https://slack.growthbook.io/?ref=docs-event-tracker-jitsu) that you can reach out to in order to get your implementation working. Once you get your implementation working please consider contributing back to the community by [creating this page](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs).",
  "title": "Setting up Jitsu as an event tracker | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your Jitsu to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/event-trackers/segment",
  "markdown": "# Setting up Segment as an event tracker\n\n## Configuring GrowthBook to work with Segment\n\nGrowthBook supports Segment as an event source for easily adding A/B testing to your application. This document is a how-to guide for setting up Segment with your application, connecting Segment to BigQuery and then connecting GrowthBook to this data.\n\n## 1\\. Setup Segment[​](#1-setup-segment \"Direct link to 1. Setup Segment\")\n\nIf you have already set up Segment, you can skip this step. Segment allows you to send events from your application to any data destination, and supports most data warehouse.\n\n## 2\\. Add Exposure Tracking Event[​](#2-add-exposure-tracking-event \"Direct link to 2. Add Exposure Tracking Event\")\n\nTo track when a user is exposed to an experiment from the client side, you'll want to add a Segment event call to your `trackingCallback` function. This function is called when a user is exposed to an experiment, and is passed the experiment name and variation name.\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  trackingCallback: (experiment, result) => {    // Example using Segment    analytics.track(\"Experiment Viewed\", {      experimentId: experiment.key,      variationId: result.key,    });  }});\n```\n\n## 3\\. Connect GrowthBook to Your Warehouse[​](#3-connect-growthbook-to-your-warehouse \"Direct link to 3. Connect GrowthBook to Your Warehouse\")\n\nNow that we have data flowing into a data warehouse, we need to have GrowthBook connect to it. It is best practice to create another service account for GrowthBook to connect to your data warehouse.\n\n![Choose Segment data schema](https://docs.growthbook.io/images/new-data-sources-modal.png)\n\nAfter choosing Segment you'll be presented with a connection window to connect to your data warehouses. Enter the connection credentials for your data warehouse.\n\nWhen successfully connected, you'll be redirected to the data source page. GrowthBook will automatically create the experiment exposure query which is need to determine which user saw which experiment variation. Depending on your needs, you may still need to adjust these queries - for instance if you're tracking both `anonymous_id` and `user_id`, you'll need to add the `user_id` query.\n\n## 3\\. Add Metrics[​](#3-add-metrics \"Direct link to 3. Add Metrics\")\n\nGrowthBook needs to know what metrics you want to use in your experiments, and how to query this data from BigQuery. This step depends on your needs as an organization. Keep in mind that metric queries will be generic, returning all users who do an event, but will be joined to the experiment exposure information when determining the impact of experiment results.\n\nMetrics are added from the Analysis → Metrics menu.\n\n![Choose Segment data schema](https://docs.growthbook.io/images/guides/metrics-addmetric.png) ![Choose Segment data schema](https://docs.growthbook.io/images/guides/metrics-metricoverview.png)",
  "title": "Setting up Segment as an event tracker | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your Segment to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/guide/matomo",
  "markdown": "# GrowthBook and Matomo | GrowthBook Docs\n\n## Configuring GrowthBook to work with Matomo\n\nGrowthBook makes it easy to do A/B testing using Matomo as an event source. This guide shows you how to set up GrowthBook to work with self-hosted Matomo and the MySQL/MariaDB that it runs on.\n\n## 1\\. Integrate GrowthBook's SDK with Matomo within your application[​](#1-integrate-growthbooks-sdk-with-matomo-within-your-application \"Direct link to 1. Integrate GrowthBook's SDK with Matomo within your application\")\n\nYou can follow the SDK integration guides depending on your language. We need to add the `TrackingCallback` call specifically for Matomo. For this guide, we'll use Javascript (Next.js).\n\nMatomo lets you track custom events, and you can adjust the `Event Category`, `Event Action`, `Event Name`, and `Event Value`. You can read more about the custom tracking call at [Matomo's documentation site](https://matomo.org/faq/reports/implement-event-tracking-with-matomo/).\n\nnote\n\nThere are a few caveats with Matomo's event schema that it is important to be aware of.\n\n*   **Event Category** cannot contain any spaces.\n    \n*   If **Event Name** is 0 or \"0\" it will record null.\n    \n*   **Event Value** must be an integer.\n    \n\nTo work with the default data schema in GrowthBook, we will encode the following:\n\n*   `Event Category`: will have the value `ExperimentViewed` to isolate the exposure events.\n*   `Event Action`: will store the experiment key.\n*   `Event Name`: will store the variation id (with a prefix of `v` or some other string)\n\n```\n// Create a GrowthBook instanceconst growthbook = new GrowthBook({  trackingCallback: (experiment, result) => {    window[\"_paq\"] = window._paq || [];    window._paq.push([      \"trackEvent\",      \"ExperimentViewed\",      experiment.key,      \"v\" + result.variationId,    ]);  },});\n```\n\nnote\n\nWe use the string prefix on the Event Name so that it is saved correctly, as `0` saves as `null`, but `v0` works correctly. This prefix is stripped with the SQL exposure query in step two.\n\nWith that set, we need to load the user id into the GrowthBook user attributes. The following code shows how to do this with the Matomo anonymous `visitor ID`\n\n```\n// add the Matomo anonId when loadedlet visitor_id;if (\"_paq\" in window) {  _paq.push([    function () {      visitor_id = this.getVisitorId();      growthbook.setAttributes({        ...growthbook.getAttributes(),        id: visitor_id,      });    },  ]);}\n```\n\nFor Next.js, we would need to do this in the useEffect and also detect the window in case of a server side render:\n\n```\n// Create a GrowthBook instanceconst growthbook = new GrowthBook({    trackingCallback: (experiment, result) => {        if (window) {            window[\"_paq\"] = window._paq || [];            window._paq.push(['trackEvent', 'ExperimentViewed', experiment.key, \"v\"+result.variationId]);        }    }});export default function MyApp({ Component, pageProps }) {    useEffect(() => {        // Load feature definitions from API        fetch(process.env.NEXT_PUBLIC_GROWTHBOOK_FEATURES_URL)            .then((res) => res.json())            .then((json) => {                growthbook.setFeatures(json.features);            });        // TODO: replace with real targeting attributes        growthbook.setAttributes({            \"company\": \"foo\",            \"browser\": \"foo\",            \"url\": \"foo\"        });        // add the Matomo anonId when loaded        let visitor_id;        if(\"_paq\" in window) {            _paq.push([function () {                visitor_id = this.getVisitorId();                growthbook.setAttributes({ ...growthbook.getAttributes(), id: visitor_id });            }]);        }    }, []);    ...\n```\n\n## 2\\. Add the Data Source for Matomo[​](#2-add-the-data-source-for-matomo \"Direct link to 2. Add the Data Source for Matomo\")\n\nFrom within the GrowthBook application, navigate to the `Data Sources` page from within the `Analysis` section. Click on `add data source` and select `Matomo` from the list of event sources.\n\n![Add Matomo data source](https://docs.growthbook.io/images/new-data-sources-modal.png)\n\nAfter you select Matomo, you will be prompted to connect to your MySQL/Maria database.\n\n![Add MySQL/MariaDB data source](https://docs.growthbook.io/images/guides/matomo-2-connect-to-db.png)\n\nOnce you've completed the connection GrowthBook will and then you can adjust some settings specific to your instance and how you implemented the Matomo tracking code.\n\n![Setting Matomo options](https://docs.growthbook.io/images/guides/matomo-3-matomo-options.png)\n\nWhen you save, you'll have the experiment exposure queries for anonymous and user\\_id set for you.\n\n![Default Matomo experiment exposure query](https://docs.growthbook.io/images/guides/matomo-4-matomo-anon.png)\n\nYou can test running this query directly against your database. It should return a list of experiments exposure events.\n\nYou will still need to define the metrics you want to test against from the metrics settings.",
  "title": "GrowthBook and Matomo | GrowthBook Docs",
  "description": "Configure GrowthBook to do A/B testing using Matomo Analytics",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/event-trackers/mparticle",
  "markdown": "# Setting up MParticle as an event tracker\n\nGrowthbook will modify its default sql settings to work as seamlessly as possible with MParticle. After choosing MParticle as your data source and filling in the connection info, you can proceed with any modifications of your [configuration settings.](https://docs.growthbook.io/app/datasources)\n\nUnfortunately a detailed guide for MParticle has not been written yet. However we do have a thriving developer community on [Slack](https://slack.growthbook.io/?ref=docs-event-tracker-mparticle) that you can reach out to in order to get your implementation working. Once you get your implementation working please consider contributing back to the community by [creating this page](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs).",
  "title": "Setting up MParticle as an event tracker | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your MParticle to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/event-trackers/custom",
  "markdown": "# Setting up a custom data source\n\nGrowthBook just needs you to write a couple SQL queries in order to query your data. Writing this SQL is a (mostly) one-time setup task. After building out this library of queries, they can easily be reused across many experiments.\n\nDon’t worry about the potentially huge number of rows returned by these raw queries. They are never run directly as-is and are instead combined, filtered, and aggregated as part of larger queries. Most of the final queries run by GrowthBook result in fewer than 10 rows returned.\n\nIn the spirit of transparency, any time a query is run, you should see a `View Queries` link in the app to view the raw SQL sent to the data warehouse. This can help with debugging or let you move a query into a tool like Mode Analytics for more advanced analysis.\n\nFind more info on what needs to be configured [here](https://docs.growthbook.io/app/datasources#configuration-settings).",
  "title": "Setting up a custom data source | GrowthBook Docs",
  "description": "This document outlines the steps needed to add a custom data source to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/event-trackers/snowplow",
  "markdown": "# Setting up Snowplow as an event tracker\n\nGrowthbook will modify its default sql settings to work as seamlessly as possible with Snowplow. After choosing Snowplow as your data source and filling in the connection info, you can proceed with any modifications of your [configuration settings.](https://docs.growthbook.io/app/datasources)\n\nUnfortunately a detailed guide for Snowplow has not been written yet. However we do have a thriving developer community on [Slack](https://slack.growthbook.io/?ref=docs-event-tracker-snowplow) that you can reach out to in order to get your implementation working. Once you get your implementation working please consider contributing back to the community by [creating this page](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs).",
  "title": "Setting up Snowplow as an event tracker | GrowthBook Docs",
  "description": "This document outlines the steps needed to add your Snowplow to GrowthBook.",
  "languageCode": "en"
},
{
  "url": "https://docs.growthbook.io/statistics/power-technical",
  "markdown": "# Power Analysis Technical Details | GrowthBook Docs\n\nHere we document the technical details behind GrowthBook power calculations and minimum detectable effect (MDE) calculations for both [frequentist](#frequentist-engine-details) and [Bayesian](#bayesian-engine-details) engines.\n\n## Frequentist engine details[​](#frequentist-engine-details \"Direct link to Frequentist engine details\")\n\n### Frequentist power[​](#frequentist-power \"Direct link to Frequentist power\")\n\nBelow we describe technical details of our implementation. First we start with the definition of power.\n\n**Power** is the probability of a statistically significant result.\n\nWe use the terms below throughout. Define:\n\n1.  the false positive rate as α\\\\alpha (GrowthBook default is α\\=0.05\\\\alpha=0.05).\n2.  the critical values Z1−α/2\\=Φ−1(1−α/2)Z\\_{1- \\\\alpha / 2}= \\\\Phi^{-1}(1-\\\\alpha/2) and Z1−α\\=Φ−1(1−α)Z\\_{1-\\\\alpha}= \\\\Phi^{-1}(1-\\\\alpha) where Φ−1\\\\Phi^{-1} is the inverse CDF of the standard normal distribution.\n3.  the true relative treatment effect as Δ\\\\Delta, its estimate as Δ^\\\\hat{\\\\Delta} and its estimated standard error as σ^Δ\\\\hat{\\\\sigma}\\_{\\\\Delta}. Note that as the sample size nn increases, σ^Δ\\\\hat{\\\\sigma}\\_{\\\\Delta} decreases by a factor of 1/n1/\\\\sqrt{n}.\n\nWe make the following assumptions:\n\n1.  equal sample sizes across control and treatment variations. If unequal sample sizes are used in the experiment, use the smaller of the two sample sizes. This will produce conservative power estimates.\n2.  equal variance across control and treatment variations;\n3.  observations across users are independent and identically distributed;\n4.  all metrics have finite variance; and\n5.  you are running a two-sample t-test. If in practice you use CUPED, your power will be higher.\n\nFor a 1-sided test, the power is\n\nπ\\=P(Δ^σ^Δ\\>Z1−α)\\=P(Δ^−Δσ^Δ\\>Z1−α−Δσ^Δ)\\=1−Φ(Z1−α−Δσ^Δ).\\\\begin{align} \\\\pi = P\\\\left(\\\\frac{\\\\hat{\\\\Delta}}{\\\\hat{\\\\sigma}\\_{\\\\Delta}} > Z\\_{1-\\\\alpha}\\\\right)=P\\\\left(\\\\frac{\\\\hat{\\\\Delta}-\\\\Delta}{\\\\hat{\\\\sigma}\\_{\\\\Delta}} > Z\\_{1-\\\\alpha}-\\\\frac{\\\\Delta}{\\\\hat{\\\\sigma}\\_{\\\\Delta}}\\\\right)=1 - \\\\Phi\\\\left(Z\\_{1-\\\\alpha}-\\\\frac{\\\\Delta}{\\\\hat{\\\\sigma}\\_{\\\\Delta}}\\\\right). \\\\end{align}\n\nFor a 2-sided test (all GrowthBook tests are 2-sided), power is composed of the probability of a statistically significant positive result and a statistically significant negative result. Using the same algebra as in Equation 1 (except using Z1−0.5αZ\\_{1-0.5\\\\alpha} for the critical value), the probability of a statistically significant positive result is\n\nπpos\\=1−Φ(Z1−α/2−Δσ^Δ).\\\\begin{align} \\\\pi\\_{pos} &= 1 - \\\\Phi\\\\left(Z\\_{1-\\\\alpha/2}-\\\\frac{\\\\Delta}{\\\\hat{\\\\sigma}\\_{\\\\Delta}}\\\\right). \\\\end{align}\n\nThe probability of a statistically significant negative result is\n\nπneg\\=P(Δ^σ^Δ<Zα/2)\\=P(Δ^−Δσ^Δ<Zα/2−Δσ^Δ)\\=Φ(Zα/2−Δσ^Δ).\\\\begin{align} \\\\pi\\_{neg} &= P\\\\left(\\\\frac{\\\\hat{\\\\Delta}}{\\\\hat{\\\\sigma}\\_{\\\\Delta}} < Z\\_{\\\\alpha/2}\\\\right)=P\\\\left(\\\\frac{\\\\hat{\\\\Delta}-\\\\Delta}{\\\\hat{\\\\sigma}\\_{\\\\Delta}} < Z\\_{\\\\alpha/2}-\\\\frac{\\\\Delta}{\\\\hat{\\\\sigma}\\_{\\\\Delta}}\\\\right)=\\\\Phi\\\\left(Z\\_{\\\\alpha/2}-\\\\frac{\\\\Delta}{\\\\hat{\\\\sigma}\\_{\\\\Delta}}\\\\right). \\\\end{align}\n\nFor a 2-sided test, the power equals\n\nπ\\=1−Φ(Z1−α/2−Δσ^Δ)+Φ(Zα/2−Δσ^Δ).\\\\begin{align} \\\\pi = 1 - \\\\Phi\\\\left(Z\\_{1-\\\\alpha/2}-\\\\frac{\\\\Delta}{\\\\hat{\\\\sigma}\\_{\\\\Delta}}\\\\right) + \\\\Phi(Z\\_{\\\\alpha/2} - \\\\frac{\\\\Delta}{\\\\hat{\\\\sigma}\\_{\\\\Delta}}). \\\\end{align}\n\n### Frequentist minimum detectable effect[​](#frequentist-minimum-detectable-effect \"Direct link to Frequentist minimum detectable effect\")\n\nSome customers want to know what effect size is required to produce at least π\\\\pi power.  \nThe **minimum detectable effect** is the smallest Δ\\\\Delta for which nominal power (e.g., 80%) is achieved.\n\nBelow we describe commonly used MDE calculations, though we do not use these at GrowthBook.  \nFor a 1-sided test there is a closed form solution for the MDE. Solving Equation 1 for Δ\\\\Delta produces\n\nMDE\\=σ^Δ(Φ−1(1−α)−Φ−1(1−π)).\\\\begin{align} \\\\text{MDE} &= \\\\hat{\\\\sigma}\\_{\\\\Delta}\\\\left(\\\\Phi^{-1}(1 - \\\\alpha)-\\\\Phi^{-1}(1 - \\\\pi)\\\\right). \\\\end{align}\n\nIn the 2-sided case there is no closed form solution.  \nOften in practice the MDE is defined as the solution to inverting Equation 2.  \nThis ignores the negligible term in Equation 3, and produces power estimates very close to π\\\\pi:\n\nMDEtwo-sided\\=σ^Δ(Φ−1(1−α/2)−Φ−1(1−π)).\\\\begin{align} \\\\text{MDE}\\_{\\\\text{two-sided}} &= \\\\hat{\\\\sigma}\\_{\\\\Delta}\\\\left(\\\\Phi^{-1}(1 - \\\\alpha/2)-\\\\Phi^{-1}(1 - \\\\pi)\\\\right). \\\\end{align}\n\nThis approach works when effects are defined on the absolute scale, where the uncertainty of effect estimate does not depend upon the true absolute effect. For relative inference, this does not hold, and so GrowthBook uses a different approach. The terms below are used to help define the variance of the sample lift.\n\n1.  Define ΔAbs\\\\Delta\\_{Abs} as the absolute effect.\n2.  Define μA\\\\mu\\_{A} as the population mean of variation AA and σ2\\\\sigma^{2} as the population variance.\n3.  For variation BB analogously define μB\\\\mu\\_{B}; recall that we assume equal variance across treatment arms.\n4.  Define NN as the per-variation sample size.\n5.  Define the sample counterparts as (μ^A\\\\hat{\\\\mu}\\_{A}, σ^A2\\\\hat{\\\\sigma}\\_{A}^{2}, μ^B\\\\hat{\\\\mu}\\_{B}, and σ^B2\\\\hat{\\\\sigma}\\_{B}^{2}).\n\nThen the variance of the sample lift is\n\nσ^Δ2\\=σ2N1μA2+σ2N∗μB2μA4\\=σ2N1μA2+σ2N∗(μA+ΔAbs)2μA4.\\\\begin{align} \\\\hat{\\\\sigma}\\_{\\\\Delta}^{2} &= \\\\frac{\\\\sigma^{2}}{N}\\\\frac{1}{\\\\mu\\_{A}^{2}} + \\\\frac{\\\\sigma^{2}}{N} \\*\\\\frac{\\\\mu\\_{B}^{2}}{\\\\mu\\_{A}^{4}} \\\\\\\\&= \\\\frac{\\\\sigma^{2}}{N}\\\\frac{1}{\\\\mu\\_{A}^{2}} + \\\\frac{\\\\sigma^{2}}{N} \\*\\\\frac{\\\\left(\\\\mu\\_{A}+\\\\Delta\\_{Abs}\\\\right)^{2}}{\\\\mu\\_{A}^{4}}. \\\\end{align}\n\nTherefore, when inverting the power formula above to find the minimum Δ\\\\Delta that produces at least 80% power, the uncertainty term σ^Δ\\\\hat{\\\\sigma}\\_{\\\\Delta} changes as Δ\\\\Delta changes.  \nTo find the MDE we solve for the equation below, where we make explicit the dependence of σ^Δ\\\\hat{\\\\sigma}\\_{\\\\Delta} on Δ\\\\Delta:\n\nΔσ^Δ(Δ)\\=Φ−1(1−α/2)−Φ−1(1−π).\\\\begin{align\\*} \\\\frac{\\\\Delta}{\\\\hat{\\\\sigma}\\_{\\\\Delta}(\\\\Delta)} = \\\\Phi^{-1}\\\\left({1-\\\\alpha/2}\\\\right) - \\\\Phi^{-1}(1 - \\\\pi). \\\\end{align\\*}\n\nDefine the constant k\\=Φ−1(1−α/2)−Φ−1(1−π)k = \\\\Phi^{-1}\\\\left({1-\\\\alpha/2}\\\\right) - \\\\Phi^{-1}(1 - \\\\pi). We solve for μB\\\\mu\\_{B} in:\n\n(μB−μA)/μAVar(Δ^)\\=k  ⟺  (μB−μA)2\\=k2μA2Var(Δ^)\\=k2μA2(σ2N1μA2+σ2N∗μB2μA4).\\\\frac{(\\\\mu\\_{B}-\\\\mu\\_{A})/\\\\mu\\_{A}}{\\\\sqrt{\\\\text{Var}(\\\\hat{\\\\Delta})}} = k \\\\iff (\\\\mu\\_{B}-\\\\mu\\_{A})^{2} =k^{2}\\\\mu\\_{A}^{2}\\\\text{Var}(\\\\hat{\\\\Delta}) = k^{2}\\\\mu\\_{A}^{2}\\\\left(\\\\frac{\\\\sigma^{2}}{N}\\\\frac{1}{\\\\mu\\_{A}^{2}} + \\\\frac{\\\\sigma^{2}}{N} \\*\\\\frac{\\\\mu\\_{B}^{2}}{\\\\mu\\_{A}^{4}}\\\\right).\n\nRearranging terms shows that μB2(1−σ2Nk2μA2)+μB(−2μA)+(μA2−k2σ2N)\\=0.\\\\mu\\_{B}^{2}\\\\left(1-\\\\frac{\\\\sigma^{2}}{N}\\\\frac{k^{2}}{\\\\mu\\_{A}^{2}}\\\\right) + \\\\mu\\_{B}\\\\left(-2\\\\mu\\_{A}\\\\right) + \\\\left(\\\\mu\\_{A}^{2}-k^{2}\\\\frac{\\\\sigma^{2}}{N}\\\\right) = 0.\n\nThis is quadratic in μB\\\\mu\\_{B} and has solution\n\nμB\\=2μA±4μA2−4(1−σ2Nk2μA2)(μA2−k2σ2N)2(1−σ2Nk2μA2)\\=μA±μA2−(1−σ2Nk2μA2)(μA2−k2σ2N)(1−σ2Nk2μA2).\\\\mu\\_{B} = \\\\frac{2 \\\\mu\\_{A} \\\\pm \\\\sqrt{4 \\\\mu\\_{A}^{2}-4\\\\left(1-\\\\frac{\\\\sigma^{2}}{N}\\\\frac{k^{2}}{\\\\mu\\_{A}^{2}}\\\\right)\\\\left(\\\\mu\\_{A}^{2}-k^{2}\\\\frac{\\\\sigma^{2}}{N}\\\\right)}}{2\\\\left(1-\\\\frac{\\\\sigma^{2}}{N}\\\\frac{k^{2}}{\\\\mu\\_{A}^{2}}\\\\right)} = \\\\frac{\\\\mu\\_{A} \\\\pm \\\\sqrt{\\\\mu\\_{A}^{2}-\\\\left(1-\\\\frac{\\\\sigma^{2}}{N}\\\\frac{k^{2}}{\\\\mu\\_{A}^{2}}\\\\right)\\\\left(\\\\mu\\_{A}^{2}-k^{2}\\\\frac{\\\\sigma^{2}}{N}\\\\right)}}{\\\\left(1-\\\\frac{\\\\sigma^{2}}{N}\\\\frac{k^{2}}{\\\\mu\\_{A}^{2}}\\\\right)} .\n\nThe discriminant reduces to\n\nk2∗σ2N(2−σ2N∗k2μA2).k^{2} \\* \\\\frac{\\\\sigma^{2}}{N} \\\\left(2 - \\\\frac{\\\\sigma^{2}}{N} \\* \\\\frac{k^{2}}{\\\\mu\\_{A}^{2}}\\\\right).\n\nso a solution for μB\\\\mu\\_{B} exists if and only if\n\n2−σ2N∗k2μA2\\>0  ⟺  2\\>σ2N∗k2μA2  ⟺  N\\>σ2k22μA2.\\\\begin{align} 2 - \\\\frac{\\\\sigma^{2}}{N} \\* \\\\frac{k^{2}}{\\\\mu\\_{A}^{2}} > 0 &\\\\iff 2 > \\\\frac{\\\\sigma^{2}}{N} \\* \\\\frac{k^{2}}{\\\\mu\\_{A}^{2}} \\\\iff N > \\\\frac{\\\\sigma^{2}k^{2}}{2\\\\mu\\_{A}^{2}}. \\\\end{align}\n\nSimilarly, the MDE returned can be negative if the denominator is negative, which is nonsensical.  \nWe return cases only where the denominator is positive, which occurs if and only if:\n\n(1−σ2Nk2μA2)\\>0  ⟺  (1−σ2Nk2μA2)\\>0  ⟺  N\\>σ2k2μA2.\\\\begin{align} \\\\left(1-\\\\frac{\\\\sigma^{2}}{N}\\\\frac{k^{2}}{\\\\mu\\_{A}^{2}}\\\\right) > 0 \\\\iff \\\\left(1-\\\\frac{\\\\sigma^{2}}{N}\\\\frac{k^{2}}{\\\\mu\\_{A}^{2}}\\\\right) > 0 \\\\iff N > \\\\frac{\\\\sigma^{2}k^{2}}{\\\\mu\\_{A}^{2}}. \\\\end{align}\n\nThe condition in Equation 10 is stricter than the condition in Equation 9.\n\nIn summary, there will be some combinations of (μA,σ2)(\\\\mu\\_{A}, \\\\sigma\\_{2}) where the MDE does not exist for a given NN. If α\\=0.05\\\\alpha=0.05 and π\\=0.8\\\\pi=0.8, then k≈2.8k\\\\approx 2.8. Therefore, a rule of thumb is that NN needs to be roughly 9 times larger than the ratio of the variance to the squared mean to return an MDE. In these cases, NN needs to be increased.\n\n### Sequential testing[​](#sequential-testing \"Direct link to Sequential testing\")\n\nTo estimate power under sequential testing, we adjust the variance term σ^δ\\\\hat{\\\\sigma}\\_{\\\\delta} to account for sequential testing, and then input this adjusted variance into our power formula. We assume that you look at the data only once, so our power estimate below is a lower bound for the actual power under sequential testing. Otherwise we would have to make assumptions about the temporal correlation of the data generating process.\n\nIn sequential testing we construct confidence intervals as\n\nΔ^±σ^∗N∗2(Nρ2+1)N2ρ2log⁡(Nρ2+1α)\\\\begin{align\\*} \\\\hat{\\\\Delta} &\\\\pm \\\\hat{\\\\sigma}\\*\\\\sqrt{N} \\* \\\\sqrt{\\\\frac{2(N\\\\rho^2 + 1)}{N^2\\\\rho^2}\\\\log\\\\left(\\\\frac{\\\\sqrt{N\\\\rho^2 + 1}}{\\\\alpha}\\\\right)} \\\\end{align\\*}\n\nwhere\n\nρ\\=−2log(α)+log(−2log(α)+1)N∗\\\\rho = \\\\sqrt{\\\\frac{-2\\\\text{log}(\\\\alpha) + \\\\text{log}(-2 \\\\text{log}(\\\\alpha) + 1)}{N^\\*}}\n\nand N⋆N^{\\\\star} is a tuning parameter. This approach relies upon asymptotic normality. For power analysis we rewrite the confidence interval as\n\nΔ^±σ^∗N∗2(Nρ2+1)N2ρ2log⁡(Nρ2+1α)Z1−α/2Z1−α/2\\=Δr^±σ~Z1−α/2\\\\begin{align\\*} \\\\hat{\\\\Delta} &\\\\pm \\\\hat{\\\\sigma}\\*\\\\sqrt{N} \\* \\\\sqrt{\\\\frac{2(N\\\\rho^2 + 1)}{N^2\\\\rho^2}\\\\log\\\\left(\\\\frac{\\\\sqrt{N\\\\rho^2 + 1}}{\\\\alpha}\\\\right)}\\\\frac{Z\\_{1-\\\\alpha/2}}{Z\\_{1-\\\\alpha/2}} \\\\\\\\&=\\\\hat{\\\\Delta\\_{r}} \\\\pm \\\\tilde{\\\\sigma}Z\\_{1-\\\\alpha/2} \\\\end{align\\*}\n\nwhere\n\nσ~\\=σ^∗N2(Nρ2+1)N2ρ2log⁡(Nρ2+1α)1Z1−α/2\\\\tilde{\\\\sigma} = \\\\hat{\\\\sigma}\\*\\\\sqrt{N}\\\\sqrt{\\\\frac{2(N\\\\rho^2 + 1)}{N^2\\\\rho^2}\\\\log\\\\left(\\\\frac{\\\\sqrt{N\\\\rho^2 + 1}}{\\\\alpha}\\\\right)}\\\\frac{1}{Z\\_{1-\\\\alpha/2}}.\n\nWe use power analysis described above, except we substitute σ~2\\\\tilde{\\\\sigma}^{2} for σ^Δ2\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}.\n\n## Bayesian engine details[​](#bayesian-engine-details \"Direct link to Bayesian engine details\")\n\n### Bayesian power[​](#bayesian-power \"Direct link to Bayesian power\")\n\nFor Bayesian power analysis, we let users specify the prior distribution of the treatment effect. We then estimate Bayesian power, which is the probability that the (1−α)(1 - \\\\alpha) credible interval does not contain 0.\n\nWe assume a conjugate normal-normal model, as follows:\n\nΔ∼N(μprior,σprior2)Δ^∣Δ∼N(Δ,σ^Δ2).\\\\begin{align\\*} \\\\Delta &\\\\stackrel{}{\\\\sim}\\\\mathcal{N}\\\\left(\\\\mu\\_{prior}, \\\\sigma\\_{prior}^{2}\\\\right) \\\\\\\\ \\\\hat{\\\\Delta}|\\\\Delta &\\\\stackrel{}{\\\\sim}\\\\mathcal{N}\\\\left(\\\\Delta, \\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}\\\\right). \\\\end{align\\*}\n\nIn words, the model has two parts: 1) the normal prior for the treatment effect, which is specified by you; and 2) conditional upon the treatment effect, the estimated effect is normally distributed. The normal prior has several advantages, including: 1) bell-shaped distribution around the prior mean, so that extreme estimates will be shrunk more towards the prior than moderate estimates; 2) the ability to specify two moments, which is often the right amount of information for a prior; and 3) simplicity.  \nThe conditional normality of the effect estimate is motivated by the central limit theorem.\n\nWe use the normal distribution below to approximate the posterior:\n\nΔ∣Δ^∼N(Ω−1ω,Ω−1)Ω\\=1/σprior2+1/σ^Δ2ω\\=μprior/σprior2+Δ^/σ^Δ2.\\\\begin{align\\*} \\\\Delta|\\\\hat{\\\\Delta} &\\\\stackrel{}{\\\\sim}\\\\mathcal{N}\\\\left(\\\\Omega^{-1}\\\\omega, \\\\Omega^{-1}\\\\right) \\\\\\\\\\\\Omega &= 1/\\\\sigma\\_{prior}^{2} + 1/\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2} \\\\\\\\\\\\omega &= \\\\mu\\_{prior}/\\\\sigma\\_{prior}^{2} + \\\\hat{\\\\Delta}/\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}. \\\\end{align\\*}\n\nThis is an approximation to the posterior because Δ\\\\Delta affects σ^Δ2\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}. We tested this approximation through extensive simulations, and found it had comparable coverage and mean squared error to a posterior distribution empirically sampled using Metropolis Hastings.\n\nWe define rejection as the 100(1−α)100(1-\\\\alpha)% confidence interval not containing zero.  \nFor our posterior approximation, this occurs if the posterior mean for Δ∣Δ^\\\\Delta|\\\\hat{\\\\Delta} (i.e., Ω−1ω\\\\Omega^{-1}\\\\omega) divided by its posterior standard deviation(i.e., Ω−1)\\\\left(\\\\text{i.e., }\\\\sqrt{\\\\Omega^{-1}}\\\\right) is beyond the the appropriate critical threshold Z⋆Z^{\\\\star} (e.g., Φ−1(0.975)\\\\Phi^{-1}(0.975) for α\\=0.05\\\\alpha=0.05).\n\nInside of a Bayesian framework, it can help to permit the case where the prior model is misspecified.  \nThat is, the prior specified by the customer differs from the true prior that generates the treatment effect.  \nWe permit misspecification of the prior for Δ\\\\Delta, as we assume that the true data generating process (DGP) is Δ∼N(μ⋆,σ⋆2)\\\\Delta \\\\stackrel{}{\\\\sim}\\\\mathcal{N}\\\\left(\\\\mu\\_{\\\\star}, \\\\sigma\\_{\\\\star}^{2}\\\\right), while the specified DGP has Δ∼N(μprior,σprior2)\\\\Delta \\\\stackrel{}{\\\\sim}\\\\mathcal{N}\\\\left(\\\\mu\\_{prior}, \\\\sigma\\_{prior}^{2}\\\\right). We assume the prior is specified on the relative scale.\n\nIn derivations below we use the marginal distribution of Δ^\\\\hat{\\\\Delta}, which we find using its moment generating function:\n\nE\\[exp⁡tΔ^\\]\\=EΔ\\[E\\[exp⁡tΔ^∣Δ\\]\\]\\=EΔ\\[exp⁡tΔ+t2σ^Δ2\\]\\=exp⁡t2σ^Δ2EΔ\\[exp⁡tΔ\\] \\=exp⁡t2σ^Δ2exp⁡tμ⋆+t2σ⋆2∼N(μ⋆,σ⋆2+σ^Δ2).\\\\begin{align\\*} E\\\\left\\[\\\\exp^{t\\\\hat{\\\\Delta}}\\\\right\\] &= E\\_{\\\\Delta}\\\\left\\[E\\\\left\\[\\\\exp^{t\\\\hat{\\\\Delta}}|\\\\Delta\\\\right\\]\\\\right\\] \\\\\\\\&= E\\_{\\\\Delta}\\\\left\\[\\\\exp^{t\\\\Delta + t^{2}\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right\\] \\\\\\\\&= \\\\exp^{ t^{2}\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}E\\_{\\\\Delta}\\\\left\\[\\\\exp^{t\\\\Delta}\\\\right\\]\\\\ \\\\\\\\&= \\\\exp^{ t^{2}\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\exp^{t\\\\mu^{\\\\star} + t^{2}\\\\sigma\\_{\\\\star}^{2}} \\\\\\\\&\\\\stackrel{}{\\\\sim}\\\\mathcal{N}\\\\left(\\\\mu^{\\\\star}, \\\\sigma\\_{\\\\star}^{2}+\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}\\\\right). \\\\end{align\\*}\n\nFor a 2-sided test the probability of rejection is\n\nP(∣Ω−1ωΩ−1/2∣\\>Z1−α/2)\\=P(∣(1σprior2+1σ^Δ2)−1/2(μpriorσprior2+Δ^σ^Δ2)∣\\>Z1−α/2)\\=P(∣(μpriorσprior2+Δ^σ^Δ2)∣\\>(1σprior2+1σ^Δ2)1/2Z1−α/2)\\=P((μpriorσprior2+Δ^σ^Δ2)\\>(1σprior2+1σ^Δ2)1/2Z1−α/2)+P((μpriorσprior2+Δ^σ^Δ2)<−(1σprior2+1σ^Δ2)1/2Z1−α/2)\\=P(Δ^\\>σ^Δ2\\[(1σprior2+1σ^Δ2)1/2Z1−α/2−μpriorσprior2\\])+P(Δ^<−σ^Δ2\\[(1σprior2+1σ^Δ2)1/2Z1−α/2+μpriorσprior2\\])\\=P(Δ^−μ⋆σ^Δ2+σ⋆2\\>σ^Δ2\\[(1σprior2+1σ^Δ2)1/2Z1−α/2−μpriorσprior2\\]−μ⋆σ^Δ2+σ⋆2)+P(Δ^−μ⋆σ^Δ2+σ⋆2<−σ^Δ2\\[(1σprior2+1σ^Δ2)1/2Z1−α/2+μpriorσprior2\\]−μ⋆σ^Δ2+σ⋆2)\\=1−Φ(σ^Δ2\\[(1σprior2+1σ^Δ2)1/2Z1−α/2−μpriorσprior2\\]−μ⋆σ^Δ2+σ⋆2)+Φ(−σ^Δ2\\[(1σprior2+1σ^Δ2)1/2Z1−α/2+μpriorσprior2\\]−μ⋆σ^Δ2+σ⋆2).\\\\begin{align\\*} &P\\\\left(\\\\left|\\\\frac{\\\\Omega^{-1}\\\\omega}{\\\\Omega^{-1/2}}\\\\right| > Z\\_{1-\\\\alpha/2}\\\\right) \\\\\\\\&=P\\\\left(\\\\left|\\\\left(\\\\frac{1}{\\\\sigma\\_{prior}^{2}} + \\\\frac{1}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)^{-1/2} \\\\left(\\\\frac{\\\\mu\\_{prior}}{\\\\sigma\\_{prior}^{2}} + \\\\frac{\\\\hat{\\\\Delta}}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)\\\\right|> Z\\_{1-\\\\alpha/2}\\\\right) \\\\\\\\&= P\\\\left(\\\\left|\\\\left(\\\\frac{\\\\mu\\_{prior}}{\\\\sigma\\_{prior}^{2}} + \\\\frac{\\\\hat{\\\\Delta}}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)\\\\right|> \\\\left(\\\\frac{1}{\\\\sigma\\_{prior}^{2}} + \\\\frac{1}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)^{1/2} Z\\_{1-\\\\alpha/2}\\\\right) \\\\\\\\&=P\\\\left(\\\\left(\\\\frac{\\\\mu\\_{prior}}{\\\\sigma\\_{prior}^{2}} + \\\\frac{\\\\hat{\\\\Delta}}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)> \\\\left(\\\\frac{1}{\\\\sigma\\_{prior}^{2}} + \\\\frac{1}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)^{1/2} Z\\_{1-\\\\alpha/2}\\\\right) \\\\\\\\&+ P\\\\left(\\\\left(\\\\frac{\\\\mu\\_{prior}}{\\\\sigma\\_{prior}^{2}} + \\\\frac{\\\\hat{\\\\Delta}}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)< -\\\\left(\\\\frac{1}{\\\\sigma\\_{prior}^{2}} + \\\\frac{1}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)^{1/2} Z\\_{1-\\\\alpha/2}\\\\right) \\\\\\\\&= P\\\\left(\\\\hat{\\\\Delta}> \\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}\\\\left\\[\\\\left(\\\\frac{1}{\\\\sigma\\_{prior}^{2}} + \\\\frac{1}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)^{1/2} Z\\_{1-\\\\alpha/2} - \\\\frac{\\\\mu\\_{prior}}{\\\\sigma\\_{prior}^{2}}\\\\right\\]\\\\right) \\\\\\\\&+ P\\\\left(\\\\hat{\\\\Delta}< -\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}\\\\left\\[\\\\left(\\\\frac{1}{\\\\sigma\\_{prior}^{2}} + \\\\frac{1}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)^{1/2} Z\\_{1-\\\\alpha/2} + \\\\frac{\\\\mu\\_{prior}}{\\\\sigma\\_{prior}^{2}}\\\\right\\]\\\\right) \\\\\\\\&= P \\\\left( \\\\frac{\\\\hat{\\\\Delta}-\\\\mu\\_{\\\\star}}{\\\\sqrt{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}+\\\\sigma\\_{\\\\star}^{2}}}> \\\\frac{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}\\\\left\\[\\\\left(\\\\frac{1}{\\\\sigma\\_{prior}^{2}} + \\\\frac{1}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)^{1/2} Z\\_{1-\\\\alpha/2} - \\\\frac{\\\\mu\\_{prior}}{\\\\sigma\\_{prior}^{2}}\\\\right\\]-\\\\mu\\_{\\\\star}}{\\\\sqrt{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}+\\\\sigma^{2}\\_{\\\\star}}}\\\\right) \\\\\\\\&+ P\\\\left(\\\\frac{\\\\hat{\\\\Delta}-\\\\mu\\_{\\\\star}}{\\\\sqrt{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}+\\\\sigma\\_{\\\\star}^{2}}}< \\\\frac{-\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}\\\\left\\[\\\\left(\\\\frac{1}{\\\\sigma\\_{prior}^{2}} + \\\\frac{1}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)^{1/2} Z\\_{1-\\\\alpha/2} + \\\\frac{\\\\mu\\_{prior}}{\\\\sigma\\_{prior}^{2}}\\\\right\\]-\\\\mu\\_{\\\\star}}{\\\\sqrt{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}+\\\\sigma\\_{\\\\star}^{2}}}\\\\right) \\\\\\\\&= 1-\\\\Phi\\\\left(\\\\frac{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}\\\\left\\[\\\\left(\\\\frac{1}{\\\\sigma\\_{prior}^{2}} + \\\\frac{1}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)^{1/2} Z\\_{1-\\\\alpha/2} - \\\\frac{\\\\mu\\_{prior}}{\\\\sigma\\_{prior}^{2}}\\\\right\\]-\\\\mu\\_{\\\\star}}{\\\\sqrt{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}+\\\\sigma^{2}\\_{\\\\star}}}\\\\right) \\\\\\\\&+ \\\\Phi\\\\left(\\\\frac{-\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}\\\\left\\[\\\\left(\\\\frac{1}{\\\\sigma\\_{prior}^{2}} + \\\\frac{1}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)^{1/2} Z\\_{1-\\\\alpha/2} + \\\\frac{\\\\mu\\_{prior}}{\\\\sigma\\_{prior}^{2}}\\\\right\\]-\\\\mu\\_{\\\\star}}{\\\\sqrt{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}+\\\\sigma\\_{\\\\star}^{2}}}\\\\right). \\\\end{align\\*}\n\nIn practice GrowthBook assumes there is a true fixed effect size, i.e., the variance of the data generating process σ⋆2\\\\sigma\\_{\\\\star}^{2} equals 0, and μ⋆\\=Δ\\\\mu\\_{\\\\star} = \\\\Delta, so two-sided power is\n\nπ\\=1−Φ(σ^Δ2\\[(1σprior2+1σ^Δ2)1/2Z1−α/2−μpriorσprior2\\]−Δσ^Δ2)+Φ(−σ^Δ2\\[(1σprior2+1σ^Δ2)1/2Z1−α/2−μpriorσprior2\\]−Δσ^Δ2).\\\\begin{align} \\\\begin{split} \\\\pi &= 1-\\\\Phi\\\\left( \\\\frac{ \\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}\\\\left\\[\\\\left(\\\\frac{1}{\\\\sigma\\_{prior}^{2}} + \\\\frac{1}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)^{1/2} Z\\_{1-\\\\alpha/2} - \\\\frac{\\\\mu\\_{prior}}{\\\\sigma\\_{prior}^{2}}\\\\right\\]-\\\\Delta} {\\\\sqrt{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}} \\\\right) \\\\\\\\&+\\\\Phi\\\\left( \\\\frac{ -\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}\\\\left\\[\\\\left(\\\\frac{1}{\\\\sigma\\_{prior}^{2}} + \\\\frac{1}{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}\\\\right)^{1/2} Z\\_{1-\\\\alpha/2} - \\\\frac{\\\\mu\\_{prior}}{\\\\sigma\\_{prior}^{2}}\\\\right\\]-\\\\Delta} {\\\\sqrt{\\\\hat{\\\\sigma}\\_{\\\\Delta}^{2}}} \\\\right) . \\\\end{split} \\\\end{align}\n\nWe assume that σ⋆2\\=0\\\\sigma\\_{\\\\star}^{2}=0 for simplicity and because large values of σ⋆2\\\\sigma\\_{\\\\star}^{2} can result in negative MDEs (see [here](#bayesian-minimum-detectable-effect)). If the prior variance σprior2\\\\sigma\\_{prior}^{2} equals infinity then Equation 11 reduces to Equation 4.\n\n### Bayesian minimum detectable effect[​](#bayesian-minimum-detectable-effect \"Direct link to Bayesian minimum detectable effect\")\n\nMDEs are not well defined in the Bayesian literature. We provide MDEs in Bayesian power analysis for customers that are used to conceptualizing MDEs and want to be able to leverage prior information in their analysis.\n\nWe could define the MDE as the minimum value of μ⋆\\\\mu\\_{\\\\star} such that at least π\\\\pi power is achieved. This definition is Bayesian in that it permits uncertainty in the parameters in the data generating process. However, if σ⋆2\\\\sigma\\_{\\\\star}^{2} is large, then there are some combinations of parameters where the MDE can be negative. That is, negative values of μ⋆\\\\mu\\_{\\\\star} result in power being at least π\\\\pi. Usually the inferential focus is the true treatment effect for the experiment (Δ\\\\Delta), not the population mean from which Δ\\\\Delta is just one realization (μ⋆\\\\mu\\_{\\\\star}), so we set σ⋆2\\=0\\\\sigma\\_{\\\\star}^{2} = 0 and consequently, Δ\\=μ⋆\\\\Delta = \\\\mu\\_{\\\\star}. This is why in practice we frame our Bayesian MDE as, \\`\\`given our prior beliefs and the data generating process, what is the probability we can detect an effect of size Δ\\\\Delta?'', where Δ\\\\Delta is a fixed number.\n\nAnother subtlety is that for a fixed sample size, Equation 11 can be decreasing in effect size, illustrated by Figure 1.\n\nFigure 1\n\n![Metric Icon showing CUPED Disabled Reason](https://docs.growthbook.io/images/statistics/power-decreasing.png)\n\nFigure 1 shows the case where the group sample sizes are 1500, the data mean is 0.1, the data variance is 0.5, the specified prior mean μprior\\=0.1\\\\mu\\_{prior} = 0.1, the specified prior variance σprior2\\\\sigma\\_{prior}^{2} is 0.3, and the variance of the data generating process σ⋆2\\\\sigma\\_{\\\\star}^{2} is 0. Nominal 80% power occurs at 1.65, continues to increase in effect size until the effect size is about 3, and then begins decreasing. Power decreases in effect size because the variance in Equation 8 is quadratic in effect size, and in Equation 11 the term in front of Z1−α/2Z\\_{1-\\\\alpha/2} goes to infinity as Δ\\\\Delta gets large. The coefficient in front of Z1−α/2Z\\_{1-\\\\alpha/2} in Equation 4 is 1, so frequentist power is increasing in effect size in all cases. Monotonicity does hold for Bayesian power for absolute effects, where the variance is not affected by the effect size.\n\nBecause power is not monotonic in effect size, we perform a grid search across effect sizes ranging from 0 to 500%. The derivative of Equation 11 is bounded in absolute value by 2ϕ(0)<0.82 \\\\phi(0) < 0.8, where ϕ(.)\\\\phi(.) is the density of the standard normal distribution.\n\nLet the length of one grid cell equal ll. We evaluate power at the points {0,l,2l,...,5−l,5}.\\\\left\\\\{0, l, 2l, ..., 5 -l , 5\\\\right\\\\}. Suppose the power at the kthk^{\\\\text{th}} gridpoint is πk\\\\pi\\_{k}, k\\>0k>0. Because 1) the maximum slope from the midpoint to the endpoint of the cell is no greater than 2ϕ(0)2 \\\\phi(0); and 2) the maximum distance from where power is evaluated is l/2l/2, the maximum power in \\[(l−1)k,lk\\]\\\\left\\[(l-1)k, lk \\\\right\\] is no greater than max⁡(πk−1,πk)+ϕ(0)l\\\\max\\\\left(\\\\pi\\_{k-1}, \\\\pi\\_{k}\\\\right)+\\\\phi(0)l. Motivated by this fact, we describe our approach in Algorithm 1.\n\nIn words, Algorithm 1 evaluates power at Δ\\={0,0.001,0.002,...5}\\\\Delta=\\\\left\\\\{0, 0.001, 0.002, ... 5\\\\right\\\\}, until it finds the first element kk such that π(k)\\>\\=π−ϕ(0)l\\\\pi(k) >= \\\\pi - \\\\phi(0)l. If power exceeds this threshold, then we evaluate a finer grid across the range from \\[k−l,k\\]\\[k-l, k\\], where the grid cell length is l′<<ll' << l. We find the first element (if it exists) of this finer grid where power is at least π\\\\pi. We return this first element as the solution if it exists; otherwise we keep searching the coarse grid.\n\nAlgorithm 1\n\n1.  Define ll as the length between points at which power is evaluated (l=0.001 in production).\n2.  Define the grid of points between 0 and 5 as G\\={0,l,2l,...,5−l,5}.\\\\mathcal{G} = \\\\left\\\\{0, l, 2l, ..., 5 -l , 5\\\\right\\\\}.\n3.  Begin evaluating π(k)\\\\pi(k) for k∈Gk \\\\in \\\\mathcal{G}.\n4.  If π(k)<π−ϕ(0)l\\\\pi(k) < \\\\pi - \\\\phi(0)l for all kk, then the MDE does not exist. Otherwise:\n5.  Find the first k∈Gk \\\\in \\\\mathcal{G} such that π(k)\\>\\=π−ϕ(0)l\\\\pi(k) >= \\\\pi - \\\\phi(0)l. Define l′l' as a finer grid resolution (in production, l′\\=l/100l' = l / 100). Find the first element of the set {k−1,k−1+l′,k−1+2l′,...,k−l′,k}\\\\left\\\\{k -1, k-1+l', k-1+2l', ..., k-l', k \\\\right\\\\} such that power evaluated at that point is at least π\\\\pi. If no such point exists, return to the coarser grid search in Step 3.\n\nIf power exceeds π+ϕ(0)l′\\\\pi + \\\\phi(0)l' at any point in \\[0,5\\]\\[0, 5\\], then Algorithm 1 is guaranteed to detect it. In practice we use l\\=10−3l=10^{-3} and l′\\=10−5l'=10^{-5}.",
  "title": "Power Analysis Technical Details | GrowthBook Docs",
  "description": "Technical details of power analysis",
  "languageCode": "en"
}]