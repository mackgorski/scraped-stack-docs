[
  {
    "url": "https://docs.docker.com/compose/",
    "markdown": "# Docker Compose overview | Docker Docs\n\nDocker Compose is a tool for defining and running multi-container applications. It is the key to unlocking a streamlined and efficient development and deployment experience.\n\nCompose simplifies the control of your entire application stack, making it easy to manage services, networks, and volumes in a single, comprehensible YAML configuration file. Then, with a single command, you create and start all the services from your configuration file.\n\nCompose works in all environments; production, staging, development, testing, as well as CI workflows. It also has commands for managing the whole lifecycle of your application:\n\n*   Start, stop, and rebuild services\n*   View the status of running services\n*   Stream the log output of running services\n*   Run a one-off command on a service",
    "title": "Docker Compose overview | Docker Docs\n",
    "description": "Learn how to use Docker Compose to define and run multi-container applications with this detailed introduction to the tool.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/",
    "markdown": "# Overview of Docker Build | Docker Docs\n\nDocker Build is one of Docker Engine's most used features. Whenever you are creating an image you are using Docker Build. Build is a key part of your software development life cycle allowing you to package and bundle your code and ship it anywhere.\n\nDocker Build is more than a command for building images, and it's not only about packaging your code. It's a whole ecosystem of tools and features that support not only common workflow tasks but also provides support for more complex and advanced scenarios.",
    "title": "Overview of Docker Build | Docker Docs\n",
    "description": "Get an overview of Docker Build to package and bundle your code and ship it anywhere",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/",
    "markdown": "# Docker Engine overview | Docker Docs\n\nDocker Engine is an open source containerization technology for building and containerizing your applications. Docker Engine acts as a client-server application with:\n\n*   A server with a long-running daemon process [`dockerd`](https://docs.docker.com/reference/cli/dockerd).\n*   APIs which specify interfaces that programs can use to talk to and instruct the Docker daemon.\n*   A command line interface (CLI) client [`docker`](https://docs.docker.com/reference/cli/docker/).\n\nThe CLI uses [Docker APIs](https://docs.docker.com/engine/api/) to control or interact with the Docker daemon through scripting or direct CLI commands. Many other Docker applications use the underlying API and CLI. The daemon creates and manages Docker objects, such as images, containers, networks, and volumes.\n\nFor more details, see [Docker Architecture](https://docs.docker.com/guides/docker-overview/#docker-architecture).\n\nThe Docker Engine is licensed under the Apache License, Version 2.0. See [LICENSE](https://github.com/moby/moby/blob/master/LICENSE) for the full license text.\n\nHowever, for commercial use of Docker Engine obtained via Docker Desktop within larger enterprises (exceeding 250 employees OR with annual revenue surpassing $10 million USD), a [paid subscription](https://www.docker.com/pricing/) is required.",
    "title": "Docker Engine overview | Docker Docs\n",
    "description": "Find a comprehensive overview of Docker Engine, including how to install, storage details, networking, and more",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/",
    "markdown": "# How services work | Docker Docs\n\nTo deploy an application image when Docker Engine is in Swarm mode, you create a service. Frequently a service is the image for a microservice within the context of some larger application. Examples of services might include an HTTP server, a database, or any other type of executable program that you wish to run in a distributed environment.\n\nWhen you create a service, you specify which container image to use and which commands to execute inside running containers. You also define options for the service including:\n\n*   The port where the swarm makes the service available outside the swarm\n*   An overlay network for the service to connect to other services in the swarm\n*   CPU and memory limits and reservations\n*   A rolling update policy\n*   The number of replicas of the image to run in the swarm\n\nWhen you deploy the service to the swarm, the swarm manager accepts your service definition as the desired state for the service. Then it schedules the service on nodes in the swarm as one or more replica tasks. The tasks run independently of each other on nodes in the swarm.\n\nFor example, imagine you want to load balance between three instances of an HTTP listener. The diagram below shows an HTTP listener service with three replicas. Each of the three instances of the listener is a task in the swarm.\n\n![ HTTP listener service with three replicas](https://docs.docker.com/engine/swarm/images/services-diagram.webp)\n\nA container is an isolated process. In the Swarm mode model, each task invokes exactly one container. A task is analogous to a “slot” where the scheduler places a container. Once the container is live, the scheduler recognizes that the task is in a running state. If the container fails health checks or terminates, the task terminates.\n\nA task is the atomic unit of scheduling within a swarm. When you declare a desired service state by creating or updating a service, the orchestrator realizes the desired state by scheduling tasks. For instance, you define a service that instructs the orchestrator to keep three instances of an HTTP listener running at all times. The orchestrator responds by creating three tasks. Each task is a slot that the scheduler fills by spawning a container. The container is the instantiation of the task. If an HTTP listener task subsequently fails its health check or crashes, the orchestrator creates a new replica task that spawns a new container.\n\nA task is a one-directional mechanism. It progresses monotonically through a series of states: assigned, prepared, running, etc. If the task fails, the orchestrator removes the task and its container and then creates a new task to replace it according to the desired state specified by the service.\n\nThe underlying logic of Docker's Swarm mode is a general purpose scheduler and orchestrator. The service and task abstractions themselves are unaware of the containers they implement. Hypothetically, you could implement other types of tasks such as virtual machine tasks or non-containerized process tasks. The scheduler and orchestrator are agnostic about the type of the task. However, the current version of Docker only supports container tasks.\n\nThe diagram below shows how Swarm mode accepts service create requests and schedules tasks to worker nodes.\n\n![Services flow](https://docs.docker.com/engine/swarm/images/service-lifecycle.webp)\n\n### [Pending services](#pending-services)\n\nA service may be configured in such a way that no node currently in the swarm can run its tasks. In this case, the service remains in state `pending`. Here are a few examples of when a service might remain in state `pending`.\n\n> **Tip** If your only intention is to prevent a service from being deployed, scale the service to 0 instead of trying to configure it in such a way that it remains in `pending`.\n\n*   If all nodes are paused or drained, and you create a service, it is pending until a node becomes available. In reality, the first node to become available gets all of the tasks, so this is not a good thing to do in a production environment.\n    \n*   You can reserve a specific amount of memory for a service. If no node in the swarm has the required amount of memory, the service remains in a pending state until a node is available which can run its tasks. If you specify a very large value, such as 500 GB, the task stays pending forever, unless you really have a node which can satisfy it.\n    \n*   You can impose placement constraints on the service, and the constraints may not be able to be honored at a given time.\n    \n\nThis behavior illustrates that the requirements and configuration of your tasks are not tightly tied to the current state of the swarm. As the administrator of a swarm, you declare the desired state of your swarm, and the manager works with the nodes in the swarm to create that state. You do not need to micro-manage the tasks on the swarm.\n\nThere are two types of service deployments, replicated and global.\n\nFor a replicated service, you specify the number of identical tasks you want to run. For example, you decide to deploy an HTTP service with three replicas, each serving the same content.\n\nA global service is a service that runs one task on every node. There is no pre-specified number of tasks. Each time you add a node to the swarm, the orchestrator creates a task and the scheduler assigns the task to the new node. Good candidates for global services are monitoring agents, anti-virus scanners or other types of containers that you want to run on every node in the swarm.\n\nThe diagram below shows a three-service replica in gray and a global service in black.\n\n![Global vs replicated services](https://docs.docker.com/engine/swarm/images/replicated-vs-global.webp)\n\n*   Read about how Swarm mode [nodes](https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/) work.\n*   Learn how [PKI](https://docs.docker.com/engine/swarm/how-swarm-mode-works/pki/) works in Swarm mode.",
    "title": "How services work | Docker Docs\n",
    "description": "How swarm mode services work",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/install/",
    "markdown": "# Install Docker Engine | Docker Docs\n\nThis section describes how to install Docker Engine on Linux, also known as Docker CE. Docker Engine is also available for Windows, macOS, and Linux, through Docker Desktop. For instructions on how to install Docker Desktop, see:\n\n*   [Docker Desktop for Linux](https://docs.docker.com/desktop/install/linux-install/)\n*   [Docker Desktop for Mac (macOS)](https://docs.docker.com/desktop/install/mac-install/)\n*   [Docker Desktop for Windows](https://docs.docker.com/desktop/install/windows-install/)\n\n| Platform | x86\\_64 / amd64 | arm64 / aarch64 | arm (32-bit) | ppc64le | s390x |\n| --- | --- | --- | --- | --- | --- |\n| [CentOS](https://docs.docker.com/engine/install/centos/) | ✅   | ✅   |     | ✅   |     |\n| [Debian](https://docs.docker.com/engine/install/debian/) | ✅   | ✅   | ✅   | ✅   |     |\n| [Fedora](https://docs.docker.com/engine/install/fedora/) | ✅   | ✅   |     | ✅   |     |\n| [Raspberry Pi OS (32-bit)](https://docs.docker.com/engine/install/raspberry-pi-os/) |     |     | ✅   |     |     |\n| [RHEL](https://docs.docker.com/engine/install/rhel/) | 🚧  | 🚧  |     |     | ✅   |\n| [SLES](https://docs.docker.com/engine/install/sles/) |     |     |     |     | ✅   |\n| [Ubuntu](https://docs.docker.com/engine/install/ubuntu/) | ✅   | ✅   | ✅   | ✅   | ✅   |\n| [Binaries](https://docs.docker.com/engine/install/binaries/) | ✅   | ✅   | ✅   |     |     |\n\n🚧 = Experimental\n\n### [Other Linux distros](#other-linux-distros)\n\n> **Note**\n> \n> While the following instructions may work, Docker doesn't test or verify installation on distro derivatives.\n\n*   If you use Debian derivatives such as \"BunsenLabs Linux\", \"Kali Linux\" or \"LMDE\" (Debian-based Mint) should follow the installation instructions for [Debian](https://docs.docker.com/engine/install/debian/), substitute the version of your distro for the corresponding Debian release. Refer to the documentation of your distro to find which Debian release corresponds with your derivative version.\n*   Likewise, if you use Ubuntu derivatives such as \"Kubuntu\", \"Lubuntu\" or \"Xubuntu\" you should follow the installation instructions for [Ubuntu](https://docs.docker.com/engine/install/ubuntu/), substituting the version of your distro for the corresponding Ubuntu release. Refer to the documentation of your distro to find which Ubuntu release corresponds with your derivative version.\n*   Some Linux distros provide a package of Docker Engine through their package repositories. These packages are built and maintained by the Linux distro's package maintainers and may have differences in configuration or are built from modified source code. Docker isn't involved in releasing these packages and you should report any bugs or issues involving these packages to your Linux distro's issue tracker.\n\nDocker provides [binaries](https://docs.docker.com/engine/install/binaries/) for manual installation of Docker Engine. These binaries are statically linked and you can use them on any Linux distro.\n\nDocker Engine has two types of update channels, **stable** and **test**:\n\n*   The **stable** channel gives you the latest versions released for general availability.\n*   The **test** channel gives you pre-release versions that are ready for testing before general availability.\n\nUse the test channel with caution. Pre-release versions include experimental and early-access features that are subject to breaking changes.\n\nDocker Engine is an open source project, supported by the Moby project maintainers and community members. Docker doesn't provide support for Docker Engine. Docker provides support for Docker products, including Docker Desktop, which uses Docker Engine as one of its components.\n\nFor information about the open source project, refer to the [Moby project website](https://mobyproject.org/).\n\n### [Upgrade path](#upgrade-path)\n\nPatch releases are always backward compatible with its major and minor version.\n\n### [Licensing](#licensing)\n\nDocker Engine is licensed under the Apache License, Version 2.0. See [LICENSE](https://github.com/moby/moby/blob/master/LICENSE) for the full license text.\n\nIf you discover a security issue, we request that you bring it to our attention immediately.\n\nDO NOT file a public issue. Instead, submit your report privately to security@docker.com.\n\nSecurity reports are greatly appreciated, and Docker will publicly thank you for it.\n\nAfter setting up Docker, you can learn the basics with [Getting started with Docker](https://docs.docker.com/guides/getting-started/).",
    "title": "Install Docker Engine | Docker Docs\n",
    "description": "Learn how to choose the best method for you to install Docker Engine. This client-server application is available on Linux, Mac, Windows, and as a static binary.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/how-swarm-mode-works/pki/",
    "markdown": "# Manage swarm security with public key infrastructure (PKI)\n\nThe Swarm mode public key infrastructure (PKI) system built into Docker makes it simple to securely deploy a container orchestration system. The nodes in a swarm use mutual Transport Layer Security (TLS) to authenticate, authorize, and encrypt the communications with other nodes in the swarm.\n\nWhen you create a swarm by running `docker swarm init`, Docker designates itself as a manager node. By default, the manager node generates a new root Certificate Authority (CA) along with a key pair, which are used to secure communications with other nodes that join the swarm. If you prefer, you can specify your own externally-generated root CA, using the `--external-ca` flag of the [docker swarm init](https://docs.docker.com/reference/cli/docker/swarm/init/) command.\n\nThe manager node also generates two tokens to use when you join additional nodes to the swarm: one worker token and one manager token. Each token includes the digest of the root CA's certificate and a randomly generated secret. When a node joins the swarm, the joining node uses the digest to validate the root CA certificate from the remote manager. The remote manager uses the secret to ensure the joining node is an approved node.\n\nEach time a new node joins the swarm, the manager issues a certificate to the node. The certificate contains a randomly generated node ID to identify the node under the certificate common name (CN) and the role under the organizational unit (OU). The node ID serves as the cryptographically secure node identity for the lifetime of the node in the current swarm.\n\nThe diagram below illustrates how manager nodes and worker nodes encrypt communications using a minimum of TLS 1.2.\n\n![TLS diagram](https://docs.docker.com/engine/swarm/images/tls.webp?w=600)\n\nThe example below shows the information from a certificate from a worker node:\n\nBy default, each node in the swarm renews its certificate every three months. You can configure this interval by running the `docker swarm update --cert-expiry <TIME PERIOD>` command. The minimum rotation value is 1 hour. Refer to the [docker swarm update](https://docs.docker.com/reference/cli/docker/swarm/update/) CLI reference for details.\n\n> **Note**\n> \n> Mirantis Kubernetes Engine (MKE), formerly known as Docker UCP, provides an external certificate manager service for the swarm. If you run swarm on MKE, you shouldn't rotate the CA certificates manually. Instead, contact Mirantis support if you need to rotate a certificate.\n\nIn the event that a cluster CA key or a manager node is compromised, you can rotate the swarm root CA so that none of the nodes trust certificates signed by the old root CA anymore.\n\nRun `docker swarm ca --rotate` to generate a new CA certificate and key. If you prefer, you can pass the `--ca-cert` and `--external-ca` flags to specify the root certificate and to use a root CA external to the swarm. Alternately, you can pass the `--ca-cert` and `--ca-key` flags to specify the exact certificate and key you would like the swarm to use.\n\nWhen you issue the `docker swarm ca --rotate` command, the following things happen in sequence:\n\n1.  Docker generates a cross-signed certificate. This means that a version of the new root CA certificate is signed with the old root CA certificate. This cross-signed certificate is used as an intermediate certificate for all new node certificates. This ensures that nodes that still trust the old root CA can still validate a certificate signed by the new CA.\n    \n2.  Docker also tells all nodes to immediately renew their TLS certificates. This process may take several minutes, depending on the number of nodes in the swarm.\n    \n3.  After every node in the swarm has a new TLS certificate signed by the new CA, Docker forgets about the old CA certificate and key material, and tells all the nodes to trust the new CA certificate only.\n    \n    This also causes a change in the swarm's join tokens. The previous join tokens are no longer valid.\n    \n\nFrom this point on, all new node certificates issued are signed with the new root CA, and do not contain any intermediates.\n\n*   Read about how [nodes](https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/) work.\n*   Learn how Swarm mode [services](https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/) work.",
    "title": "Manage swarm security with public key infrastructure (PKI) | Docker Docs\n",
    "description": "How PKI works in swarm mode",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/how-swarm-mode-works/swarm-task-states/",
    "markdown": "# Swarm task states | Docker Docs\n\nDocker lets you create services, which can start tasks. A service is a description of a desired state, and a task does the work. Work is scheduled on swarm nodes in this sequence:\n\n1.  Create a service by using `docker service create`.\n2.  The request goes to a Docker manager node.\n3.  The Docker manager node schedules the service to run on particular nodes.\n4.  Each service can start multiple tasks.\n5.  Each task has a life cycle, with states like `NEW`, `PENDING`, and `COMPLETE`.\n\nTasks are execution units that run once to completion. When a task stops, it isn't executed again, but a new task may take its place.\n\nTasks advance through a number of states until they complete or fail. Tasks are initialized in the `NEW` state. The task progresses forward through a number of states, and its state doesn't go backward. For example, a task never goes from `COMPLETE` to `RUNNING`.\n\nTasks go through the states in the following order:\n\n| Task state | Description |\n| --- | --- |\n| `NEW` | The task was initialized. |\n| `PENDING` | Resources for the task were allocated. |\n| `ASSIGNED` | Docker assigned the task to nodes. |\n| `ACCEPTED` | The task was accepted by a worker node. If a worker node rejects the task, the state changes to `REJECTED`. |\n| `READY` | The worker node is ready to start the task |\n| `PREPARING` | Docker is preparing the task. |\n| `STARTING` | Docker is starting the task. |\n| `RUNNING` | The task is executing. |\n| `COMPLETE` | The task exited without an error code. |\n| `FAILED` | The task exited with an error code. |\n| `SHUTDOWN` | Docker requested the task to shut down. |\n| `REJECTED` | The worker node rejected the task. |\n| `ORPHANED` | The node was down for too long. |\n| `REMOVE` | The task is not terminal but the associated service was removed or scaled down. |\n\nRun `docker service ps <service-name>` to get the state of a task. The `CURRENT STATE` field shows the task's state and how long it's been there.\n\n*   [Learn about swarm tasks](https://github.com/docker/swarmkit/blob/master/design/task_model.md)",
    "title": "Swarm task states | Docker Docs\n",
    "description": "Learn about tasks that are scheduled on your swarm.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/install/centos/",
    "markdown": "# Install Docker Engine on CentOS\n\nTo get started with Docker Engine on CentOS, make sure you [meet the prerequisites](#prerequisites), and then follow the [installation steps](#installation-methods).\n\n### [OS requirements](#os-requirements)\n\nTo install Docker Engine, you need a maintained version of one of the following CentOS versions:\n\n*   CentOS 9 (stream)\n\nThe `centos-extras` repository must be enabled. This repository is enabled by default. If you have disabled it, you need to re-enable it.\n\n### [Uninstall old versions](#uninstall-old-versions)\n\nOlder versions of Docker went by `docker` or `docker-engine`. Uninstall any such older versions before attempting to install a new version, along with associated dependencies.\n\n`yum` might report that you have none of these packages installed.\n\nImages, containers, volumes, and networks stored in `/var/lib/docker/` aren't automatically removed when you uninstall Docker.\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n*   You can [set up Docker's repositories](#install-using-the-repository) and install from them, for ease of installation and upgrade tasks. This is the recommended approach.\n    \n*   You can download the RPM package, [install it manually](#install-from-a-package), and manage upgrades completely manually. This is useful in situations such as installing Docker on air-gapped systems with no access to the internet.\n    \n*   In testing and development environments, you can use automated [convenience scripts](#install-using-the-convenience-script) to install Docker.\n    \n\n### [Install using the rpm repository](#install-using-the-repository)\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\n#### [Set up the repository](#set-up-the-repository)\n\nInstall the `yum-utils` package (which provides the `yum-config-manager` utility) and set up the repository.\n\n#### [Install Docker Engine](#install-docker-engine)\n\n1.  Install Docker Engine, containerd, and Docker Compose:\n    \n    * * *\n    \n    To install the latest version, run:\n    \n    If prompted to accept the GPG key, verify that the fingerprint matches `060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35`, and if so, accept it.\n    \n    This command installs Docker, but it doesn't start Docker. It also creates a `docker` group, however, it doesn't add any users to the group by default.\n    \n    To install a specific version, start by listing the available versions in the repository:\n    \n    The list returned depends on which repositories are enabled, and is specific to your version of CentOS (indicated by the `.el9` suffix in this example).\n    \n    Install a specific version by its fully qualified package name, which is the package name (`docker-ce`) plus the version string (2nd column), separated by a hyphen (`-`). For example, `docker-ce-3:27.0.3-1.el9`.\n    \n    Replace `<VERSION_STRING>` with the desired version and then run the following command to install:\n    \n    This command installs Docker, but it doesn't start Docker. It also creates a `docker` group, however, it doesn't add any users to the group by default.\n    \n    * * *\n    \n2.  Start Docker.\n    \n3.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why you’re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine)\n\nTo upgrade Docker Engine, follow the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### [Install from a package](#install-from-a-package)\n\nIf you can't use Docker's `rpm` repository to install Docker Engine, you can download the `.rpm` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [https://download.docker.com/linux/centos/](https://download.docker.com/linux/centos/) and choose your version of CentOS. Then browse to `x86_64/stable/Packages/` and download the `.rpm` file for the Docker version you want to install.\n    \n2.  Install Docker Engine, changing the following path to the path where you downloaded the Docker package.\n    \n    Docker is installed but not started. The `docker` group is created, but no users are added to the group.\n    \n3.  Start Docker.\n    \n4.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why you’re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine-1)\n\nTo upgrade Docker Engine, download the newer package files and repeat the [installation procedure](#install-from-a-package), using `yum -y upgrade` instead of `yum -y install`, and point to the new files.\n\n### [Install using the convenience script](#install-using-the-convenience-script)\n\nDocker provides a convenience script at [https://get.docker.com/](https://get.docker.com/) to install Docker into development environments non-interactively. The convenience script isn't recommended for production environments, but it's useful for creating a provisioning script tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and you can find it in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n*   The script requires `root` or `sudo` privileges to run.\n*   The script attempts to detect your Linux distribution and version and configure your package management system for you.\n*   The script doesn't allow you to customize most installation parameters.\n*   The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n*   By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test upgrades in a test environment before deploying to your production systems.\n*   The script isn't designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, resulting in outdated versions.\n\n> **Tip: preview script steps before running**\n> \n> You can run the script with the `--dry-run` option to learn what steps the script will run when invoked:\n\nThis example downloads the script from [https://get.docker.com/](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\nYou have now successfully installed and started Docker Engine. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users can't run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n> \n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user). You can also install Docker without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](https://docs.docker.com/engine/security/rootless/).\n\n#### [Install pre-releases](#install-pre-releases)\n\nDocker also provides a convenience script at [https://test.docker.com/](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equal to the script at `get.docker.com`, but configures your package manager to use the test channel of the Docker package repository. The test channel includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they're released as stable.\n\nTo install the latest version of Docker on Linux from the test channel, run:\n\n#### [Upgrade Docker after using the convenience script](#upgrade-docker-after-using-the-convenience-script)\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There's no advantage to re-running the convenience script. Re-running it can cause issues if it attempts to re-install repositories which already exist on the host machine.\n\n1.  Uninstall the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n2.  Images, containers, volumes, or custom configuration files on your host aren't automatically removed. To delete all images, containers, and volumes:\n    \n\nYou have to delete any edited configuration files manually.\n\n*   Continue to [Post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/).",
    "title": "Install Docker Engine on CentOS | Docker Docs\n",
    "description": "Learn how to install Docker Engine on CentOS. These instructions cover the different installation methods, how to uninstall, and next steps.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/swarm-mode/",
    "markdown": "# Run Docker Engine in swarm mode\n\nWhen you first install and start working with Docker Engine, Swarm mode is disabled by default. When you enable Swarm mode, you work with the concept of services managed through the `docker service` command.\n\nThere are two ways to run the engine in Swarm mode:\n\n*   Create a new swarm, covered in this article.\n*   [Join an existing swarm](https://docs.docker.com/engine/swarm/join-nodes/).\n\nWhen you run the engine in Swarm mode on your local machine, you can create and test services based upon images you've created or other available images. In your production environment, Swarm mode provides a fault-tolerant platform with cluster management features to keep your services running and available.\n\nThese instructions assume you have installed the Docker Engine on a machine to serve as a manager node in your swarm.\n\nIf you haven't already, read through the [Swarm mode key concepts](https://docs.docker.com/engine/swarm/key-concepts/) and try the [Swarm mode tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/).\n\nWhen you run the command to create a swarm, Docker Engine starts running in Swarm mode.\n\nRun [`docker swarm init`](https://docs.docker.com/reference/cli/docker/swarm/init/) to create a single-node swarm on the current node. The engine sets up the swarm as follows:\n\n*   Switches the current node into Swarm mode.\n*   Creates a swarm named `default`.\n*   Designates the current node as a leader manager node for the swarm.\n*   Names the node with the machine hostname.\n*   Configures the manager to listen on an active network interface on port \\`2377\\`\\`.\n*   Sets the current node to `Active` availability, meaning it can receive tasks from the scheduler.\n*   Starts an internal distributed data store for Engines participating in the swarm to maintain a consistent view of the swarm and all services running on it.\n*   By default, generates a self-signed root CA for the swarm.\n*   By default, generates tokens for worker and manager nodes to join the swarm.\n*   Creates an overlay network named `ingress` for publishing service ports external to the swarm.\n*   Creates an overlay default IP addresses and subnet mask for your networks\n\nThe output for `docker swarm init` provides the connection command to use when you join new worker nodes to the swarm:\n\n### [Configuring default address pools](#configuring-default-address-pools)\n\nBy default Swarm mode uses a default address pool `10.0.0.0/8` for global scope (overlay) networks. Every network that does not have a subnet specified will have a subnet sequentially allocated from this pool. In some circumstances it may be desirable to use a different default IP address pool for networks.\n\nFor example, if the default `10.0.0.0/8` range conflicts with already allocated address space in your network, then it is desirable to ensure that networks use a different range without requiring swarm users to specify each subnet with the `--subnet` command.\n\nTo configure custom default address pools, you must define pools at swarm initialization using the `--default-addr-pool` command line option. This command line option uses CIDR notation for defining the subnet mask. To create the custom address pool for Swarm, you must define at least one default address pool, and an optional default address pool subnet mask. For example, for the `10.0.0.0/27`, use the value `27`.\n\nDocker allocates subnet addresses from the address ranges specified by the `--default-addr-pool` option. For example, a command line option `--default-addr-pool 10.10.0.0/16` indicates that Docker will allocate subnets from that `/16` address range. If `--default-addr-pool-mask-len` were unspecified or set explicitly to 24, this would result in 256 `/24` networks of the form `10.10.X.0/24`.\n\nThe subnet range comes from the `--default-addr-pool`, (such as `10.10.0.0/16`). The size of 16 there represents the number of networks one can create within that `default-addr-pool` range. The `--default-addr-pool` option may occur multiple times with each option providing additional addresses for docker to use for overlay subnets.\n\nThe format of the command is:\n\nThe command to create a default IP address pool with a /16 (class B) for the `10.20.0.0` network looks like this:\n\nThe command to create a default IP address pool with a `/16` (class B) for the `10.20.0.0` and `10.30.0.0` networks, and to create a subnet mask of `/26` for each network looks like this:\n\nIn this example, `docker network create -d overlay net1` will result in `10.20.0.0/26` as the allocated subnet for `net1`, and `docker network create -d overlay net2` will result in `10.20.0.64/26` as the allocated subnet for `net2`. This continues until all the subnets are exhausted.\n\nRefer to the following pages for more information:\n\n*   [Swarm networking](https://docs.docker.com/engine/swarm/networking/) for more information about the default address pool usage\n*   `docker swarm init` [CLI reference](https://docs.docker.com/reference/cli/docker/swarm/init/) for more detail on the `--default-addr-pool` flag.\n\n### [Configure the advertise address](#configure-the-advertise-address)\n\nManager nodes use an advertise address to allow other nodes in the swarm access to the Swarmkit API and overlay networking. The other nodes on the swarm must be able to access the manager node on its advertise address.\n\nIf you don't specify an advertise address, Docker checks if the system has a single IP address. If so, Docker uses the IP address with the listening port `2377` by default. If the system has multiple IP addresses, you must specify the correct `--advertise-addr` to enable inter-manager communication and overlay networking:\n\nYou must also specify the `--advertise-addr` if the address where other nodes reach the first manager node is not the same address the manager sees as its own. For instance, in a cloud setup that spans different regions, hosts have both internal addresses for access within the region and external addresses that you use for access from outside that region. In this case, specify the external address with `--advertise-addr` so that the node can propagate that information to other nodes that subsequently connect to it.\n\nRefer to the `docker swarm init` [CLI reference](https://docs.docker.com/reference/cli/docker/swarm/init/) for more detail on the advertise address.\n\n### [View the join command or update a swarm join token](#view-the-join-command-or-update-a-swarm-join-token)\n\nNodes require a secret token to join the swarm. The token for worker nodes is different from the token for manager nodes. Nodes only use the join-token at the moment they join the swarm. Rotating the join token after a node has already joined a swarm does not affect the node's swarm membership. Token rotation ensures an old token cannot be used by any new nodes attempting to join the swarm.\n\nTo retrieve the join command including the join token for worker nodes, run:\n\nTo view the join command and token for manager nodes, run:\n\nPass the `--quiet` flag to print only the token:\n\nBe careful with the join tokens because they are the secrets necessary to join the swarm. In particular, checking a secret into version control is a bad practice because it would allow anyone with access to the application source code to add new nodes to the swarm. Manager tokens are especially sensitive because they allow a new manager node to join and gain control over the whole swarm.\n\nWe recommend that you rotate the join tokens in the following circumstances:\n\n*   If a token was checked-in by accident into a version control system, group chat or accidentally printed to your logs.\n*   If you suspect a node has been compromised.\n*   If you wish to guarantee that no new nodes can join the swarm.\n\nAdditionally, it is a best practice to implement a regular rotation schedule for any secret including swarm join tokens. We recommend that you rotate your tokens at least every 6 months.\n\nRun `swarm join-token --rotate` to invalidate the old token and generate a new token. Specify whether you want to rotate the token for `worker` or `manager` nodes:\n\n*   [Join nodes to a swarm](https://docs.docker.com/engine/swarm/join-nodes/)\n*   `swarm init` [command line reference](https://docs.docker.com/reference/cli/docker/swarm/init/)\n*   [Swarm mode tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/)",
    "title": "Run Docker Engine in swarm mode | Docker Docs\n",
    "description": "Run Docker Engine in swarm mode",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/install/debian/",
    "markdown": "# Install Docker Engine on Debian\n\nTo get started with Docker Engine on Debian, make sure you [meet the prerequisites](#prerequisites), and then follow the [installation steps](#installation-methods).\n\n### [Firewall limitations](#firewall-limitations)\n\n> **Warning**\n> \n> Before you install Docker, make sure you consider the following security implications and firewall incompatibilities.\n\n*   If you use ufw or firewalld to manage firewall settings, be aware that when you expose container ports using Docker, these ports bypass your firewall rules. For more information, refer to [Docker and ufw](https://docs.docker.com/network/packet-filtering-firewalls/#docker-and-ufw).\n*   Docker is only compatible with `iptables-nft` and `iptables-legacy`. Firewall rules created with `nft` are not supported on a system with Docker installed. Make sure that any firewall rulesets you use are created with `iptables` or `iptables6`, and that you add them to the `DOCKER-USER` chain, see [Packet filtering and firewalls](https://docs.docker.com/network/packet-filtering-firewalls/).\n\n### [OS requirements](#os-requirements)\n\nTo install Docker Engine, you need the 64-bit version of one of these Debian versions:\n\n*   Debian Bookworm 12 (stable)\n*   Debian Bullseye 11 (oldstable)\n\nDocker Engine for Debian is compatible with x86\\_64 (or amd64), armhf, arm64, and ppc64le (ppc64el) architectures.\n\n### [Uninstall old versions](#uninstall-old-versions)\n\nBefore you can install Docker Engine, you need to uninstall any conflicting packages.\n\nDistro maintainers provide unofficial distributions of Docker packages in their repositories. You must uninstall these packages before you can install the official version of Docker Engine.\n\nThe unofficial packages to uninstall are:\n\n*   `docker.io`\n*   `docker-compose`\n*   `docker-doc`\n*   `podman-docker`\n\nMoreover, Docker Engine depends on `containerd` and `runc`. Docker Engine bundles these dependencies as one bundle: `containerd.io`. If you have installed the `containerd` or `runc` previously, uninstall them to avoid conflicts with the versions bundled with Docker Engine.\n\nRun the following command to uninstall all conflicting packages:\n\n`apt-get` might report that you have none of these packages installed.\n\nImages, containers, volumes, and networks stored in `/var/lib/docker/` aren't automatically removed when you uninstall Docker. If you want to start with a clean installation, and prefer to clean up any existing data, read the [uninstall Docker Engine](#uninstall-docker-engine) section.\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n*   Docker Engine comes bundled with [Docker Desktop for Linux](https://docs.docker.com/desktop/install/linux-install/). This is the easiest and quickest way to get started.\n    \n*   Set up and install Docker Engine from [Docker's `apt` repository](#install-using-the-repository).\n    \n*   [Install it manually](#install-from-a-package) and manage upgrades manually.\n    \n*   Use a [convenience script](#install-using-the-convenience-script). Only recommended for testing and development environments.\n    \n\n### [Install using the `apt` repository](#install-using-the-repository)\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker `apt` repository. Afterward, you can install and update Docker from the repository.\n\n1.  Set up Docker's `apt` repository.\n    \n    > **Note**\n    > \n    > If you use a derivative distro, such as Kali Linux, you may need to substitute the part of this command that's expected to print the version codename:\n    > \n    > Replace this part with the codename of the corresponding Debian release, such as `bookworm`.\n    \n2.  Install the Docker packages.\n    \n    * * *\n    \n    To install the latest version, run:\n    \n    To install a specific version of Docker Engine, start by listing the available versions in the repository:\n    \n    Select the desired version and install:\n    \n    * * *\n    \n3.  Verify that the installation is successful by running the `hello-world` image:\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why you’re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine)\n\nTo upgrade Docker Engine, follow step 2 of the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### [Install from a package](#install-from-a-package)\n\nIf you can't use Docker's `apt` repository to install Docker Engine, you can download the `deb` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [`https://download.docker.com/linux/debian/dists/`](https://download.docker.com/linux/debian/dists/).\n    \n2.  Select your Debian version in the list.\n    \n3.  Go to `pool/stable/` and select the applicable architecture (`amd64`, `armhf`, `arm64`, or `s390x`).\n    \n4.  Download the following `deb` files for the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n    *   `containerd.io_<version>_<arch>.deb`\n    *   `docker-ce_<version>_<arch>.deb`\n    *   `docker-ce-cli_<version>_<arch>.deb`\n    *   `docker-buildx-plugin_<version>_<arch>.deb`\n    *   `docker-compose-plugin_<version>_<arch>.deb`\n5.  Install the `.deb` packages. Update the paths in the following example to where you downloaded the Docker packages.\n    \n    The Docker daemon starts automatically.\n    \n6.  Verify that the Docker Engine installation is successful by running the `hello-world` image:\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why you’re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine-1)\n\nTo upgrade Docker Engine, download the newer package files and repeat the [installation procedure](#install-from-a-package), pointing to the new files.\n\n### [Install using the convenience script](#install-using-the-convenience-script)\n\nDocker provides a convenience script at [https://get.docker.com/](https://get.docker.com/) to install Docker into development environments non-interactively. The convenience script isn't recommended for production environments, but it's useful for creating a provisioning script tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and you can find it in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n*   The script requires `root` or `sudo` privileges to run.\n*   The script attempts to detect your Linux distribution and version and configure your package management system for you.\n*   The script doesn't allow you to customize most installation parameters.\n*   The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n*   By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test upgrades in a test environment before deploying to your production systems.\n*   The script isn't designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, resulting in outdated versions.\n\n> **Tip: preview script steps before running**\n> \n> You can run the script with the `--dry-run` option to learn what steps the script will run when invoked:\n\nThis example downloads the script from [https://get.docker.com/](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\nYou have now successfully installed and started Docker Engine. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users can't run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n> \n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user). You can also install Docker without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](https://docs.docker.com/engine/security/rootless/).\n\n#### [Install pre-releases](#install-pre-releases)\n\nDocker also provides a convenience script at [https://test.docker.com/](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equal to the script at `get.docker.com`, but configures your package manager to use the test channel of the Docker package repository. The test channel includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they're released as stable.\n\nTo install the latest version of Docker on Linux from the test channel, run:\n\n#### [Upgrade Docker after using the convenience script](#upgrade-docker-after-using-the-convenience-script)\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There's no advantage to re-running the convenience script. Re-running it can cause issues if it attempts to re-install repositories which already exist on the host machine.\n\n1.  Uninstall the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n2.  Images, containers, volumes, or custom configuration files on your host aren't automatically removed. To delete all images, containers, and volumes:\n    \n\nYou have to delete any edited configuration files manually.\n\n*   Continue to [Post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/).",
    "title": "Install Docker Engine on Debian | Docker Docs\n",
    "description": "Learn how to install Docker Engine on Debian. These instructions cover the different installation methods, how to uninstall, and next steps.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/join-nodes/",
    "markdown": "# Join nodes to a swarm\n\nWhen you first create a swarm, you place a single Docker Engine into Swarm mode. To take full advantage of Swarm mode you can add nodes to the swarm:\n\n*   Adding worker nodes increases capacity. When you deploy a service to a swarm, the engine schedules tasks on available nodes whether they are worker nodes or manager nodes. When you add workers to your swarm, you increase the scale of the swarm to handle tasks without affecting the manager raft consensus.\n*   Manager nodes increase fault-tolerance. Manager nodes perform the orchestration and cluster management functions for the swarm. Among manager nodes, a single leader node conducts orchestration tasks. If a leader node goes down, the remaining manager nodes elect a new leader and resume orchestration and maintenance of the swarm state. By default, manager nodes also run tasks.\n\nDocker Engine joins the swarm depending on the **join-token** you provide to the `docker swarm join` command. The node only uses the token at join time. If you subsequently rotate the token, it doesn't affect existing swarm nodes. Refer to [Run Docker Engine in swarm mode](https://docs.docker.com/engine/swarm/swarm-mode/#view-the-join-command-or-update-a-swarm-join-token).\n\nTo retrieve the join command including the join token for worker nodes, run the following command on a manager node:\n\nRun the command from the output on the worker to join the swarm:\n\nThe `docker swarm join` command does the following:\n\n*   Switches Docker Engine on the current node into Swarm mode.\n*   Requests a TLS certificate from the manager.\n*   Names the node with the machine hostname.\n*   Joins the current node to the swarm at the manager listen address based upon the swarm token.\n*   Sets the current node to `Active` availability, meaning it can receive tasks from the scheduler.\n*   Extends the `ingress` overlay network to the current node.\n\nWhen you run `docker swarm join` and pass the manager token, Docker Engine switches into Swarm mode the same as for workers. Manager nodes also participate in the raft consensus. The new nodes should be `Reachable`, but the existing manager remains the swarm `Leader`.\n\nDocker recommends three or five manager nodes per cluster to implement high availability. Because Swarm-mode manager nodes share data using Raft, there must be an odd number of managers. The swarm can continue to function after as long as a quorum of more than half of the manager nodes are available.\n\nFor more detail about swarm managers and administering a swarm, see [Administer and maintain a swarm of Docker Engines](https://docs.docker.com/engine/swarm/admin_guide/).\n\nTo retrieve the join command including the join token for manager nodes, run the following command on a manager node:\n\nRun the command from the output on the new manager node to join it to the swarm:\n\n*   `swarm join` [command line reference](https://docs.docker.com/reference/cli/docker/swarm/join/)\n*   [Swarm mode tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/)",
    "title": "Join nodes to a swarm | Docker Docs\n",
    "description": "Add worker and manager nodes to a swarm",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/install/rhel/",
    "markdown": "# Install Docker Engine on RHEL\n\n> **Experimental**\n> \n> Support for Docker Engine on RHEL x86\\_64 and aarch64 is experimental.\n\n> **Docker Desktop for Linux** is also available for RHEL.\n> \n> To get access, join the [Early Access Program](https://www.docker.com/docker-desktop-preview-program/).\n\nTo get started with Docker Engine on RHEL, make sure you [meet the prerequisites](#prerequisites), and then follow the [installation steps](#installation-methods).\n\n### [OS requirements](#os-requirements)\n\nTo install Docker Engine, you need a maintained version of one of the following RHEL versions:\n\n*   RHEL 8\n*   RHEL 9\n\n### [Uninstall old versions](#uninstall-old-versions)\n\nOlder versions of Docker went by `docker` or `docker-engine`. Uninstall any such older versions before attempting to install a new version, along with associated dependencies. Also uninstall `Podman` and the associated dependencies if installed already:\n\n`yum` might report that you have none of these packages installed.\n\nImages, containers, volumes, and networks stored in `/var/lib/docker/` aren't automatically removed when you uninstall Docker.\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n*   You can [set up Docker's repositories](#install-using-the-repository) and install from them, for ease of installation and upgrade tasks. This is the recommended approach.\n    \n*   You can download the RPM package, [install it manually](#install-from-a-package), and manage upgrades completely manually. This is useful in situations such as installing Docker on air-gapped systems with no access to the internet.\n    \n*   In testing and development environments, you can use automated [convenience scripts](#install-using-the-convenience-script) to install Docker.\n    \n\n### [Install using the rpm repository](#install-using-the-repository)\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\n#### [Set up the repository](#set-up-the-repository)\n\nInstall the `yum-utils` package (which provides the `yum-config-manager` utility) and set up the repository.\n\n#### [Install Docker Engine](#install-docker-engine)\n\n1.  Install Docker Engine, containerd, and Docker Compose:\n    \n    * * *\n    \n    To install the latest version, run:\n    \n    If prompted to accept the GPG key, verify that the fingerprint matches `060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35`, and if so, accept it.\n    \n    This command installs Docker, but it doesn't start Docker. It also creates a `docker` group, however, it doesn't add any users to the group by default.\n    \n    To install a specific version, start by listing the available versions in the repository:\n    \n    The list returned depends on which repositories are enabled, and is specific to your version of RHEL (indicated by the `.el9` suffix in this example).\n    \n    Install a specific version by its fully qualified package name, which is the package name (`docker-ce`) plus the version string (2nd column), separated by a hyphen (`-`). For example, `docker-ce-3:27.0.3-1.el9`.\n    \n    Replace `<VERSION_STRING>` with the desired version and then run the following command to install:\n    \n    This command installs Docker, but it doesn't start Docker. It also creates a `docker` group, however, it doesn't add any users to the group by default.\n    \n    * * *\n    \n2.  Start Docker.\n    \n3.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why you’re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine)\n\nTo upgrade Docker Engine, follow the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### [Install from a package](#install-from-a-package)\n\nIf you can't use Docker's `rpm` repository to install Docker Engine, you can download the `.rpm` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [https://download.docker.com/linux/rhel/](https://download.docker.com/linux/rhel/).\n    \n2.  Select your RHEL version in the list.\n    \n3.  Select the applicable architecture (`x86_64`, `aarch64`, or `s390x`), and then go to `stable/Packages/`.\n    \n4.  Download the following `deb` files for the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n    *   `containerd.io_<version>_<arch>.deb`\n    *   `docker-ce_<version>_<arch>.deb`\n    *   `docker-ce-cli_<version>_<arch>.deb`\n    *   `docker-buildx-plugin_<version>_<arch>.deb`\n    *   `docker-compose-plugin_<version>_<arch>.deb`\n5.  Install Docker Engine, changing the following path to the path where you downloaded the packages.\n    \n    Docker is installed but not started. The `docker` group is created, but no users are added to the group.\n    \n6.  Start Docker.\n    \n7.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why you’re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine-1)\n\nTo upgrade Docker Engine, download the newer package files and repeat the [installation procedure](#install-from-a-package), using `yum -y upgrade` instead of `yum -y install`, and point to the new files.\n\n### [Install using the convenience script](#install-using-the-convenience-script)\n\nDocker provides a convenience script at [https://get.docker.com/](https://get.docker.com/) to install Docker into development environments non-interactively. The convenience script isn't recommended for production environments, but it's useful for creating a provisioning script tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and you can find it in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n*   The script requires `root` or `sudo` privileges to run.\n*   The script attempts to detect your Linux distribution and version and configure your package management system for you.\n*   The script doesn't allow you to customize most installation parameters.\n*   The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n*   By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test upgrades in a test environment before deploying to your production systems.\n*   The script isn't designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, resulting in outdated versions.\n\n> **Tip: preview script steps before running**\n> \n> You can run the script with the `--dry-run` option to learn what steps the script will run when invoked:\n\nThis example downloads the script from [https://get.docker.com/](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\nYou have now successfully installed and started Docker Engine. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users can't run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n> \n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user). You can also install Docker without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](https://docs.docker.com/engine/security/rootless/).\n\n#### [Install pre-releases](#install-pre-releases)\n\nDocker also provides a convenience script at [https://test.docker.com/](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equal to the script at `get.docker.com`, but configures your package manager to use the test channel of the Docker package repository. The test channel includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they're released as stable.\n\nTo install the latest version of Docker on Linux from the test channel, run:\n\n#### [Upgrade Docker after using the convenience script](#upgrade-docker-after-using-the-convenience-script)\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There's no advantage to re-running the convenience script. Re-running it can cause issues if it attempts to re-install repositories which already exist on the host machine.\n\n1.  Uninstall the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n2.  Images, containers, volumes, or custom configuration files on your host aren't automatically removed. To delete all images, containers, and volumes:\n    \n\nYou have to delete any edited configuration files manually.\n\n*   Continue to [Post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/).",
    "title": "Install Docker Engine on RHEL | Docker Docs\n",
    "description": "Learn how to install Docker Engine on RHEL. These instructions cover the different installation methods, how to uninstall, and next steps.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/install/fedora/",
    "markdown": "# Install Docker Engine on Fedora\n\nTo get started with Docker Engine on Fedora, make sure you [meet the prerequisites](#prerequisites), and then follow the [installation steps](#installation-methods).\n\n### [OS requirements](#os-requirements)\n\nTo install Docker Engine, you need a maintained version of one of the following Fedora versions:\n\n*   Fedora 39\n*   Fedora 40\n\n### [Uninstall old versions](#uninstall-old-versions)\n\nOlder versions of Docker went by `docker` or `docker-engine`. Uninstall any such older versions before attempting to install a new version, along with associated dependencies.\n\n`dnf` might report that you have none of these packages installed.\n\nImages, containers, volumes, and networks stored in `/var/lib/docker/` aren't automatically removed when you uninstall Docker.\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n*   You can [set up Docker's repositories](#install-using-the-repository) and install from them, for ease of installation and upgrade tasks. This is the recommended approach.\n    \n*   You can download the RPM package, [install it manually](#install-from-a-package), and manage upgrades completely manually. This is useful in situations such as installing Docker on air-gapped systems with no access to the internet.\n    \n*   In testing and development environments, you can use automated [convenience scripts](#install-using-the-convenience-script) to install Docker.\n    \n\n### [Install using the rpm repository](#install-using-the-repository)\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\n#### [Set up the repository](#set-up-the-repository)\n\nInstall the `dnf-plugins-core` package (which provides the commands to manage your DNF repositories) and set up the repository.\n\n#### [Install Docker Engine](#install-docker-engine)\n\n1.  Install Docker Engine, containerd, and Docker Compose:\n    \n    * * *\n    \n    To install the latest version, run:\n    \n    If prompted to accept the GPG key, verify that the fingerprint matches `060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35`, and if so, accept it.\n    \n    This command installs Docker, but it doesn't start Docker. It also creates a `docker` group, however, it doesn't add any users to the group by default.\n    \n    To install a specific version, start by listing the available versions in the repository:\n    \n    The list returned depends on which repositories are enabled, and is specific to your version of Fedora (indicated by the `.fc40` suffix in this example).\n    \n    Install a specific version by its fully qualified package name, which is the package name (`docker-ce`) plus the version string (2nd column), separated by a hyphen (`-`). For example, `docker-ce-3:27.0.3-1.fc40`.\n    \n    Replace `<VERSION_STRING>` with the desired version and then run the following command to install:\n    \n    This command installs Docker, but it doesn't start Docker. It also creates a `docker` group, however, it doesn't add any users to the group by default.\n    \n    * * *\n    \n2.  Start Docker.\n    \n3.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why you’re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine)\n\nTo upgrade Docker Engine, follow the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### [Install from a package](#install-from-a-package)\n\nIf you can't use Docker's `rpm` repository to install Docker Engine, you can download the `.rpm` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [https://download.docker.com/linux/fedora/](https://download.docker.com/linux/fedora/) and choose your version of Fedora. Then browse to `x86_64/stable/Packages/` and download the `.rpm` file for the Docker version you want to install.\n    \n2.  Install Docker Engine, changing the following path to the path where you downloaded the Docker package.\n    \n    Docker is installed but not started. The `docker` group is created, but no users are added to the group.\n    \n3.  Start Docker.\n    \n4.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why you’re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine-1)\n\nTo upgrade Docker Engine, download the newer package files and repeat the [installation procedure](#install-from-a-package), using `dnf -y upgrade` instead of `dnf -y install`, and point to the new files.\n\n### [Install using the convenience script](#install-using-the-convenience-script)\n\nDocker provides a convenience script at [https://get.docker.com/](https://get.docker.com/) to install Docker into development environments non-interactively. The convenience script isn't recommended for production environments, but it's useful for creating a provisioning script tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and you can find it in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n*   The script requires `root` or `sudo` privileges to run.\n*   The script attempts to detect your Linux distribution and version and configure your package management system for you.\n*   The script doesn't allow you to customize most installation parameters.\n*   The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n*   By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test upgrades in a test environment before deploying to your production systems.\n*   The script isn't designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, resulting in outdated versions.\n\n> **Tip: preview script steps before running**\n> \n> You can run the script with the `--dry-run` option to learn what steps the script will run when invoked:\n\nThis example downloads the script from [https://get.docker.com/](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\nYou have now successfully installed and started Docker Engine. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users can't run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n> \n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user). You can also install Docker without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](https://docs.docker.com/engine/security/rootless/).\n\n#### [Install pre-releases](#install-pre-releases)\n\nDocker also provides a convenience script at [https://test.docker.com/](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equal to the script at `get.docker.com`, but configures your package manager to use the test channel of the Docker package repository. The test channel includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they're released as stable.\n\nTo install the latest version of Docker on Linux from the test channel, run:\n\n#### [Upgrade Docker after using the convenience script](#upgrade-docker-after-using-the-convenience-script)\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There's no advantage to re-running the convenience script. Re-running it can cause issues if it attempts to re-install repositories which already exist on the host machine.\n\n1.  Uninstall the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n2.  Images, containers, volumes, or custom configuration files on your host aren't automatically removed. To delete all images, containers, and volumes:\n    \n\nYou have to delete any edited configuration files manually.\n\n*   Continue to [Post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/).",
    "title": "Install Docker Engine on Fedora | Docker Docs\n",
    "description": "Learn how to install Docker Engine on Fedora. These instructions cover the different installation methods, how to uninstall, and next steps.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/manage-nodes/",
    "markdown": "# Manage nodes in a swarm\n\nAs part of the swarm management lifecycle, you may need to:\n\n*   [List nodes in the swarm](#list-nodes)\n*   [Inspect an individual node](#inspect-an-individual-node)\n*   [Update a node](#update-a-node)\n*   [Leave the swarm](#leave-the-swarm)\n\nTo view a list of nodes in the swarm run `docker node ls` from a manager node:\n\nThe `AVAILABILITY` column shows whether or not the scheduler can assign tasks to the node:\n\n*   `Active` means that the scheduler can assign tasks to the node.\n*   `Pause` means the scheduler doesn't assign new tasks to the node, but existing tasks remain running.\n*   `Drain` means the scheduler doesn't assign new tasks to the node. The scheduler shuts down any existing tasks and schedules them on an available node.\n\nThe `MANAGER STATUS` column shows node participation in the Raft consensus:\n\n*   No value indicates a worker node that does not participate in swarm management.\n*   `Leader` means the node is the primary manager node that makes all swarm management and orchestration decisions for the swarm.\n*   `Reachable` means the node is a manager node participating in the Raft consensus quorum. If the leader node becomes unavailable, the node is eligible for election as the new leader.\n*   `Unavailable` means the node is a manager that can't communicate with other managers. If a manager node becomes unavailable, you should either join a new manager node to the swarm or promote a worker node to be a manager.\n\nFor more information on swarm administration refer to the [Swarm administration guide](https://docs.docker.com/engine/swarm/admin_guide/).\n\nYou can run `docker node inspect <NODE-ID>` on a manager node to view the details for an individual node. The output defaults to JSON format, but you can pass the `--pretty` flag to print the results in human-readable format. For example:\n\nYou can modify node attributes to:\n\n*   [Change node availability](#change-node-availability)\n*   [Add or remove label metadata](#add-or-remove-label-metadata)\n*   [Change a node role](#promote-or-demote-a-node)\n\n### [Change node availability](#change-node-availability)\n\nChanging node availability lets you:\n\n*   Drain a manager node so that it only performs swarm management tasks and is unavailable for task assignment.\n*   Drain a node so you can take it down for maintenance.\n*   Pause a node so it can't receive new tasks.\n*   Restore unavailable or paused nodes availability status.\n\nFor example, to change a manager node to `Drain` availability:\n\nSee [list nodes](#list-nodes) for descriptions of the different availability options.\n\n### [Add or remove label metadata](#add-or-remove-label-metadata)\n\nNode labels provide a flexible method of node organization. You can also use node labels in service constraints. Apply constraints when you create a service to limit the nodes where the scheduler assigns tasks for the service.\n\nRun `docker node update --label-add` on a manager node to add label metadata to a node. The `--label-add` flag supports either a `<key>` or a `<key>=<value>` pair.\n\nPass the `--label-add` flag once for each node label you want to add:\n\nThe labels you set for nodes using docker node update apply only to the node entity within the swarm. Do not confuse them with the docker daemon labels for [dockerd](https://docs.docker.com/config/labels-custom-metadata/).\n\nTherefore, node labels can be used to limit critical tasks to nodes that meet certain requirements. For example, schedule only on machines where special workloads should be run, such as machines that meet [PCI-SS compliance](https://www.pcisecuritystandards.org/).\n\nA compromised worker could not compromise these special workloads because it cannot change node labels.\n\nEngine labels, however, are still useful because some features that do not affect secure orchestration of containers might be better off set in a decentralized manner. For instance, an engine could have a label to indicate that it has a certain type of disk device, which may not be relevant to security directly. These labels are more easily \"trusted\" by the swarm orchestrator.\n\nRefer to the `docker service create` [CLI reference](https://docs.docker.com/reference/cli/docker/service/create/) for more information about service constraints.\n\n### [Promote or demote a node](#promote-or-demote-a-node)\n\nYou can promote a worker node to the manager role. This is useful when a manager node becomes unavailable or if you want to take a manager offline for maintenance. Similarly, you can demote a manager node to the worker role.\n\n> **Note**\n> \n> Regardless of your reason to promote or demote a node, you must always maintain a quorum of manager nodes in the swarm. For more information refer to the [Swarm administration guide](https://docs.docker.com/engine/swarm/admin_guide/).\n\nTo promote a node or set of nodes, run `docker node promote` from a manager node:\n\nTo demote a node or set of nodes, run `docker node demote` from a manager node:\n\n`docker node promote` and `docker node demote` are convenience commands for `docker node update --role manager` and `docker node update --role worker` respectively.\n\nIf your swarm service relies on one or more [plugins](https://docs.docker.com/engine/extend/plugin_api/), these plugins need to be available on every node where the service could potentially be deployed. You can manually install the plugin on each node or script the installation. You can also deploy the plugin in a similar way as a global service using the Docker API, by specifying a `PluginSpec` instead of a `ContainerSpec`.\n\n> **Note**\n> \n> There is currently no way to deploy a plugin to a swarm using the Docker CLI or Docker Compose. In addition, it is not possible to install plugins from a private repository.\n\nThe [`PluginSpec`](https://docs.docker.com/engine/extend/plugin_api/#json-specification) is defined by the plugin developer. To add the plugin to all Docker nodes, use the [`service/create`](https://docs.docker.com/engine/api/v1.31/#operation/ServiceCreate) API, passing the `PluginSpec` JSON defined in the `TaskTemplate`.\n\nRun the `docker swarm leave` command on a node to remove it from the swarm.\n\nFor example to leave the swarm on a worker node:\n\nWhen a node leaves the swarm, Docker Engine stops running in Swarm mode. The orchestrator no longer schedules tasks to the node.\n\nIf the node is a manager node, you receive a warning about maintaining the quorum. To override the warning, pass the `--force` flag. If the last manager node leaves the swarm, the swarm becomes unavailable requiring you to take disaster recovery measures.\n\nFor information about maintaining a quorum and disaster recovery, refer to the [Swarm administration guide](https://docs.docker.com/engine/swarm/admin_guide/).\n\nAfter a node leaves the swarm, you can run `docker node rm` on a manager node to remove the node from the node list.\n\nFor instance:\n\n*   [Swarm administration guide](https://docs.docker.com/engine/swarm/admin_guide/)\n*   [Docker Engine command line reference](https://docs.docker.com/reference/cli/docker/)\n*   [Swarm mode tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/)",
    "title": "Manage nodes in a swarm | Docker Docs\n",
    "description": "Manage existing nodes in a swarm",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/security/protect-access/",
    "markdown": "# Protect the Docker daemon socket\n\nBy default, Docker runs through a non-networked UNIX socket. It can also optionally communicate using SSH or a TLS (HTTPS) socket.\n\n> **Note**\n> \n> The given `USERNAME` must have permissions to access the docker socket on the remote machine. Refer to [manage Docker as a non-root user](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user) to learn how to give a non-root user access to the docker socket.\n\nThe following example creates a [`docker context`](https://docs.docker.com/engine/context/working-with-contexts/) to connect with a remote `dockerd` daemon on `host1.example.com` using SSH, and as the `docker-user` user on the remote machine:\n\nAfter creating the context, use `docker context use` to switch the `docker` CLI to use it, and to connect to the remote engine:\n\nUse the `default` context to switch back to the default (local) daemon:\n\nAlternatively, use the `DOCKER_HOST` environment variable to temporarily switch the `docker` CLI to connect to the remote host using SSH. This does not require creating a context, and can be useful to create an ad-hoc connection with a different engine:\n\n### [SSH Tips](#ssh-tips)\n\nFor the best user experience with SSH, configure `~/.ssh/config` as follows to allow reusing a SSH connection for multiple invocations of the `docker` CLI:\n\nIf you need Docker to be reachable through HTTP rather than SSH in a safe manner, you can enable TLS (HTTPS) by specifying the `tlsverify` flag and pointing Docker's `tlscacert` flag to a trusted CA certificate.\n\nIn the daemon mode, it only allows connections from clients authenticated by a certificate signed by that CA. In the client mode, it only connects to servers with a certificate signed by that CA.\n\n> **Important**\n> \n> Using TLS and managing a CA is an advanced topic. Familiarize yourself with OpenSSL, x509, and TLS before using it in production.\n\n### [Create a CA, server and client keys with OpenSSL](#create-a-ca-server-and-client-keys-with-openssl)\n\n> **Note**\n> \n> Replace all instances of `$HOST` in the following example with the DNS name of your Docker daemon's host.\n\nFirst, on the Docker daemon's host machine, generate CA private and public keys:\n\nNow that you have a CA, you can create a server key and certificate signing request (CSR). Make sure that \"Common Name\" matches the hostname you use to connect to Docker:\n\n> **Note**\n> \n> Replace all instances of `$HOST` in the following example with the DNS name of your Docker daemon's host.\n\nNext, we're going to sign the public key with our CA:\n\nSince TLS connections can be made through IP address as well as DNS name, the IP addresses need to be specified when creating the certificate. For example, to allow connections using `10.10.10.20` and `127.0.0.1`:\n\nSet the Docker daemon key's extended usage attributes to be used only for server authentication:\n\nNow, generate the signed certificate:\n\n[Authorization plugins](https://docs.docker.com/engine/extend/plugins_authorization/) offer more fine-grained control to supplement authentication from mutual TLS. In addition to other information described in the above document, authorization plugins running on a Docker daemon receive the certificate information for connecting Docker clients.\n\nFor client authentication, create a client key and certificate signing request:\n\n> **Note**\n> \n> For simplicity of the next couple of steps, you may perform this step on the Docker daemon's host machine as well.\n\nTo make the key suitable for client authentication, create a new extensions config file:\n\nNow, generate the signed certificate:\n\nAfter generating `cert.pem` and `server-cert.pem` you can safely remove the two certificate signing requests and extensions config files:\n\nWith a default `umask` of 022, your secret keys are _world-readable_ and writable for you and your group.\n\nTo protect your keys from accidental damage, remove their write permissions. To make them only readable by you, change file modes as follows:\n\nCertificates can be world-readable, but you might want to remove write access to prevent accidental damage:\n\nNow you can make the Docker daemon only accept connections from clients providing a certificate trusted by your CA:\n\nTo connect to Docker and validate its certificate, provide your client keys, certificates and trusted CA:\n\n> **Tip**\n> \n> This step should be run on your Docker client machine. As such, you need to copy your CA certificate, your server certificate, and your client certificate to that machine.\n\n> **Note**\n> \n> Replace all instances of `$HOST` in the following example with the DNS name of your Docker daemon's host.\n\n> **Note**\n> \n> Docker over TLS should run on TCP port 2376.\n\n> **Warning**\n> \n> As shown in the example above, you don't need to run the `docker` client with `sudo` or the `docker` group when you use certificate authentication. That means anyone with the keys can give any instructions to your Docker daemon, giving them root access to the machine hosting the daemon. Guard these keys as you would a root password!\n\n### [Secure by default](#secure-by-default)\n\nIf you want to secure your Docker client connections by default, you can move the files to the `.docker` directory in your home directory --- and set the `DOCKER_HOST` and `DOCKER_TLS_VERIFY` variables as well (instead of passing `-H=tcp://$HOST:2376` and `--tlsverify` on every call).\n\nDocker now connects securely by default:\n\n```\n$ docker ps\n```\n\n### [Other modes](#other-modes)\n\nIf you don't want to have complete two-way authentication, you can run Docker in various other modes by mixing the flags.\n\n#### [Daemon modes](#daemon-modes)\n\n*   `tlsverify`, `tlscacert`, `tlscert`, `tlskey` set: Authenticate clients\n*   `tls`, `tlscert`, `tlskey`: Do not authenticate clients\n\n#### [Client modes](#client-modes)\n\n*   `tls`: Authenticate server based on public/default CA pool\n*   `tlsverify`, `tlscacert`: Authenticate server based on given CA\n*   `tls`, `tlscert`, `tlskey`: Authenticate with client certificate, do not authenticate server based on given CA\n*   `tlsverify`, `tlscacert`, `tlscert`, `tlskey`: Authenticate with client certificate and authenticate server based on given CA\n\nIf found, the client sends its client certificate, so you just need to drop your keys into `~/.docker/{ca,cert,key}.pem`. Alternatively, if you want to store your keys in another location, you can specify that location using the environment variable `DOCKER_CERT_PATH`.\n\n#### [Connecting to the secure Docker port using `curl`](#connecting-to-the-secure-docker-port-using-curl)\n\nTo use `curl` to make test API requests, you need to use three extra command line flags:\n\n*   [Using certificates for repository client verification](https://docs.docker.com/engine/security/certificates/)\n*   [Use trusted images](https://docs.docker.com/engine/security/trust/)",
    "title": "Protect the Docker daemon socket | Docker Docs\n",
    "description": "How to setup and run Docker with SSH or HTTPS",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/services/",
    "markdown": "# Deploy services to a swarm\n\nSwarm services use a declarative model, which means that you define the desired state of the service, and rely upon Docker to maintain this state. The state includes information such as (but not limited to):\n\n*   The image name and tag the service containers should run\n*   How many containers participate in the service\n*   Whether any ports are exposed to clients outside the swarm\n*   Whether the service should start automatically when Docker starts\n*   The specific behavior that happens when the service is restarted (such as whether a rolling restart is used)\n*   Characteristics of the nodes where the service can run (such as resource constraints and placement preferences)\n\nFor an overview of Swarm mode, see [Swarm mode key concepts](https://docs.docker.com/engine/swarm/key-concepts/). For an overview of how services work, see [How services work](https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/).\n\nTo create a single-replica service with no extra configuration, you only need to supply the image name. This command starts an Nginx service with a randomly-generated name and no published ports. This is a naive example, since you can't interact with the Nginx service.\n\nThe service is scheduled on an available node. To confirm that the service was created and started successfully, use the `docker service ls` command:\n\nCreated services do not always run right away. A service can be in a pending state if its image is unavailable, if no node meets the requirements you configure for the service, or for other reasons. See [Pending services](https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/#pending-services) for more information.\n\nTo provide a name for your service, use the `--name` flag:\n\nJust like with standalone containers, you can specify a command that the service's containers should run, by adding it after the image name. This example starts a service called `helloworld` which uses an `alpine` image and runs the command `ping docker.com`:\n\nYou can also specify an image tag for the service to use. This example modifies the previous one to use the `alpine:3.6` tag:\n\nFor more details about image tag resolution, see [Specify the image version the service should use](#specify-the-image-version-a-service-should-use).\n\n### [gMSA for Swarm](#gmsa-for-swarm)\n\n> **Note**\n> \n> This example only works for a Windows container.\n\nSwarm now allows using a Docker config as a gMSA credential spec - a requirement for Active Directory-authenticated applications. This reduces the burden of distributing credential specs to the nodes they're used on.\n\nThe following example assumes a gMSA and its credential spec (called credspec.json) already exists, and that the nodes being deployed to are correctly configured for the gMSA.\n\nTo use a config as a credential spec, first create the Docker config containing the credential spec:\n\nNow, you should have a Docker config named credspec, and you can create a service using this credential spec. To do so, use the --credential-spec flag with the config name, like this:\n\nYour service uses the gMSA credential spec when it starts, but unlike a typical Docker config (used by passing the --config flag), the credential spec is not mounted into the container.\n\n### [Create a service using an image on a private registry](#create-a-service-using-an-image-on-a-private-registry)\n\nIf your image is available on a private registry which requires login, use the `--with-registry-auth` flag with `docker service create`, after logging in. If your image is stored on `registry.example.com`, which is a private registry, use a command like the following:\n\nThis passes the login token from your local client to the swarm nodes where the service is deployed, using the encrypted WAL logs. With this information, the nodes are able to log into the registry and pull the image.\n\n### [Provide credential specs for managed service accounts](#provide-credential-specs-for-managed-service-accounts)\n\nIn Enterprise Edition 3.0, security is improved through the centralized distribution and management of Group Managed Service Account(gMSA) credentials using Docker config functionality. Swarm now allows using a Docker config as a gMSA credential spec, which reduces the burden of distributing credential specs to the nodes on which they are used.\n\n> **Note**\n> \n> This option is only applicable to services using Windows containers.\n\nCredential spec files are applied at runtime, eliminating the need for host-based credential spec files or registry entries - no gMSA credentials are written to disk on worker nodes. You can make credential specs available to Docker Engine running swarm kit worker nodes before a container starts. When deploying a service using a gMSA-based config, the credential spec is passed directly to the runtime of containers in that service.\n\nThe `--credential-spec` must be in one of the following formats:\n\n*   `file://<filename>`: The referenced file must be present in the `CredentialSpecs` subdirectory in the docker data directory, which defaults to `C:\\ProgramData\\Docker\\` on Windows. For example, specifying `file://spec.json` loads `C:\\ProgramData\\Docker\\CredentialSpecs\\spec.json`.\n*   `registry://<value-name>`: The credential spec is read from the Windows registry on the daemon’s host.\n*   `config://<config-name>`: The config name is automatically converted to the config ID in the CLI. The credential spec contained in the specified `config` is used.\n\nThe following simple example retrieves the gMSA name and JSON contents from your Active Directory (AD) instance:\n\nMake sure that the nodes to which you are deploying are correctly configured for the gMSA.\n\nTo use a config as a credential spec, create a Docker config in a credential spec file named `credpspec.json`. You can specify any name for the name of the `config`.\n\nNow you can create a service using this credential spec. Specify the `--credential-spec` flag with the config name:\n\nYour service uses the gMSA credential spec when it starts, but unlike a typical Docker config (used by passing the --config flag), the credential spec is not mounted into the container.\n\nYou can change almost everything about an existing service using the `docker service update` command. When you update a service, Docker stops its containers and restarts them with the new configuration.\n\nSince Nginx is a web service, it works much better if you publish port 80 to clients outside the swarm. You can specify this when you create the service, using the `-p` or `--publish` flag. When updating an existing service, the flag is `--publish-add`. There is also a `--publish-rm` flag to remove a port that was previously published.\n\nAssuming that the `my_web` service from the previous section still exists, use the following command to update it to publish port 80.\n\nTo verify that it worked, use `docker service ls`:\n\nFor more information on how publishing ports works, see [publish ports](#publish-ports).\n\nYou can update almost every configuration detail about an existing service, including the image name and tag it runs. See [Update a service's image after creation](#update-a-services-image-after-creation).\n\nTo remove a service, use the `docker service remove` command. You can remove a service by its ID or name, as shown in the output of the `docker service ls` command. The following command removes the `my_web` service.\n\nThe following sections provide details about service configuration. This topic does not cover every flag or scenario. In almost every instance where you can define a configuration at service creation, you can also update an existing service's configuration in a similar way.\n\nSee the command-line references for [`docker service create`](https://docs.docker.com/reference/cli/docker/service/create/) and [`docker service update`](https://docs.docker.com/reference/cli/docker/service/update/), or run one of those commands with the `--help` flag.\n\n### [Configure the runtime environment](#configure-the-runtime-environment)\n\nYou can configure the following options for the runtime environment in the container:\n\n*   Environment variables using the `--env` flag\n*   The working directory inside the container using the `--workdir` flag\n*   The username or UID using the `--user` flag\n\nThe following service's containers have an environment variable `$MYVAR` set to `myvalue`, run from the `/tmp/` directory, and run as the `my_user` user.\n\n### [Update the command an existing service runs](#update-the-command-an-existing-service-runs)\n\nTo update the command an existing service runs, you can use the `--args` flag. The following example updates an existing service called `helloworld` so that it runs the command `ping docker.com` instead of whatever command it was running before:\n\n### [Specify the image version a service should use](#specify-the-image-version-a-service-should-use)\n\nWhen you create a service without specifying any details about the version of the image to use, the service uses the version tagged with the `latest` tag. You can force the service to use a specific version of the image in a few different ways, depending on your desired outcome.\n\nAn image version can be expressed in several different ways:\n\n*   If you specify a tag, the manager (or the Docker client, if you use [content trust](https://docs.docker.com/engine/security/trust/)) resolves that tag to a digest. When the request to create a container task is received on a worker node, the worker node only sees the digest, not the tag.\n    \n    Some tags represent discrete releases, such as `ubuntu:16.04`. Tags like this almost always resolve to a stable digest over time. It is recommended that you use this kind of tag when possible.\n    \n    Other types of tags, such as `latest` or `nightly`, may resolve to a new digest often, depending on how often an image's author updates the tag. It is not recommended to run services using a tag which is updated frequently, to prevent different service replica tasks from using different image versions.\n    \n*   If you don't specify a version at all, by convention the image's `latest` tag is resolved to a digest. Workers use the image at this digest when creating the service task.\n    \n    Thus, the following two commands are equivalent:\n    \n*   If you specify a digest directly, that exact version of the image is always used when creating service tasks.\n    \n\nWhen you create a service, the image's tag is resolved to the specific digest the tag points to **at the time of service creation**. Worker nodes for that service use that specific digest forever unless the service is explicitly updated. This feature is particularly important if you do use often-changing tags such as `latest`, because it ensures that all service tasks use the same version of the image.\n\n> **Note**\\>\n> \n> If [content trust](https://docs.docker.com/engine/security/trust/) is enabled, the client actually resolves the image's tag to a digest before contacting the swarm manager, to verify that the image is signed. Thus, if you use content trust, the swarm manager receives the request pre-resolved. In this case, if the client cannot resolve the image to a digest, the request fails.\n\nIf the manager can't resolve the tag to a digest, each worker node is responsible for resolving the tag to a digest, and different nodes may use different versions of the image. If this happens, a warning like the following is logged, substituting the placeholders for real information.\n\nTo see an image's current digest, issue the command `docker inspect <IMAGE>:<TAG>` and look for the `RepoDigests` line. The following is the current digest for `ubuntu:latest` at the time this content was written. The output is truncated for clarity.\n\nAfter you create a service, its image is never updated unless you explicitly run `docker service update` with the `--image` flag as described below. Other update operations such as scaling the service, adding or removing networks or volumes, renaming the service, or any other type of update operation do not update the service's image.\n\n### [Update a service's image after creation](#update-a-services-image-after-creation)\n\nEach tag represents a digest, similar to a Git hash. Some tags, such as `latest`, are updated often to point to a new digest. Others, such as `ubuntu:16.04`, represent a released software version and are not expected to update to point to a new digest often if at all. When you create a service, it is constrained to create tasks using a specific digest of an image until you update the service using `service update` with the `--image` flag.\n\nWhen you run `service update` with the `--image` flag, the swarm manager queries Docker Hub or your private Docker registry for the digest the tag currently points to and updates the service tasks to use that digest.\n\n> **Note**\n> \n> If you use [content trust](https://docs.docker.com/engine/security/trust/), the Docker client resolves image and the swarm manager receives the image and digest, rather than a tag.\n\nUsually, the manager can resolve the tag to a new digest and the service updates, redeploying each task to use the new image. If the manager can't resolve the tag or some other problem occurs, the next two sections outline what to expect.\n\n#### [If the manager resolves the tag](#if-the-manager-resolves-the-tag)\n\nIf the swarm manager can resolve the image tag to a digest, it instructs the worker nodes to redeploy the tasks and use the image at that digest.\n\n*   If a worker has cached the image at that digest, it uses it.\n    \n*   If not, it attempts to pull the image from Docker Hub or the private registry.\n    \n    *   If it succeeds, the task is deployed using the new image.\n        \n    *   If the worker fails to pull the image, the service fails to deploy on that worker node. Docker tries again to deploy the task, possibly on a different worker node.\n        \n\n#### [If the manager cannot resolve the tag](#if-the-manager-cannot-resolve-the-tag)\n\nIf the swarm manager cannot resolve the image to a digest, all is not lost:\n\n*   The manager instructs the worker nodes to redeploy the tasks using the image at that tag.\n    \n*   If the worker has a locally cached image that resolves to that tag, it uses that image.\n    \n*   If the worker does not have a locally cached image that resolves to the tag, the worker tries to connect to Docker Hub or the private registry to pull the image at that tag.\n    \n    *   If this succeeds, the worker uses that image.\n        \n    *   If this fails, the task fails to deploy and the manager tries again to deploy the task, possibly on a different worker node.\n        \n\n### [Publish ports](#publish-ports)\n\nWhen you create a swarm service, you can publish that service's ports to hosts outside the swarm in two ways:\n\n*   [You can rely on the routing mesh](#publish-a-services-ports-using-the-routing-mesh). When you publish a service port, the swarm makes the service accessible at the target port on every node, regardless of whether there is a task for the service running on that node or not. This is less complex and is the right choice for many types of services.\n    \n*   [You can publish a service task's port directly on the swarm node](#publish-a-services-ports-directly-on-the-swarm-node) where that service is running. This bypasses the routing mesh and provides the maximum flexibility, including the ability for you to develop your own routing framework. However, you are responsible for keeping track of where each task is running and routing requests to the tasks, and load-balancing across the nodes.\n    \n\nKeep reading for more information and use cases for each of these methods.\n\n#### [Publish a service's ports using the routing mesh](#publish-a-services-ports-using-the-routing-mesh)\n\nTo publish a service's ports externally to the swarm, use the `--publish <PUBLISHED-PORT>:<SERVICE-PORT>` flag. The swarm makes the service accessible at the published port on every swarm node. If an external host connects to that port on any swarm node, the routing mesh routes it to a task. The external host does not need to know the IP addresses or internally-used ports of the service tasks to interact with the service. When a user or process connects to a service, any worker node running a service task may respond. For more details about swarm service networking, see [Manage swarm service networks](https://docs.docker.com/engine/swarm/networking/).\n\n##### [Example: Run a three-task Nginx service on 10-node swarm](#example-run-a-three-task-nginx-service-on-10-node-swarm)\n\nImagine that you have a 10-node swarm, and you deploy an Nginx service running three tasks on a 10-node swarm:\n\nThree tasks run on up to three nodes. You don't need to know which nodes are running the tasks; connecting to port 8080 on any of the 10 nodes connects you to one of the three `nginx` tasks. You can test this using `curl`. The following example assumes that `localhost` is one of the swarm nodes. If this is not the case, or `localhost` does not resolve to an IP address on your host, substitute the host's IP address or resolvable host name.\n\nThe HTML output is truncated:\n\nSubsequent connections may be routed to the same swarm node or a different one.\n\n#### [Publish a service's ports directly on the swarm node](#publish-a-services-ports-directly-on-the-swarm-node)\n\nUsing the routing mesh may not be the right choice for your application if you need to make routing decisions based on application state or you need total control of the process for routing requests to your service's tasks. To publish a service's port directly on the node where it is running, use the `mode=host` option to the `--publish` flag.\n\n> **Note**\n> \n> If you publish a service's ports directly on the swarm node using `mode=host` and also set `published=<PORT>` this creates an implicit limitation that you can only run one task for that service on a given swarm node. You can work around this by specifying `published` without a port definition, which causes Docker to assign a random port for each task.\n> \n> In addition, if you use `mode=host` and you do not use the `--mode=global` flag on `docker service create`, it is difficult to know which nodes are running the service to route work to them.\n\n##### [Example: Run an `nginx` web server service on every swarm node](#example-run-an-nginx-web-server-service-on-every-swarm-node)\n\n[nginx](https://hub.docker.com/_/nginx/) is an open source reverse proxy, load balancer, HTTP cache, and a web server. If you run nginx as a service using the routing mesh, connecting to the nginx port on any swarm node shows you the web page for (effectively) a random swarm node running the service.\n\nThe following example runs nginx as a service on each node in your swarm and exposes nginx port locally on each swarm node.\n\nYou can reach the nginx server on port 8080 of every swarm node. If you add a node to the swarm, a nginx task is started on it. You cannot start another service or container on any swarm node which binds to port 8080.\n\n> **Note**\n> \n> This is a purely illustrative example. Creating an application-layer routing framework for a multi-tiered service is complex and out of scope for this topic.\n\n### [Connect the service to an overlay network](#connect-the-service-to-an-overlay-network)\n\nYou can use overlay networks to connect one or more services within the swarm.\n\nFirst, create overlay network on a manager node using the `docker network create` command with the `--driver overlay` flag.\n\nAfter you create an overlay network in swarm mode, all manager nodes have access to the network.\n\nYou can create a new service and pass the `--network` flag to attach the service to the overlay network:\n\nThe swarm extends `my-network` to each node running the service.\n\nYou can also connect an existing service to an overlay network using the `--network-add` flag.\n\nTo disconnect a running service from a network, use the `--network-rm` flag.\n\nFor more information on overlay networking and service discovery, refer to [Attach services to an overlay network](https://docs.docker.com/engine/swarm/networking/) and [Docker swarm mode overlay network security model](https://docs.docker.com/network/drivers/overlay/).\n\n### [Grant a service access to secrets](#grant-a-service-access-to-secrets)\n\nTo create a service with access to Docker-managed secrets, use the `--secret` flag. For more information, see [Manage sensitive strings (secrets) for Docker services](https://docs.docker.com/engine/swarm/secrets/)\n\n### [Customize a service's isolation mode](#customize-a-services-isolation-mode)\n\n> **Important**\n> \n> This setting applies to Windows hosts only and is ignored for Linux hosts.\n\nDocker allows you to specify a swarm service's isolation mode. The isolation mode can be one of the following:\n\n*   `default`: Use the default isolation mode configured for the Docker host, as configured by the `-exec-opt` flag or `exec-opts` array in `daemon.json`. If the daemon does not specify an isolation technology, `process` is the default for Windows Server, and `hyperv` is the default (and only) choice for Windows 10.\n    \n*   `process`: Run the service tasks as a separate process on the host.\n    \n    > **Note**\n    > \n    > `process` isolation mode is only supported on Windows Server. Windows 10 only supports `hyperv` isolation mode.\n    \n*   `hyperv`: Run the service tasks as isolated `hyperv` tasks. This increases overhead but provides more isolation.\n    \n\nYou can specify the isolation mode when creating or updating a new service using the `--isolation` flag.\n\n### [Control service placement](#control-service-placement)\n\nSwarm services provide a few different ways for you to control scale and placement of services on different nodes.\n\n*   You can specify whether the service needs to run a specific number of replicas or should run globally on every worker node. See [Replicated or global services](#replicated-or-global-services).\n    \n*   You can configure the service's [CPU or memory requirements](#reserve-memory-or-cpus-for-a-service), and the service only runs on nodes which can meet those requirements.\n    \n*   [Placement constraints](#placement-constraints) let you configure the service to run only on nodes with specific (arbitrary) metadata set, and cause the deployment to fail if appropriate nodes do not exist. For instance, you can specify that your service should only run on nodes where an arbitrary label `pci_compliant` is set to `true`.\n    \n*   [Placement preferences](#placement-preferences) let you apply an arbitrary label with a range of values to each node, and spread your service's tasks across those nodes using an algorithm. Currently, the only supported algorithm is `spread`, which tries to place them evenly. For instance, if you label each node with a label `rack` which has a value from 1-10, then specify a placement preference keyed on `rack`, then service tasks are placed as evenly as possible across all nodes with the label `rack`, after taking other placement constraints, placement preferences, and other node-specific limitations into account.\n    \n    Unlike constraints, placement preferences are best-effort, and a service does not fail to deploy if no nodes can satisfy the preference. If you specify a placement preference for a service, nodes that match that preference are ranked higher when the swarm managers decide which nodes should run the service tasks. Other factors, such as high availability of the service, also factor into which nodes are scheduled to run service tasks. For example, if you have N nodes with the rack label (and then some others), and your service is configured to run N+1 replicas, the +1 is scheduled on a node that doesn't already have the service on it if there is one, regardless of whether that node has the `rack` label or not.\n    \n\n#### [Replicated or global services](#replicated-or-global-services)\n\nSwarm mode has two types of services: replicated and global. For replicated services, you specify the number of replica tasks for the swarm manager to schedule onto available nodes. For global services, the scheduler places one task on each available node that meets the service's [placement constraints](#placement-constraints) and [resource requirements](#reserve-memory-or-cpus-for-a-service).\n\nYou control the type of service using the `--mode` flag. If you don't specify a mode, the service defaults to `replicated`. For replicated services, you specify the number of replica tasks you want to start using the `--replicas` flag. For example, to start a replicated nginx service with 3 replica tasks:\n\nTo start a global service on each available node, pass `--mode global` to `docker service create`. Every time a new node becomes available, the scheduler places a task for the global service on the new node. For example to start a service that runs alpine on every node in the swarm:\n\nService constraints let you set criteria for a node to meet before the scheduler deploys a service to the node. You can apply constraints to the service based upon node attributes and metadata or engine metadata. For more information on constraints, refer to the `docker service create` [CLI reference](https://docs.docker.com/reference/cli/docker/service/create/).\n\n#### [Reserve memory or CPUs for a service](#reserve-memory-or-cpus-for-a-service)\n\nTo reserve a given amount of memory or number of CPUs for a service, use the `--reserve-memory` or `--reserve-cpu` flags. If no available nodes can satisfy the requirement (for instance, if you request 4 CPUs and no node in the swarm has 4 CPUs), the service remains in a pending state until an appropriate node is available to run its tasks.\n\n##### [Out Of Memory Exceptions (OOME)](#out-of-memory-exceptions-oome)\n\nIf your service attempts to use more memory than the swarm node has available, you may experience an Out Of Memory Exception (OOME) and a container, or the Docker daemon, might be killed by the kernel OOM killer. To prevent this from happening, ensure that your application runs on hosts with adequate memory and see [Understand the risks of running out of memory](https://docs.docker.com/config/containers/resource_constraints/#understand-the-risks-of-running-out-of-memory).\n\nSwarm services allow you to use resource constraints, placement preferences, and labels to ensure that your service is deployed to the appropriate swarm nodes.\n\n#### [Placement constraints](#placement-constraints)\n\nUse placement constraints to control the nodes a service can be assigned to. In the following example, the service only runs on nodes with the [label](https://docs.docker.com/engine/swarm/manage-nodes/#add-or-remove-label-metadata) `region` set to `east`. If no appropriately-labelled nodes are available, tasks will wait in `Pending` until they become available. The `--constraint` flag uses an equality operator (`==` or `!=`). For replicated services, it is possible that all services run on the same node, or each node only runs one replica, or that some nodes don't run any replicas. For global services, the service runs on every node that meets the placement constraint and any [resource requirements](#reserve-memory-or-cpus-for-a-service).\n\nYou can also use the `constraint` service-level key in a `compose.yml` file.\n\nIf you specify multiple placement constraints, the service only deploys onto nodes where they are all met. The following example limits the service to run on all nodes where `region` is set to `east` and `type` is not set to `devel`:\n\nYou can also use placement constraints in conjunction with placement preferences and CPU/memory constraints. Be careful not to use settings that are not possible to fulfill.\n\nFor more information on constraints, refer to the `docker service create` [CLI reference](https://docs.docker.com/reference/cli/docker/service/create/).\n\n#### [Placement preferences](#placement-preferences)\n\nWhile [placement constraints](#placement-constraints) limit the nodes a service can run on, _placement preferences_ try to place tasks on appropriate nodes in an algorithmic way (currently, only spread evenly). For instance, if you assign each node a `rack` label, you can set a placement preference to spread the service evenly across nodes with the `rack` label, by value. This way, if you lose a rack, the service is still running on nodes on other racks.\n\nPlacement preferences are not strictly enforced. If no node has the label you specify in your preference, the service is deployed as though the preference were not set.\n\n> **Note**\n> \n> Placement preferences are ignored for global services.\n\nThe following example sets a preference to spread the deployment across nodes based on the value of the `datacenter` label. If some nodes have `datacenter=us-east` and others have `datacenter=us-west`, the service is deployed as evenly as possible across the two sets of nodes.\n\n> **Note**\n> \n> Nodes which are missing the label used to spread still receive task assignments. As a group, these nodes receive tasks in equal proportion to any of the other groups identified by a specific label value. In a sense, a missing label is the same as having the label with a null value attached to it. If the service should only run on nodes with the label being used for the spread preference, the preference should be combined with a constraint.\n\nYou can specify multiple placement preferences, and they are processed in the order they are encountered. The following example sets up a service with multiple placement preferences. Tasks are spread first over the various datacenters, and then over racks (as indicated by the respective labels):\n\nYou can also use placement preferences in conjunction with placement constraints or CPU/memory constraints. Be careful not to use settings that are not possible to fulfill.\n\nThis diagram illustrates how placement preferences work:\n\n![How placement preferences work](https://docs.docker.com/engine/swarm/images/placement_prefs.png)\n\nWhen updating a service with `docker service update`, `--placement-pref-add` appends a new placement preference after all existing placement preferences. `--placement-pref-rm` removes an existing placement preference that matches the argument.\n\n### [Configure a service's update behavior](#configure-a-services-update-behavior)\n\nWhen you create a service, you can specify a rolling update behavior for how the swarm should apply changes to the service when you run `docker service update`. You can also specify these flags as part of the update, as arguments to `docker service update`.\n\nThe `--update-delay` flag configures the time delay between updates to a service task or sets of tasks. You can describe the time `T` as a combination of the number of seconds `Ts`, minutes `Tm`, or hours `Th`. So `10m30s` indicates a 10 minute 30 second delay.\n\nBy default the scheduler updates 1 task at a time. You can pass the `--update-parallelism` flag to configure the maximum number of service tasks that the scheduler updates simultaneously.\n\nWhen an update to an individual task returns a state of `RUNNING`, the scheduler continues the update by continuing to another task until all tasks are updated. If at any time during an update a task returns `FAILED`, the scheduler pauses the update. You can control the behavior using the `--update-failure-action` flag for `docker service create` or `docker service update`.\n\nIn the example service below, the scheduler applies updates to a maximum of 2 replicas at a time. When an updated task returns either `RUNNING` or `FAILED`, the scheduler waits 10 seconds before stopping the next task to update:\n\nThe `--update-max-failure-ratio` flag controls what fraction of tasks can fail during an update before the update as a whole is considered to have failed. For example, with `--update-max-failure-ratio 0.1 --update-failure-action pause`, after 10% of the tasks being updated fail, the update is paused.\n\nAn individual task update is considered to have failed if the task doesn't start up, or if it stops running within the monitoring period specified with the `--update-monitor` flag. The default value for `--update-monitor` is 30 seconds, which means that a task failing in the first 30 seconds after it's started counts towards the service update failure threshold, and a failure after that is not counted.\n\n### [Roll back to the previous version of a service](#roll-back-to-the-previous-version-of-a-service)\n\nIn case the updated version of a service doesn't function as expected, it's possible to manually roll back to the previous version of the service using `docker service update`'s `--rollback` flag. This reverts the service to the configuration that was in place before the most recent `docker service update` command.\n\nOther options can be combined with `--rollback`; for example, `--update-delay 0s`, to execute the rollback without a delay between tasks:\n\nYou can configure a service to roll back automatically if a service update fails to deploy. See [Automatically roll back if an update fails](#automatically-roll-back-if-an-update-fails).\n\nManual rollback is handled at the server side, which allows manually-initiated rollbacks to respect the new rollback parameters. Note that `--rollback` cannot be used in conjunction with other flags to `docker service update`.\n\n### [Automatically roll back if an update fails](#automatically-roll-back-if-an-update-fails)\n\nYou can configure a service in such a way that if an update to the service causes redeployment to fail, the service can automatically roll back to the previous configuration. This helps protect service availability. You can set one or more of the following flags at service creation or update. If you do not set a value, the default is used.\n\n| Flag | Default | Description |\n| --- | --- | --- |\n| `--rollback-delay` | `0s` | Amount of time to wait after rolling back a task before rolling back the next one. A value of `0` means to roll back the second task immediately after the first rolled-back task deploys. |\n| `--rollback-failure-action` | `pause` | When a task fails to roll back, whether to `pause` or `continue` trying to roll back other tasks. |\n| `--rollback-max-failure-ratio` | `0` | The failure rate to tolerate during a rollback, specified as a floating-point number between 0 and 1. For instance, given 5 tasks, a failure ratio of `.2` would tolerate one task failing to roll back. A value of `0` means no failure are tolerated, while a value of `1` means any number of failure are tolerated. |\n| `--rollback-monitor` | `5s` | Duration after each task rollback to monitor for failure. If a task stops before this time period has elapsed, the rollback is considered to have failed. |\n| `--rollback-parallelism` | `1` | The maximum number of tasks to roll back in parallel. By default, one task is rolled back at a time. A value of `0` causes all tasks to be rolled back in parallel. |\n\nThe following example configures a `redis` service to roll back automatically if a `docker service update` fails to deploy. Two tasks can be rolled back in parallel. Tasks are monitored for 20 seconds after rollback to be sure they do not exit, and a maximum failure ratio of 20% is tolerated. Default values are used for `--rollback-delay` and `--rollback-failure-action`.\n\n### [Give a service access to volumes or bind mounts](#give-a-service-access-to-volumes-or-bind-mounts)\n\nFor best performance and portability, you should avoid writing important data directly into a container's writable layer. You should instead use data volumes or bind mounts. This principle also applies to services.\n\nYou can create two types of mounts for services in a swarm, `volume` mounts or `bind` mounts. Regardless of which type of mount you use, configure it using the `--mount` flag when you create a service, or the `--mount-add` or `--mount-rm` flag when updating an existing service. The default is a data volume if you don't specify a type.\n\n#### [Data volumes](#data-volumes)\n\nData volumes are storage that exist independently of a container. The lifecycle of data volumes under swarm services is similar to that under containers. Volumes outlive tasks and services, so their removal must be managed separately. Volumes can be created before deploying a service, or if they don't exist on a particular host when a task is scheduled there, they are created automatically according to the volume specification on the service.\n\nTo use existing data volumes with a service use the `--mount` flag:\n\nIf a volume with the name `<VOLUME-NAME>` doesn't exist when a task is scheduled to a particular host, then one is created. The default volume driver is `local`. To use a different volume driver with this create-on-demand pattern, specify the driver and its options with the `--mount` flag:\n\nFor more information on how to create data volumes and the use of volume drivers, see [Use volumes](https://docs.docker.com/storage/volumes/).\n\n#### [Bind mounts](#bind-mounts)\n\nBind mounts are file system paths from the host where the scheduler deploys the container for the task. Docker mounts the path into the container. The file system path must exist before the swarm initializes the container for the task.\n\nThe following examples show bind mount syntax:\n\n*   To mount a read-write bind:\n    \n*   To mount a read-only bind:\n    \n\n> **Important**\n> \n> Bind mounts can be useful but they can also cause problems. In most cases, it is recommended that you architect your application such that mounting paths from the host is unnecessary. The main risks include the following:\n> \n> *   If you bind mount a host path into your service’s containers, the path must exist on every swarm node. The Docker swarm mode scheduler can schedule containers on any machine that meets resource availability requirements and satisfies all constraints and placement preferences you specify.\n>     \n> *   The Docker swarm mode scheduler may reschedule your running service containers at any time if they become unhealthy or unreachable.\n>     \n> *   Host bind mounts are non-portable. When you use bind mounts, there is no guarantee that your application runs the same way in development as it does in production.\n>     \n\n### [Create services using templates](#create-services-using-templates)\n\nYou can use templates for some flags of `service create`, using the syntax provided by the Go's [text/template](https://golang.org/pkg/text/template/) package.\n\nThe following flags are supported:\n\n*   `--hostname`\n*   `--mount`\n*   `--env`\n\nValid placeholders for the Go template are:\n\n| Placeholder | Description |\n| --- | --- |\n| `.Service.ID` | Service ID |\n| `.Service.Name` | Service name |\n| `.Service.Labels` | Service labels |\n| `.Node.ID` | Node ID |\n| `.Node.Hostname` | Node hostname |\n| `.Task.Name` | Task name |\n| `.Task.Slot` | Task slot |\n\n#### [Template example](#template-example)\n\nThis example sets the template of the created containers based on the service's name and the ID of the node where the container is running:\n\nTo see the result of using the template, use the `docker service ps` and `docker inspect` commands.\n\n*   [Swarm administration guide](https://docs.docker.com/engine/swarm/admin_guide/)\n*   [Docker Engine command line reference](https://docs.docker.com/reference/cli/docker/)\n*   [Swarm mode tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/)",
    "title": "Deploy services to a swarm | Docker Docs\n",
    "description": "Deploy services to a swarm",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/security/certificates/",
    "markdown": "# Verify repository client with certificates\n\nIn [Running Docker with HTTPS](https://docs.docker.com/engine/security/protect-access/), you learned that, by default, Docker runs via a non-networked Unix socket and TLS must be enabled in order to have the Docker client and the daemon communicate securely over HTTPS. TLS ensures authenticity of the registry endpoint and that traffic to/from registry is encrypted.\n\nThis article demonstrates how to ensure the traffic between the Docker registry server and the Docker daemon (a client of the registry server) is encrypted and properly authenticated using certificate-based client-server authentication.\n\nWe show you how to install a Certificate Authority (CA) root certificate for the registry and how to set the client TLS certificate for verification.\n\nA custom certificate is configured by creating a directory under `/etc/docker/certs.d` using the same name as the registry's hostname, such as `localhost`. All `*.crt` files are added to this directory as CA roots.\n\n> **Note**\n> \n> On Linux any root certificates authorities are merged with the system defaults, including the host's root CA set. If you are running Docker on Windows Server, or Docker Desktop for Windows with Windows containers, the system default certificates are only used when no custom root certificates are configured.\n\nThe presence of one or more `<filename>.key/cert` pairs indicates to Docker that there are custom certificates required for access to the desired repository.\n\n> **Note**\n> \n> If multiple certificates exist, each is tried in alphabetical order. If there is a 4xx-level or 5xx-level authentication error, Docker continues to try with the next certificate.\n\nThe following illustrates a configuration with custom certificates:\n\nThe preceding example is operating-system specific and is for illustrative purposes only. You should consult your operating system documentation for creating an os-provided bundled certificate chain.\n\nUse OpenSSL's `genrsa` and `req` commands to first generate an RSA key and then use the key to create the certificate.\n\n> **Note**\n> \n> These TLS commands only generate a working set of certificates on Linux. The version of OpenSSL in macOS is incompatible with the type of certificate Docker requires.\n\nThe Docker daemon interprets `.crt` files as CA certificates and `.cert` files as client certificates. If a CA certificate is accidentally given the extension `.cert` instead of the correct `.crt` extension, the Docker daemon logs the following error message:\n\nIf the Docker registry is accessed without a port number, do not add the port to the directory name. The following shows the configuration for a registry on default port 443 which is accessed with `docker login my-https.registry.example.com`:\n\n*   [Use trusted images](https://docs.docker.com/engine/security/trust/)\n*   [Protect the Docker daemon socket](https://docs.docker.com/engine/security/protect-access/)",
    "title": "Verify repository client with certificates | Docker Docs\n",
    "description": "How to set up and use certificates with a registry to verify access",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/install/ubuntu/",
    "markdown": "# Install Docker Engine on Ubuntu\n\nTo get started with Docker Engine on Ubuntu, make sure you [meet the prerequisites](#prerequisites), and then follow the [installation steps](#installation-methods).\n\n### [Firewall limitations](#firewall-limitations)\n\n> **Warning**\n> \n> Before you install Docker, make sure you consider the following security implications and firewall incompatibilities.\n\n*   If you use ufw or firewalld to manage firewall settings, be aware that when you expose container ports using Docker, these ports bypass your firewall rules. For more information, refer to [Docker and ufw](https://docs.docker.com/network/packet-filtering-firewalls/#docker-and-ufw).\n*   Docker is only compatible with `iptables-nft` and `iptables-legacy`. Firewall rules created with `nft` are not supported on a system with Docker installed. Make sure that any firewall rulesets you use are created with `iptables` or `iptables6`, and that you add them to the `DOCKER-USER` chain, see [Packet filtering and firewalls](https://docs.docker.com/network/packet-filtering-firewalls/).\n\n### [OS requirements](#os-requirements)\n\nTo install Docker Engine, you need the 64-bit version of one of these Ubuntu versions:\n\n*   Ubuntu Noble 24.04 (LTS)\n*   Ubuntu Mantic 23.10 (EOL: [July 12, 2024](https://wiki.ubuntu.com/Releases))\n*   Ubuntu Jammy 22.04 (LTS)\n*   Ubuntu Focal 20.04 (LTS)\n\nDocker Engine for Ubuntu is compatible with x86\\_64 (or amd64), armhf, arm64, s390x, and ppc64le (ppc64el) architectures.\n\n### [Uninstall old versions](#uninstall-old-versions)\n\nBefore you can install Docker Engine, you need to uninstall any conflicting packages.\n\nDistro maintainers provide unofficial distributions of Docker packages in APT. You must uninstall these packages before you can install the official version of Docker Engine.\n\nThe unofficial packages to uninstall are:\n\n*   `docker.io`\n*   `docker-compose`\n*   `docker-compose-v2`\n*   `docker-doc`\n*   `podman-docker`\n\nMoreover, Docker Engine depends on `containerd` and `runc`. Docker Engine bundles these dependencies as one bundle: `containerd.io`. If you have installed the `containerd` or `runc` previously, uninstall them to avoid conflicts with the versions bundled with Docker Engine.\n\nRun the following command to uninstall all conflicting packages:\n\n`apt-get` might report that you have none of these packages installed.\n\nImages, containers, volumes, and networks stored in `/var/lib/docker/` aren't automatically removed when you uninstall Docker. If you want to start with a clean installation, and prefer to clean up any existing data, read the [uninstall Docker Engine](#uninstall-docker-engine) section.\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n*   Docker Engine comes bundled with [Docker Desktop for Linux](https://docs.docker.com/desktop/install/linux-install/). This is the easiest and quickest way to get started.\n    \n*   Set up and install Docker Engine from [Docker's `apt` repository](#install-using-the-repository).\n    \n*   [Install it manually](#install-from-a-package) and manage upgrades manually.\n    \n*   Use a [convenience script](#install-using-the-convenience-script). Only recommended for testing and development environments.\n    \n\n### [Install using the `apt` repository](#install-using-the-repository)\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\n1.  Set up Docker's `apt` repository.\n    \n    > **Note**\n    > \n    > If you use an Ubuntu derivative distro, such as Linux Mint, you may need to use `UBUNTU_CODENAME` instead of `VERSION_CODENAME`.\n    \n2.  Install the Docker packages.\n    \n    * * *\n    \n    To install the latest version, run:\n    \n    To install a specific version of Docker Engine, start by listing the available versions in the repository:\n    \n    Select the desired version and install:\n    \n    * * *\n    \n3.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why you’re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine)\n\nTo upgrade Docker Engine, follow step 2 of the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### [Install from a package](#install-from-a-package)\n\nIf you can't use Docker's `apt` repository to install Docker Engine, you can download the `deb` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [`https://download.docker.com/linux/ubuntu/dists/`](https://download.docker.com/linux/ubuntu/dists/).\n    \n2.  Select your Ubuntu version in the list.\n    \n3.  Go to `pool/stable/` and select the applicable architecture (`amd64`, `armhf`, `arm64`, or `s390x`).\n    \n4.  Download the following `deb` files for the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n    *   `containerd.io_<version>_<arch>.deb`\n    *   `docker-ce_<version>_<arch>.deb`\n    *   `docker-ce-cli_<version>_<arch>.deb`\n    *   `docker-buildx-plugin_<version>_<arch>.deb`\n    *   `docker-compose-plugin_<version>_<arch>.deb`\n5.  Install the `.deb` packages. Update the paths in the following example to where you downloaded the Docker packages.\n    \n    The Docker daemon starts automatically.\n    \n6.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why you’re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine-1)\n\nTo upgrade Docker Engine, download the newer package files and repeat the [installation procedure](#install-from-a-package), pointing to the new files.\n\n### [Install using the convenience script](#install-using-the-convenience-script)\n\nDocker provides a convenience script at [https://get.docker.com/](https://get.docker.com/) to install Docker into development environments non-interactively. The convenience script isn't recommended for production environments, but it's useful for creating a provisioning script tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and you can find it in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n*   The script requires `root` or `sudo` privileges to run.\n*   The script attempts to detect your Linux distribution and version and configure your package management system for you.\n*   The script doesn't allow you to customize most installation parameters.\n*   The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n*   By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test upgrades in a test environment before deploying to your production systems.\n*   The script isn't designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, resulting in outdated versions.\n\n> **Tip: preview script steps before running**\n> \n> You can run the script with the `--dry-run` option to learn what steps the script will run when invoked:\n\nThis example downloads the script from [https://get.docker.com/](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\nYou have now successfully installed and started Docker Engine. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users can't run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n> \n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user). You can also install Docker without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](https://docs.docker.com/engine/security/rootless/).\n\n#### [Install pre-releases](#install-pre-releases)\n\nDocker also provides a convenience script at [https://test.docker.com/](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equal to the script at `get.docker.com`, but configures your package manager to use the test channel of the Docker package repository. The test channel includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they're released as stable.\n\nTo install the latest version of Docker on Linux from the test channel, run:\n\n#### [Upgrade Docker after using the convenience script](#upgrade-docker-after-using-the-convenience-script)\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There's no advantage to re-running the convenience script. Re-running it can cause issues if it attempts to re-install repositories which already exist on the host machine.\n\n1.  Uninstall the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n2.  Images, containers, volumes, or custom configuration files on your host aren't automatically removed. To delete all images, containers, and volumes:\n    \n\nYou have to delete any edited configuration files manually.\n\n*   Continue to [Post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/).",
    "title": "Install Docker Engine on Ubuntu | Docker Docs\n",
    "description": "Jumpstart your client-side server applications with Docker Engine on Ubuntu. This guide details prerequisites and multiple methods to install Docker Engine on Ubuntu.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/stack-deploy/",
    "markdown": "# Deploy a stack to a swarm\n\nWhen running Docker Engine in swarm mode, you can use `docker stack deploy` to deploy a complete application stack to the swarm. The `deploy` command accepts a stack description in the form of a [Compose file](https://docs.docker.com/compose/compose-file/legacy-versions/).\n\n> **Note**\n> \n> The `docker stack deploy` command uses the legacy [Compose file version 3](https://docs.docker.com/compose/compose-file/compose-file-v3/) format, used by Compose V1. The latest format, defined by the [Compose specification](https://docs.docker.com/compose/compose-file/) isn't compatible with the `docker stack deploy` command.\n> \n> For more information about the evolution of Compose, see [History of Compose](https://docs.docker.com/compose/history/).\n\nTo run through this tutorial, you need:\n\n1.  A Docker Engine running in [Swarm mode](https://docs.docker.com/engine/swarm/swarm-mode/). If you're not familiar with Swarm mode, you might want to read [Swarm mode key concepts](https://docs.docker.com/engine/swarm/key-concepts/) and [How services work](https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/).\n    \n    > **Note**\n    > \n    > If you're trying things out on a local development environment, you can put your engine into Swarm mode with `docker swarm init`.\n    > \n    > If you've already got a multi-node swarm running, keep in mind that all `docker stack` and `docker service` commands must be run from a manager node.\n    \n2.  A current version of [Docker Compose](https://docs.docker.com/compose/install/).\n    \n\nBecause a swarm consists of multiple Docker Engines, a registry is required to distribute images to all of them. You can use the [Docker Hub](https://hub.docker.com/) or maintain your own. Here's how to create a throwaway registry, which you can discard afterward.\n\n1.  Start the registry as a service on your swarm:\n    \n2.  Check its status with `docker service ls`:\n    \n    Once it reads `1/1` under `REPLICAS`, it's running. If it reads `0/1`, it's probably still pulling the image.\n    \n3.  Check that it's working with `curl`:\n    \n\nThe app used in this guide is based on the hit counter app in the [Get started with Docker Compose](https://docs.docker.com/compose/gettingstarted/) guide. It consists of a Python app which maintains a counter in a Redis instance and increments the counter whenever you visit it.\n\n1.  Create a directory for the project:\n    \n2.  Create a file called `app.py` in the project directory and paste this in:\n    \n3.  Create a file called `requirements.txt` and paste these two lines in:\n    \n4.  Create a file called `Dockerfile` and paste this in:\n    \n5.  Create a file called `compose.yml` and paste this in:\n    \n    The image for the web app is built using the Dockerfile defined above. It's also tagged with `127.0.0.1:5000` - the address of the registry created earlier. This is important when distributing the app to the swarm.\n    \n\n1.  Start the app with `docker compose up`. This builds the web app image, pulls the Redis image if you don't already have it, and creates two containers.\n    \n    You see a warning about the Engine being in swarm mode. This is because Compose doesn't take advantage of swarm mode, and deploys everything to a single node. You can safely ignore this.\n    \n2.  Check that the app is running with `docker compose ps`:\n    \n    You can test the app with `curl`:\n    \n3.  Bring the app down:\n    \n\nTo distribute the web app's image across the swarm, it needs to be pushed to the registry you set up earlier. With Compose, this is very simple:\n\nThe stack is now ready to be deployed.\n\n1.  Create the stack with `docker stack deploy`:\n    \n    The last argument is a name for the stack. Each network, volume and service name is prefixed with the stack name.\n    \n2.  Check that it's running with `docker stack services stackdemo`:\n    \n    Once it's running, you should see `1/1` under `REPLICAS` for both services. This might take some time if you have a multi-node swarm, as images need to be pulled.\n    \n    As before, you can test the app with `curl`:\n    \n    With Docker's built-in routing mesh, you can access any node in the swarm on port `8000` and get routed to the app:\n    \n3.  Bring the stack down with `docker stack rm`:\n    \n4.  Bring the registry down with `docker service rm`:\n    \n5.  If you're just testing things out on a local machine and want to bring your Docker Engine out of Swarm mode, use `docker swarm leave`:",
    "title": "Deploy a stack to a swarm | Docker Docs\n",
    "description": "How to deploy a stack to a swarm",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/security/trust/",
    "markdown": "# Content trust in Docker | Docker Docs\n\nWhen transferring data among networked systems, trust is a central concern. In particular, when communicating over an untrusted medium such as the internet, it is critical to ensure the integrity and the publisher of all the data a system operates on. You use Docker Engine to push and pull images (data) to a public or private registry. Content trust gives you the ability to verify both the integrity and the publisher of all the data received from a registry over any channel.\n\n## [About Docker Content Trust (DCT)](#about-docker-content-trust-dct)\n\nDocker Content Trust (DCT) provides the ability to use digital signatures for data sent to and received from remote Docker registries. These signatures allow client-side or runtime verification of the integrity and publisher of specific image tags.\n\nThrough DCT, image publishers can sign their images and image consumers can ensure that the images they pull are signed. Publishers could be individuals or organizations manually signing their content or automated software supply chains signing content as part of their release process.\n\n### [Image tags and DCT](#image-tags-and-dct)\n\nAn individual image record has the following identifier:\n\nA particular image `REPOSITORY` can have multiple tags. For example, `latest` and `3.1.2` are both tags on the `mongo` image. An image publisher can build an image and tag combination many times changing the image with each build.\n\nDCT is associated with the `TAG` portion of an image. Each image repository has a set of keys that image publishers use to sign an image tag. Image publishers have discretion on which tags they sign.\n\nAn image repository can contain an image with one tag that is signed and another tag that is not. For example, consider [the Mongo image repository](https://hub.docker.com/r/library/mongo/tags/). The `latest` tag could be unsigned while the `3.1.6` tag could be signed. It is the responsibility of the image publisher to decide if an image tag is signed or not. In this representation, some image tags are signed, others are not:\n\n![Signed tags](https://docs.docker.com/engine/security/trust/images/tag_signing.png)\n\nPublishers can choose to sign a specific tag or not. As a result, the content of an unsigned tag and that of a signed tag with the same name may not match. For example, a publisher can push a tagged image `someimage:latest` and sign it. Later, the same publisher can push an unsigned `someimage:latest` image. This second push replaces the last unsigned tag `latest` but does not affect the signed `latest` version. The ability to choose which tags they can sign, allows publishers to iterate over the unsigned version of an image before officially signing it.\n\nImage consumers can enable DCT to ensure that images they use were signed. If a consumer enables DCT, they can only pull, run, or build with trusted images. Enabling DCT is a bit like applying a \"filter\" to your registry. Consumers \"see\" only signed image tags and the less desirable, unsigned image tags are \"invisible\" to them.\n\n![Trust view](https://docs.docker.com/engine/security/trust/images/trust_view.png)\n\nTo the consumer who has not enabled DCT, nothing about how they work with Docker images changes. Every image is visible regardless of whether it is signed or not.\n\n### [Docker Content Trust Keys](#docker-content-trust-keys)\n\nTrust for an image tag is managed through the use of signing keys. A key set is created when an operation using DCT is first invoked. A key set consists of the following classes of keys:\n\n*   An offline key that is the root of DCT for an image tag\n*   Repository or tagging keys that sign tags\n*   Server-managed keys such as the timestamp key, which provides freshness security guarantees for your repository\n\nThe following image depicts the various signing keys and their relationships:\n\n![Content Trust components](https://docs.docker.com/engine/security/trust/images/trust_components.png)\n\n> **Warning**\n> \n> The root key once lost is not recoverable. If you lose any other key, send an email to Docker Hub Support. This loss also requires manual intervention from every consumer that used a signed tag from this repository prior to the loss.\n\nYou should back up the root key somewhere safe. Given that it is only required to create new repositories, it is a good idea to store it offline in hardware. For details on securing, and backing up your keys, make sure you read how to [manage keys for DCT](https://docs.docker.com/engine/security/trust/trust_key_mng/).\n\n## [Signing images with Docker Content Trust](#signing-images-with-docker-content-trust)\n\nWithin the Docker CLI we can sign and push a container image with the `$ docker trust` command syntax. This is built on top of the Notary feature set. For more information, see the [Notary GitHub repository](https://github.com/theupdateframework/notary).\n\nA prerequisite for signing an image is a Docker Registry with a Notary server attached (Such as the Docker Hub ). Instructions for standing up a self-hosted environment can be found [here](https://docs.docker.com/engine/security/trust/deploying_notary/).\n\nTo sign a Docker Image you will need a delegation key pair. These keys can be generated locally using `$ docker trust key generate` or generated by a certificate authority.\n\nFirst we will add the delegation private key to the local Docker trust repository. (By default this is stored in `~/.docker/trust/`). If you are generating delegation keys with `$ docker trust key generate`, the private key is automatically added to the local trust store. If you are importing a separate key, you will need to use the `$ docker trust key load` command.\n\nOr if you have an existing key:\n\nNext we will need to add the delegation public key to the Notary server; this is specific to a particular image repository in Notary known as a Global Unique Name (GUN). If this is the first time you are adding a delegation to that repository, this command will also initiate the repository, using a local Notary canonical root key. To understand more about initiating a repository, and the role of delegations, head to [delegations for content trust](https://docs.docker.com/engine/security/trust/trust_delegation/).\n\nFinally, we will use the delegation private key to sign a particular tag and push it up to the registry.\n\nAlternatively, once the keys have been imported an image can be pushed with the `$ docker push` command, by exporting the DCT environmental variable.\n\nRemote trust data for a tag or a repository can be viewed by the `$ docker trust inspect` command:\n\nRemote Trust data for a tag can be removed by the `$ docker trust revoke` command:\n\n## [Client enforcement with Docker Content Trust](#client-enforcement-with-docker-content-trust)\n\nContent trust is disabled by default in the Docker Client. To enable it, set the `DOCKER_CONTENT_TRUST` environment variable to `1`. This prevents users from working with tagged images unless they contain a signature.\n\nWhen DCT is enabled in the Docker client, `docker` CLI commands that operate on tagged images must either have content signatures or explicit content hashes. The commands that operate with DCT are:\n\n*   `push`\n*   `build`\n*   `create`\n*   `pull`\n*   `run`\n\nFor example, with DCT enabled a `docker pull someimage:latest` only succeeds if `someimage:latest` is signed. However, an operation with an explicit content hash always succeeds as long as the hash exists:\n\n*   [Delegations for content trust](https://docs.docker.com/engine/security/trust/trust_delegation/)\n*   [Automation with content trust](https://docs.docker.com/engine/security/trust/trust_automation/)\n*   [Manage keys for content trust](https://docs.docker.com/engine/security/trust/trust_key_mng/)\n*   [Play in a content trust sandbox](https://docs.docker.com/engine/security/trust/trust_sandbox/)",
    "title": "Content trust in Docker | Docker Docs\n",
    "description": "Enabling content trust in Docker",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/install/sles/",
    "markdown": "# Install Docker Engine on SLES (s390x)\n\n> **Note**\n> \n> The installation instructions on this page refer to packages for SLES on the **s390x** architecture (IBM Z). Other architectures, including x86\\_64, aren't supported for SLES.\n\nTo get started with Docker Engine on SLES, make sure you [meet the prerequisites](#prerequisites), and then follow the [installation steps](#installation-methods).\n\n### [OS requirements](#os-requirements)\n\nTo install Docker Engine, you need a maintained version of one of the following SLES versions:\n\n*   SLES 15-SP4 on s390x (IBM Z)\n*   SLES 15-SP5 on s390x (IBM Z)\n\nYou must enable the [`SCC SUSE`](https://scc.suse.com/packages?name=SUSE%20Linux%20Enterprise%20Server&version=15.5&arch=s390x) repositories.\n\nYou must add the [OpenSUSE `SELinux` repository](https://download.opensuse.org/repositories/security:/SELinux/). This repository is not added by default. Run the following commands to add it:\n\n### [Uninstall old versions](#uninstall-old-versions)\n\nOlder versions of Docker went by `docker` or `docker-engine`. Uninstall any such older versions before attempting to install a new version, along with associated dependencies.\n\n`zypper` might report that you have none of these packages installed.\n\nImages, containers, volumes, and networks stored in `/var/lib/docker/` aren't automatically removed when you uninstall Docker.\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n*   You can [set up Docker's repositories](#install-using-the-repository) and install from them, for ease of installation and upgrade tasks. This is the recommended approach.\n    \n*   You can download the RPM package, [install it manually](#install-from-a-package), and manage upgrades completely manually. This is useful in situations such as installing Docker on air-gapped systems with no access to the internet.\n    \n*   In testing and development environments, you can use automated [convenience scripts](#install-using-the-convenience-script) to install Docker.\n    \n\n### [Install using the rpm repository](#install-using-the-repository)\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\n#### [Set up the repository](#set-up-the-repository)\n\nSet up the repository.\n\n#### [Install Docker Engine](#install-docker-engine)\n\n1.  Install Docker Engine, containerd, and Docker Compose:\n    \n    * * *\n    \n    To install the latest version, run:\n    \n    If prompted to accept the GPG key, verify that the fingerprint matches `060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35`, and if so, accept it.\n    \n    This command installs Docker, but it doesn't start Docker. It also creates a `docker` group, however, it doesn't add any users to the group by default.\n    \n    To install a specific version, start by listing the available versions in the repository:\n    \n    The list returned depends on which repositories are enabled, and is specific to your version of SLES.\n    \n    Install a specific version by its fully qualified package name, which is the package name (`docker-ce`) plus the version string (2nd column), separated by a hyphen (`-`). For example, `docker-ce-3:25.0.0`.\n    \n    Replace `<VERSION_STRING>` with the desired version and then run the following command to install:\n    \n    This command installs Docker, but it doesn't start Docker. It also creates a `docker` group, however, it doesn't add any users to the group by default.\n    \n    * * *\n    \n2.  Start Docker.\n    \n3.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why you’re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine)\n\nTo upgrade Docker Engine, follow the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### [Install from a package](#install-from-a-package)\n\nIf you can't use Docker's `rpm` repository to install Docker Engine, you can download the `.rpm` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [https://download.docker.com/linux/sles/](https://download.docker.com/linux/sles/) and choose your version of SLES. Then browse to `s390x/stable/Packages/` and download the `.rpm` file for the Docker version you want to install.\n    \n2.  Install Docker Engine, changing the following path to the path where you downloaded the Docker package.\n    \n    Docker is installed but not started. The `docker` group is created, but no users are added to the group.\n    \n3.  Start Docker.\n    \n4.  Verify that the Docker Engine installation is successful by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why you’re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine-1)\n\nTo upgrade Docker Engine, download the newer package files and repeat the [installation procedure](#install-from-a-package), using `zypper -y upgrade` instead of `zypper -y install`, and point to the new files.\n\n### [Install using the convenience script](#install-using-the-convenience-script)\n\nDocker provides a convenience script at [https://get.docker.com/](https://get.docker.com/) to install Docker into development environments non-interactively. The convenience script isn't recommended for production environments, but it's useful for creating a provisioning script tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and you can find it in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n*   The script requires `root` or `sudo` privileges to run.\n*   The script attempts to detect your Linux distribution and version and configure your package management system for you.\n*   The script doesn't allow you to customize most installation parameters.\n*   The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n*   By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test upgrades in a test environment before deploying to your production systems.\n*   The script isn't designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, resulting in outdated versions.\n\n> **Tip: preview script steps before running**\n> \n> You can run the script with the `--dry-run` option to learn what steps the script will run when invoked:\n\nThis example downloads the script from [https://get.docker.com/](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\nYou have now successfully installed and started Docker Engine. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users can't run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n> \n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user). You can also install Docker without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](https://docs.docker.com/engine/security/rootless/).\n\n#### [Install pre-releases](#install-pre-releases)\n\nDocker also provides a convenience script at [https://test.docker.com/](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equal to the script at `get.docker.com`, but configures your package manager to use the test channel of the Docker package repository. The test channel includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they're released as stable.\n\nTo install the latest version of Docker on Linux from the test channel, run:\n\n#### [Upgrade Docker after using the convenience script](#upgrade-docker-after-using-the-convenience-script)\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There's no advantage to re-running the convenience script. Re-running it can cause issues if it attempts to re-install repositories which already exist on the host machine.\n\n1.  Uninstall the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n2.  Images, containers, volumes, or custom configuration files on your host aren't automatically removed. To delete all images, containers, and volumes:\n    \n\nYou have to delete any edited configuration files manually.\n\n*   Continue to [Post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/).",
    "title": "Install Docker Engine on SLES (s390x) | Docker Docs\n",
    "description": "Learn how to install Docker Engine on SLES. These instructions cover the different installation methods, how to uninstall, and next steps.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/security/trust/trust_automation/",
    "markdown": "# Automation with content trust | Docker Docs\n\nIt is very common for Docker Content Trust to be built into existing automation systems. To allow tools to wrap Docker and push trusted content, there are environment variables that can be passed through to the client.\n\nThis guide follows the steps as described in [Signing images with Docker Content Trust](https://docs.docker.com/engine/security/trust/#signing-images-with-docker-content-trust). Make sure you understand and follow the prerequisites.\n\nWhen working directly with the Notary client, it uses its [own set of environment variables](https://github.com/theupdateframework/notary/blob/master/docs/reference/client-config.md#environment-variables-optional).\n\nTo automate importing a delegation private key to the local Docker trust store, we need to pass a passphrase for the new key. This passphrase will be required everytime that delegation signs a tag.\n\nIf you initialize a repository at the same time as adding a delegation public key, then you will need to use the local Notary Canonical Root Key's passphrase to create the repositories trust data. If the repository has already been initiated then you only need the repositories passphrase.\n\nFinally when signing an image, we will need to export the passphrase of the signing key. This was created when the key was loaded into the local Docker trust store with `$ docker trust key load`.\n\n## [Build with content trust](#build-with-content-trust)\n\nYou can also build with content trust. Before running the `docker build` command, you should set the environment variable `DOCKER_CONTENT_TRUST` either manually or in a scripted fashion. Consider the simple Dockerfile below.\n\nThe `FROM` tag is pulling a signed image. You cannot build an image that has a `FROM` that is not either present locally or signed. Given that content trust data exists for the tag `latest`, the following build should succeed:\n\nIf content trust is enabled, building from a Dockerfile that relies on tag without trust data, causes the build command to fail:\n\n*   [Delegations for content trust](https://docs.docker.com/engine/security/trust/trust_delegation/)\n*   [Content trust in Docker](https://docs.docker.com/engine/security/trust/)\n*   [Manage keys for content trust](https://docs.docker.com/engine/security/trust/trust_key_mng/)\n*   [Play in a content trust sandbox](https://docs.docker.com/engine/security/trust/trust_sandbox/)",
    "title": "Automation with content trust | Docker Docs\n",
    "description": "Automating content push pulls with trust",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/install/raspberry-pi-os/",
    "markdown": "# Install Docker Engine on Raspberry Pi OS (32-bit)\n\nTo get started with Docker Engine on Raspberry Pi OS, make sure you [meet the prerequisites](#prerequisites), and then follow the [installation steps](#installation-methods).\n\n> **Important**\n> \n> This installation instruction refers to the 32-bit (armhf) version of Raspberry Pi OS. If you're using the 64-bit (arm64) version, follow the instructions for [Debian](https://docs.docker.com/engine/install/debian/).\n\n### [Firewall limitations](#firewall-limitations)\n\n> **Warning**\n> \n> Before you install Docker, make sure you consider the following security implications and firewall incompatibilities.\n\n*   If you use ufw or firewalld to manage firewall settings, be aware that when you expose container ports using Docker, these ports bypass your firewall rules. For more information, refer to [Docker and ufw](https://docs.docker.com/network/packet-filtering-firewalls/#docker-and-ufw).\n*   Docker is only compatible with `iptables-nft` and `iptables-legacy`. Firewall rules created with `nft` are not supported on a system with Docker installed. Make sure that any firewall rulesets you use are created with `iptables` or `iptables6`, and that you add them to the `DOCKER-USER` chain, see [Packet filtering and firewalls](https://docs.docker.com/network/packet-filtering-firewalls/).\n\n### [OS requirements](#os-requirements)\n\nTo install Docker Engine, you need one of the following OS versions:\n\n*   32-bit Raspberry Pi OS Bookworm 12 (stable)\n*   32-bit Raspberry Pi OS Bullseye 11 (oldstable)\n\n### [Uninstall old versions](#uninstall-old-versions)\n\nBefore you can install Docker Engine, you need to uninstall any conflicting packages.\n\nDistro maintainers provide an unofficial distributions of Docker packages in APT. You must uninstall these packages before you can install the official version of Docker Engine.\n\nThe unofficial packages to uninstall are:\n\n*   `docker.io`\n*   `docker-compose`\n*   `docker-doc`\n*   `podman-docker`\n\nMoreover, Docker Engine depends on `containerd` and `runc`. Docker Engine bundles these dependencies as one bundle: `containerd.io`. If you have installed the `containerd` or `runc` previously, uninstall them to avoid conflicts with the versions bundled with Docker Engine.\n\nRun the following command to uninstall all conflicting packages:\n\n`apt-get` might report that you have none of these packages installed.\n\nImages, containers, volumes, and networks stored in `/var/lib/docker/` aren't automatically removed when you uninstall Docker. If you want to start with a clean installation, and prefer to clean up any existing data, read the [uninstall Docker Engine](#uninstall-docker-engine) section.\n\nYou can install Docker Engine in different ways, depending on your needs:\n\n*   Docker Engine comes bundled with [Docker Desktop for Linux](https://docs.docker.com/desktop/install/linux-install/). This is the easiest and quickest way to get started.\n    \n*   Set up and install Docker Engine from [Docker's `apt` repository](#install-using-the-repository).\n    \n*   [Install it manually](#install-from-a-package) and manage upgrades manually.\n    \n*   Use a [convenience script](#install-using-the-convenience-script). Only recommended for testing and development environments.\n    \n\n### [Install using the `apt` repository](#install-using-the-repository)\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker `apt` repository. Afterward, you can install and update Docker from the repository.\n\n1.  Set up Docker's `apt` repository.\n    \n2.  Install the Docker packages.\n    \n    * * *\n    \n    To install the latest version, run:\n    \n    To install a specific version of Docker Engine, start by listing the available versions in the repository:\n    \n    Select the desired version and install:\n    \n    * * *\n    \n3.  Verify that the installation is successful by running the `hello-world` image:\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why you’re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine)\n\nTo upgrade Docker Engine, follow step 2 of the [installation instructions](#install-using-the-repository), choosing the new version you want to install.\n\n### [Install from a package](#install-from-a-package)\n\nIf you can't use Docker's `apt` repository to install Docker Engine, you can download the `deb` file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n\n1.  Go to [`https://download.docker.com/linux/raspbian/dists/`](https://download.docker.com/linux/raspbian/dists/).\n    \n2.  Select your Raspberry Pi OS version in the list.\n    \n3.  Go to `pool/stable/` and select the applicable architecture (`amd64`, `armhf`, `arm64`, or `s390x`).\n    \n4.  Download the following `deb` files for the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n    *   `containerd.io_<version>_<arch>.deb`\n    *   `docker-ce_<version>_<arch>.deb`\n    *   `docker-ce-cli_<version>_<arch>.deb`\n    *   `docker-buildx-plugin_<version>_<arch>.deb`\n    *   `docker-compose-plugin_<version>_<arch>.deb`\n5.  Install the `.deb` packages. Update the paths in the following example to where you downloaded the Docker packages.\n    \n    The Docker daemon starts automatically.\n    \n6.  Verify that the Docker Engine installation is successful by running the `hello-world` image:\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why you’re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n#### [Upgrade Docker Engine](#upgrade-docker-engine-1)\n\nTo upgrade Docker Engine, download the newer package files and repeat the [installation procedure](#install-from-a-package), pointing to the new files.\n\n### [Install using the convenience script](#install-using-the-convenience-script)\n\nDocker provides a convenience script at [https://get.docker.com/](https://get.docker.com/) to install Docker into development environments non-interactively. The convenience script isn't recommended for production environments, but it's useful for creating a provisioning script tailored to your needs. Also refer to the [install using the repository](#install-using-the-repository) steps to learn about installation steps to install using the package repository. The source code for the script is open source, and you can find it in the [`docker-install` repository on GitHub](https://github.com/docker/docker-install).\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n\n*   The script requires `root` or `sudo` privileges to run.\n*   The script attempts to detect your Linux distribution and version and configure your package management system for you.\n*   The script doesn't allow you to customize most installation parameters.\n*   The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n*   By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test upgrades in a test environment before deploying to your production systems.\n*   The script isn't designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, resulting in outdated versions.\n\n> **Tip: preview script steps before running**\n> \n> You can run the script with the `--dry-run` option to learn what steps the script will run when invoked:\n\nThis example downloads the script from [https://get.docker.com/](https://get.docker.com/) and runs it to install the latest stable release of Docker on Linux:\n\nYou have now successfully installed and started Docker Engine. The `docker` service starts automatically on Debian based distributions. On `RPM` based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate `systemctl` or `service` command. As the message indicates, non-root users can't run Docker commands by default.\n\n> **Use Docker as a non-privileged user, or install in rootless mode?**\n> \n> The installation script requires `root` or `sudo` privileges to install and use Docker. If you want to grant non-root users access to Docker, refer to the [post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user). You can also install Docker without `root` privileges, or configured to run in rootless mode. For instructions on running Docker in rootless mode, refer to [run the Docker daemon as a non-root user (rootless mode)](https://docs.docker.com/engine/security/rootless/).\n\n#### [Install pre-releases](#install-pre-releases)\n\nDocker also provides a convenience script at [https://test.docker.com/](https://test.docker.com/) to install pre-releases of Docker on Linux. This script is equal to the script at `get.docker.com`, but configures your package manager to use the test channel of the Docker package repository. The test channel includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they're released as stable.\n\nTo install the latest version of Docker on Linux from the test channel, run:\n\n#### [Upgrade Docker after using the convenience script](#upgrade-docker-after-using-the-convenience-script)\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There's no advantage to re-running the convenience script. Re-running it can cause issues if it attempts to re-install repositories which already exist on the host machine.\n\n1.  Uninstall the Docker Engine, CLI, containerd, and Docker Compose packages:\n    \n2.  Images, containers, volumes, or custom configuration files on your host aren't automatically removed. To delete all images, containers, and volumes:\n    \n\nYou have to delete any edited configuration files manually.\n\n*   Continue to [Post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/).",
    "title": "Install Docker Engine on Raspberry Pi OS (32-bit) | Docker Docs\n",
    "description": "Learn how to install Docker Engine on a 32-bit Raspberry Pi OS system. These instructions cover the different installation methods, how to uninstall, and next steps.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/configs/",
    "markdown": "# Store configuration data using Docker Configs\n\nDocker swarm service configs allow you to store non-sensitive information, such as configuration files, outside a service's image or running containers. This allows you to keep your images as generic as possible, without the need to bind-mount configuration files into the containers or use environment variables.\n\nConfigs operate in a similar way to [secrets](https://docs.docker.com/engine/swarm/secrets/), except that they are not encrypted at rest and are mounted directly into the container's filesystem without the use of RAM disks. Configs can be added or removed from a service at any time, and services can share a config. You can even use configs in conjunction with environment variables or labels, for maximum flexibility. Config values can be generic strings or binary content (up to 500 kb in size).\n\n> **Note**\n> \n> Docker configs are only available to swarm services, not to standalone containers. To use this feature, consider adapting your container to run as a service with a scale of 1.\n\nConfigs are supported on both Linux and Windows services.\n\n### [Windows support](#windows-support)\n\nDocker includes support for configs on Windows containers, but there are differences in the implementations, which are called out in the examples below. Keep the following notable differences in mind:\n\n*   Config files with custom targets are not directly bind-mounted into Windows containers, since Windows does not support non-directory file bind-mounts. Instead, configs for a container are all mounted in `C:\\ProgramData\\Docker\\internal\\configs` (an implementation detail which should not be relied upon by applications) within the container. Symbolic links are used to point from there to the desired target of the config within the container. The default target is `C:\\ProgramData\\Docker\\configs`.\n    \n*   When creating a service which uses Windows containers, the options to specify UID, GID, and mode are not supported for configs. Configs are currently only accessible by administrators and users with `system` access within the container.\n    \n*   On Windows, create or update a service using `--credential-spec` with the `config://<config-name>` format. This passes the gMSA credentials file directly to nodes before a container starts. No gMSA credentials are written to disk on worker nodes. For more information, refer to [Deploy services to a swarm](https://docs.docker.com/engine/swarm/services/#gmsa-for-swarm).\n    \n\nWhen you add a config to the swarm, Docker sends the config to the swarm manager over a mutual TLS connection. The config is stored in the Raft log, which is encrypted. The entire Raft log is replicated across the other managers, ensuring the same high availability guarantees for configs as for the rest of the swarm management data.\n\nWhen you grant a newly-created or running service access to a config, the config is mounted as a file in the container. The location of the mount point within the container defaults to `/<config-name>` in Linux containers. In Windows containers, configs are all mounted into `C:\\ProgramData\\Docker\\configs` and symbolic links are created to the desired location, which defaults to `C:\\<config-name>`.\n\nYou can set the ownership (`uid` and `gid`) for the config, using either the numerical ID or the name of the user or group. You can also specify the file permissions (`mode`). These settings are ignored for Windows containers.\n\n*   If not set, the config is owned by the user running the container command (often `root`) and that user's default group (also often `root`).\n*   If not set, the config has world-readable permissions (mode `0444`), unless a `umask` is set within the container, in which case the mode is impacted by that `umask` value.\n\nYou can update a service to grant it access to additional configs or revoke its access to a given config at any time.\n\nA node only has access to configs if the node is a swarm manager or if it is running service tasks which have been granted access to the config. When a container task stops running, the configs shared to it are unmounted from the in-memory filesystem for that container and flushed from the node's memory.\n\nIf a node loses connectivity to the swarm while it is running a task container with access to a config, the task container still has access to its configs, but cannot receive updates until the node reconnects to the swarm.\n\nYou can add or inspect an individual config at any time, or list all configs. You cannot remove a config that a running service is using. See [Rotate a config](https://docs.docker.com/engine/swarm/configs/#example-rotate-a-config) for a way to remove a config without disrupting running services.\n\nTo update or roll back configs more easily, consider adding a version number or date to the config name. This is made easier by the ability to control the mount point of the config within a given container.\n\nTo update a stack, make changes to your Compose file, then re-run `docker stack deploy -c <new-compose-file> <stack-name>`. If you use a new config in that file, your services start using them. Keep in mind that configurations are immutable, so you can't change the file for an existing service. Instead, you create a new config to use a different file\n\nYou can run `docker stack rm` to stop the app and take down the stack. This removes any config that was created by `docker stack deploy` with the same stack name. This removes _all_ configs, including those not referenced by services and those remaining after a `docker service update --config-rm`.\n\nUse these links to read about specific commands, or continue to the [example about using configs with a service](#advanced-example-use-configs-with-a-nginx-service).\n\n*   [`docker config create`](https://docs.docker.com/reference/cli/docker/config/create/)\n*   [`docker config inspect`](https://docs.docker.com/reference/cli/docker/config/inspect/)\n*   [`docker config ls`](https://docs.docker.com/reference/cli/docker/config/ls/)\n*   [`docker config rm`](https://docs.docker.com/reference/cli/docker/config/rm/)\n\nThis section includes graduated examples which illustrate how to use Docker configs.\n\n> **Note**\n> \n> These examples use a single-engine swarm and unscaled services for simplicity. The examples use Linux containers, but Windows containers also support configs.\n\n### [Defining and using configs in compose files](#defining-and-using-configs-in-compose-files)\n\nThe `docker stack` command supports defining configs in a Compose file. However, the `configs` key is not supported for `docker compose`. See [the Compose file reference](https://docs.docker.com/compose/compose-file/legacy-versions/) for details.\n\n### [Simple example: Get started with configs](#simple-example-get-started-with-configs)\n\nThis simple example shows how configs work in just a few commands. For a real-world example, continue to [Advanced example: Use configs with a Nginx service](#advanced-example-use-configs-with-a-nginx-service).\n\n1.  Add a config to Docker. The `docker config create` command reads standard input because the last argument, which represents the file to read the config from, is set to `-`.\n    \n2.  Create a `redis` service and grant it access to the config. By default, the container can access the config at `/my-config`, but you can customize the file name on the container using the `target` option.\n    \n3.  Verify that the task is running without issues using `docker service ps`. If everything is working, the output looks similar to this:\n    \n4.  Get the ID of the `redis` service task container using `docker ps`, so that you can use `docker container exec` to connect to the container and read the contents of the config data file, which defaults to being readable by all and has the same name as the name of the config. The first command below illustrates how to find the container ID, and the second and third commands use shell completion to do this automatically.\n    \n5.  Try removing the config. The removal fails because the `redis` service is running and has access to the config.\n    \n6.  Remove access to the config from the running `redis` service by updating the service.\n    \n7.  Repeat steps 3 and 4 again, verifying that the service no longer has access to the config. The container ID is different, because the `service update` command redeploys the service.\n    \n8.  Stop and remove the service, and remove the config from Docker.\n    \n\n### [Simple example: Use configs in a Windows service](#simple-example-use-configs-in-a-windows-service)\n\nThis is a very simple example which shows how to use configs with a Microsoft IIS service running on Docker for Windows running Windows containers on Microsoft Windows 10. It is a naive example that stores the webpage in a config.\n\nThis example assumes that you have PowerShell installed.\n\n1.  Save the following into a new file `index.html`.\n    \n2.  If you have not already done so, initialize or join the swarm.\n    \n3.  Save the `index.html` file as a swarm config named `homepage`.\n    \n4.  Create an IIS service and grant it access to the `homepage` config.\n    \n5.  Access the IIS service at `http://localhost:8000/`. It should serve the HTML content from the first step.\n    \n6.  Remove the service and the config.\n    \n\n### [Example: Use a templated config](#example-use-a-templated-config)\n\nTo create a configuration in which the content will be generated using a template engine, use the `--template-driver` parameter and specify the engine name as its argument. The template will be rendered when container is created.\n\n1.  Save the following into a new file `index.html.tmpl`.\n    \n2.  Save the `index.html.tmpl` file as a swarm config named `homepage`. Provide parameter `--template-driver` and specify `golang` as template engine.\n    \n3.  Create a service that runs Nginx and has access to the environment variable HELLO and to the config.\n    \n4.  Verify that the service is operational: you can reach the Nginx server, and that the correct output is being served.\n    \n\n### [Advanced example: Use configs with a Nginx service](#advanced-example-use-configs-with-a-nginx-service)\n\nThis example is divided into two parts. [The first part](#generate-the-site-certificate) is all about generating the site certificate and does not directly involve Docker configs at all, but it sets up [the second part](#configure-the-nginx-container), where you store and use the site certificate as a series of secrets and the Nginx configuration as a config. The example shows how to set options on the config, such as the target location within the container and the file permissions (`mode`).\n\n#### [Generate the site certificate](#generate-the-site-certificate)\n\nGenerate a root CA and TLS certificate and key for your site. For production sites, you may want to use a service such as `Let’s Encrypt` to generate the TLS certificate and key, but this example uses command-line tools. This step is a little complicated, but is only a set-up step so that you have something to store as a Docker secret. If you want to skip these sub-steps, you can [use Let's Encrypt](https://letsencrypt.org/getting-started/) to generate the site key and certificate, name the files `site.key` and `site.crt`, and skip to [Configure the Nginx container](#configure-the-nginx-container).\n\n1.  Generate a root key.\n    \n2.  Generate a CSR using the root key.\n    \n3.  Configure the root CA. Edit a new file called `root-ca.cnf` and paste the following contents into it. This constrains the root CA to only sign leaf certificates and not intermediate CAs.\n    \n4.  Sign the certificate.\n    \n5.  Generate the site key.\n    \n6.  Generate the site certificate and sign it with the site key.\n    \n7.  Configure the site certificate. Edit a new file called `site.cnf` and paste the following contents into it. This constrains the site certificate so that it can only be used to authenticate a server and can't be used to sign certificates.\n    \n8.  Sign the site certificate.\n    \n9.  The `site.csr` and `site.cnf` files are not needed by the Nginx service, but you need them if you want to generate a new site certificate. Protect the `root-ca.key` file.\n    \n\n#### [Configure the Nginx container](#configure-the-nginx-container)\n\n1.  Produce a very basic Nginx configuration that serves static files over HTTPS. The TLS certificate and key are stored as Docker secrets so that they can be rotated easily.\n    \n    In the current directory, create a new file called `site.conf` with the following contents:\n    \n2.  Create two secrets, representing the key and the certificate. You can store any file as a secret as long as it is smaller than 500 KB. This allows you to decouple the key and certificate from the services that use them. In these examples, the secret name and the file name are the same.\n    \n3.  Save the `site.conf` file in a Docker config. The first parameter is the name of the config, and the second parameter is the file to read it from.\n    \n    List the configs:\n    \n4.  Create a service that runs Nginx and has access to the two secrets and the config. Set the mode to `0440` so that the file is only readable by its owner and that owner's group, not the world.\n    \n    Within the running containers, the following three files now exist:\n    \n    *   `/run/secrets/site.key`\n    *   `/run/secrets/site.crt`\n    *   `/etc/nginx/conf.d/site.conf`\n5.  Verify that the Nginx service is running.\n    \n6.  Verify that the service is operational: you can reach the Nginx server, and that the correct TLS certificate is being used.\n    \n7.  Unless you are going to continue to the next example, clean up after running this example by removing the `nginx` service and the stored secrets and config.\n    \n\nYou have now configured a Nginx service with its configuration decoupled from its image. You could run multiple sites with exactly the same image but separate configurations, without the need to build a custom image at all.\n\n### [Example: Rotate a config](#example-rotate-a-config)\n\nTo rotate a config, you first save a new config with a different name than the one that is currently in use. You then redeploy the service, removing the old config and adding the new config at the same mount point within the container. This example builds upon the previous one by rotating the `site.conf` configuration file.\n\n1.  Edit the `site.conf` file locally. Add `index.php` to the `index` line, and save the file.\n    \n2.  Create a new Docker config using the new `site.conf`, called `site-v2.conf`.\n    \n3.  Update the `nginx` service to use the new config instead of the old one.\n    \n4.  Verify that the `nginx` service is fully re-deployed, using `docker service ps nginx`. When it is, you can remove the old `site.conf` config.\n    \n5.  To clean up, you can remove the `nginx` service, as well as the secrets and configs.\n    \n\nYou have now updated your `nginx` service's configuration without the need to rebuild its image.",
    "title": "Store configuration data using Docker Configs | Docker Docs\n",
    "description": "How to store configuration data separate from the runtime",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/security/trust/trust_delegation/",
    "markdown": "# Delegations for content trust | Docker Docs\n\nDelegations in Docker Content Trust (DCT) allow you to control who can and cannot sign an image tag. A delegation will have a pair of private and public delegation keys. A delegation could contain multiple pairs of keys and contributors in order to a) allow multiple users to be part of a delegation, and b) to support key rotation.\n\nThe most important delegation within Docker Content Trust is `targets/releases`. This is seen as the canonical source of a trusted image tag, and without a contributor's key being under this delegation, they will be unable to sign a tag.\n\nFortunately when using the `$ docker trust` commands, we will automatically initialize a repository, manage the repository keys, and add a collaborator's key to the `targets/releases` delegation via `docker trust signer add`.\n\nBy default, the `$ docker trust` commands expect the notary server URL to be the same as the registry URL specified in the image tag (following a similar logic to `$ docker push`). When using Docker Hub or DTR, the notary server URL is the same as the registry URL. However, for self-hosted environments or 3rd party registries, you will need to specify an alternative URL for the notary server. This is done with:\n\nIf you do not export this variable in self-hosted environments, you may see errors such as:\n\nIf you have enabled authentication for your notary server, or are using DTR, you will need to log in before you can push data to the notary server.\n\nIf you do not log in, you will see:\n\nSome of the more advanced features of DCT require the Notary CLI. To install and configure the Notary CLI:\n\n1.  Download the [client](https://github.com/theupdateframework/notary/releases) and ensure that it is available on your path.\n    \n2.  Create a configuration file at `~/.notary/config.json` with the following content:\n    \n\nThe newly created configuration file contains information about the location of your local Docker trust data and the notary server URL.\n\nFor more detailed information about how to use notary outside of the Docker Content Trust use cases, refer to the Notary CLI documentation [here](https://github.com/theupdateframework/notary/blob/master/docs/command_reference.md)\n\nA prerequisite to adding your first contributor is a pair of delegation keys. These keys can either be generated locally using `$ docker trust`, generated by a certificate authority.\n\n### [Using Docker Trust to generate keys](#using-docker-trust-to-generate-keys)\n\nDocker trust has a built-in generator for a delegation key pair, `$ docker trust generate <name>`. Running this command will automatically load the delegation private key in to the local Docker trust store.\n\n### [Manually generating keys](#manually-generating-keys)\n\nIf you need to manually generate a private key (either RSA or ECDSA) and a x509 certificate containing the public key, you can use local tools like openssl or cfssl along with a local or company-wide Certificate Authority.\n\nHere is an example of how to generate a 2048-bit RSA portion key (all RSA keys must be at least 2048 bits):\n\nThey should keep `delegation.key` private because it is used to sign tags.\n\nThen they need to generate an x509 certificate containing the public key, which is what you need from them. Here is the command to generate a CSR (certificate signing request):\n\nThen they can send it to whichever CA you trust to sign certificates, or they can self-sign the certificate (in this example, creating a certificate that is valid for 1 year):\n\nThen they need to give you `delegation.crt`, whether it is self-signed or signed by a CA.\n\nFinally you will need to add the private key into your local Docker trust store.\n\n### [Viewing local delegation keys](#viewing-local-delegation-keys)\n\nTo list the keys that have been imported in to the local Docker trust store we can use the Notary CLI.\n\nWhen the first delegation is added to the Notary Server using `$ docker trust`, we automatically initiate trust data for the repository. This includes creating the notary target and snapshots keys, and rotating the snapshot key to be managed by the notary server. More information on these keys can be found [here](https://docs.docker.com/engine/security/trust/trust_key_mng/)\n\nWhen initiating a repository, you will need the key and the passphrase of a local Notary Canonical Root Key. If you have not initiated a repository before, and therefore don't have a Notary root key, `$ docker trust` will create one for you.\n\n> **Important**\n> \n> Be sure to protect and back up your [Notary Canonical Root Key](https://docs.docker.com/engine/security/trust/trust_key_mng/).\n\n### [Initiating the repository](#initiating-the-repository)\n\nTo upload the first key to a delegation, at the same time initiating a repository, you can use the `$ docker trust signer add` command. This will add the contributor's public key to the `targets/releases` delegation, and create a second `targets/<name>` delegation.\n\nFor DCT the name of the second delegation, in the below example `jeff`, is there to help you keep track of the owner of the keys. In more advanced use cases of Notary additional delegations are used for hierarchy.\n\nYou can see which keys have been pushed to the Notary server for each repository with the `$ docker trust inspect` command.\n\nYou could also use the Notary CLI to list delegations and keys. Here you can clearly see the keys were attached to `targets/releases` and `targets/jeff`.\n\n### [Adding additional signers](#adding-additional-signers)\n\nDocker Trust allows you to configure multiple delegations per repository, allowing you to manage the lifecycle of delegations. When adding additional delegations with `$ docker trust` the collaborators key is once again added to the `targets/release` role.\n\n> Note you will need the passphrase for the repository key; this would have been configured when you first initiated the repository.\n\nCheck to prove that there are now 2 delegations (Signer).\n\n### [Adding keys to an existing delegation](#adding-keys-to-an-existing-delegation)\n\nTo support things like key rotation and expiring / retiring keys you can publish multiple contributor keys per delegation. The only prerequisite here is to make sure you use the same the delegation name, in this case `jeff`. Docker trust will automatically handle adding this new key to `targets/releases`.\n\n> **Note**\n> \n> You will need the passphrase for the repository key; this would have been configured when you first initiated the repository.\n\nCheck to prove that the delegation (Signer) now contains multiple Key IDs.\n\n### [Removing a delegation](#removing-a-delegation)\n\nIf you need to remove a delegation, including the contributor keys that are attached to the `targets/releases` role, you can use the `$ docker trust signer remove` command.\n\n> **Note**\n> \n> Tags that were signed by the removed delegation will need to be resigned by an active delegation\n\n#### [Troubleshooting](#troubleshooting)\n\n1.  If you see an error that there are no usable keys in `targets/releases`, you will need to add additional delegations using `docker trust signer add` before resigning images.\n    \n2.  If you have added additional delegations already and are seeing an error message that there are no valid signatures in `targest/releases`, you will need to resign the `targets/releases` delegation file with the Notary CLI.\n    \n    Resigning the delegation file is done with the `$ notary witness` command\n    \n    More information on the `$ notary witness` command can be found [here](https://github.com/theupdateframework/notary/blob/master/docs/advanced_usage.md#recovering-a-delegation)\n    \n\n### [Removing a contributor's key from a delegation](#removing-a-contributors-key-from-a-delegation)\n\nAs part of rotating keys for a delegation, you may want to remove an individual key but retain the delegation. This can be done with the Notary CLI.\n\nRemember you will have to remove the key from both the `targets/releases` role and the role specific to that signer `targets/<name>`.\n\n1.  We will need to grab the Key ID from the Notary Server\n    \n2.  Remove from the `targets/releases` delegation\n    \n3.  Remove from the `targets/<name>` delegation\n    \n4.  Check the remaining delegation list\n    \n\n### [Removing a local delegation private key](#removing-a-local-delegation-private-key)\n\nAs part of rotating delegation keys, you may need to remove a local delegation key from the local Docker trust store. This is done with the Notary CLI, using the `$ notary key remove` command.\n\n1.  We will need to get the Key ID from the local Docker Trust store\n    \n2.  Remove the key from the local Docker Trust store\n    \n\nYou can remove all trust data from a repository, including repository, target, snapshot and all delegations keys using the Notary CLI.\n\nThis is often required by a container registry before a particular repository can be deleted.\n\n*   [Content trust in Docker](https://docs.docker.com/engine/security/trust/)\n*   [Manage keys for content trust](https://docs.docker.com/engine/security/trust/trust_key_mng/)\n*   [Automation with content trust](https://docs.docker.com/engine/security/trust/trust_automation/)\n*   [Play in a content trust sandbox](https://docs.docker.com/engine/security/trust/trust_sandbox/)",
    "title": "Delegations for content trust | Docker Docs\n",
    "description": "Delegations for content trust",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/swarm_manager_locking/",
    "markdown": "# Lock your swarm to protect its encryption key\n\nThe Raft logs used by swarm managers are encrypted on disk by default. This at-rest encryption protects your service's configuration and data from attackers who gain access to the encrypted Raft logs. One of the reasons this feature was introduced was in support of the [Docker secrets](https://docs.docker.com/engine/swarm/secrets/) feature.\n\nWhen Docker restarts, both the TLS key used to encrypt communication among swarm nodes and the key used to encrypt and decrypt Raft logs on disk are loaded into each manager node's memory. Docker has the ability to protect the mutual TLS encryption key and the key used to encrypt and decrypt Raft logs at rest, by allowing you to take ownership of these keys and to require manual unlocking of your managers. This feature is called autolock.\n\nWhen Docker restarts, you must [unlock the swarm](#unlock-a-swarm) first, using a key encryption key generated by Docker when the swarm was locked. You can rotate this key encryption key at any time.\n\n> **Note**\n> \n> You don't need to unlock the swarm when a new node joins the swarm, because the key is propagated to it over mutual TLS.\n\nWhen you initialize a new swarm, you can use the `--autolock` flag to enable autolocking of swarm manager nodes when Docker restarts.\n\nStore the key in a safe place, such as in a password manager.\n\nWhen Docker restarts, you need to [unlock the swarm](#unlock-a-swarm). A locked swarm causes an error like the following when you try to start or restart a service:\n\nTo enable autolock on an existing swarm, set the `autolock` flag to `true`.\n\nTo disable autolock, set `--autolock` to `false`. The mutual TLS key and the encryption key used to read and write Raft logs are stored unencrypted on disk. There is a trade-off between the risk of storing the encryption key unencrypted at rest and the convenience of restarting a swarm without needing to unlock each manager.\n\nKeep the unlock key around for a short time after disabling autolocking, in case a manager goes down while it is still configured to lock using the old key.\n\nTo unlock a locked swarm, use `docker swarm unlock`.\n\nEnter the encryption key that was generated and shown in the command output when you locked the swarm or rotated the key, and the swarm unlocks.\n\nConsider a situation where your swarm is running as expected, then a manager node becomes unavailable. You troubleshoot the problem and bring the physical node back online, but you need to unlock the manager by providing the unlock key to read the encrypted credentials and Raft logs.\n\nIf the key has not been rotated since the node left the swarm, and you have a quorum of functional manager nodes in the swarm, you can view the current unlock key using `docker swarm unlock-key` without any arguments.\n\nIf the key was rotated after the swarm node became unavailable and you do not have a record of the previous key, you may need to force the manager to leave the swarm and join it back to the swarm as a new manager.\n\nYou should rotate the locked swarm's unlock key on a regular schedule.\n\n> **Warning**\n> \n> When you rotate the unlock key, keep a record of the old key around for a few minutes, so that if a manager goes down before it gets the new key, it may still be unlocked with the old one.",
    "title": "Lock your swarm to protect its encryption key | Docker Docs\n",
    "description": "Automatically lock Swarm managers to protect encryption keys",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/install/binaries/",
    "markdown": "# Install Docker Engine from binaries\n\n> **Important**\n> \n> This page contains information on how to install Docker using binaries. These instructions are mostly suitable for testing purposes. We do not recommend installing Docker using binaries in production environments as they don't have automatic security updates. The Linux binaries described on this page are statically linked, which means that vulnerabilities in build-time dependencies are not automatically patched by security updates of your Linux distribution.\n> \n> Updating binaries is also slightly more involved when compared to Docker packages installed using a package manager or through Docker Desktop, as it requires (manually) updating the installed version whenever there is a new release of Docker.\n> \n> Also, static binaries may not include all functionalities provided by the dynamic packages.\n> \n> On Windows and Mac, we recommend that you install [Docker Desktop](https://docs.docker.com/desktop/) instead. For Linux, we recommend that you follow the instructions specific for your distribution.\n\nIf you want to try Docker or use it in a testing environment, but you're not on a supported platform, you can try installing from static binaries. If possible, you should use packages built for your operating system, and use your operating system's package management system to manage Docker installation and upgrades.\n\nStatic binaries for the Docker daemon binary are only available for Linux (as `dockerd`) and Windows (as `dockerd.exe`). Static binaries for the Docker client are available for Linux, Windows, and macOS (as `docker`).\n\nThis topic discusses binary installation for Linux, Windows, and macOS:\n\n*   [Install daemon and client binaries on Linux](#install-daemon-and-client-binaries-on-linux)\n*   [Install client binaries on macOS](#install-client-binaries-on-macos)\n*   [Install server and client binaries on Windows](#install-server-and-client-binaries-on-windows)\n\n### [Prerequisites](#prerequisites)\n\nBefore attempting to install Docker from binaries, be sure your host machine meets the prerequisites:\n\n*   A 64-bit installation\n*   Version 3.10 or higher of the Linux kernel. The latest version of the kernel available for your platform is recommended.\n*   `iptables` version 1.4 or higher\n*   `git` version 1.7 or higher\n*   A `ps` executable, usually provided by `procps` or a similar package.\n*   [XZ Utils](https://tukaani.org/xz/) 4.9 or higher\n*   A [properly mounted](https://github.com/tianon/cgroupfs-mount/blob/master/cgroupfs-mount) `cgroupfs` hierarchy; a single, all-encompassing `cgroup` mount point is not sufficient. See Github issues [#2683](https://github.com/moby/moby/issues/2683), [#3485](https://github.com/moby/moby/issues/3485), [#4568](https://github.com/moby/moby/issues/4568)).\n\n#### [Secure your environment as much as possible](#secure-your-environment-as-much-as-possible)\n\n##### [OS considerations](#os-considerations)\n\nEnable SELinux or AppArmor if possible.\n\nIt is recommended to use AppArmor or SELinux if your Linux distribution supports either of the two. This helps improve security and blocks certain types of exploits. Review the documentation for your Linux distribution for instructions for enabling and configuring AppArmor or SELinux.\n\n> **Security warning**\n> \n> If either of the security mechanisms is enabled, do not disable it as a work-around to make Docker or its containers run. Instead, configure it correctly to fix any problems.\n\n##### [Docker daemon considerations](#docker-daemon-considerations)\n\n*   Enable `seccomp` security profiles if possible. See [Enabling `seccomp` for Docker](https://docs.docker.com/engine/security/seccomp/).\n    \n*   Enable user namespaces if possible. See the [Daemon user namespace options](https://docs.docker.com/reference/cli/dockerd/#daemon-user-namespace-options).\n    \n\n### [Install static binaries](#install-static-binaries)\n\n1.  Download the static binary archive. Go to [https://download.docker.com/linux/static/stable/](https://download.docker.com/linux/static/stable/), choose your hardware platform, and download the `.tgz` file relating to the version of Docker Engine you want to install.\n    \n2.  Extract the archive using the `tar` utility. The `dockerd` and `docker` binaries are extracted.\n    \n3.  **Optional**: Move the binaries to a directory on your executable path, such as `/usr/bin/`. If you skip this step, you must provide the path to the executable when you invoke `docker` or `dockerd` commands.\n    \n4.  Start the Docker daemon:\n    \n    If you need to start the daemon with additional options, modify the above command accordingly or create and edit the file `/etc/docker/daemon.json` to add the custom configuration options.\n    \n5.  Verify that Docker is installed correctly by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n    \n\nYou have now successfully installed and started Docker Engine.\n\n> **Tip**\n> \n> Receiving errors when trying to run without root?\n> \n> The `docker` user group exists but contains no users, which is why you’re required to use `sudo` to run Docker commands. Continue to [Linux postinstall](https://docs.docker.com/engine/install/linux-postinstall) to allow non-privileged users to run Docker commands and for other optional configuration steps.\n\n> **Note**\n> \n> The following instructions are mostly suitable for testing purposes. The macOS binary includes the Docker client only. It does not include the `dockerd` daemon which is required to run containers. Therefore, we recommend that you install [Docker Desktop](https://docs.docker.com/desktop/) instead.\n\nThe binaries for Mac also do not contain:\n\n*   A runtime environment. You must set up a functional engine either in a Virtual Machine, or on a remote Linux machine.\n*   Docker components such as `buildx` and `docker compose`.\n\nTo install client binaries, perform the following steps:\n\n1.  Download the static binary archive. Go to [https://download.docker.com/mac/static/stable/](https://download.docker.com/mac/static/stable/) and select `x86_64` (for Mac on Intel chip) or `aarch64` (for Mac on Apple silicon), and then download the `.tgz` file relating to the version of Docker Engine you want to install.\n    \n2.  Extract the archive using the `tar` utility. The `docker` binary is extracted.\n    \n3.  Clear the extended attributes to allow it run.\n    \n    Now, when you run the following command, you can see the Docker CLI usage instructions:\n    \n4.  **Optional**: Move the binary to a directory on your executable path, such as `/usr/local/bin/`. If you skip this step, you must provide the path to the executable when you invoke `docker` or `dockerd` commands.\n    \n5.  Verify that Docker is installed correctly by running the `hello-world` image. The value of `<hostname>` is a hostname or IP address running the Docker daemon and accessible to the client.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n    \n\n> **Note**\n> \n> The following section describes how to install the Docker daemon on Windows Server which allows you to run Windows containers only. When you install the Docker daemon on Windows Server, the daemon doesn't contain Docker components such as `buildx` and `compose`. If you're running Windows 10 or 11, we recommend that you install [Docker Desktop](https://docs.docker.com/desktop/) instead.\n\nBinary packages on Windows include both `dockerd.exe` and `docker.exe`. On Windows, these binaries only provide the ability to run native Windows containers (not Linux containers).\n\nTo install server and client binaries, perform the following steps:\n\n1.  Download the static binary archive. Go to [https://download.docker.com/win/static/stable/x86\\_64](https://download.docker.com/win/static/stable/x86_64) and select the latest version from the list.\n    \n2.  Run the following PowerShell commands to install and extract the archive to your program files:\n    \n3.  Register the service and start the Docker Engine:\n    \n4.  Verify that Docker is installed correctly by running the `hello-world` image.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n    \n\nTo upgrade your manual installation of Docker Engine, first stop any `dockerd` or `dockerd.exe` processes running locally, then follow the regular installation steps to install the new version on top of the existing version.\n\n*   Continue to [Post-installation steps for Linux](https://docs.docker.com/engine/install/linux-postinstall/).",
    "title": "Install Docker Engine from binaries | Docker Docs\n",
    "description": "Learn how to install Docker as a binary. These instructions are most suitable for testing purposes.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/secrets/",
    "markdown": "# Manage sensitive data with Docker secrets\n\nIn terms of Docker Swarm services, a _secret_ is a blob of data, such as a password, SSH private key, SSL certificate, or another piece of data that should not be transmitted over a network or stored unencrypted in a Dockerfile or in your application's source code. You can use Docker _secrets_ to centrally manage this data and securely transmit it to only those containers that need access to it. Secrets are encrypted during transit and at rest in a Docker swarm. A given secret is only accessible to those services which have been granted explicit access to it, and only while those service tasks are running.\n\nYou can use secrets to manage any sensitive data which a container needs at runtime but you don't want to store in the image or in source control, such as:\n\n*   Usernames and passwords\n*   TLS certificates and keys\n*   SSH keys\n*   Other important data such as the name of a database or internal server\n*   Generic strings or binary content (up to 500 kb in size)\n\n> **Note**\n> \n> Docker secrets are only available to swarm services, not to standalone containers. To use this feature, consider adapting your container to run as a service. Stateful containers can typically run with a scale of 1 without changing the container code.\n\nAnother use case for using secrets is to provide a layer of abstraction between the container and a set of credentials. Consider a scenario where you have separate development, test, and production environments for your application. Each of these environments can have different credentials, stored in the development, test, and production swarms with the same secret name. Your containers only need to know the name of the secret to function in all three environments.\n\nYou can also use secrets to manage non-sensitive data, such as configuration files. However, Docker supports the use of [configs](https://docs.docker.com/engine/swarm/configs/) for storing non-sensitive data. Configs are mounted into the container's filesystem directly, without the use of a RAM disk.\n\n### [Windows support](#windows-support)\n\nDocker includes support for secrets on Windows containers. Where there are differences in the implementations, they are called out in the examples below. Keep the following notable differences in mind:\n\n*   Microsoft Windows has no built-in driver for managing RAM disks, so within running Windows containers, secrets are persisted in clear text to the container's root disk. However, the secrets are explicitly removed when a container stops. In addition, Windows does not support persisting a running container as an image using `docker commit` or similar commands.\n    \n*   On Windows, we recommend enabling [BitLocker](https://technet.microsoft.com/en-us/library/cc732774%28v=ws.11%29.aspx) on the volume containing the Docker root directory on the host machine to ensure that secrets for running containers are encrypted at rest.\n    \n*   Secret files with custom targets are not directly bind-mounted into Windows containers, since Windows does not support non-directory file bind-mounts. Instead, secrets for a container are all mounted in `C:\\ProgramData\\Docker\\internal\\secrets` (an implementation detail which should not be relied upon by applications) within the container. Symbolic links are used to point from there to the desired target of the secret within the container. The default target is `C:\\ProgramData\\Docker\\secrets`.\n    \n*   When creating a service which uses Windows containers, the options to specify UID, GID, and mode are not supported for secrets. Secrets are currently only accessible by administrators and users with `system` access within the container.\n    \n\nWhen you add a secret to the swarm, Docker sends the secret to the swarm manager over a mutual TLS connection. The secret is stored in the Raft log, which is encrypted. The entire Raft log is replicated across the other managers, ensuring the same high availability guarantees for secrets as for the rest of the swarm management data.\n\nWhen you grant a newly-created or running service access to a secret, the decrypted secret is mounted into the container in an in-memory filesystem. The location of the mount point within the container defaults to `/run/secrets/<secret_name>` in Linux containers, or `C:\\ProgramData\\Docker\\secrets` in Windows containers. You can also specify a custom location.\n\nYou can update a service to grant it access to additional secrets or revoke its access to a given secret at any time.\n\nA node only has access to (encrypted) secrets if the node is a swarm manager or if it is running service tasks which have been granted access to the secret. When a container task stops running, the decrypted secrets shared to it are unmounted from the in-memory filesystem for that container and flushed from the node's memory.\n\nIf a node loses connectivity to the swarm while it is running a task container with access to a secret, the task container still has access to its secrets, but cannot receive updates until the node reconnects to the swarm.\n\nYou can add or inspect an individual secret at any time, or list all secrets. You cannot remove a secret that a running service is using. See [Rotate a secret](https://docs.docker.com/engine/swarm/secrets/#example-rotate-a-secret) for a way to remove a secret without disrupting running services.\n\nTo update or roll back secrets more easily, consider adding a version number or date to the secret name. This is made easier by the ability to control the mount point of the secret within a given container.\n\nUse these links to read about specific commands, or continue to the [example about using secrets with a service](https://docs.docker.com/engine/swarm/secrets/#simple-example-get-started-with-secrets).\n\n*   [`docker secret create`](https://docs.docker.com/reference/cli/docker/secret/create/)\n*   [`docker secret inspect`](https://docs.docker.com/reference/cli/docker/secret/inspect/)\n*   [`docker secret ls`](https://docs.docker.com/reference/cli/docker/secret/ls/)\n*   [`docker secret rm`](https://docs.docker.com/reference/cli/docker/secret/rm/)\n*   [`--secret`](https://docs.docker.com/reference/cli/docker/service/create/#secret) flag for `docker service create`\n*   [`--secret-add` and `--secret-rm`](https://docs.docker.com/reference/cli/docker/service/update/#secret-add) flags for `docker service update`\n\nThis section includes three graduated examples which illustrate how to use Docker secrets. The images used in these examples have been updated to make it easier to use Docker secrets. To find out how to modify your own images in a similar way, see [Build support for Docker Secrets into your images](#build-support-for-docker-secrets-into-your-images).\n\n> **Note**\n> \n> These examples use a single-Engine swarm and unscaled services for simplicity. The examples use Linux containers, but Windows containers also support secrets. See [Windows support](#windows-support).\n\n### [Defining and using secrets in compose files](#defining-and-using-secrets-in-compose-files)\n\nBoth the `docker-compose` and `docker stack` commands support defining secrets in a compose file. See [the Compose file reference](https://docs.docker.com/compose/compose-file/legacy-versions/) for details.\n\n### [Simple example: Get started with secrets](#simple-example-get-started-with-secrets)\n\nThis simple example shows how secrets work in just a few commands. For a real-world example, continue to [Intermediate example: Use secrets with a Nginx service](#intermediate-example-use-secrets-with-a-nginx-service).\n\n1.  Add a secret to Docker. The `docker secret create` command reads standard input because the last argument, which represents the file to read the secret from, is set to `-`.\n    \n2.  Create a `redis` service and grant it access to the secret. By default, the container can access the secret at `/run/secrets/<secret_name>`, but you can customize the file name on the container using the `target` option.\n    \n3.  Verify that the task is running without issues using `docker service ps`. If everything is working, the output looks similar to this:\n    \n    If there were an error, and the task were failing and repeatedly restarting, you would see something like this:\n    \n4.  Get the ID of the `redis` service task container using `docker ps` , so that you can use `docker container exec` to connect to the container and read the contents of the secret data file, which defaults to being readable by all and has the same name as the name of the secret. The first command below illustrates how to find the container ID, and the second and third commands use shell completion to do this automatically.\n    \n5.  Verify that the secret is not available if you commit the container.\n    \n6.  Try removing the secret. The removal fails because the `redis` service is running and has access to the secret.\n    \n7.  Remove access to the secret from the running `redis` service by updating the service.\n    \n8.  Repeat steps 3 and 4 again, verifying that the service no longer has access to the secret. The container ID is different, because the `service update` command redeploys the service.\n    \n9.  Stop and remove the service, and remove the secret from Docker.\n    \n\n### [Simple example: Use secrets in a Windows service](#simple-example-use-secrets-in-a-windows-service)\n\nThis is a very simple example which shows how to use secrets with a Microsoft IIS service running on Docker for Windows running Windows containers on Microsoft Windows 10. It is a naive example that stores the webpage in a secret.\n\nThis example assumes that you have PowerShell installed.\n\n1.  Save the following into a new file `index.html`.\n    \n2.  If you have not already done so, initialize or join the swarm.\n    \n3.  Save the `index.html` file as a swarm secret named `homepage`.\n    \n4.  Create an IIS service and grant it access to the `homepage` secret.\n    \n    > **Note**\n    > \n    > There is technically no reason to use secrets for this example; [configs](https://docs.docker.com/engine/swarm/configs/) are a better fit. This example is for illustration only.\n    \n5.  Access the IIS service at `http://localhost:8000/`. It should serve the HTML content from the first step.\n    \n6.  Remove the service and the secret.\n    \n\n### [Intermediate example: Use secrets with a Nginx service](#intermediate-example-use-secrets-with-a-nginx-service)\n\nThis example is divided into two parts. [The first part](#generate-the-site-certificate) is all about generating the site certificate and does not directly involve Docker secrets at all, but it sets up [the second part](#configure-the-nginx-container), where you store and use the site certificate and Nginx configuration as secrets.\n\n#### [Generate the site certificate](#generate-the-site-certificate)\n\nGenerate a root CA and TLS certificate and key for your site. For production sites, you may want to use a service such as `Let’s Encrypt` to generate the TLS certificate and key, but this example uses command-line tools. This step is a little complicated, but is only a set-up step so that you have something to store as a Docker secret. If you want to skip these sub-steps, you can [use Let's Encrypt](https://letsencrypt.org/getting-started/) to generate the site key and certificate, name the files `site.key` and `site.crt`, and skip to [Configure the Nginx container](#configure-the-nginx-container).\n\n1.  Generate a root key.\n    \n2.  Generate a CSR using the root key.\n    \n3.  Configure the root CA. Edit a new file called `root-ca.cnf` and paste the following contents into it. This constrains the root CA to signing leaf certificates and not intermediate CAs.\n    \n4.  Sign the certificate.\n    \n5.  Generate the site key.\n    \n6.  Generate the site certificate and sign it with the site key.\n    \n7.  Configure the site certificate. Edit a new file called `site.cnf` and paste the following contents into it. This constrains the site certificate so that it can only be used to authenticate a server and can't be used to sign certificates.\n    \n8.  Sign the site certificate.\n    \n9.  The `site.csr` and `site.cnf` files are not needed by the Nginx service, but you need them if you want to generate a new site certificate. Protect the `root-ca.key` file.\n    \n\n#### [Configure the Nginx container](#configure-the-nginx-container)\n\n1.  Produce a very basic Nginx configuration that serves static files over HTTPS. The TLS certificate and key are stored as Docker secrets so that they can be rotated easily.\n    \n    In the current directory, create a new file called `site.conf` with the following contents:\n    \n2.  Create three secrets, representing the key, the certificate, and the `site.conf`. You can store any file as a secret as long as it is smaller than 500 KB. This allows you to decouple the key, certificate, and configuration from the services that use them. In each of these commands, the last argument represents the path to the file to read the secret from on the host machine's filesystem. In these examples, the secret name and the file name are the same.\n    \n3.  Create a service that runs Nginx and has access to the three secrets. The last part of the `docker service create` command creates a symbolic link from the location of the `site.conf` secret to `/etc/nginx.conf.d/`, where Nginx looks for extra configuration files. This step happens before Nginx actually starts, so you don't need to rebuild your image if you change the Nginx configuration.\n    \n    > **Note**\n    > \n    > Normally you would create a Dockerfile which copies the `site.conf` into place, build the image, and run a container using your custom image. This example does not require a custom image. It puts the `site.conf` into place and runs the container all in one step.\n    \n    Secrets are located within the `/run/secrets/` directory in the container by default, which may require extra steps in the container to make the secret available in a different path. The example below creates a symbolic link to the true location of the `site.conf` file so that Nginx can read it:\n    \n    Instead of creating symlinks, secrets allow you to specify a custom location using the `target` option. The example below illustrates how the `site.conf` secret is made available at `/etc/nginx/conf.d/site.conf` inside the container without the use of symbolic links:\n    \n    The `site.key` and `site.crt` secrets use the short-hand syntax, without a custom `target` location set. The short syntax mounts the secrets in \\`/run/secrets/ with the same name as the secret. Within the running containers, the following three files now exist:\n    \n    *   `/run/secrets/site.key`\n    *   `/run/secrets/site.crt`\n    *   `/etc/nginx/conf.d/site.conf`\n4.  Verify that the Nginx service is running.\n    \n5.  Verify that the service is operational: you can reach the Nginx server, and that the correct TLS certificate is being used.\n    \n6.  To clean up after running this example, remove the `nginx` service and the stored secrets.\n    \n\n### [Advanced example: Use secrets with a WordPress service](#advanced-example-use-secrets-with-a-wordpress-service)\n\nIn this example, you create a single-node MySQL service with a custom root password, add the credentials as secrets, and create a single-node WordPress service which uses these credentials to connect to MySQL. The [next example](#example-rotate-a-secret) builds on this one and shows you how to rotate the MySQL password and update the services so that the WordPress service can still connect to MySQL.\n\nThis example illustrates some techniques to use Docker secrets to avoid saving sensitive credentials within your image or passing them directly on the command line.\n\n> **Note**\n> \n> This example uses a single-Engine swarm for simplicity, and uses a single-node MySQL service because a single MySQL server instance cannot be scaled by simply using a replicated service, and setting up a MySQL cluster is beyond the scope of this example.\n> \n> Also, changing a MySQL root passphrase isn’t as simple as changing a file on disk. You must use a query or a `mysqladmin` command to change the password in MySQL.\n\n1.  Generate a random alphanumeric password for MySQL and store it as a Docker secret with the name `mysql_password` using the `docker secret create` command. To make the password shorter or longer, adjust the last argument of the `openssl` command. This is just one way to create a relatively random password. You can use another command to generate the password if you choose.\n    \n    > **Note**\n    > \n    > After you create a secret, you cannot update it. You can only remove and re-create it, and you cannot remove a secret that a service is using. However, you can grant or revoke a running service's access to secrets using `docker service update`. If you need the ability to update a secret, consider adding a version component to the secret name, so that you can later add a new version, update the service to use it, then remove the old version.\n    \n    The last argument is set to `-`, which indicates that the input is read from standard input.\n    \n    The value returned is not the password, but the ID of the secret. In the remainder of this tutorial, the ID output is omitted.\n    \n    Generate a second secret for the MySQL `root` user. This secret isn't shared with the WordPress service created later. It's only needed to bootstrap the `mysql` service.\n    \n    List the secrets managed by Docker using `docker secret ls`:\n    \n    The secrets are stored in the encrypted Raft logs for the swarm.\n    \n2.  Create a user-defined overlay network which is used for communication between the MySQL and WordPress services. There is no need to expose the MySQL service to any external host or container.\n    \n3.  Create the MySQL service. The MySQL service has the following characteristics:\n    \n    *   Because the scale is set to `1`, only a single MySQL task runs. Load-balancing MySQL is left as an exercise to the reader and involves more than just scaling the service.\n        \n    *   Only reachable by other containers on the `mysql_private` network.\n        \n    *   Uses the volume `mydata` to store the MySQL data, so that it persists across restarts to the `mysql` service.\n        \n    *   The secrets are each mounted in a `tmpfs` filesystem at `/run/secrets/mysql_password` and `/run/secrets/mysql_root_password`. They are never exposed as environment variables, nor can they be committed to an image if the `docker commit` command is run. The `mysql_password` secret is the one used by the non-privileged WordPress container to connect to MySQL.\n        \n    *   Sets the environment variables `MYSQL_PASSWORD_FILE` and `MYSQL_ROOT_PASSWORD_FILE` to point to the files `/run/secrets/mysql_password` and `/run/secrets/mysql_root_password`. The `mysql` image reads the password strings from those files when initializing the system database for the first time. Afterward, the passwords are stored in the MySQL system database itself.\n        \n    *   Sets environment variables `MYSQL_USER` and `MYSQL_DATABASE`. A new database called `wordpress` is created when the container starts, and the `wordpress` user has full permissions for this database only. This user cannot create or drop databases or change the MySQL configuration.\n        \n4.  Verify that the `mysql` container is running using the `docker service ls` command.\n    \n5.  Now that MySQL is set up, create a WordPress service that connects to the MySQL service. The WordPress service has the following characteristics:\n    \n    *   Because the scale is set to `1`, only a single WordPress task runs. Load-balancing WordPress is left as an exercise to the reader, because of limitations with storing WordPress session data on the container filesystem.\n    *   Exposes WordPress on port 30000 of the host machine, so that you can access it from external hosts. You can expose port 80 instead if you do not have a web server running on port 80 of the host machine.\n    *   Connects to the `mysql_private` network so it can communicate with the `mysql` container, and also publishes port 80 to port 30000 on all swarm nodes.\n    *   Has access to the `mysql_password` secret, but specifies a different target file name within the container. The WordPress container uses the mount point `/run/secrets/wp_db_password`.\n    *   Sets the environment variable `WORDPRESS_DB_PASSWORD_FILE` to the file path where the secret is mounted. The WordPress service reads the MySQL password string from that file and add it to the `wp-config.php` configuration file.\n    *   Connects to the MySQL container using the username `wordpress` and the password in `/run/secrets/wp_db_password` and creates the `wordpress` database if it does not yet exist.\n    *   Stores its data, such as themes and plugins, in a volume called `wpdata` so these files persist when the service restarts.\n6.  Verify the service is running using `docker service ls` and `docker service ps` commands.\n    \n    At this point, you could actually revoke the WordPress service's access to the `mysql_password` secret, because WordPress has copied the secret to its configuration file `wp-config.php`. Don't do that for now, because we use it later to facilitate rotating the MySQL password.\n    \n7.  Access `http://localhost:30000/` from any swarm node and set up WordPress using the web-based wizard. All of these settings are stored in the MySQL `wordpress` database. WordPress automatically generates a password for your WordPress user, which is completely different from the password WordPress uses to access MySQL. Store this password securely, such as in a password manager. You need it to log into WordPress after [rotating the secret](#example-rotate-a-secret).\n    \n    Go ahead and write a blog post or two and install a WordPress plugin or theme to verify that WordPress is fully operational and its state is saved across service restarts.\n    \n8.  Do not clean up any services or secrets if you intend to proceed to the next example, which demonstrates how to rotate the MySQL root password.\n    \n\n### [Example: Rotate a secret](#example-rotate-a-secret)\n\nThis example builds upon the previous one. In this scenario, you create a new secret with a new MySQL password, update the `mysql` and `wordpress` services to use it, then remove the old secret.\n\n> **Note**\n> \n> Changing the password on a MySQL database involves running extra queries or commands, as opposed to just changing a single environment variable or a file, since the image only sets the MySQL password if the database doesn’t already exist, and MySQL stores the password within a MySQL database by default. Rotating passwords or other secrets may involve additional steps outside of Docker.\n\n1.  Create the new password and store it as a secret named `mysql_password_v2`.\n    \n2.  Update the MySQL service to give it access to both the old and new secrets. Remember that you cannot update or rename a secret, but you can revoke a secret and grant access to it using a new target filename.\n    \n    Updating a service causes it to restart, and when the MySQL service restarts the second time, it has access to the old secret under `/run/secrets/old_mysql_password` and the new secret under `/run/secrets/mysql_password`.\n    \n    Even though the MySQL service has access to both the old and new secrets now, the MySQL password for the WordPress user has not yet been changed.\n    \n    > **Note**\n    > \n    > This example does not rotate the MySQL `root` password.\n    \n3.  Now, change the MySQL password for the `wordpress` user using the `mysqladmin` CLI. This command reads the old and new password from the files in `/run/secrets` but does not expose them on the command line or save them in the shell history.\n    \n    Do this quickly and move on to the next step, because WordPress loses the ability to connect to MySQL.\n    \n    First, find the ID of the `mysql` container task.\n    \n    Substitute the ID in the command below, or use the second variant which uses shell expansion to do it all in a single step.\n    \n    Or:\n    \n4.  Update the `wordpress` service to use the new password, keeping the target path at `/run/secrets/wp_db_password`. This triggers a rolling restart of the WordPress service and the new secret is used.\n    \n5.  Verify that WordPress works by browsing to http://localhost:30000/ on any swarm node again. Use the WordPress username and password from when you ran through the WordPress wizard in the previous task.\n    \n    Verify that the blog post you wrote still exists, and if you changed any configuration values, verify that they are still changed.\n    \n6.  Revoke access to the old secret from the MySQL service and remove the old secret from Docker.\n    \n7.  Run the following commands to remove the WordPress service, the MySQL container, the `mydata` and `wpdata` volumes, and the Docker secrets:\n    \n\nIf you develop a container that can be deployed as a service and requires sensitive data, such as a credential, as an environment variable, consider adapting your image to take advantage of Docker secrets. One way to do this is to ensure that each parameter you pass to the image when creating the container can also be read from a file.\n\nMany of the Docker Official Images in the [Docker library](https://github.com/docker-library/), such as the [wordpress](https://github.com/docker-library/wordpress/) image used in the above examples, have been updated in this way.\n\nWhen you start a WordPress container, you provide it with the parameters it needs by setting them as environment variables. The WordPress image has been updated so that the environment variables which contain important data for WordPress, such as `WORDPRESS_DB_PASSWORD`, also have variants which can read their values from a file (`WORDPRESS_DB_PASSWORD_FILE`). This strategy ensures that backward compatibility is preserved, while allowing your container to read the information from a Docker-managed secret instead of being passed directly.\n\n> **Note**\n> \n> Docker secrets do not set environment variables directly. This was a conscious decision, because environment variables can unintentionally be leaked between containers (for instance, if you use `--link`).\n\nThis example creates a simple WordPress site using two secrets in a Compose file.\n\nThe top-level element `secrets` defines two secrets `db_password` and `db_root_password`.\n\nWhen deploying, Docker creates these two secrets and populates them with the content from the file specified in the Compose file.\n\nThe `db` service uses both secrets, and `wordpress` is using one.\n\nWhen you deploy, Docker mounts a file under `/run/secrets/<secret_name>` in the services. These files are never persisted on disk, but are managed in memory.\n\nEach service uses environment variables to specify where the service should look for that secret data.\n\nMore information on short and long syntax for secrets can be found in the [Compose Specification](https://docs.docker.com/compose/compose-file/09-secrets/).",
    "title": "Manage sensitive data with Docker secrets | Docker Docs\n",
    "description": "How to securely store, retrieve, and use sensitive data with Docker services",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/install/linux-postinstall/",
    "markdown": "# Linux post-installation steps for Docker Engine\n\nThese optional post-installation procedures describe how to configure your Linux host machine to work better with Docker.\n\nThe Docker daemon binds to a Unix socket, not a TCP port. By default it's the `root` user that owns the Unix socket, and other users can only access it using `sudo`. The Docker daemon always runs as the `root` user.\n\nIf you don't want to preface the `docker` command with `sudo`, create a Unix group called `docker` and add users to it. When the Docker daemon starts, it creates a Unix socket accessible by members of the `docker` group. On some Linux distributions, the system automatically creates this group when installing Docker Engine using a package manager. In that case, there is no need for you to manually create the group.\n\n> **Warning**\n> \n> The `docker` group grants root-level privileges to the user. For details on how this impacts security in your system, see [Docker Daemon Attack Surface](https://docs.docker.com/engine/security/#docker-daemon-attack-surface).\n\n> **Note**\n> \n> To run Docker without root privileges, see [Run the Docker daemon as a non-root user (Rootless mode)](https://docs.docker.com/engine/security/rootless/).\n\nTo create the `docker` group and add your user:\n\n1.  Create the `docker` group.\n    \n2.  Add your user to the `docker` group.\n    \n3.  Log out and log back in so that your group membership is re-evaluated.\n    \n    > If you're running Linux in a virtual machine, it may be necessary to restart the virtual machine for changes to take effect.\n    \n    You can also run the following command to activate the changes to groups:\n    \n4.  Verify that you can run `docker` commands without `sudo`.\n    \n    This command downloads a test image and runs it in a container. When the container runs, it prints a message and exits.\n    \n    If you initially ran Docker CLI commands using `sudo` before adding your user to the `docker` group, you may see the following error:\n    \n    This error indicates that the permission settings for the `~/.docker/` directory are incorrect, due to having used the `sudo` command earlier.\n    \n    To fix this problem, either remove the `~/.docker/` directory (it's recreated automatically, but any custom settings are lost), or change its ownership and permissions using the following commands:\n    \n\nMany modern Linux distributions use [systemd](https://systemd.io/) to manage which services start when the system boots. On Debian and Ubuntu, the Docker service starts on boot by default. To automatically start Docker and containerd on boot for other Linux distributions using systemd, run the following commands:\n\nTo stop this behavior, use `disable` instead.\n\nYou can use systemd unit files to configure the Docker service on startup, for example to add an HTTP proxy, set a different directory or partition for the Docker runtime files, or other customizations. For an example, see [Configure the daemon to use a proxy](https://docs.docker.com/config/daemon/proxy/#systemd-unit-file).\n\nDocker provides [logging drivers](https://docs.docker.com/config/containers/logging/) for collecting and viewing log data from all containers running on a host. The default logging driver, `json-file`, writes log data to JSON-formatted files on the host filesystem. Over time, these log files expand in size, leading to potential exhaustion of disk resources.\n\nTo avoid issues with overusing disk for log data, consider one of the following options:\n\n*   Configure the `json-file` logging driver to turn on [log rotation](https://docs.docker.com/config/containers/logging/json-file/).\n*   Use an [alternative logging driver](https://docs.docker.com/config/containers/logging/configure/#configure-the-default-logging-driver) such as the [\"local\" logging driver](https://docs.docker.com/config/containers/logging/local/) that performs log rotation by default.\n*   Use a logging driver that sends logs to a remote logging aggregator.\n\n*   Take a look at the [Docker workshop](https://docs.docker.com/guides/workshop/) to learn how to build an image and run it as a containerized application.",
    "title": "Linux post-installation steps for Docker Engine | Docker Docs\n",
    "description": "Find the recommended Docker Engine post-installation steps for Linux users, including how to run Docker as a non-root user and more.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/security/trust/deploying_notary/",
    "markdown": "# Deploy Notary Server with Compose\n\nThe easiest way to deploy Notary Server is by using Docker Compose. To follow the procedure on this page, you must have already [installed Docker Compose](https://docs.docker.com/compose/install/).\n\n1.  Clone the Notary repository.\n    \n2.  Build and start Notary Server with the sample certificates.\n    \n    For more detailed documentation about how to deploy Notary Server, see the [instructions to run a Notary service](https://github.com/theupdateframework/notary/blob/master/docs/running_a_service.md) as well as [the Notary repository](https://github.com/theupdateframework/notary) for more information.\n    \n3.  Make sure that your Docker or Notary client trusts Notary Server's certificate before you try to interact with the Notary server.\n    \n\nSee the instructions for [Docker](https://docs.docker.com/engine/reference/commandline/cli/#notary) or for [Notary](https://github.com/docker/notary#using-notary) depending on which one you are using.\n\nCheck back here for instructions after Notary Server has an official stable release. To get a head start on deploying Notary in production, see [the Notary repository](https://github.com/theupdateframework/notary).",
    "title": "Deploy Notary Server with Compose | Docker Docs\n",
    "description": "Deploying Notary",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/networking/",
    "markdown": "# Manage swarm service networks | Docker Docs\n\nThis page describes networking for swarm services.\n\nA Docker swarm generates two different kinds of traffic:\n\n*   Control and management plane traffic: This includes swarm management messages, such as requests to join or leave the swarm. This traffic is always encrypted.\n    \n*   Application data plane traffic: This includes container traffic and traffic to and from external clients.\n    \n\nThe following three network concepts are important to swarm services:\n\n*   Overlay networks manage communications among the Docker daemons participating in the swarm. You can create overlay networks, in the same way as user-defined networks for standalone containers. You can attach a service to one or more existing overlay networks as well, to enable service-to-service communication. Overlay networks are Docker networks that use the `overlay` network driver.\n    \n*   The ingress network is a special overlay network that facilitates load balancing among a service's nodes. When any swarm node receives a request on a published port, it hands that request off to a module called `IPVS`. `IPVS` keeps track of all the IP addresses participating in that service, selects one of them, and routes the request to it, over the `ingress` network.\n    \n    The `ingress` network is created automatically when you initialize or join a swarm. Most users do not need to customize its configuration, but Docker allows you to do so.\n    \n*   The docker\\_gwbridge is a bridge network that connects the overlay networks (including the `ingress` network) to an individual Docker daemon's physical network. By default, each container a service is running is connected to its local Docker daemon host's `docker_gwbridge` network.\n    \n    The `docker_gwbridge` network is created automatically when you initialize or join a swarm. Most users do not need to customize its configuration, but Docker allows you to do so.\n    \n\n> **Tip**\n> \n> See also [Networking overview](https://docs.docker.com/network/) for more details about Swarm networking in general.\n\nDocker daemons participating in a swarm need the ability to communicate with each other over the following ports:\n\n*   Port `7946` TCP/UDP for container network discovery.\n*   Port `4789` UDP (configurable) for the overlay network (including ingress) data path.\n\nWhen setting up networking in a Swarm, special care should be taken. Consult the [tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/#open-protocols-and-ports-between-the-hosts) for an overview.\n\nWhen you initialize a swarm or join a Docker host to an existing swarm, two new networks are created on that Docker host:\n\n*   An overlay network called `ingress`, which handles the control and data traffic related to swarm services. When you create a swarm service and do not connect it to a user-defined overlay network, it connects to the `ingress` network by default.\n*   A bridge network called `docker_gwbridge`, which connects the individual Docker daemon to the other daemons participating in the swarm.\n\n### [Create an overlay network](#create-an-overlay-network)\n\nTo create an overlay network, specify the `overlay` driver when using the `docker network create` command:\n\nThe above command doesn't specify any custom options, so Docker assigns a subnet and uses default options. You can see information about the network using `docker network inspect`.\n\nWhen no containers are connected to the overlay network, its configuration is not very exciting:\n\nIn the above output, notice that the driver is `overlay` and that the scope is `swarm`, rather than `local`, `host`, or `global` scopes you might see in other types of Docker networks. This scope indicates that only hosts which are participating in the swarm can access this network.\n\nThe network's subnet and gateway are dynamically configured when a service connects to the network for the first time. The following example shows the same network as above, but with three containers of a `redis` service connected to it.\n\n### [Customize an overlay network](#customize-an-overlay-network)\n\nThere may be situations where you don't want to use the default configuration for an overlay network. For a full list of configurable options, run the command `docker network create --help`. The following are some of the most common options to change.\n\n#### [Configure the subnet and gateway](#configure-the-subnet-and-gateway)\n\nBy default, the network's subnet and gateway are configured automatically when the first service is connected to the network. You can configure these when creating a network using the `--subnet` and `--gateway` flags. The following example extends the previous one by configuring the subnet and gateway.\n\n##### [Using custom default address pools](#using-custom-default-address-pools)\n\nTo customize subnet allocation for your Swarm networks, you can [optionally configure them](https://docs.docker.com/engine/swarm/swarm-mode/) during `swarm init`.\n\nFor example, the following command is used when initializing Swarm:\n\nWhenever a user creates a network, but does not use the `--subnet` command line option, the subnet for this network will be allocated sequentially from the next available subnet from the pool. If the specified network is already allocated, that network will not be used for Swarm.\n\nMultiple pools can be configured if discontiguous address space is required. However, allocation from specific pools is not supported. Network subnets will be allocated sequentially from the IP pool space and subnets will be reused as they are deallocated from networks that are deleted.\n\nThe default mask length can be configured and is the same for all networks. It is set to `/24` by default. To change the default subnet mask length, use the `--default-addr-pool-mask-length` command line option.\n\n> **Note**\n> \n> Default address pools can only be configured on `swarm init` and cannot be altered after cluster creation.\n\n##### [Overlay network size limitations](#overlay-network-size-limitations)\n\nDocker recommends creating overlay networks with `/24` blocks. The `/24` overlay network blocks limit the network to 256 IP addresses.\n\nThis recommendation addresses [limitations with swarm mode](https://github.com/moby/moby/issues/30820). If you need more than 256 IP addresses, do not increase the IP block size. You can either use `dnsrr` endpoint mode with an external load balancer, or use multiple smaller overlay networks. See [Configure service discovery](#configure-service-discovery) for more information about different endpoint modes.\n\n#### [Configure encryption of application data](#encryption)\n\nManagement and control plane data related to a swarm is always encrypted. For more details about the encryption mechanisms, see the [Docker swarm mode overlay network security model](https://docs.docker.com/network/drivers/overlay/).\n\nApplication data among swarm nodes is not encrypted by default. To encrypt this traffic on a given overlay network, use the `--opt encrypted` flag on `docker network create`. This enables IPSEC encryption at the level of the vxlan. This encryption imposes a non-negligible performance penalty, so you should test this option before using it in production.\n\n> **Note**\n> \n> You must [customize the automatically created ingress](#customize-ingress) to enable encryption. By default, all ingress traffic is unencrypted, as encryption is a network-level option.\n\nTo attach a service to an existing overlay network, pass the `--network` flag to `docker service create`, or the `--network-add` flag to `docker service update`.\n\nService containers connected to an overlay network can communicate with each other across it.\n\nTo see which networks a service is connected to, use `docker service ls` to find the name of the service, then `docker service ps <service-name>` to list the networks. Alternately, to see which services' containers are connected to a network, use `docker network inspect <network-name>`. You can run these commands from any swarm node which is joined to the swarm and is in a `running` state.\n\n### [Configure service discovery](#configure-service-discovery)\n\nService discovery is the mechanism Docker uses to route a request from your service's external clients to an individual swarm node, without the client needing to know how many nodes are participating in the service or their IP addresses or ports. You don't need to publish ports which are used between services on the same network. For instance, if you have a [WordPress service that stores its data in a MySQL service](https://training.play-with-docker.com/swarm-service-discovery/), and they are connected to the same overlay network, you do not need to publish the MySQL port to the client, only the WordPress HTTP port.\n\nService discovery can work in two different ways: internal connection-based load-balancing at Layers 3 and 4 using the embedded DNS and a virtual IP (VIP), or external and customized request-based load-balancing at Layer 7 using DNS round robin (DNSRR). You can configure this per service.\n\n*   By default, when you attach a service to a network and that service publishes one or more ports, Docker assigns the service a virtual IP (VIP), which is the \"front end\" for clients to reach the service. Docker keeps a list of all worker nodes in the service, and routes requests between the client and one of the nodes. Each request from the client might be routed to a different node.\n    \n*   If you configure a service to use DNS round-robin (DNSRR) service discovery, there is not a single virtual IP. Instead, Docker sets up DNS entries for the service such that a DNS query for the service name returns a list of IP addresses, and the client connects directly to one of these.\n    \n    DNS round-robin is useful in cases where you want to use your own load balancer, such as HAProxy. To configure a service to use DNSRR, use the flag `--endpoint-mode dnsrr` when creating a new service or updating an existing one.\n    \n\nMost users never need to configure the `ingress` network, but Docker allows you to do so. This can be useful if the automatically-chosen subnet conflicts with one that already exists on your network, or you need to customize other low-level network settings such as the MTU, or if you want to [enable encryption](#encryption).\n\nCustomizing the `ingress` network involves removing and recreating it. This is usually done before you create any services in the swarm. If you have existing services which publish ports, those services need to be removed before you can remove the `ingress` network.\n\nDuring the time that no `ingress` network exists, existing services which do not publish ports continue to function but are not load-balanced. This affects services which publish ports, such as a WordPress service which publishes port 80.\n\n1.  Inspect the `ingress` network using `docker network inspect ingress`, and remove any services whose containers are connected to it. These are services that publish ports, such as a WordPress service which publishes port 80. If all such services are not stopped, the next step fails.\n    \n2.  Remove the existing `ingress` network:\n    \n3.  Create a new overlay network using the `--ingress` flag, along with the custom options you want to set. This example sets the MTU to 1200, sets the subnet to `10.11.0.0/16`, and sets the gateway to `10.11.0.2`.\n    \n    > **Note**\n    > \n    > You can name your `ingress` network something other than `ingress`, but you can only have one. An attempt to create a second one fails.\n    \n4.  Restart the services that you stopped in the first step.\n    \n\nThe `docker_gwbridge` is a virtual bridge that connects the overlay networks (including the `ingress` network) to an individual Docker daemon's physical network. Docker creates it automatically when you initialize a swarm or join a Docker host to a swarm, but it is not a Docker device. It exists in the kernel of the Docker host. If you need to customize its settings, you must do so before joining the Docker host to the swarm, or after temporarily removing the host from the swarm.\n\nYou need to have the `brctl` application installed on your operating system in order to delete an existing bridge. The package name is `bridge-utils`.\n\n1.  Stop Docker.\n    \n2.  Use the `brctl show docker_gwbridge` command to check whether a bridge device exists called `docker_gwbridge`. If so, remove it using `brctl delbr docker_gwbridge`.\n    \n3.  Start Docker. Do not join or initialize the swarm.\n    \n4.  Create or re-create the `docker_gwbridge` bridge with your custom settings. This example uses the subnet `10.11.0.0/16`. For a full list of customizable options, see [Bridge driver options](https://docs.docker.com/reference/cli/docker/network/create/#bridge-driver-options).\n    \n5.  Initialize or join the swarm.\n    \n\nBy default, all swarm traffic is sent over the same interface, including control and management traffic for maintaining the swarm itself and data traffic to and from the service containers.\n\nYou can separate this traffic by passing the `--data-path-addr` flag when initializing or joining the swarm. If there are multiple interfaces, `--advertise-addr` must be specified explicitly, and `--data-path-addr` defaults to `--advertise-addr` if not specified. Traffic about joining, leaving, and managing the swarm is sent over the `--advertise-addr` interface, and traffic among a service's containers is sent over the `--data-path-addr` interface. These flags can take an IP address or a network device name, such as `eth0`.\n\nThis example initializes a swarm with a separate `--data-path-addr`. It assumes that your Docker host has two different network interfaces: 10.0.0.1 should be used for control and management traffic and 192.168.0.1 should be used for traffic relating to services.\n\nThis example joins the swarm managed by host `192.168.99.100:2377` and sets the `--advertise-addr` flag to `eth0` and the `--data-path-addr` flag to `eth1`.\n\nSwarm services connected to the same overlay network effectively expose all ports to each other. For a port to be accessible outside of the service, that port must be _published_ using the `-p` or `--publish` flag on `docker service create` or `docker service update`. Both the legacy colon-separated syntax and the newer comma-separated value syntax are supported. The longer syntax is preferred because it is somewhat self-documenting.\n\n| Flag value | Description |\n| --- | --- |\n| \\-p 8080:80 or  <br>\\-p published=8080,target=80 | Map TCP port 80 on the service to port 8080 on the routing mesh. |\n| \\-p 8080:80/udp or  <br>\\-p published=8080,target=80,protocol=udp | Map UDP port 80 on the service to port 8080 on the routing mesh. |\n| \\-p 8080:80/tcp -p 8080:80/udp or  <br>\\-p published=8080,target=80,protocol=tcp -p published=8080,target=80,protocol=udp | Map TCP port 80 on the service to TCP port 8080 on the routing mesh, and map UDP port 80 on the service to UDP port 8080 on the routing mesh. |\n\n*   [Deploy services to a swarm](https://docs.docker.com/engine/swarm/services/)\n*   [Swarm administration guide](https://docs.docker.com/engine/swarm/admin_guide/)\n*   [Swarm mode tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/)\n*   [Networking overview](https://docs.docker.com/network/)\n*   [Docker CLI reference](https://docs.docker.com/reference/cli/docker/)",
    "title": "Manage swarm service networks | Docker Docs\n",
    "description": "Use swarm mode overlay networking features",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/reference/run/",
    "markdown": "# Running containers | Docker Docs\n\nDocker runs processes in isolated containers. A container is a process which runs on a host. The host may be local or remote. When you execute `docker run`, the container process that runs is isolated in that it has its own file system, its own networking, and its own isolated process tree separate from the host.\n\nThis page details how to use the `docker run` command to run containers.\n\nA `docker run` command takes the following form:\n\nThe `docker run` command must specify an [image reference](#image-references) to create the container from.\n\n### [Image references](#image-references)\n\nThe image reference is the name and version of the image. You can use the image reference to create or run a container based on an image.\n\n*   `docker run IMAGE[:TAG][@DIGEST]`\n*   `docker create IMAGE[:TAG][@DIGEST]`\n\nAn image tag is the image version, which defaults to `latest` when omitted. Use the tag to run a container from specific version of an image. For example, to run version `23.10` of the `ubuntu` image: `docker run ubuntu:23.10`.\n\n#### [Image digests](#image-digests)\n\nImages using the v2 or later image format have a content-addressable identifier called a digest. As long as the input used to generate the image is unchanged, the digest value is predictable.\n\nThe following example runs a container from the `alpine` image with the `sha256:9cacb71397b640eca97488cf08582ae4e4068513101088e9f96c9814bfda95e0` digest:\n\n### [Options](#options)\n\n`[OPTIONS]` let you configure options for the container. For example, you can give the container a name (`--name`), or run it as a background process (`-d`). You can also set options to control things like resource constraints and networking.\n\n### [Commands and arguments](#commands-and-arguments)\n\nYou can use the `[COMMAND]` and `[ARG...]` positional arguments to specify commands and arguments for the container to run when it starts up. For example, you can specify `sh` as the `[COMMAND]`, combined with the `-i` and `-t` flags, to start an interactive shell in the container (if the image you select has an `sh` executable on `PATH`).\n\n> **Note**\n> \n> Depending on your Docker system configuration, you may be required to preface the `docker run` command with `sudo`. To avoid having to use `sudo` with the `docker` command, your system administrator can create a Unix group called `docker` and add users to it. For more information about this configuration, refer to the Docker installation documentation for your operating system.\n\nWhen you start a container, the container runs in the foreground by default. If you want to run the container in the background instead, you can use the `--detach` (or `-d`) flag. This starts the container without occupying your terminal window.\n\nWhile the container runs in the background, you can interact with the container using other CLI commands. For example, `docker logs` lets you view the logs for the container, and `docker attach` brings it to the foreground.\n\nFor more information about `docker run` flags related to foreground and background modes, see:\n\n*   [`docker run --detach`](https://docs.docker.com/reference/cli/docker/container/run/#detach): run container in background\n*   [`docker run --attach`](https://docs.docker.com/reference/cli/docker/container/run/#attach): attach to `stdin`, `stdout`, and `stderr`\n*   [`docker run --tty`](https://docs.docker.com/reference/cli/docker/container/run/#tty): allocate a pseudo-tty\n*   [`docker run --interactive`](https://docs.docker.com/reference/cli/docker/container/run/#interactive): keep `stdin` open even if not attached\n\nFor more information about re-attaching to a background container, see [`docker attach`](https://docs.docker.com/reference/cli/docker/container/attach/).\n\nYou can identify a container in three ways:\n\n| Identifier type | Example value |\n| --- | --- |\n| UUID long identifier | `f78375b1c487e03c9438c729345e54db9d20cfa2ac1fc3494b6eb60872e74778` |\n| UUID short identifier | `f78375b1c487` |\n| Name | `evil_ptolemy` |\n\nThe UUID identifier is a random ID assigned to the container by the daemon.\n\nThe daemon generates a random string name for containers automatically. You can also defined a custom name using [the `--name` flag](https://docs.docker.com/reference/cli/docker/container/run/#name). Defining a `name` can be a handy way to add meaning to a container. If you specify a `name`, you can use it when referring to the container in a user-defined network. This works for both background and foreground Docker containers.\n\nA container identifier is not the same thing as an image reference. The image reference specifies which image to use when you run a container. You can't run `docker exec nginx:alpine sh` to open a shell in a container based on the `nginx:alpine` image, because `docker exec` expects a container identifier (name or ID), not an image.\n\nWhile the image used by a container is not an identifier for the container, you find out the IDs of containers using an image by using the `--filter` flag. For example, the following `docker ps` command gets the IDs of all running containers based on the `nginx:alpine` image:\n\nFor more information about using filters, see [Filtering](https://docs.docker.com/config/filter/).\n\nContainers have networking enabled by default, and they can make outgoing connections. If you're running multiple containers that need to communicate with each other, you can create a custom network and attach the containers to the network.\n\nWhen multiple containers are attached to the same custom network, they can communicate with each other using the container names as a DNS hostname. The following example creates a custom network named `my-net`, and runs two containers that attach to the network.\n\nFor more information about container networking, see [Networking overview](https://docs.docker.com/network/)\n\nBy default, the data in a container is stored in an ephemeral, writable container layer. Removing the container also removes its data. If you want to use persistent data with containers, you can use filesystem mounts to store the data persistently on the host system. Filesystem mounts can also let you share data between containers and the host.\n\nDocker supports two main categories of mounts:\n\n*   Volume mounts\n*   Bind mounts\n\nVolume mounts are great for persistently storing data for containers, and for sharing data between containers. Bind mounts, on the other hand, are for sharing data between a container and the host.\n\nYou can add a filesystem mount to a container using the `--mount` flag for the `docker run` command.\n\nThe following sections show basic examples of how to create volumes and bind mounts. For more in-depth examples and descriptions, refer to the section of the [storage section](https://docs.docker.com/storage/) in the documentation.\n\n### [Volume mounts](#volume-mounts)\n\nTo create a volume mount:\n\nThe `--mount` flag takes two parameters in this case: `source` and `target`. The value for the `source` parameter is the name of the volume. The value of `target` is the mount location of the volume inside the container. Once you've created the volume, any data you write to the volume is persisted, even if you stop or remove the container:\n\nThe `target` must always be an absolute path, such as `/src/docs`. An absolute path starts with a `/` (forward slash). Volume names must start with an alphanumeric character, followed by `a-z0-9`, `_` (underscore), `.` (period) or `-` (hyphen).\n\n### [Bind mounts](#bind-mounts)\n\nTo create a bind mount:\n\nIn this case, the `--mount` flag takes three parameters. A type (`bind`), and two paths. The `source` path is a the location on the host that you want to bind mount into the container. The `target` path is the mount destination inside the container.\n\nBind mounts are read-write by default, meaning that you can both read and write files to and from the mounted location from the container. Changes that you make, such as adding or editing files, are reflected on the host filesystem:\n\nThe exit code from `docker run` gives information about why the container failed to run or why it exited. The following sections describe the meanings of different container exit codes values.\n\n### [125](#125)\n\nExit code `125` indicates that the error is with Docker daemon itself.\n\n### [126](#126)\n\nExit code `126` indicates that the specified contained command can't be invoked. The container command in the following example is: `/etc; echo $?`.\n\n### [127](#127)\n\nExit code `127` indicates that the contained command can't be found.\n\n### [Other exit codes](#other-exit-codes)\n\nAny exit code other than `125`, `126`, and `127` represent the exit code of the provided container command.\n\nThe operator can also adjust the performance parameters of the container:\n\n| Option | Description |\n| --- | --- |\n| `-m`, `--memory=\"\"` | Memory limit (format: `<number>[<unit>]`). Number is a positive integer. Unit can be one of `b`, `k`, `m`, or `g`. Minimum is 6M. |\n| `--memory-swap=\"\"` | Total memory limit (memory + swap, format: `<number>[<unit>]`). Number is a positive integer. Unit can be one of `b`, `k`, `m`, or `g`. |\n| `--memory-reservation=\"\"` | Memory soft limit (format: `<number>[<unit>]`). Number is a positive integer. Unit can be one of `b`, `k`, `m`, or `g`. |\n| `--kernel-memory=\"\"` | Kernel memory limit (format: `<number>[<unit>]`). Number is a positive integer. Unit can be one of `b`, `k`, `m`, or `g`. Minimum is 4M. |\n| `-c`, `--cpu-shares=0` | CPU shares (relative weight) |\n| `--cpus=0.000` | Number of CPUs. Number is a fractional number. 0.000 means no limit. |\n| `--cpu-period=0` | Limit the CPU CFS (Completely Fair Scheduler) period |\n| `--cpuset-cpus=\"\"` | CPUs in which to allow execution (0-3, 0,1) |\n| `--cpuset-mems=\"\"` | Memory nodes (MEMs) in which to allow execution (0-3, 0,1). Only effective on NUMA systems. |\n| `--cpu-quota=0` | Limit the CPU CFS (Completely Fair Scheduler) quota |\n| `--cpu-rt-period=0` | Limit the CPU real-time period. In microseconds. Requires parent cgroups be set and cannot be higher than parent. Also check rtprio ulimits. |\n| `--cpu-rt-runtime=0` | Limit the CPU real-time runtime. In microseconds. Requires parent cgroups be set and cannot be higher than parent. Also check rtprio ulimits. |\n| `--blkio-weight=0` | Block IO weight (relative weight) accepts a weight value between 10 and 1000. |\n| `--blkio-weight-device=\"\"` | Block IO weight (relative device weight, format: `DEVICE_NAME:WEIGHT`) |\n| `--device-read-bps=\"\"` | Limit read rate from a device (format: `<device-path>:<number>[<unit>]`). Number is a positive integer. Unit can be one of `kb`, `mb`, or `gb`. |\n| `--device-write-bps=\"\"` | Limit write rate to a device (format: `<device-path>:<number>[<unit>]`). Number is a positive integer. Unit can be one of `kb`, `mb`, or `gb`. |\n| `--device-read-iops=\"\"` | Limit read rate (IO per second) from a device (format: `<device-path>:<number>`). Number is a positive integer. |\n| `--device-write-iops=\"\"` | Limit write rate (IO per second) to a device (format: `<device-path>:<number>`). Number is a positive integer. |\n| `--oom-kill-disable=false` | Whether to disable OOM Killer for the container or not. |\n| `--oom-score-adj=0` | Tune container's OOM preferences (-1000 to 1000) |\n| `--memory-swappiness=\"\"` | Tune a container's memory swappiness behavior. Accepts an integer between 0 and 100. |\n| `--shm-size=\"\"` | Size of `/dev/shm`. The format is `<number><unit>`. `number` must be greater than `0`. Unit is optional and can be `b` (bytes), `k` (kilobytes), `m` (megabytes), or `g` (gigabytes). If you omit the unit, the system uses bytes. If you omit the size entirely, the system uses `64m`. |\n\n### [User memory constraints](#user-memory-constraints)\n\nWe have four ways to set user memory usage:\n\n| Option | Result |\n| --- | --- |\n| **memory=inf, memory-swap=inf** (default) | There is no memory limit for the container. The container can use as much memory as needed. |\n| **memory=L<inf, memory-swap=inf** | (specify memory and set memory-swap as `-1`) The container is not allowed to use more than L bytes of memory, but can use as much swap as is needed (if the host supports swap memory). |\n| **memory=L<inf, memory-swap=2\\*L** | (specify memory without memory-swap) The container is not allowed to use more than L bytes of memory, swap _plus_ memory usage is double of that. |\n| **memory=L<inf, memory-swap=S<inf, L<=S** | (specify both memory and memory-swap) The container is not allowed to use more than L bytes of memory, swap _plus_ memory usage is limited by S. |\n\nExamples:\n\nWe set nothing about memory, this means the processes in the container can use as much memory and swap memory as they need.\n\nWe set memory limit and disabled swap memory limit, this means the processes in the container can use 300M memory and as much swap memory as they need (if the host supports swap memory).\n\nWe set memory limit only, this means the processes in the container can use 300M memory and 300M swap memory, by default, the total virtual memory size (--memory-swap) will be set as double of memory, in this case, memory + swap would be 2\\*300M, so processes can use 300M swap memory as well.\n\nWe set both memory and swap memory, so the processes in the container can use 300M memory and 700M swap memory.\n\nMemory reservation is a kind of memory soft limit that allows for greater sharing of memory. Under normal circumstances, containers can use as much of the memory as needed and are constrained only by the hard limits set with the `-m`/`--memory` option. When memory reservation is set, Docker detects memory contention or low memory and forces containers to restrict their consumption to a reservation limit.\n\nAlways set the memory reservation value below the hard limit, otherwise the hard limit takes precedence. A reservation of 0 is the same as setting no reservation. By default (without reservation set), memory reservation is the same as the hard memory limit.\n\nMemory reservation is a soft-limit feature and does not guarantee the limit won't be exceeded. Instead, the feature attempts to ensure that, when memory is heavily contended for, memory is allocated based on the reservation hints/setup.\n\nThe following example limits the memory (`-m`) to 500M and sets the memory reservation to 200M.\n\nUnder this configuration, when the container consumes memory more than 200M and less than 500M, the next system memory reclaim attempts to shrink container memory below 200M.\n\nThe following example set memory reservation to 1G without a hard memory limit.\n\nThe container can use as much memory as it needs. The memory reservation setting ensures the container doesn't consume too much memory for long time, because every memory reclaim shrinks the container's consumption to the reservation.\n\nBy default, kernel kills processes in a container if an out-of-memory (OOM) error occurs. To change this behaviour, use the `--oom-kill-disable` option. Only disable the OOM killer on containers where you have also set the `-m/--memory` option. If the `-m` flag is not set, this can result in the host running out of memory and require killing the host's system processes to free memory.\n\nThe following example limits the memory to 100M and disables the OOM killer for this container:\n\nThe following example, illustrates a dangerous way to use the flag:\n\nThe container has unlimited memory which can cause the host to run out memory and require killing system processes to free memory. The `--oom-score-adj` parameter can be changed to select the priority of which containers will be killed when the system is out of memory, with negative scores making them less likely to be killed, and positive scores more likely.\n\n### [Kernel memory constraints](#kernel-memory-constraints)\n\nKernel memory is fundamentally different than user memory as kernel memory can't be swapped out. The inability to swap makes it possible for the container to block system services by consuming too much kernel memory. Kernel memory includes：\n\n*   stack pages\n*   slab pages\n*   sockets memory pressure\n*   tcp memory pressure\n\nYou can setup kernel memory limit to constrain these kinds of memory. For example, every process consumes some stack pages. By limiting kernel memory, you can prevent new processes from being created when the kernel memory usage is too high.\n\nKernel memory is never completely independent of user memory. Instead, you limit kernel memory in the context of the user memory limit. Assume \"U\" is the user memory limit and \"K\" the kernel limit. There are three possible ways to set limits:\n\n| Option | Result |\n| --- | --- |\n| **U != 0, K = inf** (default) | This is the standard memory limitation mechanism already present before using kernel memory. Kernel memory is completely ignored. |\n| **U != 0, K < U** | Kernel memory is a subset of the user memory. This setup is useful in deployments where the total amount of memory per-cgroup is overcommitted. Overcommitting kernel memory limits is definitely not recommended, since the box can still run out of non-reclaimable memory. In this case, you can configure K so that the sum of all groups is never greater than the total memory. Then, freely set U at the expense of the system's service quality. |\n| **U != 0, K > U** | Since kernel memory charges are also fed to the user counter and reclamation is triggered for the container for both kinds of memory. This configuration gives the admin a unified view of memory. It is also useful for people who just want to track kernel memory usage. |\n\nExamples:\n\nWe set memory and kernel memory, so the processes in the container can use 500M memory in total, in this 500M memory, it can be 50M kernel memory tops.\n\nWe set kernel memory without **\\-m**, so the processes in the container can use as much memory as they want, but they can only use 50M kernel memory.\n\n### [Swappiness constraint](#swappiness-constraint)\n\nBy default, a container's kernel can swap out a percentage of anonymous pages. To set this percentage for a container, specify a `--memory-swappiness` value between 0 and 100. A value of 0 turns off anonymous page swapping. A value of 100 sets all anonymous pages as swappable. By default, if you are not using `--memory-swappiness`, memory swappiness value will be inherited from the parent.\n\nFor example, you can set:\n\nSetting the `--memory-swappiness` option is helpful when you want to retain the container's working set and to avoid swapping performance penalties.\n\nBy default, all containers get the same proportion of CPU cycles. This proportion can be modified by changing the container's CPU share weighting relative to the weighting of all other running containers.\n\nTo modify the proportion from the default of 1024, use the `-c` or `--cpu-shares` flag to set the weighting to 2 or higher. If 0 is set, the system will ignore the value and use the default of 1024.\n\nThe proportion will only apply when CPU-intensive processes are running. When tasks in one container are idle, other containers can use the left-over CPU time. The actual amount of CPU time will vary depending on the number of containers running on the system.\n\nFor example, consider three containers, one has a cpu-share of 1024 and two others have a cpu-share setting of 512. When processes in all three containers attempt to use 100% of CPU, the first container would receive 50% of the total CPU time. If you add a fourth container with a cpu-share of 1024, the first container only gets 33% of the CPU. The remaining containers receive 16.5%, 16.5% and 33% of the CPU.\n\nOn a multi-core system, the shares of CPU time are distributed over all CPU cores. Even if a container is limited to less than 100% of CPU time, it can use 100% of each individual CPU core.\n\nFor example, consider a system with more than three cores. If you start one container `{C0}` with `-c=512` running one process, and another container `{C1}` with `-c=1024` running two processes, this can result in the following division of CPU shares:\n\n```\nPID    container\tCPU\tCPU share\n100    {C0}\t\t0\t100% of CPU0\n101    {C1}\t\t1\t100% of CPU1\n102    {C1}\t\t2\t100% of CPU2\n```\n\n### [CPU period constraint](#cpu-period-constraint)\n\nThe default CPU CFS (Completely Fair Scheduler) period is 100ms. We can use `--cpu-period` to set the period of CPUs to limit the container's CPU usage. And usually `--cpu-period` should work with `--cpu-quota`.\n\nExamples:\n\nIf there is 1 CPU, this means the container can get 50% CPU worth of run-time every 50ms.\n\nIn addition to use `--cpu-period` and `--cpu-quota` for setting CPU period constraints, it is possible to specify `--cpus` with a float number to achieve the same purpose. For example, if there is 1 CPU, then `--cpus=0.5` will achieve the same result as setting `--cpu-period=50000` and `--cpu-quota=25000` (50% CPU).\n\nThe default value for `--cpus` is `0.000`, which means there is no limit.\n\nFor more information, see the [CFS documentation on bandwidth limiting](https://www.kernel.org/doc/Documentation/scheduler/sched-bwc.txt).\n\n### [Cpuset constraint](#cpuset-constraint)\n\nWe can set cpus in which to allow execution for containers.\n\nExamples:\n\nThis means processes in container can be executed on cpu 1 and cpu 3.\n\nThis means processes in container can be executed on cpu 0, cpu 1 and cpu 2.\n\nWe can set mems in which to allow execution for containers. Only effective on NUMA systems.\n\nExamples:\n\nThis example restricts the processes in the container to only use memory from memory nodes 1 and 3.\n\nThis example restricts the processes in the container to only use memory from memory nodes 0, 1 and 2.\n\n### [CPU quota constraint](#cpu-quota-constraint)\n\nThe `--cpu-quota` flag limits the container's CPU usage. The default 0 value allows the container to take 100% of a CPU resource (1 CPU). The CFS (Completely Fair Scheduler) handles resource allocation for executing processes and is default Linux Scheduler used by the kernel. Set this value to 50000 to limit the container to 50% of a CPU resource. For multiple CPUs, adjust the `--cpu-quota` as necessary. For more information, see the [CFS documentation on bandwidth limiting](https://www.kernel.org/doc/Documentation/scheduler/sched-bwc.txt).\n\n### [Block IO bandwidth (Blkio) constraint](#block-io-bandwidth-blkio-constraint)\n\nBy default, all containers get the same proportion of block IO bandwidth (blkio). This proportion is 500. To modify this proportion, change the container's blkio weight relative to the weighting of all other running containers using the `--blkio-weight` flag.\n\n> **Note:**\n> \n> The blkio weight setting is only available for direct IO. Buffered IO is not currently supported.\n\nThe `--blkio-weight` flag can set the weighting to a value between 10 to 1000. For example, the commands below create two containers with different blkio weight:\n\nIf you do block IO in the two containers at the same time, by, for example:\n\nYou'll find that the proportion of time is the same as the proportion of blkio weights of the two containers.\n\nThe `--blkio-weight-device=\"DEVICE_NAME:WEIGHT\"` flag sets a specific device weight. The `DEVICE_NAME:WEIGHT` is a string containing a colon-separated device name and weight. For example, to set `/dev/sda` device weight to `200`:\n\nIf you specify both the `--blkio-weight` and `--blkio-weight-device`, Docker uses the `--blkio-weight` as the default weight and uses `--blkio-weight-device` to override this default with a new value on a specific device. The following example uses a default weight of `300` and overrides this default on `/dev/sda` setting that weight to `200`:\n\nThe `--device-read-bps` flag limits the read rate (bytes per second) from a device. For example, this command creates a container and limits the read rate to `1mb` per second from `/dev/sda`:\n\nThe `--device-write-bps` flag limits the write rate (bytes per second) to a device. For example, this command creates a container and limits the write rate to `1mb` per second for `/dev/sda`:\n\nBoth flags take limits in the `<device-path>:<limit>[unit]` format. Both read and write rates must be a positive integer. You can specify the rate in `kb` (kilobytes), `mb` (megabytes), or `gb` (gigabytes).\n\nThe `--device-read-iops` flag limits read rate (IO per second) from a device. For example, this command creates a container and limits the read rate to `1000` IO per second from `/dev/sda`:\n\nThe `--device-write-iops` flag limits write rate (IO per second) to a device. For example, this command creates a container and limits the write rate to `1000` IO per second to `/dev/sda`:\n\nBoth flags take limits in the `<device-path>:<limit>` format. Both read and write rates must be a positive integer.\n\nBy default, the docker container process runs with the supplementary groups looked up for the specified user. If one wants to add more to that list of groups, then one can use this flag:\n\n| Option | Description |\n| --- | --- |\n| `--cap-add` | Add Linux capabilities |\n| `--cap-drop` | Drop Linux capabilities |\n| `--privileged` | Give extended privileges to this container |\n| `--device=[]` | Allows you to run devices inside the container without the `--privileged` flag. |\n\nBy default, Docker containers are \"unprivileged\" and cannot, for example, run a Docker daemon inside a Docker container. This is because by default a container is not allowed to access any devices, but a \"privileged\" container is given access to all devices (see the documentation on [cgroups devices](https://www.kernel.org/doc/Documentation/cgroup-v1/devices.txt)).\n\nThe `--privileged` flag gives all capabilities to the container. When the operator executes `docker run --privileged`, Docker enables access to all devices on the host, and reconfigures AppArmor or SELinux to allow the container nearly all the same access to the host as processes running outside containers on the host. Use this flag with caution. For more information about the `--privileged` flag, see the [`docker run` reference](https://docs.docker.com/reference/cli/docker/container/run/#privileged).\n\nIf you want to limit access to a specific device or devices you can use the `--device` flag. It allows you to specify one or more devices that will be accessible within the container.\n\nBy default, the container will be able to `read`, `write`, and `mknod` these devices. This can be overridden using a third `:rwm` set of options to each `--device` flag:\n\nIn addition to `--privileged`, the operator can have fine grain control over the capabilities using `--cap-add` and `--cap-drop`. By default, Docker has a default list of capabilities that are kept. The following table lists the Linux capability options which are allowed by default and can be dropped.\n\n| Capability Key | Capability Description |\n| --- | --- |\n| AUDIT\\_WRITE | Write records to kernel auditing log. |\n| CHOWN | Make arbitrary changes to file UIDs and GIDs (see chown(2)). |\n| DAC\\_OVERRIDE | Bypass file read, write, and execute permission checks. |\n| FOWNER | Bypass permission checks on operations that normally require the file system UID of the process to match the UID of the file. |\n| FSETID | Don't clear set-user-ID and set-group-ID permission bits when a file is modified. |\n| KILL | Bypass permission checks for sending signals. |\n| MKNOD | Create special files using mknod(2). |\n| NET\\_BIND\\_SERVICE | Bind a socket to internet domain privileged ports (port numbers less than 1024). |\n| NET\\_RAW | Use RAW and PACKET sockets. |\n| SETFCAP | Set file capabilities. |\n| SETGID | Make arbitrary manipulations of process GIDs and supplementary GID list. |\n| SETPCAP | Modify process capabilities. |\n| SETUID | Make arbitrary manipulations of process UIDs. |\n| SYS\\_CHROOT | Use chroot(2), change root directory. |\n\nThe next table shows the capabilities which are not granted by default and may be added.\n\n| Capability Key | Capability Description |\n| --- | --- |\n| AUDIT\\_CONTROL | Enable and disable kernel auditing; change auditing filter rules; retrieve auditing status and filtering rules. |\n| AUDIT\\_READ | Allow reading the audit log via multicast netlink socket. |\n| BLOCK\\_SUSPEND | Allow preventing system suspends. |\n| BPF | Allow creating BPF maps, loading BPF Type Format (BTF) data, retrieve JITed code of BPF programs, and more. |\n| CHECKPOINT\\_RESTORE | Allow checkpoint/restore related operations. Introduced in kernel 5.9. |\n| DAC\\_READ\\_SEARCH | Bypass file read permission checks and directory read and execute permission checks. |\n| IPC\\_LOCK | Lock memory (mlock(2), mlockall(2), mmap(2), shmctl(2)). |\n| IPC\\_OWNER | Bypass permission checks for operations on System V IPC objects. |\n| LEASE | Establish leases on arbitrary files (see fcntl(2)). |\n| LINUX\\_IMMUTABLE | Set the FS\\_APPEND\\_FL and FS\\_IMMUTABLE\\_FL i-node flags. |\n| MAC\\_ADMIN | Allow MAC configuration or state changes. Implemented for the Smack LSM. |\n| MAC\\_OVERRIDE | Override Mandatory Access Control (MAC). Implemented for the Smack Linux Security Module (LSM). |\n| NET\\_ADMIN | Perform various network-related operations. |\n| NET\\_BROADCAST | Make socket broadcasts, and listen to multicasts. |\n| PERFMON | Allow system performance and observability privileged operations using perf\\_events, i915\\_perf and other kernel subsystems |\n| SYS\\_ADMIN | Perform a range of system administration operations. |\n| SYS\\_BOOT | Use reboot(2) and kexec\\_load(2), reboot and load a new kernel for later execution. |\n| SYS\\_MODULE | Load and unload kernel modules. |\n| SYS\\_NICE | Raise process nice value (nice(2), setpriority(2)) and change the nice value for arbitrary processes. |\n| SYS\\_PACCT | Use acct(2), switch process accounting on or off. |\n| SYS\\_PTRACE | Trace arbitrary processes using ptrace(2). |\n| SYS\\_RAWIO | Perform I/O port operations (iopl(2) and ioperm(2)). |\n| SYS\\_RESOURCE | Override resource Limits. |\n| SYS\\_TIME | Set system clock (settimeofday(2), stime(2), adjtimex(2)); set real-time (hardware) clock. |\n| SYS\\_TTY\\_CONFIG | Use vhangup(2); employ various privileged ioctl(2) operations on virtual terminals. |\n| SYSLOG | Perform privileged syslog(2) operations. |\n| WAKE\\_ALARM | Trigger something that will wake up the system. |\n\nFurther reference information is available on the [capabilities(7) - Linux man page](https://man7.org/linux/man-pages/man7/capabilities.7.html), and in the [Linux kernel source code](https://github.com/torvalds/linux/blob/124ea650d3072b005457faed69909221c2905a1f/include/uapi/linux/capability.h).\n\nBoth flags support the value `ALL`, so to allow a container to use all capabilities except for `MKNOD`:\n\nThe `--cap-add` and `--cap-drop` flags accept capabilities to be specified with a `CAP_` prefix. The following examples are therefore equivalent:\n\nFor interacting with the network stack, instead of using `--privileged` they should use `--cap-add=NET_ADMIN` to modify the network interfaces.\n\nTo mount a FUSE based filesystem, you need to combine both `--cap-add` and `--device`:\n\nThe default seccomp profile will adjust to the selected capabilities, in order to allow use of facilities allowed by the capabilities, so you should not have to adjust this.\n\nWhen you build an image from a [Dockerfile](https://docs.docker.com/reference/dockerfile/), or when committing it, you can set a number of default parameters that take effect when the image starts up as a container. When you run an image, you can override those defaults using flags for the `docker run` command.\n\n*   [Default entrypoint](#default-entrypoint)\n*   [Default command and options](#default-command-and-options)\n*   [Expose ports](#exposed-ports)\n*   [Environment variables](#environment-variables)\n*   [Healthcheck](#healthchecks)\n*   [User](#user)\n*   [Working directory](#working-directory)\n\n### [Default command and options](#default-command-and-options)\n\nThe command syntax for `docker run` supports optionally specifying commands and arguments to the container's entrypoint, represented as `[COMMAND]` and `[ARG...]` in the following synopsis example:\n\nThis command is optional because whoever created the `IMAGE` may have already provided a default `COMMAND`, using the Dockerfile `CMD` instruction. When you run a container, you can override that `CMD` instruction just by specifying a new `COMMAND`.\n\nIf the image also specifies an `ENTRYPOINT` then the `CMD` or `COMMAND` get appended as arguments to the `ENTRYPOINT`.\n\n### [Default entrypoint](#default-entrypoint)\n\nThe entrypoint refers to the default executable that's invoked when you run a container. A container's entrypoint is defined using the Dockerfile `ENTRYPOINT` instruction. It's similar to specifying a default command because it specifies, but the difference is that you need to pass an explicit flag to override the entrypoint, whereas you can override default commands with positional arguments. The defines a container's default behavior, with the idea that when you set an entrypoint you can run the container _as if it were that binary_, complete with default options, and you can pass in more options as commands. But there are cases where you may want to run something else inside the container. This is when overriding the default entrypoint at runtime comes in handy, using the `--entrypoint` flag for the `docker run` command.\n\nThe `--entrypoint` flag expects a string value, representing the name or path of the binary that you want to invoke when the container starts. The following example shows you how to run a Bash shell in a container that has been set up to automatically run some other binary (like `/usr/bin/redis-server`):\n\nThe following examples show how to pass additional parameters to the custom entrypoint, using the positional command arguments:\n\nYou can reset a containers entrypoint by passing an empty string, for example:\n\n> **Note**\n> \n> Passing `--entrypoint` clears out any default command set on the image. That is, any `CMD` instruction in the Dockerfile used to build it.\n\n### [Exposed ports](#exposed-ports)\n\nBy default, when you run a container, none of the container's ports are exposed to the host. This means you won't be able to access any ports that the container might be listening on. To make a container's ports accessible from the host, you need to publish the ports.\n\nYou can start the container with the `-P` or `-p` flags to expose its ports:\n\n*   The `-P` (or `--publish-all`) flag publishes all the exposed ports to the host. Docker binds each exposed port to a random port on the host.\n    \n    The `-P` flag only publishes port numbers that are explicitly flagged as exposed, either using the Dockerfile `EXPOSE` instruction or the `--expose` flag for the `docker run` command.\n    \n*   The `-p` (or `--publish`) flag lets you explicitly map a single port or range of ports in the container to the host.\n    \n\nThe port number inside the container (where the service listens) doesn't need to match the port number published on the outside of the container (where clients connect). For example, inside the container an HTTP service might be listening on port 80. At runtime, the port might be bound to 42800 on the host. To find the mapping between the host ports and the exposed ports, use the `docker port` command.\n\n### [Environment variables](#environment-variables)\n\nDocker automatically sets some environment variables when creating a Linux container. Docker doesn't set any environment variables when creating a Windows container.\n\nThe following environment variables are set for Linux containers:\n\n| Variable | Value |\n| --- | --- |\n| `HOME` | Set based on the value of `USER` |\n| `HOSTNAME` | The hostname associated with the container |\n| `PATH` | Includes popular directories, such as `/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin` |\n| `TERM` | `xterm` if the container is allocated a pseudo-TTY |\n\nAdditionally, you can set any environment variable in the container by using one or more `-e` flags. You can even override the variables mentioned above, or variables defined using a Dockerfile `ENV` instruction when building the image.\n\nIf the you name an environment variable without specifying a value, the current value of the named variable on the host is propagated into the container's environment:\n\n### [Healthchecks](#healthchecks)\n\nThe following flags for the `docker run` command let you control the parameters for container healthchecks:\n\n| Option | Description |\n| --- | --- |\n| `--health-cmd` | Command to run to check health |\n| `--health-interval` | Time between running the check |\n| `--health-retries` | Consecutive failures needed to report unhealthy |\n| `--health-timeout` | Maximum time to allow one check to run |\n| `--health-start-period` | Start period for the container to initialize before starting health-retries countdown |\n| `--health-start-interval` | Time between running the check during the start period |\n| `--no-healthcheck` | Disable any container-specified `HEALTHCHECK` |\n\nExample:\n\nThe health status is also displayed in the `docker ps` output.\n\n### [User](#user)\n\nThe default user within a container is `root` (uid = 0). You can set a default user to run the first process with the Dockerfile `USER` instruction. When starting a container, you can override the `USER` instruction by passing the `-u` option.\n\nThe followings examples are all valid:\n\n> **Note**\n> \n> If you pass a numeric user ID, it must be in the range of 0-2147483647. If you pass a username, the user must exist in the container.\n\n### [Working directory](#working-directory)\n\nThe default working directory for running binaries within a container is the root directory (`/`). The default working directory of an image is set using the Dockerfile `WORKDIR` command. You can override the default working directory for an image using the `-w` (or `--workdir`) flag for the `docker run` command:\n\nIf the directory doesn't already exist in the container, it's created.",
    "title": "Running containers | Docker Docs\n",
    "description": "Running and configuring containers with the Docker CLI",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/security/trust/trust_key_mng/",
    "markdown": "# Manage keys for content trust\n\nTrust for an image tag is managed through the use of keys. Docker's content trust makes use of five different types of keys:\n\n| Key | Description |\n| --- | --- |\n| root key | Root of content trust for an image tag. When content trust is enabled, you create the root key once. Also known as the offline key, because it should be kept offline. |\n| targets | This key allows you to sign image tags, to manage delegations including delegated keys or permitted delegation paths. Also known as the repository key, since this key determines what tags can be signed into an image repository. |\n| snapshot | This key signs the current collection of image tags, preventing mix and match attacks. |\n| timestamp | This key allows Docker image repositories to have freshness security guarantees without requiring periodic content refreshes on the client's side. |\n| delegation | Delegation keys are optional tagging keys and allow you to delegate signing image tags to other publishers without having to share your targets key. |\n\nWhen doing a `docker push` with Content Trust enabled for the first time, the root, targets, snapshot, and timestamp keys are generated automatically for the image repository:\n\n*   The root and targets key are generated and stored locally client-side.\n    \n*   The timestamp and snapshot keys are safely generated and stored in a signing server that is deployed alongside the Docker registry. These keys are generated in a backend service that isn't directly exposed to the internet and are encrypted at rest. Use the Notary CLI to [manage your snapshot key locally](https://github.com/theupdateframework/notary/blob/master/docs/advanced_usage.md#rotate-keys).\n    \n\nDelegation keys are optional, and not generated as part of the normal `docker` workflow. They need to be [manually generated and added to the repository](https://docs.docker.com/engine/security/trust/trust_delegation/#creating-delegation-keys).\n\nThe passphrases you chose for both the root key and your repository key should be randomly generated and stored in a password manager. Having the repository key allows users to sign image tags on a repository. Passphrases are used to encrypt your keys at rest and ensure that a lost laptop or an unintended backup doesn't put the private key material at risk.\n\nAll the Docker trust keys are stored encrypted using the passphrase you provide on creation. Even so, you should still take care of the location where you back them up. Good practice is to create two encrypted USB keys.\n\n> **Warning**\n> \n> It is very important that you back up your keys to a safe, secure location. The loss of the repository key is recoverable, but the loss of the root key is not.\n\nThe Docker client stores the keys in the `~/.docker/trust/private` directory. Before backing them up, you should `tar` them into an archive:\n\nDocker Content Trust can store and sign with root keys from a Yubikey 4. The Yubikey is prioritized over keys stored in the filesystem. When you initialize a new repository with content trust, Docker Engine looks for a root key locally. If a key is not found and the Yubikey 4 exists, Docker Engine creates a root key in the Yubikey 4. Consult the [Notary documentation](https://github.com/theupdateframework/notary/blob/master/docs/advanced_usage.md#use-a-yubikey) for more details.\n\nPrior to Docker Engine 1.11, this feature was only in the experimental branch.\n\n> **Warning**\n> \n> If a publisher loses keys it means losing the ability to sign images for the repositories in question. If you lose a key, send an email to Docker Hub Support. As a reminder, the loss of a root key is not recoverable.\n\nThis loss also requires manual intervention from every consumer that used a signed tag from this repository prior to the loss.  \nImage consumers get the following error for content previously downloaded from the affected repo(s):\n\nTo correct this, they need to download a new image tag that is signed with the new key.\n\n*   [Content trust in Docker](https://docs.docker.com/engine/security/trust/)\n*   [Automation with content trust](https://docs.docker.com/engine/security/trust/trust_automation/)\n*   [Delegations for content trust](https://docs.docker.com/engine/security/trust/trust_delegation/)\n*   [Play in a content trust sandbox](https://docs.docker.com/engine/security/trust/trust_sandbox/)",
    "title": "Manage keys for content trust | Docker Docs\n",
    "description": "Manage keys for content trust",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/security/trust/trust_sandbox/",
    "markdown": "# Play in a content trust sandbox\n\nThis page explains how to set up and use a sandbox for experimenting with trust. The sandbox allows you to configure and try trust operations locally without impacting your production images.\n\nBefore working through this sandbox, you should have read through the [trust overview](https://docs.docker.com/engine/security/trust/).\n\nThese instructions assume you are running in Linux or macOS. You can run this sandbox on a local machine or on a virtual machine. You need to have privileges to run docker commands on your local machine or in the VM.\n\nThis sandbox requires you to install two Docker tools: Docker Engine >= 1.10.0 and Docker Compose >= 1.6.0. To install the Docker Engine, choose from the [list of supported platforms](https://docs.docker.com/engine/install/). To install Docker Compose, see the [detailed instructions here](https://docs.docker.com/compose/install/).\n\nIf you are just using trust out-of-the-box you only need your Docker Engine client and access to the Docker Hub. The sandbox mimics a production trust environment, and sets up these additional components.\n\n| Container | Description |\n| --- | --- |\n| trustsandbox | A container with the latest version of Docker Engine and with some preconfigured certificates. This is your sandbox where you can use the `docker` client to test trust operations. |\n| Registry server | A local registry service. |\n| Notary server | The service that does all the heavy-lifting of managing trust |\n\nThis means you run your own content trust (Notary) server and registry. If you work exclusively with the Docker Hub, you would not need these components. They are built into the Docker Hub for you. For the sandbox, however, you build your own entire, mock production environment.\n\nWithin the `trustsandbox` container, you interact with your local registry rather than the Docker Hub. This means your everyday image repositories are not used. They are protected while you play.\n\nWhen you play in the sandbox, you also create root and repository keys. The sandbox is configured to store all the keys and files inside the `trustsandbox` container. Since the keys you create in the sandbox are for play only, destroying the container destroys them as well.\n\nBy using a docker-in-docker image for the `trustsandbox` container, you also don't pollute your real Docker daemon cache with any images you push and pull. The images are stored in an anonymous volume attached to this container, and can be destroyed after you destroy the container.\n\nIn this section, you use Docker Compose to specify how to set up and link together the `trustsandbox` container, the Notary server, and the Registry server.\n\n1.  Create a new `trustsandbox` directory and change into it.\n    \n    ```\n     $ mkdir trustsandbox\n     $ cd trustsandbox\n    ```\n    \n2.  Create a file called `compose.yml` with your favorite editor. For example, using vim:\n    \n    ```\n     $ touch compose.yml\n     $ vim compose.yml\n    ```\n    \n3.  Add the following to the new file.\n    \n    ```\n     version: \"2\"\n     services:\n       notaryserver:\n         image: dockersecurity/notary_autobuilds:server-v0.5.1\n         volumes:\n           - notarycerts:/var/lib/notary/fixtures\n         networks:\n           - sandbox\n         environment:\n           - NOTARY_SERVER_STORAGE_TYPE=memory\n           - NOTARY_SERVER_TRUST_SERVICE_TYPE=local\n       sandboxregistry:\n         image: registry:2.4.1\n         networks:\n           - sandbox\n         container_name: sandboxregistry\n       trustsandbox:\n         image: docker:dind\n         networks:\n           - sandbox\n         volumes:\n           - notarycerts:/notarycerts\n         privileged: true\n         container_name: trustsandbox\n         entrypoint: \"\"\n         command: |-\n             sh -c '\n                 cp /notarycerts/root-ca.crt /usr/local/share/ca-certificates/root-ca.crt &&\n                 update-ca-certificates &&\n                 dockerd-entrypoint.sh --insecure-registry sandboxregistry:5000'\n     volumes:\n       notarycerts:\n         external: false\n     networks:\n       sandbox:\n         external: false\n    ```\n    \n4.  Save and close the file.\n    \n5.  Run the containers on your local system.\n    \n    ```\n     $ docker compose up -d\n    ```\n    \n    The first time you run this, the docker-in-docker, Notary server, and registry images are downloaded from Docker Hub.\n    \n\nNow that everything is setup, you can go into your `trustsandbox` container and start testing Docker content trust. From your host machine, obtain a shell in the `trustsandbox` container.\n\n```\n$ docker container exec -it trustsandbox sh\n/ #\n```\n\n### [Test some trust operations](#test-some-trust-operations)\n\nNow, pull some images from within the `trustsandbox` container.\n\n1.  Download a `docker` image to test with.\n    \n    ```\n     / # docker pull docker/trusttest\n     docker pull docker/trusttest\n     Using default tag: latest\n     latest: Pulling from docker/trusttest\n    \n     b3dbab3810fc: Pull complete\n     a9539b34a6ab: Pull complete\n     Digest: sha256:d149ab53f8718e987c3a3024bb8aa0e2caadf6c0328f1d9d850b2a2a67f2819a\n     Status: Downloaded newer image for docker/trusttest:latest\n    ```\n    \n2.  Tag it to be pushed to our sandbox registry:\n    \n    ```\n     / # docker tag docker/trusttest sandboxregistry:5000/test/trusttest:latest\n    ```\n    \n3.  Enable content trust.\n    \n    ```\n     / # export DOCKER_CONTENT_TRUST=1\n    ```\n    \n4.  Identify the trust server.\n    \n    ```\n     / # export DOCKER_CONTENT_TRUST_SERVER=https://notaryserver:4443\n    ```\n    \n    This step is only necessary because the sandbox is using its own server. Normally, if you are using the Docker Public Hub this step isn't necessary.\n    \n5.  Pull the test image.\n    \n    ```\n     / # docker pull sandboxregistry:5000/test/trusttest\n     Using default tag: latest\n     Error: remote trust data does not exist for sandboxregistry:5000/test/trusttest: notaryserver:4443 does not have trust data for sandboxregistry:5000/test/trusttest\n    ```\n    \n    You see an error, because this content doesn't exist on the `notaryserver` yet.\n    \n6.  Push and sign the trusted image.\n    \n    ```\n     / # docker push sandboxregistry:5000/test/trusttest:latest\n     The push refers to a repository [sandboxregistry:5000/test/trusttest]\n     5f70bf18a086: Pushed\n     c22f7bc058a9: Pushed\n     latest: digest: sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926 size: 734\n     Signing and pushing trust metadata\n     You are about to create a new root signing key passphrase. This passphrase\n     will be used to protect the most sensitive key in your signing system. Please\n     choose a long, complex passphrase and be careful to keep the password and the\n     key file itself secure and backed up. It is highly recommended that you use a\n     password manager to generate the passphrase and keep it safe. There will be no\n     way to recover this key. You can find the key in your config directory.\n     Enter passphrase for new root key with ID 27ec255:\n     Repeat passphrase for new root key with ID 27ec255:\n     Enter passphrase for new repository key with ID 58233f9 (sandboxregistry:5000/test/trusttest):\n     Repeat passphrase for new repository key with ID 58233f9 (sandboxregistry:5000/test/trusttest):\n     Finished initializing \"sandboxregistry:5000/test/trusttest\"\n     Successfully signed \"sandboxregistry:5000/test/trusttest\":latest\n    ```\n    \n    Because you are pushing this repository for the first time, Docker creates new root and repository keys and asks you for passphrases with which to encrypt them. If you push again after this, it only asks you for repository passphrase so it can decrypt the key and sign again.\n    \n7.  Try pulling the image you just pushed:\n    \n    ```\n     / # docker pull sandboxregistry:5000/test/trusttest\n     Using default tag: latest\n     Pull (1 of 1): sandboxregistry:5000/test/trusttest:latest@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926\n     sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926: Pulling from test/trusttest\n     Digest: sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926\n     Status: Downloaded newer image for sandboxregistry:5000/test/trusttest@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926\n     Tagging sandboxregistry:5000/test/trusttest@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926 as sandboxregistry:5000/test/trusttest:latest\n    ```\n    \n\n### [Test with malicious images](#test-with-malicious-images)\n\nWhat happens when data is corrupted and you try to pull it when trust is enabled? In this section, you go into the `sandboxregistry` and tamper with some data. Then, you try and pull it.\n\n1.  Leave the `trustsandbox` shell and container running.\n    \n2.  Open a new interactive terminal from your host, and obtain a shell into the `sandboxregistry` container.\n    \n    ```\n    $ docker container exec -it sandboxregistry bash\n    root@65084fc6f047:/#\n    ```\n    \n3.  List the layers for the `test/trusttest` image you pushed:\n    \n4.  Change into the registry storage for one of those layers (this is in a different directory):\n    \n    ```\n    root@65084fc6f047:/# cd /var/lib/registry/docker/registry/v2/blobs/sha256/aa/aac0c133338db2b18ff054943cee3267fe50c75cdee969aed88b1992539ed042\n    ```\n    \n5.  Add malicious data to one of the `trusttest` layers:\n    \n    ```\n    root@65084fc6f047:/# echo \"Malicious data\" > data\n    ```\n    \n6.  Go back to your `trustsandbox` terminal.\n    \n7.  List the `trusttest` image.\n    \n    ```\n    / # docker image ls | grep trusttest\n    REPOSITORY                            TAG                 IMAGE ID            CREATED             SIZE\n    docker/trusttest                      latest              cc7629d1331a        11 months ago       5.025 MB\n    sandboxregistry:5000/test/trusttest   latest              cc7629d1331a        11 months ago       5.025 MB\n    sandboxregistry:5000/test/trusttest   <none>              cc7629d1331a        11 months ago       5.025 MB\n    ```\n    \n8.  Remove the `trusttest:latest` image from our local cache.\n    \n    ```\n    / # docker image rm -f cc7629d1331a\n    Untagged: docker/trusttest:latest\n    Untagged: sandboxregistry:5000/test/trusttest:latest\n    Untagged: sandboxregistry:5000/test/trusttest@sha256:ebf59c538accdf160ef435f1a19938ab8c0d6bd96aef8d4ddd1b379edf15a926\n    Deleted: sha256:cc7629d1331a7362b5e5126beb5bf15ca0bf67eb41eab994c719a45de53255cd\n    Deleted: sha256:2a1f6535dc6816ffadcdbe20590045e6cbf048d63fd4cc753a684c9bc01abeea\n    Deleted: sha256:c22f7bc058a9a8ffeb32989b5d3338787e73855bf224af7aa162823da015d44c\n    ```\n    \n    Docker does not re-download images that it already has cached, but we want Docker to attempt to download the tampered image from the registry and reject it because it is invalid.\n    \n9.  Pull the image again. This downloads the image from the registry, because we don't have it cached.\n    \n    ```\n    / # docker pull sandboxregistry:5000/test/trusttest\n    Using default tag: latest\n    Pull (1 of 1): sandboxregistry:5000/test/trusttest:latest@sha256:35d5bc26fd358da8320c137784fe590d8fcf9417263ef261653e8e1c7f15672e\n    sha256:35d5bc26fd358da8320c137784fe590d8fcf9417263ef261653e8e1c7f15672e: Pulling from test/trusttest\n    \n    aac0c133338d: Retrying in 5 seconds\n    a3ed95caeb02: Download complete\n    error pulling image configuration: unexpected EOF\n    ```\n    \n    The pull did not complete because the trust system couldn't verify the image.\n    \n\nNow, you have a full Docker content trust sandbox on your local system, feel free to play with it and see how it behaves. If you find any security issues with Docker, feel free to send us an email at security@docker.com.\n\nWhen you are done, and want to clean up all the services you've started and any anonymous volumes that have been created, just run the following command in the directory where you've created your Docker Compose file:\n\n```\n    $ docker compose down -v\n```",
    "title": "Play in a content trust sandbox | Docker Docs\n",
    "description": "Play in a trust sandbox",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/admin_guide/",
    "markdown": "# Administer and maintain a swarm of Docker Engines\n\nWhen you run a swarm of Docker Engines, manager nodes are the key components for managing the swarm and storing the swarm state. It is important to understand some key features of manager nodes to properly deploy and maintain the swarm.\n\nRefer to [How nodes work](https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/) for a brief overview of Docker Swarm mode and the difference between manager and worker nodes.\n\nSwarm manager nodes use the [Raft Consensus Algorithm](https://docs.docker.com/engine/swarm/raft/) to manage the swarm state. You only need to understand some general concepts of Raft in order to manage a swarm.\n\nThere is no limit on the number of manager nodes. The decision about how many manager nodes to implement is a trade-off between performance and fault-tolerance. Adding manager nodes to a swarm makes the swarm more fault-tolerant. However, additional manager nodes reduce write performance because more nodes must acknowledge proposals to update the swarm state. This means more network round-trip traffic.\n\nRaft requires a majority of managers, also called the quorum, to agree on proposed updates to the swarm, such as node additions or removals. Membership operations are subject to the same constraints as state replication.\n\n### [Maintain the quorum of managers](#maintain-the-quorum-of-managers)\n\nIf the swarm loses the quorum of managers, the swarm cannot perform management tasks. If your swarm has multiple managers, always have more than two. To maintain quorum, a majority of managers must be available. An odd number of managers is recommended, because the next even number does not make the quorum easier to keep. For instance, whether you have 3 or 4 managers, you can still only lose 1 manager and maintain the quorum. If you have 5 or 6 managers, you can still only lose two.\n\nEven if a swarm loses the quorum of managers, swarm tasks on existing worker nodes continue to run. However, swarm nodes cannot be added, updated, or removed, and new or existing tasks cannot be started, stopped, moved, or updated.\n\nSee [Recovering from losing the quorum](#recover-from-losing-the-quorum) for troubleshooting steps if you do lose the quorum of managers.\n\nWhen initiating a swarm, you must specify the `--advertise-addr` flag to advertise your address to other manager nodes in the swarm. For more information, see [Run Docker Engine in swarm mode](https://docs.docker.com/engine/swarm/swarm-mode/#configure-the-advertise-address). Because manager nodes are meant to be a stable component of the infrastructure, you should use a _fixed IP address_ for the advertise address to prevent the swarm from becoming unstable on machine reboot.\n\nIf the whole swarm restarts and every manager node subsequently gets a new IP address, there is no way for any node to contact an existing manager. Therefore the swarm is hung while nodes try to contact one another at their old IP addresses.\n\nDynamic IP addresses are OK for worker nodes.\n\nYou should maintain an odd number of managers in the swarm to support manager node failures. Having an odd number of managers ensures that during a network partition, there is a higher chance that the quorum remains available to process requests if the network is partitioned into two sets. Keeping the quorum is not guaranteed if you encounter more than two network partitions.\n\n| Swarm Size | Majority | Fault Tolerance |\n| --- | --- | --- |\n| 1   | 1   | 0   |\n| 2   | 2   | 0   |\n| **3** | 2   | **1** |\n| 4   | 3   | 1   |\n| **5** | 3   | **2** |\n| 6   | 4   | 2   |\n| **7** | 4   | **3** |\n| 8   | 5   | 3   |\n| **9** | 5   | **4** |\n\nFor example, in a swarm with _5 nodes_, if you lose _3 nodes_, you don't have a quorum. Therefore you can't add or remove nodes until you recover one of the unavailable manager nodes or recover the swarm with disaster recovery commands. See [Recover from disaster](#recover-from-disaster).\n\nWhile it is possible to scale a swarm down to a single manager node, it is impossible to demote the last manager node. This ensures you maintain access to the swarm and that the swarm can still process requests. Scaling down to a single manager is an unsafe operation and is not recommended. If the last node leaves the swarm unexpectedly during the demote operation, the swarm becomes unavailable until you reboot the node or restart with `--force-new-cluster`.\n\nYou manage swarm membership with the `docker swarm` and `docker node` subsystems. Refer to [Add nodes to a swarm](https://docs.docker.com/engine/swarm/join-nodes/) for more information on how to add worker nodes and promote a worker node to be a manager.\n\n### [Distribute manager nodes](#distribute-manager-nodes)\n\nIn addition to maintaining an odd number of manager nodes, pay attention to datacenter topology when placing managers. For optimal fault-tolerance, distribute manager nodes across a minimum of 3 availability-zones to support failures of an entire set of machines or common maintenance scenarios. If you suffer a failure in any of those zones, the swarm should maintain the quorum of manager nodes available to process requests and rebalance workloads.\n\n| Swarm manager nodes | Repartition (on 3 Availability zones) |\n| --- | --- |\n| 3   | 1-1-1 |\n| 5   | 2-2-1 |\n| 7   | 3-2-2 |\n| 9   | 3-3-3 |\n\n### [Run manager-only nodes](#run-manager-only-nodes)\n\nBy default manager nodes also act as a worker nodes. This means the scheduler can assign tasks to a manager node. For small and non-critical swarms assigning tasks to managers is relatively low-risk as long as you schedule services using resource constraints for cpu and memory.\n\nHowever, because manager nodes use the Raft consensus algorithm to replicate data in a consistent way, they are sensitive to resource starvation. You should isolate managers in your swarm from processes that might block swarm operations like swarm heartbeat or leader elections.\n\nTo avoid interference with manager node operation, you can drain manager nodes to make them unavailable as worker nodes:\n\nWhen you drain a node, the scheduler reassigns any tasks running on the node to other available worker nodes in the swarm. It also prevents the scheduler from assigning tasks to the node.\n\n[Add nodes to the swarm](https://docs.docker.com/engine/swarm/join-nodes/) to balance your swarm's load. Replicated service tasks are distributed across the swarm as evenly as possible over time, as long as the worker nodes are matched to the requirements of the services. When limiting a service to run on only specific types of nodes, such as nodes with a specific number of CPUs or amount of memory, remember that worker nodes that do not meet these requirements cannot run these tasks.\n\nYou can monitor the health of manager nodes by querying the docker `nodes` API in JSON format through the `/nodes` HTTP endpoint. Refer to the [nodes API documentation](https://docs.docker.com/engine/api/v1.25/#tag/Node) for more information.\n\nFrom the command line, run `docker node inspect <id-node>` to query the nodes. For instance, to query the reachability of the node as a manager:\n\nTo query the status of the node as a worker that accept tasks:\n\nFrom those commands, we can see that `manager1` is both at the status `reachable` as a manager and `ready` as a worker.\n\nAn `unreachable` health status means that this particular manager node is unreachable from other manager nodes. In this case you need to take action to restore the unreachable manager:\n\n*   Restart the daemon and see if the manager comes back as reachable.\n*   Reboot the machine.\n*   If neither restarting nor rebooting works, you should add another manager node or promote a worker to be a manager node. You also need to cleanly remove the failed node entry from the manager set with `docker node demote <NODE>` and `docker node rm <id-node>`.\n\nAlternatively you can also get an overview of the swarm health from a manager node with `docker node ls`:\n\nYou should never restart a manager node by copying the `raft` directory from another node. The data directory is unique to a node ID. A node can only use a node ID once to join the swarm. The node ID space should be globally unique.\n\nTo cleanly re-join a manager node to a cluster:\n\n1.  Demote the node to a worker using `docker node demote <NODE>`.\n2.  Remove the node from the swarm using `docker node rm <NODE>`.\n3.  Re-join the node to the swarm with a fresh state using `docker swarm join`.\n\nFor more information on joining a manager node to a swarm, refer to [Join nodes to a swarm](https://docs.docker.com/engine/swarm/join-nodes/).\n\nIn most cases, you should shut down a node before removing it from a swarm with the `docker node rm` command. If a node becomes unreachable, unresponsive, or compromised you can forcefully remove the node without shutting it down by passing the `--force` flag. For instance, if `node9` becomes compromised:\n\nBefore you forcefully remove a manager node, you must first demote it to the worker role. Make sure that you always have an odd number of manager nodes if you demote or remove a manager.\n\nDocker manager nodes store the swarm state and manager logs in the `/var/lib/docker/swarm/` directory. This data includes the keys used to encrypt the Raft logs. Without these keys, you cannot restore the swarm.\n\nYou can back up the swarm using any manager. Use the following procedure.\n\n1.  If the swarm has auto-lock enabled, you need the unlock key to restore the swarm from backup. Retrieve the unlock key if necessary and store it in a safe location. If you are unsure, read [Lock your swarm to protect its encryption key](https://docs.docker.com/engine/swarm/swarm_manager_locking/).\n    \n2.  Stop Docker on the manager before backing up the data, so that no data is being changed during the backup. It is possible to take a backup while the manager is running (a \"hot\" backup), but this is not recommended and your results are less predictable when restoring. While the manager is down, other nodes continue generating swarm data that is not part of this backup.\n    \n    > **Note**\n    > \n    > Be sure to maintain the quorum of swarm managers. During the time that a manager is shut down, your swarm is more vulnerable to losing the quorum if further nodes are lost. The number of managers you run is a trade-off. If you regularly take down managers to do backups, consider running a five manager swarm, so that you can lose an additional manager while the backup is running, without disrupting your services.\n    \n3.  Back up the entire `/var/lib/docker/swarm` directory.\n    \n4.  Restart the manager.\n    \n\nTo restore, see [Restore from a backup](#restore-from-a-backup).\n\n### [Restore from a backup](#restore-from-a-backup)\n\nAfter backing up the swarm as described in [Back up the swarm](#back-up-the-swarm), use the following procedure to restore the data to a new swarm.\n\n1.  Shut down Docker on the target host machine for the restored swarm.\n    \n2.  Remove the contents of the `/var/lib/docker/swarm` directory on the new swarm.\n    \n3.  Restore the `/var/lib/docker/swarm` directory with the contents of the backup.\n    \n    > **Note**\n    > \n    > The new node uses the same encryption key for on-disk storage as the old one. It is not possible to change the on-disk storage encryption keys at this time.\n    > \n    > In the case of a swarm with auto-lock enabled, the unlock key is also the same as on the old swarm, and the unlock key is needed to restore the swarm.\n    \n4.  Start Docker on the new node. Unlock the swarm if necessary. Re-initialize the swarm using the following command, so that this node does not attempt to connect to nodes that were part of the old swarm, and presumably no longer exist.\n    \n5.  Verify that the state of the swarm is as expected. This may include application-specific tests or simply checking the output of `docker service ls` to be sure that all expected services are present.\n    \n6.  If you use auto-lock, [rotate the unlock key](https://docs.docker.com/engine/swarm/swarm_manager_locking/#rotate-the-unlock-key).\n    \n7.  Add manager and worker nodes to bring your new swarm up to operating capacity.\n    \n8.  Reinstate your previous backup regimen on the new swarm.\n    \n\n### [Recover from losing the quorum](#recover-from-losing-the-quorum)\n\nSwarm is resilient to failures and can recover from any number of temporary node failures (machine reboots or crash with restart) or other transient errors. However, a swarm cannot automatically recover if it loses a quorum. Tasks on existing worker nodes continue to run, but administrative tasks are not possible, including scaling or updating services and joining or removing nodes from the swarm. The best way to recover is to bring the missing manager nodes back online. If that is not possible, continue reading for some options for recovering your swarm.\n\nIn a swarm of `N` managers, a quorum (a majority) of manager nodes must always be available. For example, in a swarm with five managers, a minimum of three must be operational and in communication with each other. In other words, the swarm can tolerate up to `(N-1)/2` permanent failures beyond which requests involving swarm management cannot be processed. These types of failures include data corruption or hardware failures.\n\nIf you lose the quorum of managers, you cannot administer the swarm. If you have lost the quorum and you attempt to perform any management operation on the swarm, an error occurs:\n\nThe best way to recover from losing the quorum is to bring the failed nodes back online. If you can't do that, the only way to recover from this state is to use the `--force-new-cluster` action from a manager node. This removes all managers except the manager the command was run from. The quorum is achieved because there is now only one manager. Promote nodes to be managers until you have the desired number of managers.\n\nFrom the node to recover, run:\n\nWhen you run the `docker swarm init` command with the `--force-new-cluster` flag, the Docker Engine where you run the command becomes the manager node of a single-node swarm which is capable of managing and running services. The manager has all the previous information about services and tasks, worker nodes are still part of the swarm, and services are still running. You need to add or re-add manager nodes to achieve your previous task distribution and ensure that you have enough managers to maintain high availability and prevent losing the quorum.\n\nGenerally, you do not need to force the swarm to rebalance its tasks. When you add a new node to a swarm, or a node reconnects to the swarm after a period of unavailability, the swarm does not automatically give a workload to the idle node. This is a design decision. If the swarm periodically shifted tasks to different nodes for the sake of balance, the clients using those tasks would be disrupted. The goal is to avoid disrupting running services for the sake of balance across the swarm. When new tasks start, or when a node with running tasks becomes unavailable, those tasks are given to less busy nodes. The goal is eventual balance, with minimal disruption to the end user.\n\nYou can use the `--force` or `-f` flag with the `docker service update` command to force the service to redistribute its tasks across the available worker nodes. This causes the service tasks to restart. Client applications may be disrupted. If you have configured it, your service uses a [rolling update](https://docs.docker.com/engine/swarm/swarm-tutorial/rolling-update/).\n\nIf you use an earlier version and you want to achieve an even balance of load across workers and don't mind disrupting running tasks, you can force your swarm to re-balance by temporarily scaling the service upward. Use `docker service inspect --pretty <servicename>` to see the configured scale of a service. When you use `docker service scale`, the nodes with the lowest number of tasks are targeted to receive the new workloads. There may be multiple under-loaded nodes in your swarm. You may need to scale the service up by modest increments a few times to achieve the balance you want across all the nodes.\n\nWhen the load is balanced to your satisfaction, you can scale the service back down to the original scale. You can use `docker service ps` to assess the current balance of your service across nodes.\n\nSee also [`docker service scale`](https://docs.docker.com/reference/cli/docker/service/scale/) and [`docker service ps`](https://docs.docker.com/reference/cli/docker/service/ps/).",
    "title": "Administer and maintain a swarm of Docker Engines | Docker Docs\n",
    "description": "Manager administration guide",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/security/antivirus/",
    "markdown": "# Antivirus software and Docker | Docker Docs\n\nWhen antivirus software scans files used by Docker, these files may be locked in a way that causes Docker commands to hang.\n\nOne way to reduce these problems is to add the Docker data directory (`/var/lib/docker` on Linux, `%ProgramData%\\docker` on Windows Server, or `$HOME/Library/Containers/com.docker.docker/` on Mac) to the antivirus's exclusion list. However, this comes with the trade-off that viruses or malware in Docker images, writable layers of containers, or volumes are not detected. If you do choose to exclude Docker's data directory from background virus scanning, you may want to schedule a recurring task that stops Docker, scans the data directory, and restarts Docker.",
    "title": "Antivirus software and Docker | Docker Docs\n",
    "description": "General guidelines for using antivirus software with Docker",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/building/base-images/",
    "markdown": "# Base images | Docker Docs\n\nAll Dockerfiles start from a base image. A base is the image that your image extends. It refers to the contents of the `FROM` instruction in the Dockerfile.\n\nFor most cases, you don't need to create your own base image. Docker Hub contains a vast library of Docker images that are suitable for use as a base image in your build. [Docker Official Images](https://docs.docker.com/trusted-content/official-images/) are specifically designed as a set of hardened, battle-tested images that supports a wide variety of platforms, languages, and frameworks. There are also [Docker Verified Publisher](https://hub.docker.com/search?q=&image_filter=store) images, created by trusted publishing partners, verified by Docker.\n\nIf you need to completely control the contents of your image, you can create your own base image from a Linux distribution of your choosing, or use the special `FROM scratch` base:\n\nThe `scratch` image is typically used to create minimal images containing only just what an application needs. See [Create a minimal base image using scratch](#create-a-minimal-base-image-using-scratch).\n\nTo create a distribution base image, you can use a root filesystem, packaged as a `tar` file, and import it to Docker with `docker import`. The process for creating your own base image depends on the Linux distribution you want to package. See [Create a full image using tar](#create-a-full-image-using-tar).\n\nThe reserved, minimal `scratch` image serves as a starting point for building containers. Using the `scratch` image signals to the build process that you want the next command in the `Dockerfile` to be the first filesystem layer in your image.\n\nWhile `scratch` appears in Docker's [repository on Docker Hub](https://hub.docker.com/_/scratch), you can't pull it, run it, or tag any image with the name `scratch`. Instead, you can refer to it in your `Dockerfile`. For example, to create a minimal container using `scratch`:\n\nAssuming an executable binary named `hello` exists at the root of the [build context](https://docs.docker.com/build/building/context/). You can build this Docker image using the following `docker build` command:\n\nTo run your new image, use the `docker run` command:\n\nThis example image can only successfully execute as long as the `hello` binary doesn't have any runtime dependencies. Computer programs tend to depend on certain other programs or resources to exist in the runtime environment. For example:\n\n*   Programming language runtimes\n*   Dynamically linked C libraries\n*   CA certificates\n\nWhen building a base image, or any image, this is an important aspect to consider. And this is why creating a base image using `FROM scratch` can be difficult, for anything other than small, simple programs. On the other hand, it's also important to include only the things you need in your image, to reduce the image size and attack surface.\n\nIn general, start with a working machine that is running the distribution you'd like to package as a base image, though that is not required for some tools like Debian's [Debootstrap](https://wiki.debian.org/Debootstrap), which you can also use to build Ubuntu images.\n\nFor example, to create an Ubuntu base image:\n\nThere are more example scripts for creating base images in [the Moby GitHub repository](https://github.com/moby/moby/blob/master/contrib).\n\nFor more information about building images and writing Dockerfiles, see:\n\n*   [Dockerfile reference](https://docs.docker.com/reference/dockerfile/)\n*   [Dockerfile best practices](https://docs.docker.com/build/building/best-practices/)\n*   [Docker Official Images](https://docs.docker.com/trusted-content/official-images/)",
    "title": "Base images | Docker Docs\n",
    "description": "Learn about base images and how they're created",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/reference/commandline/cli/",
    "markdown": "# Use the Docker command line\n\nThe base command for the Docker CLI is `docker`. For information about the available flags and subcommands, refer to the [CLI reference](https://docs.docker.com/reference/cli/docker/)\n\nDepending on your Docker system configuration, you may be required to preface each `docker` command with `sudo`. To avoid having to use `sudo` with the `docker` command, your system administrator can create a Unix group called `docker` and add users to it.\n\nFor more information about installing Docker or `sudo` configuration, refer to the [installation](https://docs.docker.com/install/) instructions for your operating system.\n\nThe following list of environment variables are supported by the `docker` command line:\n\n| Variable | Description |\n| --- | --- |\n| `DOCKER_API_VERSION` | Override the negotiated API version to use for debugging (e.g. `1.19`) |\n| `DOCKER_CERT_PATH` | Location of your authentication keys. This variable is used both by the `docker` CLI and the [`dockerd` daemon](https://docs.docker.com/reference/cli/dockerd/) |\n| `DOCKER_CONFIG` | The location of your client configuration files. |\n| `DOCKER_CONTENT_TRUST_SERVER` | The URL of the Notary server to use. Defaults to the same URL as the registry. |\n| `DOCKER_CONTENT_TRUST` | When set Docker uses notary to sign and verify images. Equates to `--disable-content-trust=false` for build, create, pull, push, run. |\n| `DOCKER_CONTEXT` | Name of the `docker context` to use (overrides `DOCKER_HOST` env var and default context set with `docker context use`) |\n| `DOCKER_DEFAULT_PLATFORM` | Default platform for commands that take the `--platform` flag. |\n| `DOCKER_HIDE_LEGACY_COMMANDS` | When set, Docker hides \"legacy\" top-level commands (such as `docker rm`, and `docker pull`) in `docker help` output, and only `Management commands` per object-type (e.g., `docker container`) are printed. This may become the default in a future release. |\n| `DOCKER_HOST` | Daemon socket to connect to. |\n| `DOCKER_TLS` | Enable TLS for connections made by the `docker` CLI (equivalent of the `--tls` command-line option). Set to a non-empty value to enable TLS. Note that TLS is enabled automatically if any of the other TLS options are set. |\n| `DOCKER_TLS_VERIFY` | When set Docker uses TLS and verifies the remote. This variable is used both by the `docker` CLI and the [`dockerd` daemon](https://docs.docker.com/reference/cli/dockerd/) |\n| `BUILDKIT_PROGRESS` | Set type of progress output (`auto`, `plain`, `tty`, `rawjson`) when [building](https://docs.docker.com/reference/cli/docker/image/build/) with [BuildKit backend](https://docs.docker.com/build/buildkit/). Use plain to show container output (default `auto`). |\n\nBecause Docker is developed using Go, you can also use any environment variables used by the Go runtime. In particular, you may find these useful:\n\n| Variable | Description |\n| --- | --- |\n| `HTTP_PROXY` | Proxy URL for HTTP requests unless overridden by NoProxy. |\n| `HTTPS_PROXY` | Proxy URL for HTTPS requests unless overridden by NoProxy. |\n| `NO_PROXY` | Comma-separated values specifying hosts that should be excluded from proxying. |\n\nSee the [Go specification](https://pkg.go.dev/golang.org/x/net/http/httpproxy#Config) for details on these variables.\n\nBy default, the Docker command line stores its configuration files in a directory called `.docker` within your `$HOME` directory.\n\nDocker manages most of the files in the configuration directory and you shouldn't modify them. However, you can modify the `config.json` file to control certain aspects of how the `docker` command behaves.\n\nYou can modify the `docker` command behavior using environment variables or command-line options. You can also use options within `config.json` to modify some of the same behavior. If an environment variable and the `--config` flag are set, the flag takes precedent over the environment variable. Command line options override environment variables and environment variables override properties you specify in a `config.json` file.\n\n### [Change the `.docker` directory](#change-the-docker-directory)\n\nTo specify a different directory, use the `DOCKER_CONFIG` environment variable or the `--config` command line option. If both are specified, then the `--config` option overrides the `DOCKER_CONFIG` environment variable. The example below overrides the `docker ps` command using a `config.json` file located in the `~/testconfigs/` directory.\n\nThis flag only applies to whatever command is being ran. For persistent configuration, you can set the `DOCKER_CONFIG` environment variable in your shell (e.g. `~/.profile` or `~/.bashrc`). The example below sets the new directory to be `HOME/newdir/.docker`.\n\nUse the Docker CLI configuration to customize settings for the `docker` CLI. The configuration file uses JSON formatting, and properties:\n\nBy default, configuration file is stored in `~/.docker/config.json`. Refer to the [change the `.docker` directory](#change-the-docker-directory) section to use a different location.\n\n> **Warning**\n> \n> The configuration file and other files inside the `~/.docker` configuration directory may contain sensitive information, such as authentication information for proxies or, depending on your credential store, credentials for your image registries. Review your configuration file's content before sharing with others, and prevent committing the file to version control.\n\n### [Customize the default output format for commands](#customize-the-default-output-format-for-commands)\n\nThese fields lets you customize the default output format for some commands if no `--format` flag is provided.\n\n| Property | Description |\n| --- | --- |\n| `configFormat` | Custom default format for `docker config ls` output. See [`docker config ls`](https://docs.docker.com/reference/cli/docker/config/ls/#format) for a list of supported formatting directives. |\n| `imagesFormat` | Custom default format for `docker images` / `docker image ls` output. See [`docker images`](https://docs.docker.com/reference/cli/docker/image/ls/#format) for a list of supported formatting directives. |\n| `networksFormat` | Custom default format for `docker network ls` output. See [`docker network ls`](https://docs.docker.com/reference/cli/docker/network/ls/#format) for a list of supported formatting directives. |\n| `nodesFormat` | Custom default format for `docker node ls` output. See [`docker node ls`](https://docs.docker.com/reference/cli/docker/node/ls/#format) for a list of supported formatting directives. |\n| `pluginsFormat` | Custom default format for `docker plugin ls` output. See [`docker plugin ls`](https://docs.docker.com/reference/cli/docker/plugin/ls/#format) for a list of supported formatting directives. |\n| `psFormat` | Custom default format for `docker ps` / `docker container ps` output. See [`docker ps`](https://docs.docker.com/reference/cli/docker/container/ls/#format) for a list of supported formatting directives. |\n| `secretFormat` | Custom default format for `docker secret ls` output. See [`docker secret ls`](https://docs.docker.com/reference/cli/docker/secret/ls/#format) for a list of supported formatting directives. |\n| `serviceInspectFormat` | Custom default format for `docker service inspect` output. See [`docker service inspect`](https://docs.docker.com/reference/cli/docker/service/inspect/#format) for a list of supported formatting directives. |\n| `servicesFormat` | Custom default format for `docker service ls` output. See [`docker service ls`](https://docs.docker.com/reference/cli/docker/service/ls/#format) for a list of supported formatting directives. |\n| `statsFormat` | Custom default format for `docker stats` output. See [`docker stats`](https://docs.docker.com/reference/cli/docker/container/stats/#format) for a list of supported formatting directives. |\n| `tasksFormat` | Custom default format for `docker stack ps` output. See [`docker stack ps`](https://docs.docker.com/reference/cli/docker/stack/ps/#format) for a list of supported formatting directives. |\n| `volumesFormat` | Custom default format for `docker volume ls` output. See [`docker volume ls`](https://docs.docker.com/reference/cli/docker/volume/ls/#format) for a list of supported formatting directives. |\n\nThe property `HttpHeaders` specifies a set of headers to include in all messages sent from the Docker client to the daemon. Docker doesn't try to interpret or understand these headers; it simply puts them into the messages. Docker does not allow these headers to change any headers it sets for itself.\n\n### [Credential store options](#credential-store-options)\n\nThe property `credsStore` specifies an external binary to serve as the default credential store. When this property is set, `docker login` will attempt to store credentials in the binary specified by `docker-credential-<value>` which is visible on `$PATH`. If this property isn't set, credentials are stored in the `auths` property of the CLI configuration file. For more information, see the [**Credential stores** section in the `docker login` documentation](https://docs.docker.com/reference/cli/docker/login/#credential-stores)\n\nThe property `credHelpers` specifies a set of credential helpers to use preferentially over `credsStore` or `auths` when storing and retrieving credentials for specific registries. If this property is set, the binary `docker-credential-<value>` will be used when storing or retrieving credentials for a specific registry. For more information, see the [**Credential helpers** section in the `docker login` documentation](https://docs.docker.com/reference/cli/docker/login/#credential-helpers)\n\n### [Automatic proxy configuration for containers](#automatic-proxy-configuration-for-containers)\n\nThe property `proxies` specifies proxy environment variables to be automatically set on containers, and set as `--build-arg` on containers used during `docker build`. A `\"default\"` set of proxies can be configured, and will be used for any Docker daemon that the client connects to, or a configuration per host (Docker daemon), for example, `https://docker-daemon1.example.com`. The following properties can be set for each environment:\n\n| Property | Description |\n| --- | --- |\n| `httpProxy` | Default value of `HTTP_PROXY` and `http_proxy` for containers, and as `--build-arg` on `docker build` |\n| `httpsProxy` | Default value of `HTTPS_PROXY` and `https_proxy` for containers, and as `--build-arg` on `docker build` |\n| `ftpProxy` | Default value of `FTP_PROXY` and `ftp_proxy` for containers, and as `--build-arg` on `docker build` |\n| `noProxy` | Default value of `NO_PROXY` and `no_proxy` for containers, and as `--build-arg` on `docker build` |\n| `allProxy` | Default value of `ALL_PROXY` and `all_proxy` for containers, and as `--build-arg` on `docker build` |\n\nThese settings are used to configure proxy settings for containers only, and not used as proxy settings for the `docker` CLI or the `dockerd` daemon. Refer to the [environment variables](#environment-variables) and [HTTP/HTTPS proxy](https://docs.docker.com/config/daemon/systemd/#httphttps-proxy) sections for configuring proxy settings for the cli and daemon.\n\n> **Warning**\n> \n> Proxy settings may contain sensitive information (for example, if the proxy requires authentication). Environment variables are stored as plain text in the container's configuration, and as such can be inspected through the remote API or committed to an image when using `docker commit`.\n\n### [Default key-sequence to detach from containers](#default-key-sequence-to-detach-from-containers)\n\nOnce attached to a container, users detach from it and leave it running using the using `CTRL-p CTRL-q` key sequence. This detach key sequence is customizable using the `detachKeys` property. Specify a `<sequence>` value for the property. The format of the `<sequence>` is a comma-separated list of either a letter \\[a-Z\\], or the `ctrl-` combined with any of the following:\n\n*   `a-z` (a single lowercase alpha character )\n*   `@` (at sign)\n*   `[` (left bracket)\n*   `\\\\` (two backward slashes)\n*   `_` (underscore)\n*   `^` (caret)\n\nYour customization applies to all containers started in with your Docker client. Users can override your custom or the default key sequence on a per-container basis. To do this, the user specifies the `--detach-keys` flag with the `docker attach`, `docker exec`, `docker run` or `docker start` command.\n\n### [CLI plugin options](#cli-plugin-options)\n\nThe property `plugins` contains settings specific to CLI plugins. The key is the plugin name, while the value is a further map of options, which are specific to that plugin.\n\n### [Sample configuration file](#sample-configuration-file)\n\nFollowing is a sample `config.json` file to illustrate the format used for various fields:\n\n### [Experimental features](#experimental-features)\n\nExperimental features provide early access to future product functionality. These features are intended for testing and feedback, and they may change between releases without warning or can be removed from a future release.\n\nStarting with Docker 20.10, experimental CLI features are enabled by default, and require no configuration to enable them.\n\n### [Notary](#notary)\n\nIf using your own notary server and a self-signed certificate or an internal Certificate Authority, you need to place the certificate at `tls/<registry_url>/ca.crt` in your Docker config directory.\n\nAlternatively you can trust the certificate globally by adding it to your system's list of root Certificate Authorities.\n\n### [](#a-namehosta-specify-daemon-host--h---host)Specify daemon host (-H, --host)\n\nYou can use the `-H`, `--host` flag to specify a socket to use when you invoke a `docker` command. You can use the following protocols:\n\n| Scheme | Description | Example |\n| --- | --- | --- |\n| `unix://[<path>]` | Unix socket (Linux only) | `unix:///var/run/docker.sock` |\n| `tcp://[<IP or host>[:port]]` | TCP connection | `tcp://174.17.0.1:2376` |\n| `ssh://[username@]<IP or host>[:port]` | SSH connection | `ssh://user@192.168.64.5` |\n| `npipe://[<name>]` | Named pipe (Windows only) | `npipe:////./pipe/docker_engine` |\n\nIf you don't specify the `-H` flag, and you're not using a custom [context](https://docs.docker.com/engine/context/working-with-contexts), commands use the following default sockets:\n\n*   `unix:///var/run/docker.sock` on macOS and Linux\n*   `npipe:////./pipe/docker_engine` on Windows\n\nTo achieve a similar effect without having to specify the `-H` flag for every command, you could also [create a context](https://docs.docker.com/reference/cli/docker/context/create/), or alternatively, use the [`DOCKER_HOST` environment variable](#environment-variables).\n\nFor more information about the `-H` flag, see [Daemon socket option](https://docs.docker.com/reference/cli/dockerd/#daemon-socket-option).\n\n#### [Using TCP sockets](#using-tcp-sockets)\n\nThe following example shows how to invoke `docker ps` over TCP, to a remote daemon with IP address `174.17.0.1`, listening on port `2376`:\n\n> **Note**\n> \n> By convention, the Docker daemon uses port `2376` for secure TLS connections, and port `2375` for insecure, non-TLS connections.\n\n#### [Using SSH sockets](#using-ssh-sockets)\n\nWhen you use SSH invoke a command on a remote daemon, the request gets forwarded to the `/var/run/docker.sock` Unix socket on the SSH host.\n\nYou can optionally specify the location of the socket by appending a path component to the end of the SSH address.\n\n### [Display help text](#display-help-text)\n\nTo list the help on any command just execute the command, followed by the `--help` option.\n\n### [Option types](#option-types)\n\nSingle character command line options can be combined, so rather than typing `docker run -i -t --name test busybox sh`, you can write `docker run -it --name test busybox sh`.\n\n#### [Boolean](#boolean)\n\nBoolean options take the form `-d=false`. The value you see in the help text is the default value which is set if you do **not** specify that flag. If you specify a Boolean flag without a value, this will set the flag to `true`, irrespective of the default value.\n\nFor example, running `docker run -d` will set the value to `true`, so your container **will** run in \"detached\" mode, in the background.\n\nOptions which default to `true` (e.g., `docker build --rm=true`) can only be set to the non-default value by explicitly setting them to `false`:\n\n#### [Multi](#multi)\n\nYou can specify options like `-a=[]` multiple times in a single command line, for example in these commands:\n\nSometimes, multiple options can call for a more complex value string as for `-v`:\n\n> **Note**\n> \n> Do not use the `-t` and `-a stderr` options together due to limitations in the `pty` implementation. All `stderr` in `pty` mode simply goes to `stdout`.\n\n#### [Strings and Integers](#strings-and-integers)\n\nOptions like `--name=\"\"` expect a string, and they can only be specified once. Options like `-c=0` expect an integer, and they can only be specified once.",
    "title": "Use the Docker command line | Docker Docs\n",
    "description": "Docker's CLI command description and usage",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/context/working-with-contexts/",
    "markdown": "# Docker contexts | Docker Docs\n\nThis guide shows how you can use contexts to manage Docker daemons from a single client.\n\nEach context contains all information required to manage resources on the daemon. The `docker context` command makes it easy to configure these contexts and switch between them.\n\nAs an example, a single Docker client might be configured with two contexts:\n\n*   A default context running locally\n*   A remote, shared context\n\nOnce these contexts are configured, you can use the `docker context use <context-name>` command to switch between them.\n\nTo follow the examples in this guide, you'll need:\n\n*   A Docker client that supports the top-level `context` command\n\nRun `docker context` to verify that your Docker client supports contexts.\n\n## [The anatomy of a context](#the-anatomy-of-a-context)\n\nA context is a combination of several properties. These include:\n\n*   Name and description\n*   Endpoint configuration\n*   TLS info\n\nTo list available contexts, use the `docker context ls` command.\n\nThis shows a single context called \"default\". It's configured to talk to a daemon through the local `/var/run/docker.sock` Unix socket.\n\nThe asterisk in the `NAME` column indicates that this is the active context. This means all `docker` commands run against this context, unless overridden with environment variables such as `DOCKER_HOST` and `DOCKER_CONTEXT`, or on the command-line with the `--context` and `--host` flags.\n\nDig a bit deeper with `docker context inspect`. The following example shows how to inspect the context called `default`.\n\n### [Create a new context](#create-a-new-context)\n\nYou can create new contexts with the `docker context create` command.\n\nThe following example creates a new context called `docker-test` and specifies the host endpoint of the context to TCP socket `tcp://docker:2375`.\n\nThe new context is stored in a `meta.json` file below `~/.docker/contexts/`. Each new context you create gets its own `meta.json` stored in a dedicated sub-directory of `~/.docker/contexts/`.\n\nYou can view the new context with `docker context ls` and `docker context inspect <context-name>`.\n\nThe current context is indicated with an asterisk (\"\\*\").\n\n## [Use a different context](#use-a-different-context)\n\nYou can use `docker context use` to switch between contexts.\n\nThe following command will switch the `docker` CLI to use the `docker-test` context.\n\nVerify the operation by listing all contexts and ensuring the asterisk (\"\\*\") is against the `docker-test` context.\n\n`docker` commands will now target endpoints defined in the `docker-test` context.\n\nYou can also set the current context using the `DOCKER_CONTEXT` environment variable. The environment variable overrides the context set with `docker context use`.\n\nUse the appropriate command below to set the context to `docker-test` using an environment variable.\n\nRun `docker context ls` to verify that the `docker-test` context is now the active context.\n\nYou can also use the global `--context` flag to override the context. The following command uses a context called `production`.\n\n## [Exporting and importing Docker contexts](#exporting-and-importing-docker-contexts)\n\nYou can use the `docker context export` and `docker context import` commands to export and import contexts on different hosts.\n\nThe `docker context export` command exports an existing context to a file. The file can be imported on any host that has the `docker` client installed.\n\n### [Exporting and importing a context](#exporting-and-importing-a-context)\n\nThe following example exports an existing context called `docker-test`. It will be written to a file called `docker-test.dockercontext`.\n\nCheck the contents of the export file.\n\nImport this file on another host using `docker context import` to create context with the same configuration.\n\nYou can verify that the context was imported with `docker context ls`.\n\nThe format of the import command is `docker context import <context-name> <context-file>`.\n\n## [Updating a context](#updating-a-context)\n\nYou can use `docker context update` to update fields in an existing context.\n\nThe following example updates the description field in the existing `docker-test` context.",
    "title": "Docker contexts | Docker Docs\n",
    "description": "Learn about managing multiple daemons from a single client with contexts",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/raft/",
    "markdown": "# Raft consensus in swarm mode\n\nWhen Docker Engine runs in Swarm mode, manager nodes implement the [Raft Consensus Algorithm](http://thesecretlivesofdata.com/raft/) to manage the global cluster state.\n\nThe reason why Swarm mode is using a consensus algorithm is to make sure that all the manager nodes that are in charge of managing and scheduling tasks in the cluster are storing the same consistent state.\n\nHaving the same consistent state across the cluster means that in case of a failure, any Manager node can pick up the tasks and restore the services to a stable state. For example, if the Leader Manager which is responsible for scheduling tasks in the cluster dies unexpectedly, any other Manager can pick up the task of scheduling and re-balance tasks to match the desired state.\n\nSystems using consensus algorithms to replicate logs in a distributed systems do require special care. They ensure that the cluster state stays consistent in the presence of failures by requiring a majority of nodes to agree on values.\n\nRaft tolerates up to `(N-1)/2` failures and requires a majority or quorum of `(N/2)+1` members to agree on values proposed to the cluster. This means that in a cluster of 5 Managers running Raft, if 3 nodes are unavailable, the system cannot process any more requests to schedule additional tasks. The existing tasks keep running but the scheduler cannot rebalance tasks to cope with failures if the manager set is not healthy.\n\nThe implementation of the consensus algorithm in Swarm mode means it features the properties inherent to distributed systems:\n\n*   Agreement on values in a fault tolerant system. (Refer to [FLP impossibility theorem](https://www.the-paper-trail.org/post/2008-08-13-a-brief-tour-of-flp-impossibility/) and the [Raft Consensus Algorithm paper](https://www.usenix.org/system/files/conference/atc14/atc14-paper-ongaro.pdf))\n*   Mutual exclusion through the leader election process\n*   Cluster membership management\n*   Globally consistent object sequencing and CAS (compare-and-swap) primitives",
    "title": "Raft consensus in swarm mode | Docker Docs\n",
    "description": "Raft consensus algorithm in swarm mode",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/alternative-runtimes/",
    "markdown": "# Alternative container runtimes | Docker Docs\n\nDocker Engine uses containerd for managing the container lifecycle, which includes creating, starting, and stopping containers. By default, containerd uses runc as its container runtime.\n\nYou can use any runtime that implements the containerd [shim API](https://github.com/containerd/containerd/blob/main/core/runtime/v2/README.md). Such runtimes ship with a containerd shim, and you can use them without any additional configuration. See [Use containerd shims](#use-containerd-shims).\n\nExamples of runtimes that implement their own containerd shims include:\n\n*   [Wasmtime](https://wasmtime.dev/)\n*   [gVisor](https://github.com/google/gvisor)\n*   [Kata Containers](https://katacontainers.io/)\n\nYou can also use runtimes designed as drop-in replacements for runc. Such runtimes depend on the runc containerd shim for invoking the runtime binary. You must manually register such runtimes in the daemon configuration.\n\n[youki](https://github.com/containers/youki) is one example of a runtime that can function as a runc drop-in replacement. Refer to the [youki example](#youki) explaining the setup.\n\ncontainerd shims let you use alternative runtimes without having to change the configuration of the Docker daemon. To use a containerd shim, install the shim binary on `PATH` on the system where the Docker daemon is running.\n\nTo use a shim with `docker run`, specify the fully qualified name of the runtime as the value to the `--runtime` flag:\n\n### [Use a containerd shim without installing on PATH](#use-a-containerd-shim-without-installing-on-path)\n\nYou can use a shim without installing it on `PATH`, in which case you need to register the shim in the daemon configuration as follows:\n\nTo use the shim, specify the name that you assigned to it:\n\n### [Configure shims](#configure-shims)\n\nIf you need to pass additional configuration for a containerd shim, you can use the `runtimes` option in the daemon configuration file.\n\n1.  Edit the daemon configuration file by adding a `runtimes` entry for the shim you want to configure.\n    \n    *   Specify the fully qualified name for the runtime in `runtimeType` key\n    *   Add your runtime configuration under the `options` key\n2.  Reload the daemon's configuration.\n    \n3.  Use the customized runtime using the `--runtime` flag for `docker run`.\n    \n\nFor more information about the configuration options for containerd shims, see [Configure containerd shims](https://docs.docker.com/reference/cli/dockerd/#configure-containerd-shims).\n\nThe following examples show you how to set up and use alternative container runtimes with Docker Engine.\n\n*   [youki](#youki)\n*   [Wasmtime](#wasmtime)\n\n### [youki](#youki)\n\nyouki is a container runtime written in Rust. youki claims to be faster and use less memory than runc, making it a good choice for resource-constrained environments.\n\nyouki functions as a drop-in replacement for runc, meaning it relies on the runc shim to invoke the runtime binary. When you register runtimes acting as runc replacements, you configure the path to the runtime executable, and optionally a set of runtime arguments. For more information, see [Configure runc drop-in replacements](https://docs.docker.com/reference/cli/dockerd/#configure-runc-drop-in-replacements).\n\nTo add youki as a container runtime:\n\n1.  Install youki and its dependencies.\n    \n    For instructions, refer to the [official setup guide](https://containers.github.io/youki/user/basic_setup.html).\n    \n2.  Register youki as a runtime for Docker by editing the Docker daemon configuration file, located at `/etc/docker/daemon.json` by default.\n    \n    The `path` key should specify the path to wherever you installed youki.\n    \n3.  Reload the daemon's configuration.\n    \n\nNow you can run containers that use youki as a runtime.\n\n### [Wasmtime](#wasmtime)\n\nWasmtime is a [Bytecode Alliance](https://bytecodealliance.org/) project, and a Wasm runtime that lets you run Wasm containers. Running Wasm containers with Docker provides two layers of security. You get all the benefits from container isolation, plus the added sandboxing provided by the Wasm runtime environment.\n\nTo add Wasmtime as a container runtime, follow these steps:\n\n1.  Turn on the [containerd image store](https://docs.docker.com/storage/containerd/) feature in the daemon configuration file.\n    \n    > **Note**\n    > \n    > This is an experimental feature.\n    \n2.  Restart the Docker daemon.\n    \n3.  Install the Wasmtime containerd shim on `PATH`.\n    \n    The following command Dockerfile builds the Wasmtime binary from source and exports it to `./containerd-shim-wasmtime-v1`.\n    \n    Put the binary in a directory on `PATH`.\n    \n\nNow you can run containers that use Wasmtime as a runtime.\n\n*   To learn more about the configuration options for container runtimes, see [Configure container runtimes](https://docs.docker.com/reference/cli/dockerd/#configure-container-runtimes).\n*   You can configure which runtime that the daemon should use as its default. Refer to [Configure the default container runtime](https://docs.docker.com/reference/cli/dockerd/#configure-the-default-container-runtime).",
    "title": "Alternative container runtimes | Docker Docs\n",
    "description": "Docker Engine uses runc as the default container runtime, but you can specify alternative runtimes using the CLI or by configuring the daemon ",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/security/apparmor/",
    "markdown": "# AppArmor security profiles for Docker\n\nAppArmor (Application Armor) is a Linux security module that protects an operating system and its applications from security threats. To use it, a system administrator associates an AppArmor security profile with each program. Docker expects to find an AppArmor policy loaded and enforced.\n\nDocker automatically generates and loads a default profile for containers named `docker-default`. The Docker binary generates this profile in `tmpfs` and then loads it into the kernel.\n\n> **Note**\n> \n> This profile is used on containers, not on the Docker daemon.\n\nA profile for the Docker Engine daemon exists but it is not currently installed with the `deb` packages. If you are interested in the source for the daemon profile, it is located in [contrib/apparmor](https://github.com/moby/moby/tree/master/contrib/apparmor) in the Docker Engine source repository.\n\nThe `docker-default` profile is the default for running containers. It is moderately protective while providing wide application compatibility. The profile is generated from the following [template](https://github.com/moby/moby/blob/master/profiles/apparmor/template.go).\n\nWhen you run a container, it uses the `docker-default` policy unless you override it with the `security-opt` option. For example, the following explicitly specifies the default policy:\n\nTo load a new profile into AppArmor for use with containers:\n\nThen, run the custom profile with `--security-opt`:\n\nTo unload a profile from AppArmor:\n\n### [Resources for writing profiles](#resources-for-writing-profiles)\n\nThe syntax for file globbing in AppArmor is a bit different than some other globbing implementations. It is highly suggested you take a look at some of the below resources with regard to AppArmor profile syntax.\n\n*   [Quick Profile Language](https://gitlab.com/apparmor/apparmor/wikis/QuickProfileLanguage)\n*   [Globbing Syntax](https://gitlab.com/apparmor/apparmor/wikis/AppArmor_Core_Policy_Reference#AppArmor_globbing_syntax)\n\nIn this example, you create a custom AppArmor profile for Nginx. Below is the custom profile.\n\n1.  Save the custom profile to disk in the `/etc/apparmor.d/containers/docker-nginx` file.\n    \n    The file path in this example is not a requirement. In production, you could use another.\n    \n2.  Load the profile.\n    \n3.  Run a container with the profile.\n    \n    To run nginx in detached mode:\n    \n4.  Exec into the running container.\n    \n5.  Try some operations to test the profile.\n    \n\nYou just deployed a container secured with a custom apparmor profile.\n\nYou can use `dmesg` to debug problems and `aa-status` check the loaded profiles.\n\n### [Use dmesg](#use-dmesg)\n\nHere are some helpful tips for debugging any problems you might be facing with regard to AppArmor.\n\nAppArmor sends quite verbose messaging to `dmesg`. Usually an AppArmor line looks like the following:\n\nIn the above example, you can see `profile=/usr/bin/docker`. This means the user has the `docker-engine` (Docker Engine daemon) profile loaded.\n\nLook at another log line:\n\nThis time the profile is `docker-default`, which is run on containers by default unless in `privileged` mode. This line shows that apparmor has denied `ptrace` in the container. This is exactly as expected.\n\n### [Use aa-status](#use-aa-status)\n\nIf you need to check which profiles are loaded, you can use `aa-status`. The output looks like:\n\nThe above output shows that the `docker-default` profile running on various container PIDs is in `enforce` mode. This means AppArmor is actively blocking and auditing in `dmesg` anything outside the bounds of the `docker-default` profile.\n\nThe output above also shows the `/usr/bin/docker` (Docker Engine daemon) profile is running in `complain` mode. This means AppArmor only logs to `dmesg` activity outside the bounds of the profile. (Except in the case of Ubuntu Trusty, where some interesting behaviors are enforced.)\n\nAdvanced users and package managers can find a profile for `/usr/bin/docker` (Docker Engine daemon) underneath [contrib/apparmor](https://github.com/moby/moby/tree/master/contrib/apparmor) in the Docker Engine source repository.\n\nThe `docker-default` profile for containers lives in [profiles/apparmor](https://github.com/moby/moby/tree/master/profiles/apparmor).",
    "title": "AppArmor security profiles for Docker | Docker Docs\n",
    "description": "Enabling AppArmor in Docker",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/deprecated/",
    "markdown": "# Deprecated Engine Features | Docker Docs\n\nThis page provides an overview of features that are deprecated in Engine. Changes in packaging, and supported (Linux) distributions are not included. To learn about end of support for Linux distributions, refer to the [release notes](https://docs.docker.com/engine/release-notes/).\n\nAs changes are made to Docker there may be times when existing features need to be removed or replaced with newer features. Before an existing feature is removed it is labeled as \"deprecated\" within the documentation and remains in Docker for at least one stable release unless specified explicitly otherwise. After that time it may be removed.\n\nUsers are expected to take note of the list of deprecated features each release and plan their migration away from those features, and (if applicable) towards the replacement features as soon as possible.\n\nThe table below provides an overview of the current status of deprecated features:\n\n*   **Deprecated**: the feature is marked \"deprecated\" and should no longer be used. The feature may be removed, disabled, or change behavior in a future release. The _\"Deprecated\"_ column contains the release in which the feature was marked deprecated, whereas the _\"Remove\"_ column contains a tentative release in which the feature is to be removed. If no release is included in the _\"Remove\"_ column, the release is yet to be decided on.\n*   **Removed**: the feature was removed, disabled, or hidden. Refer to the linked section for details. Some features are \"soft\" deprecated, which means that they remain functional for backward compatibility, and to allow users to migrate to alternatives. In such cases, a warning may be printed, and users should not rely on this feature.\n\n| Status | Feature | Deprecated | Remove |\n| --- | --- | --- | --- |\n| Deprecated | [Non-standard fields in image inspect](#non-standard-fields-in-image-inspect) | v27.0 | v28.0 |\n| Deprecated | [API CORS headers](#api-cors-headers) | v27.0 | v28.0 |\n| Deprecated | [Graphdriver plugins (experimental)](#graphdriver-plugins-experimental) | v27.0 | v28.0 |\n| Deprecated | [Unauthenticated TCP connections](#unauthenticated-tcp-connections) | v26.0 | v28.0 |\n| Deprecated | [`Container` and `ContainerConfig` fields in Image inspect](#container-and-containerconfig-fields-in-image-inspect) | v25.0 | v26.0 |\n| Deprecated | [Deprecate legacy API versions](#deprecate-legacy-api-versions) | v25.0 | v26.0 |\n| Removed | [Container short ID in network Aliases field](#container-short-id-in-network-aliases-field) | v25.0 | v26.0 |\n| Deprecated | [IsAutomated field, and \"is-automated\" filter on docker search](#isautomated-field-and-is-automated-filter-on-docker-search) | v25.0 | v26.0 |\n| Removed | [logentries logging driver](#logentries-logging-driver) | v24.0 | v25.0 |\n| Removed | [OOM-score adjust for the daemon](#oom-score-adjust-for-the-daemon) | v24.0 | v25.0 |\n| Removed | [Buildkit build information](#buildkit-build-information) | v23.0 | v24.0 |\n| Deprecated | [Legacy builder for Linux images](#legacy-builder-for-linux-images) | v23.0 | \\-  |\n| Deprecated | [Legacy builder fallback](#legacy-builder-fallback) | v23.0 | \\-  |\n| Removed | [Btrfs storage driver on CentOS 7 and RHEL 7](#btrfs-storage-driver-on-centos-7-and-rhel-7) | v20.10 | v23.0 |\n| Removed | [Support for encrypted TLS private keys](#support-for-encrypted-tls-private-keys) | v20.10 | v23.0 |\n| Removed | [Kubernetes stack and context support](#kubernetes-stack-and-context-support) | v20.10 | v23.0 |\n| Deprecated | [Pulling images from non-compliant image registries](#pulling-images-from-non-compliant-image-registries) | v20.10 | \\-  |\n| Removed | [Linux containers on Windows (LCOW)](#linux-containers-on-windows-lcow-experimental) | v20.10 | v23.0 |\n| Deprecated | [BLKIO weight options with cgroups v1](#blkio-weight-options-with-cgroups-v1) | v20.10 | \\-  |\n| Removed | [Kernel memory limit](#kernel-memory-limit) | v20.10 | v23.0 |\n| Removed | [Classic Swarm and overlay networks using external key/value stores](#classic-swarm-and-overlay-networks-using-cluster-store) | v20.10 | v23.0 |\n| Removed | [Support for the legacy `~/.dockercfg` configuration file for authentication](#support-for-legacy-dockercfg-configuration-files) | v20.10 | v23.0 |\n| Deprecated | [CLI plugins support](#cli-plugins-support) | v20.10 | \\-  |\n| Deprecated | [Dockerfile legacy `ENV name value` syntax](#dockerfile-legacy-env-name-value-syntax) | v20.10 | \\-  |\n| Removed | [`docker build --stream` flag (experimental)](#docker-build---stream-flag-experimental) | v20.10 | v20.10 |\n| Deprecated | [`fluentd-async-connect` log opt](#fluentd-async-connect-log-opt) | v20.10 | \\-  |\n| Removed | [Configuration options for experimental CLI features](#configuration-options-for-experimental-cli-features) | v19.03 | v23.0 |\n| Deprecated | [Pushing and pulling with image manifest v2 schema 1](#pushing-and-pulling-with-image-manifest-v2-schema-1) | v19.03 | v27.0 |\n| Removed | [`docker engine` subcommands](#docker-engine-subcommands) | v19.03 | v20.10 |\n| Removed | [Top-level `docker deploy` subcommand (experimental)](#top-level-docker-deploy-subcommand-experimental) | v19.03 | v20.10 |\n| Removed | [`docker stack deploy` using \"dab\" files (experimental)](#docker-stack-deploy-using-dab-files-experimental) | v19.03 | v20.10 |\n| Removed | [Support for the `overlay2.override_kernel_check` storage option](#support-for-the-overlay2override_kernel_check-storage-option) | v19.03 | v24.0 |\n| Removed | [AuFS storage driver](#aufs-storage-driver) | v19.03 | v24.0 |\n| Removed | [Legacy \"overlay\" storage driver](#legacy-overlay-storage-driver) | v18.09 | v24.0 |\n| Removed | [Device mapper storage driver](#device-mapper-storage-driver) | v18.09 | v25.0 |\n| Removed | [Use of reserved namespaces in engine labels](#use-of-reserved-namespaces-in-engine-labels) | v18.06 | v20.10 |\n| Removed | [`--disable-legacy-registry` override daemon option](#--disable-legacy-registry-override-daemon-option) | v17.12 | v19.03 |\n| Removed | [Interacting with V1 registries](#interacting-with-v1-registries) | v17.06 | v17.12 |\n| Removed | [Asynchronous `service create` and `service update` as default](#asynchronous-service-create-and-service-update-as-default) | v17.05 | v17.10 |\n| Removed | [`-g` and `--graph` flags on `dockerd`](#-g-and---graph-flags-on-dockerd) | v17.05 | v23.0 |\n| Deprecated | [Top-level network properties in NetworkSettings](#top-level-network-properties-in-networksettings) | v1.13 | v17.12 |\n| Removed | [`filter` param for `/images/json` endpoint](#filter-param-for-imagesjson-endpoint) | v1.13 | v20.10 |\n| Removed | [`repository:shortid` image references](#repositoryshortid-image-references) | v1.13 | v17.12 |\n| Removed | [`docker daemon` subcommand](#docker-daemon-subcommand) | v1.13 | v17.12 |\n| Removed | [Duplicate keys with conflicting values in engine labels](#duplicate-keys-with-conflicting-values-in-engine-labels) | v1.13 | v17.12 |\n| Deprecated | [`MAINTAINER` in Dockerfile](#maintainer-in-dockerfile) | v1.13 | \\-  |\n| Deprecated | [API calls without a version](#api-calls-without-a-version) | v1.13 | v17.12 |\n| Removed | [Backing filesystem without `d_type` support for overlay/overlay2](#backing-filesystem-without-d_type-support-for-overlayoverlay2) | v1.13 | v17.12 |\n| Removed | [`--automated` and `--stars` flags on `docker search`](#--automated-and---stars-flags-on-docker-search) | v1.12 | v20.10 |\n| Deprecated | [`-h` shorthand for `--help`](#-h-shorthand-for---help) | v1.12 | v17.09 |\n| Removed | [`-e` and `--email` flags on `docker login`](#-e-and---email-flags-on-docker-login) | v1.11 | v17.06 |\n| Deprecated | [Separator (`:`) of `--security-opt` flag on `docker run`](#separator--of---security-opt-flag-on-docker-run) | v1.11 | v17.06 |\n| Deprecated | [Ambiguous event fields in API](#ambiguous-event-fields-in-api) | v1.10 | \\-  |\n| Removed | [`-f` flag on `docker tag`](#-f-flag-on-docker-tag) | v1.10 | v1.12 |\n| Removed | [HostConfig at API container start](#hostconfig-at-api-container-start) | v1.10 | v1.12 |\n| Removed | [`--before` and `--since` flags on `docker ps`](#--before-and---since-flags-on-docker-ps) | v1.10 | v1.12 |\n| Removed | [Driver-specific log tags](#driver-specific-log-tags) | v1.9 | v1.12 |\n| Removed | [Docker Content Trust `ENV` passphrase variables name change](#docker-content-trust-env-passphrase-variables-name-change) | v1.9 | v1.12 |\n| Removed | [`/containers/(id or name)/copy` endpoint](#containersid-or-namecopy-endpoint) | v1.8 | v1.12 |\n| Removed | [LXC built-in exec driver](#lxc-built-in-exec-driver) | v1.8 | v1.10 |\n| Removed | [Old Command Line Options](#old-command-line-options) | v1.8 | v1.10 |\n| Removed | [`--api-enable-cors` flag on `dockerd`](#--api-enable-cors-flag-on-dockerd) | v1.6 | v17.09 |\n| Removed | [`--run` flag on `docker commit`](#--run-flag-on-docker-commit) | v0.10 | v1.13 |\n| Removed | [Three arguments form in `docker import`](#three-arguments-form-in-docker-import) | v0.6.7 | v1.12 |\n\n### [Non-standard fields in image inspect](#non-standard-fields-in-image-inspect)\n\n**Deprecated in Release: v27.0** **Target For Removal In Release: v28.0**\n\nThe `Config` field returned shown in `docker image inspect` (and as returned by the `GET /images/{name}/json` API endpoint) returns additional fields that are not part of the image's configuration and not part of the [Docker Image Spec](https://github.com/moby/docker-image-spec/blob/v1.3.1/specs-go/v1/image.go#L19-L32) and \\[OCI Image Specification\\].\n\nThese fields are never set (and always return the default value for the type), but are not omitted in the response when left empty. As these fields were not intended to be part of the image configuration response, they are deprecated, and will be removed from the API in thee next release.\n\nThe following fields are currently included in the API response, but are not part of the underlying image's Config, and deprecated:\n\n*   `Hostname`\n*   `Domainname`\n*   `AttachStdin`\n*   `AttachStdout`\n*   `AttachStderr`\n*   `Tty`\n*   `OpenStdin`\n*   `StdinOnce`\n*   `Image`\n*   `NetworkDisabled` (already omitted unless set)\n*   `MacAddress` (already omitted unless set)\n*   `StopTimeout` (already omitted unless set)\n\n### [Graphdriver plugins (experimental)](#graphdriver-plugins-experimental)\n\n**Deprecated in Release: v27.0** **Disabled by default in Release: v27.0** **Target For Removal In Release: v28.0**\n\n[Graphdriver plugins](https://github.com/docker/cli/blob/v26.1.4/docs/extend/plugins_graphdriver.md) are an experimental feature that allow extending the Docker Engine with custom storage drivers for storing images and containers. This feature was not maintained since its inception, and will no longer be supported in upcoming releases.\n\nSupport for graphdriver plugins is disabled by default in v27.0, and will be removed v28.0. An `DOCKERD_DEPRECATED_GRAPHDRIVER_PLUGINS` environment variable is provided in v27.0 to re-enable the feature. This environment variable must be set to a non-empty value in the daemon's environment.\n\nThe `DOCKERD_DEPRECATED_GRAPHDRIVER_PLUGINS` environment variable, along with support for graphdriver plugins, will be removed in v28.0. Users of this feature are recommended to instead configure the Docker Engine to use the [containerd image store](https://docs.docker.com/storage/containerd/) and a custom [snapshotter](https://github.com/containerd/containerd/tree/v1.7.18/docs/snapshotters)\n\n**Deprecated in Release: v27.0** **Target For Removal In Release: v28.0**\n\nThe `api-cors-header` configuration option for the Docker daemon is insecure, and is therefore deprecated and scheduled for removal. Incorrectly setting this option could leave a window of opportunity for unauthenticated cross-origin requests to be accepted by the daemon.\n\nStarting in Docker Engine v27.0, this flag can still be set, but it has no effect unless the environment variable `DOCKERD_DEPRECATED_CORS_HEADER` is also set to a non-empty value.\n\nThis flag will be removed altogether in v28.0.\n\nThis is a breaking change for authorization plugins and other programs that depend on this option for accessing the Docker API from a browser. If you need to access the API through a browser, use a reverse proxy.\n\n### [Unauthenticated TCP connections](#unauthenticated-tcp-connections)\n\n**Deprecated in Release: v26.0** **Target For Removal In Release: v28.0**\n\nConfiguring the Docker daemon to listen on a TCP address will require mandatory TLS verification. This change aims to ensure secure communication by preventing unauthorized access to the Docker daemon over potentially insecure networks. This mandatory TLS requirement applies to all TCP addresses except `tcp://localhost`.\n\nIn version 27.0 and later, specifying `--tls=false` or `--tlsverify=false` CLI flags causes the daemon to fail to start if it's also configured to accept remote connections over TCP. This also applies to the equivalent configuration options in `daemon.json`.\n\nTo facilitate remote access to the Docker daemon over TCP, you'll need to implement TLS verification. This secures the connection by encrypting data in transit and providing a mechanism for mutual authentication.\n\nFor environments remote daemon access isn't required, we recommend binding the Docker daemon to a Unix socket. For daemon's where remote access is required and where TLS encryption is not feasible, you may want to consider using SSH as an alternative solution.\n\nFor further information, assistance, and step-by-step instructions on configuring TLS (or SSH) for the Docker daemon, refer to [Protect the Docker daemon socket](https://docs.docker.com/engine/security/protect-access/).\n\n### [`Container` and `ContainerConfig` fields in Image inspect](#container-and-containerconfig-fields-in-image-inspect)\n\n**Deprecated in Release: v25.0** **Target For Removal In Release: v26.0**\n\nThe `Container` and `ContainerConfig` fields returned by `docker inspect` are mostly an implementation detail of the classic (non-BuildKit) image builder. These fields are not portable and are empty when using the BuildKit-based builder (enabled by default since v23.0). These fields are deprecated in v25.0 and will be omitted starting from v26.0. If image configuration of an image is needed, you can obtain it from the `Config` field.\n\n### [Deprecate legacy API versions](#deprecate-legacy-api-versions)\n\n**Deprecated in Release: v25.0** **Target For Removal In Release: v26.0**\n\nThe Docker daemon provides a versioned API for backward compatibility with old clients. Docker clients can perform API-version negotiation to select the most recent API version supported by the daemon (downgrading to and older version of the API when necessary). API version negotiation was introduced in Docker v1.12.0 (API 1.24), and clients before that used a fixed API version.\n\nDocker Engine versions through v25.0 provide support for all [API versions](https://docs.docker.com/engine/api/#api-version-matrix) included in stable releases for a given platform. For Docker daemons on Linux, the earliest supported API version is 1.12 (corresponding with Docker Engine v1.0.0), whereas for Docker daemons on Windows, the earliest supported API version is 1.24 (corresponding with Docker Engine v1.12.0).\n\nSupport for legacy API versions (providing old API versions on current versions of the Docker Engine) is primarily intended to provide compatibility with recent, but still supported versions of the client, which is a common scenario (the Docker daemon may be updated to the latest release, but not all clients may be up-to-date or vice versa). Support for API versions before that (API versions provided by EOL versions of the Docker Daemon) is provided on a \"best effort\" basis.\n\nUse of old API versions is very rare, and support for legacy API versions involves significant complexity (Docker 1.0.0 having been released 10 years ago). Because of this, we'll start deprecating support for legacy API versions.\n\nDocker Engine v25.0 by default disables API version older than 1.24 (aligning the minimum supported API version between Linux and Windows daemons). When connecting with a client that uses an API version version older than 1.24, the daemon returns an error. The following example configures the docker CLI to use API version 1.23, which produces an error:\n\nAn environment variable (`DOCKER_MIN_API_VERSION`) is introduced that allows re-enabling older API versions in the daemon. This environment variable must be set in the daemon's environment (for example, through a [systemd override file](https://docs.docker.com/config/daemon/systemd/)), and the specified API version must be supported by the daemon (`1.12` or higher on Linux, or `1.24` or higher on Windows).\n\nSupport for API versions lower than `1.24` will be permanently removed in Docker Engine v26, and the minimum supported API version will be incrementally raised in releases following that.\n\nWe do not recommend depending on the `DOCKER_MIN_API_VERSION` environment variable other than for exceptional cases where it's not possible to update old clients, and those clients must be supported.\n\n### [Container short ID in network Aliases field](#container-short-id-in-network-aliases-field)\n\n**Deprecated in Release: v25.0** **Removed In Release: v26.0**\n\nThe `Aliases` field returned by `docker inspect` contains the container short ID once the container is started. This behavior is deprecated in v25.0 but kept until the next release, v26.0. Starting with that version, the `Aliases` field will only contain the aliases set through the `docker container create` and `docker run` flag `--network-alias`.\n\nA new field `DNSNames` containing the container name (if one was specified), the hostname, the network aliases, as well as the container short ID, has been introduced in v25.0 and should be used instead of the `Aliases` field.\n\n### [IsAutomated field, and \"is-automated\" filter on docker search](#isautomated-field-and-is-automated-filter-on-docker-search)\n\n**Deprecated in Release: v25.0** **Target For Removal In Release: v26.0**\n\nThe \"is\\_automated\" field has been deprecated by Docker Hub's search API. Consequently, the `IsAutomated` field in image search will always be set to `false` in future, and searching for \"is-automated=true\" will yield no results.\n\nThe `AUTOMATED` column has been removed from the default `docker search` and `docker image search` output in v25.0, and the corresponding `IsAutomated` templating option will be removed in v26.0.\n\n### [Logentries logging driver](#logentries-logging-driver)\n\n**Deprecated in Release: v24.0** **Removed in Release: v25.0**\n\nThe logentries service SaaS was shut down on November 15, 2022, rendering this logging driver non-functional. Users should no longer use this logging driver, and the driver has been removed in Docker 25.0. Existing containers using this logging-driver are migrated to use the \"local\" logging driver after upgrading.\n\n### [OOM-score adjust for the daemon](#oom-score-adjust-for-the-daemon)\n\n**Deprecated in Release: v24.0** **Removed in Release: v25.0**\n\nThe `oom-score-adjust` option was added to prevent the daemon from being OOM-killed before other processes. This option was mostly added as a convenience, as running the daemon as a systemd unit was not yet common.\n\nHaving the daemon set its own limits is not best-practice, and something better handled by the process-manager starting the daemon.\n\nDocker v20.10 and newer no longer adjust the daemon's OOM score by default, instead setting the OOM-score to the systemd unit (OOMScoreAdjust) that's shipped with the packages.\n\nUsers currently depending on this feature are recommended to adjust the daemon's OOM score using systemd or through other means, when starting the daemon.\n\n### [Buildkit build information](#buildkit-build-information)\n\n**Deprecated in Release: v23.0** **Removed in Release: v24.0**\n\n[Build information](https://github.com/moby/buildkit/blob/v0.11/docs/buildinfo.md) structures have been introduced in [BuildKit v0.10.0](https://github.com/moby/buildkit/releases/tag/v0.10.0) and are generated with build metadata that allows you to see all the sources (images, git repositories) that were used by the build with their exact versions and also the configuration that was passed to the build. This information is also embedded into the image configuration if one is generated.\n\n### [Legacy builder for Linux images](#legacy-builder-for-linux-images)\n\n**Deprecated in Release: v23.0**\n\nDocker v23.0 now uses BuildKit by default to build Linux images, and uses the [Buildx](https://docs.docker.com/buildx/working-with-buildx/) CLI component for `docker build`. With this change, `docker build` now exposes all advanced features that BuildKit provides and which were previously only available through the `docker buildx` subcommands.\n\nThe Buildx component is installed automatically when installing the `docker` CLI using our `.deb` or `.rpm` packages, and statically linked binaries are provided both on `download.docker.com`, and through the [`docker/buildx-bin` image](https://hub.docker.com/r/docker/buildx-bin) on Docker Hub. Refer the [Buildx section](http://docs.docker.com/go/buildx/) for detailed instructions on installing the Buildx component.\n\nThis release marks the beginning of the deprecation cycle of the classic (\"legacy\") builder for Linux images. No active development will happen on the classic builder (except for bugfixes). BuildKit development started five Years ago, left the \"experimental\" phase since Docker 18.09, and is already the default builder for [Docker Desktop](https://docs.docker.com/desktop/previous-versions/3.x-mac/#docker-desktop-320). While we're comfortable that BuildKit is stable for general use, there may be some changes in behavior. If you encounter issues with BuildKit, we encourage you to report issues in the [BuildKit issue tracker on GitHub](https://github.com/moby/buildkit/){:target=\"_blank\" rel=\"noopener\" class=\"_\"}\n\n> Classic builder for building Windows images\n> \n> BuildKit does not (yet) provide support for building Windows images, and `docker build` continues to use the classic builder to build native Windows images on Windows daemons.\n\n### [Legacy builder fallback](#legacy-builder-fallback)\n\n**Deprecated in Release: v23.0**\n\n[Docker v23.0 now uses BuildKit by default to build Linux images](#legacy-builder-for-linux-images), which requires the Buildx component to build images with BuildKit. There may be situations where the Buildx component is not available, and BuildKit cannot be used.\n\nTo provide a smooth transition to BuildKit as the default builder, Docker v23.0 has an automatic fallback for some situations, or produces an error to assist users to resolve the problem.\n\nIn situations where the user did not explicitly opt-in to use BuildKit (i.e., `DOCKER_BUILDKIT=1` is not set), the CLI automatically falls back to the classic builder, but prints a deprecation warning:\n\nThis situation may occur if the `docker` CLI is installed using the static binaries, and the Buildx component is not installed or not installed correctly. This fallback will be removed in a future release, therefore we recommend to [install the Buildx component](https://docs.docker.com/go/buildx/) and use BuildKit for your builds, or opt-out of using BuildKit with `DOCKER_BUILDKIT=0`.\n\nIf you opted-in to use BuildKit (`DOCKER_BUILDKIT=1`), but the Buildx component is missing, an error is printed instead, and the `docker build` command fails:\n\nWe recommend to [install the Buildx component](https://docs.docker.com/go/buildx/) to continue using BuildKit for your builds, but alternatively, users can either unset the `DOCKER_BUILDKIT` environment variable to fall back to the legacy builder, or opt-out of using BuildKit with `DOCKER_BUILDKIT=0`.\n\nBe aware that the [classic builder is deprecated](#legacy-builder-for-linux-images) so both the automatic fallback and opting-out of using BuildKit will no longer be possible in a future release.\n\n### [Btrfs storage driver on CentOS 7 and RHEL 7](#btrfs-storage-driver-on-centos-7-and-rhel-7)\n\n**Removed in Release: v23.0**\n\nThe `btrfs` storage driver on CentOS and RHEL was provided as a technology preview by CentOS and RHEL, but has been deprecated since the [Red Hat Enterprise Linux 7.4 release](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/storage_administration_guide/ch-btrfs), and removed in CentOS 8 and RHEL 8. Users of the `btrfs` storage driver on CentOS are recommended to migrate to a different storage driver, such as `overlay2`, which is now the default storage driver. Docker 23.0 continues to provide the `btrfs` storage driver to allow users to migrate to an alternative driver. The next release of Docker will no longer provide this driver.\n\n### [Support for encrypted TLS private keys](#support-for-encrypted-tls-private-keys)\n\n**Deprecated in Release: v20.10**\n\n**Removed in Release: v23.0**\n\nUse of encrypted TLS private keys has been deprecated, and has been removed. Golang has deprecated support for legacy PEM encryption (as specified in [RFC 1423](https://datatracker.ietf.org/doc/html/rfc1423)), as it is insecure by design (see [https://go-review.googlesource.com/c/go/+/264159](https://go-review.googlesource.com/c/go/+/264159)).\n\nThis feature allowed using an encrypted private key with a supplied password, but did not provide additional security as the encryption is known to be broken, and the key is sitting next to the password in the filesystem. Users are recommended to decrypt the private key, and store it un-encrypted to continue using it.\n\n### [Kubernetes stack and context support](#kubernetes-stack-and-context-support)\n\n**Deprecated in Release: v20.10** **Removed in Release: v23.0**\n\nFollowing the deprecation of [Compose on Kubernetes](https://github.com/docker/compose-on-kubernetes), support for Kubernetes in the `stack` and `context` commands has been removed from the cli, and options related to this functionality are now either ignored, or may produce an error.\n\nThe following command-line flags are removed from the `docker context` subcommands:\n\n*   `--default-stack-orchestrator` - swarm is now the only (and default) orchestrator for stacks.\n*   `--kubernetes` - the kubernetes endpoint can no longer be stored in `docker context`.\n*   `--kubeconfig` - exporting a context as a kubeconfig file is no longer supported.\n\nThe output produced by the `docker context inspect` subcommand no longer contains information about `StackOrchestrator` and `Kubernetes` endpoints for new contexts.\n\nThe following command-line flags are removed from the `docker stack` subcommands:\n\n*   `--kubeconfig` - using a kubeconfig file as context is no longer supported.\n*   `--namespace` - configuring the kubernetes namespace for stacks is no longer supported.\n*   `--orchestrator` - swarm is now the only (and default) orchestrator for stacks.\n\nThe `DOCKER_STACK_ORCHESTRATOR`, `DOCKER_ORCHESTRATOR`, and `KUBECONFIG` environment variables, as well as the `stackOrchestrator` option in the `~/.docker/config.json` cli configuration file are no longer used, and ignored.\n\n### [Pulling images from non-compliant image registries](#pulling-images-from-non-compliant-image-registries)\n\n**Deprecated in Release: v20.10**\n\nDocker Engine v20.10 and up includes optimizations to verify if images in the local image cache need updating before pulling, preventing the Docker Engine from making unnecessary API requests. These optimizations require the container image registry to conform to the [Open Container Initiative Distribution Specification](https://github.com/opencontainers/distribution-spec).\n\nWhile most registries conform to the specification, we encountered some registries to be non-compliant, resulting in `docker pull` to fail.\n\nAs a temporary solution, Docker Engine v20.10 includes a fallback mechanism to allow `docker pull` to be functional when using a non-compliant registry. A warning message is printed in this situation:\n\n```\nWARNING Failed to pull manifest by the resolved digest. This registry does not\n        appear to conform to the distribution registry specification; falling back to\n        pull by tag. This fallback is DEPRECATED, and will be removed in a future\n        release.\n```\n\nThe fallback is added to allow users to either migrate their images to a compliant registry, or for these registries to become compliant.\n\nNote that this fallback only addresses failures on `docker pull`. Other commands, such as `docker stack deploy`, or pulling images with `containerd` will continue to fail.\n\nGiven that other functionality is still broken with these registries, we consider this fallback a _temporary_ solution, and will remove the fallback in an upcoming major release.\n\n### [Linux containers on Windows (LCOW) (experimental)](#linux-containers-on-windows-lcow-experimental)\n\n**Deprecated in Release: v20.10** **Removed in Release: v23.0**\n\nThe experimental feature to run Linux containers on Windows (LCOW) was introduced as a technical preview in Docker 17.09. While many enhancements were made after its introduction, the feature never reached completeness, and development has now stopped in favor of running docker natively on Linux in WSL2.\n\nDevelopers who want to run Linux workloads on a Windows host are encouraged to use [Docker Desktop with WSL2](https://docs.docker.com/docker-for-windows/wsl/) instead.\n\n### [BLKIO weight options with cgroups v1](#blkio-weight-options-with-cgroups-v1)\n\n**Deprecated in Release: v20.10**\n\nSpecifying blkio weight (`docker run --blkio-weight` and `docker run --blkio-weight-device`) is now marked as deprecated when using cgroups v1 because the corresponding features were [removed in Linux kernel v5.0 and up](https://github.com/torvalds/linux/commit/f382fb0bcef4c37dc049e9f6963e3baf204d815c). When using cgroups v2, the `--blkio-weight` options are implemented using [\\`io.weight](https://github.com/torvalds/linux/blob/v5.0/Documentation/admin-guide/cgroup-v2.rst#io).\n\n### [Kernel memory limit](#kernel-memory-limit)\n\n**Deprecated in Release: v20.10** **Removed in Release: v23.0**\n\nSpecifying kernel memory limit (`docker run --kernel-memory`) is no longer supported because the [Linux kernel deprecated `kmem.limit_in_bytes` in v5.4](https://github.com/torvalds/linux/commit/0158115f702b0ba208ab0b5adf44cae99b3ebcc7). The OCI runtime specification now marks this option (as well as `--kernel-memory-tcp`) as [\"NOT RECOMMENDED\"](https://github.com/opencontainers/runtime-spec/pull/1093), and OCI runtimes such as `runc` no longer support this option.\n\nDocker API v1.42 and up now ignores this option when set. Older versions of the API continue to accept the option, but depending on the OCI runtime used, may take no effect.\n\n> **Note**\n> \n> While not deprecated (yet) in Docker, the OCI runtime specification also deprecated the `memory.kmem.tcp.limit_in_bytes` option. When using `runc` as runtime, this option takes no effect. The linux kernel did not explicitly deprecate this feature, and there is a tracking ticket in the `runc` issue tracker to determine if this option should be reinstated or if this was an oversight of the Linux kernel maintainers (see [opencontainers/runc#3174](https://github.com/opencontainers/runc/issues/3174)).\n> \n> The `memory.kmem.tcp.limit_in_bytes` option is only supported with cgroups v1, and not available on installations running with cgroups v2. This option is only supported by the API, and not exposed on the `docker` command-line.\n\n### [Classic Swarm and overlay networks using cluster store](#classic-swarm-and-overlay-networks-using-cluster-store)\n\n**Deprecated in Release: v20.10** **Removed in Release: v23.0**\n\nStandalone (\"classic\") Swarm has been deprecated, and with that the use of overlay networks using an external key/value store. The corresponding`--cluster-advertise`, `--cluster-store`, and `--cluster-store-opt` daemon options have been removed.\n\n### [Support for legacy `~/.dockercfg` configuration files](#support-for-legacy-dockercfg-configuration-files)\n\n**Deprecated in Release: v20.10** **Removed in Release: v23.0**\n\nThe docker CLI up until v1.7.0 used the `~/.dockercfg` file to store credentials after authenticating to a registry (`docker login`). Docker v1.7.0 replaced this file with a new CLI configuration file, located in `~/.docker/config.json`. When implementing the new configuration file, the old file (and file-format) was kept as a fall-back, to assist existing users with migrating to the new file.\n\nGiven that the old file format encourages insecure storage of credentials (credentials are stored unencrypted), and that no version of the CLI since Docker v1.7.0 has created this file, support for this file, and its format has been removed.\n\n### [Configuration options for experimental CLI features](#configuration-options-for-experimental-cli-features)\n\n**Deprecated in Release: v19.03**\n\n**Removed in Release: v23.0**\n\nThe `DOCKER_CLI_EXPERIMENTAL` environment variable and the corresponding `experimental` field in the CLI configuration file are deprecated. Experimental features are enabled by default, and these configuration options are no longer functional.\n\nStarting with v23.0, the Docker CLI no longer prints `Experimental` for the client in the output of `docker version`, and the field has been removed from the JSON format.\n\n### [CLI plugins support](#cli-plugins-support)\n\n**Deprecated in Release: v20.10**\n\nCLI Plugin API is now marked as deprecated.\n\n### [Dockerfile legacy `ENV name value` syntax](#dockerfile-legacy-env-name-value-syntax)\n\n**Deprecated in Release: v20.10**\n\nThe Dockerfile `ENV` instruction allows values to be set using either `ENV name=value` or `ENV name value`. The latter (`ENV name value`) form can be ambiguous, for example, the following defines a single env-variable (`ONE`) with value `\"TWO= THREE=world\"`, but may have intended to be setting three env-vars:\n\nThis format also does not allow setting multiple environment-variables in a single `ENV` line in the Dockerfile.\n\nUse of the `ENV name value` syntax is discouraged, and may be removed in a future release. Users are encouraged to update their Dockerfiles to use the `ENV name=value` syntax, for example:\n\n### [`docker build --stream` flag (experimental)](#docker-build---stream-flag-experimental)\n\n**Deprecated in Release: v20.10** **Removed in Release: v20.10**\n\nDocker v17.07 introduced an experimental `--stream` flag on `docker build` which allowed the build-context to be incrementally sent to the daemon, instead of unconditionally sending the whole build-context.\n\nThis functionality has been reimplemented as part of BuildKit, which uses streaming by default and the `--stream` option will be ignored when using the classic builder, printing a deprecation warning instead.\n\nUsers that want to use this feature are encouraged to enable BuildKit by setting the `DOCKER_BUILDKIT=1` environment variable or through the daemon or CLI configuration files.\n\n### [`fluentd-async-connect` log opt](#fluentd-async-connect-log-opt)\n\n**Deprecated in Release: v20.10**\n\nThe `--log-opt fluentd-async-connect` option for the fluentd logging driver is [deprecated in favor of `--log-opt fluentd-async`](https://github.com/moby/moby/pull/39086). A deprecation message is logged in the daemon logs if the old option is used:\n\nUsers are encouraged to use the `fluentd-async` option going forward, as support for the old option will be removed in a future release.\n\n### [Pushing and pulling with image manifest v2 schema 1](#pushing-and-pulling-with-image-manifest-v2-schema-1)\n\n**Deprecated in Release: v19.03**\n\n**Disabled by default in Release: v26.0**\n\n**Target For Removal In Release: v27.0**\n\nThe image manifest [v2 schema 1](https://distribution.github.io/distribution/spec/deprecated-schema-v1/) and \"Docker Image v1\" formats were deprecated in favor of the [v2 schema 2](https://distribution.github.io/distribution/spec/manifest-v2-2/) and [OCI image spec](https://github.com/opencontainers/image-spec/tree/v1.1.0) formats.\n\nThese legacy formats should no longer be used, and users are recommended to update images to use current formats, or to upgrade to more current images. Starting with Docker v26.0, pulling these images is disabled by default, and produces an error when attempting to pull the image:\n\nAn environment variable (`DOCKER_ENABLE_DEPRECATED_PULL_SCHEMA_1_IMAGE`) is added in Docker v26.0 that allows re-enabling support for these image formats in the daemon. This environment variable must be set to a non-empty value in the daemon's environment (for example, through a [systemd override file](https://docs.docker.com/config/daemon/systemd/)). Support for the `DOCKER_ENABLE_DEPRECATED_PULL_SCHEMA_1_IMAGE` environment variable will be removed in Docker v27.0 after which this functionality is removed permanently.\n\n### [`docker engine` subcommands](#docker-engine-subcommands)\n\n**Deprecated in Release: v19.03**\n\n**Removed in Release: v20.10**\n\nThe `docker engine activate`, `docker engine check`, and `docker engine update` provided an alternative installation method to upgrade Docker Community engines to Docker Enterprise, using an image-based distribution of the Docker Engine.\n\nThis feature was only available on Linux, and only when executed on a local node. Given the limitations of this feature, and the feature not getting widely adopted, the `docker engine` subcommands will be removed, in favor of installation through standard package managers.\n\n### [Top-level `docker deploy` subcommand (experimental)](#top-level-docker-deploy-subcommand-experimental)\n\n**Deprecated in Release: v19.03**\n\n**Removed in Release: v20.10**\n\nThe top-level `docker deploy` command (using the \"Docker Application Bundle\" (.dab) file format was introduced as an experimental feature in Docker 1.13 / 17.03, but superseded by support for Docker Compose files using the `docker stack deploy` subcommand.\n\n### [`docker stack deploy` using \"dab\" files (experimental)](#docker-stack-deploy-using-dab-files-experimental)\n\n**Deprecated in Release: v19.03**\n\n**Removed in Release: v20.10**\n\nWith no development being done on this feature, and no active use of the file format, support for the DAB file format and the top-level docker deploy command (hidden by default in 19.03), will be removed, in favour of `docker stack deploy` using compose files.\n\n### [Support for the `overlay2.override_kernel_check` storage option](#support-for-the-overlay2override_kernel_check-storage-option)\n\n**Deprecated in Release: v19.03** **Removed in Release: v24.0**\n\nThis daemon configuration option disabled the Linux kernel version check used to detect if the kernel supported OverlayFS with multiple lower dirs, which is required for the overlay2 storage driver. Starting with Docker v19.03.7, the detection was improved to no longer depend on the kernel _version_, so this option was no longer used.\n\n### [AuFS storage driver](#aufs-storage-driver)\n\n**Deprecated in Release: v19.03** **Removed in Release: v24.0**\n\nThe `aufs` storage driver is deprecated in favor of `overlay2`, and has been removed in a Docker Engine v24.0. Users of the `aufs` storage driver must migrate to a different storage driver, such as `overlay2`, before upgrading to Docker Engine v24.0.\n\nThe `aufs` storage driver facilitated running Docker on distros that have no support for OverlayFS, such as Ubuntu 14.04 LTS, which originally shipped with a 3.14 kernel.\n\nNow that Ubuntu 14.04 is no longer a supported distro for Docker, and `overlay2` is available to all supported distros (as they are either on kernel 4.x, or have support for multiple lowerdirs backported), there is no reason to continue maintenance of the `aufs` storage driver.\n\n### [Legacy overlay storage driver](#legacy-overlay-storage-driver)\n\n**Deprecated in Release: v18.09** **Removed in Release: v24.0**\n\nThe `overlay` storage driver is deprecated in favor of the `overlay2` storage driver, which has all the benefits of `overlay`, without its limitations (excessive inode consumption). The legacy `overlay` storage driver has been removed in Docker Engine v24.0. Users of the `overlay` storage driver should migrate to the `overlay2` storage driver before upgrading to Docker Engine v24.0.\n\nThe legacy `overlay` storage driver allowed using overlayFS-backed filesystems on pre 4.x kernels. Now that all supported distributions are able to run `overlay2` (as they are either on kernel 4.x, or have support for multiple lowerdirs backported), there is no reason to keep maintaining the `overlay` storage driver.\n\n### [Device mapper storage driver](#device-mapper-storage-driver)\n\n**Deprecated in Release: v18.09** **Disabled by default in Release: v23.0** **Removed in Release: v25.0**\n\nThe `devicemapper` storage driver is deprecated in favor of `overlay2`, and has been removed in Docker Engine v25.0. Users of the `devicemapper` storage driver must migrate to a different storage driver, such as `overlay2`, before upgrading to Docker Engine v25.0.\n\nThe `devicemapper` storage driver facilitates running Docker on older (3.x) kernels that have no support for other storage drivers (such as overlay2, or btrfs).\n\nNow that support for `overlay2` is added to all supported distros (as they are either on kernel 4.x, or have support for multiple lowerdirs backported), there is no reason to continue maintenance of the `devicemapper` storage driver.\n\n### [Use of reserved namespaces in engine labels](#use-of-reserved-namespaces-in-engine-labels)\n\n**Deprecated in Release: v18.06**\n\n**Removed In Release: v20.10**\n\nThe namespaces `com.docker.*`, `io.docker.*`, and `org.dockerproject.*` in engine labels were always documented to be reserved, but there was never any enforcement.\n\nUsage of these namespaces will now cause a warning in the engine logs to discourage their use, and will error instead in v20.10 and above.\n\n### [`--disable-legacy-registry` override daemon option](#--disable-legacy-registry-override-daemon-option)\n\n**Disabled In Release: v17.12**\n\n**Removed In Release: v19.03**\n\nThe `--disable-legacy-registry` flag was disabled in Docker 17.12 and will print an error when used. For this error to be printed, the flag itself is still present, but hidden. The flag has been removed in Docker 19.03.\n\n### [Interacting with V1 registries](#interacting-with-v1-registries)\n\n**Disabled By Default In Release: v17.06**\n\n**Removed In Release: v17.12**\n\nVersion 1.8.3 added a flag (`--disable-legacy-registry=false`) which prevents the docker daemon from `pull`, `push`, and `login` operations against v1 registries. Though enabled by default, this signals the intent to deprecate the v1 protocol.\n\nSupport for the v1 protocol to the public registry was removed in 1.13. Any mirror configurations using v1 should be updated to use a [v2 registry mirror](https://docs.docker.com/registry/recipes/mirror/).\n\nStarting with Docker 17.12, support for V1 registries has been removed, and the `--disable-legacy-registry` flag can no longer be used, and `dockerd` will fail to start when set.\n\n### [Asynchronous `service create` and `service update` as default](#asynchronous-service-create-and-service-update-as-default)\n\n**Deprecated In Release: v17.05**\n\n**Disabled by default in release: [v17.10](https://github.com/docker/docker-ce/releases/tag/v17.10.0-ce)**\n\nDocker 17.05 added an optional `--detach=false` option to make the `docker service create` and `docker service update` work synchronously. This option will be enabled by default in Docker 17.10, at which point the `--detach` flag can be used to use the previous (asynchronous) behavior.\n\nThe default for this option will also be changed accordingly for `docker service rollback` and `docker service scale` in Docker 17.10.\n\n### [`-g` and `--graph` flags on `dockerd`](#-g-and---graph-flags-on-dockerd)\n\n**Deprecated In Release: v17.05**\n\n**Removed In Release: v23.0**\n\nThe `-g` or `--graph` flag for the `dockerd` or `docker daemon` command was used to indicate the directory in which to store persistent data and resource configuration and has been replaced with the more descriptive `--data-root` flag. These flags were deprecated and hidden in v17.05, and removed in v23.0.\n\n### [Top-level network properties in NetworkSettings](#top-level-network-properties-in-networksettings)\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Target For Removal In Release: v17.12**\n\nWhen inspecting a container, `NetworkSettings` contains top-level information about the default (\"bridge\") network;\n\n`EndpointID`, `Gateway`, `GlobalIPv6Address`, `GlobalIPv6PrefixLen`, `IPAddress`, `IPPrefixLen`, `IPv6Gateway`, and `MacAddress`.\n\nThese properties are deprecated in favor of per-network properties in `NetworkSettings.Networks`. These properties were already \"deprecated\" in docker 1.9, but kept around for backward compatibility.\n\nRefer to [#17538](https://github.com/docker/docker/pull/17538) for further information.\n\n### [`filter` param for `/images/json` endpoint](#filter-param-for-imagesjson-endpoint)\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Removed In Release: v20.10**\n\nThe `filter` param to filter the list of image by reference (name or name:tag) is now implemented as a regular filter, named `reference`.\n\n### [`repository:shortid` image references](#repositoryshortid-image-references)\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Removed In Release: v17.12**\n\nThe `repository:shortid` syntax for referencing images is very little used, collides with tag references, and can be confused with digest references.\n\nSupport for the `repository:shortid` notation to reference images was removed in Docker 17.12.\n\n### [`docker daemon` subcommand](#docker-daemon-subcommand)\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Removed In Release: v17.12**\n\nThe daemon is moved to a separate binary (`dockerd`), and should be used instead.\n\n### [Duplicate keys with conflicting values in engine labels](#duplicate-keys-with-conflicting-values-in-engine-labels)\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Removed In Release: v17.12**\n\nWhen setting duplicate keys with conflicting values, an error will be produced, and the daemon will fail to start.\n\n### [`MAINTAINER` in Dockerfile](#maintainer-in-dockerfile)\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n`MAINTAINER` was an early very limited form of `LABEL` which should be used instead.\n\n### [API calls without a version](#api-calls-without-a-version)\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Target For Removal In Release: v17.12**\n\nAPI versions should be supplied to all API calls to ensure compatibility with future Engine versions. Instead of just requesting, for example, the URL `/containers/json`, you must now request `/v1.25/containers/json`.\n\n### [Backing filesystem without `d_type` support for overlay/overlay2](#backing-filesystem-without-d_type-support-for-overlayoverlay2)\n\n**Deprecated In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\n**Removed In Release: v17.12**\n\nThe overlay and overlay2 storage driver does not work as expected if the backing filesystem does not support `d_type`. For example, XFS does not support `d_type` if it is formatted with the `ftype=0` option.\n\nSupport for these setups has been removed, and Docker v23.0 and up now fails to start when attempting to use the `overlay2` or `overlay` storage driver on a backing filesystem without `d_type` support.\n\nRefer to [#27358](https://github.com/docker/docker/issues/27358) for details.\n\n### [`--automated` and `--stars` flags on `docker search`](#--automated-and---stars-flags-on-docker-search)\n\n**Deprecated in Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\n**Removed In Release: v20.10**\n\nThe `docker search --automated` and `docker search --stars` options are deprecated. Use `docker search --filter=is-automated=<true|false>` and `docker search --filter=stars=...` instead.\n\n### [`-h` shorthand for `--help`](#-h-shorthand-for---help)\n\n**Deprecated In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\n**Target For Removal In Release: v17.09**\n\nThe shorthand (`-h`) is less common than `--help` on Linux and cannot be used on all subcommands (due to it conflicting with, e.g. `-h` / `--hostname` on `docker create`). For this reason, the `-h` shorthand was not printed in the \"usage\" output of subcommands, nor documented, and is now marked \"deprecated\".\n\n### [`-e` and `--email` flags on `docker login`](#-e-and---email-flags-on-docker-login)\n\n**Deprecated In Release: [v1.11.0](https://github.com/docker/docker/releases/tag/v1.11.0)**\n\n**Removed In Release: [v17.06](https://github.com/docker/docker-ce/releases/tag/v17.06.0-ce)**\n\nThe docker login command is removing the ability to automatically register for an account with the target registry if the given username doesn't exist. Due to this change, the email flag is no longer required, and will be deprecated.\n\n### [Separator (`:`) of `--security-opt` flag on `docker run`](#separator--of---security-opt-flag-on-docker-run)\n\n**Deprecated In Release: [v1.11.0](https://github.com/docker/docker/releases/tag/v1.11.0)**\n\n**Target For Removal In Release: v17.06**\n\nThe flag `--security-opt` doesn't use the colon separator (`:`) anymore to divide keys and values, it uses the equal symbol (`=`) for consistency with other similar flags, like `--storage-opt`.\n\n### [Ambiguous event fields in API](#ambiguous-event-fields-in-api)\n\n**Deprecated In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\nThe fields `ID`, `Status` and `From` in the events API have been deprecated in favor of a more rich structure. See the events API documentation for the new format.\n\n### [`-f` flag on `docker tag`](#-f-flag-on-docker-tag)\n\n**Deprecated In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nTo make tagging consistent across the various `docker` commands, the `-f` flag on the `docker tag` command is deprecated. It is no longer necessary to specify `-f` to move a tag from one image to another. Nor will `docker` generate an error if the `-f` flag is missing and the specified tag is already in use.\n\n### [HostConfig at API container start](#hostconfig-at-api-container-start)\n\n**Deprecated In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nPassing an `HostConfig` to `POST /containers/{name}/start` is deprecated in favor of defining it at container creation (`POST /containers/create`).\n\n### [`--before` and `--since` flags on `docker ps`](#--before-and---since-flags-on-docker-ps)\n\n**Deprecated In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nThe `docker ps --before` and `docker ps --since` options are deprecated. Use `docker ps --filter=before=...` and `docker ps --filter=since=...` instead.\n\n### [Driver-specific log tags](#driver-specific-log-tags)\n\n**Deprecated In Release: [v1.9.0](https://github.com/docker/docker/releases/tag/v1.9.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nLog tags are now generated in a standard way across different logging drivers. Because of which, the driver specific log tag options `syslog-tag`, `gelf-tag` and `fluentd-tag` have been deprecated in favor of the generic `tag` option.\n\n### [Docker Content Trust ENV passphrase variables name change](#docker-content-trust-env-passphrase-variables-name-change)\n\n**Deprecated In Release: [v1.9.0](https://github.com/docker/docker/releases/tag/v1.9.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nSince 1.9, Docker Content Trust Offline key has been renamed to Root key and the Tagging key has been renamed to Repository key. Due to this renaming, we're also changing the corresponding environment variables\n\n*   DOCKER\\_CONTENT\\_TRUST\\_OFFLINE\\_PASSPHRASE is now named DOCKER\\_CONTENT\\_TRUST\\_ROOT\\_PASSPHRASE\n*   DOCKER\\_CONTENT\\_TRUST\\_TAGGING\\_PASSPHRASE is now named DOCKER\\_CONTENT\\_TRUST\\_REPOSITORY\\_PASSPHRASE\n\n### [`/containers/(id or name)/copy` endpoint](#containersid-or-namecopy-endpoint)\n\n**Deprecated In Release: [v1.8.0](https://github.com/docker/docker/releases/tag/v1.8.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nThe endpoint `/containers/(id or name)/copy` is deprecated in favor of `/containers/(id or name)/archive`.\n\n### [LXC built-in exec driver](#lxc-built-in-exec-driver)\n\n**Deprecated In Release: [v1.8.0](https://github.com/docker/docker/releases/tag/v1.8.0)**\n\n**Removed In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\nThe built-in LXC execution driver, the lxc-conf flag, and API fields have been removed.\n\n### [Old Command Line Options](#old-command-line-options)\n\n**Deprecated In Release: [v1.8.0](https://github.com/docker/docker/releases/tag/v1.8.0)**\n\n**Removed In Release: [v1.10.0](https://github.com/docker/docker/releases/tag/v1.10.0)**\n\nThe flags `-d` and `--daemon` are deprecated in favor of the `daemon` subcommand:\n\n```\ndocker daemon -H ...\n```\n\nThe following single-dash (`-opt`) variant of certain command line options are deprecated and replaced with double-dash options (`--opt`):\n\n```\ndocker attach -nostdin\ndocker attach -sig-proxy\ndocker build -no-cache\ndocker build -rm\ndocker commit -author\ndocker commit -run\ndocker events -since\ndocker history -notrunc\ndocker images -notrunc\ndocker inspect -format\ndocker ps -beforeId\ndocker ps -notrunc\ndocker ps -sinceId\ndocker rm -link\ndocker run -cidfile\ndocker run -dns\ndocker run -entrypoint\ndocker run -expose\ndocker run -link\ndocker run -lxc-conf\ndocker run -n\ndocker run -privileged\ndocker run -volumes-from\ndocker search -notrunc\ndocker search -stars\ndocker search -t\ndocker search -trusted\ndocker tag -force\n```\n\nThe following double-dash options are deprecated and have no replacement:\n\n```\ndocker run --cpuset\ndocker run --networking\ndocker ps --since-id\ndocker ps --before-id\ndocker search --trusted\n```\n\n**Deprecated In Release: [v1.5.0](https://github.com/docker/docker/releases/tag/v1.5.0)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nThe single-dash (`-help`) was removed, in favor of the double-dash `--help`\n\n```\ndocker -help\ndocker [COMMAND] -help\n```\n\n### [`--api-enable-cors` flag on dockerd](#--api-enable-cors-flag-on-dockerd)\n\n**Deprecated In Release: [v1.6.0](https://github.com/docker/docker/releases/tag/v1.6.0)**\n\n**Removed In Release: [v17.09](https://github.com/docker/docker-ce/releases/tag/v17.09.0-ce)**\n\nThe flag `--api-enable-cors` is deprecated since v1.6.0. Use the flag `--api-cors-header` instead.\n\n### [`--run` flag on docker commit](#--run-flag-on-docker-commit)\n\n**Deprecated In Release: [v0.10.0](https://github.com/docker/docker/releases/tag/v0.10.0)**\n\n**Removed In Release: [v1.13.0](https://github.com/docker/docker/releases/tag/v1.13.0)**\n\nThe flag `--run` of the docker commit (and its short version `-run`) were deprecated in favor of the `--changes` flag that allows to pass `Dockerfile` commands.\n\n### [Three arguments form in `docker import`](#three-arguments-form-in-docker-import)\n\n**Deprecated In Release: [v0.6.7](https://github.com/docker/docker/releases/tag/v0.6.7)**\n\n**Removed In Release: [v1.12.0](https://github.com/docker/docker/releases/tag/v1.12.0)**\n\nThe `docker import` command format `file|URL|- [REPOSITORY [TAG]]` is deprecated since November 2013. It's no more supported.",
    "title": "Deprecated Engine Features | Docker Docs\n",
    "description": "Deprecated Features.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/checks/",
    "markdown": "# Checking your build configuration | Docker Docs\n\nIntroduced in Buildx version 0.15.0\n\nBuild checks are a feature introduced in Dockerfile 1.8. It lets you validate your build configuration and conduct a series of checks prior to executing your build. Think of it as an advanced form of linting for your Dockerfile and build options, or a dry-run mode for builds.\n\nYou can find the list of checks available, and a description of each, in the [Build checks reference](https://docs.docker.com/reference/build-checks/).\n\nTypically, when you run a build, Docker executes the build steps in your Dockerfile and build options as specified. With build checks, rather than executing the build steps, Docker checks the Dockerfile and options you provide and reports any issues it detects.\n\nBuild checks are useful for:\n\n*   Validating your Dockerfile and build options before running a build.\n*   Ensuring that your Dockerfile and build options are up-to-date with the latest best practices.\n*   Identifying potential issues or anti-patterns in your Dockerfile and build options.\n\nBuild checks are supported in Buildx version 0.15.0 and later. Invoking a build runs the checks by default, and displays any violations in the build output. For example, the following command both builds the image and runs the checks:\n\nIn this example, the build ran successfully, but a [JSONArgsRecommended](https://docs.docker.com/reference/build-checks/json-args-recommended/) warning was reported, because `CMD` instructions should use JSON array syntax.\n\n### [More verbose output](#more-verbose-output)\n\nCheck warnings for a regular `docker build` display a concise message containing the rule name, the message, and the line number of where in the Dockerfile the issue originated. If you want to see more detailed information about the checks, you can use the `--debug` flag. For example:\n\nWith the `--debug` flag, the output includes a link to the documentation for the check, and a snippet of the Dockerfile where the issue was found.\n\nTo run build checks without actually building, you can use the `docker build` command as you typically would, but with the addition of the `--check` flag. Here's an example:\n\nInstead of executing the build steps, this command only runs the checks and reports any issues it finds. If there are any issues, they will be reported in the output. For example:\n\nThis output with `--check` shows the [verbose message](#more-verbose-output) for the check.\n\nUnlike a regular build, if any violations are reported when using the `--check` flag, the command exits with a non-zero status code.\n\nCheck violations for builds are reported as warnings, with exit code 0, by default. You can configure Docker to fail the build when violations are reported, using a `check=error=true` directive in your Dockerfile. This will cause the build to error out when after the build checks are run, before the actual build gets executed.\n\nWithout the `# check=error=true` directive, this build would complete with an exit code of 0. However, with the directive, build check violation results in non-zero exit code:\n\nYou can also set the error directive on the CLI by passing the `BUILDKIT_DOCKERFILE_CHECK` build argument:\n\nBy default, all checks are run when you build an image. If you want to skip specific checks, you can use the `check=skip` directive in your Dockerfile. The `skip` parameter takes a CSV string of the check IDs you want to skip. For example:\n\nBuilding this Dockerfile results in no check violations.\n\nYou can also skip checks by passing the `BUILDKIT_DOCKERFILE_CHECK` build argument with a CSV string of check IDs you want to skip. For example:\n\nTo both skip specific checks and error on check violations, pass both the `skip` and `error` parameters separated by a semi-colon (`;`) to the `check` directive in your Dockerfile or in a build argument. For example:",
    "title": "Checking your build configuration | Docker Docs\n",
    "description": "Learn how to use build checks to validate your build configuration.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/27.0/",
    "markdown": "# Docker Engine 27.0 release notes\n\nThis page describes the latest changes, additions, known issues, and fixes for Docker Engine version 27.0.\n\nFor more information about:\n\n*   Deprecated and removed features, see [Deprecated Engine Features](https://docs.docker.com/engine/deprecated/).\n*   Changes to the Engine API, see [Engine API version history](https://docs.docker.com/engine/api/version-history/).\n\n_2024-07-01_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 27.0.3 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A27.0.3)\n*   [moby/moby, 27.0.3 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A27.0.3)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v27.0.3/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v27.0.3/docs/api/version-history.md).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements)\n\n*   Fix a regression that incorrectly reported a port mapping from a host IPv6 address to an IPv4-only container as an error. [moby/moby#48090](https://github.com/moby/moby/pull/48090)\n*   Fix a regression that caused duplicate subnet allocations when creating networks. [moby/moby#48089](https://github.com/moby/moby/pull/48089)\n*   Fix a regression resulting in `fail to register layer: failed to Lchown` errors when trying to pull an image with rootless enabled on a system that supports native overlay with user-namespaces. [moby/moby#48086](https://github.com/moby/moby/pull/48086)\n\n_2024-06-27_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 27.0.2 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A27.0.2)\n*   [moby/moby, 27.0.2 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A27.0.2)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v27.0.2/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v27.0.2/docs/api/version-history.md).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-1)\n\n*   Fix a regression that caused port numbers to be ignored when parsing a Docker registry URL. [docker/cli#5197](https://github.com/docker/cli/pull/5197), [docker/cli#5198](https://github.com/docker/cli/pull/5198)\n\n### [Removed](#removed)\n\n*   api/types: deprecate `ContainerJSONBase.Node` field and `ContainerNode` type. These definitions were used by the standalone (\"classic\") Swarm API, but never implemented in the Docker Engine itself. [moby/moby#48055](https://github.com/moby/moby/pull/48055)\n\n_2024-06-24_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 27.0.0 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A27.0.0)\n*   [moby/moby, 27.0.0 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A27.0.0)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v27.0.1/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v27.0.1/docs/api/version-history.md).\n\n### [New](#new)\n\n*   containerd image store: Add `--platform` flag to `docker image push` and improve the default behavior when not all platforms of the multi-platform image are available locally. [docker/cli#4984](https://github.com/docker/cli/pull/4984), [moby/moby#47679](https://github.com/moby/moby/pull/47679)\n*   Add support to `docker stack deploy` for `driver_opts` in a service's networks. [docker/cli#5125](https://github.com/docker/cli/pull/5125)\n*   Consider additional `/usr/local/libexec` and `/usr/libexec` paths when looking up the userland proxy binaries by a name with a `docker-` prefix. [moby/moby#47804](https://github.com/moby/moby/pull/47804)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-2)\n\n*   `*client.Client` instances are now always safe for concurrent use by multiple goroutines. Previously, this could lead to data races when the `WithAPIVersionNegotiation()` option is used. [moby/moby#47961](https://github.com/moby/moby/pull/47961)\n*   Fix a bug causing the Docker CLI to leak Unix sockets in `$TMPDIR` in some cases. [docker/cli#5146](https://github.com/docker/cli/pull/5146)\n*   Don't ignore a custom seccomp profile when used in conjunction with `--privileged`. [moby/moby#47500](https://github.com/moby/moby/pull/47500)\n*   rootless: overlay2: support native overlay diff when using rootless-mode with Linux kernel version 5.11 and later. [moby/moby#47605](https://github.com/moby/moby/pull/47605)\n*   Fix the `StartInterval` default value of healthcheck to reflect the documented value of 5s. [moby/moby#47799](https://github.com/moby/moby/pull/47799)\n*   Fix `docker save` and `docker load` not ending on the daemon side when the operation was cancelled by the user, for example with Ctrl+C. [moby/moby#47629](https://github.com/moby/moby/pull/47629)\n*   The `StartedAt` property of containers is now recorded before container startup, guaranteeing that the `StartedAt` is always before `FinishedAt`. [moby/moby#47003](https://github.com/moby/moby/pull/47003)\n*   The internal DNS resolver used by Windows containers on Windows now forwards requests to external DNS servers by default. This enables `nslookup` to resolve external hostnames. This behaviour can be disabled via `daemon.json`, using `\"features\": { \"windows-dns-proxy\": false }`. The configuration option will be removed in a future release. [moby/moby#47826](https://github.com/moby/moby/pull/47826)\n*   Print a warning when the CLI does not have permissions to read the configuration file. [docker/cli#5077](https://github.com/docker/cli/pull/5077)\n*   Fix a goroutine and file-descriptor leak on container attach. [moby/moby#45052](https://github.com/moby/moby/pull/45052)\n*   Clear the networking state of all stopped or dead containers during daemon start-up. [moby/moby#47984](https://github.com/moby/moby/pull/47984)\n*   Write volume options JSON atomically to avoid \"invalid JSON\" errors after system crash. [moby/moby#48034](https://github.com/moby/moby/pull/48034)\n*   Allow multiple macvlan networks with the same parent. [moby/moby#47318](https://github.com/moby/moby/pull/47318)\n*   Allow BuildKit to be used on Windows daemons that advertise it. [docker/cli#5178](https://github.com/docker/cli/pull/5178)\n\n### [Networking](#networking)\n\n*   Allow sysctls to be set per-interface during container creation and network connection. [moby/moby#47686](https://github.com/moby/moby/pull/47686)\n    *   In a future release, this will be the only way to set per-interface sysctl options. For example, on the command line in a `docker run` command,`--network mynet --sysctl net.ipv4.conf.eth0.log_martians=1` will be rejected. Instead, you must use `--network name=mynet,driver-opt=com.docker.network.endpoint.sysctls=net.ipv4.conf.IFNAME.log_martians=1`.\n\n#### [IPv6](#ipv6)\n\n*   `ip6tables` is no longer experimental. You may remove the `experimental` configuration option and continue to use IPv6, if it is not required by any other features.\n*   `ip6tables` is now enabled for Linux bridge networks by default. [moby/moby#47747](https://github.com/moby/moby/pull/47747)\n    *   This makes IPv4 and IPv6 behaviors consistent with each other, and reduces the risk that IPv6-enabled containers are inadvertently exposed to the network.\n    *   There is no impact if you are running Docker Engine with `ip6tables` enabled (new default).\n    *   If you are using an IPv6-enabled bridge network without `ip6tables`, this is likely a breaking change. Only published container ports (`-p` or `--publish`) are accessible from outside the Docker bridge network, and outgoing connections masquerade as the host.\n    *   To restore the behavior of earlier releases, no `ip6tables` at all, set `\"ip6tables\": false` in `daemon.json`, or use the CLI option `--ip6tables=false`. Alternatively, leave `ip6tables` enabled, publish ports, and enable direct routing.\n    *   With `ip6tables` enabled, if `ip6tables` is not functional on your host, Docker Engine will start but it will not be possible to create an IPv6-enabled network.\n\n#### [IPv6 network configuration improvements](#ipv6-network-configuration-improvements)\n\n*   A Unique Local Address (ULA) base prefix is automatically added to `default-address-pools` if this parameter wasn't manually configured, or if it contains no IPv6 prefixes. [moby/moby#47853](https://github.com/moby/moby/pull/47853)\n    *   Prior to this release, to create an IPv6-enabled network it was necessary to use the `--subnet` option to specify an IPv6 subnet, or add IPv6 ranges to `default-address-pools` in `daemon.json`.\n    *   Starting in this release, when a bridge network is created with `--ipv6` and no IPv6 subnet is defined by those options, an IPv6 Unique Local Address (ULA) base prefix is used.\n    *   The ULA prefix is derived from the Engine host ID such that it's unique across hosts and over time.\n*   IPv6 address pools of any size can now be added to `default-address-pools`. [moby/moby#47768](https://github.com/moby/moby/pull/47768)\n*   IPv6 can now be enabled by default on all custom bridge networks using `\"default-network-opts\": { \"bridge\": {\"com.docker.network.enable_ipv6\": \"true\"}}` in `daemon.json`, or `dockerd --default-network-opt=bridge=com.docker.network.enable_ipv6=true`on the comand line. [moby/moby#47867](https://github.com/moby/moby/pull/47867)\n*   Direct routing for IPv6 networks, with `ip6tables` enabled. [moby/moby#47871](https://github.com/moby/moby/pull/47871)\n    *   Added bridge driver option `com.docker.network.bridge.gateway_mode_ipv6=<nat|routed>`.\n    *   The default behavior, `nat`, is unchanged from previous releases running with `ip6tables` enabled. NAT and masquerading rules are set up for each published container port.\n    *   When set to `routed`, no NAT or masquerading rules are configured for published ports. This enables direct IPv6 access to the container, if the host's network can route packets for the container's address to the host. Published ports will be opened in the container's firewall.\n    *   When a port mapping only applies to `routed` mode, only addresses `0.0.0.0` or `::` are allowed and a host port must not be given.\n    *   Note that published container ports, in `nat` or `routed` mode, are accessible from any remote address if routing is set up in the network, unless the Docker host's firewall has additional restrictions. For example: `docker network create --ipv6 -o com.docker.network.bridge.gateway_mode_ipv6=routed mynet`.\n    *   The option `com.docker.network.bridge.gateway_mode_ipv4=<nat|routed>` is also available, with the same behavior but for IPv4.\n*   If firewalld is running on the host, Docker creates policy `docker-forwarding` to allow forwarding from any zone to the `docker` zone. This makes it possible to configure a bridge network with a routable IPv6 address, and no NAT or masquerading. [moby/moby#47745](https://github.com/moby/moby/pull/47745)\n*   When a port is published with no host port specified, or a host port range is given, the same port will be allocated for IPv4 and IPv6. [moby/moby#47871](https://github.com/moby/moby/pull/47871)\n    *   For example `-p 80` will result in the same ephemeral port being allocated for `0.0.0.0` and `::`, and `-p 8080-8083:80` will pick the same port from the range for both address families.\n    *   Similarly, ports published to specific addresses will be allocated the same port. For example, `-p 127.0.0.1::80 -p '[::1]::80'`.\n    *   If no port is available on all required addresses, container creation will fail.\n*   Environment variable `DOCKER_ALLOW_IPV6_ON_IPV4_INTERFACE`, introduced in release 26.1.1, no longer has any effect. [moby/moby#47963](https://github.com/moby/moby/pull/47963)\n    *   If IPv6 could not be disabled on an interface because of a read-only `/proc/sys/net`, the environment variable allowed the container to start anyway.\n    *   In this release, if IPv4 cannot be disabled for an interface, IPv6 can be explicitly enabled for the network simply by using `--ipv6` when creating it. Other workarounds are to configure the OS to disable IPv6 by default on new interfaces, mount `/proc/sys/net` read-write, or use a kernel with no IPv6 support.\n*   For IPv6-enabled bridge networks, do not attempt to replace the bridge's kernel-assigned link local address with `fe80::1`. [moby/moby#47787](https://github.com/moby/moby/pull/47787)\n\n### [Removed](#removed-1)\n\n*   Deprecate experimental GraphDriver plugins. [moby/moby#48050](https://github.com/moby/moby/pull/48050), [docker/cli#5172](https://github.com/docker/cli/pull/5172)\n*   pkg/archive: deprecate `NewTempArchive` and `TempArchive`. These types were only used in tests and will be removed in the next release. [moby/moby#48002](https://github.com/moby/moby/pull/48002)\n*   pkg/archive: deprecate `CanonicalTarNameForPath` [moby/moby#48001](https://github.com/moby/moby/pull/48001)\n*   Deprecate pkg/dmesg. This package was no longer used, and will be removed in the next release. [moby/moby#47999](https://github.com/moby/moby/pull/47999)\n*   Deprecate `pkg/stringid.ValidateID` and `pkg/stringid.IsShortID` [moby/moby#47995](https://github.com/moby/moby/pull/47995)\n*   runconfig: deprecate `SetDefaultNetModeIfBlank` and move `ContainerConfigWrapper` to `api/types/container` [moby/moby#48007](https://github.com/moby/moby/pull/48007)\n*   runconfig: deprecate `DefaultDaemonNetworkMode` and move to `daemon/network` [moby/moby#48008](https://github.com/moby/moby/pull/48008)\n*   runconfig: deprecate `opts.ConvertKVStringsToMap`. This utility is no longer used, and will be removed in the next release. [moby/moby#48016](https://github.com/moby/moby/pull/48016)\n*   runconfig: deprecate `IsPreDefinedNetwork`. [moby/moby#48011](https://github.com/moby/moby/pull/48011)\n\n### [API](#api)\n\n*   containerd image store: `POST /images/{name}/push` now supports a `platform` parameter (JSON encoded OCI Platform type) that allows selecting a specific platform-manifest from the multi-platform image. This is experimental and may change in future API versions. [moby/moby#47679](https://github.com/moby/moby/pull/47679)\n*   `POST /services/create` and `POST /services/{id}/update` now support `OomScoreAdj`. [moby/moby#47950](https://github.com/moby/moby/pull/47950)\n*   `ContainerList` api returns container annotations. [moby/moby#47866](https://github.com/moby/moby/pull/47866)\n*   `POST /containers/create` and `POST /services/create` now take `Options` as part of `HostConfig.Mounts.TmpfsOptions` allowing to set options for tmpfs mounts. [moby/moby#46809](https://github.com/moby/moby/pull/46809)\n*   The `Healthcheck.StartInterval` property is now correctly ignored when updating a Swarm service using API versions less than v1.44. [moby/moby#47991](https://github.com/moby/moby/pull/47991)\n*   `GET /events` now supports image `create` event that is emitted when a new image is built regardless if it was tagged or not. [moby/moby#47929](https://github.com/moby/moby/pull/47929)\n*   `GET /info` now includes a `Containerd` field containing information about the location of the containerd API socket and containerd namespaces used by the daemon to run containers and plugins. [moby/moby#47239](https://github.com/moby/moby/pull/47239)\n*   Deprecate non-standard (config) fields in image inspect output. The `Config` field returned by this endpoint (used for `docker image inspect`) returned additional fields that are not part of the image's configuration and not part of the [Docker Image Spec](https://github.com/moby/docker-image-spec/blob/v1.3.1/specs-go/v1/image.go#L19-L32) and the [OCI Image Spec](https://github.com/opencontainers/image-spec/blob/v1.1.0/specs-go/v1/config.go#L24-L62). These fields are never set (and always return the default value for the type), but are not omitted in the response when left empty. As these fields were not intended to be part of the image configuration response, they are deprecated, and will be removed in the future API versions.\n*   Deprecate the daemon flag `--api-cors-header` and the corresponding `daemon.json` configuration option. These will be removed in the next major release. [moby/moby#45313](https://github.com/moby/moby/pull/45313)\n\nThe following deprecated fields are currently included in the API response, but are not part of the underlying image's `Config`: [moby/moby#47941](https://github.com/moby/moby/pull/47941)\n\n*   `Hostname`\n*   `Domainname`\n*   `AttachStdin`\n*   `AttachStdout`\n*   `AttachStderr`\n*   `Tty`\n*   `OpenStdin`\n*   `StdinOnce`\n*   `Image`\n*   `NetworkDisabled` (already omitted unless set)\n*   `MacAddress` (already omitted unless set)\n*   `StopTimeout` (already omitted unless set)\n\n### [Go SDK changes](#go-sdk-changes)\n\n*   Client API callback for the following functions now require a context parameter. [moby/moby#47536](https://github.com/moby/moby/pull/47536)\n    *   `client.RequestPrivilegeFunc`\n    *   `client.ImageSearchOptions.AcceptPermissionsFunc`\n    *   `image.ImportOptions.PrivilegeFunc`\n*   Remove deprecated aliases for Image types. [moby/moby#47900](https://github.com/moby/moby/pull/47900)\n    *   `ImageImportOptions`\n    *   `ImageCreateOptions`\n    *   `ImagePullOptions`\n    *   `ImagePushOptions`\n    *   `ImageListOptions`\n    *   `ImageRemoveOptions`\n*   Introduce `Ulimit` type alias for `github.com/docker/go-units.Ulimit`. The `Ulimit` type as used in the API is defined in a Go module that will transition to a new location in future. A type alias is added to reduce the friction that comes with moving the type to a new location. The alias makes sure that existing code continues to work, but its definition may change in future. Users are recommended to use this alias instead of the `units.Ulimit` directly. [moby/moby#48023](https://github.com/moby/moby/pull/48023)\n\nMove and rename types, changing their import paths and exported names. [moby/moby#47936](https://github.com/moby/moby/pull/47936), [moby/moby#47873](https://github.com/moby/moby/pull/47873), [moby/moby#47887](https://github.com/moby/moby/pull/47887), [moby/moby#47882](https://github.com/moby/moby/pull/47882), [moby/moby#47921](https://github.com/moby/moby/pull/47921), [moby/moby#48040](https://github.com/moby/moby/pull/48040)\n\n*   Move the following types to `api/types/container`:\n    *   `BlkioStatEntry`\n    *   `BlkioStats`\n    *   `CPUStats`\n    *   `CPUUsage`\n    *   `ContainerExecInspect`\n    *   `ContainerPathStat`\n    *   `ContainerStats`\n    *   `ContainersPruneReport`\n    *   `CopyToContainerOptions`\n    *   `ExecConfig`\n    *   `ExecStartCheck`\n    *   `MemoryStats`\n    *   `NetworkStats`\n    *   `PidsStats`\n    *   `StatsJSON`\n    *   `Stats`\n    *   `StorageStats`\n    *   `ThrottlingData`\n*   Move the following types to `api/types/image`:\n    *   `ImagesPruneReport`\n    *   `ImageImportSource`\n    *   `ImageLoadResponse`\n*   Move the `ExecStartOptions` type to `api/types/backend`.\n*   Move the `VolumesPruneReport` type to `api/types/volume`.\n*   Move the `EventsOptions` type to `api/types/events`.\n*   Move the `ImageSearchOptions` type to `api/types/registry`.\n*   Drop `Network` prefix and move the following types to `api/types/network`:\n    *   `NetworkCreateResponse`\n    *   `NetworkConnect`\n    *   `NetworkDisconnect`\n    *   `NetworkInspectOptions`\n    *   `EndpointResource`\n    *   `NetworkListOptions`\n    *   `NetworkCreateOptions`\n    *   `NetworkCreateRequest`\n    *   `NetworksPruneReport`\n*   Move `NetworkResource` to `api/types/network`.\n\n### [Packaging updates](#packaging-updates)\n\n*   Update Buildx to [v0.15.1](https://github.com/docker/buildx/releases/tag/v0.15.1). [docker/docker-ce-packaging#1029](https://github.com/docker/docker-ce-packaging/pull/1029)\n*   Update BuildKit to [v0.14.1](https://github.com/moby/buildkit/releases/tag/v0.14.1). [moby/moby#48028](https://github.com/moby/moby/pull/48028)\n*   Update runc to [v1.1.13](https://github.com/opencontainers/runc/releases/tag/v1.1.13) [moby/moby#47976](https://github.com/moby/moby/pull/47976)\n*   Update Compose to [v2.28.1](https://github.com/docker/compose/releases/tag/v2.28.1). [moby/docker-ce-packaging#1032](https://github.com/docker/docker-ce-packaging/pull/1032)\n\nThere's no 27.0.0 release due to a mistake during the pre-release of 27.0.0-rc.1 on GitHub which resulted in the v27.0.0 tag being created. Unfortunately the tag was already picked up by the [Go Module Mirror](https://sum.golang.org/) so it's not possible to cleanly change the v27.0.0. To workaround this, the 27.0.1 will be the first release of the 27.0.",
    "title": "Docker Engine 27.0 release notes | Docker Docs\n",
    "description": "Learn about the new features, bug fixes, and breaking changes for Docker Engine",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/builders/",
    "markdown": "# Builders | Docker Docs\n\nA builder is a BuildKit daemon that you can use to run your builds. BuildKit is the build engine that solves the build steps in a Dockerfile to produce a container image or other artifacts.\n\nYou can create and manage builders, inspect them, and even connect to builders running remotely. You interact with builders using the Docker CLI.\n\nDocker Engine automatically creates a builder that becomes the default backend for your builds. This builder uses the BuildKit library bundled with the daemon. This builder requires no configuration.\n\nThe default builder is directly bound to the Docker daemon and its [context](https://docs.docker.com/engine/context/working-with-contexts/). If you change the Docker context, your `default` builder refers to the new Docker context.\n\nBuildx implements a concept of [build drivers](https://docs.docker.com/build/drivers/) to refer to different builder configurations. The default builder created by the daemon uses the [`docker` driver](https://docs.docker.com/build/drivers/docker/).\n\nBuildx supports the following build drivers:\n\n*   `docker`: uses the BuildKit library bundled into the Docker daemon.\n*   `docker-container`: creates a dedicated BuildKit container using Docker.\n*   `kubernetes`: creates BuildKit pods in a Kubernetes cluster.\n*   `remote`: connects directly to a manually managed BuildKit daemon.\n\nSelected builder refers to the builder that's used by default when you run build commands.\n\nWhen you run a build, or interact with builders in some way using the CLI, you can use the optional `--builder` flag, or the `BUILDX_BUILDER` [environment variable](https://docs.docker.com/build/building/variables/#buildx_builder), to specify a builder by name. If you don't specify a builder, the selected builder is used.\n\nUse the `docker buildx ls` command to see the available builder instances. The asterisk (`*`) next to a builder name indicates the selected builder.\n\n### [Select a different builder](#select-a-different-builder)\n\nTo switch between builders, use the `docker buildx use <name>` command.\n\nAfter running this command, the builder you specify is automatically selected when you invoke builds.\n\n*   For information about how to interact with and manage builders, see [Manage builders](https://docs.docker.com/build/builders/manage/)\n*   To learn about different types of builders, see [Build drivers](https://docs.docker.com/build/drivers/)",
    "title": "Builders | Docker Docs\n",
    "description": "Learn about builders and how to manage them",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/security/userns-remap/",
    "markdown": "# Isolate containers with a user namespace\n\nLinux namespaces provide isolation for running processes, limiting their access to system resources without the running process being aware of the limitations. For more information on Linux namespaces, see [Linux namespaces](https://www.linux.com/news/understanding-and-securing-linux-namespaces).\n\nThe best way to prevent privilege-escalation attacks from within a container is to configure your container's applications to run as unprivileged users. For containers whose processes must run as the `root` user within the container, you can re-map this user to a less-privileged user on the Docker host. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself.\n\nThe remapping itself is handled by two files: `/etc/subuid` and `/etc/subgid`. Each file works the same, but one is concerned with the user ID range, and the other with the group ID range. Consider the following entry in `/etc/subuid`:\n\nThis means that `testuser` is assigned a subordinate user ID range of `231072` and the next 65536 integers in sequence. UID `231072` is mapped within the namespace (within the container, in this case) as UID `0` (`root`). UID `231073` is mapped as UID `1`, and so forth. If a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, which does not even map to a real user. This means the process has no privileges on the host system at all.\n\n> **Note**\n> \n> It is possible to assign multiple subordinate ranges for a given user or group by adding multiple non-overlapping mappings for the same user or group in the `/etc/subuid` or `/etc/subgid` file. In this case, Docker uses only the first five mappings, in accordance with the kernel's limitation of only five entries in `/proc/self/uid_map` and `/proc/self/gid_map`.\n\nWhen you configure Docker to use the `userns-remap` feature, you can optionally specify an existing user and/or group, or you can specify `default`. If you specify `default`, a user and group `dockremap` is created and used for this purpose.\n\n> **Warning**\n> \n> Some distributions do not automatically add the new group to the `/etc/subuid` and `/etc/subgid` files. If that's the case, you are may have to manually edit these files and assign non-overlapping ranges. This step is covered in [Prerequisites](#prerequisites).\n\nIt is very important that the ranges do not overlap, so that a process cannot gain access in a different namespace. On most Linux distributions, system utilities manage the ranges for you when you add or remove users.\n\nThis re-mapping is transparent to the container, but introduces some configuration complexity in situations where the container needs access to resources on the Docker host, such as bind mounts into areas of the filesystem that the system user cannot write to. From a security standpoint, it is best to avoid these situations.\n\n1.  The subordinate UID and GID ranges must be associated with an existing user, even though the association is an implementation detail. The user owns the namespaced storage directories under `/var/lib/docker/`. If you don't want to use an existing user, Docker can create one for you and use that. If you want to use an existing username or user ID, it must already exist. Typically, this means that the relevant entries need to be in `/etc/passwd` and `/etc/group`, but if you are using a different authentication back-end, this requirement may translate differently.\n    \n    To verify this, use the `id` command:\n    \n2.  The way the namespace remapping is handled on the host is using two files, `/etc/subuid` and `/etc/subgid`. These files are typically managed automatically when you add or remove users or groups, but on some distributions, you may need to manage these files manually.\n    \n    Each file contains three fields: the username or ID of the user, followed by a beginning UID or GID (which is treated as UID or GID 0 within the namespace) and a maximum number of UIDs or GIDs available to the user. For instance, given the following entry:\n    \n    This means that user-namespaced processes started by `testuser` are owned by host UID `231072` (which looks like UID `0` inside the namespace) through 296607 (231072 + 65536 - 1). These ranges should not overlap, to ensure that namespaced processes cannot access each other's namespaces.\n    \n    After adding your user, check `/etc/subuid` and `/etc/subgid` to see if your user has an entry in each. If not, you need to add it, being careful to avoid overlap.\n    \n    If you want to use the `dockremap` user automatically created by Docker, check for the `dockremap` entry in these files after configuring and restarting Docker.\n    \n3.  If there are any locations on the Docker host where the unprivileged user needs to write, adjust the permissions of those locations accordingly. This is also true if you want to use the `dockremap` user automatically created by Docker, but you can't modify the permissions until after configuring and restarting Docker.\n    \n4.  Enabling `userns-remap` effectively masks existing image and container layers, as well as other Docker objects within `/var/lib/docker/`. This is because Docker needs to adjust the ownership of these resources and actually stores them in a subdirectory within `/var/lib/docker/`. It is best to enable this feature on a new Docker installation rather than an existing one.\n    \n    Along the same lines, if you disable `userns-remap` you can't access any of the resources created while it was enabled.\n    \n5.  Check the [limitations](#user-namespace-known-limitations) on user namespaces to be sure your use case is possible.\n    \n\nYou can start `dockerd` with the `--userns-remap` flag or follow this procedure to configure the daemon using the `daemon.json` configuration file. The `daemon.json` method is recommended. If you use the flag, use the following command as a model:\n\n1.  Edit `/etc/docker/daemon.json`. Assuming the file was previously empty, the following entry enables `userns-remap` using user and group called `testuser`. You can address the user and group by ID or name. You only need to specify the group name or ID if it is different from the user name or ID. If you provide both the user and group name or ID, separate them by a colon (`:`) character. The following formats all work for the value, assuming the UID and GID of `testuser` are `1001`:\n    \n    *   `testuser`\n    *   `testuser:testuser`\n    *   `1001`\n    *   `1001:1001`\n    *   `testuser:1001`\n    *   `1001:testuser`\n    \n    > **Note**\n    > \n    > To use the `dockremap` user and have Docker create it for you, set the value to `default` rather than `testuser`.\n    \n    Save the file and restart Docker.\n    \n2.  If you are using the `dockremap` user, verify that Docker created it using the `id` command.\n    \n    Verify that the entry has been added to `/etc/subuid` and `/etc/subgid`:\n    \n    If these entries are not present, edit the files as the `root` user and assign a starting UID and GID that is the highest-assigned one plus the offset (in this case, `65536`). Be careful not to allow any overlap in the ranges.\n    \n3.  Verify that previous images are not available using the `docker image ls` command. The output should be empty.\n    \n4.  Start a container from the `hello-world` image.\n    \n5.  Verify that a namespaced directory exists within `/var/lib/docker/` named with the UID and GID of the namespaced user, owned by that UID and GID, and not group-or-world-readable. Some of the subdirectories are still owned by `root` and have different permissions.\n    \n    Your directory listing may have some differences, especially if you use a different container storage driver than `aufs`.\n    \n    The directories which are owned by the remapped user are used instead of the same directories directly beneath `/var/lib/docker/` and the unused versions (such as `/var/lib/docker/tmp/` in the example here) can be removed. Docker does not use them while `userns-remap` is enabled.\n    \n\nIf you enable user namespaces on the daemon, all containers are started with user namespaces enabled by default. In some situations, such as privileged containers, you may need to disable user namespaces for a specific container. See [user namespace known limitations](#user-namespace-known-limitations) for some of these limitations.\n\nTo disable user namespaces for a specific container, add the `--userns=host` flag to the `docker container create`, `docker container run`, or `docker container exec` command.\n\nThere is a side effect when using this flag: user remapping will not be enabled for that container but, because the read-only (image) layers are shared between containers, ownership of the containers filesystem will still be remapped.\n\nWhat this means is that the whole container filesystem will belong to the user specified in the `--userns-remap` daemon config (`231072` in the example above). This can lead to unexpected behavior of programs inside the container. For instance `sudo` (which checks that its binaries belong to user `0`) or binaries with a `setuid` flag.\n\nThe following standard Docker features are incompatible with running a Docker daemon with user namespaces enabled:\n\n*   Sharing PID or NET namespaces with the host (`--pid=host` or `--network=host`).\n*   External (volume or storage) drivers which are unaware or incapable of using daemon user mappings.\n*   Using the `--privileged` mode flag on `docker run` without also specifying `--userns=host`.\n\nUser namespaces are an advanced feature and require coordination with other capabilities. For example, if volumes are mounted from the host, file ownership must be pre-arranged need read or write access to the volume contents.\n\nWhile the root user inside a user-namespaced container process has many of the expected privileges of the superuser within the container, the Linux kernel imposes restrictions based on internal knowledge that this is a user-namespaced process. One notable restriction is the inability to use the `mknod` command. Permission is denied for device creation within the container when run by the `root` user.",
    "title": "Isolate containers with a user namespace | Docker Docs\n",
    "description": "Isolate containers within a user namespace",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/extend/",
    "markdown": "# Docker Engine managed plugin system\n\n*   [Installing and using a plugin](https://docs.docker.com/engine/extend/#installing-and-using-a-plugin)\n*   [Developing a plugin](https://docs.docker.com/engine/extend/#developing-a-plugin)\n*   [Debugging plugins](https://docs.docker.com/engine/extend/#debugging-plugins)\n\nDocker Engine's plugin system lets you install, start, stop, and remove plugins using Docker Engine.\n\nFor information about legacy (non-managed) plugins, refer to [Understand legacy Docker Engine plugins](https://docs.docker.com/engine/extend/legacy_plugins/).\n\n> **Note**\n> \n> Docker Engine managed plugins are currently not supported on Windows daemons.\n\nPlugins are distributed as Docker images and can be hosted on Docker Hub or on a private registry.\n\nTo install a plugin, use the `docker plugin install` command, which pulls the plugin from Docker Hub or your private registry, prompts you to grant permissions or capabilities if necessary, and enables the plugin.\n\nTo check the status of installed plugins, use the `docker plugin ls` command. Plugins that start successfully are listed as enabled in the output.\n\nAfter a plugin is installed, you can use it as an option for another Docker operation, such as creating a volume.\n\nIn the following example, you install the `sshfs` plugin, verify that it is enabled, and use it to create a volume.\n\n> **Note**\n> \n> This example is intended for instructional purposes only. Once the volume is created, your SSH password to the remote host is exposed as plaintext when inspecting the volume. Delete the volume as soon as you are done with the example.\n\n1.  Install the `sshfs` plugin.\n    \n    The plugin requests 2 privileges:\n    \n    *   It needs access to the `host` network.\n    *   It needs the `CAP_SYS_ADMIN` capability, which allows the plugin to run the `mount` command.\n2.  Check that the plugin is enabled in the output of `docker plugin ls`.\n    \n3.  Create a volume using the plugin. This example mounts the `/remote` directory on host `1.2.3.4` into a volume named `sshvolume`.\n    \n    This volume can now be mounted into containers.\n    \n4.  Verify that the volume was created successfully.\n    \n5.  Start a container that uses the volume `sshvolume`.\n    \n6.  Remove the volume `sshvolume`\n    \n\nTo disable a plugin, use the `docker plugin disable` command. To completely remove it, use the `docker plugin remove` command. For other available commands and options, see the [command line reference](https://docs.docker.com/engine/reference/commandline/cli/).\n\n#### [The rootfs directory](#the-rootfs-directory)\n\nThe `rootfs` directory represents the root filesystem of the plugin. In this example, it was created from a Dockerfile:\n\n> **Note**\n> \n> The `/run/docker/plugins` directory is mandatory inside of the plugin's filesystem for Docker to communicate with the plugin.\n\n#### [The config.json file](#the-configjson-file)\n\nThe `config.json` file describes the plugin. See the [plugins config reference](https://docs.docker.com/engine/extend/config/).\n\nConsider the following `config.json` file.\n\nThis plugin is a volume driver. It requires a `host` network and the `CAP_SYS_ADMIN` capability. It depends upon the `/docker-volume-sshfs` entrypoint and uses the `/run/docker/plugins/sshfs.sock` socket to communicate with Docker Engine. This plugin has no runtime parameters.\n\n#### [Creating the plugin](#creating-the-plugin)\n\nA new plugin can be created by running `docker plugin create <plugin-name> ./path/to/plugin/data` where the plugin data contains a plugin configuration file `config.json` and a root filesystem in subdirectory `rootfs`.\n\nAfter that the plugin `<plugin-name>` will show up in `docker plugin ls`. Plugins can be pushed to remote registries with `docker plugin push <plugin-name>`.\n\nStdout of a plugin is redirected to dockerd logs. Such entries have a `plugin=<ID>` suffix. Here are a few examples of commands for pluginID `f52a3df433b9aceee436eaada0752f5797aab1de47e5485f1690a073b860ff62` and their corresponding log entries in the docker daemon logs.\n\n#### [Using runc to obtain logfiles and shell into the plugin.](#using-runc-to-obtain-logfiles-and-shell-into-the-plugin)\n\nUse `runc`, the default docker container runtime, for debugging plugins by collecting plugin logs redirected to a file.\n\nIf the plugin has a built-in shell, then exec into the plugin can be done as follows:\n\n#### [Using curl to debug plugin socket issues.](#using-curl-to-debug-plugin-socket-issues)\n\nTo verify if the plugin API socket that the docker daemon communicates with is responsive, use curl. In this example, we will make API calls from the docker host to volume and network plugins using curl 7.47.0 to ensure that the plugin is listening on the said socket. For a well functioning plugin, these basic requests should work. Note that plugin sockets are available on the host under `/var/run/docker/plugins/<pluginID>`\n\nWhen using curl 7.5 and above, the URL should be of the form `http://hostname/APICall`, where `hostname` is the valid hostname where the plugin is installed and `APICall` is the call to the plugin API.\n\nFor example, `http://localhost/VolumeDriver.List`",
    "title": "Docker Engine managed plugin system | Docker Docs\n",
    "description": "Develop and use a plugin with the managed plugin system",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/security/seccomp/",
    "markdown": "# Seccomp security profiles for Docker\n\n`acct`Accounting syscall which could let containers disable their own resource limits or process accounting. Also gated by `CAP_SYS_PACCT`.`add_key`Prevent containers from using the kernel keyring, which is not namespaced.`bpf`Deny loading potentially persistent bpf programs into kernel, already gated by `CAP_SYS_ADMIN`.`clock_adjtime`Time/date is not namespaced. Also gated by `CAP_SYS_TIME`.`clock_settime`Time/date is not namespaced. Also gated by `CAP_SYS_TIME`.`clone`Deny cloning new namespaces. Also gated by `CAP_SYS_ADMIN` for CLONE\\_\\* flags, except `CLONE_NEWUSER`.`create_module`Deny manipulation and functions on kernel modules. Obsolete. Also gated by `CAP_SYS_MODULE`.`delete_module`Deny manipulation and functions on kernel modules. Also gated by `CAP_SYS_MODULE`.`finit_module`Deny manipulation and functions on kernel modules. Also gated by `CAP_SYS_MODULE`.`get_kernel_syms`Deny retrieval of exported kernel and module symbols. Obsolete.`get_mempolicy`Syscall that modifies kernel memory and NUMA settings. Already gated by `CAP_SYS_NICE`.`init_module`Deny manipulation and functions on kernel modules. Also gated by `CAP_SYS_MODULE`.`ioperm`Prevent containers from modifying kernel I/O privilege levels. Already gated by `CAP_SYS_RAWIO`.`iopl`Prevent containers from modifying kernel I/O privilege levels. Already gated by `CAP_SYS_RAWIO`.`kcmp`Restrict process inspection capabilities, already blocked by dropping `CAP_SYS_PTRACE`.`kexec_file_load`Sister syscall of `kexec_load` that does the same thing, slightly different arguments. Also gated by `CAP_SYS_BOOT`.`kexec_load`Deny loading a new kernel for later execution. Also gated by `CAP_SYS_BOOT`.`keyctl`Prevent containers from using the kernel keyring, which is not namespaced.`lookup_dcookie`Tracing/profiling syscall, which could leak a lot of information on the host. Also gated by `CAP_SYS_ADMIN`.`mbind`Syscall that modifies kernel memory and NUMA settings. Already gated by `CAP_SYS_NICE`.`mount`Deny mounting, already gated by `CAP_SYS_ADMIN`.`move_pages`Syscall that modifies kernel memory and NUMA settings.`nfsservctl`Deny interaction with the kernel nfs daemon. Obsolete since Linux 3.1.`open_by_handle_at`Cause of an old container breakout. Also gated by `CAP_DAC_READ_SEARCH`.`perf_event_open`Tracing/profiling syscall, which could leak a lot of information on the host.`personality`Prevent container from enabling BSD emulation. Not inherently dangerous, but poorly tested, potential for a lot of kernel vulns.`pivot_root`Deny `pivot_root`, should be privileged operation.`process_vm_readv`Restrict process inspection capabilities, already blocked by dropping `CAP_SYS_PTRACE`.`process_vm_writev`Restrict process inspection capabilities, already blocked by dropping `CAP_SYS_PTRACE`.`ptrace`Tracing/profiling syscall. Blocked in Linux kernel versions before 4.8 to avoid seccomp bypass. Tracing/profiling arbitrary processes is already blocked by dropping `CAP_SYS_PTRACE`, because it could leak a lot of information on the host.`query_module`Deny manipulation and functions on kernel modules. Obsolete.`quotactl`Quota syscall which could let containers disable their own resource limits or process accounting. Also gated by `CAP_SYS_ADMIN`.`reboot`Don't let containers reboot the host. Also gated by `CAP_SYS_BOOT`.`request_key`Prevent containers from using the kernel keyring, which is not namespaced.`set_mempolicy`Syscall that modifies kernel memory and NUMA settings. Already gated by `CAP_SYS_NICE`.`setns`Deny associating a thread with a namespace. Also gated by `CAP_SYS_ADMIN`.`settimeofday`Time/date is not namespaced. Also gated by `CAP_SYS_TIME`.`stime`Time/date is not namespaced. Also gated by `CAP_SYS_TIME`.`swapon`Deny start/stop swapping to file/device. Also gated by `CAP_SYS_ADMIN`.`swapoff`Deny start/stop swapping to file/device. Also gated by `CAP_SYS_ADMIN`.`sysfs`Obsolete syscall.`_sysctl`Obsolete, replaced by /proc/sys.`umount`Should be a privileged operation. Also gated by `CAP_SYS_ADMIN`.`umount2`Should be a privileged operation. Also gated by `CAP_SYS_ADMIN`.`unshare`Deny cloning new namespaces for processes. Also gated by `CAP_SYS_ADMIN`, with the exception of `unshare --user`.`uselib`Older syscall related to shared libraries, unused for a long time.`userfaultfd`Userspace page fault handling, largely needed for process migration.`ustat`Obsolete syscall.`vm86`In kernel x86 real mode virtual machine. Also gated by `CAP_SYS_ADMIN`.`vm86old`In kernel x86 real mode virtual machine. Also gated by `CAP_SYS_ADMIN`.",
    "title": "Seccomp security profiles for Docker | Docker Docs\n",
    "description": "Enabling seccomp in Docker",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/builders/manage/",
    "markdown": "# Manage builders | Docker Docs\n\nYou can create, inspect, and manage builders using `docker buildx` commands, or [using Docker Desktop](#manage-builders-with-docker-desktop).\n\nThe default builder uses the [`docker` driver](https://docs.docker.com/build/drivers/docker/). You can't manually create new `docker` builders, but you can create builders that use other drivers, such as the [`docker-container` driver](https://docs.docker.com/build/drivers/docker-container/), which runs the BuildKit daemon in a container.\n\nUse the [`docker buildx create`](https://docs.docker.com/reference/cli/docker/buildx/create/) command to create a builder.\n\nBuildx uses the `docker-container` driver by default if you omit the `--driver` flag. For more information about available drivers, see [Build drivers](https://docs.docker.com/build/drivers/).\n\nUse `docker buildx ls` to see builder instances available on your system, and the drivers they're using.\n\nThe asterisk (`*`) next to the builder name indicates the [selected builder](https://docs.docker.com/build/builders/#selected-builder).\n\nTo inspect a builder with the CLI, use `docker buildx inspect <name>`. You can only inspect a builder if the builder is active. You can add the `--bootstrap` flag to the command to start the builder.\n\nIf you want to see how much disk space a builder is using, use the `docker buildx du` command. By default, this command shows the total disk usage for all available builders. To see usage for a specific builder, use the `--builder` flag.\n\nUse the [`docker buildx remove`](https://docs.docker.com/reference/cli/docker/buildx/create/) command to remove a builder.\n\nIf you remove your currently selected builder, the default `docker` builder is automatically selected. You can't remove the default builder.\n\nLocal build cache for the builder is also removed.\n\n### [Removing remote builders](#removing-remote-builders)\n\nRemoving a remote builder doesn't affect the remote build cache. It also doesn't stop the remote BuildKit daemon. It only removes your connection to the builder.\n\nIf you have turned on the [Docker Desktop Builds view](https://docs.docker.com/desktop/use-desktop/builds/), you can inspect builders in Docker Desktop settings. See:\n\n*   [Change settings, Windows](https://docs.docker.com/desktop/settings/windows/#builders)\n*   [Change settings, Mac](https://docs.docker.com/desktop/settings/mac/#builders)\n*   [Change settings, Linux](https://docs.docker.com/desktop/settings/linux/#builders)",
    "title": "Manage builders | Docker Docs\n",
    "description": "",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/extend/plugins_authorization/",
    "markdown": "# Access authorization plugin | Docker Docs\n\nThis document describes the Docker Engine plugins available in Docker Engine. To view information on plugins managed by Docker Engine, refer to [Docker Engine plugin system](https://docs.docker.com/engine/extend/).\n\nDocker's out-of-the-box authorization model is all or nothing. Any user with permission to access the Docker daemon can run any Docker client command. The same is true for callers using Docker's Engine API to contact the daemon. If you require greater access control, you can create authorization plugins and add them to your Docker daemon configuration. Using an authorization plugin, a Docker administrator can configure granular access policies for managing access to the Docker daemon.\n\nAnyone with the appropriate skills can develop an authorization plugin. These skills, at their most basic, are knowledge of Docker, understanding of REST, and sound programming knowledge. This document describes the architecture, state, and methods information available to an authorization plugin developer.\n\nDocker's [plugin infrastructure](https://docs.docker.com/engine/extend/plugin_api/) enables extending Docker by loading, removing and communicating with third-party components using a generic API. The access authorization subsystem was built using this mechanism.\n\nUsing this subsystem, you don't need to rebuild the Docker daemon to add an authorization plugin. You can add a plugin to an installed Docker daemon. You do need to restart the Docker daemon to add a new plugin.\n\nAn authorization plugin approves or denies requests to the Docker daemon based on both the current authentication context and the command context. The authentication context contains all user details and the authentication method. The command context contains all the relevant request data.\n\nAuthorization plugins must follow the rules described in [Docker Plugin API](https://docs.docker.com/engine/extend/plugin_api/). Each plugin must reside within directories described under the [Plugin discovery](https://docs.docker.com/engine/extend/plugin_api/#plugin-discovery) section.\n\n> **Note**\n> \n> The abbreviations `AuthZ` and `AuthN` mean authorization and authentication respectively.\n\nIf TLS is enabled in the [Docker daemon](https://docs.docker.com/engine/security/https/), the default user authorization flow extracts the user details from the certificate subject name. That is, the `User` field is set to the client certificate subject common name, and the `AuthenticationMethod` field is set to `TLS`.\n\nYou are responsible for registering your plugin as part of the Docker daemon startup. You can install multiple plugins and chain them together. This chain can be ordered. Each request to the daemon passes in order through the chain. Only when all the plugins grant access to the resource, is the access granted.\n\nWhen an HTTP request is made to the Docker daemon through the CLI or via the Engine API, the authentication subsystem passes the request to the installed authentication plugin(s). The request contains the user (caller) and command context. The plugin is responsible for deciding whether to allow or deny the request.\n\nThe sequence diagrams below depict an allow and deny authorization flow:\n\n![Authorization Allow flow](https://docs.docker.com/engine/extend/images/authz_allow.png)\n\n![Authorization Deny flow](https://docs.docker.com/engine/extend/images/authz_deny.png)\n\nEach request sent to the plugin includes the authenticated user, the HTTP headers, and the request/response body. Only the user name and the authentication method used are passed to the plugin. Most importantly, no user credentials or tokens are passed. Finally, not all request/response bodies are sent to the authorization plugin. Only those request/response bodies where the `Content-Type` is either `text/*` or `application/json` are sent.\n\nFor commands that can potentially hijack the HTTP connection (`HTTP Upgrade`), such as `exec`, the authorization plugin is only called for the initial HTTP requests. Once the plugin approves the command, authorization is not applied to the rest of the flow. Specifically, the streaming data is not passed to the authorization plugins. For commands that return chunked HTTP response, such as `logs` and `events`, only the HTTP request is sent to the authorization plugins.\n\nDuring request/response processing, some authorization flows might need to do additional queries to the Docker daemon. To complete such flows, plugins can call the daemon API similar to a regular user. To enable these additional queries, the plugin must provide the means for an administrator to configure proper authentication and security policies.\n\nTo enable and configure the authorization plugin, the plugin developer must support the Docker client interactions detailed in this section.\n\n### [Setting up Docker daemon](#setting-up-docker-daemon)\n\nEnable the authorization plugin with a dedicated command line flag in the `--authorization-plugin=PLUGIN_ID` format. The flag supplies a `PLUGIN_ID` value. This value can be the plugin’s socket or a path to a specification file. Authorization plugins can be loaded without restarting the daemon. Refer to the [`dockerd` documentation](https://docs.docker.com/reference/cli/dockerd/#configuration-reload-behavior) for more information.\n\nDocker's authorization subsystem supports multiple `--authorization-plugin` parameters.\n\n### [Calling authorized command (allow)](#calling-authorized-command-allow)\n\n### [Calling unauthorized command (deny)](#calling-unauthorized-command-deny)\n\n### [Error from plugins](#error-from-plugins)\n\nIn addition to Docker's standard plugin registration method, each plugin should implement the following two methods:\n\n*   `/AuthZPlugin.AuthZReq` This authorize request method is called before the Docker daemon processes the client request.\n    \n*   `/AuthZPlugin.AuthZRes` This authorize response method is called before the response is returned from Docker daemon to the client.\n    \n\n#### [/AuthZPlugin.AuthZReq](#authzpluginauthzreq)\n\nRequest\n\nResponse\n\n#### [/AuthZPlugin.AuthZRes](#authzpluginauthzres)\n\nRequest:\n\nResponse:\n\n### [Request authorization](#request-authorization)\n\nEach plugin must support two request authorization messages formats, one from the daemon to the plugin and then from the plugin to the daemon. The tables below detail the content expected in each message.\n\n#### [Daemon -> Plugin](#daemon---plugin)\n\n| Name | Type | Description |\n| --- | --- | --- |\n| User | string | The user identification |\n| Authentication method | string | The authentication method used |\n| Request method | enum | The HTTP method (GET/DELETE/POST) |\n| Request URI | string | The HTTP request URI including API version (e.g., v.1.17/containers/json) |\n| Request headers | map\\[string\\]string | Request headers as key value pairs (without the authorization header) |\n| Request body | \\[\\]byte | Raw request body |\n\n#### [Plugin -> Daemon](#plugin---daemon)\n\n| Name | Type | Description |\n| --- | --- | --- |\n| Allow | bool | Boolean value indicating whether the request is allowed or denied |\n| Msg | string | Authorization message (will be returned to the client in case the access is denied) |\n| Err | string | Error message (will be returned to the client in case the plugin encounter an error. The string value supplied may appear in logs, so should not include confidential information) |\n\n### [Response authorization](#response-authorization)\n\nThe plugin must support two authorization messages formats, one from the daemon to the plugin and then from the plugin to the daemon. The tables below detail the content expected in each message.\n\n#### [Daemon -> Plugin](#daemon---plugin-1)\n\n| Name | Type | Description |\n| --- | --- | --- |\n| User | string | The user identification |\n| Authentication method | string | The authentication method used |\n| Request method | string | The HTTP method (GET/DELETE/POST) |\n| Request URI | string | The HTTP request URI including API version (e.g., v.1.17/containers/json) |\n| Request headers | map\\[string\\]string | Request headers as key value pairs (without the authorization header) |\n| Request body | \\[\\]byte | Raw request body |\n| Response status code | int | Status code from the Docker daemon |\n| Response headers | map\\[string\\]string | Response headers as key value pairs |\n| Response body | \\[\\]byte | Raw Docker daemon response body |\n\n#### [Plugin -> Daemon](#plugin---daemon-1)\n\n| Name | Type | Description |\n| --- | --- | --- |\n| Allow | bool | Boolean value indicating whether the response is allowed or denied |\n| Msg | string | Authorization message (will be returned to the client in case the access is denied) |\n| Err | string | Error message (will be returned to the client in case the plugin encounter an error. The string value supplied may appear in logs, so should not include confidential information) |",
    "title": "Access authorization plugin | Docker Docs\n",
    "description": "How to create authorization plugins to manage access control to your Docker daemon.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/",
    "markdown": "# Swarm mode overview | Docker Docs\n\n> **Note**\n> \n> Swarm mode is an advanced feature for managing a cluster of Docker daemons.\n> \n> Use Swarm mode if you intend to use Swarm as a production runtime environment.\n> \n> If you're not planning on deploying with Swarm, use [Docker Compose](https://docs.docker.com/compose/) instead. If you're developing for a Kubernetes deployment, consider using the [integrated Kubernetes feature](https://docs.docker.com/desktop/kubernetes/) in Docker Desktop.\n\nCurrent versions of Docker include Swarm mode for natively managing a cluster of Docker Engines called a swarm. Use the Docker CLI to create a swarm, deploy application services to a swarm, and manage swarm behavior.\n\nDocker Swarm mode is built into the Docker Engine. Do not confuse Docker Swarm mode with [Docker Classic Swarm](https://github.com/docker/classicswarm) which is no longer actively developed.\n\n### [Cluster management integrated with Docker Engine](#cluster-management-integrated-with-docker-engine)\n\nUse the Docker Engine CLI to create a swarm of Docker Engines where you can deploy application services. You don't need additional orchestration software to create or manage a swarm.\n\n### [Decentralized design](#decentralized-design)\n\nInstead of handling differentiation between node roles at deployment time, the Docker Engine handles any specialization at runtime. You can deploy both kinds of nodes, managers and workers, using the Docker Engine. This means you can build an entire swarm from a single disk image.\n\n### [Declarative service model](#declarative-service-model)\n\nDocker Engine uses a declarative approach to let you define the desired state of the various services in your application stack. For example, you might describe an application comprised of a web front end service with message queueing services and a database backend.\n\n### [Scaling](#scaling)\n\nFor each service, you can declare the number of tasks you want to run. When you scale up or down, the swarm manager automatically adapts by adding or removing tasks to maintain the desired state.\n\n### [Desired state reconciliation](#desired-state-reconciliation)\n\nThe swarm manager node constantly monitors the cluster state and reconciles any differences between the actual state and your expressed desired state. For example, if you set up a service to run 10 replicas of a container, and a worker machine hosting two of those replicas crashes, the manager creates two new replicas to replace the replicas that crashed. The swarm manager assigns the new replicas to workers that are running and available.\n\n### [Multi-host networking](#multi-host-networking)\n\nYou can specify an overlay network for your services. The swarm manager automatically assigns addresses to the containers on the overlay network when it initializes or updates the application.\n\n### [Service discovery](#service-discovery)\n\nSwarm manager nodes assign each service in the swarm a unique DNS name and load balance running containers. You can query every container running in the swarm through a DNS server embedded in the swarm.\n\n### [Load balancing](#load-balancing)\n\nYou can expose the ports for services to an external load balancer. Internally, the swarm lets you specify how to distribute service containers between nodes.\n\n### [Secure by default](#secure-by-default)\n\nEach node in the swarm enforces TLS mutual authentication and encryption to secure communications between itself and all other nodes. You have the option to use self-signed root certificates or certificates from a custom root CA.\n\n### [Rolling updates](#rolling-updates)\n\nAt rollout time you can apply service updates to nodes incrementally. The swarm manager lets you control the delay between service deployment to different sets of nodes. If anything goes wrong, you can roll back to a previous version of the service.\n\n*   Learn Swarm mode [key concepts](https://docs.docker.com/engine/swarm/key-concepts/).\n*   Get started with the [Swarm mode tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/).\n*   Explore Swarm mode CLI commands\n    *   [swarm init](https://docs.docker.com/reference/cli/docker/swarm/init/)\n    *   [swarm join](https://docs.docker.com/reference/cli/docker/swarm/join/)\n    *   [service create](https://docs.docker.com/reference/cli/docker/service/create/)\n    *   [service inspect](https://docs.docker.com/reference/cli/docker/service/inspect/)\n    *   [service ls](https://docs.docker.com/reference/cli/docker/service/ls/)\n    *   [service rm](https://docs.docker.com/reference/cli/docker/service/rm/)\n    *   [service scale](https://docs.docker.com/reference/cli/docker/service/scale/)\n    *   [service ps](https://docs.docker.com/reference/cli/docker/service/ps/)\n    *   [service update](https://docs.docker.com/reference/cli/docker/service/update/)",
    "title": "Swarm mode overview | Docker Docs\n",
    "description": "Docker Engine Swarm mode overview",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/drivers/",
    "markdown": "# Build drivers | Docker Docs\n\nBuild drivers are configurations for how and where the BuildKit backend runs. Driver settings are customizable and allows fine-grained control of the builder. Buildx supports the following drivers:\n\n*   `docker`: uses the BuildKit library bundled into the Docker daemon.\n*   `docker-container`: creates a dedicated BuildKit container using Docker.\n*   `kubernetes`: creates BuildKit pods in a Kubernetes cluster.\n*   `remote`: connects directly to a manually managed BuildKit daemon.\n\nDifferent drivers support different use cases. The default `docker` driver prioritizes simplicity and ease of use. It has limited support for advanced features like caching and output formats, and isn't configurable. Other drivers provide more flexibility and are better at handling advanced scenarios.\n\nThe following table outlines some differences between drivers.\n\n| Feature | `docker` | `docker-container` | `kubernetes` | `remote` |\n| --- | --- | --- | --- | --- |\n| **Automatically load image** | ✅   |     |     |     |\n| **Cache export** | ✓\\* | ✅   | ✅   | ✅   |\n| **Tarball output** |     | ✅   | ✅   | ✅   |\n| **Multi-arch images** |     | ✅   | ✅   | ✅   |\n| **BuildKit configuration** |     | ✅   | ✅   | Managed externally |\n\n\\* _The `docker` driver doesn't support all cache export options. See [Cache storage backends](https://docs.docker.com/build/cache/backends/) for more information._\n\nUnlike when using the default `docker` driver, images built using other drivers aren't automatically loaded into the local image store. If you don't specify an output, the build result is exported to the build cache only.\n\nTo build an image using a non-default driver and load it to the image store, use the `--load` flag with the build command:\n\nWith this option, the image is available in the image store after the build finishes:\n\n### [Load by default](#load-by-default)\n\nIntroduced in Buildx version 0.14.0\n\nYou can configure the custom build drivers to behave in a similar way to the default `docker` driver, and load images to the local image store by default. To do so, set the `default-load` driver option when creating the builder:\n\nNote that, just like with the `docker` driver, if you specify a different output format with `--output`, the result will not be loaded to the image store unless you also explicitly specify `--output type=docker` or use the `--load` flag.\n\nRead about each driver:\n\n*   [Docker driver](https://docs.docker.com/build/drivers/docker/)\n*   [Docker container driver](https://docs.docker.com/build/drivers/docker-container/)\n*   [Kubernetes driver](https://docs.docker.com/build/drivers/kubernetes/)\n*   [Remote driver](https://docs.docker.com/build/drivers/remote/)",
    "title": "Build drivers | Docker Docs\n",
    "description": "Build drivers are configurations for how and where the BuildKit backend runs.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/drivers/docker/",
    "markdown": "# Docker driver | Docker Docs\n\nThe Buildx Docker driver is the default driver. It uses the BuildKit server components built directly into the Docker engine. The Docker driver requires no configuration.\n\nUnlike the other drivers, builders using the Docker driver can't be manually created. They're only created automatically from the Docker context.\n\nImages built with the Docker driver are automatically loaded to the local image store.\n\nIt's not possible to configure which BuildKit version to use, or to pass any additional BuildKit parameters to a builder using the Docker driver. The BuildKit version and parameters are preset by the Docker engine internally.\n\nIf you need additional configuration and flexibility, consider using the [Docker container driver](https://docs.docker.com/build/drivers/docker-container/).\n\nFor more information on the Docker driver, see the [buildx reference](https://docs.docker.com/reference/cli/docker/buildx/create/#driver).",
    "title": "Docker driver | Docker Docs\n",
    "description": "The Docker driver is the default driver. It uses the BuildKit bundled with the Docker Engine. ",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/key-concepts/",
    "markdown": "# Swarm mode key concepts | Docker Docs\n\nThis topic introduces some of the concepts unique to the cluster management and orchestration features of Docker Engine 1.12.\n\nThe cluster management and orchestration features embedded in Docker Engine are built using [swarmkit](https://github.com/docker/swarmkit/). Swarmkit is a separate project which implements Docker's orchestration layer and is used directly within Docker.\n\nA swarm consists of multiple Docker hosts which run in Swarm mode and act as managers, to manage membership and delegation, and workers, which run [swarm services](#services-and-tasks). A given Docker host can be a manager, a worker, or perform both roles. When you create a service, you define its optimal state - number of replicas, network and storage resources available to it, ports the service exposes to the outside world, and more. Docker works to maintain that desired state. For instance, if a worker node becomes unavailable, Docker schedules that node's tasks on other nodes. A task is a running container which is part of a swarm service and is managed by a swarm manager, as opposed to a standalone container.\n\nOne of the key advantages of swarm services over standalone containers is that you can modify a service's configuration, including the networks and volumes it is connected to, without the need to manually restart the service. Docker will update the configuration, stop the service tasks with out of date configuration, and create new ones matching the desired configuration.\n\nWhen Docker is running in Swarm mode, you can still run standalone containers on any of the Docker hosts participating in the swarm, as well as swarm services. A key difference between standalone containers and swarm services is that only swarm managers can manage a swarm, while standalone containers can be started on any daemon. Docker daemons can participate in a swarm as managers, workers, or both.\n\nIn the same way that you can use [Docker Compose](https://docs.docker.com/compose/) to define and run containers, you can define and run [Swarm service](https://docs.docker.com/engine/swarm/services/) stacks.\n\nKeep reading for details about concepts related to Docker swarm services, including nodes, services, tasks, and load balancing.\n\nA node is an instance of the Docker engine participating in the swarm. You can also think of this as a Docker node. You can run one or more nodes on a single physical computer or cloud server, but production swarm deployments typically include Docker nodes distributed across multiple physical and cloud machines.\n\nTo deploy your application to a swarm, you submit a service definition to a manager node\\*. The manager node dispatches units of work called [tasks](#services-and-tasks) to worker nodes.\n\nManager nodes also perform the orchestration and cluster management functions required to maintain the desired state of the swarm. Manager nodes elect a single leader to conduct orchestration tasks.\n\nWorker nodes receive and execute tasks dispatched from manager nodes. By default manager nodes also run services as worker nodes, but you can configure them to run manager tasks exclusively and be manager-only nodes. An agent runs on each worker node and reports on the tasks assigned to it. The worker node notifies the manager node of the current state of its assigned tasks so that the manager can maintain the desired state of each worker.\n\nA service is the definition of the tasks to execute on the manager or worker nodes. It is the central structure of the swarm system and the primary root of user interaction with the swarm.\n\nWhen you create a service, you specify which container image to use and which commands to execute inside running containers.\n\nIn the replicated services model, the swarm manager distributes a specific number of replica tasks among the nodes based upon the scale you set in the desired state.\n\nFor global services, the swarm runs one task for the service on every available node in the cluster.\n\nA task carries a Docker container and the commands to run inside the container. It is the atomic scheduling unit of swarm. Manager nodes assign tasks to worker nodes according to the number of replicas set in the service scale. Once a task is assigned to a node, it cannot move to another node. It can only run on the assigned node or fail.\n\nThe swarm manager uses ingress load balancing to expose the services you want to make available externally to the swarm. The swarm manager can automatically assign the service a published port or you can configure a published port for the service. You can specify any unused port. If you do not specify a port, the swarm manager assigns the service a port in the 30000-32767 range.\n\nExternal components, such as cloud load balancers, can access the service on the published port of any node in the cluster whether or not the node is currently running the task for the service. All nodes in the swarm route ingress connections to a running task instance.\n\nSwarm mode has an internal DNS component that automatically assigns each service in the swarm a DNS entry. The swarm manager uses internal load balancing to distribute requests among services within the cluster based upon the DNS name of the service.\n\n*   Read the [Swarm mode overview](https://docs.docker.com/engine/swarm/).\n*   Get started with the [Swarm mode tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/).",
    "title": "Swarm mode key concepts | Docker Docs\n",
    "description": "Introducing key concepts for Docker Engine swarm mode",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/26.0/",
    "markdown": "# Docker Engine 26.0 release notes\n\nThis page describes the latest changes, additions, known issues, and fixes for Docker Engine version 26.0.\n\nFor more information about:\n\n*   Deprecated and removed features, see [Deprecated Engine Features](https://docs.docker.com/engine/deprecated/).\n*   Changes to the Engine API, see [Engine API version history](https://docs.docker.com/engine/api/version-history/).\n\n_2024-04-18_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 26.0.2 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A26.0.2)\n*   [moby/moby, 26.0.2 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A26.0.2)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v26.0.2/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v26.0.2/docs/api/version-history.md).\n\n### [Security](#security)\n\nThis release contains a security fix for [CVE-2024-32473](https://github.com/moby/moby/security/advisories/GHSA-x84c-p2g9-rqv9), an unexpected configuration of IPv6 on IPv4-only interfaces.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements)\n\n*   [CVE-2024-32473](https://github.com/moby/moby/security/advisories/GHSA-x84c-p2g9-rqv9): Ensure IPv6 is disabled on interfaces only allocated an IPv4 address by the engine. [moby#GHSA-x84c-p2g9-rqv9](https://github.com/moby/moby/security/advisories/GHSA-x84c-p2g9-rqv9)\n    \n\n_2024-04-11_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 26.0.1 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A26.0.1)\n*   [moby/moby, 26.0.1 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A26.0.1)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v26.0.1/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v26.0.1/docs/api/version-history.md).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-1)\n\n*   Fix a regression that meant network interface specific `--sysctl` options prevented container startup. [moby/moby#47646](https://github.com/moby/moby/pull/47646)\n*   Remove erroneous `platform` from image `config` OCI descriptor in `docker save` output. [moby/moby#47694](https://github.com/moby/moby/pull/47694)\n*   containerd image store: OCI archives produced by `docker save` will now have a non-empty `mediaType` field in `index.json` [moby/moby#47701](https://github.com/moby/moby/pull/47701)\n*   Fix a regression that prevented the internal resolver from forwarding requests from IPvlan L3 networks to external resolvers. [moby/moby#47705](https://github.com/moby/moby/pull/47705)\n*   Prevent the use of external resolvers in IPvlan and Macvlan networks created with no parent interface specified. [moby/moby#47705](https://github.com/moby/moby/pull/47705)\n\n### [Packaging updates](#packaging-updates)\n\n*   Update Go runtime to 1.21.9 [moby/moby#47671](https://github.com/moby/moby/pull/47671), [docker/cli#4987](https://github.com/docker/cli/pull/4987)\n*   Update Compose to [v1.26.1](https://github.com/docker/compose/releases/tag/v2.26.1) , [docker/docker-ce-packaging#1009](https://github.com/docker/docker-ce-packaging/pull/1009)\n*   Update containerd to [v1.7.15](https://github.com/containerd/containerd/releases/tag/v1.7.15) (static binaries only) [moby/moby#47692](https://github.com/moby/moby/pull/47692)\n\n_2024-03-20_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 26.0.0 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A26.0.0)\n*   [moby/moby, 26.0.0 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A26.0.0)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v26.0.0/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v26.0.0/docs/api/version-history.md).\n\n### [Security](#security-1)\n\nThis release contains a security fix for [CVE-2024-29018](https://github.com/moby/moby/security/advisories/GHSA-mq39-4gv4-mvpx), a potential data exfiltration from 'internal' networks via authoritative DNS servers.\n\n### [New](#new)\n\n*   Add `Subpath` field to the `VolumeOptions` making it possible to mount a subpath of a volume. [moby/moby#45687](https://github.com/moby/moby/pull/45687)\n*   Add `volume-subpath` support to the mount flag (`--mount type=volume,...,volume-subpath=<subpath>`). [docker/cli#4331](https://github.com/docker/cli/pull/4331)\n*   Accept `=` separators and `[ipv6]` in compose files for `docker stack deploy`. [docker/cli#4860](https://github.com/docker/cli/pull/4860)\n*   rootless: Add support for enabling host loopback by setting the `DOCKERD_ROOTLESS_ROOTLESSKIT_DISABLE_HOST_LOOPBACK` environment variable to `false` (defaults to `true`). This lets containers connect to the host by using IP address `10.0.2.2`. [moby/moby#47352](https://github.com/moby/moby/pull/47352)\n*   containerd image store: `docker image ls` no longer creates duplicates entries for multi-platform images. [moby/moby#45967](https://github.com/moby/moby/pull/45967)\n*   containerd image store: Send Prometheus metrics. [moby/moby#47555](https://github.com/moby/moby/pull/47555)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-2)\n\n*   [CVE-2024-29018](https://github.com/moby/moby/security/advisories/GHSA-mq39-4gv4-mvpx): Do not forward requests to external DNS servers for a container that is only connected to an 'internal' network. Previously, requests were forwarded if the host's DNS server was running on a loopback address, like systemd's 127.0.0.53. [moby/moby#47589](https://github.com/moby/moby/pull/47589)\n    \n*   Ensure that a generated MAC address is not restored when a container is restarted, but a configured MAC address is preserved. [moby/moby#47233](https://github.com/moby/moby/pull/47233)\n    \n    > **Warning**\n    > \n    > Containers created using Docker Engine 25.0.0 may have duplicate MAC addresses, they must be re-created. Containers created using version 25.0.0 or 25.0.1 with user-defined MAC addresses will get generated MAC addresses when they are started using 25.0.2. They must also be re-created.\n    \n*   Always attempt to enable IPv6 on a container's loopback interface, and only include IPv6 in `/etc/hosts` if successful. [moby/moby#47062](https://github.com/moby/moby/pull/47062)\n    \n    > **Note**\n    > \n    > By default, IPv6 will remain enabled on a container's loopback interface when the container is not connected to an IPv6-enabled network. For example, containers that are only connected to an IPv4-only network now have the `::1` address on their loopback interface.\n    > \n    > To disable IPv6 in a container, use option `--sysctl net.ipv6.conf.all.disable_ipv6=1` in the `create` or `run` command, or the equivalent `sysctls` option in the service configuration section of a Compose file.\n    > \n    > If IPv6 is not available in a container because it has been explicitly disabled for the container, or the host's networking stack does not have IPv6 enabled (or for any other reason) the container's `/etc/hosts` file will not include IPv6 entries.\n    \n*   Fix `ADD` Dockerfile instruction failing with `lsetxattr <file>: operation not supported` when unpacking archive with xattrs onto a filesystem that doesn't support them. [moby/moby#47175](https://github.com/moby/moby/pull/47175)\n    \n*   Fix `docker container start` failing when used with `--checkpoint`. [moby/moby#47456](https://github.com/moby/moby/pull/47456)\n    \n*   Restore IP connectivity between the host and containers on an internal bridge network. [moby/moby#47356](https://github.com/moby/moby/pull/47356)\n    \n*   Do not enforce new validation rules for existing swarm networks. [moby/moby#47361](https://github.com/moby/moby/pull/47361)\n    \n*   Restore DNS names for containers in the default \"nat\" network on Windows. [moby/moby#47375](https://github.com/moby/moby/pull/47375)\n    \n*   Print hint when invoking `docker image ls` with ambiguous argument. [docker/cli#4849](https://github.com/docker/cli/pull/4849)\n    \n*   Cleanup `@docker_cli_[UUID]` files on OpenBSD. [docker/cli#4862](https://github.com/docker/cli/pull/4862)\n    \n*   Add explicit [deprecation notice](https://github.com/docker/cli/blob/v26.0.0/docs/deprecated.md#unauthenticated-tcp-connections) message when using remote TCP connections without TLS. [docker/cli#4928](https://github.com/docker/cli/pull/4928), [moby/moby#47556](https://github.com/moby/moby/pull/47556)\n    \n*   Use IPv6 nameservers from the host's `resolv.conf` as upstream resolvers for Docker Engine's internal DNS, rather than listing them in the container's `resolv.conf`. [moby/moby#47512](https://github.com/moby/moby/pull/47512)\n    \n*   containerd image store: Isolate images with different containerd namespaces when `--userns-remap` option is used. [moby/moby#46786](https://github.com/moby/moby/pull/46786)\n    \n*   containerd image store: Fix image pull not emitting `Pulling fs layer` status. [moby/moby#47432](https://github.com/moby/moby/pull/47432)\n    \n\n### [API](#api)\n\n*   To preserve backwards compatibility, read-only mounts are not recursive by default when using older clients (API version < v1.44). [moby/moby#47391](https://github.com/moby/moby/pull/47391)\n*   `GET /images/{id}/json` omits the `Created` field (previously it was `0001-01-01T00:00:00Z`) if the `Created` field is missing from the image config. [moby/moby#47451](https://github.com/moby/moby/pull/47451)\n*   Populate a missing `Created` field in `GET /images/{id}/json` with `0001-01-01T00:00:00Z` for API version <= 1.43. [moby/moby#47387](https://github.com/moby/moby/pull/47387)\n*   The `is_automated` field in the `POST /images/search` endpoint results is always `false` now. Consequently, searching for `is-automated=true` will yield no results, while `is-automated=false` will be a no-op. [moby/moby#47465](https://github.com/moby/moby/pull/47465)\n*   Remove `Container` and `ContainerConfig` fields from the `GET /images/{name}/json` response. [moby/moby#47430](https://github.com/moby/moby/pull/47430)\n\n### [Packaging updates](#packaging-updates-1)\n\n*   Update BuildKit to [v0.13.1](https://github.com/moby/buildkit/releases/tag/v0.13.1). [moby/moby#47582](https://github.com/moby/moby/pull/47582)\n*   Update Buildx to [v0.13.1](https://github.com/docker/buildx/releases/tag/v0.13.1). [docker/docker-ce-packaging#1000](https://github.com/docker/docker-ce-packaging/pull/1000)\n*   Update Compose to [v2.25.0](https://github.com/docker/compose/releases/tag/v2.25.0). [docker/docker-ce-packaging#1002](https://github.com/docker/docker-ce-packaging/pull/1002)\n*   Update Go runtime to [1.21.8](https://go.dev/doc/devel/release#go1.21.8). [moby/moby#47502](https://github.com/moby/moby/pull/47502)\n*   Update RootlessKit to [v2.0.2](https://github.com/rootless-containers/rootlesskit/releases/tag/v2.0.2). [moby/moby#47508](https://github.com/moby/moby/pull/47504)\n*   Update containerd to v1.7.13 (static binaries only) [moby/moby#47278](https://github.com/moby/moby/pull/47278)\n*   Update runc binary to v1.1.12 [moby/moby#47268](https://github.com/moby/moby/pull/47268)\n*   Update OTel to v0.46.1 / v1.21.0 [moby/moby#47245](https://github.com/moby/moby/pull/47245)\n\n### [Removed](#removed)\n\n*   Remove `Container` and `ContainerConfig` fields from the `GET /images/{name}/json` response. [moby/moby#47430](https://github.com/moby/moby/pull/47430)\n    \n*   Deprecate the ability to accept remote TCP connections without TLS. [Deprecation notice](https://github.com/docker/cli/tree/v26.0.0/deprecation.md#unauthenticated-tcp-connections) [docker/cli#4928](https://github.com/docker/cli/pull/4928) [moby/moby#47556](https://github.com/moby/moby/pull/47556).\n    \n*   Remove deprecated API versions (API < v1.24) [moby/moby#47155](https://github.com/moby/moby/pull/47155)\n    \n*   Disable pulling of deprecated image formats by default. These image formats are deprecated, and support will be removed in a future version. [moby/moby#47459](https://github.com/moby/moby/pull/47459)\n    \n*   image: remove deprecated IDFromDigest [moby/moby#47198](https://github.com/moby/moby/pull/47198)\n    \n*   Remove the deprecated `github.com/docker/docker/pkg/loopback` package. [moby/moby#47128](https://github.com/moby/moby/pull/47128)\n    \n*   pkg/system: remove deprecated `ErrNotSupportedOperatingSystem`, `IsOSSupported` [moby/moby#47129](https://github.com/moby/moby/pull/47129)\n    \n*   pkg/homedir: remove deprecated Key() and GetShortcutString() [moby/moby#47130](https://github.com/moby/moby/pull/47130)\n    \n*   pkg/containerfs: remove deprecated ResolveScopedPath [moby/moby#47131](https://github.com/moby/moby/pull/47131)\n    \n*   The daemon flag `--oom-score-adjust` was deprecated in v24.0 and is now removed. [moby/moby#46113](https://github.com/moby/moby/pull/46113)\n    \n*   Remove deprecated aliases from the api/types package. These types were deprecated in v25.0.0, which provided temporary aliases. [moby/moby#47148](https://github.com/moby/moby/pull/47148) These aliases are now removed: `types.Info`, `types.Commit`, `types.PluginsInfo`, `types.NetworkAddressPool`, `types.Runtime`, `types.SecurityOpt`, `types.KeyValue`, `types.DecodeSecurityOptions`, `types.CheckpointCreateOptions`, `types.CheckpointListOptions`, `types.CheckpointDeleteOptions`, `types.Checkpoint`, `types.ImageDeleteResponseItem`, `types.ImageSummary`, `types.ImageMetadata`, `types.ServiceUpdateResponse`, `types.ServiceCreateResponse`, `types.ResizeOptions`, `types.ContainerAttachOptions`, `types.ContainerCommitOptions`, `types.ContainerRemoveOptions`, `types.ContainerStartOptions`, `types.ContainerListOptions`, `types.ContainerLogsOptions`\n    \n*   cli/command/container: remove deprecated `NewStartOptions()` [docker/cli#4811](https://github.com/docker/cli/pull/4811)\n    \n*   cli/command: remove deprecated `DockerCliOption`, `InitializeOpt` [docker/cli#4810](https://github.com/docker/cli/pull/4810)",
    "title": "Docker Engine 26.0 release notes | Docker Docs\n",
    "description": "Learn about the new features, bug fixes, and breaking changes for Docker Engine",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/extend/legacy_plugins/",
    "markdown": "# Use Docker Engine plugins | Docker Docs\n\nThis document describes the Docker Engine plugins generally available in Docker Engine. To view information on plugins managed by Docker, refer to [Docker Engine plugin system](https://docs.docker.com/engine/extend/).\n\nYou can extend the capabilities of the Docker Engine by loading third-party plugins. This page explains the types of plugins and provides links to several volume and network plugins for Docker.\n\nPlugins extend Docker's functionality. They come in specific types. For example, a [volume plugin](https://docs.docker.com/engine/extend/plugins_volume/) might enable Docker volumes to persist across multiple Docker hosts and a [network plugin](https://docs.docker.com/engine/extend/plugins_network/) might provide network plumbing.\n\nCurrently Docker supports authorization, volume and network driver plugins. In the future it will support additional plugin types.\n\nFollow the instructions in the plugin's documentation.\n\nThe sections below provide an overview of available third-party plugins.\n\n### [Network plugins](#network-plugins)\n\n| Plugin | Description |\n| --- | --- |\n| [Contiv Networking](https://github.com/contiv/netplugin) | An open source network plugin to provide infrastructure and security policies for a multi-tenant micro services deployment, while providing an integration to physical network for non-container workload. Contiv Networking implements the remote driver and IPAM APIs available in Docker 1.9 onwards. |\n| [Kuryr Network Plugin](https://github.com/openstack/kuryr) | A network plugin is developed as part of the OpenStack Kuryr project and implements the Docker networking (libnetwork) remote driver API by utilizing Neutron, the OpenStack networking service. It includes an IPAM driver as well. |\n| [Kathará Network Plugin](https://github.com/KatharaFramework/NetworkPlugin) | Docker Network Plugin used by Kathará, an open source container-based network emulation system for showing interactive demos/lessons, testing production networks in a sandbox environment, or developing new network protocols. |\n\n### [Volume plugins](#volume-plugins)\n\n| Plugin | Description |\n| --- | --- |\n| [Azure File Storage plugin](https://github.com/Azure/azurefile-dockervolumedriver) | Lets you mount Microsoft [Azure File Storage](https://azure.microsoft.com/blog/azure-file-storage-now-generally-available/) shares to Docker containers as volumes using the SMB 3.0 protocol. [Learn more](https://azure.microsoft.com/blog/persistent-docker-volumes-with-azure-file-storage/). |\n| [BeeGFS Volume Plugin](https://github.com/RedCoolBeans/docker-volume-beegfs) | An open source volume plugin to create persistent volumes in a BeeGFS parallel file system. |\n| [Blockbridge plugin](https://github.com/blockbridge/blockbridge-docker-volume) | A volume plugin that provides access to an extensible set of container-based persistent storage options. It supports single and multi-host Docker environments with features that include tenant isolation, automated provisioning, encryption, secure deletion, snapshots and QoS. |\n| [Contiv Volume Plugin](https://github.com/contiv/volplugin) | An open source volume plugin that provides multi-tenant, persistent, distributed storage with intent based consumption. It has support for Ceph and NFS. |\n| [Convoy plugin](https://github.com/rancher/convoy) | A volume plugin for a variety of storage back-ends including device mapper and NFS. It's a simple standalone executable written in Go and provides the framework to support vendor-specific extensions such as snapshots, backups and restore. |\n| [DigitalOcean Block Storage plugin](https://github.com/omallo/docker-volume-plugin-dostorage) | Integrates DigitalOcean's [block storage solution](https://www.digitalocean.com/products/storage/) into the Docker ecosystem by automatically attaching a given block storage volume to a DigitalOcean droplet and making the contents of the volume available to Docker containers running on that droplet. |\n| [DRBD plugin](https://www.drbd.org/en/supported-projects/docker) | A volume plugin that provides highly available storage replicated by [DRBD](https://www.drbd.org/). Data written to the docker volume is replicated in a cluster of DRBD nodes. |\n| [Flocker plugin](https://github.com/ScatterHQ/flocker) | A volume plugin that provides multi-host portable volumes for Docker, enabling you to run databases and other stateful containers and move them around across a cluster of machines. |\n| [Fuxi Volume Plugin](https://github.com/openstack/fuxi) | A volume plugin that is developed as part of the OpenStack Kuryr project and implements the Docker volume plugin API by utilizing Cinder, the OpenStack block storage service. |\n| [gce-docker plugin](https://github.com/mcuadros/gce-docker) | A volume plugin able to attach, format and mount Google Compute [persistent-disks](https://cloud.google.com/compute/docs/disks/persistent-disks). |\n| [GlusterFS plugin](https://github.com/calavera/docker-volume-glusterfs) | A volume plugin that provides multi-host volumes management for Docker using GlusterFS. |\n| [Horcrux Volume Plugin](https://github.com/muthu-r/horcrux) | A volume plugin that allows on-demand, version controlled access to your data. Horcrux is an open-source plugin, written in Go, and supports SCP, [Minio](https://www.minio.io/) and Amazon S3. |\n| [HPE 3Par Volume Plugin](https://github.com/hpe-storage/python-hpedockerplugin/) | A volume plugin that supports HPE 3Par and StoreVirtual iSCSI storage arrays. |\n| [Infinit volume plugin](https://infinit.sh/documentation/docker/volume-plugin) | A volume plugin that makes it easy to mount and manage Infinit volumes using Docker. |\n| [IPFS Volume Plugin](https://github.com/vdemeester/docker-volume-ipfs) | An open source volume plugin that allows using an [ipfs](https://ipfs.io/) filesystem as a volume. |\n| [Keywhiz plugin](https://github.com/calavera/docker-volume-keywhiz) | A plugin that provides credentials and secret management using Keywhiz as a central repository. |\n| [Linode Volume Plugin](https://github.com/linode/docker-volume-linode) | A plugin that adds the ability to manage Linode Block Storage as Docker Volumes from within a Linode. |\n| [Local Persist Plugin](https://github.com/CWSpear/local-persist) | A volume plugin that extends the default `local` driver's functionality by allowing you specify a mountpoint anywhere on the host, which enables the files to _always persist_, even if the volume is removed via `docker volume rm`. |\n| [NetApp Plugin](https://github.com/NetApp/netappdvp) (nDVP) | A volume plugin that provides direct integration with the Docker ecosystem for the NetApp storage portfolio. The nDVP package supports the provisioning and management of storage resources from the storage platform to Docker hosts, with a robust framework for adding additional platforms in the future. |\n| [Netshare plugin](https://github.com/ContainX/docker-volume-netshare) | A volume plugin that provides volume management for NFS 3/4, AWS EFS and CIFS file systems. |\n| [Nimble Storage Volume Plugin](https://scod.hpedev.io/docker_volume_plugins/hpe_nimble_storage/index.html) | A volume plug-in that integrates with Nimble Storage Unified Flash Fabric arrays. The plug-in abstracts array volume capabilities to the Docker administrator to allow self-provisioning of secure multi-tenant volumes and clones. |\n| [OpenStorage Plugin](https://github.com/libopenstorage/openstorage) | A cluster-aware volume plugin that provides volume management for file and block storage solutions. It implements a vendor neutral specification for implementing extensions such as CoS, encryption, and snapshots. It has example drivers based on FUSE, NFS, NBD and EBS to name a few. |\n| [Portworx Volume Plugin](https://github.com/portworx/px-dev) | A volume plugin that turns any server into a scale-out converged compute/storage node, providing container granular storage and highly available volumes across any node, using a shared-nothing storage backend that works with any docker scheduler. |\n| [Quobyte Volume Plugin](https://github.com/quobyte/docker-volume) | A volume plugin that connects Docker to [Quobyte](https://www.quobyte.com/containers)'s data center file system, a general-purpose scalable and fault-tolerant storage platform. |\n| [REX-Ray plugin](https://github.com/emccode/rexray) | A volume plugin which is written in Go and provides advanced storage functionality for many platforms including VirtualBox, EC2, Google Compute Engine, OpenStack, and EMC. |\n| [Virtuozzo Storage and Ploop plugin](https://github.com/virtuozzo/docker-volume-ploop) | A volume plugin with support for Virtuozzo Storage distributed cloud file system as well as ploop devices. |\n| [VMware vSphere Storage Plugin](https://github.com/vmware/docker-volume-vsphere) | Docker Volume Driver for vSphere enables customers to address persistent storage requirements for Docker containers in vSphere environments. |\n\n| Plugin | Description |\n| --- | --- |\n| [Casbin AuthZ Plugin](https://github.com/casbin/casbin-authz-plugin) | An authorization plugin based on [Casbin](https://github.com/casbin/casbin), which supports access control models like ACL, RBAC, ABAC. The access control model can be customized. The policy can be persisted into file or DB. |\n| [HBM plugin](https://github.com/kassisol/hbm) | An authorization plugin that prevents from executing commands with certains parameters. |\n| [Twistlock AuthZ Broker](https://github.com/twistlock/authz) | A basic extendable authorization plugin that runs directly on the host or inside a container. This plugin allows you to define user policies that it evaluates during authorization. Basic authorization is provided if Docker daemon is started with the --tlsverify flag (username is extracted from the certificate common name). |\n\nIf you are having problems with Docker after loading a plugin, ask the authors of the plugin for help. The Docker team may not be able to assist you.\n\nIf you are interested in writing a plugin for Docker, or seeing how they work under the hood, see the [Docker plugins reference](https://docs.docker.com/engine/extend/plugin_api/).",
    "title": "Use Docker Engine plugins | Docker Docs\n",
    "description": "How to add additional functionality to Docker with plugins extensions",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/26.1/",
    "markdown": "# Docker Engine 26.1 release notes\n\nThis page describes the latest changes, additions, known issues, and fixes for Docker Engine version 26.1.\n\nFor more information about:\n\n*   Deprecated and removed features, see [Deprecated Engine Features](https://docs.docker.com/engine/deprecated/).\n*   Changes to the Engine API, see [Engine API version history](https://docs.docker.com/engine/api/version-history/).\n\n_2024-06-05_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 26.1.4 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A26.1.4)\n*   [moby/moby, 26.1.4 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A26.1.4)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v26.1.4/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v26.1.4/docs/api/version-history.md).\n\n### [Security](#security)\n\nThis release updates the Go runtime to 1.21.11 which contains security fixes for:\n\n*   [CVE-2024-24789](https://github.com/golang/go/issues/66869)\n*   [CVE-2024-24790](https://github.com/golang/go/issues/67680)\n*   A symlink time of check to time of use race condition during directory removal reported by [Addison Crump](https://github.com/addisoncrump).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements)\n\n*   Fixed an issue where promoting a node immediately after another node was demoted could cause the promotion to fail. [moby/moby#47870](https://github.com/moby/moby/pull/47870)\n*   Prevent the daemon log from being spammed with `superfluous response.WriteHeader call ...` messages. [moby/moby#47843](https://github.com/moby/moby/pull/47843)\n*   Don't show empty hints when plugins return an empty hook message. [docker/cli#5083](https://github.com/docker/cli/pull/5083)\n*   Fix a compatibility issue with Visual Studio Container Tools. [docker/cli#5095](https://github.com/docker/cli/pull/5095)\n\n### [Packaging updates](#packaging-updates)\n\n*   Update containerd (static binaries only) to [v1.7.17](https://github.com/containerd/containerd/releases/tag/v1.7.17). [moby/moby#47841](https://github.com/moby/moby/pull/47841)\n*   [CVE-2024-24789](https://github.com/golang/go/issues/66869), [CVE-2024-24790](https://github.com/golang/go/issues/67680): Update Go runtime to 1.21.11. [moby/moby#47904](https://github.com/moby/moby/pull/47904)\n*   Update Compose to [v2.27.1](https://github.com/docker/compose/releases/tag/v2.27.1). [docker/docker-ce-packages#1022](https://github.com/docker/docker-ce-packaging/pull/1022)\n*   Update Buildx to [v0.14.1](https://github.com/docker/buildx/releases/tag/v0.14.1). [docker/docker-ce-packages#1021](https://github.com/docker/docker-ce-packaging/pull/1021)\n\n_2024-05-16_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 26.1.3 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A26.1.3)\n*   [moby/moby, 26.1.3 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A26.1.3)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v26.1.3/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v26.1.3/docs/api/version-history.md).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-1)\n\n*   Fix a regression that prevented the use of DNS servers within a `--internal` network. [moby/moby#47832](https://github.com/moby/moby/pull/47832)\n*   When the internal DNS server's own address is supplied as an external server address, ignore it to avoid unproductive recursion. [moby/moby#47833](https://github.com/moby/moby/pull/47833)\n\n### [Packaging updates](#packaging-updates-1)\n\n*   Allow runc to kill containers when confined to the runc profile in AppArmor version 4.0.0 and later. [moby/moby#47829](https://github.com/moby/moby/pull/47829)\n\n_2024-05-08_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 26.1.2 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A26.1.2)\n*   [moby/moby, 26.1.2 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A26.1.2)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v26.1.2/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v26.1.2/docs/api/version-history.md).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-2)\n\n*   Fix an issue where the CLI process would sometimes hang when a container failed to start. [docker/cli#5062](https://github.com/docker/cli/pull/5062)\n\n### [Packaging updates](#packaging-updates-2)\n\n*   Update Go runtime to 1.21.10. [moby/moby#47806](https://github.com/moby/moby/pull/47806)\n\n_2024-04-30_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 26.1.1 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A26.1.1)\n*   [moby/moby, 26.1.1 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A26.1.1)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v26.1.1/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v26.1.1/docs/api/version-history.md).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-3)\n\n*   Fix `docker run -d` printing an `context canceled` spurious error when OpenTelemetry is configured. [docker/cli#5044](https://github.com/docker/cli/pull/5044)\n*   Experimental environment variable `DOCKER_BRIDGE_PRESERVE_KERNEL_LL=1` will prevent the daemon from removing the kernel-assigned link local address on a Linux bridge. [moby/moby#47775](https://github.com/moby/moby/pull/47775)\n*   Resolve an issue preventing container creation on hosts with a read-only `/proc/sys/net` filesystem. If IPv6 cannot be disabled on an interface due to this, either disable IPv6 by default on the host or ensure `/proc/sys/net` is read-write. To bypass the error, set the environment variable `DOCKER_ALLOW_IPV6_ON_IPV4_INTERFACE=1` before starting the Docker daemon. [moby/moby#47769](https://github.com/moby/moby/pull/47769)\n\n> **Note**\n> \n> The `DOCKER_ALLOW_IPV6_ON_IPV4_INTERFACE` is added as a temporary fix and will be phased out in a future major release, when the IPv6 enablement process has been improved.\n\n### [Packaging updates](#packaging-updates-3)\n\n*   Update BuildKit to [v0.13.2](https://github.com/moby/buildkit/releases/tag/v0.13.2). [moby/moby#47762](https://github.com/moby/moby/pull/47762)\n*   Update Compose to [v2.27.0](https://github.com/docker/compose/releases/tag/v2.27.0). [docker/docker-ce-packages#1017](https://github.com/docker/docker-ce-packaging/pull/1017)\n\n_2024-04-22_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 26.1.0 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A26.1.0)\n*   [moby/moby, 26.1.0 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A26.1.0)\n*   Deprecated and removed features, see [Deprecated Features](https://github.com/docker/cli/blob/v26.1.0/docs/deprecated.md).\n*   Changes to the Engine API, see [API version history](https://github.com/moby/moby/blob/v26.1.0/docs/api/version-history.md).\n\n### [New](#new)\n\n*   Added configurable OpenTelemetry utilities and basic instrumentation to commands. For more information, see [OpenTelemetry for the Docker CLI](https://docs.docker.com/config/otel). [docker/cli#4889](https://github.com/docker/cli/pull/4889)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-4)\n\n*   Native Windows containers are configured with an internal DNS server for container name resolution, and external DNS servers for other lookups. Not all resolvers, including `nslookup`, fall back to the external resolvers when they get a `SERVFAIL` answer from the internal server. So, the internal DNS server can now be configured to forward requests to the external resolvers, by setting a `feature` option in the `daemon.json` file:\n    \n    [moby/moby#47584](https://github.com/moby/moby/pull/47584)\n    \n    > **Note**\n    > \n    > *   This will be the new default behavior in Docker Engine 27.0.\n    > *   The `windows-dns-proxy` feature flag will be removed in a future release.\n    \n*   Swarm: Fix `Subpath` not being passed to the container config. [moby/moby#47711](https://github.com/moby/moby/pull/47711)\n    \n*   Classic builder: Fix cache miss on `WORKDIR <directory>/` build step (directory with a trailing slash). [moby/moby#47723](https://github.com/moby/moby/pull/47723)\n    \n*   containerd image store: Fix `docker images` failing when any image in the store has unexpected target. [moby/moby#47738](https://github.com/moby/moby/pull/47738)",
    "title": "Docker Engine 26.1 release notes | Docker Docs\n",
    "description": "Learn about the new features, bug fixes, and breaking changes for Docker Engine",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/extend/plugins_network/",
    "markdown": "# Docker network driver plugins | Docker Docs\n\nThis document describes Docker Engine network driver plugins generally available in Docker Engine. To view information on plugins managed by Docker Engine, refer to [Docker Engine plugin system](https://docs.docker.com/engine/extend/).\n\nDocker Engine network plugins enable Engine deployments to be extended to support a wide range of networking technologies, such as VXLAN, IPVLAN, MACVLAN or something completely different. Network driver plugins are supported via the LibNetwork project. Each plugin is implemented as a \"remote driver\" for LibNetwork, which shares plugin infrastructure with Engine. Effectively, network driver plugins are activated in the same way as other plugins, and use the same kind of protocol.\n\n[Legacy plugins](https://docs.docker.com/engine/extend/legacy_plugins/) do not work in Swarm mode. However, plugins written using the [v2 plugin system](https://docs.docker.com/engine/extend/) do work in Swarm mode, as long as they are installed on each Swarm worker node.\n\nThe means of installing and running a network driver plugin depend on the particular plugin. So, be sure to install your plugin according to the instructions obtained from the plugin developer.\n\nOnce running however, network driver plugins are used just like the built-in network drivers: by being mentioned as a driver in network-oriented Docker commands. For example,\n\nSome network driver plugins are listed in [plugins](https://docs.docker.com/engine/extend/legacy_plugins/)\n\nThe `mynet` network is now owned by `weave`, so subsequent commands referring to that network will be sent to the plugin,\n\nNetwork plugins are written by third parties, and are published by those third parties, either on [Docker Hub](https://hub.docker.com/search?q=&type=plugin) or on the third party's site.\n\nNetwork plugins implement the [Docker plugin API](https://docs.docker.com/engine/extend/plugin_api/) and the network plugin protocol\n\nThe network driver protocol, in addition to the plugin activation call, is documented as part of libnetwork: [https://github.com/moby/moby/blob/master/libnetwork/docs/remote.md](https://github.com/moby/moby/blob/master/libnetwork/docs/remote.md).\n\nTo interact with the Docker maintainers and other interested users, see the IRC channel `#docker-network`.\n\n*   [Docker networks feature overview](https://docs.docker.com/engine/userguide/networking/)\n*   The [LibNetwork](https://github.com/docker/libnetwork) project",
    "title": "Docker network driver plugins | Docker Docs\n",
    "description": "Network driver plugins.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/",
    "markdown": "# Getting started with Swarm mode\n\nThis tutorial introduces you to the features of Docker Engine Swarm mode. You may want to familiarize yourself with the [key concepts](https://docs.docker.com/engine/swarm/key-concepts/) before you begin.\n\nThe tutorial guides you through:\n\n*   Initializing a cluster of Docker Engines in swarm mode\n*   Adding nodes to the swarm\n*   Deploying application services to the swarm\n*   Managing the swarm once you have everything running\n\nThis tutorial uses Docker Engine CLI commands entered on the command line of a terminal window.\n\nIf you are brand new to Docker, see [About Docker Engine](https://docs.docker.com/engine/).\n\nTo run this tutorial, you need:\n\n*   [Three Linux hosts which can communicate over a network, with Docker installed](#three-networked-host-machines)\n*   [The IP address of the manager machine](#the-ip-address-of-the-manager-machine)\n*   [Open ports between the hosts](#open-protocols-and-ports-between-the-hosts)\n\n### [Three networked host machines](#three-networked-host-machines)\n\nThis tutorial requires three Linux hosts which have Docker installed and can communicate over a network. These can be physical machines, virtual machines, Amazon EC2 instances, or hosted in some other way. Check out [Deploy to Swarm](https://docs.docker.com/guides/deployment-orchestration/swarm-deploy/#prerequisites) for one possible set-up for the hosts.\n\nOne of these machines is a manager (called `manager1`) and two of them are workers (`worker1` and `worker2`).\n\n> **Note**\n> \n> You can follow many of the tutorial steps to test single-node swarm as well, in which case you need only one host. Multi-node commands do not work, but you can initialize a swarm, create services, and scale them.\n\n#### [Install Docker Engine on Linux machines](#install-docker-engine-on-linux-machines)\n\nIf you are using Linux based physical computers or cloud-provided computers as hosts, simply follow the [Linux install instructions](https://docs.docker.com/engine/install/) for your platform. Spin up the three machines, and you are ready. You can test both single-node and multi-node swarm scenarios on Linux machines.\n\n### [The IP address of the manager machine](#the-ip-address-of-the-manager-machine)\n\nThe IP address must be assigned to a network interface available to the host operating system. All nodes in the swarm need to connect to the manager at the IP address.\n\nBecause other nodes contact the manager node on its IP address, you should use a fixed IP address.\n\nYou can run `ifconfig` on Linux or macOS to see a list of the available network interfaces.\n\nThe tutorial uses `manager1` : `192.168.99.100`.\n\n### [Open protocols and ports between the hosts](#open-protocols-and-ports-between-the-hosts)\n\nThe following ports must be available. On some systems, these ports are open by default.\n\n*   Port `2377` TCP for communication with and between manager nodes\n*   Port `7946` TCP/UDP for overlay network node discovery\n*   Port `4789` UDP (configurable) for overlay network traffic\n\nIf you plan on creating an overlay network with encryption (`--opt encrypted`), you also need to ensure IP protocol 50 (IPSec ESP) traffic is allowed.\n\nPort `4789` is the default value for the Swarm data path port, also known as the VXLAN port. It is important to prevent any untrusted traffic from reaching this port, as VXLAN does not provide authentication. This port should only be opened to a trusted network, and never at a perimeter firewall.\n\nIf the network which Swarm traffic traverses is not fully trusted, it is strongly suggested that encrypted overlay networks be used. If encrypted overlay networks are in exclusive use, some additional hardening is suggested:\n\n*   [Customize the default ingress network](https://docs.docker.com/engine/swarm/networking/) to use encryption\n*   Only accept encrypted packets on the Data Path Port:\n\nNext, you'll create a swarm.",
    "title": "Getting started with Swarm mode | Docker Docs\n",
    "description": "Getting Started tutorial for Docker Engine Swarm mode",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/25.0/",
    "markdown": "# Docker Engine 25.0 release notes\n\nThis page describes the latest changes, additions, known issues, and fixes for Docker Engine version 25.0.\n\nFor more information about:\n\n*   Deprecated and removed features, see [Deprecated Engine Features](https://docs.docker.com/engine/deprecated/).\n*   Changes to the Engine API, see [Engine API version history](https://docs.docker.com/engine/api/version-history/).\n\n_2024-03-19_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 25.0.5 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A25.0.5)\n*   [moby/moby, 25.0.5 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A25.0.5)\n\n### [Security](#security)\n\nThis release contains a security fix for [CVE-2024-29018](https://github.com/moby/moby/security/advisories/GHSA-mq39-4gv4-mvpx), a potential data exfiltration from 'internal' networks via authoritative DNS servers.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements)\n\n*   [CVE-2024-29018](https://github.com/moby/moby/security/advisories/GHSA-mq39-4gv4-mvpx): Do not forward requests to external DNS servers for a container that is only connected to an 'internal' network. Previously, requests were forwarded if the host's DNS server was running on a loopback address, like systemd's 127.0.0.53. [moby/moby#47589](https://github.com/moby/moby/pull/47589)\n    \n*   plugin: fix mounting /etc/hosts when running in UserNS. [moby/moby#47588](https://github.com/moby/moby/pull/47588)\n    \n*   rootless: fix `open /etc/docker/plugins: permission denied`. [moby/moby#47587](https://github.com/moby/moby/pull/47587)\n    \n*   Fix multiple parallel `docker build` runs leaking disk space. [moby/moby#47527](https://github.com/moby/moby/pull/47527)\n    \n\n_2024-03-07_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 25.0.4 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A25.0.4)\n*   [moby/moby, 25.0.4 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A25.0.4)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-1)\n\n*   Restore DNS names for containers in the default \"nat\" network on Windows. [moby/moby#47490](https://github.com/moby/moby/pull/47490)\n*   Fix `docker start` failing when used with `--checkpoint` [moby/moby#47466](https://github.com/moby/moby/pull/47466)\n*   Don't enforce new validation rules for existing swarm networks [moby/moby#47482](https://github.com/moby/moby/pull/47482)\n*   Restore IP connectivity between the host and containers on an internal bridge network. [moby/moby#47481](https://github.com/moby/moby/pull/47481)\n*   Fix a regression introduced in v25.0 that prevented the classic builder from adding tar archive with `xattrs` created on a non-Linux OS [moby/moby#47483](https://github.com/moby/moby/pull/47483)\n*   containerd image store: Fix image pull not emitting `Pulling fs layer status` [moby/moby#47484](https://github.com/moby/moby/pull/47484)\n*   API: To preserve backwards compatibility, make read-only mounts non-recursive by default when using older clients (API versions < v1.44). [moby/moby#47393](https://github.com/moby/moby/pull/47393)\n*   API: `GET /images/{id}/json` omits the `Created` field (previously it was `0001-01-01T00:00:00Z`) if the `Created` field was missing from the image config. [moby/moby#47451](https://github.com/moby/moby/pull/47451)\n*   API: Populate a missing `Created` field in `GET /images/{id}/json` with `0001-01-01T00:00:00Z` for API versions <= 1.43. [moby/moby#47387](https://github.com/moby/moby/pull/47387)\n*   API: Fix a regression that caused API socket connection failures to report an API version negotiation failure instead. [moby/moby#47470](https://github.com/moby/moby/pull/47470)\n*   API: Preserve supplied endpoint configuration in a container-create API request, when a container-wide MAC address is specified, but `NetworkMode` name or id is not the same as the name or id used in `NetworkSettings.Networks`. [moby/moby#47510](https://github.com/moby/moby/pull/47510)\n\n### [Packaging updates](#packaging-updates)\n\n*   Upgrade Go runtime to 1.21.8. [moby/moby#47503](https://github.com/moby/moby/pull/47503)\n*   Upgrade RootlessKit to v2.0.2. [moby/moby#47508](https://github.com/moby/moby/pull/47508)\n*   Upgrade Compose to v2.24.7. [docker/docker-ce-packaging#998](https://github.com/moby/moby/pull/998)\n*   Upgrade Buildx to v0.13.0. [docker/docker-ce-packaging#997](https://github.com/moby/moby/pull/997)\n\n_2024-02-06_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 25.0.3 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A25.0.3)\n*   [moby/moby, 25.0.3 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A25.0.3)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-2)\n\n*   containerd image store: Fix a bug where `docker image history` would fail if a manifest wasn't found in the content store. [moby/moby#47348](https://github.com/moby/moby/pull/47348)\n    \n*   Ensure that a generated MAC address is not restored when a container is restarted, but a configured MAC address is preserved. [moby/moby#47304](https://github.com/moby/moby/pull/47304)\n    \n    > **Note**\n    > \n    > *   Containers created with Docker Engine version 25.0.0 may have duplicate MAC addresses. They must be re-created.\n    > *   Containers with user-defined MAC addresses created with Docker Engine versions 25.0.0 or 25.0.1 receive new MAC addresses when started using Docker Engine version 25.0.2. They must also be re-created.\n    \n*   Fix `docker save <image>@<digest>` producing an OCI archive with index without manifests. [moby/moby#47294](https://github.com/moby/moby/pull/47294)\n    \n*   Fix a bug preventing bridge networks from being created with an MTU higher than 1500 on RHEL and CentOS 7. [moby/moby#47308](https://github.com/moby/moby/issues/47308), [moby/moby#47311](https://github.com/moby/moby/pull/47311)\n    \n*   Fix a bug where containers are unable to communicate over an `internal` network. [moby/moby#47303](https://github.com/moby/moby/pull/47303)\n    \n*   Fix a bug where the value of the `ipv6` daemon option was ignored. [moby/moby#47310](https://github.com/moby/moby/pull/47310)\n    \n*   Fix a bug where trying to install a pulling using a digest revision would cause a panic. [moby/moby#47323](https://github.com/moby/moby/pull/47323)\n    \n*   Fix a potential race condition in the managed containerd supervisor. [moby/moby#47313](https://github.com/moby/moby/pull/47313)\n    \n*   Fix an issue with the `journald` log driver preventing container logs from being followed correctly with systemd version 255. [moby/moby47243](https://github.com/moby/moby/pull/47243)\n    \n*   seccomp: Update the builtin seccomp profile to include syscalls added in kernel v5.17 - v6.7 to align the profile with the profile used by containerd. [moby/moby#47341](https://github.com/moby/moby/pull/47341)\n    \n*   Windows: Fix cache not being used when building images based on Windows versions older than the host's version. [moby/moby#47307](https://github.com/moby/moby/pull/47307), [moby/moby#47337](https://github.com/moby/moby/pull/47337)\n    \n\n### [Packaging updates](#packaging-updates-1)\n\n*   Removed support for Ubuntu Lunar (23.04). [docker/ce-packaging#986](https://github.com/docker/docker-ce-packaging/pull/986)\n\n_2024-01-31_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 25.0.2 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A25.0.2)\n*   [moby/moby, 25.0.2 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A25.0.2)\n\n### [Security](#security-1)\n\nThis release contains security fixes for the following CVEs affecting Docker Engine and its components.\n\n| CVE | Component | Fix version | Severity |\n| --- | --- | --- | --- |\n| [CVE-2024-21626](https://scout.docker.com/v/CVE-2024-21626) | runc | 1.1.12 | High, CVSS 8.6 |\n| [CVE-2024-23651](https://scout.docker.com/v/CVE-2024-23651) | BuildKit | 1.12.5 | High, CVSS 8.7 |\n| [CVE-2024-23652](https://scout.docker.com/v/CVE-2024-23652) | BuildKit | 1.12.5 | High, CVSS 8.7 |\n| [CVE-2024-23653](https://scout.docker.com/v/CVE-2024-23653) | BuildKit | 1.12.5 | High, CVSS 7.7 |\n| [CVE-2024-23650](https://scout.docker.com/v/CVE-2024-23650) | BuildKit | 1.12.5 | Medium, CVSS 5.5 |\n| [CVE-2024-24557](https://scout.docker.com/v/CVE-2024-24557) | Docker Engine | 25.0.2 | Medium, CVSS 6.9 |\n\nThe potential impacts of the above vulnerabilities include:\n\n*   Unauthorized access to the host filesystem\n*   Compromising the integrity of the build cache\n*   In the case of CVE-2024-21626, a scenario that could lead to full container escape\n\nFor more information about the security issues addressed in this release, refer to the [blog post](https://www.docker.com/blog/docker-security-advisory-multiple-vulnerabilities-in-runc-buildkit-and-moby/). For details about each vulnerability, see the relevant security advisory:\n\n*   [CVE-2024-21626](https://github.com/opencontainers/runc/security/advisories/GHSA-xr7r-f8xq-vfvv)\n*   [CVE-2024-23651](https://github.com/moby/buildkit/security/advisories/GHSA-m3r6-h7wv-7xxv)\n*   [CVE-2024-23652](https://github.com/moby/buildkit/security/advisories/GHSA-4v98-7qmw-rqr8)\n*   [CVE-2024-23653](https://github.com/moby/buildkit/security/advisories/GHSA-wr6v-9f75-vh2g)\n*   [CVE-2024-23650](https://github.com/moby/buildkit/security/advisories/GHSA-9p26-698r-w4hx)\n*   [CVE-2024-24557](https://github.com/moby/moby/security/advisories/GHSA-xw73-rw38-6vjc)\n\n### [Packaging updates](#packaging-updates-2)\n\n*   Upgrade containerd to [v1.6.28](https://github.com/containerd/containerd/releases/tag/v1.6.28).\n*   Upgrade containerd to v1.7.13 (static binaries only). [moby/moby#47280](https://github.com/moby/moby/pull/47280)\n*   Upgrade runc to v1.1.12. [moby/moby#47269](https://github.com/moby/moby/pull/47269)\n*   Upgrade Compose to v2.24.5. [docker/docker-ce-packaging#985](https://github.com/docker/docker-ce-packaging/pull/985)\n*   Upgrade BuildKit to v0.12.5. [moby/moby#47273](https://github.com/moby/moby/pull/47273)\n\n_2024-01-23_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 25.0.1 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A25.0.1)\n*   [moby/moby, 25.0.1 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A25.0.1)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-3)\n\n*   API: Fix incorrect HTTP status code for containers with an invalid network configuration created before upgrading to Docker Engine v25.0. [moby/moby#47159](https://github.com/moby/moby/pull/47159)\n*   Ensure that a MAC address based on a container's IP address is re-generated when the container is stopped and restarted, in case the generated IP/MAC addresses have been reused. [moby/moby#47171](https://github.com/moby/moby/pull/47171)\n*   Fix `host-gateway-ip` not working during build when not set through configuration. [moby/moby#47192](https://github.com/moby/moby/pull/47192)\n*   Fix a bug that prevented a container from being renamed twice. [moby/moby#47196](https://github.com/moby/moby/pull/47196)\n*   Fix an issue causing containers to have their short ID added to their network alias when inspecting them. [moby/moby#47182](https://github.com/moby/moby/pull/47182)\n*   Fix an issue in detecting whether a remote build context is a Git repository. [moby/moby#47136](https://github.com/moby/moby/pull/47136)\n*   Fix an issue with layers order in OCI manifests. [moby/moby#47150](https://github.com/moby/moby/issues/47150)\n*   Fix volume mount error when passing an `addr` or `ip` mount option. [moby/moby#47185](https://github.com/moby/moby/pull/47185)\n*   Improve error message related to extended attributes that can't be set due to improperly namespaced attribute names. [moby/moby#47178](https://github.com/moby/moby/pull/47178)\n*   Swarm: Fixed `start_interval` not being passed to the container config. [moby/moby#47163](https://github.com/moby/moby/pull/47163)\n\n### [Packaging updates](#packaging-updates-3)\n\n*   Upgrade Compose to `2.24.2`. [docker/docker-ce-packaging#981](https://github.com/docker/docker-ce-packaging/pull/981)\n\n_2024-01-19_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 25.0.0 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A25.0.0)\n*   [moby/moby, 25.0.0 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A25.0.0)\n\n> **Note**\n> \n> In earlier versions of Docker Engine, recursive mounts (submounts) would always be mounted as writable, even when specifying a read-only mount. This behavior has changed in v25.0.0, for hosts running on kernel version 5.12 or later. Now, read-only bind mounts are **recursively read-only** by default.\n> \n> To get the same behavior as earlier releases, you can specify the `bind-recursive` option for the `--mount` flag.\n> \n> This option isn't supported with the `-v` or `--volume` flag. For more information, see [Recursive mounts](https://docs.docker.com/storage/bind-mounts/#recursive-mounts).\n\n### [New](#new)\n\n*   The daemon now uses systemd's default `LimitNOFILE`. In earlier versions of Docker Engine, this limit was set to `infinity`. This would cause issues with recent versions of systemd, where the hard limit was increased, causing programs that adjusted their behaviors based on ulimits to consume a high amount of memory. [moby/moby#45534](https://github.com/moby/moby/pull/45534)\n    \n    The new setting makes containers behave the same way as programs running on the host, but may cause programs that make incorrect assumptions based on the soft limit to misbehave. To get the previous behavior, you can set `LimitNOFILE=1048576`.\n    \n    This change currently only affects build containers created with `docker build` when using BuildKit with the `docker` driver. Future versions of containerd will also use this limit, which will cause this behavior to affect all containers, not only build containers.\n    \n    If you're experiencing issues with the higher ulimit in systemd v240 or later, consider adding a system `drop-in` or `override` file to configure the ulimit settings for your setup. The [Flatcar Container Linux documentation](https://www.flatcar.org/docs/latest/setup/systemd/drop-in-units/) has a great article covering this topic in detail.\n    \n*   Add OpenTelemetry tracing. [moby/moby#45652](https://github.com/moby/moby/pull/45652), [moby/moby#45579](https://github.com/moby/moby/pull/45579)\n    \n*   Add support for CDI devices under Linux. [moby/moby#45134](https://github.com/moby/moby/pull/45134), [docker/cli#4510](https://github.com/docker/cli/pull/4510), [moby/moby#46004](https://github.com/moby/moby/pull/46004)\n    \n*   Add an additional interval to be used by healthchecks during the container start period. [moby/moby#40894](https://github.com/moby/moby/pull/40894), [docker/cli#4405](https://github.com/docker/cli/pull/4405), [moby/moby#45965](https://github.com/moby/moby/pull/45965)\n    \n*   Add a `--log-format` flag to `dockerd` to control the logging format: text (default) or JSON. [moby/moby#45737](https://github.com/moby/moby/pull/45737)\n    \n*   Add support for recursive read-only mounts. [moby/moby#45278](https://github.com/moby/moby/pull/45278), [moby/moby#46037](https://github.com/moby/moby/pull/46037)\n    \n*   Add support for filtering images based on timestamp with `docker image ls --filter=until=<timestamp>`. [moby/moby#46577](https://github.com/moby/moby/pull/46577)\n    \n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-4)\n\n*   API: Fix error message for invalid policies at `ValidateRestartPolicy`. [moby/moby#46352](https://github.com/moby/moby/pull/46352)\n*   API: Update `/info` endpoint to use singleflight. [moby/moby#45847](https://github.com/moby/moby/pull/45847)\n*   Add an error message for when specifying a Dockerfile filename with `-f`, and also using `stdin`. [docker/cli#4346](https://github.com/docker/cli/pull/4346)\n*   Add support for `mac-address` and `link-local-ip` fields in `--network` long format. [docker/cli#4419](https://github.com/docker/cli/pull/4419)\n*   Add support for specifying multiple `--network` flags with `docker container create` and `docker run`. [moby/moby#45906](https://github.com/moby/moby/pull/45906)\n*   Automatically enable IPv6 on a network when an IPv6 subnet is specified. [moby/moby#46455](https://github.com/moby/moby/pull/46455)\n*   Add support for overlay networks over IPv6 transport. [moby/moby#46790](https://github.com/moby/moby/pull/46790)\n*   Configuration reloading is now more robust: if there's an error during the configuration reload process, no configuration changes are applied. [moby/moby#43980](https://github.com/moby/moby/pull/43980)\n*   Live restore: Containers with auto remove (`docker run --rm`) are no longer forcibly removed on engine restart. [moby/moby#46857](https://github.com/moby/moby/pull/46857)\n*   Live restore: containers that are live-restored will now be given another health-check start period when the daemon restarts. [moby/moby#47051](https://github.com/moby/moby/pull/47051)\n*   Container health status is flushed to disk less frequently, reducing wear on flash storage. [moby/moby#47044](https://github.com/moby/moby/pull/47044)\n*   Ensure network names are unique. [moby/moby#46251](https://github.com/moby/moby/pull/46251)\n*   Ensure that overlay2 layer metadata is correct. [moby/moby#46471](https://github.com/moby/moby/pull/46471)\n*   Fix `Downloading` progress message on image pull. [moby/moby#46515](https://github.com/moby/moby/pull/46515)\n*   Fix `NetworkConnect` and `ContainerCreate` with improved data validation, and return all validation errors at once. [moby/moby#46183](https://github.com/moby/moby/pull/46183)\n*   Fix `com.docker.network.host_ipv4` option when IPv6 and ip6tables are enabled. [moby/moby#46446](https://github.com/moby/moby/pull/46446)\n*   Fix daemon's `cleanupContainer` if containerd is stopped. [moby/moby#46213](https://github.com/moby/moby/pull/46213)\n*   Fix returning incorrect HTTP status codes for libnetwork errors. [moby/moby#46146](https://github.com/moby/moby/pull/46146)\n*   Fix various issues with images/json API filters and image list. [moby/moby#46034](https://github.com/moby/moby/pull/46034)\n*   CIFS volumes now resolves FQDN correctly. [moby/moby#46863](https://github.com/moby/moby/pull/46863)\n*   Improve validation of the `userland-proxy-path` daemon configuration option. Validation now happens during daemon startup, instead of producing an error when starting a container with port-mapping. [moby/moby#47000](https://github.com/moby/moby/pull/47000)\n*   Set the MAC address of container's interface when network mode is a short network ID. [moby/moby#46406](https://github.com/moby/moby/pull/46406)\n*   Sort unconsumed build arguments before display in build output. [moby/moby#45917](https://github.com/moby/moby/pull/45917)\n*   The `docker image save` tarball output is now OCI compliant. [moby/moby#44598](https://github.com/moby/moby/pull/44598)\n*   The daemon no longer appends `ACCEPT` rules to the end of the `INPUT` iptables chain for encrypted overlay networks. Depending on firewall configuration, a rule may be needed to permit incoming encrypted overlay network traffic. [moby/moby#45280](https://github.com/moby/moby/pull/45280)\n*   Unpacking layers with extended attributes onto an incompatible filesystem will now fail instead of silently discarding extended attributes. [moby/moby#45464](https://github.com/moby/moby/pull/45464)\n*   Update daemon MTU option to BridgeConfig and display warning on Windows. [moby/moby#45887](https://github.com/moby/moby/pull/45887)\n*   Validate IPAM config when creating a network. Automatically fix networks created prior to this release where `--ip-range` is larger than `--subnet`. [moby/moby#45759](https://github.com/moby/moby/pull/45759)\n*   Containers connected only to internal networks will now have no default route set, making the `connect` syscall fail-fast. [moby/moby#46603](https://github.com/moby/moby/pull/46603)\n*   containerd image store: Add image events for `push`, `pull`, and `save`. [moby/moby#46405](https://github.com/moby/moby/pull/46405)\n*   containerd image store: Add support for pulling legacy schema1 images. [moby/moby#46513](https://github.com/moby/moby/pull/46513)\n*   containerd image store: Add support for pushing all tags. [moby/moby#46485](https://github.com/moby/moby/pull/46485)\n*   containerd image store: Add support for registry token. [moby/moby#46475](https://github.com/moby/moby/pull/46475)\n*   containerd image store: Add support for showing the number of containers that use an image. [moby/moby#46511](https://github.com/moby/moby/pull/46511)\n*   containerd image store: Fix a bug related to the `ONBUILD`, `MAINTAINER`, and `HEALTHCHECK` Dockerfile instructions. [moby/moby#46313](https://github.com/moby/moby/pull/46313)\n*   containerd image store: Fix `Pulling from` progress message. [moby/moby#46494](https://github.com/moby/moby/pull/46494)\n*   containerd image store: Add support for referencing images via the truncated ID with `sha256:` prefix. [moby/moby#46435](https://github.com/moby/moby/pull/46435)\n*   containerd image store: Fix `docker images` showing intermediate layers by default. [moby/moby#46423](https://github.com/moby/moby/pull/46423)\n*   containerd image store: Fix checking if the specified platform exists when getting an image. [moby/moby#46495](https://github.com/moby/moby/pull/46495)\n*   containerd image store: Fix errors when multiple `ADD` or `COPY` instructions were used with the classic builder. [moby/moby#46383](https://github.com/moby/moby/pull/46383)\n*   containerd image store: Fix stack overflow errors when importing an image. [moby/moby#46418](https://github.com/moby/moby/pull/46418)\n*   containerd image store: Improve `docker pull` progress output. [moby/moby#46412](https://github.com/moby/moby/pull/46412)\n*   containerd image store: Print the tag, digest, and size after pushing an image. [moby/moby#46384](https://github.com/moby/moby/pull/46384)\n*   containerd image store: Remove panic from `UpdateConfig`. [moby/moby#46433](https://github.com/moby/moby/pull/46433)\n*   containerd image store: Return an error when an image tag resembles a digest. [moby/moby#46492](https://github.com/moby/moby/pull/46492)\n*   containerd image store: `docker image ls` now shows the correct image creation time and date. [moby/moby#46719](https://github.com/moby/moby/pull/46719)\n*   containerd image store: Fix an issue handling user namespace settings. [moby/moby#46375](https://github.com/moby/moby/pull/46375)\n*   containerd image store: Add support for pulling all tags (`docker pull -a`). [moby/moby#46618](https://github.com/moby/moby/pull/46618)\n*   containerd image store: Use the domain name in the image reference as the default registry authentication domain. [moby/moby#46779](https://github.com/moby/moby/pull/46779)\n\n### [Packaging updates](#packaging-updates-4)\n\n*   Upgrade API to v1.44. [moby/moby#45468](https://github.com/moby/moby/pull/45468)\n*   Upgrade Compose to `2.24.1`. [docker/docker-ce-packaging#980](https://github.com/docker/docker-ce-packaging/pull/980)\n*   Upgrade containerd to v1.7.12 (static binaries only). [moby/moby#47070](https://github.com/moby/moby/pull/47070)\n*   Upgrade Go runtime to [1.21.6](https://go.dev/doc/devel/release#go1.21.minor). [moby/moby#47053](https://github.com/moby/moby/pull/47053)\n*   Upgrade runc to v1.1.11. [moby/moby#47007](https://github.com/moby/moby/pull/47007)\n*   Upgrade BuildKit to v0.12.4. [moby/moby#46882](https://github.com/moby/moby/pull/46882)\n*   Upgrade Buildx to v0.12.1. [docker/docker-ce-packaging#979](https://github.com/docker/docker-ce-packaging/pull/979)\n\n### [Removed](#removed)\n\n*   API: Remove VirtualSize field for the `GET /images/json` and `GET /images/{id}/json` endpoints. [moby/moby#45469](https://github.com/moby/moby/pull/45469)\n*   Remove deprecated `devicemapper` storage driver. [moby/moby#43637](https://github.com/moby/moby/pull/43637)\n*   Remove deprecated orchestrator options. [docker/cli#4366](https://github.com/docker/cli/pull/4366)\n*   Remove support for Debian Upstart init system. [moby/moby#45548](https://github.com/moby/moby/pull/45548), [moby/moby#45551](https://github.com/moby/moby/pull/45551)\n*   Remove the `--oom-score-adjust` daemon option. [moby/moby#45484](https://github.com/moby/moby/pull/45484)\n*   Remove warning for deprecated `~/.dockercfg` file. [docker/cli#4281](https://github.com/docker/cli/pull/4281)\n*   Remove `logentries` logging driver. [moby/moby#46925](https://github.com/moby/moby/pull/46925)\n\n### [Deprecated](#deprecated)\n\n*   Deprecate API versions older than 1.24. [Deprecation notice](https://docs.docker.com/engine/deprecated/#deprecate-legacy-api-versions)\n*   Deprecate `IsAutomated` field and `is-automated` filter for `docker search`. [Deprecation notice](https://docs.docker.com/engine/deprecated/#isautomated-field-and-is-automated-filter-on-docker-search)\n*   API: Deprecate `Container` and `ContainerConfig` properties for `/images/{id}/json` (`docker image inspect`). [moby/moby#46939](https://github.com/moby/moby/pull/46939)\n\n### [Known limitations](#known-limitations)\n\n#### [Extended attributes for tar files](#extended-attributes-for-tar-files)\n\nIn this release, the code that handles `tar` archives was changed to be more strict and to produce an error when failing to write extended attributes (`xattr`). The `tar` implementation for macOS generates additional extended attributes by default when creating tar files. These attribute prefixes aren't valid Linux `xattr` namespace prefixes, which causes an error when Docker attempts to process these files. For example, if you try to use a tar file with an `ADD` Dockerfile instruction, you might see an error message similar to the following:\n\nError messages related to extended attribute validation were improved to include more context in [v25.0.1](#2501), but the limitation in Docker being unable to process the files remains. Tar files created with the macOS `tar` using default arguments will produce an error when the tar file is used with Docker.\n\nAs a workaround, if you need to use tar files with Docker generated on macOS, you can either:\n\n*   Use the `--no-xattr` flag for the macOS `tar` command to strip **all** the extended attributes. If you want to preserve extended attributes, this isn't a recommended option.\n    \n*   Install and use `gnu-tar` to create the tarballs on macOS instead of the default `tar` implementation. To install `gnu-tar` using Homebrew:\n    \n    After installing, add the `gnu-tar` binary to your `PATH`, for example by updating your `.zshrc` file:",
    "title": "Docker Engine 25.0 release notes | Docker Docs\n",
    "description": "Learn about the new features, bug fixes, and breaking changes for Docker Engine",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/drivers/docker-container/",
    "markdown": "# Docker container build driver | Docker Docs\n\nThe Docker container driver allows creation of a managed and customizable BuildKit environment in a dedicated Docker container.\n\nUsing the Docker container driver has a couple of advantages over the default Docker driver. For example:\n\n*   Specify custom BuildKit versions to use.\n*   Build multi-arch images, see [QEMU](#qemu)\n*   Advanced options for [cache import and export](https://docs.docker.com/build/cache/backends/)\n\nRun the following command to create a new builder, named `container`, that uses the Docker container driver:\n\nThe following table describes the available driver-specific options that you can pass to `--driver-opt`:\n\n| Parameter | Type | Default | Description |\n| --- | --- | --- | --- |\n| `image` | String |     | Sets the BuildKit image to use for the container. |\n| `memory` | String |     | Sets the amount of memory the container can use. |\n| `memory-swap` | String |     | Sets the memory swap limit for the container. |\n| `cpu-quota` | String |     | Imposes a CPU CFS quota on the container. |\n| `cpu-period` | String |     | Sets the CPU CFS scheduler period for the container. |\n| `cpu-shares` | String |     | Configures CPU shares (relative weight) of the container. |\n| `cpuset-cpus` | String |     | Limits the set of CPU cores the container can use. |\n| `cpuset-mems` | String |     | Limits the set of CPU memory nodes the container can use. |\n| `default-load` | Boolean | `false` | Automatically load images to the Docker Engine image store. |\n| `network` | String |     | Sets the network mode for the container. |\n| `cgroup-parent` | String | `/docker/buildx` | Sets the cgroup parent of the container if Docker is using the \"cgroupfs\" driver. |\n| `restart-policy` | String | `unless-stopped` | Sets the container's [restart policy](https://docs.docker.com/config/containers/start-containers-automatically/#use-a-restart-policy). |\n| `env.<key>` | String |     | Sets the environment variable `key` to the specified `value` in the container. |\n\nBefore you configure the resource limits for the container, read about [configuring runtime resource constraints for containers](https://docs.docker.com/config/containers/resource_constraints/).\n\nWhen you run a build, Buildx pulls the specified `image` (by default, [`moby/buildkit`](https://hub.docker.com/r/moby/buildkit)). When the container has started, Buildx submits the build submitted to the containerized build server.\n\nThe `docker-container` driver supports cache persistence, as it stores all the BuildKit state and related cache into a dedicated Docker volume.\n\nTo persist the `docker-container` driver's cache, even after recreating the driver using `docker buildx rm` and `docker buildx create`, you can destroy the builder using the `--keep-state` flag:\n\nFor example, to create a builder named `container` and then remove it while persisting state:\n\nThe `docker-container` driver supports using [QEMU](https://www.qemu.org/) (user mode) to build non-native platforms. Use the `--platform` flag to specify which architectures that you want to build for.\n\nFor example, to build a Linux image for `amd64` and `arm64`:\n\n> **Note**\n> \n> Emulation with QEMU can be much slower than native builds, especially for compute-heavy tasks like compilation and compression or decompression.\n\nYou can customize the network that the builder container uses. This is useful if you need to use a specific network for your builds.\n\nFor example, let's [create a network](https://docs.docker.com/reference/cli/docker/network/create/) named `foonet`:\n\nNow create a [`docker-container` builder](https://docs.docker.com/reference/cli/docker/buildx/create/) that will use this network:\n\nBoot and [inspect `mybuilder`](https://docs.docker.com/reference/cli/docker/buildx/inspect/):\n\n[Inspect the builder container](https://docs.docker.com/reference/cli/docker/inspect/) and see what network is being used:\n\nFor more information on the Docker container driver, see the [buildx reference](https://docs.docker.com/reference/cli/docker/buildx/create/#driver).",
    "title": "Docker container build driver | Docker Docs\n",
    "description": "The Docker container driver runs BuildKit in a container image.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/24.0/",
    "markdown": "# Docker Engine 24.0 release notes\n\nThis page describes the latest changes, additions, known issues, and fixes for Docker Engine version 24.0.\n\nFor more information about:\n\n*   Deprecated and removed features, see [Deprecated Engine Features](https://docs.docker.com/engine/deprecated/).\n*   Changes to the Engine API, see [Engine API version history](https://docs.docker.com/engine/api/version-history/).\n\n_2024-01-31_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.9 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.9)\n*   [moby/moby, 24.0.9 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.9)\n\nThis release contains security fixes for the following CVEs affecting Docker Engine and its components.\n\n| CVE | Component | Fix version | Severity |\n| --- | --- | --- | --- |\n| [CVE-2024-21626](https://scout.docker.com/v/CVE-2024-21626) | runc | 1.1.12 | High, CVSS 8.6 |\n| [CVE-2024-24557](https://scout.docker.com/v/CVE-2024-24557) | Docker Engine | 24.0.9 | Medium, CVSS 6.9 |\n\n> **Important**\n> \n> Note that this release of Docker Engine doesn't include fixes for the following known vulnerabilities in BuildKit:\n> \n> *   [CVE-2024-23651](https://scout.docker.com/v/CVE-2024-23651)\n> *   [CVE-2024-23652](https://scout.docker.com/v/CVE-2024-23652)\n> *   [CVE-2024-23653](https://scout.docker.com/v/CVE-2024-23653)\n> *   [CVE-2024-23650](https://scout.docker.com/v/CVE-2024-23650)\n> \n> To address these vulnerabilities, upgrade to [Docker Engine v25.0.2](https://docs.docker.com/engine/release-notes/25.0/#2502).\n\nFor more information about the security issues addressed in this release, and the unaddressed vulnerabilities in BuildKit, refer to the [blog post](https://www.docker.com/blog/docker-security-advisory-multiple-vulnerabilities-in-runc-buildkit-and-moby/).\n\nFor details about each vulnerability, see the relevant security advisory:\n\n*   [CVE-2024-21626](https://github.com/opencontainers/runc/security/advisories/GHSA-xr7r-f8xq-vfvv)\n*   [CVE-2024-24557](https://github.com/moby/moby/security/advisories/GHSA-xw73-rw38-6vjc)\n\n### [Packaging updates](#packaging-updates)\n\n*   Upgrade runc to [v1.1.12](https://github.com/opencontainers/runc/releases/tag/v1.1.12). [moby/moby#47269](https://github.com/moby/moby/pull/47269)\n*   Upgrade containerd to [v1.7.13](https://github.com/containerd/containerd/releases/tag/v1.7.13) (static binaries only). [moby/moby#47280](https://github.com/moby/moby/pull/47280)\n\n_2024-01-25_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.8 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.8)\n*   [moby/moby, 24.0.8 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.8)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements)\n\n*   Live restore: Containers with auto remove (`docker run --rm`) are no longer forcibly removed on engine restart. [moby/moby#46857](https://github.com/moby/moby/pull/46869)\n\n### [Packaging updates](#packaging-updates-1)\n\n*   Upgrade Go to `go1.20.13`. [moby/moby#47054](https://github.com/moby/moby/pull/47054), [docker/cli#4826](https://github.com/docker/cli/pull/4826), [docker/docker-ce-packaging#975](https://github.com/docker/docker-ce-packaging/pull/975)\n*   Upgrade containerd (static binaries only) to [v1.7.12](https://github.com/containerd/containerd/releases/tag/v1.7.12) [moby/moby#47096](https://github.com/moby/moby/pull/47096)\n*   Upgrade runc to v1.1.11. [moby/moby#47010](https://github.com/moby/moby/pull/47010)\n\n_2023-10-27_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.7 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.7)\n*   [moby/moby, 24.0.7 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.7)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-1)\n\n*   Write overlay2 layer metadata atomically. [moby/moby#46703](https://github.com/moby/moby/pull/46703)\n*   Fix \"Rootful-in-Rootless\" Docker-in-Docker on systemd version 250 and later. [moby/moby#46626](https://github.com/moby/moby/pull/46626)\n*   Fix `dockerd-rootless-setuptools.sh` when username contains a backslash. [moby/moby#46407](https://github.com/moby/moby/pull/46407)\n*   Fix a bug that would prevent network sandboxes to be fully deleted when stopping containers with no network attachments and when `dockerd --bridge=none` is used. [moby/moby#46702](https://github.com/moby/moby/pull/46702)\n*   Fix a bug where cancelling an API request could interrupt container restart. [moby/moby#46697](https://github.com/moby/moby/pull/46697)\n*   Fix an issue where containers would fail to start when providing `--ip-range` with a range larger than the subnet. [docker/for-mac#6870](https://github.com/docker/for-mac/issues/6870)\n*   Fix data corruption with zstd output. [moby/moby#46709](https://github.com/moby/moby/pull/46709)\n*   Fix the conditions under which the container's MAC address is applied. [moby/moby#46478](https://github.com/moby/moby/pull/46478)\n*   Improve the performance of the stats collector. [moby/moby#46448](https://github.com/moby/moby/pull/46448)\n*   Fix an issue with source policy rules ending up in the wrong order. [moby/moby#46441](https://github.com/moby/moby/pull/46441)\n\n### [Packaging updates](#packaging-updates-2)\n\n*   Add support for Fedora 39 and Ubuntu 23.10. [docker/docker-ce-packaging#940](https://github.com/docker/docker-ce-packaging/pull/940), [docker/docker-ce-packaging#955](https://github.com/docker/docker-ce-packaging/pull/955)\n*   Fix `docker.socket` not getting disabled when uninstalling the `docker-ce` RPM package. [docker/docker-ce-packaging#852](https://github.com/docker/docker-ce-packaging/pull/852)\n*   Upgrade Go to `go1.20.10`. [docker/docker-ce-packaging#951](https://github.com/docker/docker-ce-packaging/pull/951)\n*   Upgrade containerd to `v1.7.6` (static binaries only). [moby/moby#46103](https://github.com/moby/moby/pull/46103)\n*   Upgrade the `containerd.io` package to [`v1.6.24`](https://github.com/containerd/containerd/releases/tag/v1.6.24).\n\n### [Security](#security-1)\n\n*   Deny containers access to `/sys/devices/virtual/powercap` by default. This change hardens against [CVE-2020-8694](https://scout.docker.com/v/CVE-2020-8694), [CVE-2020-8695](https://scout.docker.com/v/CVE-2020-8695), and [CVE-2020-12912](https://scout.docker.com/v/CVE-2020-12912), and an attack known as [the PLATYPUS attack](https://platypusattack.com/).\n    \n    For more details, see [advisory](https://github.com/moby/moby/security/advisories/GHSA-jq35-85cj-fj4p), [commit](https://github.com/moby/moby/commit/c9ccbfad11a60e703e91b6cca4f48927828c7e35).\n    \n\n_2023-09-05_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.6 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.6)\n*   [moby/moby, 24.0.6 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.6)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-2)\n\n*   containerd storage backend: Fix `docker ps` failing when a container image is no longer present in the content store. [moby/moby#46095](https://github.com/moby/moby/pull/46095)\n*   containerd storage backend: Fix `docker ps -s -a` and `docker container prune` failing when a container image config is no longer present in the content store. [moby/moby#46097](https://github.com/moby/moby/pull/46097)\n*   containerd storage backend: Fix `docker inspect` failing when a container image config is no longer (or was never) present in the content store. [moby/moby#46244](https://github.com/moby/moby/pull/46244)\n*   containerd storage backend: Fix diff and export with the `overlayfs` snapshotter by using reference-counted rootfs mounts. [moby/moby#46266](https://github.com/moby/moby/pull/46266)\n*   containerd storage backend: Fix a misleading error message when the image platforms available locally do not match the desired platform. [moby/moby#46300](https://github.com/moby/moby/pull/46300)\n*   containerd storage backend: Fix the `FROM scratch` Dockerfile instruction with the classic builder. [moby/moby#46302](https://github.com/moby/moby/pull/46302)\n*   containerd storage backend: Fix `mismatched image rootfs and manifest layers` errors with the classic builder. [moby/moby#46310](https://github.com/moby/moby/pull/46310)\n*   Warn when pulling Docker Image Format v1, and Docker Image manifest version 2, schema 1 images from all registries. [moby/moby#46290](https://github.com/moby/moby/pull/46290)\n*   Fix live-restore of volumes with custom volume options. [moby/moby#46366](https://github.com/moby/moby/pull/46366)\n*   Fix incorrectly dropping capabilities bits when running a container as a non-root user (note: this change was already effectively present due to a regression). [moby/moby#46221](https://github.com/moby/moby/pull/46221)\n*   Fix network isolation iptables rules preventing IPv6 Neighbor Solicitation packets from being exchanged between containers. [moby/moby#46214](https://github.com/moby/moby/pull/46214)\n*   Fix `dockerd.exe --register-service` not working when the binary is in the current directory on Windows. [moby/moby#46215](https://github.com/moby/moby/pull/46215)\n*   Add a hint suggesting the use of a PAT to `docker login` against Docker Hub. [docker/cli#4500](https://github.com/docker/cli/pull/4500)\n*   Improve shell startup time for users of Bash completion for the CLI. [docker/cli#4517](https://github.com/docker/cli/pull/4517)\n*   Improve the speed of some commands by skipping `GET /_ping` when possible. [docker/cli#4508](https://github.com/docker/cli/pull/4508)\n*   Fix credential scopes when using a PAT to `docker manifest inspect` an image on Docker Hub. [docker/cli#4512](https://github.com/docker/cli/pull/4512)\n*   Fix `docker events` not supporting `--format=json`. [docker/cli#4544](https://github.com/docker/cli/pull/4544)\n\n### [Packaging updates](#packaging-updates-3)\n\n*   Upgrade Go to `go1.20.7`. [moby/moby#46140](https://github.com/moby/moby/pull/46140), [docker/cli#4476](https://github.com/docker/cli/pull/4476), [docker/docker-ce-packaging#932](https://github.com/docker/docker-ce-packaging/pull/932)\n*   Upgrade containerd to `v1.7.3` (static binaries only). [moby/moby#46103](https://github.com/moby/moby/pull/46103)\n*   Upgrade Compose to `v2.21.0`. [docker/docker-ce-packaging#936](https://github.com/docker/docker-ce-packaging/pull/936)\n\n_2023-07-24_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.5 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.5)\n*   [moby/moby, 24.0.5 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.5)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-3)\n\n*   The Go client now avoids using UNIX socket paths in the HTTP `Host:` header, in order to be compatible with changes introduced in `go1.20.6`. [moby/moby#45962](https://github.com/moby/moby/pull/45962), [moby/moby#45990](https://github.com/moby/moby/pull/45990)\n*   containerd storage backend: Fix `Variant` not being included in `docker image inspect` and `GET /images/{name}/json`. [moby/moby#46025](https://github.com/moby/moby/pull/46025)\n*   containerd storage backend: Prevent potential garbage collection of content during image export. [moby/moby#46021](https://github.com/moby/moby/pull/46021)\n*   containerd storage backend: Prevent duplicate digest entries in `RepoDigests`. [moby/moby#46014](https://github.com/moby/moby/pull/46014)\n*   containerd storage backend: Fix operations taking place against the incorrect tag when working with an image referenced by tag and digest. [moby/moby#46013](https://github.com/moby/moby/pull/46013)\n*   containerd storage backend: Fix a panic caused by `EXPOSE` when building containers with the legacy builder. [moby/moby#45921](https://github.com/moby/moby/pull/45921)\n*   Fix a regression causing unintuitive errors to be returned when attempting to create an `overlay` network on a non-Swarm node. [moby/moby#45974](https://github.com/moby/moby/pull/45974)\n*   Properly report errors parsing volume specifications from the command line. [docker/cli#4423](https://github.com/docker/cli/pull/4423)\n*   Fix a panic caused when `auths: null` is found in the CLI config file. [docker/cli#4450](https://github.com/docker/cli/pull/4450)\n\n### [Packaging updates](#packaging-updates-4)\n\n*   Use init scripts as provided by in moby/moby `contrib/init`. [docker/docker-ce-packaging#914](https://github.com/docker/docker-ce-packaging/pull/914), [docker/docker-ce-packaging#926](https://github.com/docker/docker-ce-packaging/pull/926)\n*   Drop Upstart from `contrib/init`. [moby/moby#46044](https://github.com/moby/moby/pull/46044)\n*   Upgrade Go to `go1.20.6`. [docker/cli#4428](https://github.com/docker/cli/pull/4428), [moby/moby#45970](https://github.com/moby/moby/pull/45970), [docker/docker-ce-packaging#921](https://github.com/docker/docker-ce-packaging/pull/921)\n*   Upgrade Compose to `v2.20.2`. [docker/docker-ce-packaging#924](https://github.com/docker/docker-ce-packaging/pull/924)\n*   Upgrade buildx to `v0.11.2`. [docker/docker-ce-packaging#922](https://github.com/docker/docker-ce-packaging/pull/922)\n\n_2023-07-07_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.4 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.4)\n*   [moby/moby, 24.0.4 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.4)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-4)\n\n*   Fix a regression introduced during 24.0.3 that causes a panic during live-restore of containers with bind mounts. [moby/moby#45903](https://github.com/moby/moby/pull/45903)\n\n_2023-07-06_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.3 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.3)\n*   [moby/moby, 24.0.3 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.3)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-5)\n\n*   containerd image store: Fix an issue where multi-platform images that did not include a manifest for the default platform could not be interacted with. [moby/moby#45849](https://github.com/moby/moby/pull/45849)\n*   containerd image store: Fix specious attempts to cache `FROM scratch` in container builds. [moby/moby#45822](https://github.com/moby/moby/pull/45822)\n*   containerd image store: Fix `docker cp` with snapshotters that cannot mount the same content multiple times. [moby/moby#45780](https://github.com/moby/moby/pull/45780), [moby/moby#45786](https://github.com/moby/moby/pull/45786)\n*   containerd image store: Fix builds with `type=image` not being correctly unpacked/stored. [moby/moby#45692](https://github.com/moby/moby/pull/45692)\n*   containerd image store: Fix incorrectly attempting to unpack pseudo-images (including attestations) in `docker load`. [moby/moby#45688](https://github.com/moby/moby/pull/45688)\n*   containerd image store: Correctly set the user agent, and include additional information like the snapshotter when interacting with registries. [moby/moby#45671](https://github.com/moby/moby/pull/45671), [moby/moby#45684](https://github.com/moby/moby/pull/45684)\n*   containerd image store: Fix a failure to unpack already-pulled content after switching between snapshotters. [moby/moby#45678](https://github.com/moby/moby/pull/45678)\n*   containerd image store: Fix images that have been re-tagged or with all tags removed being pruned while still in use. [moby/moby#45857](https://github.com/moby/moby/pull/45857)\n*   Fix a Swarm CSI issue where the Topology field was not propagated into NodeCSIInfo. [moby/moby#45810](https://github.com/moby/moby/pull/45810)\n*   Fix failures to add new Swarm managers caused by a very large raft log. [moby/moby#45703](https://github.com/moby/moby/pull/45703), [moby/swarmkit#3122](https://github.com/moby/swarmkit/pull/3122), [moby/swarmkit#3128](https://github.com/moby/swarmkit/pull/3128)\n*   `name_to_handle_at(2)` is now always allowed in the default seccomp profile. [moby/moby#45833](https://github.com/moby/moby/pull/45833)\n*   Fix an issue that prevented encrypted Swarm overlay networks from working on ports other than the default (4789). [moby/moby#45637](https://github.com/moby/moby/pull/45637)\n*   Fix a failure to restore mount reference-counts during live-restore. [moby/moby#45824](https://github.com/moby/moby/pull/45824)\n*   Fix various networking-related failures during live-restore. [moby/moby#45658](https://github.com/moby/moby/pull/45658), [moby/moby#45659](https://github.com/moby/moby/pull/45659)\n*   Fix running containers restoring with a zero (successful) exit status when the daemon is unexpectedly terminated. [moby/moby#45801](https://github.com/moby/moby/pull/45801)\n*   Fix a potential panic while executing healthcheck probes. [moby/moby#45798](https://github.com/moby/moby/pull/45798)\n*   Fix a panic caused by a race condition in container exec start. [moby/moby#45794](https://github.com/moby/moby/pull/45794)\n*   Fix an exception caused by attaching a terminal to an exec with a non-existent command. [moby/moby#45643](https://github.com/moby/moby/pull/45643)\n*   Fix `host-gateway` with BuildKit by passing the IP as a label (also requires [docker/buildx#1894](https://github.com/docker/buildx/pull/1894)). [moby/moby#45790](https://github.com/moby/moby/pull/45790)\n*   Fix an issue where `POST /containers/{id}/stop` would forcefully terminate the container when the request was canceled, instead of waiting until the specified timeout for a 'graceful' stop. [moby/moby#45774](https://github.com/moby/moby/pull/45774)\n*   Fix an issue where `docker cp -a` from the root (`/`) directory would fail. [moby/moby#45748](https://github.com/moby/moby/pull/45748)\n*   Improve compatibility with non-runc container runtimes by more correctly setting resource constraint parameters in the OCI config. [moby/moby#45746](https://github.com/moby/moby/pull/45746)\n*   Fix an issue caused by overlapping subuid/subgid ranges in certain configurations (e.g. LDAP) in rootless mode. [moby/moby#45747](https://github.com/moby/moby/pull/45747), [rootless-containers/rootlesskit#369](https://github.com/rootless-containers/rootlesskit/pull/369)\n*   Greatly reduce CPU and memory usage while populating the Debug section of `GET /info`. [moby/moby#45856](https://github.com/moby/moby/pull/45856)\n*   Fix an issue where debug information was not correctly printed during `docker info` when only the client is in debug mode. [docker/cli#4393](https://github.com/docker/cli/pull/4393)\n*   Fix issues related to hung connections when connecting to hosts over a SSH connection. [docker/cli#4395](https://github.com/docker/cli/pull/4395)\n\n### [Packaging updates](#packaging-updates-5)\n\n*   Upgrade Go to `go1.20.5`. [moby/moby#45745](https://github.com/moby/moby/pull/45745), [docker/cli#4351](https://github.com/docker/cli/pull/4351), [docker/docker-ce-packaging#904](https://github.com/docker/docker-ce-packaging/pull/904)\n*   Upgrade Compose to `v2.19.1`. [docker/docker-ce-packaging#916](https://github.com/docker/docker-ce-packaging/pull/916)\n*   Upgrade buildx to `v0.11.1`. [docker/docker-ce-packaging#918](https://github.com/docker/docker-ce-packaging/pull/918)\n\n_2023-05-26_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.2 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.2)\n*   [moby/moby, 24.0.2 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.2)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-6)\n\n*   Fix a panic during build when referencing locally tagged images. [moby/buildkit#3899](https://github.com/moby/buildkit/pull/3899), [moby/moby#45582](https://github.com/moby/moby/pull/45582)\n*   Fix builds potentially failing with `exit code: 4294967295` when performing many concurrent build stages. [moby/moby#45620](https://github.com/moby/moby/pull/45620)\n*   Fix DNS resolution on Windows ignoring `etc/hosts` (`%WINDIR%\\System32\\Drivers\\etc\\hosts`), including resolution of `localhost`. [moby/moby#45562](https://github.com/moby/moby/pull/45562)\n*   Apply a workaround for a containerd bug that causes concurrent `docker exec` commands to take significantly longer than expected. [moby/moby#45625](https://github.com/moby/moby/pull/45625)\n*   containerd image store: Fix an issue where the image `Created` field would contain an incorrect value. [moby/moby#45623](https://github.com/moby/moby/pull/45623)\n*   containerd image store: Adjust the output of image pull progress so that the output has the same format regardless of whether the containerd image store is enabled. [moby/moby#45602](https://github.com/moby/moby/pull/45602)\n*   containerd image store: Switching between the default and containerd image store now requires a daemon restart. [moby/moby#45616](https://github.com/moby/moby/pull/45616)\n\n### [Packaging updates](#packaging-updates-6)\n\n*   Upgrade Buildx to `v0.10.5`. [docker/docker-ce-packaging#900](https://github.com/docker/docker-ce-packaging/pull/900)\n\n_2023-05-19_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.1 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.1)\n*   [moby/moby, 24.0.1 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.1)\n\n### [Removed](#removed)\n\n*   Remove CLI completions for storage drivers removed in the 24.0 major release. [docker/cli#4302](https://github.com/docker/cli/pull/4302)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-7)\n\n*   Fix an issue where DNS query NXDOMAIN replies from external servers were forwarded to the client as SERVFAIL. [moby/moby#45573](https://github.com/moby/moby/pull/45573)\n*   Fix an issue where `docker pull --platform` would report `No such image` regarding another tag pointing to the same image. [moby/moby#45562](https://github.com/moby/moby/pull/45562)\n*   Fix an issue where insecure registry configuration would be forgotten during config reload. [moby/moby#45571](https://github.com/moby/moby/pull/45571)\n*   containerd image store: Fix an issue where images which have no layers would not be listed in `docker images -a` [moby/moby#45588](https://github.com/moby/moby/pull/45588)\n*   API: Fix an issue where `GET /images/{id}/json` would return `null` instead of empty `RepoTags` and `RepoDigests`. [moby/moby#45564](https://github.com/moby/moby/pull/45564)\n*   API: Fix an issue where `POST /commit` did not accept an empty request body. [moby/moby#45568](https://github.com/moby/moby/pull/45568)\n\n### [Packaging updates](#packaging-updates-7)\n\n*   Upgrade Compose to `v2.18.1`. [docker/docker-ce-packaging#896](https://github.com/docker/docker-ce-packaging/pull/896)\n\n_2023-05-16_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 24.0.0 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A24.0.0)\n*   [moby/moby, 24.0.0 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A24.0.0)\n\n### [New](#new)\n\n*   Introduce experimental support for containerd as the content store (replacing the existing storage drivers). [moby/moby#43735](https://github.com/moby/moby/pull/43735), [other moby/moby pull requests](https://github.com/moby/moby/pulls?q=is%3Apr+is%3Amerged+milestone%3A24.0.0+-label%3Aprocess%2Fcherry-picked+label%3Acontainerd-integration+)\n*   The `--host` CLI flag now supports a path component in a `ssh://` host address, allowing use of an alternate socket path without configuration on the remote host. [docker/cli#4073](https://github.com/docker/cli/pull/4073)\n*   The `docker info` CLI command now reports a version and platform field. [docker/cli#4180](https://github.com/docker/cli/pull/4180)\n*   Introduce the daemon flag `--default-network-opt` to configure options for newly created networks. [moby/moby#43197](https://github.com/moby/moby/pull/43197)\n*   Restrict access to `AF_VSOCK` in the `socket(2)` family of syscalls in the default seccomp profile. [moby/moby#44562](https://github.com/moby/moby/pull/44562)\n*   Introduce support for setting OCI runtime annotations on containers. [docker/cli#45025](https://github.com/docker/cli/pull/4156), [moby/moby#45025](https://github.com/moby/moby/pull/45025)\n*   Alternative runtimes can now be configured in `daemon.json`, enabling runtime names to be aliased and options to be passed. [moby/moby#45032](https://github.com/moby/moby/pull/45032)\n*   The `docker-init` binary will now be discovered in FHS-compliant libexec directories, in addition to the `PATH`. [moby/moby#45198](https://github.com/moby/moby/pull/45198)\n*   API: Surface the daemon-level `--no-new-privileges` in `GET /info`. [moby/moby#45320](https://github.com/moby/moby/pull/45320)\n\n### [Removed](#removed-1)\n\n*   `docker info` no longer reports `IndexServiceAddress`. [docker/cli#4204](https://github.com/docker/cli/pull/4204)\n*   libnetwork: Remove fallback code for obsolete kernel versions. [moby/moby#44684](https://github.com/moby/moby/pull/44684), [moby/moby#44802](https://github.com/moby/moby/pull/44802)\n*   libnetwork: Remove unused code related to classic Swarm. [moby/moby#44965](https://github.com/moby/moby/pull/44965)\n*   libnetwork: Remove usage of the `xt_u32` kernel module from encrypted Swarm overlay networks. [moby/moby#45281](https://github.com/moby/moby/pull/45281)\n*   Remove support for BuildKit's deprecated `buildinfo` in favor of standard provenance attestations. [moby/moby#45097](https://github.com/moby/moby/pull/45097)\n*   Remove the deprecated AUFS and legacy `overlay` storage drivers. [moby/moby#45342](https://github.com/moby/moby/pull/45342), [moby/moby#45359](https://github.com/moby/moby/pull/45359)\n*   Remove the deprecated `overlay2.override_kernel_check` storage driver option. [moby/moby#45368](https://github.com/moby/moby/pull/45368)\n*   Remove workarounds for obsolete versions of `apparmor_parser` from the AppArmor profiles. [moby/moby#45500](https://github.com/moby/moby/pull/45500)\n*   API: `GET /images/json` no longer represents empty RepoTags and RepoDigests as`<none>:<none>`/`<none>@<none>`. Empty arrays are returned instead on API >= 1.43. [moby/moby#45068](https://github.com/moby/moby/pull/45068)\n\n### [Deprecated](#deprecated)\n\n*   Deprecate the `--oom-score-adjust` daemon option. [moby/moby#45315](https://github.com/moby/moby/pull/45315)\n*   API: Deprecate the `VirtualSize` field in `GET /images/json` and `GET /images/{id}/json`. [moby/moby#45346](https://github.com/moby/moby/pull/45346)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-8)\n\n*   The `docker stack` command no longer validates the `build` section of Compose files. [docker/cli#4214](https://github.com/docker/cli/pull/4214)\n*   Fix lingering healthcheck processes after the timeout is reached. [moby/moby#43739](https://github.com/moby/moby/pull/43739)\n*   Reduce the overhead of container startup when using the `overlay2` storage driver. [moby/moby#44285](https://github.com/moby/moby/pull/44285)\n*   API: Handle multiple `before=` and `since=` filters in `GET /images`. [moby/moby#44503](https://github.com/moby/moby/pull/44503)\n*   Fix numerous bugs in the embedded DNS resolver implementation used by user-defined networks. [moby/moby#44664](https://github.com/moby/moby/pull/44664)\n*   Add `execDuration` field to the map of event attributes. [moby/moby#45494](https://github.com/moby/moby/pull/45494)\n*   Swarm-level networks can now be created with the Windows `internal`, `l2bridge`, and `nat` drivers. [moby/swarmkit#3121](https://github.com/moby/swarmkit/pull/3121), [moby/moby#45291](https://github.com/moby/moby/pull/45291)\n\n### [Packaging updates](#packaging-updates-8)\n\n*   Update Go to `1.20.4`. [docker/cli#4253](https://github.com/docker/cli/pull/4253), [moby/moby#45456](https://github.com/moby/moby/pull/45456), [docker/docker-ce-packaging#888](https://github.com/docker/docker-ce-packaging/pull/888)\n*   Update `containerd` to [`v1.7.1`](https://github.com/containerd/containerd/releases/tag/v1.7.1). [moby/moby#45537](https://github.com/moby/moby/pull/45537)\n*   Update `buildkit` to [`v0.11.6`](https://github.com/moby/buildkit/releases/v0.11.6). [moby/moby#45367](https://github.com/moby/moby/pull/45367)",
    "title": "Docker Engine 24.0 release notes | Docker Docs\n",
    "description": "Learn about the new features, bug fixes, and breaking changes for Docker Engine",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/extend/plugins_logging/",
    "markdown": "# Docker log driver plugins | Docker Docs\n\nThis document describes logging driver plugins for Docker.\n\nLogging drivers enables users to forward container logs to another service for processing. Docker includes several logging drivers as built-ins, however can never hope to support all use-cases with built-in drivers. Plugins allow Docker to support a wide range of logging services without requiring to embed client libraries for these services in the main Docker codebase. See the [plugin documentation](https://docs.docker.com/engine/extend/legacy_plugins/) for more information.\n\nThe main interface for logging plugins uses the same JSON+HTTP RPC protocol used by other plugin types. See the [example](https://github.com/cpuguy83/docker-log-driver-test) plugin for a reference implementation of a logging plugin. The example wraps the built-in `jsonfilelog` log driver.\n\nLogging plugins must register as a `LogDriver` during plugin activation. Once activated users can specify the plugin as a log driver.\n\nThere are two HTTP endpoints that logging plugins must implement:\n\n### [`/LogDriver.StartLogging`](#logdriverstartlogging)\n\nSignals to the plugin that a container is starting that the plugin should start receiving logs for.\n\nLogs will be streamed over the defined file in the request. On Linux this file is a FIFO. Logging plugins are not currently supported on Windows.\n\nRequest:\n\n`File` is the path to the log stream that needs to be consumed. Each call to `StartLogging` should provide a different file path, even if it's a container that the plugin has already received logs for prior. The file is created by Docker with a randomly generated name.\n\n`Info` is details about the container that's being logged. This is fairly free-form, but is defined by the following struct definition:\n\n`ContainerID` will always be supplied with this struct, but other fields may be empty or missing.\n\nResponse:\n\nIf an error occurred during this request, add an error message to the `Err` field in the response. If no error then you can either send an empty response (`{}`) or an empty value for the `Err` field.\n\nThe driver should at this point be consuming log messages from the passed in file. If messages are unconsumed, it may cause the container to block while trying to write to its stdio streams.\n\nLog stream messages are encoded as protocol buffers. The protobuf definitions are in the [moby repository](https://github.com/moby/moby/blob/master/api/types/plugins/logdriver/entry.proto).\n\nSince protocol buffers are not self-delimited you must decode them from the stream using the following stream format:\n\nWhere `size` is a 4-byte big endian binary encoded uint32. `size` in this case defines the size of the next message. `message` is the actual log entry.\n\nA reference golang implementation of a stream encoder/decoder can be found [here](https://github.com/docker/docker/blob/master/api/types/plugins/logdriver/io.go)\n\n### [`/LogDriver.StopLogging`](#logdriverstoplogging)\n\nSignals to the plugin to stop collecting logs from the defined file. Once a response is received, the file will be removed by Docker. You must make sure to collect all logs on the stream before responding to this request or risk losing log data.\n\nRequests on this endpoint does not mean that the container has been removed only that it has stopped.\n\nRequest:\n\nResponse:\n\nIf an error occurred during this request, add an error message to the `Err` field in the response. If no error then you can either send an empty response (`{}`) or an empty value for the `Err` field.\n\nLogging plugins can implement two extra logging endpoints:\n\n### [`/LogDriver.Capabilities`](#logdrivercapabilities)\n\nDefines the capabilities of the log driver. You must implement this endpoint for Docker to be able to take advantage of any of the defined capabilities.\n\nRequest:\n\nResponse:\n\nSupported capabilities:\n\n*   `ReadLogs` - this tells Docker that the plugin is capable of reading back logs to clients. Plugins that report that they support `ReadLogs` must implement the `/LogDriver.ReadLogs` endpoint\n\n### [`/LogDriver.ReadLogs`](#logdriverreadlogs)\n\nReads back logs to the client. This is used when `docker logs <container>` is called.\n\nIn order for Docker to use this endpoint, the plugin must specify as much when `/LogDriver.Capabilities` is called.\n\nRequest:\n\n`ReadConfig` is the list of options for reading, it is defined with the following golang struct:\n\n*   `Since` defines the oldest log that should be sent.\n*   `Tail` defines the number of lines to read (e.g. like the command `tail -n 10`)\n*   `Follow` signals that the client wants to stay attached to receive new log messages as they come in once the existing logs have been read.\n\n`Info` is the same type defined in `/LogDriver.StartLogging`. It should be used to determine what set of logs to read.\n\nResponse:\n\nThe response should be the encoded log message using the same format as the messages that the plugin consumed from Docker.",
    "title": "Docker log driver plugins | Docker Docs\n",
    "description": "Log driver plugins.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/",
    "markdown": "# Create a swarm | Docker Docs\n\nAfter you complete the [tutorial setup](https://docs.docker.com/engine/swarm/swarm-tutorial/) steps, you're ready to create a swarm. Make sure the Docker Engine daemon is started on the host machines.\n\n1.  Open a terminal and ssh into the machine where you want to run your manager node. This tutorial uses a machine named `manager1`.\n    \n2.  Run the following command to create a new swarm:\n    \n    In the tutorial, the following command creates a swarm on the `manager1` machine:\n    \n    The `--advertise-addr` flag configures the manager node to publish its address as `192.168.99.100`. The other nodes in the swarm must be able to access the manager at the IP address.\n    \n    The output includes the commands to join new nodes to the swarm. Nodes will join as managers or workers depending on the value for the `--token` flag.\n    \n3.  Run `docker info` to view the current state of the swarm:\n    \n4.  Run the `docker node ls` command to view information about nodes:\n    \n    The `*` next to the node ID indicates that you're currently connected on this node.\n    \n    Docker Engine Swarm mode automatically names the node with the machine host name. The tutorial covers other columns in later steps.\n    \n\nNext, you'll add two more nodes to the cluster.",
    "title": "Create a swarm | Docker Docs\n",
    "description": "Initialize the swarm",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/23.0/",
    "markdown": "# Docker Engine 23.0 release notes\n\n> **Note**\n> \n> From Docker Engine version 23.0.0, Buildx is distributed in a separate package: `docker-buildx-plugin`. In earlier versions, Buildx was included in the `docker-ce-cli` package. When you upgrade to this version of Docker Engine, make sure you update all packages. For example, on Ubuntu:\n> \n> Refer to the [Docker Engine installation instructions](https://docs.docker.com/engine/install/) for your operating system for more details on upgrading Docker Engine.\n\nThis page describes the latest changes, additions, known issues, and fixes for Docker Engine version 23.0.\n\nFor more information about:\n\n*   Deprecated and removed features, see [Deprecated Engine Features](https://docs.docker.com/engine/deprecated/).\n*   Changes to the Engine API, see [Engine API version history](https://docs.docker.com/engine/api/version-history/).\n\nStarting with the 23.0.0 release, Docker Engine moves away from using CalVer versioning, and starts using the [SemVer versioning format](https://semver.org/). Changing the version format is a stepping-stone towards Go module compatibility, but the repository doesn't yet use Go modules, and still requires using a \"+incompatible\" version. Work continues towards Go module compatibility in a future release.\n\n_2023-05-08_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 23.0.6 milestone](https://github.com/docker/cli/issues?q=is%3Aclosed+milestone%3A23.0.6)\n*   [moby/moby, 23.0.6 milestone](https://github.com/moby/moby/issues?q=is%3Aclosed+milestone%3A23.0.6)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements)\n\n*   Fix vfs storage driver not working on NFS. [moby/moby#45465](https://github.com/moby/moby/pull/45465)\n\n### [Packaging Updates](#packaging-updates)\n\n*   Upgrade Go to `1.19.9`. [docker/docker-ce-packaging#889](https://github.com/docker/docker-ce-packaging/pull/889), [docker/cli#4254](https://github.com/docker/cli/pull/4254), [moby/moby#45455](https://github.com/moby/moby/pull/45455)\n*   Upgrade `containerd` to [v1.6.21](https://github.com/containerd/containerd/releases/tag/v1.6.21)\n*   Upgrade `runc` to [v1.1.7](https://github.com/opencontainers/runc/releases/tag/v1.1.7)\n\n_2023-04-26_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 23.0.5 milestone](https://github.com/docker/cli/milestone/79?closed=1)\n*   [moby/moby, 23.0.5 milestone](https://github.com/moby/moby/milestone/118?closed=1)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-1)\n\n*   Add the `--all` / `-a` option when pruning volumes. [docker/cli#4229](https://github.com/docker/cli/pull/4229)\n*   Add `--format=json` for `docker info`. [docker/cli#4320](https://github.com/docker/cli/pull/4230)\n*   Fix log loss with the AWSLogs log driver. [moby/moby#45350](https://github.com/moby/moby/pull/45350)\n*   Fix a regression introduced in v23.0.4 where dockerd would refuse to start if the fixed-cidr config parameter is provided but not bip. [moby/moby#45403](https://github.com/moby/moby/pull/45403)\n*   Fix a panic in libnetwork during daemon start [moby/moby#45376](https://github.com/moby/moby/pull/45376)\n*   Fix \"tag\" event not being sent when an image is built with `buildx`. [moby/moby#45410](https://github.com/moby/moby/pull/45410)\n\n### [Packaging Updates](#packaging-updates-1)\n\n*   Upgrade Compose to `2.17.3`. [docker/docker-ce-packaging#883](https://github.com/docker/docker-ce-packaging/pull/883)\n\n_2023-04-17_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 23.0.4 milestone](https://github.com/docker/cli/milestone/77?closed=1)\n*   [moby/moby, 23.0.4 milestone](https://github.com/moby/moby/milestone/117?closed=1)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-2)\n\n*   Fix a performance regression in Docker CLI 23.0.0 [docker/cli#4141](https://github.com/docker/cli/pull/4141).\n*   Fix progress indicator on `docker cp` not functioning as intended [docker/cli#4157](https://github.com/docker/cli/pull/4157).\n*   Fix shell completion for `docker compose --file` [docker/cli#4177](https://github.com/docker/cli/pull/4177).\n*   Fix an error caused by incorrect handling of \"default-address-pools\" in `daemon.json` [moby/moby#45246](https://github.com/moby/moby/pull/45246).\n\n### [Packaging Updates](#packaging-updates-2)\n\n*   Fix missing packages for CentOS 9 Stream.\n*   Upgrade Go to `1.19.8`. [docker/docker-ce-packaging#878](https://github.com/docker/docker-ce-packaging/pull/878), [docker/cli#4164](https://github.com/docker/cli/pull/4164), [moby/moby#45277](https://github.com/moby/moby/pull/45277), which contains fixes for [CVE-2023-24537](https://github.com/advisories/GHSA-fp86-2355-v99r), [CVE-2023-24538](https://github.com/advisories/GHSA-v4m2-x4rp-hv22), [CVE-2023-24534](https://github.com/advisories/GHSA-8v5j-pwr7-w5f8), and [CVE-2023-24536](https://github.com/advisories/GHSA-9f7g-gqwh-jpf5)\n\n_2023-04-04_\n\n> **Note**\n> \n> Due to an issue with CentOS 9 Stream's package repositories, packages for CentOS 9 are currently unavailable. Packages for CentOS 9 may be added later, or as part of the next (23.0.4) patch release.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-3)\n\n*   Fixed a number of issues that can cause Swarm encrypted overlay networks to fail to uphold their guarantees, addressing [CVE-2023-28841](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-28841), [CVE-2023-28840](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-28840), and [CVE-2023-28842](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-28842).\n    *   A lack of kernel support for encrypted overlay networks now reports as an error.\n    *   Encrypted overlay networks are eagerly set up, rather than waiting for multiple nodes to attach.\n    *   Encrypted overlay networks are now usable on Red Hat Enterprise Linux 9 through the use of the `xt_bpf` kernel module.\n    *   Users of Swarm overlay networks should review [GHSA-vwm3-crmr-xfxw](https://github.com/moby/moby/security/advisories/GHSA-vwm3-crmr-xfxw) to ensure that unintentional exposure has not occurred.\n\n### [Packaging Updates](#packaging-updates-3)\n\n*   Upgrade `containerd` to [v1.6.20](https://github.com/containerd/containerd/releases/tag/v1.6.20).\n*   Upgrade `runc` to [v1.1.5](https://github.com/opencontainers/runc/releases/tag/v1.1.5).\n\n_2023-03-28_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 23.0.2 milestone](https://github.com/docker/cli/milestone/75?closed=1)\n*   [moby/moby, 23.0.2 milestone](https://github.com/moby/moby/milestone/114?closed=1)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-4)\n\n*   Fully resolve missing checks for `apparmor_parser` when an AppArmor enabled kernel is detected. [containerd/containerd#8087](https://github.com/containerd/containerd/pull/8087), [moby/moby#45043](https://github.com/moby/moby/pull/45043)\n*   Ensure that credentials are redacted from Git URLs when generating BuildKit buildinfo. Fixes [CVE-2023-26054](https://github.com/moby/buildkit/security/advisories/GHSA-gc89-7gcr-jxqc). [moby/moby#45110](https://github.com/moby/moby/pull/45110)\n*   Fix anonymous volumes created by a `VOLUME` line in a Dockerfile being excluded from volume prune. [moby/moby#45159](https://github.com/moby/moby/pull/45159)\n*   Fix a failure to properly propagate errors during removal of volumes on a Swarm node. [moby/moby#45155](https://github.com/moby/moby/pull/45155)\n*   Temporarily work around a bug in BuildKit `COPY --link` by disabling mergeop/diffop optimization. [moby/moby#45112](https://github.com/moby/moby/pull/45112)\n*   Properly clean up child tasks when a parent Swarm job is removed. [moby/swarmkit#3112](https://github.com/moby/swarmkit/pull/3112), [moby/moby#45107](https://github.com/moby/moby/pull/45107)\n*   Fix Swarm service creation logic so that both a GenericResource and a non-default network can be used together. [moby/swarmkit#3082](https://github.com/moby/swarmkit/pull/3082), [moby/moby#45107](https://github.com/moby/moby/pull/45107)\n*   Fix Swarm CSI support requiring the CSI plugin to offer staging endpoints in order to publish a volume. [moby/swarmkit#3116](https://github.com/moby/swarmkit/pull/3116), [moby/moby#45107](https://github.com/moby/moby/pull/45107)\n*   Fix a panic caused by log buffering in some configurations. [containerd/fifo#47](https://github.com/containerd/fifo/pull/47), [moby/moby#45051](https://github.com/moby/moby/pull/45051)\n*   Log errors in the REST to Swarm gRPC API translation layer at the debug level to reduce redundancy and noise. [moby/moby#45016](https://github.com/moby/moby/pull/45016)\n*   Fix a DNS resolution issue affecting containers created with `--dns-opt` or `--dns-search` when `systemd-resolved` is used outside the container. [moby/moby#45000](https://github.com/moby/moby/pull/45000)\n*   Fix a panic when logging errors in handling DNS queries originating from inside a container. [moby/moby#44980](https://github.com/moby/moby/pull/44980)\n*   Improve the speed of `docker ps` by allowing users to opt out of size calculations with `--size=false`. [docker/cli#4107](https://github.com/docker/cli/pull/4107)\n*   Extend support for Bash completion to all plugins. [docker/cli#4092](https://github.com/docker/cli/pull/4092)\n*   Fix `docker stack deploy` failing on Windows when special environment variables set by `cmd.exe` are present. [docker/cli#4083](https://github.com/docker/cli/pull/4083)\n*   Add forward compatibility for future API versions by considering empty image tags to be the same as `<none>`. [docker/cli#4065](https://github.com/docker/cli/pull/4065)\n*   Atomically write context files to greatly reduce the probability of corruption, and improve the error message for a corrupt context. [docker/cli#4063](https://github.com/docker/cli/pull/4063)\n\n### [Packaging](#packaging)\n\n*   Upgrade Go to `1.19.7`. [docker/docker-ce-packaging#857](https://github.com/docker/docker-ce-packaging/pull/857), [docker/cli#4086](https://github.com/docker/cli/pull/4086), [moby/moby#45137](https://github.com/moby/moby/pull/45137)\n*   Upgrade `containerd` to `v1.6.19`. [moby/moby#45084](https://github.com/moby/moby/pull/45084), [moby/moby#45099](https://github.com/moby/moby/pull/45099)\n*   Upgrade Buildx to `v0.10.4`. [docker/docker-ce-packaging#855](https://github.com/docker/docker-ce-packaging/pull/855)\n*   Upgrade Compose to `v2.17.2`. [docker/docker-ce-packaging#867](https://github.com/docker/docker-ce-packaging/pull/867)\n\n_2023-02-09_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 23.0.1 milestone](https://github.com/docker/cli/milestone/73?closed=1)\n*   [moby/moby, 23.0.1 milestone](https://github.com/moby/moby/milestone/113?closed=1)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-5)\n\n*   Fix containers not starting if the kernel has AppArmor enabled, but `apparmor_parser` is not available. [moby/moby#44942](https://github.com/moby/moby/pull/44942)\n*   Fix BuildKit-enabled builds with inline caching causing the daemon to crash. [moby/moby#44944](https://github.com/moby/moby/pull/44944)\n*   Fix BuildKit improperly loading cached layers created by previous versions. [moby/moby#44959](https://github.com/moby/moby/pull/44959)\n*   Fix an issue where `ipvlan` networks created prior to upgrading would prevent the daemon from starting. [moby/moby#44937](https://github.com/moby/moby/pull/44937)\n*   Fix the `overlay2` storage driver failing early in `metacopy` testing when initialized on an unsupported backing filesystem. [moby/moby#44922](https://github.com/moby/moby/pull/44922)\n*   Fix `exec` exit events being misinterpreted as container exits under some runtimes, such as Kata Containers. [moby/moby#44892](https://github.com/moby/moby/pull/44892)\n*   Improve the error message returned by the CLI when receiving a truncated JSON response caused by the API hanging up mid-request. [docker/cli#4004](https://github.com/docker/cli/pull/4004)\n*   Fix an incorrect CLI exit code when attempting to execute a directory with a `runc` compiled using Go 1.20. [docker/cli#4004](https://github.com/docker/cli/pull/4004)\n*   Fix mishandling the size argument to `--device-write-bps` as a path. [docker/cli#4004](https://github.com/docker/cli/pull/4004)\n\n### [Packaging](#packaging-1)\n\n*   Add `/etc/docker` to RPM and DEB packaging. [docker/docker-ce-packaging#842](https://github.com/docker/docker-ce-packaging/pull/842)\n    *   Not all use cases will benefit; if you depend on this, you should explicitly `mkdir -p /etc/docker`.\n*   Upgrade Compose to `v2.16.0`. [docker/docker-ce-packaging#844](https://github.com/docker/docker-ce-packaging/pull/844)\n\n_2023-02-01_\n\nFor a full list of pull requests and changes in this release, refer to the relevant GitHub milestones:\n\n*   [docker/cli, 23.0.0 milestone](https://github.com/docker/cli/milestone/51?closed=1)\n*   [moby/moby, 23.0.0 milestone](https://github.com/moby/moby/milestone/91?closed=1)\n\n### [New](#new)\n\n*   Set Buildx and BuildKit as the default builder on Linux. [moby/moby#43992](https://github.com/moby/moby/pull/43992)\n    *   Alias `docker build` to `docker buildx build`. [docker/cli#3314](https://github.com/docker/cli/pull/3314)\n    *   The legacy builder can still be used by explicitly setting `DOCKER_BUILDKIT=0`.\n    *   There are differences in how BuildKit and the legacy builder handle multi-stage builds. For more information, see [Multi-stage builds](https://docs.docker.com/build/building/multi-stage/#differences-between-legacy-builder-and-buildkit).\n*   Add support for pulling `zstd` compressed layers. [moby/moby#41759](https://github.com/moby/moby/pull/41759), [moby/moby#42862](https://github.com/moby/moby/pull/42862)\n*   Add support for alternate OCI runtimes on Linux, compatible with the containerd runtime v2 API. [moby/moby#43887](https://github.com/moby/moby/pull/43887), [moby/moby#43993](https://github.com/moby/moby/pull/43993)\n*   Add support for the containerd `runhcs` shim on Windows (off by default). [moby/moby#42089](https://github.com/moby/moby/pull/42089)\n*   Add `dockerd --validate` to check the daemon JSON config and exit. [moby/moby#42393](https://github.com/moby/moby/pull/42393)\n*   Add the ability to configure the daemon's HTTP proxy via flags or JSON config. [moby/moby#42835](https://github.com/moby/moby/pull/42835)\n*   Add support for RFC 3021 point-to-point networks (IPv4 /31s) and single hosts (IPv4 /32s). For networks with two or fewer addresses, IPAM won't reserve a network and broadcast address. [moby/moby#42626](https://github.com/moby/moby/pull/42626)\n*   Add support for setting `ipvlan_flag` and using the `l3s` `ipvlan_mode` in the `ipvlan` network driver. [moby/moby#42542](https://github.com/moby/moby/pull/42542)\n*   Add support for displaying the value of the `metacopy` option for the `overlay2` storage driver. [moby/moby#43557](https://github.com/moby/moby/pull/43557)\n*   Add support for describing Windows devices using the syntax `IDType://ID`. [moby/moby#43368](https://github.com/moby/moby/pull/43368)\n*   Add `RootlessKit`, `slirp4netns`, and `VPNKit` version reporting. [moby/moby#42330](https://github.com/moby/moby/pull/42330)\n*   Add experimental support for SwarmKit cluster volumes (CSI). [moby/moby#41982](https://github.com/moby/moby/pull/41982)\n    *   CLI: Add cluster volume (CSI) options to `docker volume`. [docker/cli#3606](https://github.com/docker/cli/pull/3606)\n    *   CLI: Add cluster volume (CSI) support to `docker stack`. [docker/cli#3662](https://github.com/docker/cli/pull/3662)\n*   Add support for SwarmKit jobs in `docker stack deploy`. [docker/cli#2907](https://github.com/docker/cli/pull/2907)\n*   Add the `docker stack config` command to output the merged and interpolated config files as utilized by `stack deploy`. [docker/cli#3544](https://github.com/docker/cli/pull/3544)\n*   Add a new `docker context show` command that prints the name of the current context. [docker/cli#3567](https://github.com/docker/cli/pull/3567)\n*   Add the `--format=json` shorthand variant of `--format=\"{{ json . }}\"` to all commands supporting the `--format` flag. [docker/cli#2936](https://github.com/docker/cli/pull/2936)\n*   Add a `--quiet` option to `docker create` and `docker run` commands to suppress output when pulling an image. [docker/cli#3377](https://github.com/docker/cli/pull/3377)\n*   Add a `--force` option to `docker network rm` subcommand. Causes CLI to return a 0 exit code even if the network doesn't exist. Has no effect on the server-side procedure for removing a network. [docker/cli#3547](https://github.com/docker/cli/pull/3547)\n*   Add a `--signal` option to `docker stop` and `docker restart`. [docker/cli#3614](https://github.com/docker/cli/pull/3614)\n*   Add a `-v/--version` flag to `docker-proxy`. [moby/moby#44703](https://github.com/moby/moby/pull/44703)\n*   Plugins are now discovered in well-known user-level paths when the daemon is running in rootless mode. [moby/moby#44778](https://github.com/moby/moby/pull/44778)\n*   The daemon now handles common alternate JSON encodings in the JSON configuration file gracefully, and reports useful errors. [moby/moby#44777](https://github.com/moby/moby/pull/44777), [moby/moby#44832](https://github.com/moby/moby/pull/44832)\n    *   UTF-8 with a byte order mark is accepted.\n    *   UTF-16 with a byte order mark is accepted.\n    *   Invalid UTF-8 is reported early and with a comprehensible error message.\n*   Allow use of `STOPSIGNAL` via `docker commit`. [moby/moby#43369](https://github.com/moby/moby/pull/43369)\n*   Add a new option to the `awslogs` log driver to allow skipping log stream creation in CloudWatch. [moby/moby#42132](https://github.com/moby/moby/pull/42132)\n*   Add a new option to the `awslogs` log driver to specify the log format that's sent to CloudWatch. [moby/moby#42838](https://github.com/moby/moby/pull/42838)\n*   Add a new option to the `fluentd` log driver to set the reconnection interval. [moby/moby#43100](https://github.com/moby/moby/pull/43100)\n*   Add new options-setters to the Go API client: `WithTLSClientConfigFromEnv()`, `WithHostFromEnv()`, and `WithVersionFromEnv()`. [moby/moby#42224](https://github.com/moby/moby/pull/42224)\n*   Add generation of shell command completion through a `docker completion` subcommand. [docker/cli#3429](https://github.com/docker/cli/pull/3429)\n*   API: Add a `Swarm` header to `GET /_ping` and `HEAD /_ping`, allowing single-request detection of Swarm support. [moby/moby#42064](https://github.com/moby/moby/pull/42064)\n*   API: Add a `signal` parameter to `POST /containers/{id}/stop` and `POST /containers/{id}/restart` to set the signal used. [moby/moby#43206](https://github.com/moby/moby/pull/43206)\n*   API: Add a `CreateMountPoint` parameter to `POST /containers/create`. [moby/moby#43484](https://github.com/moby/moby/pull/43484)\n*   API: Add a `shared-size` parameter to `GET /images/json` to enable shared-size computation of images. [moby/moby#42531](https://github.com/moby/moby/pull/42531)\n*   API: Add a `type` parameter to `GET /system/df`, to control what object types to are considered when computing disk usage. [moby/moby#42559](https://github.com/moby/moby/pull/42559)\n*   systemd: Use a systemd-managed containerd instead of a daemon-managed containerd. [moby/moby#42373](https://github.com/moby/moby/pull/42373)\n*   systemd: Start `docker.service` after `time-set.target`. [moby/moby#43107](https://github.com/moby/moby/pull/43107)\n\n### [Removed](#removed)\n\n*   Remove support for reading configuration from `~/.dockercfg`. [docker/cli#2504](https://github.com/docker/cli/pull/2504)\n    *   This location has been deprecated since 1.7.0.\n    *   [Deprecation notice](https://docs.docker.com/engine/deprecated/#support-for-legacy-dockercfg-configuration-files)\n*   Remove the `-g` and `--graph` daemon options in favor of `--data-root`. [docker/cli#3739](https://github.com/docker/cli/pull/3739)\n    *   These options have been hidden and deprecated since 17.05.\n    *   [Deprecation notice](https://docs.docker.com/engine/deprecated/#-g-and---graph-flags-on-dockerd)\n*   Remove client-side sorting of results, in favor of the order in which the search API returns. [docker/cli#3470](https://github.com/docker/cli/pull/3470)\n*   Remove warnings related to deprecated storage drivers from the CLI. Warnings are now handled by the daemon instead. [docker/cli#3542](https://github.com/docker/cli/pull/3542)\n*   Remove `Experimental` client field from `docker version`. [docker/cli#3543](https://github.com/docker/cli/pull/3543)\n    *   [Deprecation notice](https://docs.docker.com/engine/deprecated/#configuration-options-for-experimental-cli-features)\n*   Require explicit opt-in to use deprecated storage drivers, and don't automatically select them when upgrading. [moby/moby#43378](https://github.com/moby/moby/pull/43378)\n*   Remove deprecated support for `overlay` and `overlay2` storage drivers on backing filesystems without `d_type` support. [moby/moby#43472](https://github.com/moby/moby/pull/43472)\n    *   [Deprecation notice](https://docs.docker.com/engine/deprecated/#backing-filesystem-without-d_type-support-for-overlayoverlay2)\n*   Remove the deprecated `overrideKernelCheck` option from the `overlay2` storage driver. [moby/moby#44279](https://github.com/moby/moby/pull/44279) [Deprecation notice](https://docs.docker.com/engine/deprecated/#support-for-the-overlay2override_kernel_check-storage-option)\n*   Remove support for the deprecated `io.containerd.runtime.v1.linux` OCI runtime. [moby/moby#43695](https://github.com/moby/moby/pull/43695)\n*   Remove LCOW (Linux Containers on Windows). [moby/moby#42451](https://github.com/moby/moby/pull/42451), [moby/moby#42499](https://github.com/moby/moby/pull/42499), [moby/moby#42506](https://github.com/moby/moby/pull/42506), [moby/moby#42511](https://github.com/moby/moby/pull/42511), [moby/moby#42520](https://github.com/moby/moby/pull/42520), [moby/moby#42683](https://github.com/moby/moby/pull/42683), [moby/moby#42684](https://github.com/moby/moby/pull/42684), [moby/moby#42685](https://github.com/moby/moby/pull/42685), [moby/moby#43187](https://github.com/moby/moby/pull/43187)\n    *   LCOW was introduced as a technical preview in 17.09 and deprecated in 20.10.\n    *   [Deprecation notice](https://docs.docker.com/engine/deprecated/#linux-containers-on-windows-lcow-experimental)\n*   Remove daemon options related to legacy overlay networks used with standalone Swarm.\n    *   Remove `--cluster-xx` options from `dockerd`. [moby/moby#40383](https://github.com/moby/moby/issues/40383)\n    *   Remove `host-discovery` and overlay networks with external k/v stores. [moby/moby#42247](https://github.com/moby/moby/pull/42247)\n    *   [Deprecation notice](https://docs.docker.com/engine/deprecated/#classic-swarm-and-overlay-networks-using-cluster-store)\n*   Remove a deprecated `arm` platform fallback. `--platform linux/arm/vY` will now return a error when `arm/vY` isn't available instead of pulling the wrong image. [moby/moby#44414](https://github.com/moby/moby/pull/44414)\n*   Remove the deprecated `SetCustomHTTPHeaders()`, `CustomHTTPHeaders()` options-setters from the Go client API. [moby/moby#42694](https://github.com/moby/moby/pull/42694)\n*   Remove the deprecated `WithDialer()` option-setter from the Go client API. [moby/moby#44022](https://github.com/moby/moby/pull/44022)\n    *   Use `WithDialContext()` instead.\n*   Remove the daemon implementation of `opts.QuotedString`. The implementation has moved to the CLI. [moby/moby#43250](https://github.com/moby/moby/pull/43250)\n*   Remove separate daemon ID from trust-key in the daemon, and disable generating the trust-key. [moby/moby#43555](https://github.com/moby/moby/pull/43555)\n*   API: Remove the deprecated `KernelMemory` option from `POST /containers/create` on API version >= 1.42. [moby/moby#43214](https://github.com/moby/moby/pull/43214)\n    *   [Deprecation notice](https://docs.docker.com/engine/deprecated/#kernel-memory-limit)\n\n### [Deprecated](#deprecated)\n\n*   Require Windows Server RS5 / LTSC 2019 (build 17763) as the minimum to run the daemon. [moby/moby#43254](https://github.com/moby/moby/pull/43254)\n*   Deprecate `BuilderSize` on API version >= 1.42. [moby/moby#42608](https://github.com/moby/moby/pull/42608)\n*   Deprecate `BuildCache.Parent` in favor of the newly introduced `BuildCache.Parents` on API version >= 1.42. [moby/moby#43908](https://github.com/moby/moby/pull/43908)\n*   Deprecate `pkg/urlutil`, moving the implementation to `builder/remotecontext/urlutil`. [moby/moby#43477](https://github.com/moby/moby/pull/43477)\n\n### [Upgrades](#upgrades)\n\n*   Upgrade Go to `1.19.5`. [docker/cli#3958](https://github.com/docker/cli/pull/3958), [moby/moby#44794](https://github.com/moby/moby/pull/44794)\n*   Upgrade `rootlesskit` to `v0.14.4`. [moby/moby#42708](https://github.com/moby/moby/pull/42708)\n*   Upgrade `buildkit` to `v0.10.6`. [moby/moby#43239](https://github.com/moby/moby/pull/43239)\n*   Upgrade `buildx` to `v0.10.2`. [docker/docker-ce-packaging#840](https://github.com/docker/docker-ce-packaging/pull/840)\n*   Upgrade `swarmkit` to `v2.0.0-20230119195359-904c221ac281`. [moby/moby#44858](https://github.com/moby/moby/pull/44858)\n*   Upgrade `containerd` to `v1.6.16`. [moby/moby#44766](https://github.com/moby/moby/pull/44766), [moby/moby#44769](https://github.com/moby/moby/pull/44769), [moby/moby#44881](https://github.com/moby/moby/pull/44881)\n*   Upgrade `runc` to `v1.1.4`. [moby/moby#44039](https://github.com/moby/moby/pull/44039)\n*   Upgrade `hcsshim` `v0.9.6`. [moby/moby#44658](https://github.com/moby/moby/pull/44658)\n*   The `btrfs` storage driver now depends on Linux kernel headers (>= 4.12) instead of headers from btrfs-progs. [moby/moby#44776](https://github.com/moby/moby/pull/44776)\n\n### [Security](#security)\n\n*   Change permissions on container `hostconfig.json` files to `0600` (was `0644`). [moby/moby#41620](https://github.com/moby/moby/pull/41620)\n*   Fix `--seccomp-profile` not accepting `unconfined` and renamed the default seccomp profile to `builtin`. [moby/moby#42481](https://github.com/moby/moby/pull/42481)\n*   Always build with seccomp support, and remove the `seccomp` build tag. [moby/moby#42501](https://github.com/moby/moby/pull/42501)\n*   Add seccomp support on `riscv64`. [moby/moby#43553](https://github.com/moby/moby/pull/43553)\n*   Add support for setting flags passed to `seccomp(2)` in seccomp profiles. [moby/moby#42648](https://github.com/moby/moby/pull/42648)\n*   Refactor seccomp types to reuse runtime-spec, and add support for `ErrnoRet`. [moby/moby#42005](https://github.com/moby/moby/pull/42005)\n*   Add support for `DefaultErrnoRet` in `seccomp` profiles. [moby/moby#42604](https://github.com/moby/moby/pull/42604)\n*   Add an explicit `DefaultErrnoRet` field to the default seccomp profile, with no behavior change. [moby/moby#42649](https://github.com/moby/moby/pull/42649)\n*   Block `socket` with `AF_VSOCK` in the default seccomp profile. [moby/moby#44563](https://github.com/moby/moby/pull/44563)\n*   Re-enable `process_vm_readv` and `process_vm_writev` in the default seccomp profile. [moby/moby#42083](https://github.com/moby/moby/pull/42083)\n*   Add syscalls related to PKU to the default seccomp profile. [moby/moby#43812](https://github.com/moby/moby/pull/43812)\n*   Allow `clock_settime64` with `CAP_SYS_TIME`. [moby/moby#43775](https://github.com/moby/moby/pull/43775)\n*   Allow `bpf` with `CAP_BPF` and `perf_event_open` with `CAP_PERFMON`. [moby/moby#43988](https://github.com/moby/moby/pull/43988)\n*   Explicitly set the `clone3` syscall to return `ENOSYS` in the default seccomp profile, in order to ensure `glibc` will correctly fallback to using `clone`. [moby/moby#42681](https://github.com/moby/moby/pull/42681)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-6)\n\n*   Promote `overlay2` to be the default storage driver (`btrfs` and `zfs` are now opt-in). [moby/moby#42661](https://github.com/moby/moby/pull/42661)\n*   Add a loading spinner to the `docker cp` command. [docker/cli#2708](https://github.com/docker/cli/pull/2708)\n*   Deprecate the `ElectAuthServer` function, and made it return the default registry without calling the `GET /info` API endpoint. [docker/cli#2819](https://github.com/docker/cli/pull/2819)\n*   Progress bars are no longer reversed when rolling back Swarm services. [docker/cli#2940](https://github.com/docker/cli/pull/2940)\n*   Use `net.JoinHostPort()` to fix formatting with IPv6 addresses. [docker/cli#2972](https://github.com/docker/cli/pull/2972)\n*   CLI error messages are now printed to `stderr`. [docker/cli#3044](https://github.com/docker/cli/pull/3044)\n*   Improve performance of `docker info` if a custom `--format` is used that only uses local information. With this change, the CLI only uses the daemon API if it detects that information from the daemon is needed. [docker/cli#3179](https://github.com/docker/cli/pull/3179)\n*   Remove the default value from the `--stop-signal` flag, as it may not reflect the actual default used by the daemon. [docker/cli#3245](https://github.com/docker/cli/pull/3245)\n*   Add Compose schema `3.10` to `docker stack`; allow omitting the `version` field (resulting in `latest`). [docker/cli#3257](https://github.com/docker/cli/pull/3257)\n*   Compose version `3` is now equivalent to `3.x` (latest) in `docker stack`. [docker/cli#3445](https://github.com/docker/cli/pull/3445)\n*   Fix `<Ctrl-c>` hanging on Windows to exit after running a container in non-interactive mode. [docker/cli#3302](https://github.com/docker/cli/pull/3302)\n*   Add relative source paths to the `run` command in the `-v`/`--volume` and `-m`/`--mount` flags. [docker/cli#3469](https://github.com/docker/cli/pull/3469)\n*   `docker exec -t` now sets the console size for the executed process immediately when it's created. [docker/cli#3627](https://github.com/docker/cli/pull/3627)\n*   Update the pretty-print format of `docker info` to provide more details on installed plugins. [docker/cli#3645](https://github.com/docker/cli/pull/3645)\n*   Print warning messages for the `docker context list` and `docker context use` commands when the context is overridden by the environment. [docker/cli#3668](https://github.com/docker/cli/pull/3668)\n*   Add a custom `aliases` annotation that can be used to print all available aliases for a command. [docker/cli#3694](https://github.com/docker/cli/pull/3694)\n*   The CLI no longer creates or updates the CLI configuration file when running `docker context use` and selecting the current context. [docker/cli#3721](https://github.com/docker/cli/pull/3721)\n*   Non-existing contexts are now ignored when running `docker context rm --force`. [docker/cli#3791](https://github.com/docker/cli/pull/3791)\n*   Add the ability to override integers to `0` in Compose files. [docker/cli#3812](https://github.com/docker/cli/pull/3812)\n*   SIGINT (`<Ctrl-c>`) now passes through to running containers instead of causing the CLI to exit. [docker/cli#3849](https://github.com/docker/cli/pull/3849)\n*   Improve `docker port CONTAINER` UX by sorting ports before printing. [docker/cli#3892](https://github.com/docker/cli/pull/3892)\n*   API: `GET /containers/{id}/logs` and `POST /containers/{id}/attach` now report which raw-stream format is in use using the `Content-type` response header on API version >= 1.42. [moby/moby#39812](https://github.com/moby/moby/pull/39812)\n*   Set default sandbox size for Windows layers to 127GB, and ensure that the `--storage-opts` flag applies to all storage on Windows. [moby/moby#41636](https://github.com/moby/moby/pull/41636)\n*   Remove the plugin section from the containerd configuration file (`/var/run/docker/containerd/containerd.toml`). [moby/moby#41675](https://github.com/moby/moby/pull/41675)\n*   Reject `null` manifests during tar import. [moby/moby#41842](https://github.com/moby/moby/pull/41842)\n*   Add shim config for custom runtimes for plugins. [moby/moby#41854](https://github.com/moby/moby/pull/41854)\n*   Container health checks now resume when the daemon is restarted. [moby/moby#41935](https://github.com/moby/moby/pull/41935)\n*   Quota is no longer disabled on cleanup of the `btrfs` driver. [moby/moby#42273](https://github.com/moby/moby/pull/42273)\n*   Host devices that are accessible can now be mounted in `--privileged` rootless containers. [moby/moby#42638](https://github.com/moby/moby/pull/42638)\n*   Fix incorrect handling of `**/foo` recursive wildcard directory patterns in `.dockerignore`. [moby/moby#42676](https://github.com/moby/moby/pull/42676)\n*   Extend `docker import --platform` to allow marking an imported image as a foreign architecture. [moby/moby#43103](https://github.com/moby/moby/pull/43103)\n*   Validation of CPU real-time options is now performed when the daemon starts instead of performing validations for each individual container, allowing startup to fail early. [moby/moby#43131](https://github.com/moby/moby/pull/43131)\n*   Freeze the `namesgenerator` package against new additions. Users will have to be satisfied with the existing 25359 adjective-name combinations. [moby/moby#43210](https://github.com/moby/moby/pull/43210)\n*   API: `containers/{id}/attach/ws` only to streams according by `stdin`, `stdout` and `stderr` parameters on API version >= 1.42. [moby/moby#43322](https://github.com/moby/moby/pull/43322)\n*   Fix UDP traffic in containers not working after the container is restarted under sustained traffic. [moby/moby#43409](https://github.com/moby/moby/pull/43409)\n*   Add support for pulling images with custom amd64 micro-architecture feature levels as supported by the latest versions of Go, GCC, LLVM, and other compiler tools. [moby/moby#43434](https://github.com/moby/moby/pull/43434)\n*   Improve validation of invalid JSON requests in the API. [moby/moby#43463](https://github.com/moby/moby/pull/43463)\n*   Mitigate the impact of slow `exec` starts on health checks. Check timeout now only applies to the duration that the health check command is running. The time it takes to start the command no longer counts against the timeout. [moby/moby#43480](https://github.com/moby/moby/pull/43480)\n*   Console `tty` size is set immediately on creation. [moby/moby#43593](https://github.com/moby/moby/pull/43593), [moby/moby#43622](https://github.com/moby/moby/pull/43622)\n*   Fix `overlay2` mounts not being cleaned up after failed container starts, or daemon shutdown. [moby/moby#43659](https://github.com/moby/moby/pull/43659)\n*   Match manifest list resolution with `containerd`. [moby/moby#43675](https://github.com/moby/moby/pull/43675)\n*   Skip use of `firewalld` for networking when the daemon is running in rootless mode. [moby/moby#43813](https://github.com/moby/moby/pull/43813)\n*   Custom NAT networks are now re-created after daemon restart if missing on Windows. [moby/moby#43858](https://github.com/moby/moby/pull/43858)\n*   Fix terminating the container health-check process when it times out. [moby/moby#43994](https://github.com/moby/moby/pull/43994)\n*   Fix `live-restore` with restart policies and volume refs. [moby/moby#44237](https://github.com/moby/moby/pull/44237)\n*   API: Only anonymous volumes now pruned by default on API version >= v1.42. Pass the filter `all=true` to prune named volumes in addition to anonymous. [moby/moby#44259](https://github.com/moby/moby/pull/44259)\n*   API: Support concurrent calls on the `GET /system/df` endpoint. [moby/moby#42715](https://github.com/moby/moby/pull/42715)\n*   Improve the reliability of the daemon dumping the stack and exits with code 2 when sent a SIGQUIT. [moby/moby#44831](https://github.com/moby/moby/pull/44831)\n*   Improve the reliability of `docker logs -f` on Windows, and prevent newlines from being dropped in the `local` log driver. [moby/moby#43294](https://github.com/moby/moby/pull/43294)\n*   Fix a rare deadlock in the daemon caused by buffering of container logs. [moby/moby#44856](https://github.com/moby/moby/pull/44856)\n*   Improve error handling in misc filesystem operations so that the daemon can start on a overlayfs backing filesystem. [moby/moby#44834](https://github.com/moby/moby/pull/44834)\n*   Fix an issue where `--ipc=host` wasn't handled correctly when the daemon is running in rootless mode. [moby/moby#44863](https://github.com/moby/moby/pull/44863)\n*   Fix a long-standing set of issues where stale conntrack entries caused incorrect routing of UDP traffic for containers. [moby/moby#44752](https://github.com/moby/moby/pull/44752)\n*   Fix half-registered containers being listed in the API, as well as a nil pointer de-reference and panic caused by using a partially registered container in API calls. [moby/moby#44633](https://github.com/moby/moby/pull/44633)\n*   Fix a failure to create the `DOCKER-USER` ip6tables chain. [moby/moby#44845](https://github.com/moby/moby/pull/44845)\n*   Fix a failure to clean up iptables rules when the `ip6tables` command isn't available. [moby/moby#44727](https://github.com/moby/moby/pull/44727)\n*   Fix an issue where some iptables NAT rules weren't cleaned up after enabling the userland proxy. [moby/moby#44811](https://github.com/moby/moby/pull/44811)\n*   Fix a potentially leaked process in rare situations where cleaning up a failed attempt to start a container was mishandled. [moby/moby#44400](https://github.com/moby/moby/pull/44400)\n*   Fix the `CreatedAt` time of a volume reflecting initialization and not creation. [moby/moby#44725](https://github.com/moby/moby/pull/44725)\n*   Fix an issue where the CLI incorrectly reported an incompatible server instead of an unreachable server in some commands. [docker/cli#3901](https://github.com/docker/cli/pull/3901), [docker/cli#3904](https://github.com/docker/cli/pull/3904)\n*   Fix broken completion of volumes in Zsh. [docker/cli#2998](https://github.com/docker/cli/pull/2998)\n*   Improve output of `docker context` when an invalid context is present. [docker/cli#3847](https://github.com/docker/cli/pull/3847)\n*   Remove ANSI decoration of CLI help annotations when the output isn't a TTY, and added a newline for readability. [docker/cli#3973](https://github.com/docker/cli/pull/3973)\n*   Add `docker container remove` as an alias for `docker container rm`. [docker/cli#3986](https://github.com/docker/cli/pull/3986)\n\n### [Known issues](#known-issues)\n\n#### [apparmor\\_parser (](#apparmor_parser-tracking-issuehttpsgithubcommobymobyissues44900) [tracking issue](https://github.com/moby/moby/issues/44900))\n\nSome Debian users have reported issues with containers failing to start after upgrading to the 23.0 branch. The error message indicates that the issue is due to a missing `apparmor_parser` binary:\n\nThe workaround to this issue is to install the `apparmor` package manually:\n\n#### [BuildKit inline cache (](#buildkit-inline-cache-tracking-issuehttpsgithubcommobymobyissues44918) [tracking issue](https://github.com/moby/moby/issues/44918))\n\nAttempting to build an image with BuildKit's inline cache feature (e.g. `docker build --build-arg BUILDKIT_INLINE_CACHE=1 .`, `docker buildx build --cache-to type=inline .`) will result in the daemon unexpectedly exiting:\n\nThe daemon will restart if configured to do so (e.g. via systemd) after such a crash. The only available mitigation in this release is to avoid performing builds with the inline cache feature enabled.\n\n#### [BuildKit with warm cache (](#buildkit-with-warm-cache-tracking-issuehttpsgithubcommobymobyissues44943) [tracking issue](https://github.com/moby/moby/issues/44943))\n\nIf an image was built with BuildKit on a previous version of the daemon, and is built with a 23.0 daemon, previously cached layers will not be restored correctly. The image may appear to build correctly if no lines are changed in the Dockerfile; however, if partial cache invalidation occurs due to changing some lines in the Dockerfile, the still valid and previously cached layers will not be loaded correctly.\n\nThis most often presents as files that should be present in the image not being present in a `RUN` stage, or any other stage that references files, after changing some lines in the Dockerfile:\n\nTo mitigate this, the previous build cache must be discarded. `docker builder prune -a` will completely empty the build cache, and allow the affected builds to proceed again by removing the mishandled cache layers.\n\n#### [ipvlan networks (](#ipvlan-networks-tracking-issuehttpsgithubcommobymobyissues44925) [tracking issue](https://github.com/moby/moby/issues/44925))\n\nWhen upgrading to the 23.0 branch, the existence of any [ipvlan](https://docs.docker.com/network/drivers/ipvlan/) networks will prevent the daemon from starting:\n\nTo mitigate this, affected users can downgrade and remove the network, then upgrade again. Alternatively, the entire network store can be removed, and networks can be recreated after the upgrade. The network store is located at `/var/lib/docker/network/files/local-kv.db`. If the daemon is using an alternate `--data-root`, substitute `/var/lib/docker` for the alternate path.\n\n#### [Kata Containers (](#kata-containers-tracking-issuehttpsgithubcomkata-containerskata-containersissues6154) [tracking issue](https://github.com/kata-containers/kata-containers/issues/6154))\n\nThe 23.0 branch brings support for alternate containerd shims, such as `io.containerd.runsc.v1` (gVisor) and `io.containerd.kata.v2` (Kata Containers).\n\nWhen using the Kata Containers runtime, exiting an `exec` session stops the running container, and hangs the connected CLI if a TTY was opened. There is no mitigation at this time beyond avoiding execing into containers running on the Kata runtime.\n\nThe root cause of this issue is a long-standing bug in Moby. This will be resolved in a future release. Be advised that support for alternate OCI runtimes is a new feature and that similar issues may be discovered as more users start exercising this functionality.",
    "title": "Docker Engine 23.0 release notes | Docker Docs\n",
    "description": "Learn about the new features, bug fixes, and breaking changes for Docker Engine",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/extend/plugins_volume/",
    "markdown": "# Docker volume plugins | Docker Docs\n\nDocker Engine volume plugins enable Engine deployments to be integrated with external storage systems such as Amazon EBS, and enable data volumes to persist beyond the lifetime of a single Docker host. See the [plugin documentation](https://docs.docker.com/engine/extend/legacy_plugins/) for more information.\n\n### [1.13.0](#1130)\n\n*   If used as part of the v2 plugin architecture, mountpoints that are part of paths returned by the plugin must be mounted under the directory specified by `PropagatedMount` in the plugin configuration ( [#26398](https://github.com/docker/docker/pull/26398))\n\n### [1.12.0](#1120)\n\n*   Add `Status` field to `VolumeDriver.Get` response ( [#21006](https://github.com/docker/docker/pull/21006#))\n*   Add `VolumeDriver.Capabilities` to get capabilities of the volume driver ( [#22077](https://github.com/docker/docker/pull/22077))\n\n### [1.10.0](#1100)\n\n*   Add `VolumeDriver.Get` which gets the details about the volume ( [#16534](https://github.com/docker/docker/pull/16534))\n*   Add `VolumeDriver.List` which lists all volumes owned by the driver ( [#16534](https://github.com/docker/docker/pull/16534))\n\n### [1.8.0](#180)\n\n*   Initial support for volume driver plugins ( [#14659](https://github.com/docker/docker/pull/14659))\n\nTo give a container access to a volume, use the `--volume` and `--volume-driver` flags on the `docker container run` command. The `--volume` (or `-v`) flag accepts a volume name and path on the host, and the `--volume-driver` flag accepts a driver type.\n\n### [`--volume`](#--volume)\n\nThe `--volume` (or `-v`) flag takes a value that is in the format `<volume_name>:<mountpoint>`. The two parts of the value are separated by a colon (`:`) character.\n\n*   The volume name is a human-readable name for the volume, and cannot begin with a `/` character. It is referred to as `volume_name` in the rest of this topic.\n*   The `Mountpoint` is the path on the host (v1) or in the plugin (v2) where the volume has been made available.\n\n### [`volumedriver`](#volumedriver)\n\nSpecifying a `volumedriver` in conjunction with a `volumename` allows you to use plugins such as [Flocker](https://github.com/ScatterHQ/flocker) to manage volumes external to a single host, such as those on EBS.\n\nThe container creation endpoint (`/containers/create`) accepts a `VolumeDriver` field of type `string` allowing to specify the name of the driver. If not specified, it defaults to `\"local\"` (the default driver for local volumes).\n\nIf a plugin registers itself as a `VolumeDriver` when activated, it must provide the Docker Daemon with writeable paths on the host filesystem. The Docker daemon provides these paths to containers to consume. The Docker daemon makes the volumes available by bind-mounting the provided paths into the containers.\n\n> **Note**\n> \n> Volume plugins should _not_ write data to the `/var/lib/docker/` directory, including `/var/lib/docker/volumes`. The `/var/lib/docker/` directory is reserved for Docker.\n\n### [`/VolumeDriver.Create`](#volumedrivercreate)\n\nRequest:\n\nInstruct the plugin that the user wants to create a volume, given a user specified volume name. The plugin does not need to actually manifest the volume on the filesystem yet (until `Mount` is called). `Opts` is a map of driver specific options passed through from the user request.\n\nResponse:\n\nRespond with a string error if an error occurred.\n\n### [`/VolumeDriver.Remove`](#volumedriverremove)\n\nRequest:\n\nDelete the specified volume from disk. This request is issued when a user invokes `docker rm -v` to remove volumes associated with a container.\n\nResponse:\n\nRespond with a string error if an error occurred.\n\n### [`/VolumeDriver.Mount`](#volumedrivermount)\n\nRequest:\n\nDocker requires the plugin to provide a volume, given a user specified volume name. `Mount` is called once per container start. If the same `volume_name` is requested more than once, the plugin may need to keep track of each new mount request and provision at the first mount request and deprovision at the last corresponding unmount request.\n\n`ID` is a unique ID for the caller that is requesting the mount.\n\nResponse:\n\n*   v1\n    \n*   v2\n    \n\n`Mountpoint` is the path on the host (v1) or in the plugin (v2) where the volume has been made available.\n\n`Err` is either empty or contains an error string.\n\n### [`/VolumeDriver.Path`](#volumedriverpath)\n\nRequest:\n\nRequest the path to the volume with the given `volume_name`.\n\nResponse:\n\n*   v1\n    \n*   v2\n    \n\nRespond with the path on the host (v1) or inside the plugin (v2) where the volume has been made available, and/or a string error if an error occurred.\n\n`Mountpoint` is optional. However, the plugin may be queried again later if one is not provided.\n\n### [`/VolumeDriver.Unmount`](#volumedriverunmount)\n\nRequest:\n\nDocker is no longer using the named volume. `Unmount` is called once per container stop. Plugin may deduce that it is safe to deprovision the volume at this point.\n\n`ID` is a unique ID for the caller that is requesting the mount.\n\nResponse:\n\nRespond with a string error if an error occurred.\n\n### [`/VolumeDriver.Get`](#volumedriverget)\n\nRequest:\n\nGet info about `volume_name`.\n\nResponse:\n\n*   v1\n    \n*   v2\n    \n\nRespond with a string error if an error occurred. `Mountpoint` and `Status` are optional.\n\n### [/VolumeDriver.List](#volumedriverlist)\n\nRequest:\n\nGet the list of volumes registered with the plugin.\n\nResponse:\n\n*   v1\n    \n*   v2\n    \n\nRespond with a string error if an error occurred. `Mountpoint` is optional.\n\n### [/VolumeDriver.Capabilities](#volumedrivercapabilities)\n\nRequest:\n\nGet the list of capabilities the driver supports.\n\nThe driver is not required to implement `Capabilities`. If it is not implemented, the default values are used.\n\nResponse:\n\nSupported scopes are `global` and `local`. Any other value in `Scope` will be ignored, and `local` is used. `Scope` allows cluster managers to handle the volume in different ways. For instance, a scope of `global`, signals to the cluster manager that it only needs to create the volume once instead of on each Docker host. More capabilities may be added in the future.",
    "title": "Docker volume plugins | Docker Docs\n",
    "description": "How to manage data with external volume plugins",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/drivers/kubernetes/",
    "markdown": "# Kubernetes driver | Docker Docs\n\nThe Kubernetes driver lets you connect your local development or CI environments to builders in a Kubernetes cluster to allow access to more powerful compute resources, optionally on multiple native architectures.\n\nRun the following command to create a new builder, named `kube`, that uses the Kubernetes driver:\n\nThe following table describes the available driver-specific options that you can pass to `--driver-opt`:\n\n| Parameter | Type | Default | Description |\n| --- | --- | --- | --- |\n| `image` | String |     | Sets the image to use for running BuildKit. |\n| `namespace` | String | Namespace in current Kubernetes context | Sets the Kubernetes namespace. |\n| `default-load` | Boolean | `false` | Automatically load images to the Docker Engine image store. |\n| `replicas` | Integer | 1   | Sets the number of Pod replicas to create. See [scaling BuildKit](#scaling-buildkit) |\n| `requests.cpu` | CPU units |     | Sets the request CPU value specified in units of Kubernetes CPU. For example `requests.cpu=100m` or `requests.cpu=2` |\n| `requests.memory` | Memory size |     | Sets the request memory value specified in bytes or with a valid suffix. For example `requests.memory=500Mi` or `requests.memory=4G` |\n| `requests.ephemeral-storage` | Storage size |     | Sets the request ephemeral-storage value specified in bytes or with a valid suffix. For example `requests.ephemeral-storage=2Gi` |\n| `limits.cpu` | CPU units |     | Sets the limit CPU value specified in units of Kubernetes CPU. For example `requests.cpu=100m` or `requests.cpu=2` |\n| `limits.memory` | Memory size |     | Sets the limit memory value specified in bytes or with a valid suffix. For example `requests.memory=500Mi` or `requests.memory=4G` |\n| `limits.ephemeral-storage` | Storage size |     | Sets the limit ephemeral-storage value specified in bytes or with a valid suffix. For example `requests.ephemeral-storage=100M` |\n| `nodeselector` | CSV string |     | Sets the pod's `nodeSelector` label(s). See [node assignment](#node-assignment). |\n| `annotation` | CSV string |     | Sets additional annotations on the deployments and pods. |\n| `labels` | CSV string |     | Sets additional labels on the deployments and pods. |\n| `tolerations` | CSV string |     | Configures the pod's taint toleration. See [node assignment](#node-assignment). |\n| `serviceaccount` | String |     | Sets the pod's `serviceAccountName`. |\n| `schedulername` | String |     | Sets the scheduler responsible for scheduling the pod. |\n| `timeout` | Time | `120s` | Set the timeout limit that determines how long Buildx will wait for pods to be provisioned before a build. |\n| `rootless` | Boolean | `false` | Run the container as a non-root user. See [rootless mode](#rootless-mode). |\n| `loadbalance` | String | `sticky` | Load-balancing strategy (`sticky` or `random`). If set to `sticky`, the pod is chosen using the hash of the context path. |\n| `qemu.install` | Boolean | `false` | Install QEMU emulation for multi platforms support. See [QEMU](#qemu). |\n| `qemu.image` | String | `tonistiigi/binfmt:latest` | Sets the QEMU emulation image. See [QEMU](#qemu). |\n\nOne of the main advantages of the Kubernetes driver is that you can scale the number of builder replicas up and down to handle increased build load. Scaling is configurable using the following driver options:\n\n*   `replicas=N`\n    \n    This scales the number of BuildKit pods to the desired size. By default, it only creates a single pod. Increasing the number of replicas lets you take advantage of multiple nodes in your cluster.\n    \n*   `requests.cpu`, `requests.memory`, `requests.ephemeral-storage`, `limits.cpu`, `limits.memory`, `limits.ephemeral-storage`\n    \n    These options allow requesting and limiting the resources available to each BuildKit pod according to the official Kubernetes documentation [here](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/).\n    \n\nFor example, to create 4 replica BuildKit pods:\n\nListing the pods, you get this:\n\nAdditionally, you can use the `loadbalance=(sticky|random)` option to control the load-balancing behavior when there are multiple replicas. `random` selects random nodes from the node pool, providing an even workload distribution across replicas. `sticky` (the default) attempts to connect the same build performed multiple times to the same node each time, ensuring better use of local cache.\n\nFor more information on scalability, see the options for [`docker buildx create`](https://docs.docker.com/reference/cli/docker/buildx/create/#driver-opt).\n\nThe Kubernetes driver allows you to control the scheduling of BuildKit pods using the `nodeSelector` and `tolerations` driver options. You can also set the `schedulername` option if you want to use a custom scheduler altogether.\n\nYou can use the `annotations` and `labels` driver options to apply additional metadata to the deployments and pods that's hosting your builders.\n\nThe value of the `nodeSelector` parameter is a comma-separated string of key-value pairs, where the key is the node label and the value is the label text. For example: `\"nodeselector=kubernetes.io/arch=arm64\"`\n\nThe `tolerations` parameter is a semicolon-separated list of taints. It accepts the same values as the Kubernetes manifest. Each `tolerations` entry specifies a taint key and the value, operator, or effect. For example: `\"tolerations=key=foo,value=bar;key=foo2,operator=exists;key=foo3,effect=NoSchedule\"`\n\nThese options accept CSV-delimited strings as values. Due to quoting rules for shell commands, you must wrap the values in single quotes. You can even wrap all of `--driver-opt` in single quotes, for example:\n\nThe Kubernetes driver has support for creating [multi-platform images](https://docs.docker.com/build/building/multi-platform/), either using QEMU or by leveraging the native architecture of nodes.\n\n### [QEMU](#qemu)\n\nLike the `docker-container` driver, the Kubernetes driver also supports using [QEMU](https://www.qemu.org/) (user mode) to build images for non-native platforms. Include the `--platform` flag and specify which platforms you want to output to.\n\nFor example, to build a Linux image for `amd64` and `arm64`:\n\n> **Warning**\n> \n> QEMU performs full-CPU emulation of non-native platforms, which is much slower than native builds. Compute-heavy tasks like compilation and compression/decompression will likely take a large performance hit.\n\nUsing a custom BuildKit image or invoking non-native binaries in builds may require that you explicitly turn on QEMU using the `qemu.install` option when creating the builder:\n\n### [Native](#native)\n\nIf you have access to cluster nodes of different architectures, the Kubernetes driver can take advantage of these for native builds. To do this, use the `--append` flag of `docker buildx create`.\n\nFirst, create your builder with explicit support for a single architecture, for example `amd64`:\n\nThis creates a Buildx builder named `kube`, containing a single builder node named `builder-amd64`. Assigning a node name using `--node` is optional. Buildx generates a random node name if you don't provide one.\n\nNote that the Buildx concept of a node isn't the same as the Kubernetes concept of a node. A Buildx node in this case could connect multiple Kubernetes nodes of the same architecture together.\n\nWith the `kube` builder created, you can now introduce another architecture into the mix using `--append`. For example, to add `arm64`:\n\nListing your builders shows both nodes for the `kube` builder:\n\nYou can now build multi-arch `amd64` and `arm64` images, by specifying those platforms together in your build command:\n\nYou can repeat the `buildx create --append` command for as many architectures that you want to support.\n\nThe Kubernetes driver supports rootless mode. For more information on how rootless mode works, and it's requirements, see [here](https://github.com/moby/buildkit/blob/master/docs/rootless.md).\n\nTo turn it on in your cluster, you can use the `rootless=true` driver option:\n\nThis will create your pods without `securityContext.privileged`.\n\nRequires Kubernetes version 1.19 or later. Using Ubuntu as the host kernel is recommended.\n\nThis guide shows you how to:\n\n*   Create a namespace for your Buildx resources\n*   Create a Kubernetes builder.\n*   List the available builders\n*   Build an image using your Kubernetes builders\n\nPrerequisites:\n\n*   You have an existing Kubernetes cluster. If you don't already have one, you can follow along by installing [minikube](https://minikube.sigs.k8s.io/docs/).\n*   The cluster you want to connect to is accessible via the `kubectl` command, with the `KUBECONFIG` environment variable [set appropriately](https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/#set-the-kubeconfig-environment-variable) if necessary.\n\n1.  Create a `buildkit` namespace.\n    \n    Creating a separate namespace helps keep your Buildx resources separate from other resources in the cluster.\n    \n2.  Create a new builder with the Kubernetes driver:\n    \n    > **Note**\n    > \n    > Remember to specify the namespace in driver options.\n    \n3.  List available builders using `docker buildx ls`\n    \n4.  Inspect the running pods created by the build driver with `kubectl`.\n    \n    The build driver creates the necessary resources on your cluster in the specified namespace (in this case, `buildkit`), while keeping your driver configuration locally.\n    \n5.  Use your new builder by including the `--builder` flag when running buildx commands. For example: :\n    \n\nThat's it! You've now built an image from a Kubernetes pod, using Buildx!\n\nFor more information on the Kubernetes driver, see the [buildx reference](https://docs.docker.com/reference/cli/docker/buildx/create/#driver).",
    "title": "Kubernetes driver | Docker Docs\n",
    "description": "The Kubernetes driver lets you run BuildKit in a Kubernetes cluster. You can connect to, and run your builds in, the cluster using Buildx. ",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/drivers/remote/",
    "markdown": "# Remote driver | Docker Docs\n\nThe Buildx remote driver allows for more complex custom build workloads, allowing you to connect to externally managed BuildKit instances. This is useful for scenarios that require manual management of the BuildKit daemon, or where a BuildKit daemon is exposed from another source.\n\nThe following table describes the available driver-specific options that you can pass to `--driver-opt`:\n\n| Parameter | Type | Default | Description |\n| --- | --- | --- | --- |\n| `key` | String |     | Sets the TLS client key. |\n| `cert` | String |     | Absolute path to the TLS client certificate to present to `buildkitd`. |\n| `cacert` | String |     | Absolute path to the TLS certificate authority used for validation. |\n| `servername` | String | Endpoint hostname. | TLS server name used in requests. |\n| `default-load` | Boolean | `false` | Automatically load images to the Docker Engine image store. |\n\nThis guide shows you how to create a setup with a BuildKit daemon listening on a Unix socket, and have Buildx connect through it.\n\n1.  Ensure that [BuildKit](https://github.com/moby/buildkit) is installed.\n    \n    For example, you can launch an instance of buildkitd with:\n    \n    Alternatively, [see here](https://github.com/moby/buildkit/blob/master/docs/rootless.md) for running buildkitd in rootless mode or [here](https://github.com/moby/buildkit/tree/master/examples/systemd) for examples of running it as a systemd service.\n    \n2.  Check that you have a Unix socket that you can connect to.\n    \n3.  Connect Buildx to it using the remote driver:\n    \n4.  List available builders with `docker buildx ls`. You should then see `remote-unix` among them:\n    \n\nYou can switch to this new builder as the default using `docker buildx use remote-unix`, or specify it per build using `--builder`:\n\nRemember that you need to use the `--load` flag if you want to load the build result into the Docker daemon.\n\nThis guide will show you how to create setup similar to the `docker-container` driver, by manually booting a BuildKit Docker container and connecting to it using the Buildx remote driver. This procedure will manually create a container and access it via it's exposed port. (You'd probably be better of just using the `docker-container` driver that connects to BuildKit through the Docker daemon, but this is for illustration purposes.)\n\n1.  Generate certificates for BuildKit.\n    \n    You can use this [bake definition](https://github.com/moby/buildkit/blob/master/examples/create-certs) as a starting point:\n    \n    Note that while it's possible to expose BuildKit over TCP without using TLS, it's not recommended. Doing so allows arbitrary access to BuildKit without credentials.\n    \n2.  With certificates generated in `.certs/`, startup the container:\n    \n    This command starts a BuildKit container and exposes the daemon's port 1234 to localhost.\n    \n3.  Connect to this running container using Buildx:\n    \n    Alternatively, use the `docker-container://` URL scheme to connect to the BuildKit container without specifying a port:\n    \n\nThis guide will show you how to create a setup similar to the `kubernetes` driver by manually creating a BuildKit `Deployment`. While the `kubernetes` driver will do this under-the-hood, it might sometimes be desirable to scale BuildKit manually. Additionally, when executing builds from inside Kubernetes pods, the Buildx builder will need to be recreated from within each pod or copied between them.\n\n1.  Create a Kubernetes deployment of `buildkitd`, as per the instructions [here](https://github.com/moby/buildkit/tree/master/examples/kubernetes).\n    \n    Following the guide, create certificates for the BuildKit daemon and client using [create-certs.sh](https://github.com/moby/buildkit/blob/master/examples/kubernetes/create-certs.sh), and create a deployment of BuildKit pods with a service that connects to them.\n    \n2.  Assuming that the service is called `buildkitd`, create a remote builder in Buildx, ensuring that the listed certificate files are present:\n    \n\nNote that this only works internally, within the cluster, since the BuildKit setup guide only creates a `ClusterIP` service. To access a builder remotely, you can set up and use an ingress, which is outside the scope of this guide.\n\n### [Debug a remote builder in Kubernetes](#debug-a-remote-builder-in-kubernetes)\n\nIf you're having trouble accessing a remote builder deployed in Kubernetes, you can use the `kube-pod://` URL scheme to connect directly to a BuildKit pod through the Kubernetes API. Note that this method only connects to a single pod in the deployment.\n\nAlternatively, use the port forwarding mechanism of `kubectl`:\n\nThen you can point the remote driver at `tcp://localhost:1234`.",
    "title": "Remote driver | Docker Docs\n",
    "description": "The remote driver lets you connect to a remote BuildKit instance that you set up and configure manually. ",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/extend/config/",
    "markdown": "# Plugin Config Version 1 of Plugin V2\n\n```\n{\n  \"Args\": {\n    \"Description\": \"\",\n    \"Name\": \"\",\n    \"Settable\": null,\n    \"Value\": null\n  },\n  \"Description\": \"A sample volume plugin for Docker\",\n  \"Documentation\": \"https://docs.docker.com/engine/extend/plugins/\",\n  \"Entrypoint\": [\n    \"/usr/bin/sample-volume-plugin\",\n    \"/data\"\n  ],\n  \"Env\": [\n    {\n      \"Description\": \"\",\n      \"Name\": \"DEBUG\",\n      \"Settable\": [\n        \"value\"\n      ],\n      \"Value\": \"0\"\n    }\n  ],\n  \"Interface\": {\n    \"Socket\": \"plugin.sock\",\n    \"Types\": [\n      \"docker.volumedriver/1.0\"\n    ]\n  },\n  \"Linux\": {\n    \"Capabilities\": null,\n    \"AllowAllDevices\": false,\n    \"Devices\": null\n  },\n  \"Mounts\": null,\n  \"Network\": {\n    \"Type\": \"\"\n  },\n  \"PropagatedMount\": \"/data\",\n  \"User\": {},\n  \"Workdir\": \"\"\n}\n```",
    "title": "Plugin Config Version 1 of Plugin V2 | Docker Docs\n",
    "description": "How to develop and use a plugin with the managed plugin system",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/exporters/",
    "markdown": "# Exporters overview | Docker Docs\n\nExporters save your build results to a specified output type. You specify the exporter to use with the [`--output` CLI option](https://docs.docker.com/reference/cli/docker/buildx/build/#output). Buildx supports the following exporters:\n\n*   `image`: exports the build result to a container image.\n*   `registry`: exports the build result into a container image, and pushes it to the specified registry.\n*   `local`: exports the build root filesystem into a local directory.\n*   `tar`: packs the build root filesystem into a local tarball.\n*   `oci`: exports the build result to the local filesystem in the [OCI image layout](https://github.com/opencontainers/image-spec/blob/v1.0.1/image-layout.md) format.\n*   `docker`: exports the build result to the local filesystem in the [Docker Image Specification v1.2.0](https://github.com/moby/moby/blob/v25.0.0/image/spec/v1.2.md) format.\n*   `cacheonly`: doesn't export a build output, but runs the build and creates a cache.\n\nTo specify an exporter, use the following command syntax:\n\nMost common use cases don't require that you specify which exporter to use explicitly. You only need to specify the exporter if you intend to customize the output, or if you want to save it to disk. The `--load` and `--push` options allow Buildx to infer the exporter settings to use.\n\nFor example, if you use the `--push` option in combination with `--tag`, Buildx automatically uses the `image` exporter, and configures the exporter to push the results to the specified registry.\n\nTo get the full flexibility out of the various exporters BuildKit has to offer, you use the `--output` flag that lets you configure exporter options.\n\nEach exporter type is designed for different use cases. The following sections describe some common scenarios, and how you can use exporters to generate the output that you need.\n\n### [Load to image store](#load-to-image-store)\n\nBuildx is often used to build container images that can be loaded to an image store. That's where the `docker` exporter comes in. The following example shows how to build an image using the `docker` exporter, and have that image loaded to the local image store, using the `--output` option:\n\nBuildx CLI will automatically use the `docker` exporter and load it to the image store if you supply the `--tag` and `--load` options:\n\nBuilding images using the `docker` driver are automatically loaded to the local image store.\n\nImages loaded to the image store are available to `docker run` immediately after the build finishes, and you'll see them in the list of images when you run the `docker images` command.\n\n### [Push to registry](#push-to-registry)\n\nTo push a built image to a container registry, you can use the `registry` or `image` exporters.\n\nWhen you pass the `--push` option to the Buildx CLI, you instruct BuildKit to push the built image to the specified registry:\n\nUnder the hood, this uses the `image` exporter, and sets the `push` parameter. It's the same as using the following long-form command using the `--output` option:\n\nYou can also use the `registry` exporter, which does the same thing:\n\n### [Export image layout to file](#export-image-layout-to-file)\n\nYou can use either the `oci` or `docker` exporters to save the build results to image layout on your local filesystem. Both of these exporters generate a tar archive file containing the corresponding image layout. The `dest` parameter defines the target output path for the tarball.\n\n### [Export filesystem](#export-filesystem)\n\nIf you don't want to build an image from your build results, but instead export the filesystem that was built, you can use the `local` and `tar` exporters.\n\nThe `local` exporter unpacks the filesystem into a directory structure in the specified location. The `tar` exporter creates a tarball archive file.\n\nThe `local` exporter is useful in [multi-stage builds](https://docs.docker.com/build/building/multi-stage/) since it allows you to export only a minimal number of build artifacts, such as self-contained binaries.\n\n### [Cache-only export](#cache-only-export)\n\nThe `cacheonly` exporter can be used if you just want to run a build, without exporting any output. This can be useful if, for example, you want to run a test build. Or, if you want to run the build first, and create exports using subsequent commands. The `cacheonly` exporter creates a build cache, so any successive builds are instant.\n\nIf you don't specify an exporter, and you don't provide short-hand options like `--load` that automatically selects the appropriate exporter, Buildx defaults to using the `cacheonly` exporter. Except if you build using the `docker` driver, in which case you use the `docker` exporter.\n\nBuildx logs a warning message when using `cacheonly` as a default:\n\nIntroduced in Buildx version 0.13.0\n\nYou can use multiple exporters for any given build by specifying the `--output` flag multiple times. This requires **both Buildx and BuildKit** version 0.13.0 or later.\n\nThe following example runs a single build, using three different exporters:\n\n*   The `registry` exporter to push the image to a registry\n*   The `local` exporter to extract the build results to the local filesystem\n*   The `--load` flag (a shorthand for the `image` exporter) to load the results to the local image store.\n\nThis section describes some configuration options available for exporters.\n\nThe options described here are common for at least two or more exporter types. Additionally, the different exporters types support specific parameters as well. See the detailed page about each exporter for more information about which configuration parameters apply.\n\nThe common parameters described here are:\n\n*   [Compression](#compression)\n*   [OCI media type](#oci-media-types)\n\n### [Compression](#compression)\n\nWhen you export a compressed output, you can configure the exact compression algorithm and level to use. While the default values provide a good out-of-the-box experience, you may wish to tweak the parameters to optimize for storage vs compute costs. Changing the compression parameters can reduce storage space required, and improve image download times, but will increase build times.\n\nTo select the compression algorithm, you can use the `compression` option. For example, to build an `image` with `compression=zstd`:\n\nUse the `compression-level=<value>` option alongside the `compression` parameter to choose a compression level for the algorithms which support it:\n\n*   0-9 for `gzip` and `estargz`\n*   0-22 for `zstd`\n\nAs a general rule, the higher the number, the smaller the resulting file will be, and the longer the compression will take to run.\n\nUse the `force-compression=true` option to force re-compressing layers imported from a previous image, if the requested compression algorithm is different from the previous compression algorithm.\n\n> **Note**\n> \n> The `gzip` and `estargz` compression methods use the [`compress/gzip` package](https://pkg.go.dev/compress/gzip), while `zstd` uses the [`github.com/klauspost/compress/zstd` package](https://github.com/klauspost/compress/tree/master/zstd).\n\n### [OCI media types](#oci-media-types)\n\nThe `image`, `registry`, `oci` and `docker` exporters create container images. These exporters support both Docker media types (default) and OCI media types\n\nTo export images with OCI media types set, use the `oci-mediatypes` property.\n\nRead about each of the exporters to learn about how they work and how to use them:\n\n*   [Image and registry exporters](https://docs.docker.com/build/exporters/image-registry/)\n*   [OCI and Docker exporters](https://docs.docker.com/build/exporters/oci-docker/).\n*   [Local and tar exporters](https://docs.docker.com/build/exporters/local-tar/)",
    "title": "Exporters overview | Docker Docs\n",
    "description": "Build exporters define the output format of your build result",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/deploy-service/",
    "markdown": "# Deploy a service to the swarm\n\nAfter you [create a swarm](https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/), you can deploy a service to the swarm. For this tutorial, you also [added worker nodes](https://docs.docker.com/engine/swarm/swarm-tutorial/add-nodes/), but that is not a requirement to deploy a service.\n\n1.  Open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n    \n2.  Run the following command:\n    \n    *   The `docker service create` command creates the service.\n    *   The `--name` flag names the service `helloworld`.\n    *   The `--replicas` flag specifies the desired state of 1 running instance.\n    *   The arguments `alpine ping docker.com` define the service as an Alpine Linux container that executes the command `ping docker.com`.\n3.  Run `docker service ls` to see the list of running services:\n    \n\nNow you're ready to inspect the service.",
    "title": "Deploy a service to the swarm | Docker Docs\n",
    "description": "Deploy a service to the swarm",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/add-nodes/",
    "markdown": "# Add nodes to the swarm\n\nOnce you've [created a swarm](https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/) with a manager node, you're ready to add worker nodes.\n\n1.  Open a terminal and ssh into the machine where you want to run a worker node. This tutorial uses the name `worker1`.\n    \n2.  Run the command produced by the `docker swarm init` output from the [Create a swarm](https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/) tutorial step to create a worker node joined to the existing swarm:\n    \n    If you don't have the command available, you can run the following command on a manager node to retrieve the join command for a worker:\n    \n3.  Open a terminal and ssh into the machine where you want to run a second worker node. This tutorial uses the name `worker2`.\n    \n4.  Run the command produced by the `docker swarm init` output from the [Create a swarm](https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/) tutorial step to create a second worker node joined to the existing swarm:\n    \n5.  Open a terminal and ssh into the machine where the manager node runs and run the `docker node ls` command to see the worker nodes:\n    \n    The `MANAGER` column identifies the manager nodes in the swarm. The empty status in this column for `worker1` and `worker2` identifies them as worker nodes.\n    \n    Swarm management commands like `docker node ls` only work on manager nodes.\n    \n\nNow your swarm consists of a manager and two worker nodes. Next, you'll deploy a service.",
    "title": "Add nodes to the swarm | Docker Docs\n",
    "description": "Add nodes to the swarm",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/20.10/",
    "markdown": "# Docker Engine 20.10 release notes\n\nThis document describes the latest changes, additions, known issues, and fixes for Docker Engine version 20.10.\n\n_2023-04-04_\n\n### [Updates](#updates)\n\n*   Update Go runtime to [1.19.7](https://go.dev/doc/devel/release#go1.19.minor).\n*   Update Docker Buildx to [v0.10.4](https://github.com/docker/buildx/releases/tag/v0.10.4).\n*   Update containerd to [v1.6.20](https://github.com/containerd/containerd/releases/tag/v1.6.20).\n*   Update runc to [v1.1.5](https://github.com/opencontainers/runc/releases/tag/v1.1.5).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements)\n\n*   Fixed a number of issues that can cause Swarm encrypted overlay networks to fail to uphold their guarantees, addressing [CVE-2023-28841](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-28841), [CVE-2023-28840](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-28840), and [CVE-2023-28842](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-28842).\n    *   A lack of kernel support for encrypted overlay networks now reports as an error.\n    *   Encrypted overlay networks are eagerly set up, rather than waiting for multiple nodes to attach.\n    *   Encrypted overlay networks are now usable on Red Hat Enterprise Linux 9 through the use of the `xt_bpf` kernel module.\n    *   Users of Swarm overlay networks should review [GHSA-vwm3-crmr-xfxw](https://github.com/moby/moby/security/advisories/GHSA-vwm3-crmr-xfxw) to ensure that unintentional exposure has not occurred.\n*   Upgrade github.com/containerd/fifo to v1.1.0 to fix a potential panic [moby/moby#45216](https://github.com/moby/moby/pull/45242).\n*   Fix missing Bash completion for installed cli-plugins [docker/cli#4091](https://github.com/docker/cli/pull/4091).\n\n_2023-01-19_\n\nThis release of Docker Engine contains updated versions of Docker Compose, Docker Buildx, containerd, and some minor bug fixes and enhancements.\n\n### [Updates](#updates-1)\n\n*   Update Docker Compose to [v2.15.1](https://github.com/docker/compose/releases/tag/v2.15.1).\n*   Update Docker Buildx to [v0.10.0](https://github.com/docker/buildx/releases/tag/v0.10.0).\n*   Update containerd (`containerd.io` package) to [v1.6.15](https://github.com/containerd/containerd/releases/tag/v1.6.15).\n*   Update the package versioning format for `docker-compose-cli` to allow distro version updates [docker/docker-ce-packaging#822](https://github.com/docker/docker-ce-packaging/pull/822).\n*   Update Go runtime to [1.18.10](https://go.dev/doc/devel/release#go1.18.minor),\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-1)\n\n*   Fix an issue where `docker build` would fail when using `--add-host=host.docker.internal:host-gateway` with BuildKit enabled [moby/moby#44650](https://github.com/moby/moby/pull/44650).\n    \n*   Revert seccomp: block socket calls to `AF_VSOCK` in default profile [moby/moby#44712](https://github.com/moby/moby/pull/44712).\n    \n    This change, while favorable from a security standpoint, caused a change in behavior for some use-cases. As such, we are reverting it to ensure stability and compatibility for the affected users.\n    \n    However, users of `AF_VSOCK` in containers should recognize that this (special) address family is not currently namespaced in any version of the Linux kernel, and may result in unexpected behavior, like containers communicating directly with host hypervisors.\n    \n    Future releases, will filter `AF_VSOCK`. Users who need to allow containers to communicate over the unnamespaced `AF_VSOCK` will need to turn off seccomp confinement or set a custom seccomp profile.\n    \n\n_2022-12-16_\n\nThis release of Docker Engine contains updated versions of Docker Compose, Docker Scan, containerd, and some minor bug fixes and enhancements.\n\n### [Updates](#updates-2)\n\n*   Update Docker Compose to [v2.14.1](https://github.com/docker/compose/releases/tag/v2.14.1).\n*   Update Docker Scan to [v0.23.0](https://github.com/docker/scan-cli-plugin/releases/tag/v0.23.0).\n*   Update containerd (`containerd.io` package) to [v1.6.13](https://github.com/containerd/containerd/releases/tag/v1.6.13), to include a fix for [CVE-2022-23471](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23471).\n*   Update Go runtime to [1.18.9](https://go.dev/doc/devel/release#go1.18.minor), to include fixes for [CVE-2022-41716](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41716), [CVE-2022-41717](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41717), and [CVE-2022-41720](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41720).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-2)\n\n*   Improve error message when attempting to pull an unsupported image format or OCI artifact [moby/moby#44413](https://github.com/moby/moby/pull/44413), [moby/moby#44569](https://github.com/moby/moby/pull/44569).\n*   Fix an issue where the host's ephemeral port-range was ignored when selecting random ports for containers [moby/moby#44476](https://github.com/moby/moby/pull/44476).\n*   Fix `ssh: parse error in message type 27` errors during `docker build` on hosts using OpenSSH 8.9 or above [moby/moby#3862](https://github.com/moby/moby/pull/3862).\n*   seccomp: block socket calls to `AF_VSOCK` in default profile [moby/moby#44564](https://github.com/moby/moby/pull/44564).\n\n_2022-10-25_\n\nThis release of Docker Engine contains updated versions of Docker Compose, Docker Scan, containerd, added packages for Ubuntu 22.10, and some minor bug fixes and enhancements.\n\n### [New](#new)\n\n*   Provide packages for Ubuntu 22.10 (Kinetic Kudu).\n*   Add support for `allow-nondistributable-artifacts` towards Docker Hub [moby/moby#44313](https://github.com/moby/moby/pull/44313).\n\n### [Updates](#updates-3)\n\n*   Update Docker Compose to [v2.12.2](https://github.com/docker/compose/releases/tag/v2.12.2).\n*   Update Docker Scan to [v0.21.0](https://github.com/docker/scan-cli-plugin/releases/tag/v0.21.0).\n*   Update containerd (`containerd.io` package) to [v1.6.9](https://github.com/containerd/containerd/releases/tag/v1.6.9).\n*   Update bundled BuildKit version to fix `output clipped, log limit 1MiB reached` errors [moby/moby#44339](https://github.com/moby/moby/pull/44339).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-3)\n\n*   Remove experimental gate for `--platform` in bash completion [docker/cli#3824](https://github.com/docker/cli/pull/3824).\n*   Fix an `Invalid standard handle identifier` panic when registering the Docker Engine as a service from a legacy CLI on Windows [moby/moby#44326](https://github.com/moby/moby/pull/44326).\n*   Fix running Git commands in Cygwin on Windows [moby/moby#44332](https://github.com/moby/moby/pull/44332).\n\n_2022-10-18_\n\nThis release of Docker Engine contains partial mitigations for a Git vulnerability ( [CVE-2022-39253](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-39253)), and has updated handling of `image:tag@digest` image references.\n\nThe Git vulnerability allows a maliciously crafted Git repository, when used as a build context, to copy arbitrary filesystem paths into resulting containers/images; this can occur in both the daemon, and in API clients, depending on the versions and tools in use.\n\nThe mitigations available in this release and in other consumers of the daemon API are partial and only protect users who build a Git URL context (e.g. `git+protocol://`). As the vulnerability could still be exploited by manually run Git commands that interact with and check out submodules, users should immediately upgrade to a patched version of Git to protect against this vulnerability. Further details are available from the GitHub blog ( [\"Git security vulnerabilities announced\"](https://github.blog/2022-10-18-git-security-vulnerabilities-announced/)).\n\n### [Updates](#updates-4)\n\n*   Update Docker Compose to [v2.12.0](https://github.com/docker/compose/releases/tag/v2.12.0).\n*   Updated handling of `image:tag@digest` references. When pulling an image using the `image:tag@digest` (\"pull by digest\"), image resolution happens through the content-addressable digest and the `image` and `tag` are not used. While this is expected, this could lead to confusing behavior, and could potentially be exploited through social engineering to run an image that is already present in the local image store. Docker now checks if the digest matches the repository name used to pull the image, and otherwise will produce an error.\n*   Updated handling of `image:tag@digest` references. Refer to the \"Daemon\" section above for details.\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-4)\n\n*   Added a mitigation for [CVE-2022-39253](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-39253), when using the classic Builder with a Git URL as the build context.\n*   Added a mitigation to the classic Builder and updated BuildKit to [v0.8.3-31-gc0149372](https://github.com/moby/buildkit/commit/c014937225cba29cfb1d5161fd134316c0e9bdaa), for [CVE-2022-39253](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-39253).\n\n_2022-10-14_\n\nThis release of Docker Engine comes with some bug-fixes, and an updated version of Docker Compose.\n\n### [Updates](#updates-5)\n\n*   Update Docker Compose to [v2.11.2](https://github.com/docker/compose/releases/tag/v2.11.2).\n*   Update Go runtime to [1.18.7](https://go.dev/doc/devel/release#go1.18.minor), which contains fixes for [CVE-2022-2879](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-2879), [CVE-2022-2880](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-2880), and [CVE-2022-41715](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41715).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-5)\n\n*   Fix an issue that could result in a panic during `docker builder prune` or `docker system prune` [moby/moby#44122](https://github.com/moby/moby/pull/44122).\n*   Fix a bug where using `docker volume prune` would remove volumes that were still in use if the daemon was running with \"live restore\" and was restarted [moby/moby#44238](https://github.com/moby/moby/pull/44238).\n\n_2022-09-09_\n\nThis release of Docker Engine comes with a fix for a low-severity security issue, some minor bug fixes, and updated versions of Docker Compose, Docker Buildx, `containerd`, and `runc`.\n\n### [Updates](#updates-6)\n\n*   Update Docker Buildx to [v0.9.1](https://github.com/docker/buildx/releases/tag/v0.9.1).\n*   Update Docker Compose to [v2.10.2](https://github.com/docker/compose/releases/tag/v2.10.2).\n*   Update containerd (`containerd.io` package) to [v1.6.8](https://github.com/containerd/containerd/releases/tag/v1.6.8).\n*   Update runc version to [v1.1.4](https://github.com/opencontainers/runc/releases/tag/v1.1.4).\n*   Update Go runtime to [1.18.6](https://go.dev/doc/devel/release#go1.18.minor), which contains fixes for [CVE-2022-27664](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-27664) and [CVE-2022-32190](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-32190).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-6)\n\n*   Add Bash completion for Docker Compose [docker/cli#3752](https://github.com/docker/cli/pull/3752).\n*   Fix an issue where file-capabilities were not preserved during build [moby/moby#43876](https://github.com/moby/moby/pull/43876).\n*   Fix an issue that could result in a panic caused by a concurrent map read and map write [moby/moby#44067](https://github.com/moby/moby/pull/44067).\n*   Fix a security vulnerability relating to supplementary group permissions, which could allow a container process to bypass primary group restrictions within the container [CVE-2022-36109](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36109), [GHSA-rc4r-wh2q-q6c4](https://github.com/moby/moby/security/advisories/GHSA-rc4r-wh2q-q6c4).\n*   seccomp: add support for Landlock syscalls in default policy [moby/moby#43991](https://github.com/moby/moby/pull/43991).\n*   seccomp: update default policy to support new syscalls introduced in kernel 5.12 - 5.16 [moby/moby#43991](https://github.com/moby/moby/pull/43991).\n*   Fix an issue where cache lookup for image manifests would fail, resulting in a redundant round-trip to the image registry [moby/moby#44109](https://github.com/moby/moby/pull/44109).\n*   Fix an issue where `exec` processes and healthchecks were not terminated when they timed out [moby/moby#44018](https://github.com/moby/moby/pull/44018).\n\n_2022-06-06_\n\nThis release of Docker Engine comes with updated versions of Docker Compose and the `containerd`, and `runc` components, as well as some minor bug fixes.\n\n### [Updates](#updates-7)\n\n*   Update Docker Compose to [v2.6.0](https://github.com/docker/compose/releases/tag/v2.6.0).\n*   Update containerd (`containerd.io` package) to [v1.6.6](https://github.com/containerd/containerd/releases/tag/v1.6.6), which contains a fix for [CVE-2022-31030](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-31030)\n*   Update runc version to [v1.1.2](https://github.com/opencontainers/runc/releases/tag/v1.1.2), which contains a fix for [CVE-2022-29162](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29162).\n*   Update Go runtime to [1.17.11](https://go.dev/doc/devel/release#go1.17.minor), which contains fixes for [CVE-2022-30634](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-30634), [CVE-2022-30629](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-30629), [CVE-2022-30580](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-30580) and [CVE-2022-29804](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29804)\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-7)\n\n*   Remove asterisk from docker commands in zsh completion script [docker/cli#3648](https://github.com/docker/cli/pull/3648).\n*   Fix Windows port conflict with published ports in host mode for overlay [moby/moby#43644](https://github.com/moby/moby/pull/43644).\n*   Ensure performance tuning is always applied to libnetwork sandboxes [moby/moby#43683](https://github.com/moby/moby/pull/43683).\n\n_2022-05-12_\n\nThis release of Docker Engine fixes a regression in the Docker CLI builds for macOS, fixes an issue with `docker stats` when using containerd 1.5 and up, and updates the Go runtime to include a fix for [CVE-2022-29526](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29526).\n\n### [Updates](#updates-8)\n\n*   Update golang.org/x/sys dependency which contains a fix for [CVE-2022-29526](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29526).\n*   Updated the `golang.org/x/sys` build-time dependency which contains a fix for [CVE-2022-29526](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29526).\n*   Updated Go runtime to [1.17.10](https://go.dev/doc/devel/release#go1.17.minor), which contains a fix for [CVE-2022-29526](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29526).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-8)\n\n*   Fixed a regression in binaries for macOS introduced in [20.10.15](#201015), which resulted in a panic [docker/cli#43426](https://github.com/docker/cli/pull/3592).\n*   Fixed an issue where `docker stats` was showing empty stats when running with containerd 1.5.0 or up [moby/moby#43567](https://github.com/moby/moby/pull/43567).\n*   Used \"weak\" dependencies for the `docker scan` CLI plugin, to prevent a \"conflicting requests\" error when users performed an off-line installation from downloaded RPM packages [docker/docker-ce-packaging#659](https://github.com/docker/docker-ce-packaging/pull/659).\n\n_2022-05-05_\n\nThis release of Docker Engine comes with updated versions of the `compose`, `buildx`, `containerd`, and `runc` components, as well as some minor bug fixes.\n\n### [Updates](#updates-9)\n\n*   Update Docker Compose to [v2.5.0](https://github.com/docker/compose/releases/tag/v2.5.0).\n*   Update Docker Buildx to [v0.8.2](https://github.com/docker/buildx/releases/tag/v0.8.2).\n*   Update Go runtime to [1.17.9](https://go.dev/doc/devel/release#go1.17.minor).\n*   Update containerd (`containerd.io` package) to [v1.6.4](https://github.com/containerd/containerd/releases/tag/v1.6.4).\n*   Update runc version to [v1.1.1](https://github.com/opencontainers/runc/releases/tag/v1.1.1).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-9)\n\n*   Use a RWMutex for stateCounter to prevent potential locking congestion [moby/moby#43426](https://github.com/moby/moby/pull/43426).\n*   Prevent an issue where the daemon was unable to find an available IP-range in some conditions [moby/moby#43360](https://github.com/moby/moby/pull/43360)\n*   Add packages for CentOS 9 stream and Fedora 36.\n\n### [Known issues](#known-issues)\n\n*   We've identified an issue with the [macOS CLI binaries](https://download.docker.com/mac/static/stable/) in the 20.10.15 release. This issue has been resolved in the [20.10.16](#201016) release.\n\n_2022-03-23_\n\nThis release of Docker Engine updates the default inheritable capabilities for containers to address [CVE-2022-24769](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-24769), a new version of the `containerd.io` runtime is also included to address the same issue.\n\n### [Updates](#updates-10)\n\n*   Update the default inheritable capabilities.\n*   Update the default inheritable capabilities for containers used during build.\n*   Update containerd (`containerd.io` package) to [v1.5.11](https://github.com/containerd/containerd/releases/tag/v1.5.11).\n*   Update `docker buildx` to [v0.8.1](https://github.com/docker/buildx/releases/tag/v0.8.1).\n\n_2022-03-10_\n\nThis release of Docker Engine contains some bug-fixes and packaging changes, updates to the `docker scan` and `docker buildx` commands, an updated version of the Go runtime, and new versions of the `containerd.io` runtime. Together with this release, we now also provide `.deb` and `.rpm` packages of Docker Compose V2, which can be installed using the (optional) `docker-compose-plugin` package.\n\n### [New](#new-1)\n\n*   Provide `.deb` and `.rpm` packages for Docker Compose V2. [Docker Compose v2.3.3](https://github.com/docker/compose/releases/tag/v2.3.3) can now be installed on Linux using the `docker-compose-plugin` packages, which provides the `docker compose` subcommand on the Docker CLI. The Docker Compose plugin can also be installed and run standalone to be used as a drop-in replacement for `docker-compose` (Docker Compose V1) [docker/docker-ce-packaging#638](https://github.com/docker/docker-ce-packaging/pull/638). The `compose-cli-plugin` package can also be used on older version of the Docker CLI with support for CLI plugins (Docker CLI 18.09 and up).\n*   Provide packages for the upcoming Ubuntu 22.04 \"Jammy Jellyfish\" LTS release [docker/docker-ce-packaging#645](https://github.com/docker/docker-ce-packaging/pull/645), [docker/containerd-packaging#271](https://github.com/docker/containerd-packaging/pull/271).\n\n### [Updates](#updates-11)\n\n*   Updated the bundled version of buildx to [v0.8.0](https://github.com/docker/buildx/releases/tag/v0.8.0).\n*   Update `docker buildx` to [v0.8.0](https://github.com/docker/buildx/releases/tag/v0.8.0).\n*   Update `docker scan` (`docker-scan-plugin`) to [v0.17.0](https://github.com/docker/scan-cli-plugin/releases/tag/v0.17.0).\n*   Update containerd (`containerd.io` package) to [v1.5.10](https://github.com/containerd/containerd/releases/tag/v1.5.10).\n*   Update the bundled runc version to [v1.0.3](https://github.com/opencontainers/runc/releases/tag/v1.0.3).\n*   Update Golang runtime to Go 1.16.15.\n*   Updates the fluentd log driver to prevent a potential daemon crash, and prevent containers from hanging when using the `fluentd-async-connect=true` and the remote server is unreachable [moby/moby#43147](https://github.com/moby/moby/pull/43147).\n\n### [Bug fixes and enhancements](#bug-fixes-and-enhancements-10)\n\n*   Fix a race condition when updating the container's state [moby/moby#43166](https://github.com/moby/moby/pull/43166).\n*   Update the etcd dependency to prevent the daemon from incorrectly holding file locks [moby/moby#43259](https://github.com/moby/moby/pull/43259)\n*   Fix detection of user-namespaces when configuring the default `net.ipv4.ping_group_range` sysctl [moby/moby#43084](https://github.com/moby/moby/pull/43084).\n*   Retry downloading image-manifests if a connection failure happens during image pull [moby/moby#43333](https://github.com/moby/moby/pull/43333).\n*   Various fixes in command-line reference and API documentation.\n*   Prevent an OOM when using the \"local\" logging driver with containers that produce a large amount of log messages [moby/moby#43165](https://github.com/moby/moby/pull/43165).\n\n2021-12-13\n\nThis release of Docker Engine contains changes in packaging only, and provides updates to the `docker scan` and `docker buildx` commands. Versions of `docker scan` before v0.11.0 are not able to detect the [Log4j 2 CVE-2021-44228](https://nvd.nist.gov/vuln/detail/CVE-2021-44228). We are shipping an updated version of `docker scan` in this release to help you scan your images for this vulnerability.\n\n> **Note**\n> \n> The `docker scan` command on Linux is currently only supported on x86 platforms. We do not yet provide a package for other hardware architectures on Linux.\n\nThe `docker scan` feature is provided as a separate package and, depending on your upgrade or installation method, 'docker scan' may not be updated automatically to the latest version. Use the instructions below to update `docker scan` to the latest version. You can also use these instructions to install, or upgrade the `docker scan` package without upgrading the Docker Engine:\n\nOn `.deb` based distros, such as Ubuntu and Debian:\n\nOn rpm-based distros, such as CentOS or Fedora:\n\nAfter upgrading, verify you have the latest version of `docker scan` installed:\n\n[Read our blog post on CVE-2021-44228](https://www.docker.com/blog/apache-log4j-2-cve-2021-44228/) to learn how to use the `docker scan` command to check if images are vulnerable.\n\n### [Packaging](#packaging)\n\n*   Update `docker scan` to [v0.12.0](https://github.com/docker/scan-cli-plugin/releases/tag/v0.12.0).\n*   Update `docker buildx` to [v0.7.1](https://github.com/docker/buildx/releases/tag/v0.7.1).\n*   Update Golang runtime to Go 1.16.12.\n\n2021-11-17\n\n> **IMPORTANT**\n> \n> Due to [net/http changes](https://github.com/golang/go/issues/40909) in [Go 1.16](https://golang.org/doc/go1.16#net/http), HTTP proxies configured through the `$HTTP_PROXY` environment variable are no longer used for TLS (`https://`) connections. Make sure you also set an `$HTTPS_PROXY` environment variable for handling requests to `https://` URLs.\n> \n> Refer to [Configure the daemon to use a proxy](https://docs.docker.com/config/daemon/proxy/) to learn how to configure the Docker Daemon to use a proxy server.\n\n### [Distribution](#distribution)\n\n*   Handle ambiguous OCI manifest parsing to mitigate [CVE-2021-41190](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41190) / [GHSA-mc8v-mgrf-8f4m](https://github.com/opencontainers/distribution-spec/security/advisories/GHSA-mc8v-mgrf-8f4m). See [GHSA-xmmx-7jpf-fx42](https://github.com/moby/moby/security/advisories/GHSA-xmmx-7jpf-fx42) for details.\n\n### [Windows](#windows)\n\n*   Fix panic.log file having read-only attribute set [moby/moby#42987](https://github.com/moby/moby/pull/42987).\n\n### [Packaging](#packaging-1)\n\n*   Update containerd to [v1.4.12](https://github.com/containerd/containerd/releases/tag/v1.4.12) to mitigate [CVE-2021-41190](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41190).\n*   Update Golang runtime to Go 1.16.10.\n\n2021-10-25\n\n> **IMPORTANT**\n> \n> Due to [net/http changes](https://github.com/golang/go/issues/40909) in [Go 1.16](https://golang.org/doc/go1.16#net/http), HTTP proxies configured through the `$HTTP_PROXY` environment variable are no longer used for TLS (`https://`) connections. Make sure you also set an `$HTTPS_PROXY` environment variable for handling requests to `https://` URLs.\n> \n> Refer to the [HTTP/HTTPS proxy section](https://docs.docker.com/config/daemon/proxy/#httphttps-proxy) to learn how to configure the Docker Daemon to use a proxy server.\n\n### [Builder](#builder)\n\n*   Fix platform-matching logic to fix `docker build` using not finding images in the local image cache on Arm machines when using BuildKit [moby/moby#42954](https://github.com/moby/moby/pull/42954)\n\n### [Runtime](#runtime)\n\n*   Add support for `clone3` syscall in the default seccomp policy to support running containers based on recent versions of Fedora and Ubuntu. [moby/moby/#42836](https://github.com/moby/moby/pull/42836).\n*   Windows: update hcsshim library to fix a bug in sparse file handling in container layers, which was exposed by recent changes in Windows [moby/moby#42944](https://github.com/moby/moby/pull/42944).\n*   Fix some situations where `docker stop` could hang forever [moby/moby#42956](https://github.com/moby/moby/pull/42956).\n\n### [Swarm](#swarm)\n\n*   Fix an issue where updating a service did not roll back on failure [moby/moby#42875](https://github.com/moby/moby/pull/42875).\n\n### [Packaging](#packaging-2)\n\n*   Add packages for Ubuntu 21.10 \"Impish Indri\" and Fedora 35.\n*   Update `docker scan` to v0.9.0\n*   Update Golang runtime to Go 1.16.9.\n\n2021-10-04\n\nThis release is a security release with security fixes in the CLI, runtime, as well as updated versions of the containerd.io package.\n\n> **IMPORTANT**\n> \n> Due to [net/http changes](https://github.com/golang/go/issues/40909) in [Go 1.16](https://golang.org/doc/go1.16#net/http), HTTP proxies configured through the `$HTTP_PROXY` environment variable are no longer used for TLS (`https://`) connections. Make sure you also set an `$HTTPS_PROXY` environment variable for handling requests to `https://` URLs.\n> \n> Refer to the [HTTP/HTTPS proxy section](https://docs.docker.com/config/daemon/proxy/#httphttps-proxy) to learn how to configure the Docker Daemon to use a proxy server.\n\n### [Client](#client)\n\n*   [CVE-2021-41092](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41092) Ensure default auth config has address field set, to prevent credentials being sent to the default registry.\n\n### [Runtime](#runtime-1)\n\n*   [CVE-2021-41089](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41089) Create parent directories inside a chroot during `docker cp` to prevent a specially crafted container from changing permissions of existing files in the host’s filesystem.\n*   [CVE-2021-41091](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41091) Lock down file permissions to prevent unprivileged users from discovering and executing programs in `/var/lib/docker`.\n\n### [Packaging](#packaging-3)\n\n> **Known issue**\n> \n> The `ctr` binary shipping with the static packages of this release is not statically linked, and will not run in Docker images using alpine as a base image. Users can install the `libc6-compat` package, or download a previous version of the `ctr` binary as a workaround. Refer to the containerd ticket related to this issue for more details: [containerd/containerd#5824](https://github.com/containerd/containerd/issues/5824).\n\n*   Update Golang runtime to Go 1.16.8, which contains fixes for [CVE-2021-36221](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-36221) and [CVE-2021-39293](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-39293)\n*   Update static binaries and containerd.io rpm and deb packages to containerd v1.4.11 and runc v1.0.2 to address [CVE-2021-41103](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41103).\n*   Update the bundled buildx version to v0.6.3 for rpm and deb packages.\n\n2021-08-03\n\n> **IMPORTANT**\n> \n> Due to [net/http changes](https://github.com/golang/go/issues/40909) in [Go 1.16](https://golang.org/doc/go1.16#net/http), HTTP proxies configured through the `$HTTP_PROXY` environment variable are no longer used for TLS (`https://`) connections. Make sure you also set an `$HTTPS_PROXY` environment variable for handling requests to `https://` URLs.\n> \n> Refer to the [HTTP/HTTPS proxy section](https://docs.docker.com/config/daemon/proxy/#httphttps-proxy) to learn how to configure the Docker Daemon to use a proxy server.\n\n### [Deprecation](#deprecation)\n\n*   Deprecate support for encrypted TLS private keys. Legacy PEM encryption as specified in RFC 1423 is insecure by design. Because it does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext. Support for encrypted TLS private keys is now marked as deprecated, and will be removed in an upcoming release. [docker/cli#3219](https://github.com/docker/cli/pull/3219)\n*   Deprecate Kubernetes stack support. Following the deprecation of [Compose on Kubernetes](https://github.com/docker/compose-on-kubernetes), support for Kubernetes in the `stack` and `context` commands in the Docker CLI is now marked as deprecated, and will be removed in an upcoming release [docker/cli#3174](https://github.com/docker/cli/pull/3174).\n\n### [Client](#client-1)\n\n*   Fix `Invalid standard handle identifier` errors on Windows [docker/cli#3132](https://github.com/docker/cli/pull/3132).\n\n### [Rootless](#rootless)\n\n*   Avoid `can't open lock file /run/xtables.lock: Permission denied` error on SELinux hosts [moby/moby#42462](https://github.com/moby/moby/pull/42462).\n*   Disable overlay2 when running with SELinux to prevent permission denied errors [moby/moby#42462](https://github.com/moby/moby/pull/42462).\n*   Fix `x509: certificate signed by unknown authority` error on openSUSE Tumbleweed [moby/moby#42462](https://github.com/moby/moby/pull/42462).\n\n### [Runtime](#runtime-2)\n\n*   Print a warning when using the `--platform` option to pull a single-arch image that does not match the specified architecture [moby/moby#42633](https://github.com/moby/moby/pull/42633).\n*   Fix incorrect `Your kernel does not support swap memory limit` warning when running with cgroups v2 [moby/moby#42479](https://github.com/moby/moby/pull/42479).\n*   Windows: Fix a situation where containers were not stopped if `HcsShutdownComputeSystem` returned an `ERROR_PROC_NOT_FOUND` error [moby/moby#42613](https://github.com/moby/moby/pull/42613)\n\n### [Swarm](#swarm-1)\n\n*   Fix a possibility where overlapping IP addresses could exist as a result of the node failing to clean up its old loadbalancer IPs [moby/moby#42538](https://github.com/moby/moby/pull/42538)\n*   Fix a deadlock in log broker (\"dispatcher is stopped\") [moby/moby#42537](https://github.com/moby/moby/pull/42537)\n\n### [Packaging](#packaging-4)\n\n> **Known issue**\n> \n> The `ctr` binary shipping with the static packages of this release is not statically linked, and will not run in Docker images using alpine as a base image. Users can install the `libc6-compat` package, or download a previous version of the `ctr` binary as a workaround. Refer to the containerd ticket related to this issue for more details: [containerd/containerd#5824](https://github.com/containerd/containerd/issues/5824).\n\n*   Remove packaging for Ubuntu 16.04 \"Xenial\" and Fedora 32, as they reached EOL [docker/docker-ce-packaging#560](https://github.com/docker/docker-ce-packaging/pull/560)\n*   Update Golang runtime to Go 1.16.6\n*   Update the bundled buildx version to v0.6.1 for rpm and deb packages [docker/docker-ce-packaging#562](https://github.com/docker/docker-ce-packaging/pull/562)\n*   Update static binaries and containerd.io rpm and deb packages to containerd v1.4.9 and runc v1.0.1: [docker/containerd-packaging#241](https://github.com/docker/containerd-packaging/pull/241), [docker/containerd-packaging#245](https://github.com/docker/containerd-packaging/pull/245), [docker/containerd-packaging#247](https://github.com/docker/containerd-packaging/pull/247).\n\n2021-06-02\n\n### [Client](#client-2)\n\n*   Suppress warnings for deprecated cgroups [docker/cli#3099](https://github.com/docker/cli/pull/3099).\n*   Prevent sending `SIGURG` signals to container on Linux and macOS. The Go runtime (starting with Go 1.14) uses `SIGURG` signals internally as an interrupt to support preemptable syscalls. In situations where the Docker CLI was attached to a container, these interrupts were forwarded to the container. This fix changes the Docker CLI to ignore `SIGURG` signals [docker/cli#3107](https://github.com/docker/cli/pull/3107), [moby/moby#42421](https://github.com/moby/moby/pull/42421).\n\n### [Builder](#builder-1)\n\n*   Update BuildKit to version v0.8.3-3-g244e8cde [moby/moby#42448](https://github.com/moby/moby/pull/42448):\n    *   Transform relative mountpoints for exec mounts in the executor to work around a breaking change in runc v1.0.0-rc94 and up. [moby/buildkit#2137](https://github.com/moby/buildkit/pull/2137).\n    *   Add retry on image push 5xx errors. [moby/buildkit#2043](https://github.com/moby/buildkit/pull/2043).\n    *   Fix build-cache not being invalidated when renaming a file that is copied using a `COPY` command with a wildcard. Note that this change invalidates existing build caches for copy commands that use a wildcard. [moby/buildkit#2018](https://github.com/moby/buildkit/pull/2018).\n    *   Fix build-cache not being invalidated when using mounts [moby/buildkit#2076](https://github.com/moby/buildkit/pull/2076).\n*   Fix build failures when `FROM` image is not cached when using legacy schema 1 images [moby/moby#42382](https://github.com/moby/moby/pull/42382).\n\n### [Logging](#logging)\n\n*   Update the hcsshim SDK to make daemon logs on Windows less verbose [moby/moby#42292](https://github.com/moby/moby/pull/42292).\n\n### [Rootless](#rootless-1)\n\n*   Fix capabilities not being honored when an image was built on a daemon with user-namespaces enabled [moby/moby#42352](https://github.com/moby/moby/pull/42352).\n\n### [Networking](#networking)\n\n*   Update libnetwork to fix publishing ports on environments with kernel boot parameter `ipv6.disable=1`, and to fix a deadlock causing internal DNS lookups to fail [moby/moby#42413](https://github.com/moby/moby/pull/42413).\n\n### [Contrib](#contrib)\n\n*   Update rootlesskit to v0.14.2 to fix a timeout when starting the userland proxy with the `slirp4netns` port driver [moby/moby#42294](https://github.com/moby/moby/pull/42294).\n*   Fix \"Device or resource busy\" errors when running docker-in-docker on a rootless daemon [moby/moby#42342](https://github.com/moby/moby/pull/42342).\n\n### [Packaging](#packaging-5)\n\n*   Update containerd to v1.4.6, runc v1.0.0-rc95 to address [CVE-2021-30465](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-30465) [moby/moby#42398](https://github.com/moby/moby/pull/42398), [moby/moby#42395](https://github.com/moby/moby/pull/42395), [docker/containerd-packaging#234](https://github.com/docker/containerd-packaging/pull/234)\n*   Update containerd to v1.4.5, runc v1.0.0-rc94 [moby/moby#42372](https://github.com/moby/moby/pull/42372), [moby/moby#42388](https://github.com/moby/moby/pull/42388), [docker/containerd-packaging#232](https://github.com/docker/containerd-packaging/pull/232).\n*   Update Docker Scan plugin packages (`docker-scan-plugin`) to v0.8 [docker/docker-ce-packaging#545](https://github.com/docker/docker-ce-packaging/pull/545).\n\n2021-04-12\n\n### [Client](#client-3)\n\n*   Apple Silicon (darwin/arm64) support for Docker CLI [docker/cli#3042](https://github.com/docker/cli/pull/3042)\n*   config: print deprecation warning when falling back to pre-v1.7.0 config file `~/.dockercfg`. Support for this file will be removed in a future release [docker/cli#3000](https://github.com/docker/cli/pull/3000)\n\n### [Builder](#builder-2)\n\n*   Fix classic builder silently ignoring unsupported Dockerfile options and prompt to enable BuildKit instead [moby/moby#42197](https://github.com/moby/moby/pull/42197)\n\n### [Logging](#logging-1)\n\n*   json-file: fix sporadic unexpected EOF errors [moby/moby#42174](https://github.com/moby/moby/pull/42174)\n\n### [Networking](#networking-1)\n\n*   Fix a regression in docker 20.10, causing IPv6 addresses no longer to be bound by default when mapping ports [moby/moby#42205](https://github.com/moby/moby/pull/42205)\n*   Fix implicit IPv6 port-mappings not included in API response. Before docker 20.10, published ports were accessible through both IPv4 and IPv6 by default, but the API only included information about the IPv4 (0.0.0.0) mapping [moby/moby#42205](https://github.com/moby/moby/pull/42205)\n*   Fix a regression in docker 20.10, causing the docker-proxy to not be terminated in all cases [moby/moby#42205](https://github.com/moby/moby/pull/42205)\n*   Fix iptables forwarding rules not being cleaned up upon container removal [moby/moby#42205](https://github.com/moby/moby/pull/42205)\n\n### [Packaging](#packaging-6)\n\n*   Update containerd to [v1.4.4](https://github.com/containerd/containerd/releases/tag/v1.4.4) for static binaries. The containerd.io package on apt/yum repos already had this update out of band. Includes a fix for [CVE-2021-21334](https://github.com/containerd/containerd/security/advisories/GHSA-6g2q-w5j3-fwh4). [moby/moby#42124](https://github.com/moby/moby/pull/42124)\n*   Packages for Debian/Raspbian 11 Bullseye, Ubuntu 21.04 Hirsute Hippo and Fedora 34 [docker/docker-ce-packaging#521](https://github.com/docker/docker-ce-packaging/pull/521) [docker/docker-ce-packaging#522](https://github.com/docker/docker-ce-packaging/pull/522) [docker/docker-ce-packaging#533](https://github.com/docker/docker-ce-packaging/pull/533)\n*   Provide the [Docker Scan CLI](https://github.com/docker/scan-cli-plugin) plugin on Linux amd64 via a `docker-scan-plugin` package as a recommended dependency for the `docker-ce-cli` package [docker/docker-ce-packaging#537](https://github.com/docker/docker-ce-packaging/pull/537)\n*   Include VPNKit binary for arm64 [moby/moby#42141](https://github.com/moby/moby/pull/42141)\n\n### [Plugins](#plugins)\n\n*   Fix docker plugin create making plugins that were incompatible with older versions of Docker [moby/moby#42256](https://github.com/moby/moby/pull/42256)\n\n### [Rootless](#rootless-2)\n\n*   Update RootlessKit to [v0.14.1](https://github.com/rootless-containers/rootlesskit/releases/tag/v0.14.1) (see also [v0.14.0](https://github.com/rootless-containers/rootlesskit/releases/tag/v0.14.0) [v0.13.2](https://github.com/rootless-containers/rootlesskit/releases/tag/v0.13.2)) [moby/moby#42186](https://github.com/moby/moby/pull/42186) [moby/moby#42232](https://github.com/moby/moby/pull/42232)\n*   dockerd-rootless-setuptool.sh: create CLI context \"rootless\" [moby/moby#42109](https://github.com/moby/moby/pull/42109)\n*   dockerd-rootless.sh: prohibit running as root [moby/moby#42072](https://github.com/moby/moby/pull/42072)\n*   Fix \"operation not permitted\" when bind mounting existing mounts [moby/moby#42233](https://github.com/moby/moby/pull/42233)\n*   overlay2: fix \"createDirWithOverlayOpaque(...) ... input/output error\" [moby/moby#42235](https://github.com/moby/moby/pull/42235)\n*   overlay2: support \"userxattr\" option (kernel 5.11) [moby/moby#42168](https://github.com/moby/moby/pull/42168)\n*   btrfs: allow unprivileged user to delete subvolumes (kernel >= 4.18) [moby/moby#42253](https://github.com/moby/moby/pull/42253)\n*   cgroup2: Move cgroup v2 out of experimental [moby/moby#42263](https://github.com/moby/moby/pull/42263)\n\n2021-03-02\n\n### [Client](#client-4)\n\n*   Revert [docker/cli#2960](https://github.com/docker/cli/pull/2960) to fix hanging in `docker start --attach` and remove spurious `Unsupported signal: <nil>. Discarding` messages. [docker/cli#2987](https://github.com/docker/cli/pull/2987).\n\n2021-02-26\n\n### [Builder](#builder-3)\n\n*   Fix incorrect cache match for inline cache import with empty layers [moby/moby#42061](https://github.com/moby/moby/pull/42061)\n*   Update BuildKit to v0.8.2 [moby/moby#42061](https://github.com/moby/moby/pull/42061)\n    *   resolver: avoid error caching on token fetch\n    *   fileop: fix checksum to contain indexes of inputs preventing certain cache misses\n    *   Fix reference count issues on typed errors with mount references (fixing `invalid mutable ref` errors)\n    *   git: set token only for main remote access allowing cloning submodules with different credentials\n*   Ensure blobs get deleted in /var/lib/docker/buildkit/content/blobs/sha256 after pull. To clean up old state run `builder prune` [moby/moby#42065](https://github.com/moby/moby/pull/42065)\n*   Fix parallel pull synchronization regression [moby/moby#42049](https://github.com/moby/moby/pull/42049)\n*   Ensure libnetwork state files do not leak [moby/moby#41972](https://github.com/moby/moby/pull/41972)\n\n### [Client](#client-5)\n\n*   Fix a panic on `docker login` if no config file is present [docker/cli#2959](https://github.com/docker/cli/pull/2959)\n*   Fix `WARNING: Error loading config file: .dockercfg: $HOME is not defined` [docker/cli#2958](https://github.com/docker/cli/pull/2958)\n\n### [Runtime](#runtime-3)\n\n*   docker info: silence unhandleable warnings [moby/moby#41958](https://github.com/moby/moby/pull/41958)\n*   Avoid creating parent directories for XGlobalHeader [moby/moby#42017](https://github.com/moby/moby/pull/42017)\n*   Use 0755 permissions when creating missing directories [moby/moby#42017](https://github.com/moby/moby/pull/42017)\n*   Fallback to manifest list when no platform matches in image config [moby/moby#42045](https://github.com/moby/moby/pull/42045) [moby/moby#41873](https://github.com/moby/moby/pull/41873)\n*   Fix a daemon panic on setups with a custom default runtime configured [moby/moby#41974](https://github.com/moby/moby/pull/41974)\n*   Fix a panic when daemon configuration is empty [moby/moby#41976](https://github.com/moby/moby/pull/41976)\n*   Fix daemon panic when starting container with invalid device cgroup rule [moby/moby#42001](https://github.com/moby/moby/pull/42001)\n*   Fix userns-remap option when username & UID match [moby/moby#42013](https://github.com/moby/moby/pull/42013)\n*   static: update runc binary to v1.0.0-rc93 [moby/moby#42014](https://github.com/moby/moby/pull/42014)\n\n### [Logger](#logger)\n\n*   Honor `labels-regex` config even if `labels` is not set [moby/moby#42046](https://github.com/moby/moby/pull/42046)\n*   Handle long log messages correctly preventing awslogs in non-blocking mode to split events bigger than 16kB [mobymoby#41975](https://github.com/moby/moby/pull/41975)\n\n### [Rootless](#rootless-3)\n\n*   Prevent the service hanging when stopping by setting systemd KillMode to mixed [moby/moby#41956](https://github.com/moby/moby/pull/41956)\n*   dockerd-rootless.sh: add typo guard [moby/moby#42070](https://github.com/moby/moby/pull/42070)\n*   Update rootlesskit to v0.13.1 to fix handling of IPv6 addresses [moby/moby#42025](https://github.com/moby/moby/pull/42025)\n*   allow mknodding FIFO inside userns [moby/moby#41957](https://github.com/moby/moby/pull/41957)\n\n### [Security](#security)\n\n*   profiles: seccomp: update to Linux 5.11 syscall list [moby/moby#41971](https://github.com/moby/moby/pull/41971)\n\n### [Swarm](#swarm-2)\n\n*   Fix issue with heartbeat not persisting upon restart [moby/moby#42060](https://github.com/moby/moby/pull/42060)\n*   Fix potential stalled tasks [moby/moby#42060](https://github.com/moby/moby/pull/42060)\n*   Fix `--update-order` and `--rollback-order` flags when only `--update-order` or `--rollback-order` is provided [docker/cli#2963](https://github.com/docker/cli/pull/2963)\n*   Fix `docker service rollback` returning a non-zero exit code in some situations [docker/cli#2964](https://github.com/docker/cli/pull/2964)\n*   Fix inconsistent progress-bar direction on `docker service rollback` [docker/cli#2964](https://github.com/docker/cli/pull/2964)\n\n2021-02-01\n\n### [Security](#security-1)\n\n*   [CVE-2021-21285](https://github.com/moby/moby/security/advisories/GHSA-6fj5-m822-rqx8) Prevent an invalid image from crashing docker daemon\n*   [CVE-2021-21284](https://github.com/moby/moby/security/advisories/GHSA-7452-xqpj-6rpc) Lock down file permissions to prevent remapped root from accessing docker state\n*   Ensure AppArmor and SELinux profiles are applied when building with BuildKit\n\n### [Client](#client-6)\n\n*   Check contexts before importing them to reduce risk of extracted files escaping context store\n*   Windows: prevent executing certain binaries from current directory [docker/cli#2950](https://github.com/docker/cli/pull/2950)\n\n2021-01-04\n\n### [Runtime](#runtime-4)\n\n*   Fix a daemon start up hang when restoring containers with restart policies but that keep failing to start [moby/moby#41729](https://github.com/moby/moby/pull/41729)\n*   overlay2: fix an off-by-one error preventing to build or run containers when data-root is 24-bytes long [moby/moby#41830](https://github.com/moby/moby/pull/41830)\n*   systemd: send `sd_notify STOPPING=1` when shutting down [moby/moby#41832](https://github.com/moby/moby/pull/41832)\n\n### [Networking](#networking-2)\n\n*   Fix IPv6 port forwarding [moby/moby#41805](https://github.com/moby/moby/pull/41805) [moby/libnetwork#2604](https://github.com/moby/libnetwork/pull/2604)\n\n### [Swarm](#swarm-3)\n\n*   Fix filtering for `replicated-job` and `global-job` service modes [moby/moby#41806](https://github.com/moby/moby/pull/41806)\n\n### [Packaging](#packaging-7)\n\n*   buildx updated to [v0.5.1](https://github.com/docker/buildx/releases/tag/v0.5.1) [docker/docker-ce-packaging#516](https://github.com/docker/docker-ce-packaging/pull/516)\n\n2020-12-14\n\n### [Builder](#builder-4)\n\n*   buildkit: updated to [v0.8.1](https://github.com/moby/buildkit/releases/tag/v0.8.1) with various bugfixes [moby/moby#41793](https://github.com/moby/moby/pull/41793)\n\n### [Packaging](#packaging-8)\n\n*   Revert a change in the systemd unit that could prevent docker from starting due to a startup order conflict [docker/docker-ce-packaging#514](https://github.com/docker/docker-ce-packaging/pull/514)\n*   buildx updated to [v0.5.0](https://github.com/docker/buildx/releases/tag/v0.5.0) [docker/docker-ce-packaging#515](https://github.com/docker/docker-ce-packaging/pull/515)\n\n2020-12-08\n\n### [Deprecation / Removal](#deprecation--removal)\n\nFor an overview of all deprecated features, refer to the [Deprecated Engine Features](https://docs.docker.com/engine/deprecated/) page.\n\n*   Warnings and deprecation notice when `docker pull`\\-ing from non-compliant registries not supporting pull-by-digest [docker/cli#2872](https://github.com/docker/cli/pull/2872)\n*   Sterner warnings and deprecation notice for unauthenticated tcp access [moby/moby#41285](https://github.com/moby/moby/pull/41285)\n*   Deprecate KernelMemory (`docker run --kernel-memory`) [moby/moby#41254](https://github.com/moby/moby/pull/41254) [docker/cli#2652](https://github.com/docker/cli/pull/2652)\n*   Deprecate `aufs` storage driver [docker/cli#1484](https://github.com/docker/cli/pull/1484)\n*   Deprecate host-discovery and overlay networks with external k/v stores [moby/moby#40614](https://github.com/moby/moby/pull/40614) [moby/moby#40510](https://github.com/moby/moby/pull/40510)\n*   Deprecate Dockerfile legacy 'ENV name value' syntax, use `ENV name=value` instead [docker/cli#2743](https://github.com/docker/cli/pull/2743)\n*   Remove deprecated \"filter\" parameter for API v1.41 and up [moby/moby#40491](https://github.com/moby/moby/pull/40491)\n*   Disable distribution manifest v2 schema 1 on push [moby/moby#41295](https://github.com/moby/moby/pull/41295)\n*   Remove hack MalformedHostHeaderOverride breaking old docker clients (<= 1.12) in which case, set `DOCKER_API_VERSION` [moby/moby#39076](https://github.com/moby/moby/pull/39076)\n*   Remove \"docker engine\" subcommands [docker/cli#2207](https://github.com/docker/cli/pull/2207)\n*   Remove experimental \"deploy\" from \"dab\" files [docker/cli#2216](https://github.com/docker/cli/pull/2216)\n*   Remove deprecated `docker search --automated` and `--stars` flags [docker/cli#2338](https://github.com/docker/cli/pull/2338)\n*   No longer allow reserved namespaces in engine labels [docker/cli#2326](https://github.com/docker/cli/pull/2326)\n\n### [API](#api)\n\n*   Update API version to v1.41\n*   Do not require \"experimental\" for metrics API [moby/moby#40427](https://github.com/moby/moby/pull/40427)\n*   `GET /events` now returns `prune` events after pruning resources have completed [moby/moby#41259](https://github.com/moby/moby/pull/41259)\n    *   Prune events are returned for `container`, `network`, `volume`, `image`, and `builder`, and have a `reclaimed` attribute, indicating the amount of space reclaimed (in bytes)\n*   Add `one-shot` stats option to not prime the stats [moby/moby#40478](https://github.com/moby/moby/pull/40478)\n*   Adding OS version info to the system info's API (`/info`) [moby/moby#38349](https://github.com/moby/moby/pull/38349)\n*   Add DefaultAddressPools to docker info [moby/moby#40714](https://github.com/moby/moby/pull/40714)\n*   Add API support for PidsLimit on services [moby/moby#39882](https://github.com/moby/moby/pull/39882)\n\n### [Builder](#builder-5)\n\n*   buildkit,dockerfile: Support for `RUN --mount` options without needing to specify experimental dockerfile `#syntax` directive. [moby/buildkit#1717](https://github.com/moby/buildkit/pull/1717)\n*   dockerfile: `ARG` command now supports defining multiple build args on the same line similarly to `ENV` [moby/buildkit#1692](https://github.com/moby/buildkit/pull/1692)\n*   dockerfile: `--chown` flag in `ADD` now allows parameter expansion [moby/buildkit#1473](https://github.com/moby/buildkit/pull/1473)\n*   buildkit: Fetching authorization tokens has been moved to client-side (if the client supports it). Passwords do not leak into the build daemon anymore and users can see from build output when credentials or tokens are accessed. [moby/buildkit#1660](https://github.com/moby/buildkit/pull/1660)\n*   buildkit: Connection errors while communicating with the registry for push and pull now trigger a retry [moby/buildkit#1791](https://github.com/moby/buildkit/pull/1791)\n*   buildkit: Git source now supports token authentication via build secrets [moby/moby#41234](https://github.com/moby/moby/pull/41234) [docker/cli#2656](https://github.com/docker/cli/pull/2656) [moby/buildkit#1533](https://github.com/moby/buildkit/pull/1533)\n*   buildkit: Building from git source now supports forwarding SSH socket for authentication [moby/buildkit#1782](https://github.com/moby/buildkit/pull/1782)\n*   buildkit: Avoid builds that generate excessive logs to cause a crash or slow down the build. Clipping is performed if needed. [moby/buildkit#1754](https://github.com/moby/buildkit/pull/1754)\n*   buildkit: Change default Seccomp profile to the one provided by Docker [moby/buildkit#1807](https://github.com/moby/buildkit/pull/1807)\n*   buildkit: Support for exposing SSH agent socket on Windows has been improved [moby/buildkit#1695](https://github.com/moby/buildkit/pull/1695)\n*   buildkit: Disable truncating by default when using --progress=plain [moby/buildkit#1435](https://github.com/moby/buildkit/pull/1435)\n*   buildkit: Allow better handling client sessions dropping while it is being shared by multiple builds [moby/buildkit#1551](https://github.com/moby/buildkit/pull/1551)\n*   buildkit: secrets: allow providing secrets with env [moby/moby#41234](https://github.com/moby/moby/pull/41234) [docker/cli#2656](https://github.com/docker/cli/pull/2656) [moby/buildkit#1534](https://github.com/moby/buildkit/pull/1534)\n    *   Support `--secret id=foo,env=MY_ENV` as an alternative for storing a secret value to a file.\n    *   `--secret id=GIT_AUTH_TOKEN` will load env if it exists and the file does not.\n*   buildkit: Support for mirrors fallbacks, insecure TLS and custom TLS config [moby/moby#40814](https://github.com/moby/moby/pull/40814)\n*   buildkit: remotecache: Only visit each item once when walking results [moby/moby#41234](https://github.com/moby/moby/pull/41234) [moby/buildkit#1577](https://github.com/moby/buildkit/pull/1577)\n    *   Improves performance and CPU use on bigger graphs\n*   buildkit: Check remote when local image platform doesn't match [moby/moby#40629](https://github.com/moby/moby/pull/40629)\n*   buildkit: image export: Use correct media type when creating new layer blobs [moby/moby#41234](https://github.com/moby/moby/pull/41234) [moby/buildkit#1541](https://github.com/moby/buildkit/pull/1541)\n*   buildkit: progressui: fix logs time formatting [moby/moby#41234](https://github.com/moby/moby/pull/41234) [docker/cli#2656](https://github.com/docker/cli/pull/2656) [moby/buildkit#1549](https://github.com/moby/buildkit/pull/1549)\n*   buildkit: mitigate containerd issue on parallel push [moby/moby#41234](https://github.com/moby/moby/pull/41234) [moby/buildkit#1548](https://github.com/moby/buildkit/pull/1548)\n*   buildkit: inline cache: fix handling of duplicate blobs [moby/moby#41234](https://github.com/moby/moby/pull/41234) [moby/buildkit#1568](https://github.com/moby/buildkit/pull/1568)\n    *   Fixes [https://github.com/moby/buildkit/issues/1388](https://github.com/moby/buildkit/issues/1388) cache-from working unreliably\n    *   Fixes [https://github.com/moby/moby/issues/41219](https://github.com/moby/moby/issues/41219) Image built from cached layers is missing data\n*   Allow ssh:// for remote context URLs [moby/moby#40179](https://github.com/moby/moby/pull/40179)\n*   builder: remove legacy build's session handling (was experimental) [moby/moby#39983](https://github.com/moby/moby/pull/39983)\n\n### [Client](#client-7)\n\n*   Add swarm jobs support to CLI [docker/cli#2262](https://github.com/docker/cli/pull/2262)\n*   Add `-a/--all-tags` to docker push [docker/cli#2220](https://github.com/docker/cli/pull/2220)\n*   Add support for Kubernetes username/password auth [docker/cli#2308](https://github.com/docker/cli/pull/2308)\n*   Add `--pull=missing|always|never` to `run` and `create` commands [docker/cli#1498](https://github.com/docker/cli/pull/1498)\n*   Add `--env-file` flag to `docker exec` for parsing environment variables from a file [docker/cli#2602](https://github.com/docker/cli/pull/2602)\n*   Add shorthand `-n` for `--tail` option [docker/cli#2646](https://github.com/docker/cli/pull/2646)\n*   Add log-driver and options to service inspect \"pretty\" format [docker/cli#1950](https://github.com/docker/cli/pull/1950)\n*   docker run: specify cgroup namespace mode with `--cgroupns` [docker/cli#2024](https://github.com/docker/cli/pull/2024)\n*   `docker manifest rm` command to remove manifest list draft from local storage [docker/cli#2449](https://github.com/docker/cli/pull/2449)\n*   Add \"context\" to \"docker version\" and \"docker info\" [docker/cli#2500](https://github.com/docker/cli/pull/2500)\n*   Propagate platform flag to container create API [docker/cli#2551](https://github.com/docker/cli/pull/2551)\n*   The `docker ps --format` flag now has a `.State` placeholder to print the container's state without additional details about uptime and health check [docker/cli#2000](https://github.com/docker/cli/pull/2000)\n*   Add support for docker-compose schema v3.9 [docker/cli#2073](https://github.com/docker/cli/pull/2073)\n*   Add support for docker push `--quiet` [docker/cli#2197](https://github.com/docker/cli/pull/2197)\n*   Hide flags that are not supported by BuildKit, if BuildKit is enabled [docker/cli#2123](https://github.com/docker/cli/pull/2123)\n*   Update flag description for `docker rm -v` to clarify the option only removes anonymous (unnamed) volumes [docker/cli#2289](https://github.com/docker/cli/pull/2289)\n*   Improve tasks printing for docker services [docker/cli#2341](https://github.com/docker/cli/pull/2341)\n*   docker info: list CLI plugins alphabetically [docker/cli#2236](https://github.com/docker/cli/pull/2236)\n*   Fix order of processing of `--label-add/--label-rm`, `--container-label-add/--container-label-rm`, and `--env-add/--env-rm` flags on `docker service update` to allow replacing existing values [docker/cli#2668](https://github.com/docker/cli/pull/2668)\n*   Fix `docker rm --force` returning a non-zero exit code if one or more containers did not exist [docker/cli#2678](https://github.com/docker/cli/pull/2678)\n*   Improve memory stats display by using `total_inactive_file` instead of `cache` [docker/cli#2415](https://github.com/docker/cli/pull/2415)\n*   Mitigate against YAML files that has excessive aliasing [docker/cli#2117](https://github.com/docker/cli/pull/2117)\n*   Allow using advanced syntax when setting a config or secret with only the source field [docker/cli#2243](https://github.com/docker/cli/pull/2243)\n*   Fix reading config files containing `username` and `password` auth even if `auth` is empty [docker/cli#2122](https://github.com/docker/cli/pull/2122)\n*   docker cp: prevent NPE when failing to stat destination [docker/cli#2221](https://github.com/docker/cli/pull/2221)\n*   config: preserve ownership and permissions on configfile [docker/cli#2228](https://github.com/docker/cli/pull/2228)\n\n### [Logging](#logging-2)\n\n*   Support reading `docker logs` with all logging drivers (best effort) [moby/moby#40543](https://github.com/moby/moby/pull/40543)\n*   Add `splunk-index-acknowledgment` log option to work with Splunk HECs with index acknowledgment enabled [moby/moby#39987](https://github.com/moby/moby/pull/39987)\n*   Add partial metadata to journald logs [moby/moby#41407](https://github.com/moby/moby/pull/41407)\n*   Reduce allocations for logfile reader [moby/moby#40796](https://github.com/moby/moby/pull/40796)\n*   Fluentd: add fluentd-async, fluentd-request-ack, and deprecate fluentd-async-connect [moby/moby#39086](https://github.com/moby/moby/pull/39086)\n\n### [Runtime](#runtime-5)\n\n*   Support cgroup2 [moby/moby#40174](https://github.com/moby/moby/pull/40174) [moby/moby#40657](https://github.com/moby/moby/pull/40657) [moby/moby#40662](https://github.com/moby/moby/pull/40662)\n*   cgroup2: use \"systemd\" cgroup driver by default when available [moby/moby#40846](https://github.com/moby/moby/pull/40846)\n*   new storage driver: fuse-overlayfs [moby/moby#40483](https://github.com/moby/moby/pull/40483)\n*   Update containerd binary to v1.4.3 [moby/moby#41732](https://github.com/moby/moby/pull/41732)\n*   `docker push` now defaults to `latest` tag instead of all tags [moby/moby#40302](https://github.com/moby/moby/pull/40302)\n*   Added ability to change the number of reconnect attempts during connection loss while pulling an image by adding max-download-attempts to the config file [moby/moby#39949](https://github.com/moby/moby/pull/39949)\n*   Add support for containerd v2 shim by using the now default `io.containerd.runc.v2` runtime [moby/moby#41182](https://github.com/moby/moby/pull/41182)\n*   cgroup v1: change the default runtime to io.containerd.runc.v2. Requires containerd v1.3.0 or later. v1.3.5 or later is recommended [moby/moby#41210](https://github.com/moby/moby/pull/41210)\n*   Start containers in their own cgroup namespaces [moby/moby#38377](https://github.com/moby/moby/pull/38377)\n*   Enable DNS Lookups for CIFS Volumes [moby/moby#39250](https://github.com/moby/moby/pull/39250)\n*   Use MemAvailable instead of MemFree to estimate actual available memory [moby/moby#39481](https://github.com/moby/moby/pull/39481)\n*   The `--device` flag in `docker run` will now be honored when the container is started in privileged mode [moby/moby#40291](https://github.com/moby/moby/pull/40291)\n*   Enforce reserved internal labels [moby/moby#40394](https://github.com/moby/moby/pull/40394)\n*   Raise minimum memory limit to 6M, to account for higher memory use by runtimes during container startup [moby/moby#41168](https://github.com/moby/moby/pull/41168)\n*   vendor runc v1.0.0-rc92 [moby/moby#41344](https://github.com/moby/moby/pull/41344) [moby/moby#41317](https://github.com/moby/moby/pull/41317)\n*   info: add warnings about missing blkio cgroup support [moby/moby#41083](https://github.com/moby/moby/pull/41083)\n*   Accept platform spec on container create [moby/moby#40725](https://github.com/moby/moby/pull/40725)\n*   Fix handling of looking up user- and group-names with spaces [moby/moby#41377](https://github.com/moby/moby/pull/41377)\n\n### [Networking](#networking-3)\n\n*   Support host.docker.internal in dockerd on Linux [moby/moby#40007](https://github.com/moby/moby/pull/40007)\n*   Include IPv6 address of linked containers in /etc/hosts [moby/moby#39837](https://github.com/moby/moby/pull/39837)\n*   `--ip6tables` enables IPv6 iptables rules (only if experimental) [moby/moby#41622](https://github.com/moby/moby/pull/41622)\n*   Add alias for hostname if hostname != container name [moby/moby#39204](https://github.com/moby/moby/pull/39204)\n*   Better selection of DNS server (with systemd) [moby/moby#41022](https://github.com/moby/moby/pull/41022)\n*   Add docker interfaces to firewalld docker zone [moby/moby#41189](https://github.com/moby/moby/pull/41189) [moby/libnetwork#2548](https://github.com/moby/libnetwork/pull/2548)\n    *   Fixes DNS issue on CentOS8 [docker/for-linux#957](https://github.com/docker/for-linux/issues/957)\n    *   Fixes Port Forwarding on RHEL 8 with Firewalld running with FirewallBackend=nftables [moby/libnetwork#2496](https://github.com/moby/libnetwork/issues/2496)\n*   Fix an issue reporting 'failed to get network during CreateEndpoint' [moby/moby#41189](https://github.com/moby/moby/pull/41189) [moby/libnetwork#2554](https://github.com/moby/libnetwork/pull/2554)\n*   Log error instead of disabling IPv6 router advertisement failed [moby/moby#41189](https://github.com/moby/moby/pull/41189) [moby/libnetwork#2563](https://github.com/moby/libnetwork/pull/2563)\n*   No longer ignore `--default-address-pool` option in certain cases [moby/moby#40711](https://github.com/moby/moby/pull/40711)\n*   Produce an error with invalid address pool [moby/moby#40808](https://github.com/moby/moby/pull/40808) [moby/libnetwork#2538](https://github.com/moby/libnetwork/pull/2538)\n*   Fix `DOCKER-USER` chain not created when IPTableEnable=false [moby/moby#40808](https://github.com/moby/moby/pull/40808) [moby/libnetwork#2471](https://github.com/moby/libnetwork/pull/2471)\n*   Fix panic on startup in systemd environments [moby/moby#40808](https://github.com/moby/moby/pull/40808) [moby/libnetwork#2544](https://github.com/moby/libnetwork/pull/2544)\n*   Fix issue preventing containers to communicate over macvlan internal network [moby/moby#40596](https://github.com/moby/moby/pull/40596) [moby/libnetwork#2407](https://github.com/moby/libnetwork/pull/2407)\n*   Fix InhibitIPv4 nil panic [moby/moby#40596](https://github.com/moby/moby/pull/40596)\n*   Fix VFP leak in Windows overlay network deletion [moby/moby#40596](https://github.com/moby/moby/pull/40596) [moby/libnetwork#2524](https://github.com/moby/libnetwork/pull/2524)\n\n### [Packaging](#packaging-9)\n\n*   docker.service: Add multi-user.target to After= in unit file [moby/moby#41297](https://github.com/moby/moby/pull/41297)\n*   docker.service: Allow socket activation [moby/moby#37470](https://github.com/moby/moby/pull/37470)\n*   seccomp: Remove dependency in dockerd on libseccomp [moby/moby#41395](https://github.com/moby/moby/pull/41395)\n\n### [Rootless](#rootless-4)\n\n*   rootless: graduate from experimental [moby/moby#40759](https://github.com/moby/moby/pull/40759)\n*   Add dockerd-rootless-setuptool.sh [moby/moby#40950](https://github.com/moby/moby/pull/40950)\n*   Support `--exec-opt native.cgroupdriver=systemd` [moby/moby#40486](https://github.com/moby/moby/pull/40486)\n\n### [Security](#security-2)\n\n*   Fix CVE-2019-14271 loading of nsswitch based config inside chroot under Glibc [moby/moby#39612](https://github.com/moby/moby/pull/39612)\n*   seccomp: Whitelist `clock_adjtime`. `CAP_SYS_TIME` is still required for time adjustment [moby/moby#40929](https://github.com/moby/moby/pull/40929)\n*   seccomp: Add openat2 and faccessat2 to default seccomp profile [moby/moby#41353](https://github.com/moby/moby/pull/41353)\n*   seccomp: allow 'rseq' syscall in default seccomp profile [moby/moby#41158](https://github.com/moby/moby/pull/41158)\n*   seccomp: allow syscall membarrier [moby/moby#40731](https://github.com/moby/moby/pull/40731)\n*   seccomp: whitelist io-uring related system calls [moby/moby#39415](https://github.com/moby/moby/pull/39415)\n*   Add default sysctls to allow ping sockets and privileged ports with no capabilities [moby/moby#41030](https://github.com/moby/moby/pull/41030)\n*   Fix seccomp profile for clone syscall [moby/moby#39308](https://github.com/moby/moby/pull/39308)\n\n### [Swarm](#swarm-4)\n\n*   Add support for swarm jobs [moby/moby#40307](https://github.com/moby/moby/pull/40307)\n*   Add capabilities support to stack/service commands [docker/cli#2687](https://github.com/docker/cli/pull/2687) [docker/cli#2709](https://github.com/docker/cli/pull/2709) [moby/moby#39173](https://github.com/moby/moby/pull/39173) [moby/moby#41249](https://github.com/moby/moby/pull/41249)\n*   Add support for sending down service Running and Desired task counts [moby/moby#39231](https://github.com/moby/moby/pull/39231)\n*   service: support `--mount type=bind,bind-nonrecursive` [moby/moby#38788](https://github.com/moby/moby/pull/38788)\n*   Support ulimits on Swarm services. [moby/moby#41284](https://github.com/moby/moby/pull/41284) [docker/cli#2712](https://github.com/docker/cli/pull/2712)\n*   Fixed an issue where service logs could leak goroutines on the worker [moby/moby#40426](https://github.com/moby/moby/pull/40426)",
    "title": "Docker Engine 20.10 release notes | Docker Docs\n",
    "description": "Learn about the new features, bug fixes, and breaking changes for Docker Engine",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/extend/plugin_api/",
    "markdown": "# Docker Plugin API | Docker Docs\n\nDocker plugins are out-of-process extensions which add capabilities to the Docker Engine.\n\nThis document describes the Docker Engine plugin API. To view information on plugins managed by Docker Engine, refer to [Docker Engine plugin system](https://docs.docker.com/engine/extend/).\n\nThis page is intended for people who want to develop their own Docker plugin. If you just want to learn about or use Docker plugins, look [here](https://docs.docker.com/engine/extend/legacy_plugins/).\n\nA plugin is a process running on the same or a different host as the Docker daemon, which registers itself by placing a file on the daemon host in one of the plugin directories described in [Plugin discovery](#plugin-discovery).\n\nPlugins have human-readable names, which are short, lowercase strings. For example, `flocker` or `weave`.\n\nPlugins can run inside or outside containers. Currently running them outside containers is recommended.\n\nDocker discovers plugins by looking for them in the plugin directory whenever a user or container tries to use one by name.\n\nThere are three types of files which can be put in the plugin directory.\n\n*   `.sock` files are Unix domain sockets.\n*   `.spec` files are text files containing a URL, such as `unix:///other.sock` or `tcp://localhost:8080`.\n*   `.json` files are text files containing a full json specification for the plugin.\n\nPlugins with Unix domain socket files must run on the same host as the Docker daemon. Plugins with `.spec` or `.json` files can run on a different host if you specify a remote URL.\n\nUnix domain socket files must be located under `/run/docker/plugins`, whereas spec files can be located either under `/etc/docker/plugins` or `/usr/lib/docker/plugins`.\n\nThe name of the file (excluding the extension) determines the plugin name.\n\nFor example, the `flocker` plugin might create a Unix socket at `/run/docker/plugins/flocker.sock`.\n\nYou can define each plugin into a separated subdirectory if you want to isolate definitions from each other. For example, you can create the `flocker` socket under `/run/docker/plugins/flocker/flocker.sock` and only mount `/run/docker/plugins/flocker` inside the `flocker` container.\n\nDocker always searches for Unix sockets in `/run/docker/plugins` first. It checks for spec or json files under `/etc/docker/plugins` and `/usr/lib/docker/plugins` if the socket doesn't exist. The directory scan stops as soon as it finds the first plugin definition with the given name.\n\n### [JSON specification](#json-specification)\n\nThis is the JSON format for a plugin:\n\nThe `TLSConfig` field is optional and TLS will only be verified if this configuration is present.\n\nPlugins should be started before Docker, and stopped after Docker. For example, when packaging a plugin for a platform which supports `systemd`, you might use [`systemd` dependencies](https://www.freedesktop.org/software/systemd/man/systemd.unit.html#Before=) to manage startup and shutdown order.\n\nWhen upgrading a plugin, you should first stop the Docker daemon, upgrade the plugin, then start Docker again.\n\nWhen a plugin is first referred to -- either by a user referring to it by name (e.g. `docker run --volume-driver=foo`) or a container already configured to use a plugin being started -- Docker looks for the named plugin in the plugin directory and activates it with a handshake. See Handshake API below.\n\nPlugins are not activated automatically at Docker daemon startup. Rather, they are activated only lazily, or on-demand, when they are needed.\n\nPlugins may also be socket activated by `systemd`. The official [Plugins helpers](https://github.com/docker/go-plugins-helpers) natively supports socket activation. In order for a plugin to be socket activated it needs a `service` file and a `socket` file.\n\nThe `service` file (for example `/lib/systemd/system/your-plugin.service`):\n\nThe `socket` file (for example `/lib/systemd/system/your-plugin.socket`):\n\nThis will allow plugins to be actually started when the Docker daemon connects to the sockets they're listening on (for instance the first time the daemon uses them or if one of the plugin goes down accidentally).\n\nThe Plugin API is RPC-style JSON over HTTP, much like webhooks.\n\nRequests flow from the Docker daemon to the plugin. The plugin needs to implement an HTTP server and bind this to the Unix socket mentioned in the \"plugin discovery\" section.\n\nAll requests are HTTP `POST` requests.\n\nThe API is versioned via an Accept header, which currently is always set to `application/vnd.docker.plugins.v1+json`.\n\nPlugins are activated via the following \"handshake\" API call.\n\n### [/Plugin.Activate](#pluginactivate)\n\nRequest: empty body\n\nResponse:\n\nResponds with a list of Docker subsystems which this plugin implements. After activation, the plugin will then be sent events from this subsystem.\n\nPossible values are:\n\n*   [`authz`](https://docs.docker.com/engine/extend/plugins_authorization/)\n*   [`NetworkDriver`](https://docs.docker.com/engine/extend/plugins_network/)\n*   [`VolumeDriver`](https://docs.docker.com/engine/extend/plugins_volume/)\n\nAttempts to call a method on a plugin are retried with an exponential backoff for up to 30 seconds. This may help when packaging plugins as containers, since it gives plugin containers a chance to start up before failing any user containers which depend on them.\n\nTo ease plugins development, we're providing an `sdk` for each kind of plugins currently supported by Docker at [docker/go-plugins-helpers](https://github.com/docker/go-plugins-helpers).",
    "title": "Docker Plugin API | Docker Docs\n",
    "description": "How to write Docker plugins extensions ",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/19.03/",
    "markdown": "# Docker Engine 19.03 release notes\n\n2021-02-01\n\n### [Security](#security)\n\n*   [CVE-2021-21285](https://github.com/moby/moby/security/advisories/GHSA-6fj5-m822-rqx8) Prevent an invalid image from crashing docker daemon\n*   [CVE-2021-21284](https://github.com/moby/moby/security/advisories/GHSA-7452-xqpj-6rpc) Lock down file permissions to prevent remapped root from accessing docker state\n*   Ensure AppArmor and SELinux profiles are applied when building with BuildKit\n\n### [Client](#client)\n\n*   Check contexts before importing them to reduce risk of extracted files escaping context store\n\n2020-12-01\n\n### [Security](#security-1)\n\n*   [CVE-2020-15257](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15257): Update bundled static binaries of containerd to v1.3.9 [moby/moby#41731](https://github.com/moby/moby/pull/41731). Package managers should update the containerd.io package.\n\n### [Builder](#builder)\n\n*   Beta versions of apparmor are now parsed correctly preventing build failures [moby/moby#41542](https://github.com/moby/moby/pull/41542)\n\n### [Networking](#networking)\n\n*   Fix panic when swarmkit service keeps failing to start [moby/moby#41635](https://github.com/moby/moby/pull/41635)\n\n### [Runtime](#runtime)\n\n*   Return correct errors instead of spurrious -EINVAL [moby/moby#41293](https://github.com/moby/moby/pull/41293)\n\n### [Rootless](#rootless)\n\n*   Lock state dir for preventing automatic clean-up by systemd-tmpfiles [moby/moby#41635](https://github.com/moby/moby/pull/41635)\n*   dockerd-rootless.sh: support new containerd shim socket path convention [moby/moby#41557](https://github.com/moby/moby/pull/41557)\n\n### [Logging](#logging)\n\n*   gcplogs: Fix memory/connection leak [moby/moby#41522](https://github.com/moby/moby/pull/41522)\n*   awslogs: Support for AWS imdsv2 [moby/moby#41494](https://github.com/moby/moby/pull/41494)\n\n2020-09-16\n\n### [Builder](#builder-1)\n\n*   buildkit: Fix nil dereference in cache logic [moby/moby#41279](https://github.com/moby/moby/pull/41279)\n*   buildkit: Treat Unix sockets as regular files during COPY/ADD [moby/moby#41269](https://github.com/moby/moby/pull/41269)\n*   buildkit: Ignore system and security xattrs in calculation to ensure consistent COPY caching regardless of SELinux environment [moby/moby#41222](https://github.com/moby/moby/pull/41222)\n*   buildkit: Make `--cache-from` behavior more reliable [moby/moby#41222](https://github.com/moby/moby/pull/41222)\n*   buildkit: Fix infinite loop burning CPU when exporting cache [moby/moby#41185](https://github.com/moby/moby/pull/41185)\n\n### [Client](#client-1)\n\n*   Bump Golang 1.13.15 [docker/cli#2674](https://github.com/docker/cli/pull/2674)\n*   Fix config file permission issues (~/.docker/config.json) [docker/cli#2631](https://github.com/docker/cli/pull/2631)\n*   build: Fix panic on terminals with zero height [docker/cli#2719](https://github.com/docker/cli/pull/2719)\n*   windows: Fix potential issue with newline character in console [docker/cli#2623](https://github.com/docker/cli/pull/2623)\n\n### [Networking](#networking-1)\n\n*   Clean up network sandbox on failure [moby/moby#41081](https://github.com/moby/moby/pull/41081)\n*   Fix shallow error messages by forwarding deadline-related errors to user [moby/moby#41312](https://github.com/moby/moby/pull/41312)\n*   Fix leaking of netns file descriptors [moby/moby#41287](https://github.com/moby/moby/41287)\n\n### [Rootless](#rootless-1)\n\n*   Fix port forwarder resource leak [moby/moby#41277](https://github.com/moby/moby/pull/41277)\n\n### [Runtime](#runtime-1)\n\n*   Bump Golang 1.13.15 [moby/moby#41334](https://github.com/moby/moby/pull/41334)\n*   Update to containerd 1.3.7 [moby/moby#40408](https://github.com/moby/moby/pull/40408)\n\n### [Windows](#windows)\n\n*   Fix slow Windows container start time when using servercore image [moby/moby#41192](https://github.com/moby/moby/pull/41192)\n\n2020-06-18\n\n### [Client](#client-2)\n\n*   Fix bug preventing logout from registry when using multiple config files (e.g. Windows vs WSL2 when using Docker Desktop) [docker/cli#2592](https://github.com/docker/cli/pull/2592)\n*   Fix regression preventing context metadata to be read [docker/cli#2586](https://github.com/docker/cli/pull/2586)\n*   Bump Golang 1.13.12 [docker/cli#2575](https://github.com/docker/cli/pull/2575)\n\n### [Networking](#networking-2)\n\n*   Fix regression preventing daemon start up in a systemd-nspawn environment [moby/moby#41124](https://github.com/moby/moby/pull/41124) [moby/libnetwork#2567](https://github.com/moby/libnetwork/pull/2567)\n*   Fix the retry logic for creating overlay networks in swarm [moby/moby#41124](https://github.com/moby/moby/pull/41124) [moby/libnetwork#2565](https://github.com/moby/libnetwork/pull/2565)\n\n### [Runtime](#runtime-2)\n\n*   Bump Golang 1.13.12 [moby/moby#41082](https://github.com/moby/moby/pull/41082)\n\n2020-06-01\n\n### [Network](#network)\n\nDisable IPv6 Router Advertisements to prevent address spoofing. [CVE-2020-13401](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13401)\n\n**Description**\n\nIn the Docker default configuration, the container network interface is a virtual ethernet link going to the host (veth interface). In this configuration, an attacker able to run a process as root in a container can send and receive arbitrary packets to the host using the `CAP_NET_RAW` capability (present in the default configuration).\n\nIf IPv6 is not totally disabled on the host (via `ipv6.disable=1` on the kernel cmdline), it will be either unconfigured or configured on some interfaces, but it’s pretty likely that ipv6 forwarding is disabled, that is, `/proc/sys/net/ipv6/conf//forwarding == 0`. Also by default, `/proc/sys/net/ipv6/conf//accept_ra == 1`. The combination of these 2 sysctls means that the host accepts router advertisements and configures the IPv6 stack using them.\n\nBy sending “rogue” router advertisements from a container, an attacker can reconfigure the host to redirect part or all of the IPv6 traffic of the host to the attacker-controlled container.\n\nEven if there was no IPv6 traffic before, if the DNS returns A (IPv4) and AAAA (IPv6) records, many HTTP libraries will try to connect via IPv6 first then fallback to IPv4, giving an opportunity to the attacker to respond. If by chance the host has a vulnerability like last year’s RCE in apt (CVE-2019-3462), the attacker can now escalate to the host.\n\nAs `CAP_NET_ADMIN` is not present by default for Docker containers, the attacker can’t configure the IPs they want to MitM, they can’t use iptables to NAT or REDIRECT the traffic, and they can’t use `IP_TRANSPARENT`. The attacker can however still use `CAP_NET_RAW` and implement a tcp/ip stack in user space.\n\nSee [kubernetes/kubernetes#91507](https://github.com/kubernetes/kubernetes/issues/91507) for related issues.\n\n2020-05-29\n\n### [Client](#client-3)\n\n*   Fix version negotiation with older engine. [docker/cli#2538](https://github.com/docker/cli/pull/2538)\n*   Avoid setting SSH flags through hostname. [docker/cli#2560](https://github.com/docker/cli/pull/2560)\n*   Fix panic when DOCKER\\_CLI\\_EXPERIMENTAL is invalid. [docker/cli#2558](https://github.com/docker/cli/pull/2558)\n*   Avoid potential panic on s390x by upgrading Go to 1.13.11. [docker/cli#2532](https://github.com/docker/cli/pull/2532)\n\n### [Networking](#networking-3)\n\n*   Fix DNS fallback regression. [moby/moby#41009](https://github.com/moby/moby/pull/41009)\n\n### [Runtime](#runtime-3)\n\n*   Avoid potential panic on s390x by upgrading Go to 1.13.11. [moby/moby#40978](https://github.com/moby/moby/pull/40978)\n\n### [Packaging](#packaging)\n\n*   Fix ARM builds on ARM64. [moby/moby#41027](https://github.com/moby/moby/pull/41027)\n\n2020-05-14\n\n### [Builder](#builder-2)\n\n*   buildkit: Fix concurrent map write panic when building multiple images in parallel. [moby/moby#40780](https://github.com/moby/moby/pull/40780)\n*   buildkit: Fix issue preventing chowning of non-root-owned files between stages with userns. [moby/moby#40955](https://github.com/moby/moby/pull/40955)\n*   Avoid creation of irrelevant temporary files on Windows. [moby/moby#40877](https://github.com/moby/moby/pull/40877)\n\n### [Client](#client-4)\n\n*   Fix panic on single-character volumes. [docker/cli#2471](https://github.com/docker/cli/pull/2471)\n*   Lazy daemon feature detection to avoid long timeouts on simple commands. [docker/cli#2442](https://github.com/docker/cli/pull/2442)\n*   docker context inspect on Windows is now faster. [docker/cli#2516](https://github.com/docker/cli/pull/2516)\n*   Bump Golang 1.13.10. [docker/cli#2431](https://github.com/docker/cli/pull/2431)\n*   Bump gopkg.in/yaml.v2 to v2.2.8. [docker/cli#2470](https://github.com/docker/cli/pull/2470)\n\n### [Logging](#logging-1)\n\n*   Avoid situation preventing container logs to rotate due to closing a closed log file. [moby/moby#40921](https://github.com/moby/moby/pull/40921)\n\n### [Networking](#networking-4)\n\n*   Fix potential panic upon restart. [moby/moby#40809](https://github.com/moby/moby/pull/40809)\n*   Assign the correct network value to the default bridge Subnet field. [moby/moby#40565](https://github.com/moby/moby/pull/40565)\n\n### [Runtime](#runtime-4)\n\n*   Fix docker crash when creating namespaces with UID in /etc/subuid and /etc/subgid. [moby/moby#40562](https://github.com/moby/moby/pull/40562)\n*   Improve ARM platform matching. [moby/moby#40758](https://github.com/moby/moby/pull/40758)\n*   overlay2: show backing filesystem. [moby/moby#40652](https://github.com/moby/moby/pull/40652)\n*   Update CRIU to v3.13 \"Silicon Willet\". [moby/moby#40850](https://github.com/moby/moby/pull/40850)\n*   Only show registry v2 schema1 deprecation warning upon successful fallback, as opposed to any registry error. [moby/moby#40681](https://github.com/moby/moby/pull/40681)\n*   Use FILE\\_SHARE\\_DELETE for log files on Windows. [moby/moby#40563](https://github.com/moby/moby/pull/40563)\n*   Bump Golang 1.13.10. [moby/moby#40803](https://github.com/moby/moby/pull/40803)\n\n### [Rootless](#rootless-2)\n\n*   Now rootlesskit-docker-proxy returns detailed error message on exposing privileged ports. [moby/moby#40863](https://github.com/moby/moby/pull/40863)\n*   Supports numeric ID in /etc/subuid and /etc/subgid. [moby/moby#40951](https://github.com/moby/moby/pull/40951)\n\n### [Security](#security-2)\n\n*   apparmor: add missing rules for userns. [moby/moby#40564](https://github.com/moby/moby/pull/40564)\n*   SElinux: fix ENOTSUP errors not being detected when relabeling. [moby/moby#40946](https://github.com/moby/moby/pull/40946)\n\n### [Swarm](#swarm)\n\n*   Increase refill rate for logger to avoid hanging on service logs. [moby/moby#40628](https://github.com/moby/moby/pull/40628)\n*   Fix issue where single swarm manager is stuck in Down state after reboot. [moby/moby#40831](https://github.com/moby/moby/pull/40831)\n*   tasks.db no longer grows indefinitely. [moby/moby#40831](https://github.com/moby/moby/pull/40831)\n\n2020-03-10\n\n### [Runtime](#runtime-5)\n\n*   Improve mitigation for [CVE-2019-14271](https://nvd.nist.gov/vuln/detail/CVE-2019-14271) for some nscd configuration.\n\n2020-03-03\n\n### [Builder](#builder-3)\n\n*   builder-next: Fix deadlock issues in corner cases. [moby/moby#40557](https://github.com/moby/moby/pull/40557)\n\n### [Runtime](#runtime-6)\n\n*   overlay: remove modprobe execs. [moby/moby#40462](https://github.com/moby/moby/pull/40462)\n*   selinux: display better error messages when setting file labels. [moby/moby#40547](https://github.com/moby/moby/pull/40547)\n*   Speed up initial stats collection. [moby/moby#40549](https://github.com/moby/moby/pull/40549)\n\n*   rootless: use certs.d from XDG\\_CONFIG\\_HOME. [moby/moby#40461](https://github.com/moby/moby/pull/40461)\n*   Bump Golang 1.12.17. [moby/moby#40533](https://github.com/moby/moby/pull/40533)\n*   Bump google.golang.org/grpc to v1.23.1. [moby/moby#40566](https://github.com/moby/moby/pull/40566)\n*   Update containerd binary to v1.2.13. [moby/moby#40540](https://github.com/moby/moby/pull/40540)\n*   Prevent showing stopped containers as running in an edge case. [moby/moby#40555](https://github.com/moby/moby/pull/40555)\n*   Prevent potential lock. [moby/moby#40604](https://github.com/moby/moby/pull/40604)\n\n### [Client](#client-5)\n\n*   Bump Golang 1.12.17. [docker/cli#2342](https://github.com/docker/cli/pull/2342)\n*   Bump google.golang.org/grpc to v1.23.1. [docker/cli#1884](https://github.com/docker/cli/pull/1884) [docker/cli#2373](https://github.com/docker/cli/pull/2373)\n\n2020-02-12\n\n### [Builder](#builder-4)\n\n*   builder-next: Allow modern sign hashes for ssh forwarding. [docker/engine#453](https://github.com/docker/engine/pull/453)\n*   builder-next: Clear onbuild rules after triggering. [docker/engine#453](https://github.com/docker/engine/pull/453)\n*   builder-next: Fix issue with directory permissions when usernamespaces is enabled. [moby/moby#40440](https://github.com/moby/moby/pull/40440)\n*   Bump hcsshim to fix docker build failing on Windows 1903. [docker/engine#429](https://github.com/docker/engine/pull/429)\n\n### [Networking](#networking-5)\n\n*   Shorten controller ID in exec-root to not hit UNIX\\_PATH\\_MAX. [docker/engine#424](https://github.com/docker/engine/pull/424)\n*   Fix panic in drivers/overlay/encryption.go. [docker/engine#424](https://github.com/docker/engine/pull/424)\n*   Fix hwaddr set race between us and udev. [docker/engine#439](https://github.com/docker/engine/pull/439)\n\n### [Runtime](#runtime-7)\n\n*   Bump Golang 1.12.16. [moby/moby#40433](https://github.com/moby/moby/pull/40433)\n*   Update containerd binary to v1.2.12. [moby/moby#40433](https://github.com/moby/moby/pull/40453)\n*   Update to runc v1.0.0-rc10. [moby/moby#40433](https://github.com/moby/moby/pull/40453)\n\n*   Fix possible runtime panic in Lgetxattr. [docker/engine#454](https://github.com/docker/engine/pull/454)\n*   rootless: fix proxying UDP packets. [docker/engine#434](https://github.com/docker/engine/pull/434)\n\n2019-11-14\n\n### [Builder](#builder-5)\n\n*   builder-next: Added `entitlements` in builder config. [docker/engine#412](https://github.com/docker/engine/pull/412)\n*   Fix builder-next: permission errors on using build secrets or ssh forwarding with userns-remap. [docker/engine#420](https://github.com/docker/engine/pull/420)\n*   Fix builder-next: copying a symlink inside an already copied directory. [docker/engine#420](https://github.com/docker/engine/pull/420)\n\n### [Packaging](#packaging-1)\n\n*   Support RHEL 8 packages\n\n### [Runtime](#runtime-8)\n\n*   Bump Golang to 1.12.12. [docker/engine#418](https://github.com/docker/engine/pull/418)\n*   Update to RootlessKit to v0.7.0 to harden slirp4netns with mount namespace and seccomp. [docker/engine#397](https://github.com/docker/engine/pull/397)\n*   Fix to propagate GetContainer error from event processor. [docker/engine#407](https://github.com/docker/engine/pull/407)\n*   Fix push of OCI image. [docker/engine#405](https://github.com/docker/engine/pull/405)\n\n2019-10-17\n\n### [Networking](#networking-6)\n\n*   Rollback libnetwork changes to fix `DOCKER-USER` iptables chain issue. [docker/engine#404](https://github.com/docker/engine/pull/404)\n\n### [Known Issues](#known-issues)\n\n#### [Existing](#existing)\n\n*   In some circumstances with large clusters, Docker information might, as part of the Swarm section, include the error `code = ResourceExhausted desc = grpc: received message larger than max (5351376 vs. 4194304)`. This does not indicate any failure or misconfiguration by the user, and requires no response.\n*   Orchestrator port conflict can occur when redeploying all services as new. Due to many Swarm manager requests in a short amount of time, some services are not able to receive traffic and are causing a `404` error after being deployed.\n    *   **Workaround:** restart all tasks via `docker service update --force`.\n*   [CVE-2018-15664](https://nvd.nist.gov/vuln/detail/CVE-2018-15664) symlink-exchange attack with directory traversal. Workaround until proper fix is available in upcoming patch release: `docker pause` container before doing file operations. [moby/moby#39252](https://github.com/moby/moby/pull/39252)\n*   `docker cp` regression due to CVE mitigation. An error is produced when the source of `docker cp` is set to `/`.\n\n2019-10-08\n\n### [Security](#security-3)\n\n*   Patched `runc` in containerd. [CVE-2017-18367](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-18367)\n\n### [Builder](#builder-6)\n\n*   Fix builder-next: resolve digest for third party registries. [docker/engine#339](https://github.com/docker/engine/pull/339)\n    \n*   Fix builder-next: user namespace builds when daemon started with socket activation. [docker/engine#373](https://github.com/docker/engine/pull/373)\n    \n*   Fix builder-next; session: release forwarded ssh socket connection per connection. [docker/engine#373](https://github.com/docker/engine/pull/373)\n    \n*   Fix build-next: llbsolver: error on multiple cache importers. [docker/engine#373](https://github.com/docker/engine/pull/373)\n    \n\n### [Client](#client-6)\n\n*   Added support for Docker Template 0.1.6.\n    \n*   Mitigate against YAML files that have excessive aliasing. [docker/cli#2119](https://github.com/docker/cli/pull/2119)\n    \n\n### [Runtime](#runtime-9)\n\n*   Bump Golang to 1.12.10. [docker/engine#387](https://github.com/docker/engine/pull/387)\n    \n*   Bump containerd to 1.2.10. [docker/engine#385](https://github.com/docker/engine/pull/385)\n    \n*   Distribution: modify warning logic when pulling v2 schema1 manifests. [docker/engine#368](https://github.com/docker/engine/pull/368)\n    \n*   Fix `POST /images/create` returning a 500 status code when providing an incorrect platform option. [docker/engine#365](https://github.com/docker/engine/pull/365)\n    \n*   Fix `POST /build` returning a 500 status code when providing an incorrect platform option. [docker/engine#365](https://github.com/docker/engine/pull/365)\n    \n*   Fix panic on 32-bit ARMv7 caused by misaligned struct member. [docker/engine#363](https://github.com/docker/engine/pull/363)\n    \n*   Fix to return \"invalid parameter\" when linking to non-existing container. [docker/engine#352](https://github.com/docker/engine/pull/352)\n    \n*   Fix overlay2: busy error on mount when using kernel >= 5.2. [docker/engine#332](https://github.com/docker/engine/pull/332)\n    \n*   Fix `docker rmi` stuck in certain misconfigured systems, e.g. dead NFS share. [docker/engine#335](https://github.com/docker/engine/pull/335)\n    \n*   Fix handling of blocked I/O of exec'd processes. [docker/engine#296](https://github.com/docker/engine/pull/296)\n    \n*   Fix jsonfile logger: follow logs stuck when `max-size` is set and `max-file=1`. [docker/engine#378](https://github.com/docker/engine/pull/378)\n    \n\n### [Known Issues](#known-issues-1)\n\n#### [New](#new)\n\n*   `DOCKER-USER` iptables chain is missing: [docker/for-linux#810](https://github.com/docker/for-linux/issues/810). Users cannot perform additional container network traffic filtering on top of this iptables chain. You are not affected by this issue if you are not customizing iptable chains on top of `DOCKER-USER`.\n    *   **Workaround:** Insert the iptables chain after the docker daemon starts. For example:\n\n#### [Existing](#existing-1)\n\n*   In some circumstances with large clusters, docker information might, as part of the Swarm section, include the error `code = ResourceExhausted desc = grpc: received message larger than max (5351376 vs. 4194304)`. This does not indicate any failure or misconfiguration by the user, and requires no response.\n*   Orchestrator port conflict can occur when redeploying all services as new. Due to many swarm manager requests in a short amount of time, some services are not able to receive traffic and are causing a `404` error after being deployed.\n    *   **Workaround:** restart all tasks via `docker service update --force`.\n*   [CVE-2018-15664](https://nvd.nist.gov/vuln/detail/CVE-2018-15664) symlink-exchange attack with directory traversal. Workaround until proper fix is available in upcoming patch release: `docker pause` container before doing file operations. [moby/moby#39252](https://github.com/moby/moby/pull/39252)\n*   `docker cp` regression due to CVE mitigation. An error is produced when the source of `docker cp` is set to `/`.\n\n2019-09-03\n\n### [Builder](#builder-7)\n\n*   Fix `COPY --from` to non-existing directory on Windows. [moby/moby#39695](https://github.com/moby/moby/pull/39695)\n    \n*   Fix builder-next: metadata commands not having created time in history. [moby/moby#39456](https://github.com/moby/moby/issues/39456)\n    \n*   Fix builder-next: close progress on layer export error. [moby/moby#39782](https://github.com/moby/moby/pull/39782)\n    \n*   Update buildkit to 588c73e1e4. [moby/moby#39781](https://github.com/moby/moby/pull/39781)\n    \n\n### [Client](#client-7)\n\n*   Fix Windows absolute path detection on non-Windows [docker/cli#1990](https://github.com/docker/cli/pull/1990)\n    \n*   Fix to zsh completion script for `docker login --username`.\n    \n*   Fix context: produce consistent output on `context create`. [docker/cli#1985](https://github.com/docker/cli/pull/1874)\n    \n*   Fix support for HTTP proxy env variable. [docker/cli#2059](https://github.com/docker/cli/pull/2059)\n    \n\n### [Logging](#logging-2)\n\n*   Fix for reading journald logs. [moby/moby#37819](https://github.com/moby/moby/pull/37819) [moby/moby#38859](https://github.com/moby/moby/pull/38859)\n\n### [Networking](#networking-7)\n\n*   Prevent panic on network attached to a container with disabled networking. [moby/moby#39589](https://github.com/moby/moby/pull/39589)\n\n### [Runtime](#runtime-10)\n\n*   Bump Golang to 1.12.8.\n    \n*   Fix a potential engine panic when using XFS disk quota for containers. [moby/moby#39644](https://github.com/moby/moby/pull/39644)\n    \n\n### [Swarm](#swarm-1)\n\n*   Fix an issue where nodes with several tasks could not be removed. [docker/swarmkit#2867](https://github.com/docker/swarmkit/pull/2867)\n\n### [Known issues](#known-issues-2)\n\n*   In some circumstances with large clusters, docker information might, as part of the Swarm section, include the error `code = ResourceExhausted desc = grpc: received message larger than max (5351376 vs. 4194304)`. This does not indicate any failure or misconfiguration by the user, and requires no response.\n    \n*   Orchestrator port conflict can occur when redeploying all services as new. Due to many swarm manager requests in a short amount of time, some services are not able to receive traffic and are causing a `404` error after being deployed.\n    \n    *   Workaround: restart all tasks via `docker service update --force`.\n*   Traffic cannot egress the HOST because of missing Iptables rules in the FORWARD chain The missing rules are :\n    \n    *   Workaround: Add these rules back using a script and cron definitions. The script must contain '-C' commands to check for the presence of a rule and '-A' commands to add rules back. Run the script on a cron in regular intervals, for example, every minutes.\n    *   Affected versions: 18.09.1, 19.03.0\n*   [CVE-2018-15664](https://nvd.nist.gov/vuln/detail/CVE-2018-15664) symlink-exchange attack with directory traversal. Workaround until proper fix is available in upcoming patch release: `docker pause` container before doing file operations. [moby/moby#39252](https://github.com/moby/moby/pull/39252)\n    \n*   `docker cp` regression due to CVE mitigation. An error is produced when the source of `docker cp` is set to `/`.\n    \n\n2019-07-25\n\n### [Security](#security-4)\n\n*   Fixed loading of nsswitch based config inside chroot under Glibc. [CVE-2019-14271](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-14271)\n\n### [Known issues](#known-issues-3)\n\n*   In some circumstances, in large clusters, docker information might, as part of the Swarm section, include the error `code = ResourceExhausted desc = grpc: received message larger than max (5351376 vs. 4194304)`. This does not indicate any failure or misconfiguration by the user, and requires no response.\n    \n*   Orchestrator port conflict can occur when redeploying all services as new. Due to many swarm manager requests in a short amount of time, some services are not able to receive traffic and are causing a `404` error after being deployed.\n    \n    *   Workaround: restart all tasks via `docker service update --force`.\n*   Traffic cannot egress the HOST because of missing Iptables rules in the FORWARD chain The missing rules are :\n    \n    *   Workaround: Add these rules back using a script and cron definitions. The script must contain '-C' commands to check for the presence of a rule and '-A' commands to add rules back. Run the script on a cron in regular intervals, for example, every minutes.\n    *   Affected versions: 18.09.1, 19.03.0\n*   [CVE-2018-15664](https://nvd.nist.gov/vuln/detail/CVE-2018-15664) symlink-exchange attack with directory traversal. Workaround until proper fix is available in upcoming patch release: `docker pause` container before doing file operations. [moby/moby#39252](https://github.com/moby/moby/pull/39252)\n    \n*   `docker cp` regression due to CVE mitigation. An error is produced when the source of `docker cp` is set to `/`.\n    \n\n2019-07-22\n\n### [Builder](#builder-8)\n\n*   Fixed `COPY --from` to preserve ownership. [moby/moby#38599](https://github.com/moby/moby/pull/38599)\n    \n*   builder-next:\n    \n    *   Added inline cache support `--cache-from`. [docker/engine#215](https://github.com/docker/engine/pull/215)\n    *   Outputs configuration allowed. [moby/moby#38898](https://github.com/moby/moby/pull/38898)\n    *   Fixed gcr workaround token cache. [docker/engine#212](https://github.com/docker/engine/pull/212)\n    *   `stopprogress` called on download error. [docker/engine#215](https://github.com/docker/engine/pull/215)\n    *   Buildkit now uses systemd's `resolv.conf`. [docker/engine#260](https://github.com/docker/engine/pull/260).\n    *   Setting buildkit outputs now allowed. [docker/cli#1766](https://github.com/docker/cli/pull/1766)\n    *   Look for Dockerfile specific dockerignore file (for example, Dockerfile.dockerignore) for ignored paths. [docker/engine#215](https://github.com/docker/engine/pull/215)\n    *   Automatically detect if process execution is possible for x86, arm, and arm64 binaries. [docker/engine#215](https://github.com/docker/engine/pull/215)\n    *   Updated buildkit to 1f89ec1. [docker/engine#260](https://github.com/docker/engine/pull/260)\n    *   Use Dockerfile frontend version `docker/dockerfile:1.1` by default. [docker/engine#215](https://github.com/docker/engine/pull/215)\n    *   No longer rely on an external image for COPY/ADD operations. [docker/engine#215](https://github.com/docker/engine/pull/215)\n\n### [Client](#client-8)\n\n*   Added `--pids-limit` flag to `docker update`. [docker/cli#1765](https://github.com/docker/cli/pull/1765)\n*   Added systctl support for services. [docker/cli#1754](https://github.com/docker/cli/pull/1754)\n*   Added support for `template_driver` in compose files. [docker/cli#1746](https://github.com/docker/cli/pull/1746)\n*   Added `--device` support for Windows. [docker/cli#1606](https://github.com/docker/cli/pull/1606)\n*   Added support for Data Path Port configuration. [docker/cli#1509](https://github.com/docker/cli/pull/1509)\n*   Added fast context switch: commands. [docker/cli#1501](https://github.com/docker/cli/pull/1501)\n*   Support added for `--mount type=bind,bind-nonrecursive,...` [docker/cli#1430](https://github.com/docker/cli/pull/1430)\n*   Added maximum replicas per node. [docker/cli#1612](https://github.com/docker/cli/pull/1612)\n*   Added option to pull images quietly. [docker/cli#882](https://github.com/docker/cli/pull/882)\n*   Added a separate `--domainname` flag. [docker/cli#1130](https://github.com/docker/cli/pull/1130)\n*   Added support for secret drivers in `docker stack deploy`. [docker/cli#1783](https://github.com/docker/cli/pull/1783)\n*   Added ability to use swarm `Configs` as `CredentialSpecs` on services. [docker/cli#1781](https://github.com/docker/cli/pull/1781)\n*   Added `--security-opt systempaths=unconfined` support. [docker/cli#1808](https://github.com/docker/cli/pull/1808)\n*   Added basic framework for writing and running CLI plugins. [docker/cli#1564](https://github.com/docker/cli/pull/1564) [docker/cli#1898](https://github.com/docker/cli/pull/1898)\n*   Bumped Docker App to v0.8.0. [docker/docker-ce-packaging#341](https://github.com/docker/docker-ce-packaging/pull/341)\n*   Added support for Docker buildx. [docker/docker-ce-packaging#336](https://github.com/docker/docker-ce-packaging/pull/336)\n*   Added support for Docker Assemble v0.36.0.\n*   Added support for Docker Cluster v1.0.0-rc2.\n*   Added support for Docker Template v0.1.4.\n*   Added support for Docker Registry v0.1.0-rc1.\n*   Bumped google.golang.org/grpc to v1.20.1. [docker/cli#1884](https://github.com/docker/cli/pull/1884)\n*   CLI changed to pass driver specific options to `docker run`. [docker/cli#1767](https://github.com/docker/cli/pull/1767)\n*   Bumped Golang 1.12.5. [docker/cli#1875](https://github.com/docker/cli/pull/1875)\n*   `docker system info` output now segregates information relevant to the client and daemon. [docker/cli#1638](https://github.com/docker/cli/pull/1638)\n*   (Experimental) When targeting Kubernetes, added support for `x-pull-secret: some-pull-secret` in compose-files service configs. [docker/cli#1617](https://github.com/docker/cli/pull/1617)\n*   (Experimental) When targeting Kubernetes, added support for `x-pull-policy: <Never|Always|IfNotPresent>` in compose-files service configs. [docker/cli#1617](https://github.com/docker/cli/pull/1617)\n*   cp, save, export: Now preventing overwriting irregular files. [docker/cli#1515](https://github.com/docker/cli/pull/1515)\n*   npipe volume type on stack file now allowed. [docker/cli#1195](https://github.com/docker/cli/pull/1195)\n*   Fixed tty initial size error. [docker/cli#1529](https://github.com/docker/cli/pull/1529)\n*   Fixed problem with labels copying value from environment variables. [docker/cli#1671](https://github.com/docker/cli/pull/1671)\n\n### [API](#api)\n\n*   Updated API version to v1.40. [moby/moby#38089](https://github.com/moby/moby/pull/38089)\n*   Added warnings to `/info` endpoint, and moved detection to the daemon. [moby/moby#37502](https://github.com/moby/moby/pull/37502)\n*   Added HEAD support for `/_ping` endpoint. [moby/moby#38570](https://github.com/moby/moby/pull/38570)\n*   Added `Cache-Control` headers to disable caching `/_ping` endpoint. [moby/moby#38569](https://github.com/moby/moby/pull/38569)\n*   Added `containerd`, `runc`, and `docker-init` versions to `/version`. [moby/moby#37974](https://github.com/moby/moby/pull/37974)\n*   Added undocumented `/grpc` endpoint and registered BuildKit's controller. [moby/moby#38990](https://github.com/moby/moby/pull/38990)\n\n### [Experimental](#experimental)\n\n*   Enabled checkpoint/restore of containers with TTY. [moby/moby#38405](https://github.com/moby/moby/pull/38405)\n*   LCOW: Added support for memory and CPU limits. [moby/moby#37296](https://github.com/moby/moby/pull/37296)\n*   Windows: Added ContainerD runtime. [moby/moby#38541](https://github.com/moby/moby/pull/38541)\n*   Windows: LCOW now requires Windows RS5+. [moby/moby#39108](https://github.com/moby/moby/pull/39108)\n\n### [Security](#security-5)\n\n*   mount: added BindOptions.NonRecursive (API v1.40). [moby/moby#38003](https://github.com/moby/moby/pull/38003)\n*   seccomp: whitelisted `io_pgetevents()`. [moby/moby#38895](https://github.com/moby/moby/pull/38895)\n*   seccomp: `ptrace(2)` for 4.8+ kernels now allowed. [moby/moby#38137](https://github.com/moby/moby/pull/38137)\n\n### [Runtime](#runtime-11)\n\n*   Running `dockerd` as a non-root user (Rootless mode) is now allowed. [moby/moby#380050](https://github.com/moby/moby/pull/38050)\n*   Rootless: optional support provided for `lxc-user-nic` SUID binary. [docker/engine#208](https://github.com/docker/engine/pull/208)\n*   Added DeviceRequests to HostConfig to support NVIDIA GPUs. [moby/moby#38828](https://github.com/moby/moby/pull/38828)\n*   Added `--device` support for Windows. [moby/moby#37638](https://github.com/moby/moby/pull/37638)\n*   Added `memory.kernelTCP` support for linux. [moby/moby#37043](https://github.com/moby/moby/pull/37043)\n*   Windows credential specs can now be passed directly to the engine. [moby/moby#38777](https://github.com/moby/moby/pull/38777)\n*   Added pids-limit support in docker update. [moby/moby#32519](https://github.com/moby/moby/pull/32519)\n*   Added support for exact list of capabilities. [moby/moby#38380](https://github.com/moby/moby/pull/38380)\n*   daemon: Now use 'private' ipc mode by default. [moby/moby#35621](https://github.com/moby/moby/pull/35621)\n*   daemon: switched to semaphore-gated WaitGroup for startup tasks. [moby/moby#38301](https://github.com/moby/moby/pull/38301)\n*   Now use `idtools.LookupGroup` instead of parsing `/etc/group` file for docker.sock ownership to fix: `api.go doesn't respect nsswitch.conf`. [moby/moby#38126](https://github.com/moby/moby/pull/38126)\n*   cli: fixed images filter when using multi reference filter. [moby/moby#38171](https://github.com/moby/moby/pull/38171)\n*   Bumped Golang to 1.12.5. [docker/engine#209](https://github.com/docker/engine/pull/209)\n*   Bumped `containerd` to 1.2.6. [moby/moby#39016](https://github.com/moby/moby/pull/39016)\n*   Bumped `runc` to 1.0.0-rc8, opencontainers/selinux v1.2.2. [docker/engine#210](https://github.com/docker/engine/pull/210)\n*   Bumped `google.golang.org/grpc` to v1.20.1. [docker/engine#215](https://github.com/docker/engine/pull/215)\n*   Performance optimized in aufs and layer store for massively parallel container creation/removal. [moby/moby#39135](https://github.com/moby/moby/pull/39135) [moby/moby#39209](https://github.com/moby/moby/pull/39209)\n*   Root is now passed to chroot for chroot Tar/Untar (CVE-2018-15664) [moby/moby#39292](https://github.com/moby/moby/pull/39292)\n*   Fixed `docker --init` with /dev bind mount. [moby/moby#37665](https://github.com/moby/moby/pull/37665)\n*   The right device number is now fetched when greater than 255 and using the `--device-read-bps` option. [moby/moby#39212](https://github.com/moby/moby/pull/39212)\n*   Fixed `Path does not exist` error when path definitely exists. [moby/moby#39251](https://github.com/moby/moby/pull/39251)\n\n### [Networking](#networking-8)\n\n*   Moved IPVLAN driver out of experimental. [moby/moby#38983](https://github.com/moby/moby/pull/38983)\n*   Added support for 'dangling' filter. [moby/moby#31551](https://github.com/moby/moby/pull/31551) [docker/libnetwork#2230](https://github.com/docker/libnetwork/pull/2230)\n*   Load balancer sandbox is now deleted when a service is updated with `--network-rm`. [docker/engine#213](https://github.com/docker/engine/pull/213)\n*   Windows: Now forcing a nil IP specified in `PortBindings` to IPv4zero (0.0.0.0). [docker/libnetwork#2376](https://github.com/docker/libnetwork/pull/2376)\n\n### [Swarm](#swarm-2)\n\n*   Added support for maximum replicas per node. [moby/moby#37940](https://github.com/moby/moby/pull/37940)\n*   Added support for GMSA CredentialSpecs from Swarmkit configs. [moby/moby#38632](https://github.com/moby/moby/pull/38632)\n*   Added support for sysctl options in services. [moby/moby#37701](https://github.com/moby/moby/pull/37701)\n*   Added support for filtering on node labels. [moby/moby#37650](https://github.com/moby/moby/pull/37650)\n*   Windows: Support added for named pipe mounts in docker service create + stack yml. [moby/moby#37400](https://github.com/moby/moby/pull/37400)\n*   VXLAN UDP Port configuration now supported. [moby/moby#38102](https://github.com/moby/moby/pull/38102)\n*   Now using Service Placement Constraints in Enforcer. [docker/swarmkit#2857](https://github.com/docker/swarmkit/pull/2857)\n*   Increased max recv gRPC message size for nodes and secrets. [docker/engine#256](https://github.com/docker/engine/pull/256)\n\n### [Logging](#logging-3)\n\n*   Enabled gcplogs driver on Windows. [moby/moby#37717](https://github.com/moby/moby/pull/37717)\n*   Added zero padding for RFC5424 syslog format. [moby/moby#38335](https://github.com/moby/moby/pull/38335)\n*   Added `IMAGE_NAME` attribute to `journald` log events. [moby/moby#38032](https://github.com/moby/moby/pull/38032)\n\n### [Deprecation](#deprecation)\n\n*   Deprecate image manifest v2 schema1 in favor of v2 schema2. Future version of Docker will remove support for v2 schema1 althogether. [moby/moby#39365](https://github.com/moby/moby/pull/39365)\n*   Removed v1.10 migrator. [moby/moby#38265](https://github.com/moby/moby/pull/38265)\n*   Now skipping deprecated storage-drivers in auto-selection. [moby/moby#38019](https://github.com/moby/moby/pull/38019)\n*   Deprecated `aufs` storage driver and added warning. [moby/moby#38090](https://github.com/moby/moby/pull/38090)\n*   Removed support for 17.09.\n\nFor more information on deprecated flags and APIs, refer to [deprecation information](https://docs.docker.com/engine/deprecated/) for target removal dates.\n\n### [Known issues](#known-issues-4)\n\n*   In some circumstances with large clusters, docker information might, as part of the Swarm section, include the error `code = ResourceExhausted desc = grpc: received message larger than max (5351376 vs. 4194304)`. This does not indicate any failure or misconfiguration by the user, and requires no response.\n    \n*   Orchestrator port conflict can occur when redeploying all services as new. Due to many swarm manager requests in a short amount of time, some services are not able to receive traffic and are causing a `404` error after being deployed.\n    \n    *   Workaround: restart all tasks via `docker service update --force`.\n*   Traffic cannot egress the HOST because of missing Iptables rules in the FORWARD chain The missing rules are :\n    \n    *   Workaround: Add these rules back using a script and cron definitions. The script must contain '-C' commands to check for the presence of a rule and '-A' commands to add rules back. Run the script on a cron in regular intervals, for example, every minutes.\n    *   Affected versions: 18.09.1, 19.03.0\n*   [CVE-2018-15664](https://nvd.nist.gov/vuln/detail/CVE-2018-15664) symlink-exchange attack with directory traversal. Workaround until proper fix is available in upcoming patch release: `docker pause` container before doing file operations. [moby/moby#39252](https://github.com/moby/moby/pull/39252)\n    \n*   `docker cp` regression due to CVE mitigation. An error is produced when the source of `docker cp` is set to `/`.",
    "title": "Docker Engine 19.03 release notes | Docker Docs\n",
    "description": "",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/18.05/",
    "markdown": "# Docker Engine 18.05 release notes\n\n2018-05-09\n\n### [Builder](#builder)\n\n*   Adding `netbsd` compatibility to the package `pkg/term`. [moby/moby#36887](https://github.com/moby/moby/pull/36887)\n*   Standardizes output path for artifacts of intermediate builds to `/build/`. [moby/moby#36858](https://github.com/moby/moby/pull/36858)\n\n### [Client](#client)\n\n*   Fix `docker stack deploy` reference flag. [docker/cli#981](https://github.com/docker/cli/pull/981)\n*   Fix docker stack deploy re-deploying services after the service was updated with `--force`. [docker/cli#963](https://github.com/docker/cli/pull/963)\n\n*   Add bash completion for `secret|config create --template-driver`. [docker/cli#1004](https://github.com/docker/cli/pull/1004)\n*   Add fish completions for docker trust subcommand. [docker/cli#984](https://github.com/docker/cli/pull/984)\n\n*   Fix --format example for docker history. [docker/cli#980](https://github.com/docker/cli/pull/980)\n*   Fix error with merge composefile with networks. [docker/cli#983](https://github.com/docker/cli/pull/983)\n\n### [Logging](#logging)\n\n*   Standardized the properties of storage-driver log messages. [moby/moby#36492](https://github.com/moby/moby/pull/36492)\n*   Improve partial message support in logger. [moby/moby#35831](https://github.com/moby/moby/pull/35831)\n\n### [Networking](#networking)\n\n*   Allow for larger preset property values, do not override. [docker/libnetwork#2124](https://github.com/docker/libnetwork/pull/2124)\n*   networkdb: User write lock in handleNodeEvent. [docker/libnetwork#2136](https://github.com/docker/libnetwork/pull/2136)\n\n*   Import libnetwork fix for rolling updates. [moby/moby#36638](https://github.com/moby/moby/pull/36638)\n*   Update libnetwork to improve scalabiltiy of bridge network isolation rules. [moby/moby#36774](https://github.com/moby/moby/pull/36774)\n\n*   Fix a misused network object name. [moby/moby#36745](https://github.com/moby/moby/pull/36745)\n\n### [Runtime](#runtime)\n\n*   LCOW: Implement `docker save`. [moby/moby#36599](https://github.com/moby/moby/pull/36599)\n*   Pkg: devmapper: dynamically load dm\\_task\\_deferred\\_remove. [moby/moby#35518](https://github.com/moby/moby/pull/35518)\n*   Windows: Add GetLayerPath implementation in graphdriver. [moby/moby#36738](https://github.com/moby/moby/pull/36738)\n\n*   Fix Windows layer leak when write fails. [moby/moby#36728](https://github.com/moby/moby/pull/36728)\n*   Fix FIFO, sockets and device files when run in user NS. [moby/moby#36756](https://github.com/moby/moby/pull/36756)\n*   Fix docker version output alignment. [docker/cli#965](https://github.com/docker/cli/pull/965)\n\n*   Always make sysfs read-write with privileged. [moby/moby#36808](https://github.com/moby/moby/pull/36808)\n*   Bump Golang to 1.10.1. [moby/moby#35739](https://github.com/moby/moby/pull/35739)\n*   Bump containerd client. [moby/moby#36684](https://github.com/moby/moby/pull/36684)\n*   Bump golang.org/x/net to go1.10 release commit. [moby/moby#36894](https://github.com/moby/moby/pull/36894)\n*   Context.WithTimeout: do call the cancel func. [moby/moby#36920](https://github.com/moby/moby/pull/36920)\n*   Copy: avoid using all system memory with authz plugins. [moby/moby#36595](https://github.com/moby/moby/pull/36595)\n*   Daemon/cluster: handle partial attachment entries during configure. [moby/moby#36769](https://github.com/moby/moby/pull/36769)\n*   Don't make container mount unbindable. [moby/moby#36768](https://github.com/moby/moby/pull/36768)\n*   Extra check before unmounting on shutdown. [moby/moby#36879](https://github.com/moby/moby/pull/36879)\n*   Move mount parsing to separate package. [moby/moby#36896](https://github.com/moby/moby/pull/36896)\n*   No global volume driver store. [moby/moby#36637](https://github.com/moby/moby/pull/36637)\n*   Pkg/mount improvements. [moby/moby#36091](https://github.com/moby/moby/pull/36091)\n*   Relax some libcontainerd client locking. [moby/moby#36848](https://github.com/moby/moby/pull/36848)\n*   Remove daemon dependency on api packages. [moby/moby#36912](https://github.com/moby/moby/pull/36912)\n*   Remove the retries for service update. [moby/moby#36827](https://github.com/moby/moby/pull/36827)\n*   Revert unencryted storage warning prompt. [docker/cli#1008](https://github.com/docker/cli/pull/1008)\n*   Support cancellation in `directory.Size()`. [moby/moby#36734](https://github.com/moby/moby/pull/36734)\n*   Switch from x/net/context -> context. [moby/moby#36904](https://github.com/moby/moby/pull/36904)\n*   Fixed a function to check Content-type is `application/json` or not. [moby/moby#36778](https://github.com/moby/moby/pull/36778)\n\n*   Add default pollSettings config functions. [moby/moby#36706](https://github.com/moby/moby/pull/36706)\n*   Add if judgment before receiving operations on daemonWaitCh. [moby/moby#36651](https://github.com/moby/moby/pull/36651)\n\n*   Fix issues with running volume tests as non-root.. [moby/moby#36935](https://github.com/moby/moby/pull/36935)\n\n### [Swarm Mode](#swarm-mode)\n\n*   RoleManager will remove detected nodes from the cluster membership [docker/swarmkit#2548](https://github.com/docker/swarmkit/pull/2548)\n*   Scheduler/TaskReaper: handle unassigned tasks marked for shutdown [docker/swarmkit#2574](https://github.com/docker/swarmkit/pull/2574)\n*   Avoid predefined error log. [docker/swarmkit#2561](https://github.com/docker/swarmkit/pull/2561)\n*   Task reaper should delete tasks with removed slots that were not yet assigned. [docker/swarmkit#2557](https://github.com/docker/swarmkit/pull/2557)\n*   Agent reports FIPS status. [docker/swarmkit#2587](https://github.com/docker/swarmkit/pull/2587)\n\n*   Fix: timeMutex critical operation outside of critical section. [docker/swarmkit#2603](https://github.com/docker/swarmkit/pull/2603)\n\n*   Expose swarmkit's Raft tuning parameters in engine config. [moby/moby#36726](https://github.com/moby/moby/pull/36726)\n*   Make internal/test/daemon.Daemon swarm aware. [moby/moby#36826](https://github.com/moby/moby/pull/36826)",
    "title": "Docker Engine 18.05 release notes | Docker Docs\n",
    "description": "",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/exporters/image-registry/",
    "markdown": "# Image and registry exporters | Docker Docs\n\nThe `image` exporter outputs the build result into a container image format. The `registry` exporter is identical, but it automatically pushes the result by setting `push=true`.\n\nBuild a container image using the `image` and `registry` exporters:\n\nThe following table describes the available parameters that you can pass to `--output` for `type=image`:\n\n| Parameter | Type | Default | Description |\n| --- | --- | --- | --- |\n| `name` | String |     | Specify image name(s) |\n| `push` | `true`,`false` | `false` | Push after creating the image. |\n| `push-by-digest` | `true`,`false` | `false` | Push image without name. |\n| `registry.insecure` | `true`,`false` | `false` | Allow pushing to insecure registry. |\n| `dangling-name-prefix` | `<value>` |     | Name image with `prefix@<digest>`, used for anonymous images |\n| `name-canonical` | `true`,`false` |     | Add additional canonical name `name@<digest>` |\n| `compression` | `uncompressed`,`gzip`,`estargz`,`zstd` | `gzip` | Compression type, see [compression](https://docs.docker.com/build/exporters/#compression) |\n| `compression-level` | `0..22` |     | Compression level, see [compression](https://docs.docker.com/build/exporters/#compression) |\n| `force-compression` | `true`,`false` | `false` | Forcefully apply compression, see [compression](https://docs.docker.com/build/exporters/#compression) |\n| `oci-mediatypes` | `true`,`false` | `false` | Use OCI media types in exporter manifests, see [OCI Media types](https://docs.docker.com/build/exporters/#oci-media-types) |\n| `unpack` | `true`,`false` | `false` | Unpack image after creation (for use with containerd) |\n| `store` | `true`,`false` | `true` | Store the result images to the worker's (for example, containerd) image store, and ensures that the image has all blobs in the content store. Ignored if the worker doesn't have image store (when using OCI workers, for example). |\n| `annotation.<key>` | String |     | Attach an annotation with the respective `key` and `value` to the built image,see [annotations](#annotations) |\n\nThese exporters support adding OCI annotation using `annotation` parameter, followed by the annotation name using dot notation. The following example sets the `org.opencontainers.image.title` annotation:\n\nFor more information about annotations, see [BuildKit documentation](https://github.com/moby/buildkit/blob/master/docs/annotations.md).\n\nFor more information on the `image` or `registry` exporters, see the [BuildKit README](https://github.com/moby/buildkit/blob/master/README.md#imageregistry).",
    "title": "Image and registry exporters | Docker Docs\n",
    "description": "The image and registry exporters create an image that can be loaded to your local image store or pushed to a registry ",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/security/",
    "markdown": "# Docker security | Docker Docs\n\nThere are four major areas to consider when reviewing Docker security:\n\n*   The intrinsic security of the kernel and its support for namespaces and cgroups\n*   The attack surface of the Docker daemon itself\n*   Loopholes in the container configuration profile, either by default, or when customized by users.\n*   The \"hardening\" security features of the kernel and how they interact with containers.\n\nDocker containers are very similar to LXC containers, and they have similar security features. When you start a container with `docker run`, behind the scenes Docker creates a set of namespaces and control groups for the container.\n\nNamespaces provide the first and most straightforward form of isolation. Processes running within a container cannot see, and even less affect, processes running in another container, or in the host system.\n\nEach container also gets its own network stack, meaning that a container doesn't get privileged access to the sockets or interfaces of another container. Of course, if the host system is setup accordingly, containers can interact with each other through their respective network interfaces — just like they can interact with external hosts. When you specify public ports for your containers or use [links](https://docs.docker.com/network/links/) then IP traffic is allowed between containers. They can ping each other, send/receive UDP packets, and establish TCP connections, but that can be restricted if necessary. From a network architecture point of view, all containers on a given Docker host are sitting on bridge interfaces. This means that they are just like physical machines connected through a common Ethernet switch; no more, no less.\n\nHow mature is the code providing kernel namespaces and private networking? Kernel namespaces were introduced [between kernel version 2.6.15 and 2.6.26](https://man7.org/linux/man-pages/man7/namespaces.7.html). This means that since July 2008 (date of the 2.6.26 release ), namespace code has been exercised and scrutinized on a large number of production systems. And there is more: the design and inspiration for the namespaces code are even older. Namespaces are actually an effort to reimplement the features of [OpenVZ](https://en.wikipedia.org/wiki/OpenVZ) in such a way that they could be merged within the mainstream kernel. And OpenVZ was initially released in 2005, so both the design and the implementation are pretty mature.\n\nControl Groups are another key component of Linux containers. They implement resource accounting and limiting. They provide many useful metrics, but they also help ensure that each container gets its fair share of memory, CPU, disk I/O; and, more importantly, that a single container cannot bring the system down by exhausting one of those resources.\n\nSo while they do not play a role in preventing one container from accessing or affecting the data and processes of another container, they are essential to fend off some denial-of-service attacks. They are particularly important on multi-tenant platforms, like public and private PaaS, to guarantee a consistent uptime (and performance) even when some applications start to misbehave.\n\nControl Groups have been around for a while as well: the code was started in 2006, and initially merged in kernel 2.6.24.\n\nRunning containers (and applications) with Docker implies running the Docker daemon. This daemon requires `root` privileges unless you opt-in to [Rootless mode](https://docs.docker.com/engine/security/rootless/), and you should therefore be aware of some important details.\n\nFirst of all, only trusted users should be allowed to control your Docker daemon. This is a direct consequence of some powerful Docker features. Specifically, Docker allows you to share a directory between the Docker host and a guest container; and it allows you to do so without limiting the access rights of the container. This means that you can start a container where the `/host` directory is the `/` directory on your host; and the container can alter your host filesystem without any restriction. This is similar to how virtualization systems allow filesystem resource sharing. Nothing prevents you from sharing your root filesystem (or even your root block device) with a virtual machine.\n\nThis has a strong security implication: for example, if you instrument Docker from a web server to provision containers through an API, you should be even more careful than usual with parameter checking, to make sure that a malicious user cannot pass crafted parameters causing Docker to create arbitrary containers.\n\nFor this reason, the REST API endpoint (used by the Docker CLI to communicate with the Docker daemon) changed in Docker 0.5.2, and now uses a Unix socket instead of a TCP socket bound on 127.0.0.1 (the latter being prone to cross-site request forgery attacks if you happen to run Docker directly on your local machine, outside of a VM). You can then use traditional Unix permission checks to limit access to the control socket.\n\nYou can also expose the REST API over HTTP if you explicitly decide to do so. However, if you do that, be aware of the above mentioned security implications. Note that even if you have a firewall to limit accesses to the REST API endpoint from other hosts in the network, the endpoint can be still accessible from containers, and it can easily result in the privilege escalation. Therefore it is _mandatory_ to secure API endpoints with [HTTPS and certificates](https://docs.docker.com/engine/security/protect-access/). Exposing the daemon API over HTTP without TLS is not permitted, and such a configuration causes the daemon to fail early on startup, see [Unauthenticated TCP connections](https://docs.docker.com/engine/deprecated/#unauthenticated-tcp-connections). It is also recommended to ensure that it is reachable only from a trusted network or VPN.\n\nYou can also use `DOCKER_HOST=ssh://USER@HOST` or `ssh -L /path/to/docker.sock:/var/run/docker.sock` instead if you prefer SSH over TLS.\n\nThe daemon is also potentially vulnerable to other inputs, such as image loading from either disk with `docker load`, or from the network with `docker pull`. As of Docker 1.3.2, images are now extracted in a chrooted subprocess on Linux/Unix platforms, being the first-step in a wider effort toward privilege separation. As of Docker 1.10.0, all images are stored and accessed by the cryptographic checksums of their contents, limiting the possibility of an attacker causing a collision with an existing image.\n\nFinally, if you run Docker on a server, it is recommended to run exclusively Docker on the server, and move all other services within containers controlled by Docker. Of course, it is fine to keep your favorite admin tools (probably at least an SSH server), as well as existing monitoring/supervision processes, such as NRPE and collectd.\n\nBy default, Docker starts containers with a restricted set of capabilities. What does that mean?\n\nCapabilities turn the binary \"root/non-root\" dichotomy into a fine-grained access control system. Processes (like web servers) that just need to bind on a port below 1024 do not need to run as root: they can just be granted the `net_bind_service` capability instead. And there are many other capabilities, for almost all the specific areas where root privileges are usually needed. This means a lot for container security.\n\nTypical servers run several processes as `root`, including the SSH daemon, `cron` daemon, logging daemons, kernel modules, network configuration tools, and more. A container is different, because almost all of those tasks are handled by the infrastructure around the container:\n\n*   SSH access are typically managed by a single server running on the Docker host\n*   `cron`, when necessary, should run as a user process, dedicated and tailored for the app that needs its scheduling service, rather than as a platform-wide facility\n*   Log management is also typically handed to Docker, or to third-party services like Loggly or Splunk\n*   Hardware management is irrelevant, meaning that you never need to run `udevd` or equivalent daemons within containers\n*   Network management happens outside of the containers, enforcing separation of concerns as much as possible, meaning that a container should never need to perform `ifconfig`, `route`, or ip commands (except when a container is specifically engineered to behave like a router or firewall, of course)\n\nThis means that in most cases, containers do not need \"real\" root privileges at all\\* And therefore, containers can run with a reduced capability set; meaning that \"root\" within a container has much less privileges than the real \"root\". For instance, it is possible to:\n\n*   Deny all \"mount\" operations\n*   Deny access to raw sockets (to prevent packet spoofing)\n*   Deny access to some filesystem operations, like creating new device nodes, changing the owner of files, or altering attributes (including the immutable flag)\n*   Deny module loading\n\nThis means that even if an intruder manages to escalate to root within a container, it is much harder to do serious damage, or to escalate to the host.\n\nThis doesn't affect regular web apps, but reduces the vectors of attack by malicious users considerably. By default Docker drops all capabilities except [those needed](https://github.com/moby/moby/blob/master/oci/caps/defaults.go#L6-L19), an allowlist instead of a denylist approach. You can see a full list of available capabilities in [Linux manpages](https://man7.org/linux/man-pages/man7/capabilities.7.html).\n\nOne primary risk with running Docker containers is that the default set of capabilities and mounts given to a container may provide incomplete isolation, either independently, or when used in combination with kernel vulnerabilities.\n\nDocker supports the addition and removal of capabilities, allowing use of a non-default profile. This may make Docker more secure through capability removal, or less secure through the addition of capabilities. The best practice for users would be to remove all capabilities except those explicitly required for their processes.\n\n## [Docker Content Trust signature verification](#docker-content-trust-signature-verification)\n\nDocker Engine can be configured to only run signed images. The Docker Content Trust signature verification feature is built directly into the `dockerd` binary.  \nThis is configured in the Dockerd configuration file.\n\nTo enable this feature, trustpinning can be configured in `daemon.json`, whereby only repositories signed with a user-specified root key can be pulled and run.\n\nThis feature provides more insight to administrators than previously available with the CLI for enforcing and performing image signature verification.\n\nFor more information on configuring Docker Content Trust Signature Verification, go to [Content trust in Docker](https://docs.docker.com/engine/security/trust/).\n\nCapabilities are just one of the many security features provided by modern Linux kernels. It is also possible to leverage existing, well-known systems like TOMOYO, AppArmor, SELinux, GRSEC, etc. with Docker.\n\nWhile Docker currently only enables capabilities, it doesn't interfere with the other systems. This means that there are many different ways to harden a Docker host. Here are a few examples.\n\n*   You can run a kernel with GRSEC and PAX. This adds many safety checks, both at compile-time and run-time; it also defeats many exploits, thanks to techniques like address randomization. It doesn't require Docker-specific configuration, since those security features apply system-wide, independent of containers.\n*   If your distribution comes with security model templates for Docker containers, you can use them out of the box. For instance, we ship a template that works with AppArmor and Red Hat comes with SELinux policies for Docker. These templates provide an extra safety net (even though it overlaps greatly with capabilities).\n*   You can define your own policies using your favorite access control mechanism.\n\nJust as you can use third-party tools to augment Docker containers, including special network topologies or shared filesystems, tools exist to harden Docker containers without the need to modify Docker itself.\n\nAs of Docker 1.10 User Namespaces are supported directly by the docker daemon. This feature allows for the root user in a container to be mapped to a non uid-0 user outside the container, which can help to mitigate the risks of container breakout. This facility is available but not enabled by default.\n\nRefer to the [daemon command](https://docs.docker.com/reference/cli/dockerd/#daemon-user-namespace-options) in the command line reference for more information on this feature. Additional information on the implementation of User Namespaces in Docker can be found in [this blog post](https://integratedcode.us/2015/10/13/user-namespaces-have-arrived-in-docker/).\n\nDocker containers are, by default, quite secure; especially if you run your processes as non-privileged users inside the container.\n\nYou can add an extra layer of safety by enabling AppArmor, SELinux, GRSEC, or another appropriate hardening system.\n\nIf you think of ways to make docker more secure, we welcome feature requests, pull requests, or comments on the Docker community forums.\n\n*   [Use trusted images](https://docs.docker.com/engine/security/trust/)\n*   [Seccomp security profiles for Docker](https://docs.docker.com/engine/security/seccomp/)\n*   [AppArmor security profiles for Docker](https://docs.docker.com/engine/security/apparmor/)\n*   [On the Security of Containers (2014)](https://medium.com/@ewindisch/on-the-security-of-containers-2c60ffe25a9e)\n*   [Docker swarm mode overlay network security model](https://docs.docker.com/network/drivers/overlay/)",
    "title": "Docker security | Docker Docs\n",
    "description": "Review of the Docker Daemon attack surface",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/inspect-service/",
    "markdown": "# Inspect a service on the swarm\n\nWhen you have [deployed a service](https://docs.docker.com/engine/swarm/swarm-tutorial/deploy-service/) to your swarm, you can use the Docker CLI to see details about the service running in the swarm.\n\n1.  If you haven't already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n    \n2.  Run `docker service inspect --pretty <SERVICE-ID>` to display the details about a service in an easily readable format.\n    \n    To see the details on the `helloworld` service:\n    \n    > **Tip**\n    > \n    > To return the service details in json format, run the same command without the `--pretty` flag.\n    \n3.  Run `docker service ps <SERVICE-ID>` to see which nodes are running the service:\n    \n    In this case, the one instance of the `helloworld` service is running on the `worker2` node. You may see the service running on your manager node. By default, manager nodes in a swarm can execute tasks just like worker nodes.\n    \n    Swarm also shows you the `DESIRED STATE` and `CURRENT STATE` of the service task so you can see if tasks are running according to the service definition.\n    \n4.  Run `docker ps` on the node where the task is running to see details about the container for the task.\n    \n    > **Tip**\n    > \n    > If `helloworld` is running on a node other than your manager node, you must ssh to that node.\n    \n\nNext, you'll change the scale for the service running in the swarm.",
    "title": "Inspect a service on the swarm | Docker Docs\n",
    "description": "Inspect the application",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/18.09/",
    "markdown": "# Docker Engine 18.09 release notes\n\n> **Note:**\n> \n> With this release, the daemon, client and container runtime are now all shipped in separate packages. When updating, you need to update all packages at the same time to get the latest patch releases for each. For example, on Ubuntu:\n> \n> See the [installation instructions](https://docs.docker.com/engine/install/) for the corresponding Linux distro for details.\n\n2019-09-03\n\n### [Client](#client)\n\n*   Fix Windows absolute path detection on non-Windows. [docker/cli#1990](https://github.com/docker/cli/pull/1990)\n*   Fix Docker refusing to load key from delegation.key on Windows. [docker/cli#1968](https://github.com/docker/cli/pull/1968)\n*   Completion scripts updates for bash and zsh.\n\n### [Logging](#logging)\n\n*   Fix for reading journald logs. [moby/moby#37819](https://github.com/moby/moby/pull/37819) [moby/moby#38859](https://github.com/moby/moby/pull/38859)\n\n### [Networking](#networking)\n\n*   Prevent panic on network attached to a container with disabled networking. [moby/moby#39589](https://github.com/moby/moby/pull/39589)\n*   Fix service port for an application becomes unavailable randomly. [docker/libnetwork#2069](https://github.com/docker/libnetwork/pull/2069)\n*   Fix cleaning up `--config-only` networks `--config-from` networkshave ungracefully exited. [docker/libnetwork#2373](https://github.com/docker/libnetwork/pull/2373)\n\n### [Runtime](#runtime)\n\n*   Update to Go 1.11.13.\n*   Fix a potential engine panic when using XFS disk quota for containers. [moby/moby#39644](https://github.com/moby/moby/pull/39644)\n\n### [Swarm](#swarm)\n\n*   Fix \"grpc: received message larger than max\" errors. [moby/moby#39306](https://github.com/moby/moby/pull/39306)\n*   Fix an issue where nodes several tasks could not be removed. [docker/swarmkit#2867](https://github.com/docker/swarmkit/pull/2867)\n\n2019-07-17\n\n### [Runtime](#runtime-1)\n\n*   Masked the secrets updated to the log files when running Docker Engine in debug mode. [CVE-2019-13509](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-13509): If a Docker engine is running in debug mode, and `docker stack deploy` is used to redeploy a stack which includes non-external secrets, the logs will contain the secret.\n\n### [Client](#client-1)\n\n*   Fixed rollback config type interpolation for `parallelism` and `max_failure_ratio` fields.\n\n### [Known Issue](#known-issue)\n\n*   There are important changes to the upgrade process that, if not correctly followed, can have an impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or later.\n\n2019-06-27\n\n### [Builder](#builder)\n\n*   Fixed a panic error when building dockerfiles that contain only comments. [moby/moby#38487](https://github.com/moby/moby/pull/38487)\n*   Added a workaround for GCR authentication issue. [moby/moby#38246](https://github.com/moby/moby/pull/38246)\n*   Builder-next: Fixed a bug in the GCR token cache implementation workaround. [moby/moby#39183](https://github.com/moby/moby/pull/39183)\n\n### [Networking](#networking-1)\n\n*   Fixed an error where `--network-rm` would fail to remove a network. [moby/moby#39174](https://github.com/moby/moby/pull/39174)\n\n### [Runtime](#runtime-2)\n\n*   Added performance optimizations in aufs and layer store that helps in massively parallel container creation and removal. [moby/moby#39107](https://github.com/moby/moby/pull/39107), [moby/moby#39135](https://github.com/moby/moby/pull/39135)\n*   Updated containerd to version 1.2.6. [moby/moby#39016](https://github.com/moby/moby/pull/39016)\n*   Fixed [CVE-2018-15664](https://nvd.nist.gov/vuln/detail/CVE-2018-15664) symlink-exchange attack with directory traversal. [moby/moby#39357](https://github.com/moby/moby/pull/39357)\n*   Windows: fixed support for `docker service create --limit-cpu`. [moby/moby#39190](https://github.com/moby/moby/pull/39190)\n*   daemon: fixed a mirrors validation issue. [moby/moby#38991](https://github.com/moby/moby/pull/38991)\n*   Docker no longer supports sorting UID and GID ranges in ID maps. [moby/moby#39288](https://github.com/moby/moby/pull/39288)\n\n### [Logging](#logging-1)\n\n*   Added a fix that now allows large log lines for logger plugins. [moby/moby#39038](https://github.com/moby/moby/pull/39038)\n\n### [Known Issue](#known-issue-1)\n\n*   There are important changes to the upgrade process that, if not correctly followed, can have an impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or later.\n\n2019-05-06\n\n### [Builder](#builder-1)\n\n*   Fixed `COPY` and `ADD` with multiple `<src>` to not invalidate cache if `DOCKER_BUILDKIT=1`. [moby/moby#38964](https://github.com/moby/moby/issues/38964)\n\n### [Networking](#networking-2)\n\n*   Cleaned up the cluster provider when the agent is closed. [docker/libnetwork#2354](https://github.com/docker/libnetwork/pull/2354)\n*   Windows: Now selects a random host port if the user does not specify a host port. [docker/libnetwork#2369](https://github.com/docker/libnetwork/pull/2369)\n\n### [Known Issues](#known-issues)\n\n*   There are important changes to the upgrade process that, if not correctly followed, can have an impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or later.\n\n2019-04-11\n\n### [Builder](#builder-2)\n\n*   Fixed `DOCKER_BUILDKIT=1 docker build --squash ..` [docker/engine#176](https://github.com/docker/engine/pull/176)\n\n### [Client](#client-2)\n\n*   Fixed tty initial size error. [docker/cli#1775](https://github.com/docker/cli/pull/1775)\n*   Fixed dial-stdio goroutine leakage. [docker/cli#1795](https://github.com/docker/cli/pull/1795)\n*   Fixed the stack informer's selector used to track deployment. [docker/cli#1794](https://github.com/docker/cli/pull/1794)\n\n### [Networking](#networking-3)\n\n*   Fixed `network=host` using wrong `resolv.conf` with `systemd-resolved`. [docker/engine#180](https://github.com/docker/engine/pull/180)\n*   Fixed Windows ARP entries getting corrupted randomly under load. [docker/engine#192](https://github.com/docker/engine/pull/192)\n\n### [Runtime](#runtime-3)\n\n*   Now showing stopped containers with restart policy as `Restarting`. [docker/engine#181](https://github.com/docker/engine/pull/181)\n*   Now using original process spec for execs. [docker/engine#178](https://github.com/docker/engine/pull/178)\n\n### [Swarm Mode](#swarm-mode)\n\n*   Fixed leaking task resources when nodes are deleted. [docker/engine#185](https://github.com/docker/engine/pull/185)\n\n### [Known Issues](#known-issues-1)\n\n*   There are important changes to the upgrade process that, if not correctly followed, can have an impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or later.\n\n2019-03-28\n\n### [Builder](#builder-3)\n\n*   Fixed [CVE-2019-13139](https://nvd.nist.gov/vuln/detail/CVE-2019-13139) by adding validation for `git ref` to avoid misinterpretation as a flag. [moby/moby#38944](https://github.com/moby/moby/pull/38944)\n\n### [Runtime](#runtime-4)\n\n*   Fixed `docker cp` error for filenames greater than 100 characters. [moby/moby#38634](https://github.com/moby/moby/pull/38634)\n*   Fixed `layer/layer_store` to ensure `NewInputTarStream` resources are released. [moby/moby#38413](https://github.com/moby/moby/pull/38413)\n*   Increased GRPC limit for `GetConfigs`. [moby/moby#38800](https://github.com/moby/moby/pull/38800)\n*   Updated `containerd` 1.2.5. [docker/engine#173](https://github.com/docker/engine/pull/173)\n\n### [Swarm Mode](#swarm-mode-1)\n\n*   Fixed nil pointer exception when joining node to swarm. [moby/moby#38618](https://github.com/moby/moby/issues/38618)\n*   Fixed issue for swarm nodes not being able to join as masters if http proxy is set. \\[moby/moby#36951\\]\n\n### [Known Issues](#known-issues-2)\n\n*   There are important changes to the upgrade process that, if not correctly followed, can have impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or later.\n\n2019-02-28\n\n### [Networking fixes](#networking-fixes)\n\n*   Windows: now avoids regeneration of network IDs to prevent broken references to networks. [docker/engine#149](https://github.com/docker/engine/pull/149)\n*   Windows: Fixed an issue to address `- restart always` flag on standalone containers not working when specifying a network. (docker/escalation#1037)\n*   Fixed an issue to address the IPAM state from networkdb if the manager is not attached to the overlay network. (docker/escalation#1049)\n\n### [Runtime fixes and updates](#runtime-fixes-and-updates)\n\n*   Updated to Go version 1.10.8.\n*   Modified names in the container name generator. [docker/engine#159](https://github.com/docker/engine/pull/159)\n*   When copying an existing folder, xattr set errors when the target filesystem doesn't support xattr are now ignored. [docker/engine#135](https://github.com/docker/engine/pull/135)\n*   Graphdriver: fixed \"device\" mode not being detected if \"character-device\" bit is set. [docker/engine#160](https://github.com/docker/engine/pull/160)\n*   Fixed nil pointer derefence on failure to connect to containerd. [docker/engine#162](https://github.com/docker/engine/pull/162)\n*   Deleted stale containerd object on start failure. [docker/engine#154](https://github.com/docker/engine/pull/154)\n\n### [Known Issues](#known-issues-3)\n\n*   There are important changes to the upgrade process that, if not correctly followed, can have impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or greater.\n\n2019-02-11\n\n### [Security fixes](#security-fixes)\n\n*   Update `runc` to address a critical vulnerability that allows specially-crafted containers to gain administrative privileges on the host. [CVE-2019-5736](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-5736)\n*   Ubuntu 14.04 customers using a 3.13 kernel will need to upgrade to a supported Ubuntu 4.x kernel\n\nFor additional information, [refer to the Docker blog post](https://blog.docker.com/2019/02/docker-security-update-cve-2018-5736-and-container-security-best-practices/).\n\n### [Known Issues](#known-issues-4)\n\n*   There are important changes to the upgrade process that, if not correctly followed, can have impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or greater.\n\n2019-01-09\n\n#### [Important notes about this release](#important-notes-about-this-release)\n\nIn Docker versions prior to 18.09, containerd was managed by the Docker engine daemon. In Docker Engine 18.09, containerd is managed by systemd. Since containerd is managed by systemd, any custom configuration to the `docker.service` systemd configuration which changes mount settings (for example, `MountFlags=slave`) breaks interactions between the Docker Engine daemon and containerd, and you will not be able to start containers.\n\nRun the following command to get the current value of the `MountFlags` property for the `docker.service`:\n\nUpdate your configuration if this command prints a non-empty value for `MountFlags`, and restart the docker service.\n\n### [Security fixes](#security-fixes-1)\n\n*   Upgraded Go language to 1.10.6 to resolve [CVE-2018-16873](https://nvd.nist.gov/vuln/detail/CVE-2018-16873), [CVE-2018-16874](https://nvd.nist.gov/vuln/detail/CVE-2018-16874), and [CVE-2018-16875](https://nvd.nist.gov/vuln/detail/CVE-2018-16875).\n*   Fixed authz plugin for 0-length content and path validation.\n*   Added `/proc/asound` to masked paths [docker/engine#126](https://github.com/docker/engine/pull/126)\n\n### [Improvements](#improvements)\n\n*   Updated to BuildKit 0.3.3 [docker/engine#122](https://github.com/docker/engine/pull/122)\n*   Updated to containerd 1.2.2 [docker/engine#144](https://github.com/docker/engine/pull/144)\n*   Provided additional warnings for use of deprecated legacy overlay and devicemapper storage drivers [docker/engine#85](https://github.com/docker/engine/pull/85)\n*   prune: perform image pruning before build cache pruning [docker/cli#1532](https://github.com/docker/cli/pull/1532)\n*   Added bash completion for experimental CLI commands (manifest) [docker/cli#1542](https://github.com/docker/cli/pull/1542)\n*   Windows: allow process isolation on Windows 10 [docker/engine#81](https://github.com/docker/engine/pull/81)\n\n### [Fixes](#fixes)\n\n*   Disable kmem accounting in runc on RHEL/CentOS (docker/escalation#614, docker/escalation#692) [docker/engine#121](https://github.com/docker/engine/pull/121)\n*   Fixed inefficient networking configuration [docker/engine#123](https://github.com/docker/engine/pull/123)\n*   Fixed docker system prune doesn't accept until filter [docker/engine#122](https://github.com/docker/engine/pull/122)\n*   Avoid unset credentials in `containerd` [docker/engine#122](https://github.com/docker/engine/pull/122)\n*   Fixed iptables compatibility on Debian [docker/engine#107](https://github.com/docker/engine/pull/107)\n*   Fixed setting default schema to tcp for docker host [docker/cli#1454](https://github.com/docker/cli/pull/1454)\n*   Fixed bash completion for `service update --force` [docker/cli#1526](https://github.com/docker/cli/pull/1526)\n*   Windows: DetachVhd attempt in cleanup [docker/engine#113](https://github.com/docker/engine/pull/113)\n*   API: properly handle invalid JSON to return a 400 status [docker/engine#110](https://github.com/docker/engine/pull/110)\n*   API: ignore default address-pools on API < 1.39 [docker/engine#118](https://github.com/docker/engine/pull/118)\n*   API: add missing default address pool fields to swagger [docker/engine#119](https://github.com/docker/engine/pull/119)\n*   awslogs: account for UTF-8 normalization in limits [docker/engine#112](https://github.com/docker/engine/pull/112)\n*   Prohibit reading more than 1MB in HTTP error responses [docker/engine#114](https://github.com/docker/engine/pull/114)\n*   apparmor: allow receiving of signals from `docker kill` [docker/engine#116](https://github.com/docker/engine/pull/116)\n*   overlay2: use index=off if possible (fix EBUSY on mount) [docker/engine#84](https://github.com/docker/engine/pull/84)\n\n### [Packaging](#packaging)\n\n*   Add docker.socket requirement for docker.service. [docker/docker-ce-packaging#276](https://github.com/docker/docker-ce-packaging/pull/276)\n*   Add socket activation for RHEL-based distributions. [docker/docker-ce-packaging#274](https://github.com/docker/docker-ce-packaging/pull/274)\n*   Add libseccomp requirement for RPM packages. [docker/docker-ce-packaging#266](https://github.com/docker/docker-ce-packaging/pull/266)\n\n### [Known Issues](#known-issues-5)\n\n*   When upgrading from 18.09.0 to 18.09.1, `containerd` is not upgraded to the correct version on Ubuntu.\n*   There are important changes to the upgrade process that, if not correctly followed, can have impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or greater.\n\n2018-11-08\n\n### [Important notes about this release](#important-notes-about-this-release-1)\n\nIn Docker versions prior to 18.09, containerd was managed by the Docker engine daemon. In Docker Engine 18.09, containerd is managed by systemd. Since containerd is managed by systemd, any custom configuration to the `docker.service` systemd configuration which changes mount settings (for example, `MountFlags=slave`) breaks interactions between the Docker Engine daemon and containerd, and you will not be able to start containers.\n\nRun the following command to get the current value of the `MountFlags` property for the `docker.service`:\n\nUpdate your configuration if this command prints a non-empty value for `MountFlags`, and restart the docker service.\n\n### [New features](#new-features)\n\n*   Updated API version to 1.39 [moby/moby#37640](https://github.com/moby/moby/pull/37640)\n*   Added support for remote connections using SSH [docker/cli#1014](https://github.com/docker/cli/pull/1014)\n*   Builder: added prune options to the API [moby/moby#37651](https://github.com/moby/moby/pull/37651)\n*   Added \"Warnings\" to `/info` endpoint, and move detection to the daemon [moby/moby#37502](https://github.com/moby/moby/pull/37502)\n*   Allows BuildKit builds to run without experimental mode enabled. Buildkit can now be configured with an option in daemon.json [moby/moby#37593](https://github.com/moby/moby/pull/37593) [moby/moby#37686](https://github.com/moby/moby/pull/37686) [moby/moby#37692](https://github.com/moby/moby/pull/37692) [docker/cli#1303](https://github.com/docker/cli/pull/1303) [docker/cli#1275](https://github.com/docker/cli/pull/1275)\n*   Added support for build-time secrets using a `--secret` flag when using BuildKit [docker/cli#1288](https://github.com/docker/cli/pull/1288)\n*   Added SSH agent socket forwarder (`docker build --ssh $SSHMOUNTID=$SSH_AUTH_SOCK`) when using BuildKit [docker/cli#1438](https://github.com/docker/cli/pull/1438) / [docker/cli#1419](https://github.com/docker/cli/pull/1419)\n*   Added `--chown` flag support for `ADD` and `COPY` commands on Windows [moby/moby#35521](https://github.com/moby/moby/pull/35521)\n*   Added `builder prune` subcommand to prune BuildKit build cache [docker/cli#1295](https://github.com/docker/cli/pull/1295) [docker/cli#1334](https://github.com/docker/cli/pull/1334)\n*   BuildKit: Adds configurable garbage collection policy for the BuildKit build cache [docker/engine#59](https://github.com/docker/engine/pull/59) / [moby/moby#37846](https://github.com/moby/moby/pull/37846)\n*   BuildKit: Adds support for `docker build --pull ...` when using BuildKit [moby/moby#37613](https://github.com/moby/moby/pull/37613)\n*   BuildKit: Adds support or \"registry-mirrors\" and \"insecure-registries\" when using BuildKit [docker/engine#59](https://github.com/docker/engine/pull/59) / [moby/moby#37852](https://github.com/moby/moby/pull/37852)\n*   BuildKit: Enables net modes and bridge. [moby/moby#37620](https://github.com/moby/moby/pull/37620)\n*   Added `docker engine` subcommand to manage the lifecycle of a Docker Engine running as a privileged container on top of containerd, and to allow upgrades to Docker Engine Enterprise [docker/cli#1260](https://github.com/docker/cli/pull/1260)\n*   Exposed product license in `docker info` output [docker/cli#1313](https://github.com/docker/cli/pull/1313)\n*   Showed warnings produced by daemon in `docker info` output [docker/cli#1225](https://github.com/docker/cli/pull/1225)\n*   Added \"local\" log driver [moby/moby#37092](https://github.com/moby/moby/pull/37092)\n*   Amazon CloudWatch: adds `awslogs-endpoint` logging option [moby/moby#37374](https://github.com/moby/moby/pull/37374)\n*   Added support for global default address pools [moby/moby#37558](https://github.com/moby/moby/pull/37558) [docker/cli#1233](https://github.com/docker/cli/pull/1233)\n*   Configured containerd log-level to be the same as dockerd [moby/moby#37419](https://github.com/moby/moby/pull/37419)\n*   Added configuration option for cri-containerd [moby/moby#37519](https://github.com/moby/moby/pull/37519)\n*   Updates containerd client to v1.2.0-rc.1 [moby/moby#37664](https://github.com/moby/moby/pull/37664), [docker/engine#75](https://github.com/docker/engine/pull/75) / [moby/moby#37710](https://github.com/moby/moby/pull/37710)\n*   Added support for global default address pools [moby/moby#37558](https://github.com/moby/moby/pull/37558) [docker/cli#1233](https://github.com/docker/cli/pull/1233)\n*   Moved the `POST /session` endpoint out of experimental. [moby/moby#40028](https://github.com/moby/moby/pull/40028)\n\n### [Improvements](#improvements-1)\n\n*   Does not return \"`<unknown>`\" in /info response [moby/moby#37472](https://github.com/moby/moby/pull/37472)\n*   BuildKit: Changes `--console=[auto,false,true]` to `--progress=[auto,plain,tty]` [docker/cli#1276](https://github.com/docker/cli/pull/1276)\n*   BuildKit: Sets BuildKit's ExportedProduct variable to show useful errors in the future. [moby/moby#37439](https://github.com/moby/moby/pull/37439)\n*   Hides `--data-path-addr` flags when connected to a daemon that doesn't support this option [docker/docker/cli#1240](https://github.com/docker/cli/pull/1240)\n*   Only shows buildkit-specific flags if BuildKit is enabled [docker/cli#1438](https://github.com/docker/cli/pull/1438) / [docker/cli#1427](https://github.com/docker/cli/pull/1427)\n*   Improves version output alignment [docker/cli#1204](https://github.com/docker/cli/pull/1204)\n*   Sorts plugin names and networks in a natural order [docker/cli#1166](https://github.com/docker/cli/pull/1166), [docker/cli#1266](https://github.com/docker/cli/pull/1266)\n*   Updates bash and zsh [completion scripts](https://github.com/docker/cli/issues?q=label%3Aarea%2Fcompletion+milestone%3A18.09.0+is%3Aclosed)\n*   Passes log-level to containerd. [moby/moby#37419](https://github.com/moby/moby/pull/37419)\n*   Uses direct server return (DSR) in east-west overlay load balancing [docker/engine#93](https://github.com/docker/engine/pull/93) / [docker/libnetwork#2270](https://github.com/docker/libnetwork/pull/2270)\n*   Builder: temporarily disables bridge networking when using buildkit. [moby/moby#37691](https://github.com/moby/moby/pull/37691)\n*   Blocks task starting until node attachments are ready [moby/moby#37604](https://github.com/moby/moby/pull/37604)\n*   Propagates the provided external CA certificate to the external CA object in swarm. [docker/cli#1178](https://github.com/docker/cli/pull/1178)\n*   Removes Ubuntu 14.04 \"Trusty Tahr\" as a supported platform [docker-ce-packaging#255](https://github.com/docker/docker-ce-packaging/pull/255) / [docker-ce-packaging#254](https://github.com/docker/docker-ce-packaging/pull/254)\n*   Removes Debian 8 \"Jessie\" as a supported platform [docker-ce-packaging#255](https://github.com/docker/docker-ce-packaging/pull/255) / [docker-ce-packaging#254](https://github.com/docker/docker-ce-packaging/pull/254)\n*   Removes 'docker-' prefix for containerd and runc binaries [docker/engine#61](https://github.com/docker/engine/pull/61) / [moby/moby#37907](https://github.com/moby/moby/pull/37907), [docker-ce-packaging#241](https://github.com/docker/docker-ce-packaging/pull/241)\n*   Splits \"engine\", \"cli\", and \"containerd\" to separate packages, and run containerd as a separate systemd service [docker-ce-packaging#131](https://github.com/docker/docker-ce-packaging/pull/131), [docker-ce-packaging#158](https://github.com/docker/docker-ce-packaging/pull/158)\n*   Builds binaries with Go 1.10.4 [docker-ce-packaging#181](https://github.com/docker/docker-ce-packaging/pull/181)\n*   Removes `-ce` suffix from version string [docker-ce-packaging#206](https://github.com/docker/docker-ce-packaging/pull/206)\n\n### [Fixes](#fixes-1)\n\n*   BuildKit: Do not cancel buildkit status request. [moby/moby#37597](https://github.com/moby/moby/pull/37597)\n*   Fixes no error is shown if build args are missing during docker build [moby/moby#37396](https://github.com/moby/moby/pull/37396)\n*   Fixes error \"unexpected EOF\" when adding an 8GB file [moby/moby#37771](https://github.com/moby/moby/pull/37771)\n*   LCOW: Ensures platform is populated on `COPY`/`ADD`. [moby/moby#37563](https://github.com/moby/moby/pull/37563)\n*   Fixes mapping a range of host ports to a single container port [docker/cli#1102](https://github.com/docker/cli/pull/1102)\n*   Fixes `trust inspect` typo: \"`AdminstrativeKeys`\" [docker/cli#1300](https://github.com/docker/cli/pull/1300)\n*   Fixes environment file parsing for imports of absent variables and those with no name. [docker/cli#1019](https://github.com/docker/cli/pull/1019)\n*   Fixes a potential \"out of memory exception\" when running `docker image prune` with a large list of dangling images [docker/cli#1432](https://github.com/docker/cli/pull/1432) / [docker/cli#1423](https://github.com/docker/cli/pull/1423)\n*   Fixes pipe handling in ConEmu and ConsoleZ on Windows [moby/moby#37600](https://github.com/moby/moby/pull/37600)\n*   Fixes long startup on windows, with non-hns governed Hyper-V networks [docker/engine#67](https://github.com/docker/engine/pull/67) / [moby/moby#37774](https://github.com/moby/moby/pull/37774)\n*   Fixes daemon won't start when \"runtimes\" option is defined both in config file and cli [docker/engine#57](https://github.com/docker/engine/pull/57) / [moby/moby#37871](https://github.com/moby/moby/pull/37871)\n*   Loosens permissions on `/etc/docker` directory to prevent \"permission denied\" errors when using `docker manifest inspect` [docker/engine#56](https://github.com/docker/engine/pull/56) / [moby/moby#37847](https://github.com/moby/moby/pull/37847)\n*   Fixes denial of service with large numbers in `cpuset-cpus` and `cpuset-mems` [docker/engine#70](https://github.com/docker/engine/pull/70) / [moby/moby#37967](https://github.com/moby/moby/pull/37967)\n*   LCOW: Add `--platform` to `docker import` [docker/cli#1375](https://github.com/docker/cli/pull/1375) / [docker/cli#1371](https://github.com/docker/cli/pull/1371)\n*   LCOW: Add LinuxMetadata support by default on Windows [moby/moby#37514](https://github.com/moby/moby/pull/37514)\n*   LCOW: Mount to short container paths to avoid command-line length limit [moby/moby#37659](https://github.com/moby/moby/pull/37659)\n*   LCOW: Fix builder using wrong cache layer [moby/moby#37356](https://github.com/moby/moby/pull/37356)\n*   Fixes json-log file descriptors leaking when using `--follow` [docker/engine#48](https://github.com/docker/engine/pull/48) [moby/moby#37576](https://github.com/moby/moby/pull/37576) [moby/moby#37734](https://github.com/moby/moby/pull/37734)\n*   Fixes a possible deadlock on closing the watcher on kqueue [moby/moby#37392](https://github.com/moby/moby/pull/37392)\n*   Uses poller based watcher to work around the file caching issue in Windows [moby/moby#37412](https://github.com/moby/moby/pull/37412)\n*   Handles systemd-resolved case by providing appropriate resolv.conf to networking layer [moby/moby#37485](https://github.com/moby/moby/pull/37485)\n*   Removes support for TLS < 1.2 [moby/moby#37660](https://github.com/moby/moby/pull/37660)\n*   Seccomp: Whitelist syscalls linked to `CAP_SYS_NICE` in default seccomp profile [moby/moby#37242](https://github.com/moby/moby/pull/37242)\n*   Seccomp: move the syslog syscall to be gated by `CAP_SYS_ADMIN` or `CAP_SYSLOG` [docker/engine#64](https://github.com/docker/engine/pull/64) / [moby/moby#37929](https://github.com/moby/moby/pull/37929)\n*   SELinux: Fix relabeling of local volumes specified via Mounts API on selinux-enabled systems [moby/moby#37739](https://github.com/moby/moby/pull/37739)\n*   Adds warning if REST API is accessible through an insecure connection [moby/moby#37684](https://github.com/moby/moby/pull/37684)\n*   Masks proxy credentials from URL when displayed in system info [docker/engine#72](https://github.com/docker/engine/pull/72) / [moby/moby#37934](https://github.com/moby/moby/pull/37934)\n*   Fixes mount propagation for btrfs [docker/engine#86](https://github.com/docker/engine/pull/86) / [moby/moby#38026](https://github.com/moby/moby/pull/38026)\n*   Fixes nil pointer dereference in node allocation [docker/engine#94](https://github.com/docker/engine/pull/94) / [docker/swarmkit#2764](https://github.com/docker/swarmkit/pull/2764)\n\n### [Known Issues](#known-issues-6)\n\n*   There are important changes to the upgrade process that, if not correctly followed, can have impact on the availability of applications running on the Swarm during upgrades. These constraints impact any upgrades coming from any version before 18.09 to version 18.09 or greater.\n    \n*   With [https://github.com/boot2docker/boot2docker/releases/download/v18.09.0/boot2docker.iso](https://github.com/boot2docker/boot2docker/releases/download/v18.09.0/boot2docker.iso), connection is being refused from a node on the virtual machine. Any publishing of swarm ports in virtualbox-created docker-machine VM's will not respond. This is occurring on macOS and Windows 10, using docker-machine version 0.15 and 0.16.\n    \n    The following `docker run` command works, allowing access from host browser:\n    \n    `docker run -d -p 4000:80 nginx`\n    \n    However, the following `docker service` command fails, resulting in curl/chrome unable to connect (connection refused):\n    \n    `docker service create -p 5000:80 nginx`\n    \n    This issue is not apparent when provisioning 18.09.0 cloud VM's using docker-machine.\n    \n    Workarounds:\n    \n    *   Use cloud VM's that don't rely on boot2docker.\n    *   `docker run` is unaffected.\n    *   For Swarm, set VIRTUALBOX\\_BOOT2DOCKER\\_URL=https://github.com/boot2docker/boot2docker/releases/download/v18.06.1-ce/boot2docker.iso.\n    \n    This issue is resolved in 18.09.1.\n    \n\n### [Deprecation Notices](#deprecation-notices)\n\n*   Docker has deprecated support for Device Mapper as a storage driver. It will continue to be supported at this time, but support will be removed in a future release.\n    \n    The [Overlay2 storage driver](https://docs.docker.com/storage/storagedriver/overlayfs-driver/) is now the default for Docker engine implementations.\n    \n\nFor more information on the list of deprecated flags and APIs, have a look at the [deprecation information](https://docs.docker.com/engine/deprecated/) where you can find the target removal dates.\n\n### [End of Life Notification](#end-of-life-notification)\n\nIn this release, Docker has also removed support for TLS < 1.2 [moby/moby#37660](https://github.com/moby/moby/pull/37660), Ubuntu 14.04 \"Trusty Tahr\" [docker-ce-packaging#255](https://github.com/docker/docker-ce-packaging/pull/255) / [docker-ce-packaging#254](https://github.com/docker/docker-ce-packaging/pull/254), and Debian 8 \"Jessie\" [docker-ce-packaging#255](https://github.com/docker/docker-ce-packaging/pull/255) / [docker-ce-packaging#254](https://github.com/docker/docker-ce-packaging/pull/254).",
    "title": "Docker Engine 18.09 release notes | Docker Docs\n",
    "description": "",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/18.04/",
    "markdown": "# Docker Engine 18.04 release notes\n\n2018-04-10\n\n### [Builder](#builder)\n\n*   Fix typos in builder and client. [moby/moby#36424](https://github.com/moby/moby/pull/36424)\n\n### [Client](#client)\n\n*   Print Stack API and Kubernetes versions in version command. [docker/cli#898](https://github.com/docker/cli/pull/898)\n\n*   Fix Kubernetes duplication in version command. [docker/cli#953](https://github.com/docker/cli/pull/953)\n\n*   Use HasAvailableFlags instead of HasFlags for Options in help. [docker/cli#959](https://github.com/docker/cli/pull/959)\n\n*   Add support for mandatory variables to stack deploy. [docker/cli#893](https://github.com/docker/cli/pull/893)\n\n*   Fix docker stack services command Port output. [docker/cli#943](https://github.com/docker/cli/pull/943)\n\n*   Deprecate unencrypted storage. [docker/cli#561](https://github.com/docker/cli/pull/561)\n*   Don't set a default filename for ConfigFile. [docker/cli#917](https://github.com/docker/cli/pull/917)\n\n*   Fix compose network name. [docker/cli#941](https://github.com/docker/cli/pull/941)\n\n### [Logging](#logging)\n\n*   Silent login: use credentials from cred store to login. [docker/cli#139](https://github.com/docker/cli/pull/139)\n\n*   Add support for compressibility of log file. [moby/moby#29932](https://github.com/moby/moby/pull/29932)\n\n*   Fix empty LogPath with non-blocking logging mode. [moby/moby#36272](https://github.com/moby/moby/pull/36272)\n\n### [Networking](#networking)\n\n*   Prevent explicit removal of ingress network. [moby/moby#36538](https://github.com/moby/moby/pull/36538)\n\n### [Runtime](#runtime)\n\n*   Devmapper cleanup improvements. [moby/moby#36307](https://github.com/moby/moby/pull/36307)\n*   Devmapper.Mounted: remove. [moby/moby#36437](https://github.com/moby/moby/pull/36437)\n*   Devmapper/Remove(): use Rmdir, ignore errors. [moby/moby#36438](https://github.com/moby/moby/pull/36438)\n*   LCOW - Change platform parser directive to FROM statement flag. [moby/moby#35089](https://github.com/moby/moby/pull/35089)\n*   Split daemon service code to windows file. [moby/moby#36653](https://github.com/moby/moby/pull/36653)\n*   Windows: Block pulling uplevel images. [moby/moby#36327](https://github.com/moby/moby/pull/36327)\n*   Windows: Hyper-V containers are broken after 36586 was merged. [moby/moby#36610](https://github.com/moby/moby/pull/36610)\n*   Windows: Move kernel\\_windows to use golang registry functions. [moby/moby#36617](https://github.com/moby/moby/pull/36617)\n*   Windows: Pass back system errors on container exit. [moby/moby#35967](https://github.com/moby/moby/pull/35967)\n*   Windows: Remove servicing mode. [moby/moby#36267](https://github.com/moby/moby/pull/36267)\n*   Windows: Report Version and UBR. [moby/moby#36451](https://github.com/moby/moby/pull/36451)\n*   Bump Runc to 1.0.0-rc5. [moby/moby#36449](https://github.com/moby/moby/pull/36449)\n*   Mount failure indicates the path that failed. [moby/moby#36407](https://github.com/moby/moby/pull/36407)\n*   Change return for errdefs.getImplementer(). [moby/moby#36489](https://github.com/moby/moby/pull/36489)\n*   Client: fix hijackedconn reading from buffer. [moby/moby#36663](https://github.com/moby/moby/pull/36663)\n*   Content encoding negotiation added to archive request. [moby/moby#36164](https://github.com/moby/moby/pull/36164)\n*   Daemon/stats: more resilient cpu sampling. [moby/moby#36519](https://github.com/moby/moby/pull/36519)\n*   Daemon/stats: remove obnoxious types file. [moby/moby#36494](https://github.com/moby/moby/pull/36494)\n*   Daemon: use context error rather than inventing new one. [moby/moby#36670](https://github.com/moby/moby/pull/36670)\n*   Enable CRIU on non-amd64 architectures (v2). [moby/moby#36676](https://github.com/moby/moby/pull/36676)\n\n*   Fixes intermittent client hang after closing stdin to attached container [moby/moby#36517](https://github.com/moby/moby/pull/36517)\n*   Fix daemon panic on container export after restart [moby/moby#36586](https://github.com/moby/moby/pull/36586)\n*   Follow-up fixes on multi-stage moby's Dockerfile. [moby/moby#36425](https://github.com/moby/moby/pull/36425)\n\n*   Freeze busybox and latest glibc in Docker image. [moby/moby#36375](https://github.com/moby/moby/pull/36375)\n*   If container will run as non root user, drop permitted, effective caps early. [moby/moby#36587](https://github.com/moby/moby/pull/36587)\n*   Layer: remove metadata store interface. [moby/moby#36504](https://github.com/moby/moby/pull/36504)\n*   Minor optimizations to dockerd. [moby/moby#36577](https://github.com/moby/moby/pull/36577)\n*   Whitelist statx syscall. [moby/moby#36417](https://github.com/moby/moby/pull/36417)\n\n*   Add missing error return for plugin creation. [moby/moby#36646](https://github.com/moby/moby/pull/36646)\n\n*   Fix AppArmor not being applied to Exec processes. [moby/moby#36466](https://github.com/moby/moby/pull/36466)\n\n*   Daemon/logger/ring.go: log error not instance. [moby/moby#36475](https://github.com/moby/moby/pull/36475)\n\n*   Fix stats collector spinning CPU if no stats are collected. [moby/moby#36609](https://github.com/moby/moby/pull/36609)\n*   Fix(distribution): digest cache should not be moved if it was an auth. [moby/moby#36509](https://github.com/moby/moby/pull/36509)\n*   Make sure plugin container is removed on failure. [moby/moby#36715](https://github.com/moby/moby/pull/36715)\n\n*   Bump to containerd 1.0.3. [moby/moby#36749](https://github.com/moby/moby/pull/36749)\n*   Don't sort plugin mount slice. [moby/moby#36711](https://github.com/moby/moby/pull/36711)\n\n### [Swarm Mode](#swarm-mode)\n\n*   Fixes for synchronizing the dispatcher shutdown with in-progress rpcs. [moby/moby#36371](https://github.com/moby/moby/pull/36371)\n*   Increase raft ElectionTick to 10xHeartbeatTick. [moby/moby#36672](https://github.com/moby/moby/pull/36672)\n*   Make Swarm manager Raft quorum parameters configurable in daemon config. [moby/moby#36726](https://github.com/moby/moby/pull/36726)\n*   Ingress network should not be attachable. [docker/swarmkit#2523](https://github.com/docker/swarmkit/pull/2523)\n*   \\[manager/state\\] Add fernet as an option for raft encryption. [docker/swarmkit#2535](https://github.com/docker/swarmkit/pull/2535)\n*   Log GRPC server errors. [docker/swarmkit#2541](https://github.com/docker/swarmkit/pull/2541)\n*   Log leadership changes at the manager level. [docker/swarmkit#2542](https://github.com/docker/swarmkit/pull/2542)\n*   Remove the containerd executor. [docker/swarmkit#2568](https://github.com/docker/swarmkit/pull/2568)\n*   Agent: backoff session when no remotes are available. [docker/swarmkit#2570](https://github.com/docker/swarmkit/pull/2570)\n*   \\[ca/manager\\] Remove root CA key encryption support entirely. [docker/swarmkit#2573](https://github.com/docker/swarmkit/pull/2573)\n\n*   Fix agent logging race. [docker/swarmkit#2578](https://github.com/docker/swarmkit/pull/2578)\n\n*   Adding logic to restore networks in order. [docker/swarmkit#2571](https://github.com/docker/swarmkit/pull/2571)",
    "title": "Docker Engine 18.04 release notes | Docker Docs\n",
    "description": "",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/security/non-events/",
    "markdown": "# Docker security non-events | Docker Docs\n\nThis page lists security vulnerabilities which Docker mitigated, such that processes run in Docker containers were never vulnerable to the bug—even before it was fixed. This assumes containers are run without adding extra capabilities or not run as `--privileged`.\n\nThe list below is not even remotely complete. Rather, it is a sample of the few bugs we've actually noticed to have attracted security review and publicly disclosed vulnerabilities. In all likelihood, the bugs that haven't been reported far outnumber those that have. Luckily, since Docker's approach to secure by default through apparmor, seccomp, and dropping capabilities, it likely mitigates unknown bugs just as well as it does known ones.\n\nBugs mitigated:\n\n*   [CVE-2013-1956](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1956), [1957](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1957), [1958](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1958), [1959](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1959), [1979](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-1979), [CVE-2014-4014](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-4014), [5206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-5206), [5207](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-5207), [7970](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-7970), [7975](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-7975), [CVE-2015-2925](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-2925), [8543](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-8543), [CVE-2016-3134](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-3134), [3135](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-3135), etc.: The introduction of unprivileged user namespaces lead to a huge increase in the attack surface available to unprivileged users by giving such users legitimate access to previously root-only system calls like `mount()`. All of these CVEs are examples of security vulnerabilities due to introduction of user namespaces. Docker can use user namespaces to set up containers, but then disallows the process inside the container from creating its own nested namespaces through the default seccomp profile, rendering these vulnerabilities unexploitable.\n*   [CVE-2014-0181](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-0181), [CVE-2015-3339](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-3339): These are bugs that require the presence of a setuid binary. Docker disables setuid binaries inside containers via the `NO_NEW_PRIVS` process flag and other mechanisms.\n*   [CVE-2014-4699](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-4699): A bug in `ptrace()` could allow privilege escalation. Docker disables `ptrace()` inside the container using apparmor, seccomp and by dropping `CAP_PTRACE`. Three times the layers of protection there!\n*   [CVE-2014-9529](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-9529): A series of crafted `keyctl()` calls could cause kernel DoS / memory corruption. Docker disables `keyctl()` inside containers using seccomp.\n*   [CVE-2015-3214](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-3214), [4036](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-4036): These are bugs in common virtualization drivers which could allow a guest OS user to execute code on the host OS. Exploiting them requires access to virtualization devices in the guest. Docker hides direct access to these devices when run without `--privileged`. Interestingly, these seem to be cases where containers are \"more secure\" than a VM, going against common wisdom that VMs are \"more secure\" than containers.\n*   [CVE-2016-0728](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-0728): Use-after-free caused by crafted `keyctl()` calls could lead to privilege escalation. Docker disables `keyctl()` inside containers using the default seccomp profile.\n*   [CVE-2016-2383](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-2383): A bug in eBPF -- the special in-kernel DSL used to express things like seccomp filters -- allowed arbitrary reads of kernel memory. The `bpf()` system call is blocked inside Docker containers using (ironically) seccomp.\n*   [CVE-2016-3134](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-3134), [4997](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-4997), [4998](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-4998): A bug in setsockopt with `IPT_SO_SET_REPLACE`, `ARPT_SO_SET_REPLACE`, and `ARPT_SO_SET_REPLACE` causing memory corruption / local privilege escalation. These arguments are blocked by `CAP_NET_ADMIN`, which Docker does not allow by default.\n\nBugs not mitigated:\n\n*   [CVE-2015-3290](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-3290), [5157](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-5157): Bugs in the kernel's non-maskable interrupt handling allowed privilege escalation. Can be exploited in Docker containers because the `modify_ldt()` system call is not currently blocked using seccomp.\n*   [CVE-2016-5195](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-5195): A race condition was found in the way the Linux kernel's memory subsystem handled the copy-on-write (COW) breakage of private read-only memory mappings, which allowed unprivileged local users to gain write access to read-only memory. Also known as \"dirty COW.\" _Partial mitigations:_ on some operating systems this vulnerability is mitigated by the combination of seccomp filtering of `ptrace` and the fact that `/proc/self/mem` is read-only.",
    "title": "Docker security non-events | Docker Docs\n",
    "description": "Review of security vulnerabilities Docker mitigated",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/scale-service/",
    "markdown": "# Scale the service in the swarm\n\nOnce you have [deployed a service](https://docs.docker.com/engine/swarm/swarm-tutorial/deploy-service/) to a swarm, you are ready to use the Docker CLI to scale the number of containers in the service. Containers running in a service are called tasks.\n\n1.  If you haven't already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n    \n2.  Run the following command to change the desired state of the service running in the swarm:\n    \n    For example:\n    \n3.  Run `docker service ps <SERVICE-ID>` to see the updated task list:\n    \n    You can see that swarm has created 4 new tasks to scale to a total of 5 running instances of Alpine Linux. The tasks are distributed between the three nodes of the swarm. One is running on `manager1`.\n    \n4.  Run `docker ps` to see the containers running on the node where you're connected. The following example shows the tasks running on `manager1`:\n    \n    If you want to see the containers running on other nodes, ssh into those nodes and run the `docker ps` command.\n    \n\nAt this point in the tutorial, you're finished with the `helloworld` service. Next, you'll delete the service",
    "title": "Scale the service in the swarm | Docker Docs\n",
    "description": "Scale the service running in the swarm",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/18.06/",
    "markdown": "# Docker Engine 18.06 release notes\n\n2019-02-19\n\n### [Security fixes for Docker Engine](#security-fixes-for-docker-engine)\n\n*   Change how the `runc` critical vulnerability patch is applied to include the fix in RPM packages. [docker/engine#156](https://github.com/docker/engine/pull/156)\n\n2019-02-11\n\n### [Security fixes for Docker Engine](#security-fixes-for-docker-engine-1)\n\n*   Update `runc` to address a critical vulnerability that allows specially-crafted containers to gain administrative privileges on the host. [CVE-2019-5736](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-5736)\n*   Ubuntu 14.04 customers using a 3.13 kernel will need to upgrade to a supported Ubuntu 4.x kernel\n\n2018-08-21\n\n### [Builder](#builder)\n\n*   Fix no error if build args are missing during docker build. [docker/engine#25](https://github.com/docker/engine/pull/25)\n\n*   Set BuildKit's ExportedProduct variable to show useful errors. [docker/engine#21](https://github.com/docker/engine/pull/21)\n\n### [Client](#client)\n\n*   Various shell completion script updates: [docker/cli#1229](https://github.com/docker/cli/pull/1229), [docker/cli#1268](https://github.com/docker/cli/pull/1268), and [docker/cli#1272](https://github.com/docker/cli/pull/1272)\n\n*   Fix `DOCKER_CONFIG` warning message and fallback search. [docker/cli#1241](https://github.com/docker/cli/pull/1241)\n*   Fix help message flags on `docker stack` commands and sub-commands. [docker/cli#1267](https://github.com/docker/cli/pull/1267)\n\n### [Runtime](#runtime)\n\n*   Disable CRI plugin listening on port 10010 by default. [docker/engine#29](https://github.com/docker/engine/pull/29)\n*   Update containerd to v1.1.2. [docker/engine#33](https://github.com/docker/engine/pull/33)\n\n*   Windows: Do not invoke HCS shutdown if terminate called. [docker/engine#31](https://github.com/docker/engine/pull/31)\n\n*   Windows: Select polling-based watcher for Windows log watcher. [docker/engine#34](https://github.com/docker/engine/pull/34)\n\n### [Swarm Mode](#swarm-mode)\n\n*   Fix the condition used for skipping over running tasks. [docker/swarmkit#2677](https://github.com/docker/swarmkit/pull/2677)\n*   Fix task sorting. [docker/swarmkit#2712](https://github.com/docker/swarmkit/pull/2712)\n\n2018-07-18\n\n### [Important notes about this release](#important-notes-about-this-release)\n\n*   Docker 18.06 CE will be the last release with a 4-month maintenance lifecycle. The planned Docker 18.09 CE release will be supported for 7 months with Docker 19.03 CE being the next release in line. More details about the release process can be found [here](https://docs.docker.com/get-docker/).\n\n### [Builder](#builder-1)\n\n*   Builder: fix layer leak on multi-stage wildcard copy. [moby/moby#37178](https://github.com/moby/moby/pull/37178)\n*   Fix parsing of invalid environment variable substitution . [moby/moby#37134](https://github.com/moby/moby/pull/37134)\n*   Builder: use the arch info from base image. [moby/moby#36816](https://github.com/moby/moby/pull/36816) [moby/moby#37197](https://github.com/moby/moby/pull/37197)\n\n*   New experimental builder backend based on [BuildKit](https://github.com/moby/buildkit). To enable, run daemon in experimental mode and set `DOCKER_BUILDKIT=1` environment variable on the docker CLI. [moby/moby#37151](https://github.com/moby/moby/pull/37151) [docker/cli#1111](https://github.com/docker/cli/pull/1111)\n\n*   Fix handling uppercase targets names in multi-stage builds. [moby/moby#36960](https://github.com/moby/moby/pull/36960)\n\n### [Client](#client-1)\n\n*   Bump spf13/cobra to v0.0.3, pflag to v1.0.1. [moby/moby#37106](https://github.com/moby/moby/pull/37106)\n*   Add support for the new Stack API for Kubernetes v1beta2. [docker/cli#899](https://github.com/docker/cli/pull/899)\n*   K8s: more robust stack error detection on deploy. [docker/cli#948](https://github.com/docker/cli/pull/948)\n*   Support for rollback config in compose 3.7. [docker/cli#409](https://github.com/docker/cli/pull/409)\n*   Update Cobra and pflag, and use built-in --version feature. [docker/cli#1069](https://github.com/docker/cli/pull/1069)\n*   Fix `docker stack deploy --prune` with empty name removing all services. [docker/cli#1088](https://github.com/docker/cli/pull/1088)\n*   \\[Kubernetes\\] stack services filters. [docker/cli#1023](https://github.com/docker/cli/pull/1023)\n\n*   Only show orchestrator flag in root, stack and version commands in help. [docker/cli#1106](https://github.com/docker/cli/pull/1106)\n*   Add an `Extras` field on the compose config types. [docker/cli#1126](https://github.com/docker/cli/pull/1126)\n*   Add options to the compose loader. [docker/cli#1128](https://github.com/docker/cli/pull/1128)\n\n*   Fix always listing nodes in docker stack ps command on Kubernetes. [docker/cli#1093](https://github.com/docker/cli/pull/1093)\n*   Fix output being shown twice on stack rm error message. [docker/cli#1093](https://github.com/docker/cli/pull/1093)\n\n*   Extend client API with custom HTTP requests. [moby/moby#37071](https://github.com/moby/moby/pull/37071)\n*   Changed error message for unreadable files to clarify possibility of a .Dockerignore entry. [docker/cli#1053](https://github.com/docker/cli/pull/1053)\n*   Restrict kubernetes.allNamespaces value to 'enabled' or 'disabled' in configuration file. [docker/cli#1087](https://github.com/docker/cli/pull/1087)\n*   Check errors when initializing the docker client in the help command. [docker/cli#1119](https://github.com/docker/cli/pull/1119)\n*   Better namespace experience with Kubernetes. Fix using namespace defined in ~/.kube/config for stack commands. Add a NAMESPACE column for docker stack ls command. Add a --all-namespaces flag for docker stack ls command. [docker/cli#991](https://github.com/docker/cli/pull/991)\n*   Export Push and Save. [docker/cli#1123](https://github.com/docker/cli/pull/1123)\n*   Export pull as a public function. [docker/cli#1026](https://github.com/docker/cli/pull/1026)\n*   Remove Kubernetes commands from experimental. [docker/cli#1068](https://github.com/docker/cli/pull/1068)\n*   Adding configs/secrets to service inspect pretty. [docker/cli#1006](https://github.com/docker/cli/pull/1006)\n\n*   Fix service filtering by name on Kubernetes. [docker/cli#1101](https://github.com/docker/cli/pull/1101)\n*   Fix component information alignment in `docker version`. [docker/cli#1065](https://github.com/docker/cli/pull/1065)\n*   Fix cpu/memory limits and reservations being reset on service update. [docker/cli#1079](https://github.com/docker/cli/pull/1079)\n\n*   Manifest list: request specific permissions. [docker/cli#1024](https://github.com/docker/cli/pull/1024)\n*   Setting --orchestrator=all also sets --all-namespaces unless specific --namespace are set. [docker/cli#1059](https://github.com/docker/cli/pull/1059)\n\n*   Fix panics when --compress and --stream are used together. [docker/cli#1105](https://github.com/docker/cli/pull/1105)\n\n*   Switch from x/net/context to context. [docker/cli#1038](https://github.com/docker/cli/pull/1038)\n\n*   Add --init option to `docker service create`. [docker/cli#479](https://github.com/docker/cli/pull/479)\n*   Fixed bug displaying garbage output for build command when --stream and --quiet flags combined. [docker/cli#1090](https://github.com/docker/cli/pull/1090)\n*   Add `init` support in 3.7 schema. [docker/cli#1129](https://github.com/docker/cli/pull/1129)\n\n*   Fix docker trust signer removal. [docker/cli#1112](https://github.com/docker/cli/pull/1112)\n*   Fix error message from docker inspect. [docker/cli#1071](https://github.com/docker/cli/pull/1071)\n\n*   Allow `x-*` extension on 3rd level objects. [docker/cli#1097](https://github.com/docker/cli/pull/1097)\n*   An invalid orchestrator now generates an error instead of being silently ignored. [docker/cli#1055](https://github.com/docker/cli/pull/1055)\n*   Added ORCHESTRATOR column to docker stack ls command. [docker/cli#973](https://github.com/docker/cli/pull/973)\n*   Warn when using host-ip for published ports for services. [docker/cli#1017](https://github.com/docker/cli/pull/1017)\n\n*   Added the option to enable experimental cli features through the `DOCKER_CLI_EXPERIMENTAL` environment variable. [docker/cli#1138](https://github.com/docker/cli/pull/1138)\n*   Add exec\\_die to the list of known container events. [docker/cli#1028](https://github.com/docker/cli/pull/1028)\n\n*   \\[K8s\\] Do env-variable expansion on the uninterpreted Config files. [docker/cli#974](https://github.com/docker/cli/pull/974)\n\n*   Print warnings on stderr for each unsupported features while parsing a compose file for deployment on Kubernetes. [docker/cli#903](https://github.com/docker/cli/pull/903)\n*   Added description about pids count. [docker/cli#1045](https://github.com/docker/cli/pull/1045)\n\n*   Warn user of filter when pruning. [docker/cli#1043](https://github.com/docker/cli/pull/1043)\n*   Fix `--rollback-*` options overwriting `--update-*` options. [docker/cli#1052](https://github.com/docker/cli/pull/1052)\n\n*   Update Attach, Build, Commit, Cp, Create subcommand fish completions. [docker/cli#1005](https://github.com/docker/cli/pull/1005)\n\n*   Add bash completion for `dockerd --default-address-pool`. [docker/cli#1173](https://github.com/docker/cli/pull/1173)\n*   Add bash completion for `exec_die` event. [docker/cli#1173](https://github.com/docker/cli/pull/1173)\n\n*   Update docker-credential-helper so `pass` is not called on every docker command. [docker/cli#1184](https://github.com/docker/cli/pull/1184)\n*   Fix for rotating swarm external CA. [docker/cli#1199](https://github.com/docker/cli/pull/1199)\n*   Improve version output alignment. [docker/cli#1207](https://github.com/docker/cli/pull/1207)\n\n*   Add bash completion for `service create|update --init`. [docker/cli#1210](https://github.com/docker/cli/pull/1210)\n\n### [Deprecation](#deprecation)\n\n*   Document reserved namespaces deprecation. [docker/cli#1040](https://github.com/docker/cli/pull/1040)\n\n### [Logging](#logging)\n\n*   Allow awslogs to use non-blocking mode. [moby/moby#36522](https://github.com/moby/moby/pull/36522)\n*   Improve logging of long log lines on fluentd log driver.. [moby/moby#36159](https://github.com/moby/moby/pull/36159)\n*   Re-order CHANGELOG.md to pass `make validate` test. [moby/moby#37047](https://github.com/moby/moby/pull/37047)\n*   Update Events, Exec, Export, History, Images, Import, Inspect, Load, and Login subcommand fish completions. [docker/cli#1061](https://github.com/docker/cli/pull/1061)\n*   Update documentation for RingLogger's ring buffer. [moby/moby#37084](https://github.com/moby/moby/pull/37084)\n\n*   Add metrics for log failures/partials. [moby/moby#37034](https://github.com/moby/moby/pull/37034)\n\n*   Fix logging plugin crash unrecoverable. [moby/moby#37028](https://github.com/moby/moby/pull/37028)\n*   Fix logging test type. [moby/moby#37070](https://github.com/moby/moby/pull/37070)\n*   Fix race conditions in logs API. [moby/moby#37062](https://github.com/moby/moby/pull/37062)\n*   Fix some issues in logfile reader and rotation. [moby/moby#37063](https://github.com/moby/moby/pull/37063)\n\n### [Networking](#networking)\n\n*   Allow user to specify default address pools for docker networks. [moby/moby#36396](https://github.com/moby/moby/pull/36396) [docker/cli#818](https://github.com/docker/cli/pull/818)\n*   Adding logs for ipam state [doccker/libnetwork#2417](https://github.com/docker/libnetwork/pull/2147)\n*   Fix race conditions in the overlay network driver [doccker/libnetwork#2143](https://github.com/docker/libnetwork/pull/2143)\n*   Add wait time into xtables lock warning [doccker/libnetwork#2142](https://github.com/docker/libnetwork/pull/2142)\n*   filter xtables lock warnings when firewalld is active [doccker/libnetwork#2135](https://github.com/docker/libnetwork/pull/2135)\n*   Switch from x/net/context to context [doccker/libnetwork#2140](https://github.com/docker/libnetwork/pull/2140)\n*   Adding a recovery mechanism for a split gossip cluster [doccker/libnetwork#2134](https://github.com/docker/libnetwork/pull/2134)\n*   Running docker inspect on network attachment tasks now returns a full task object. [moby/moby#35246](https://github.com/moby/moby/pull/35246)\n*   Some container/network cleanups. [moby/moby#37033](https://github.com/moby/moby/pull/37033)\n\n*   Fix network inspect for overlay network. [moby/moby#37045](https://github.com/moby/moby/pull/37045)\n\n*   Improve Scalability of the Linux load balancing. [docker/engine#16](https://github.com/docker/engine/pull/16)\n*   Change log level from error to warning. [docker/engine#19](https://github.com/docker/engine/pull/19)\n\n### [Runtime](#runtime-1)\n\n*   Aufs: log why aufs is not supported. [moby/moby#36995](https://github.com/moby/moby/pull/36995)\n*   Hide experimental checkpoint features on Windows. [docker/cli#1094](https://github.com/docker/cli/pull/1094)\n*   Lcow: Allow the client to customize capabilities and device cgroup rules for LCOW containers. [moby/moby#37294](https://github.com/moby/moby/pull/37294)\n*   Changed path given for executable output in windows to actual location of executable output. [moby/moby#37295](https://github.com/moby/moby/pull/37295)\n\n*   Add windows recycle bin test and update hcsshim to v0.6.11. [moby/moby#36994](https://github.com/moby/moby/pull/36994)\n\n*   Allow to add any args when doing a make run. [moby/moby#37190](https://github.com/moby/moby/pull/37190)\n*   Optimize ContainerTop() aka docker top. [moby/moby#37131](https://github.com/moby/moby/pull/37131)\n\n*   Fix compilation on 32bit machines. [moby/moby#37292](https://github.com/moby/moby/pull/37292)\n\n*   Update API version to v1 38. [moby/moby#37141](https://github.com/moby/moby/pull/37141)\n\n*   Fix `docker service update --host-add` does not update existing host entry. [docker/cli#1054](https://github.com/docker/cli/pull/1054)\n*   Fix swagger file type for ExecIds. [moby/moby#36962](https://github.com/moby/moby/pull/36962)\n*   Fix swagger volume type generation. [moby/moby#37060](https://github.com/moby/moby/pull/37060)\n*   Fix wrong assertion in volume/service package. [moby/moby#37211](https://github.com/moby/moby/pull/37211)\n*   Fix daemon panic on restart when a plugin is running. [moby/moby#37234](https://github.com/moby/moby/pull/37234)\n\n*   Construct and add 'LABEL' command from 'label' option to last stage. [moby/moby#37011](https://github.com/moby/moby/pull/37011)\n\n*   Fix race condition between exec start and resize.. [moby/moby#37172](https://github.com/moby/moby/pull/37172)\n\n*   Alternative failure mitigation of `TestExecInteractiveStdinClose`. [moby/moby#37143](https://github.com/moby/moby/pull/37143)\n*   RawAccess allows a set of paths to be not set as masked or readonly. [moby/moby#36644](https://github.com/moby/moby/pull/36644)\n*   Be explicit about github.com prefix being a legacy feature. [moby/moby#37174](https://github.com/moby/moby/pull/37174)\n*   Bump Golang to 1.10.3. [docker/cli#1122](https://github.com/docker/cli/pull/1122)\n*   Close ReadClosers to prevent xz zombies. [moby/moby#34218](https://github.com/moby/moby/pull/34218)\n*   Daemon.ContainerStop(): fix for a negative timeout. [moby/moby#36874](https://github.com/moby/moby/pull/36874)\n*   Daemon.setMounts(): copy slice in place. [moby/moby#36991](https://github.com/moby/moby/pull/36991)\n*   Describe IP field of swagger Port definition. [moby/moby#36971](https://github.com/moby/moby/pull/36971)\n*   Extract volume interaction to a volumes service. [moby/moby#36688](https://github.com/moby/moby/pull/36688)\n*   Fixed markdown formatting in docker image v1, v1.1, and v1.2 spec. [moby/moby#37051](https://github.com/moby/moby/pull/37051)\n*   Improve GetTimestamp parsing. [moby/moby#35402](https://github.com/moby/moby/pull/35402)\n*   Jsonmessage: pass message to aux callback. [moby/moby#37064](https://github.com/moby/moby/pull/37064)\n*   Overlay2: remove unused cdMountFrom() helper function. [moby/moby#37041](https://github.com/moby/moby/pull/37041)\n\n*   Overlay: Fix overlay storage-driver silently ignoring unknown storage-driver options. [moby/moby#37040](https://github.com/moby/moby/pull/37040)\n\n*   Remove some unused contrib items. [moby/moby#36977](https://github.com/moby/moby/pull/36977)\n*   Restartmanager: do not apply restart policy on created containers. [moby/moby#36924](https://github.com/moby/moby/pull/36924)\n*   Set item-type for ExecIDs. [moby/moby#37121](https://github.com/moby/moby/pull/37121)\n*   Use go-systemd const instead of magic string in Linux version of dockerd. [moby/moby#37136](https://github.com/moby/moby/pull/37136)\n*   Use stdlib TLS dialer. [moby/moby#36687](https://github.com/moby/moby/pull/36687)\n*   Warn when an engine label using a reserved namespace (com.docker.\\*, io.docker.\\*, or org.dockerproject.\\*) is configured, as per [Docker object labels](https://docs.docker.com/config/labels-custom-metadata/). [moby/moby#36921](https://github.com/moby/moby/pull/36921)\n\n*   Fix missing plugin name in message. [moby/moby#37052](https://github.com/moby/moby/pull/37052)\n*   Fix link anchors in CONTRIBUTING.md. [moby/moby#37276](https://github.com/moby/moby/pull/37276)\n*   Fix link to Docker Toolbox. [moby/moby#37240](https://github.com/moby/moby/pull/37240)\n*   Fix mis-used skip condition. [moby/moby#37179](https://github.com/moby/moby/pull/37179)\n*   Fix bind mounts not working in some cases. [moby/moby#37031](https://github.com/moby/moby/pull/37031)\n*   Fix fd leak on attach. [moby/moby#37184](https://github.com/moby/moby/pull/37184)\n*   Fix fluentd partial detection. [moby/moby#37029](https://github.com/moby/moby/pull/37029)\n*   Fix incorrect link in version-history.md. [moby/moby#37049](https://github.com/moby/moby/pull/37049)\n\n*   Allow vim to be case insensitive for D in dockerfile. [moby/moby#37235](https://github.com/moby/moby/pull/37235)\n\n*   Add `t.Name()` to tests so that service names are unique. [moby/moby#37166](https://github.com/moby/moby/pull/37166)\n*   Add additional message when backendfs is extfs without d\\_type support. [moby/moby#37022](https://github.com/moby/moby/pull/37022)\n*   Add api version checking for tests from new feature. [moby/moby#37169](https://github.com/moby/moby/pull/37169)\n*   Add image metrics for push and pull. [moby/moby#37233](https://github.com/moby/moby/pull/37233)\n*   Add support for `init` on services. [moby/moby#37183](https://github.com/moby/moby/pull/37183)\n*   Add verification of escapeKeys array length in pkg/term/proxy.go. [moby/moby#36918](https://github.com/moby/moby/pull/36918)\n\n*   When link id is empty for overlay2, do not remove this link.. [moby/moby#36161](https://github.com/moby/moby/pull/36161)\n\n*   Fix build on OpenBSD by defining Self(). [moby/moby#37301](https://github.com/moby/moby/pull/37301)\n*   Windows: Fix named pipe support for hyper-v isolated containers. [docker/engine#2](https://github.com/docker/engine/pull/2) [docker/cli#1165](https://github.com/docker/cli/pull/1165)\n*   Fix manifest lists to always use correct size. [docker/cli#1183](https://github.com/docker/cli/pull/1183)\n\n*   Register OCI media types. [docker/engine#4](https://github.com/docker/engine/pull/4)\n*   Update containerd to v1.1.1 [docker/engine#17](https://github.com/docker/engine/pull/17)\n*   LCOW: Prefer Windows over Linux in a manifest list. [docker/engine#3](https://github.com/docker/engine/pull/3)\n*   Add updated `MaskPaths` that are used in code paths directly using containerd to address [CVE-2018-10892](https://cve.mitre.org/cgi-bin/cvename.cgi?name=2018-10892). [docker/engine#15](https://github.com/docker/engine/pull/15)\n*   Add `/proc/acpi` to masked paths to address [CVE-2018-10892](https://cve.mitre.org/cgi-bin/cvename.cgi?name=2018-10892). [docker/engine#14](https://github.com/docker/engine/pull/14)\n\n*   Fix bindmount autocreate race. [docker/engine#11](https://github.com/docker/engine/pull/11)\n\n### [Swarm Mode](#swarm-mode-1)\n\n*   List stacks for both Swarm and Kubernetes with --orchestrator=all in docker stack ls. Allow several occurrences of --namespace for Kubernetes with docker stack ls. [docker/cli#1031](https://github.com/docker/cli/pull/1031)\n*   Bump SwarmKit to remove deprecated grpc metadata wrappers. [moby/moby#36905](https://github.com/moby/moby/pull/36905)\n*   Issue an error for --orchestrator=all when working on mismatched Swarm and Kubernetes hosts. [docker/cli#1035](https://github.com/docker/cli/pull/1035)\n\n*   Fix broken swarm commands with Kubernetes defined as orchestrator. \"--orchestrator\" flag is no longer global but local to stack commands and subcommands [docker/cli#1137](https://github.com/docker/cli/pull/1137) [docker/cli#1139](https://github.com/docker/cli/pull/1139)\n\n*   Bump swarmkit to include task reaper fixes and more metrics. [docker/engine#13](https://github.com/docker/engine/pull/13)\n\n*   Avoid a leak when a service with unassigned tasks is deleted. [docker/engine#27](https://github.com/docker/engine/pull/27)\n*   Fix racy batching on the dispatcher. [docker/engine#27](https://github.com/docker/engine/pull/27)",
    "title": "Docker Engine 18.06 release notes | Docker Docs\n",
    "description": "",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/18.03/",
    "markdown": "# Docker Engine 18.03 release notes\n\n2018-04-26\n\n### [Client](#client)\n\n*   Fix error with merge compose file with networks [docker/cli#983](https://github.com/docker/cli/pull/983)\n\n*   Fix docker stack deploy re-deploying services after the service was updated with `--force` [docker/cli#963](https://github.com/docker/cli/pull/963)\n*   Fix docker version output alignment [docker/cli#965](https://github.com/docker/cli/pull/965)\n\n### [Runtime](#runtime)\n\n*   Fix AppArmor profiles not being applied to `docker exec` processes [moby/moby#36466](https://github.com/moby/moby/pull/36466)\n*   Don't sort plugin mount slice [moby/moby#36711](https://github.com/moby/moby/pull/36711)\n*   Daemon/cluster: handle partial attachment entries during configure [moby/moby#36769](https://github.com/moby/moby/pull/36769)\n\n*   Bump Golang to 1.9.5 [moby/moby#36779](https://github.com/moby/moby/pull/36779) [docker/cli#986](https://github.com/docker/cli/pull/986)\n\n*   Daemon/stats: more resilient cpu sampling [moby/moby#36519](https://github.com/moby/moby/pull/36519)\n\n*   Containerd: update to 1.0.3 release [moby/moby#36749](https://github.com/moby/moby/pull/36749)\n\n*   Fix Windows layer leak when write fails [moby/moby#36728](https://github.com/moby/moby/pull/36728)\n\n*   Don't make container mount unbindable [moby/moby#36768](https://github.com/moby/moby/pull/36768)\n\n*   Fix Daemon panics on container export after a daemon restart [moby/moby/36586](https://github.com/moby/moby/pull/36586)\n*   Fix digest cache being removed on autherrors [moby/moby#36509](https://github.com/moby/moby/pull/36509)\n*   Make sure plugin container is removed on failure [moby/moby#36715](https://github.com/moby/moby/pull/36715)\n*   Copy: avoid using all system memory with authz plugins [moby/moby#36595](https://github.com/moby/moby/pull/36595)\n*   Relax some libcontainerd client locking [moby/moby#36848](https://github.com/moby/moby/pull/36848)\n*   Update `hcsshim` to v0.6.10 to address [CVE-2018-8115](https://portal.msrc.microsoft.com/en-us/security-guidance/advisory/CVE-2018-8115)\n\n### [Swarm Mode](#swarm-mode)\n\n*   Increase raft Election tick to 10 times Heartbeat tick [moby/moby#36672](https://github.com/moby/moby/pull/36672)\n\n### [Networking](#networking)\n\n*   Gracefully remove LB endpoints from services [docker/libnetwork#2112](https://github.com/docker/libnetwork/pull/2112)\n*   Retry other external DNS servers on ServFail [docker/libnetwork#2121](https://github.com/docker/libnetwork/pull/2121)\n*   Improve scalabiltiy of bridge network isolation rules [docker/libnetwork#2117](https://github.com/docker/libnetwork/pull/2117)\n*   Allow for larger preset property values, do not override [docker/libnetwork#2124](https://github.com/docker/libnetwork/pull/2124)\n*   Prevent panics on concurrent reads/writes when calling `changeNodeState` [docker/libnetwork#2136](https://github.com/docker/libnetwork/pull/2136)\n\n2018-03-21\n\n### [Builder](#builder)\n\n*   Switch to -buildmode=pie [moby/moby#34369](https://github.com/moby/moby/pull/34369)\n*   Allow Dockerfile to be outside of build-context [docker/cli#886](https://github.com/docker/cli/pull/886)\n*   Builder: fix wrong cache hits building from tars [moby/moby#36329](https://github.com/moby/moby/pull/36329)\n\n*   Fixes files leaking to other images in a multi-stage build [moby/moby#36338](https://github.com/moby/moby/pull/36338)\n\n### [Client](#client-1)\n\n*   Simplify the marshaling of compose types.Config [docker/cli#895](https://github.com/docker/cli/pull/895)\n\n*   Add support for multiple composefile when deploying [docker/cli#569](https://github.com/docker/cli/pull/569)\n\n*   Fix broken Kubernetes stack flags [docker/cli#831](https://github.com/docker/cli/pull/831)\n*   Fix stack marshaling for Kubernetes [docker/cli#890](https://github.com/docker/cli/pull/890)\n*   Fix and simplify bash completion for service env, mounts and labels [docker/cli#682](https://github.com/docker/cli/pull/682)\n*   Fix `before` and `since` filter for `docker ps` [moby/moby#35938](https://github.com/moby/moby/pull/35938)\n*   Fix `--label-file` weird behavior [docker/cli#838](https://github.com/docker/cli/pull/838)\n*   Fix compilation of defaultCredentialStore() on unsupported platforms [docker/cli#872](https://github.com/docker/cli/pull/872)\n\n*   Improve and fix bash completion for images [docker/cli#717](https://github.com/docker/cli/pull/717)\n\n*   Added check for empty source in bind mount [docker/cli#824](https://github.com/docker/cli/pull/824)\n\n*   Fix TLS from environment variables in client [moby/moby#36270](https://github.com/moby/moby/pull/36270)\n\n*   docker build now runs faster when registry-specific credential helper(s) are configured [docker/cli#840](https://github.com/docker/cli/pull/840)\n*   Update event filter zsh completion with `disable`, `enable`, `install` and `remove` [docker/cli#372](https://github.com/docker/cli/pull/372)\n*   Produce errors when empty ids are passed into inspect calls [moby/moby#36144](https://github.com/moby/moby/pull/36144)\n*   Marshall version for the k8s controller [docker/cli#891](https://github.com/docker/cli/pull/891)\n*   Set a non-zero timeout for HTTP client communication with plugin backend [docker/cli#883](https://github.com/docker/cli/pull/883)\n\n*   Add DOCKER\\_TLS environment variable for --tls option [docker/cli#863](https://github.com/docker/cli/pull/863)\n*   Add --template-driver option for secrets/configs [docker/cli#896](https://github.com/docker/cli/pull/896)\n*   Move `docker trust` commands out of experimental [docker/cli#934](https://github.com/docker/cli/pull/934) [docker/cli#935](https://github.com/docker/cli/pull/935) [docker/cli#944](https://github.com/docker/cli/pull/944)\n\n### [Logging](#logging)\n\n*   AWS logs - don't add new lines to maximum sized events [moby/moby#36078](https://github.com/moby/moby/pull/36078)\n*   Move log validator logic after plugins are loaded [moby/moby#36306](https://github.com/moby/moby/pull/36306)\n*   Support a proxy in Splunk log driver [moby/moby#36220](https://github.com/moby/moby/pull/36220)\n\n*   Fix log tail with empty logs [moby/moby#36305](https://github.com/moby/moby/pull/36305)\n\n### [Networking](#networking-1)\n\n*   Libnetwork revendoring [moby/moby#36137](https://github.com/moby/moby/pull/36137)\n\n*   Fix for deadlock on exit with Memberlist revendor [docker/libnetwork#2040](https://github.com/docker/libnetwork/pull/2040)\n\n*   Fix user specified ndots option [docker/libnetwork#2065](https://github.com/docker/libnetwork/pull/2065)\n\n*   Fix to use ContainerID for Windows instead of SandboxID [docker/libnetwork#2010](https://github.com/docker/libnetwork/pull/2010)\n\n*   Verify NetworkingConfig to make sure EndpointSettings is not nil [moby/moby#36077](https://github.com/moby/moby/pull/36077)\n\n*   Fix `DockerNetworkInternalMode` issue [moby/moby#36298](https://github.com/moby/moby/pull/36298)\n*   Fix race in attachable network attachment [moby/moby#36191](https://github.com/moby/moby/pull/36191)\n*   Fix timeout issue of `InspectNetwork` on AArch64 [moby/moby#36257](https://github.com/moby/moby/pull/36257)\n\n*   Verbose info is missing for partial overlay ID [moby/moby#35989](https://github.com/moby/moby/pull/35989)\n*   Update `FindNetwork` to address network name duplications [moby/moby#30897](https://github.com/moby/moby/pull/30897)\n*   Disallow attaching ingress network [docker/swarmkit#2523](https://github.com/docker/swarmkit/pull/2523)\n\n*   Prevent implicit removal of the ingress network [moby/moby#36538](https://github.com/moby/moby/pull/36538)\n*   Fix stale HNS endpoints on Windows [moby/moby#36603](https://github.com/moby/moby/pull/36603)\n*   IPAM fixes for duplicate IP addresses [docker/libnetwork#2104](https://github.com/docker/libnetwork/pull/2104) [docker/libnetwork#2105](https://github.com/docker/libnetwork/pull/2105)\n\n### [Runtime](#runtime-1)\n\n*   Enable HotAdd for Windows [moby/moby#35414](https://github.com/moby/moby/pull/35414)\n*   LCOW: Graphdriver fix deadlock in hotRemoveVHDs [moby/moby#36114](https://github.com/moby/moby/pull/36114)\n*   LCOW: Regular mount if only one layer [moby/moby#36052](https://github.com/moby/moby/pull/36052)\n*   Remove interim env var LCOW\\_API\\_PLATFORM\\_IF\\_OMITTED [moby/moby#36269](https://github.com/moby/moby/pull/36269)\n*   Revendor Microsoft/opengcs @ v0.3.6 [moby/moby#36108](https://github.com/moby/moby/pull/36108)\n\n*   Fix issue of ExitCode and PID not show up in Task.Status.ContainerStatus [moby/moby#36150](https://github.com/moby/moby/pull/36150)\n*   Fix issue with plugin scanner going too deep [moby/moby#36119](https://github.com/moby/moby/pull/36119)\n\n*   Do not make graphdriver homes private mounts [moby/moby#36047](https://github.com/moby/moby/pull/36047)\n*   Do not recursive unmount on cleanup of zfs/btrfs [moby/moby#36237](https://github.com/moby/moby/pull/36237)\n*   Don't restore image if layer does not exist [moby/moby#36304](https://github.com/moby/moby/pull/36304)\n*   Adjust minimum API version for templated configs/secrets [moby/moby#36366](https://github.com/moby/moby/pull/36366)\n*   Bump containerd to 1.0.2 (cfd04396dc68220d1cecbe686a6cc3aa5ce3667c) [moby/moby#36308](https://github.com/moby/moby/pull/36308)\n*   Bump Golang to 1.9.4 [moby/moby#36243](https://github.com/moby/moby/pull/36243)\n*   Ensure daemon root is unmounted on shutdown [moby/moby#36107](https://github.com/moby/moby/pull/36107)\n*   Update runc to 6c55f98695e902427906eed2c799e566e3d3dfb5 [moby/moby#36222](https://github.com/moby/moby/pull/36222)\n\n*   Fix container cleanup on daemon restart [moby/moby#36249](https://github.com/moby/moby/pull/36249)\n\n*   Support SCTP port mapping (bump up API to v1.37) [moby/moby#33922](https://github.com/moby/moby/pull/33922)\n*   Support SCTP port mapping [docker/cli#278](https://github.com/docker/cli/pull/278)\n\n*   Fix Volumes property definition in ContainerConfig [moby/moby#35946](https://github.com/moby/moby/pull/35946)\n\n*   Bump moby and dependencies [docker/cli#829](https://github.com/docker/cli/pull/829)\n*   C.RWLayer: check for nil before use [moby/moby#36242](https://github.com/moby/moby/pull/36242)\n\n*   Add `REMOVE` and `ORPHANED` to TaskState [moby/moby#36146](https://github.com/moby/moby/pull/36146)\n\n*   Fixed error detection using `IsErrNotFound` and `IsErrNotImplemented` for `ContainerStatPath`, `CopyFromContainer`, and `CopyToContainer` methods [moby/moby#35979](https://github.com/moby/moby/pull/35979)\n\n*   Add an integration/internal/container helper package [moby/moby#36266](https://github.com/moby/moby/pull/36266)\n*   Add canonical import path [moby/moby#36194](https://github.com/moby/moby/pull/36194)\n*   Add/use container.Exec() to integration [moby/moby#36326](https://github.com/moby/moby/pull/36326)\n\n*   Fix \"--node-generic-resource\" singular/plural [moby/moby#36125](https://github.com/moby/moby/pull/36125)\n\n*   Daemon.cleanupContainer: nullify container RWLayer upon release [moby/moby#36160](https://github.com/moby/moby/pull/36160)\n*   Daemon: passdown the `--oom-kill-disable` option to containerd [moby/moby#36201](https://github.com/moby/moby/pull/36201)\n*   Display a warn message when there is binding ports and net mode is host [moby/moby#35510](https://github.com/moby/moby/pull/35510)\n*   Refresh containerd remotes on containerd restarted [moby/moby#36173](https://github.com/moby/moby/pull/36173)\n*   Set daemon root to use shared propagation [moby/moby#36096](https://github.com/moby/moby/pull/36096)\n*   Optimizations for recursive unmount [moby/moby#34379](https://github.com/moby/moby/pull/34379)\n*   Perform plugin mounts in the runtime [moby/moby#35829](https://github.com/moby/moby/pull/35829)\n*   Graphdriver: Fix RefCounter memory leak [moby/moby#36256](https://github.com/moby/moby/pull/36256)\n*   Use continuity fs package for volume copy [moby/moby#36290](https://github.com/moby/moby/pull/36290)\n*   Use proc/exe for reexec [moby/moby#36124](https://github.com/moby/moby/pull/36124)\n\n*   Add API support for templated secrets and configs [moby/moby#33702](https://github.com/moby/moby/pull/33702) and [moby/moby#36366](https://github.com/moby/moby/pull/36366)\n\n*   Use rslave propagation for mounts from daemon root [moby/moby#36055](https://github.com/moby/moby/pull/36055)\n\n*   Add /proc/keys to masked paths [moby/moby#36368](https://github.com/moby/moby/pull/36368)\n\n*   Bump Runc to 1.0.0-rc5 [moby/moby#36449](https://github.com/moby/moby/pull/36449)\n\n*   Fixes `runc exec` on big-endian architectures [moby/moby#36449](https://github.com/moby/moby/pull/36449)\n\n*   Use chroot when mount namespaces aren't provided [moby/moby#36449](https://github.com/moby/moby/pull/36449)\n\n*   Fix systemd slice expansion so that it could be consumed by cAdvisor [moby/moby#36449](https://github.com/moby/moby/pull/36449)\n*   Fix devices mounted with wrong uid/gid [moby/moby#36449](https://github.com/moby/moby/pull/36449)\n*   Fix read-only containers with IPC private mounts `/dev/shm` read-only [moby/moby#36526](https://github.com/moby/moby/pull/36526)\n\n### [Swarm Mode](#swarm-mode-1)\n\n*   Replace EC Private Key with PKCS#8 PEMs [docker/swarmkit#2246](https://github.com/docker/swarmkit/pull/2246)\n*   Fix IP overlap with empty EndpointSpec [docker/swarmkit #2505](https://github.com/docker/swarmkit/pull/2505)\n*   Add support for Support SCTP port mapping [docker/swarmkit#2298](https://github.com/docker/swarmkit/pull/2298)\n*   Do not reschedule tasks if only placement constraints change and are satisfied by the assigned node [docker/swarmkit#2496](https://github.com/docker/swarmkit/pull/2496)\n*   Ensure task reaper stopChan is closed no more than once [docker/swarmkit #2491](https://github.com/docker/swarmkit/pull/2491)\n*   Synchronization fixes [docker/swarmkit#2495](https://github.com/docker/swarmkit/pull/2495)\n*   Add log message to indicate message send retry if streaming unimplemented [docker/swarmkit#2483](https://github.com/docker/swarmkit/pull/2483)\n*   Debug logs for session, node events on dispatcher, heartbeats [docker/swarmkit#2486](https://github.com/docker/swarmkit/pull/2486)\n\n*   Add swarm types to bash completion event type filter [docker/cli#888](https://github.com/docker/cli/pull/888)\n\n*   Fix issue where network inspect does not show Created time for networks in swarm scope [moby/moby#36095](https://github.com/moby/moby/pull/36095)",
    "title": "Docker Engine 18.03 release notes | Docker Docs\n",
    "description": "",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/exporters/local-tar/",
    "markdown": "# Local and tar exporters | Docker Docs\n\nThe `local` and `tar` exporters output the root filesystem of the build result into a local directory. They're useful for producing artifacts that aren't container images.\n\n*   `local` exports files and directories.\n*   `tar` exports the same, but bundles the export into a tarball.\n\nBuild a container image using the `local` exporter:\n\nThe following table describes the available parameters:\n\n| Parameter | Type | Default | Description |\n| --- | --- | --- | --- |\n| `dest` | String |     | Path to copy files to |\n\nFor more information on the `local` or `tar` exporters, see the [BuildKit README](https://github.com/moby/buildkit/blob/master/README.md#local-directory).",
    "title": "Local and tar exporters | Docker Docs\n",
    "description": "The local and tar exporters save the build result to the local filesystem ",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/delete-service/",
    "markdown": "# Delete the service running on the swarm\n\nThe remaining steps in the tutorial don't use the `helloworld` service, so now you can delete the service from the swarm.\n\n1.  If you haven't already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n    \n2.  Run `docker service rm helloworld` to remove the `helloworld` service.\n    \n3.  Run `docker service inspect <SERVICE-ID>` to verify that the swarm manager removed the service. The CLI returns a message that the service is not found:\n    \n4.  Even though the service no longer exists, the task containers take a few seconds to clean up. You can use `docker ps` on the nodes to verify when the tasks have been removed.\n    \n\nNext, you'll set up a new service and apply a rolling update.",
    "title": "Delete the service running on the swarm | Docker Docs\n",
    "description": "Remove the service from the swarm",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/security/rootless/",
    "markdown": "# Run the Docker daemon as a non-root user (Rootless mode)\n\nRootless mode allows running the Docker daemon and containers as a non-root user to mitigate potential vulnerabilities in the daemon and the container runtime.\n\nRootless mode does not require root privileges even during the installation of the Docker daemon, as long as the [prerequisites](#prerequisites) are met.\n\nRootless mode executes the Docker daemon and containers inside a user namespace. This is very similar to [`userns-remap` mode](https://docs.docker.com/engine/security/userns-remap/), except that with `userns-remap` mode, the daemon itself is running with root privileges, whereas in rootless mode, both the daemon and the container are running without root privileges.\n\nRootless mode does not use binaries with `SETUID` bits or file capabilities, except `newuidmap` and `newgidmap`, which are needed to allow multiple UIDs/GIDs to be used in the user namespace.\n\n*   You must install `newuidmap` and `newgidmap` on the host. These commands are provided by the `uidmap` package on most distros.\n    \n*   `/etc/subuid` and `/etc/subgid` should contain at least 65,536 subordinate UIDs/GIDs for the user. In the following example, the user `testuser` has 65,536 subordinate UIDs/GIDs (231072-296607).\n    \n\n### [Distribution-specific hint](#distribution-specific-hint)\n\n> **Tip**\n> \n> We recommend that you use the Ubuntu kernel.\n\n* * *\n\n*   Install `dbus-user-session` package if not installed. Run `sudo apt-get install -y dbus-user-session` and relogin.\n    \n*   Install `uidmap` package if not installed. Run `sudo apt-get install -y uidmap`.\n    \n*   If running in a terminal where the user was not directly logged into, you will need to install `systemd-container` with `sudo apt-get install -y systemd-container`, then switch to TheUser with the command `sudo machinectl shell TheUser@`.\n    \n*   `overlay2` storage driver is enabled by default ( [Ubuntu-specific kernel patch](https://kernel.ubuntu.com/git/ubuntu/ubuntu-bionic.git/commit/fs/overlayfs?id=3b7da90f28fe1ed4b79ef2d994c81efbc58f1144)).\n    \n*   Ubuntu 24.04 and later enables restricted unprivileged user namespaces by default, which prevents unprivileged processes in creating user namespaces unless an AppArmor profile is configured to allow programs to use unprivileged user namespaces.\n    \n    If you install `docker-ce-rootless-extras` using the deb package (`apt-get install docker-ce-rootless-extras`), then the AppArmor profile for `rootlesskit` is already bundled with the `apparmor` deb package. With this installation method, you don't need to add any manual the AppArmor configuration. If you install the rootless extras using the [installation script](https://get.docker.com/rootless), however, you must add an AppArmor profile for `rootlesskit` manually:\n    \n    1.  Create and install the currently logged-in user's AppArmor profile:\n        \n    2.  Restart AppArmor.\n        \n\n*   Install `dbus-user-session` package if not installed. Run `sudo apt-get install -y dbus-user-session` and relogin.\n    \n*   For Debian 10, add `kernel.unprivileged_userns_clone=1` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system`. This step is not required on Debian 11.\n    \n*   Installing `fuse-overlayfs` is recommended. Run `sudo apt-get install -y fuse-overlayfs`. Using `overlay2` storage driver with Debian-specific modprobe option `sudo modprobe overlay permit_mounts_in_userns=1` is also possible, however, highly discouraged due to [instability](https://github.com/moby/moby/issues/42302).\n    \n*   Rootless docker requires version of `slirp4netns` greater than `v0.4.0` (when `vpnkit` is not installed). Check you have this with\n    \n    If you do not have this download and install with `sudo apt-get install -y slirp4netns` or download the latest [release](https://github.com/rootless-containers/slirp4netns/releases).\n    \n\n*   Installing `fuse-overlayfs` is recommended. Run `sudo pacman -S fuse-overlayfs`.\n    \n*   Add `kernel.unprivileged_userns_clone=1` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system`\n    \n\n*   Installing `fuse-overlayfs` is recommended. Run `sudo zypper install -y fuse-overlayfs`.\n    \n*   `sudo modprobe ip_tables iptable_mangle iptable_nat iptable_filter` is required. This might be required on other distros as well depending on the configuration.\n    \n*   Known to work on openSUSE 15 and SLES 15.\n    \n\n*   Installing `fuse-overlayfs` is recommended. Run `sudo dnf install -y fuse-overlayfs`.\n    \n*   You might need `sudo dnf install -y iptables`.\n    \n\n* * *\n\n*   Only the following storage drivers are supported:\n    *   `overlay2` (only if running with kernel 5.11 or later, or Ubuntu-flavored kernel)\n    *   `fuse-overlayfs` (only if running with kernel 4.18 or later, and `fuse-overlayfs` is installed)\n    *   `btrfs` (only if running with kernel 4.18 or later, or `~/.local/share/docker` is mounted with `user_subvol_rm_allowed` mount option)\n    *   `vfs`\n*   Cgroup is supported only when running with cgroup v2 and systemd. See [Limiting resources](#limiting-resources).\n*   Following features are not supported:\n    *   AppArmor\n    *   Checkpoint\n    *   Overlay network\n    *   Exposing SCTP ports\n*   To use the `ping` command, see [Routing ping packets](#routing-ping-packets).\n*   To expose privileged TCP/UDP ports (< 1024), see [Exposing privileged ports](#exposing-privileged-ports).\n*   `IPAddress` shown in `docker inspect` is namespaced inside RootlessKit's network namespace. This means the IP address is not reachable from the host without `nsenter`\\-ing into the network namespace.\n*   Host network (`docker run --net=host`) is also namespaced inside RootlessKit.\n*   NFS mounts as the docker \"data-root\" is not supported. This limitation is not specific to rootless mode.\n\n> **Note**\n> \n> If the system-wide Docker daemon is already running, consider disabling it:\n> \n> Should you choose not to shut down the `docker` service and socket, you will need to use the `--force` parameter in the next section. There are no known issues, but until you shutdown and disable you're still running rootful Docker.\n\n* * *\n\nIf you installed Docker 20.10 or later with [RPM/DEB packages](https://docs.docker.com/engine/install), you should have `dockerd-rootless-setuptool.sh` in `/usr/bin`.\n\nRun `dockerd-rootless-setuptool.sh install` as a non-root user to set up the daemon:\n\nIf `dockerd-rootless-setuptool.sh` is not present, you may need to install the `docker-ce-rootless-extras` package manually, e.g.,\n\nIf you do not have permission to run package managers like `apt-get` and `dnf`, consider using the installation script available at [https://get.docker.com/rootless](https://get.docker.com/rootless). Since static packages are not available for `s390x`, hence it is not supported for `s390x`.\n\nThe binaries will be installed at `~/bin`.\n\n* * *\n\nSee [Troubleshooting](#troubleshooting) if you faced an error.\n\nTo remove the systemd service of the Docker daemon, run `dockerd-rootless-setuptool.sh uninstall`:\n\nUnset environment variables PATH and DOCKER\\_HOST if you have added them to `~/.bashrc`.\n\nTo remove the data directory, run `rootlesskit rm -rf ~/.local/share/docker`.\n\nTo remove the binaries, remove `docker-ce-rootless-extras` package if you installed Docker with package managers. If you installed Docker with [https://get.docker.com/rootless](https://get.docker.com/rootless) ( [Install without packages](#install)), remove the binary files under `~/bin`:\n\n### [Daemon](#daemon)\n\n* * *\n\nThe systemd unit file is installed as `~/.config/systemd/user/docker.service`.\n\nUse `systemctl --user` to manage the lifecycle of the daemon:\n\nTo launch the daemon on system startup, enable the systemd service and lingering:\n\nStarting Rootless Docker as a systemd-wide service (`/etc/systemd/system/docker.service`) is not supported, even with the `User=` directive.\n\nTo run the daemon directly without systemd, you need to run `dockerd-rootless.sh` instead of `dockerd`.\n\nThe following environment variables must be set:\n\n*   `$HOME`: the home directory\n*   `$XDG_RUNTIME_DIR`: an ephemeral directory that is only accessible by the expected user, e,g, `~/.docker/run`. The directory should be removed on every host shutdown. The directory can be on tmpfs, however, should not be under `/tmp`. Locating this directory under `/tmp` might be vulnerable to TOCTOU attack.\n\n* * *\n\nRemarks about directory paths:\n\n*   The socket path is set to `$XDG_RUNTIME_DIR/docker.sock` by default. `$XDG_RUNTIME_DIR` is typically set to `/run/user/$UID`.\n*   The data dir is set to `~/.local/share/docker` by default. The data dir should not be on NFS.\n*   The daemon config dir is set to `~/.config/docker` by default. This directory is different from `~/.docker` that is used by the client.\n\n### [Client](#client)\n\nYou need to specify either the socket path or the CLI context explicitly.\n\nTo specify the socket path using `$DOCKER_HOST`:\n\nTo specify the CLI context using `docker context`:\n\n### [Rootless Docker in Docker](#rootless-docker-in-docker)\n\nTo run Rootless Docker inside \"rootful\" Docker, use the `docker:<version>-dind-rootless` image instead of `docker:<version>-dind`.\n\nThe `docker:<version>-dind-rootless` image runs as a non-root user (UID 1000). However, `--privileged` is required for disabling seccomp, AppArmor, and mount masks.\n\n### [Expose Docker API socket through TCP](#expose-docker-api-socket-through-tcp)\n\nTo expose the Docker API socket through TCP, you need to launch `dockerd-rootless.sh` with `DOCKERD_ROOTLESS_ROOTLESSKIT_FLAGS=\"-p 0.0.0.0:2376:2376/tcp\"`.\n\n### [Expose Docker API socket through SSH](#expose-docker-api-socket-through-ssh)\n\nTo expose the Docker API socket through SSH, you need to make sure `$DOCKER_HOST` is set on the remote host.\n\n### [Routing ping packets](#routing-ping-packets)\n\nOn some distributions, `ping` does not work by default.\n\nAdd `net.ipv4.ping_group_range = 0 2147483647` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system` to allow using `ping`.\n\n### [Exposing privileged ports](#exposing-privileged-ports)\n\nTo expose privileged ports (< 1024), set `CAP_NET_BIND_SERVICE` on `rootlesskit` binary and restart the daemon.\n\nOr add `net.ipv4.ip_unprivileged_port_start=0` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system`.\n\n### [Limiting resources](#limiting-resources)\n\nLimiting resources with cgroup-related `docker run` flags such as `--cpus`, `--memory`, `--pids-limit` is supported only when running with cgroup v2 and systemd. See [Changing cgroup version](https://docs.docker.com/config/containers/runmetrics/) to enable cgroup v2.\n\nIf `docker info` shows `none` as `Cgroup Driver`, the conditions are not satisfied. When these conditions are not satisfied, rootless mode ignores the cgroup-related `docker run` flags. See [Limiting resources without cgroup](#limiting-resources-without-cgroup) for workarounds.\n\nIf `docker info` shows `systemd` as `Cgroup Driver`, the conditions are satisfied. However, typically, only `memory` and `pids` controllers are delegated to non-root users by default.\n\nTo allow delegation of all controllers, you need to change the systemd configuration as follows:\n\n> **Note**\n> \n> Delegating `cpuset` requires systemd 244 or later.\n\n#### [Limiting resources without cgroup](#limiting-resources-without-cgroup)\n\nEven when cgroup is not available, you can still use the traditional `ulimit` and [`cpulimit`](https://github.com/opsengine/cpulimit), though they work in process-granularity rather than in container-granularity, and can be arbitrarily disabled by the container process.\n\nFor example:\n\n*   To limit CPU usage to 0.5 cores (similar to `docker run --cpus 0.5`): `docker run <IMAGE> cpulimit --limit=50 --include-children <COMMAND>`\n    \n*   To limit max VSZ to 64MiB (similar to `docker run --memory 64m`): `docker run <IMAGE> sh -c \"ulimit -v 65536; <COMMAND>\"`\n    \n*   To limit max number of processes to 100 per namespaced UID 2000 (similar to `docker run --pids-limit=100`): `docker run --user 2000 --ulimit nproc=100 <IMAGE> <COMMAND>`\n    \n\n### [Unable to install with systemd when systemd is present on the system](#unable-to-install-with-systemd-when-systemd-is-present-on-the-system)\n\n`rootlesskit` cannot detect systemd properly if you switch to your user via `sudo su`. For users which cannot be logged-in, you must use the `machinectl` command which is part of the `systemd-container` package. After installing `systemd-container` switch to `myuser` with the following command:\n\nWhere `myuser@` is your desired username and @ signifies this machine.\n\n### [Errors when starting the Docker daemon](#errors-when-starting-the-docker-daemon)\n\n**\\[rootlesskit:parent\\] error: failed to start the child: fork/exec /proc/self/exe: operation not permitted**\n\nThis error occurs mostly when the value of `/proc/sys/kernel/unprivileged_userns_clone` is set to 0:\n\nTo fix this issue, add `kernel.unprivileged_userns_clone=1` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system`.\n\n**\\[rootlesskit:parent\\] error: failed to start the child: fork/exec /proc/self/exe: no space left on device**\n\nThis error occurs mostly when the value of `/proc/sys/user/max_user_namespaces` is too small:\n\nTo fix this issue, add `user.max_user_namespaces=28633` to `/etc/sysctl.conf` (or `/etc/sysctl.d`) and run `sudo sysctl --system`.\n\n**\\[rootlesskit:parent\\] error: failed to setup UID/GID map: failed to compute uid/gid map: No subuid ranges found for user 1001 (\"testuser\")**\n\nThis error occurs when `/etc/subuid` and `/etc/subgid` are not configured. See [Prerequisites](#prerequisites).\n\n**could not get XDG\\_RUNTIME\\_DIR**\n\nThis error occurs when `$XDG_RUNTIME_DIR` is not set.\n\nOn a non-systemd host, you need to create a directory and then set the path:\n\n> **Note**\n> \n> You must remove the directory every time you log out.\n\nOn a systemd host, log into the host using `pam_systemd` (see below). The value is automatically set to `/run/user/$UID` and cleaned up on every logout.\n\n**`systemctl --user` fails with \"Failed to connect to bus: No such file or directory\"**\n\nThis error occurs mostly when you switch from the root user to an non-root user with `sudo`:\n\nInstead of `sudo -iu <USERNAME>`, you need to log in using `pam_systemd`. For example:\n\n*   Log in through the graphic console\n*   `ssh <USERNAME>@localhost`\n*   `machinectl shell <USERNAME>@`\n\n**The daemon does not start up automatically**\n\nYou need `sudo loginctl enable-linger $(whoami)` to enable the daemon to start up automatically. See [Usage](#usage).\n\n**iptables failed: iptables -t nat -N DOCKER: Fatal: can't open lock file /run/xtables.lock: Permission denied**\n\nThis error may happen with an older version of Docker when SELinux is enabled on the host.\n\nThe issue has been fixed in Docker 20.10.8. A known workaround for older version of Docker is to run the following commands to disable SELinux for `iptables`:\n\n### [`docker pull` errors](#docker-pull-errors)\n\n**docker: failed to register layer: Error processing tar file(exit status 1): lchown <FILE>: invalid argument**\n\nThis error occurs when the number of available entries in `/etc/subuid` or `/etc/subgid` is not sufficient. The number of entries required vary across images. However, 65,536 entries are sufficient for most images. See [Prerequisites](#prerequisites).\n\n**docker: failed to register layer: ApplyLayer exit status 1 stdout: stderr: lchown <FILE>: operation not permitted**\n\nThis error occurs mostly when `~/.local/share/docker` is located on NFS.\n\nA workaround is to specify non-NFS `data-root` directory in `~/.config/docker/daemon.json` as follows:\n\n### [`docker run` errors](#docker-run-errors)\n\n**docker: Error response from daemon: OCI runtime create failed: ...: read unix @->/run/systemd/private: read: connection reset by peer: unknown.**\n\nThis error occurs on cgroup v2 hosts mostly when the dbus daemon is not running for the user.\n\nTo fix the issue, run `sudo apt-get install -y dbus-user-session` or `sudo dnf install -y dbus-daemon`, and then relogin.\n\nIf the error still occurs, try running `systemctl --user enable --now dbus` (without sudo).\n\n**`--cpus`, `--memory`, and `--pids-limit` are ignored**\n\nThis is an expected behavior on cgroup v1 mode. To use these flags, the host needs to be configured for enabling cgroup v2. For more information, see [Limiting resources](#limiting-resources).\n\n### [Networking errors](#networking-errors)\n\nThis section provides troubleshooting tips for networking in rootless mode.\n\nNetworking in rootless mode is supported via network and port drivers in RootlessKit. Network performance and characteristics depend on the combination of network and port driver you use. If you're experiencing unexpected behavior or performance related to networking, review the following table which shows the configurations supported by RootlessKit, and how they compare:\n\n| Network driver | Port driver | Net throughput | Port throughput | Source IP propagation | No SUID | Note |\n| --- | --- | --- | --- | --- | --- | --- |\n| `slirp4netns` | `builtin` | Slow | Fast ✅ | ❌   | ✅   | Default in a typical setup |\n| `vpnkit` | `builtin` | Slow | Fast ✅ | ❌   | ✅   | Default when `slirp4netns` isn't installed |\n| `slirp4netns` | `slirp4netns` | Slow | Slow | ✅   | ✅   |     |\n| `pasta` | `implicit` | Slow | Fast ✅ | ✅   | ✅   | Experimental; Needs pasta version 2023\\_12\\_04 or later |\n| `lxc-user-nic` | `builtin` | Fast ✅ | Fast ✅ | ❌   | ❌   | Experimental |\n| `bypass4netns` | `bypass4netns` | Fast ✅ | Fast ✅ | ✅   | ✅   | **Note:** Not integrated to RootlessKit as it needs a custom seccomp profile |\n\nFor information about troubleshooting specific networking issues, see:\n\n*   [`docker run -p` fails with `cannot expose privileged port`](#docker-run--p-fails-with-cannot-expose-privileged-port)\n*   [Ping doesn't work](#ping-doesnt-work)\n*   [`IPAddress` shown in `docker inspect` is unreachable](#ipaddress-shown-in-docker-inspect-is-unreachable)\n*   [`--net=host` doesn't listen ports on the host network namespace](#--nethost-doesnt-listen-ports-on-the-host-network-namespace)\n*   [Newtork is slow](#network-is-slow)\n*   [`docker run -p` does not propagate source IP addresses](#docker-run--p-does-not-propagate-source-ip-addresses)\n\n#### [`docker run -p` fails with `cannot expose privileged port`](#docker-run--p-fails-with-cannot-expose-privileged-port)\n\n`docker run -p` fails with this error when a privileged port (< 1024) is specified as the host port.\n\nWhen you experience this error, consider using an unprivileged port instead. For example, 8080 instead of 80.\n\nTo allow exposing privileged ports, see [Exposing privileged ports](#exposing-privileged-ports).\n\n#### [Ping doesn't work](#ping-doesnt-work)\n\nPing does not work when `/proc/sys/net/ipv4/ping_group_range` is set to `1 0`:\n\nFor details, see [Routing ping packets](#routing-ping-packets).\n\n#### [`IPAddress` shown in `docker inspect` is unreachable](#ipaddress-shown-in-docker-inspect-is-unreachable)\n\nThis is an expected behavior, as the daemon is namespaced inside RootlessKit's network namespace. Use `docker run -p` instead.\n\n#### [`--net=host` doesn't listen ports on the host network namespace](#--nethost-doesnt-listen-ports-on-the-host-network-namespace)\n\nThis is an expected behavior, as the daemon is namespaced inside RootlessKit's network namespace. Use `docker run -p` instead.\n\n#### [Network is slow](#network-is-slow)\n\nDocker with rootless mode uses [slirp4netns](https://github.com/rootless-containers/slirp4netns) as the default network stack if slirp4netns v0.4.0 or later is installed. If slirp4netns is not installed, Docker falls back to [VPNKit](https://github.com/moby/vpnkit). Installing slirp4netns may improve the network throughput.\n\nFor more information about network drivers for RootlessKit, see [RootlessKit documentation](https://github.com/rootless-containers/rootlesskit/blob/v2.0.0/docs/network.md).\n\nAlso, changing MTU value may improve the throughput. The MTU value can be specified by creating `~/.config/systemd/user/docker.service.d/override.conf` with the following content:\n\nAnd then restart the daemon:\n\n#### [`docker run -p` does not propagate source IP addresses](#docker-run--p-does-not-propagate-source-ip-addresses)\n\nThis is because Docker in rootless mode uses RootlessKit's `builtin` port driver by default, which doesn't support source IP propagation. To enable source IP propagation, you can:\n\n*   Use the `slirp4netns` RootlessKit port driver\n*   Use the `pasta` RootlessKit network driver, with the `implicit` port driver\n\nThe `pasta` network driver is experimental, but provides improved throughput performance compared to the `slirp4netns` port driver. The `pasta` driver requires Docker Engine version 25.0 or later.\n\nTo change the RootlessKit networking configuration:\n\n1.  Create a file at `~/.config/systemd/user/docker.service.d/override.conf`.\n    \n2.  Add the following contents, depending on which configuration you would like to use:\n    \n    *   `slirp4netns`\n        \n    *   `pasta` network driver with `implicit` port driver\n        \n3.  Restart the daemon:\n    \n\nFor more information about networking options for RootlessKit, see:\n\n*   [Network drivers](https://github.com/rootless-containers/rootlesskit/blob/v2.0.0/docs/network.md)\n*   [Port drivers](https://github.com/rootless-containers/rootlesskit/blob/v2.0.0/docs/port.md)\n\n### [Tips for debugging](#tips-for-debugging)\n\n**Entering into `dockerd` namespaces**\n\nThe `dockerd-rootless.sh` script executes `dockerd` in its own user, mount, and network namespaces.\n\nFor debugging, you can enter the namespaces by running `nsenter -U --preserve-credentials -n -m -t $(cat $XDG_RUNTIME_DIR/docker.pid)`.",
    "title": "Run the Docker daemon as a non-root user (Rootless mode) | Docker Docs\n",
    "description": "Run the Docker daemon as a non-root user (Rootless mode)",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/exporters/oci-docker/",
    "markdown": "# OCI and Docker exporters | Docker Docs\n\nThe `oci` exporter outputs the build result into an [OCI image layout](https://github.com/opencontainers/image-spec/blob/main/image-layout.md) tarball. The `docker` exporter behaves the same way, except it exports a Docker image layout instead.\n\nThe [`docker` driver](https://docs.docker.com/build/drivers/docker/) doesn't support these exporters. You must use `docker-container` or some other driver if you want to generate these outputs.\n\nBuild a container image using the `oci` and `docker` exporters:\n\nThe following table describes the available parameters:\n\n| Parameter | Type | Default | Description |\n| --- | --- | --- | --- |\n| `name` | String |     | Specify image name(s) |\n| `dest` | String |     | Path |\n| `tar` | `true`,`false` | `true` | Bundle the output into a tarball layout |\n| `compression` | `uncompressed`,`gzip`,`estargz`,`zstd` | `gzip` | Compression type, see [compression](https://docs.docker.com/build/exporters/#compression) |\n| `compression-level` | `0..22` |     | Compression level, see [compression](https://docs.docker.com/build/exporters/#compression) |\n| `force-compression` | `true`,`false` | `false` | Forcefully apply compression, see [compression](https://docs.docker.com/build/exporters/#compression) |\n| `oci-mediatypes` | `true`,`false` |     | Use OCI media types in exporter manifests. Defaults to `true` for `type=oci`, and `false` for `type=docker`. See [OCI Media types](https://docs.docker.com/build/exporters/#oci-media-types) |\n| `annotation.<key>` | String |     | Attach an annotation with the respective `key` and `value` to the built image,see [annotations](#annotations) |\n\nThese exporters support adding OCI annotation using `annotation` parameter, followed by the annotation name using dot notation. The following example sets the `org.opencontainers.image.title` annotation:\n\nFor more information about annotations, see [BuildKit documentation](https://github.com/moby/buildkit/blob/master/docs/annotations.md).\n\nFor more information on the `oci` or `docker` exporters, see the [BuildKit README](https://github.com/moby/buildkit/blob/master/README.md#docker-tarball).",
    "title": "OCI and Docker exporters | Docker Docs\n",
    "description": "The OCI and Docker exporters create an image layout tarball on the local filesystem ",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/18.02/",
    "markdown": "# Docker Engine 18.02 release notes\n\n2018-02-07\n\n### [Builder](#builder)\n\n*   Gitutils: fix checking out submodules [moby/moby#35737](https://github.com/moby/moby/pull/35737)\n\n### [Client](#client)\n\n*   Attach: Ensure attach exit code matches container's [docker/cli#696](https://github.com/docker/cli/pull/696)\n\n*   Added support for tmpfs-mode in compose file [docker/cli#808](https://github.com/docker/cli/pull/808)\n*   Adds a new compose file version 3.6 [docker/cli#808](https://github.com/docker/cli/pull/808)\n\n*   Fix issue of filter in `docker ps` where `health=starting` returns nothing [moby/moby#35940](https://github.com/moby/moby/pull/35940)\n\n*   Improve presentation of published port ranges [docker/cli#581](https://github.com/docker/cli/pull/581)\n\n*   Bump Go to 1.9.3 [docker/cli#827](https://github.com/docker/cli/pull/827)\n\n*   Fix broken Kubernetes stack flags [docker/cli#831](https://github.com/docker/cli/pull/831)\n\n*   Annotate \"stack\" commands to be \"swarm\" and \"kubernetes\" [docker/cli#804](https://github.com/docker/cli/pull/804)\n\n### [Experimental](#experimental)\n\n*   Add manifest command [docker/cli#138](https://github.com/docker/cli/pull/138)\n\n*   LCOW remotefs - return error in Read() implementation [moby/moby#36051](https://github.com/moby/moby/pull/36051)\n\n*   LCOW: Coalesce daemon stores, allow dual LCOW and WCOW mode [moby/moby#34859](https://github.com/moby/moby/pull/34859)\n\n*   LCOW: Fix OpenFile parameters [moby/moby#36043](https://github.com/moby/moby/pull/36043)\n\n*   LCOW: Raise minimum requirement to Windows RS3 RTM build (16299) [moby/moby#36065](https://github.com/moby/moby/pull/36065)\n\n### [Logging](#logging)\n\n*   Improve daemon config reload; log active configuration [moby/moby#36019](https://github.com/moby/moby/pull/36019)\n\n*   Fixed error detection using IsErrNotFound and IsErrNotImplemented for the ContainerLogs method [moby/moby#36000](https://github.com/moby/moby/pull/36000)\n\n*   Add journald tag as SYSLOG\\_IDENTIFIER [moby/moby#35570](https://github.com/moby/moby/pull/35570)\n\n*   Splunk: limit the reader size on error responses [moby/moby#35509](https://github.com/moby/moby/pull/35509)\n\n### [Networking](#networking)\n\n*   Disable service on release network results in zero-downtime deployments with rolling upgrades [moby/moby#35960](https://github.com/moby/moby/pull/35960)\n\n*   Fix services failing to start if multiple networks with the same name exist in different spaces [moby/moby#30897](https://github.com/moby/moby/pull/30897)\n*   Fix duplicate networks being added with `docker service update --network-add` [docker/cli#780](https://github.com/docker/cli/pull/780)\n*   Fixing ingress network when upgrading from 17.09 to 17.12. [moby/moby#36003](https://github.com/moby/moby/pull/36003)\n*   Fix ndots configuration [docker/libnetwork#1995](https://github.com/docker/libnetwork/pull/1995)\n*   Fix IPV6 networking being deconfigured if live-restore is enabled [docker/libnetwork#2043](https://github.com/docker/libnetwork/pull/2043)\n\n*   Add support for MX type DNS queries in the embedded DNS server [docker/libnetwork#2041](https://github.com/docker/libnetwork/pull/2041)\n\n### [Packaging](#packaging)\n\n*   Added packaging for Fedora 26, Fedora 27, and Centos 7 on aarch64 [docker/docker-ce-packaging#71](https://github.com/docker/docker-ce-packaging/pull/71)\n\n*   Removed support for Ubuntu Zesty [docker/docker-ce-packaging#73](https://github.com/docker/docker-ce-packaging/pull/73)\n*   Removed support for Fedora 25 [docker/docker-ce-packaging#72](https://github.com/docker/docker-ce-packaging/pull/72)\n\n### [Runtime](#runtime)\n\n*   Fixes unexpected Docker Daemon shutdown based on pipe error [moby/moby#35968](https://github.com/moby/moby/pull/35968)\n*   Fix some occurrences of hcsshim::ImportLayer failed in Win32: The system cannot find the path specified [moby/moby#35924](https://github.com/moby/moby/pull/35924)\n\n*   Windows: increase the maximum layer size during build to 127GB [moby/moby#35925](https://github.com/moby/moby/pull/35925)\n\n*   Fix Devicemapper: Error running DeleteDevice dm\\_task\\_run failed [moby/moby#35919](https://github.com/moby/moby/pull/35919)\n\n*   Introduce « exec\\_die » event [moby/moby#35744](https://github.com/moby/moby/pull/35744)\n\n*   Update API to version 1.36 [moby/moby#35744](https://github.com/moby/moby/pull/35744)\n\n*   Fix `docker update` not updating cpu quota, and cpu-period of a running container [moby/moby#36030](https://github.com/moby/moby/pull/36030)\n\n*   Make container shm parent unbindable [moby/moby#35830](https://github.com/moby/moby/pull/35830)\n\n*   Make image (layer) downloads faster by using pigz [moby/moby#35697](https://github.com/moby/moby/pull/35697)\n*   Protect the daemon from volume plugins that are slow or deadlocked [moby/moby#35441](https://github.com/moby/moby/pull/35441)\n\n*   Fix `DOCKER_RAMDISK` environment variable not being honoured [moby/moby#35957](https://github.com/moby/moby/pull/35957)\n\n*   Bump containerd to 1.0.1 (9b55aab90508bd389d7654c4baf173a981477d55) [moby/moby#35986](https://github.com/moby/moby/pull/35986)\n*   Update runc to fix hang during start and exec [moby/moby#36097](https://github.com/moby/moby/pull/36097)\n\n*   Fix \"--node-generic-resource\" singular/plural [moby/moby#36125](https://github.com/moby/moby/pull/36125)",
    "title": "Docker Engine 18.02 release notes | Docker Docs\n",
    "description": "",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/rolling-update/",
    "markdown": "# Apply rolling updates to a service\n\nIn a previous step of the tutorial, you [scaled](https://docs.docker.com/engine/swarm/swarm-tutorial/scale-service/) the number of instances of a service. In this part of the tutorial, you deploy a service based on the Redis 3.0.6 container tag. Then you upgrade the service to use the Redis 3.0.7 container image using rolling updates.\n\n1.  If you haven't already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n    \n2.  Deploy your Redis tag to the swarm and configure the swarm with a 10 second update delay. Note that the following example shows an older Redis tag:\n    \n    You configure the rolling update policy at service deployment time.\n    \n    The `--update-delay` flag configures the time delay between updates to a service task or sets of tasks. You can describe the time `T` as a combination of the number of seconds `Ts`, minutes `Tm`, or hours `Th`. So `10m30s` indicates a 10 minute 30 second delay.\n    \n    By default the scheduler updates 1 task at a time. You can pass the `--update-parallelism` flag to configure the maximum number of service tasks that the scheduler updates simultaneously.\n    \n    By default, when an update to an individual task returns a state of `RUNNING`, the scheduler schedules another task to update until all tasks are updated. If at any time during an update a task returns `FAILED`, the scheduler pauses the update. You can control the behavior using the `--update-failure-action` flag for `docker service create` or `docker service update`.\n    \n3.  Inspect the `redis` service:\n    \n4.  Now you can update the container image for `redis`. The swarm manager applies the update to nodes according to the `UpdateConfig` policy:\n    \n    The scheduler applies rolling updates as follows by default:\n    \n    *   Stop the first task.\n    *   Schedule update for the stopped task.\n    *   Start the container for the updated task.\n    *   If the update to a task returns `RUNNING`, wait for the specified delay period then start the next task.\n    *   If, at any time during the update, a task returns `FAILED`, pause the update.\n5.  Run `docker service inspect --pretty redis` to see the new image in the desired state:\n    \n    The output of `service inspect` shows if your update paused due to failure:\n    \n    To restart a paused update run `docker service update <SERVICE-ID>`. For example:\n    \n    To avoid repeating certain update failures, you may need to reconfigure the service by passing flags to `docker service update`.\n    \n6.  Run `docker service ps <SERVICE-ID>` to watch the rolling update:\n    \n    Before Swarm updates all of the tasks, you can see that some are running `redis:3.0.6` while others are running `redis:3.0.7`. The output above shows the state once the rolling updates are done.\n    \n\nNext, you'll learn how to drain a node in the swarm.",
    "title": "Apply rolling updates to a service | Docker Docs\n",
    "description": "Apply rolling updates to a service on the swarm",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/cache/",
    "markdown": "# Docker build cache | Docker Docs\n\nWhen you build the same Docker image multiple times, knowing how to optimize the build cache is a great tool for making sure the builds run fast.\n\nUnderstanding Docker's build cache helps you write better Dockerfiles that result in faster builds.\n\nThe following example shows a small Dockerfile for a program written in C.\n\nEach instruction in this Dockerfile translates to a layer in your final image. You can think of image layers as a stack, with each layer adding more content on top of the layers that came before it:\n\n![Image layer diagram](https://docs.docker.com/build/images/cache-stack.png)\n\nWhenever a layer changes, that layer will need to be re-built. For example, suppose you make a change to your program in the `main.c` file. After this change, the `COPY` command will have to run again in order for those changes to appear in the image. In other words, Docker will invalidate the cache for this layer.\n\nIf a layer changes, all other layers that come after it are also affected. When the layer with the `COPY` command gets invalidated, all layers that follow will need to run again, too:\n\n![Image layer diagram, showing cache invalidation](https://docs.docker.com/build/images/cache-stack-invalidated.png)\n\nAnd that's the Docker build cache in a nutshell. Once a layer changes, then all downstream layers need to be rebuilt as well. Even if they wouldn't build anything differently, they still need to re-run.\n\nFor more details about how cache invalidation works, see [Cache invalidation](https://docs.docker.com/build/cache/invalidation/).\n\nNow that you understand how the cache works, you can begin to use the cache to your advantage. While the cache will automatically work on any `docker build` that you run, you can often refactor your Dockerfile to get even better performance. These optimizations can save precious seconds (or even minutes) off of your builds.\n\n### [Order your layers](#order-your-layers)\n\nPutting the commands in your Dockerfile into a logical order is a great place to start. Because a change causes a rebuild for steps that follow, try to make expensive steps appear near the beginning of the Dockerfile. Steps that change often should appear near the end of the Dockerfile, to avoid triggering rebuilds of layers that haven't changed.\n\nConsider the following example. A Dockerfile snippet that runs a JavaScript build from the source files in the current directory:\n\nThis Dockerfile is rather inefficient. Updating any file causes a reinstall of all dependencies every time you build the Docker image even if the dependencies didn't change since last time!\n\nInstead, the `COPY` command can be split in two. First, copy over the package management files (in this case, `package.json` and `yarn.lock`). Then, install the dependencies. Finally, copy over the project source code, which is subject to frequent change.\n\nBy installing dependencies in earlier layers of the Dockerfile, there is no need to rebuild those layers when a project file has changed.\n\n### [Keep layers small](#keep-layers-small)\n\nOne of the best things you can do to speed up image building is to just put less stuff into your build. Fewer parts means the cache stay smaller, but also that there should be fewer things that could be out-of-date and need rebuilding.\n\nTo get started, here are a few tips and tricks:\n\n#### [Don't include unnecessary files](#dont-include-unnecessary-files)\n\nBe considerate of what files you add to the image.\n\nRunning a command like `COPY . /src` will copy your entire [build context](https://docs.docker.com/build/building/context/) into the image. If you've got logs, package manager artifacts, or even previous build results in your current directory, those will also be copied over. This could make your image larger than it needs to be, especially as those files are usually not useful.\n\nAvoid adding unnecessary files to your builds by explicitly stating the files or directories you intend to copy over. For example, you might only want to add a `Makefile` and your `src` directory to the image filesystem. In that case, consider adding this to your Dockerfile:\n\nAs opposed to this:\n\nYou can also create a [`.dockerignore` file](https://docs.docker.com/build/building/context/#dockerignore-files), and use that to specify which files and directories to exclude from the build context.\n\n#### [Use your package manager wisely](#use-your-package-manager-wisely)\n\nMost Docker image builds involve using a package manager to help install software into the image. Debian has `apt`, Alpine has `apk`, Python has `pip`, NodeJS has `npm`, and so on.\n\nWhen installing packages, be considerate. Make sure to only install the packages that you need. If you're not going to use them, don't install them. Remember that this might be a different list for your local development environment and your production environment. You can use multi-stage builds to split these up efficiently.\n\n#### [Use the dedicated `RUN` cache](#use-the-dedicated-run-cache)\n\nThe `RUN` command supports a specialized cache, which you can use when you need a more fine-grained cache between runs. For example, when installing packages, you don't always need to fetch all of your packages from the internet each time. You only need the ones that have changed.\n\nTo solve this problem, you can use `RUN --mount type=cache`. For example, for your Debian-based image you might use the following:\n\nUsing the explicit cache with the `--mount` flag keeps the contents of the `target` directory preserved between builds. When this layer needs to be rebuilt, then it'll use the `apt` cache in `/var/cache/apt`.\n\n### [Minimize the number of layers](#minimize-the-number-of-layers)\n\nKeeping your layers small is a good first step, and the logical next step is to reduce the number of layers that you have. Fewer layers mean that you have less to rebuild, when something in your Dockerfile changes, so your build will complete faster.\n\nThe following sections outline some tips you can use to keep the number of layers to a minimum.\n\n#### [Use an appropriate base image](#use-an-appropriate-base-image)\n\nDocker provides over 170 pre-built [official images](https://hub.docker.com/search?q=&image_filter=official) for almost every common development scenario. For example, if you're building a Java web server, use a dedicated image such as [`eclipse-temurin`](https://hub.docker.com/_/eclipse-temurin/). Even when there's not an official image for what you might want, Docker provides images from [verified publishers](https://hub.docker.com/search?q=&image_filter=store) and [open source partners](https://hub.docker.com/search?q=&image_filter=open_source) that can help you on your way. The Docker community often produces third-party images to use as well.\n\nUsing official images saves you time and ensures you stay up to date and secure by default.\n\n#### [Use multi-stage builds](#use-multi-stage-builds)\n\n[Multi-stage builds](https://docs.docker.com/build/building/multi-stage/) let you split up your Dockerfile into multiple distinct stages. Each stage completes a step in the build process, and you can bridge the different stages to create your final image at the end. The Docker builder will work out dependencies between the stages and run them using the most efficient strategy. This even allows you to run multiple builds concurrently.\n\nMulti-stage builds use two or more `FROM` commands. The following example illustrates building a simple web server that serves HTML from your `docs` directory in Git:\n\nThis build has 3 stages: `git`, `fetch` and `site`. In this example, `git` is the base for the `fetch` stage. It uses the `COPY --from` flag to copy the data from the `docs/` directory into the Nginx server directory.\n\nEach stage has only a few instructions, and when possible, Docker will run these stages in parallel. Only the instructions in the `site` stage will end up as layers in the final image. The entire `git` history doesn't get embedded into the final result, which helps keep the image small and secure.\n\n#### [Combine commands together wherever possible](#combine-commands-together-wherever-possible)\n\nMost Dockerfile commands, and `RUN` commands in particular, can often be joined together. For example, instead of using `RUN` like this:\n\nIt's possible to run both of these commands inside a single `RUN`, which means that they will share the same cache! This is achievable using the `&&` shell operator to run one command after another:\n\nAnother shell feature that allows you to simplify and concatenate commands in a neat way are [`heredocs`](https://en.wikipedia.org/wiki/Here_document). It enables you to create multi-line scripts with good readability:\n\n(Note the `set -e` command to exit immediately after any command fails, instead of continuing.)\n\nFor more information on using cache to do efficient builds, see:\n\n*   [Cache invalidation](https://docs.docker.com/build/cache/invalidation/)\n*   [Garbage collection](https://docs.docker.com/build/cache/garbage-collection/)\n*   [Cache storage backends](https://docs.docker.com/build/cache/backends/)",
    "title": "Docker build cache | Docker Docs\n",
    "description": "Improve your build speed with effective use of the build cache",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/18.01/",
    "markdown": "# Docker Engine 18.01 release notes\n\n2018-01-10\n\n### [Builder](#builder)\n\n*   Fix files not being deleted if user-namespaces are enabled [moby/moby#35822](https://github.com/moby/moby/pull/35822)\n\n*   Add support for expanding environment-variables in `docker commit --change ...` [moby/moby#35582](https://github.com/moby/moby/pull/35582)\n\n### [Client](#client)\n\n*   Return errors from client in stack deploy configs [docker/cli#757](https://github.com/docker/cli/pull/757)\n\n*   Fix description of filter flag in prune commands [docker/cli#774](https://github.com/docker/cli/pull/774)\n\n*   Add \"pid\" to unsupported options list [docker/cli#768](https://github.com/docker/cli/pull/768)\n*   Add support for experimental Cli configuration [docker/cli#758](https://github.com/docker/cli/pull/758)\n*   Add support for generic resources to bash completion [docker/cli#749](https://github.com/docker/cli/pull/749)\n\n*   Fix error in zsh completion script for docker exec [docker/cli#751](https://github.com/docker/cli/pull/751)\n\n*   Add a debug message when client closes websocket attach connection [moby/moby#35720](https://github.com/moby/moby/pull/35720)\n\n*   Fix bash completion for `\"docker swarm\"` [docker/cli#772](https://github.com/docker/cli/pull/772)\n\n### [Documentation](#documentation)\n\n*   Correct references to `--publish` long syntax in docs [docker/cli#746](https://github.com/docker/cli/pull/746)\n*   Corrected descriptions for MAC\\_ADMIN and MAC\\_OVERRIDE [docker/cli#761](https://github.com/docker/cli/pull/761)\n*   Updated developer doc to explain external CLI [moby/moby#35681](https://github.com/moby/moby/pull/35681)\n\n*   Fix `\"on-failure\"` restart policy being documented as \"failure\" [docker/cli#754](https://github.com/docker/cli/pull/754)\n*   Fix anchors to \"Storage driver options\" [docker/cli#748](https://github.com/docker/cli/pull/748)\n\n### [Experimental](#experimental)\n\n*   Add kubernetes support to `docker stack` command [docker/cli#721](https://github.com/docker/cli/pull/721)\n\n*   Don't append the container id to custom directory checkpoints. [moby/moby#35694](https://github.com/moby/moby/pull/35694)\n\n### [Logging](#logging)\n\n*   Fix daemon crash when using the GELF log driver over TCP when the GELF server goes down [moby/moby#35765](https://github.com/moby/moby/pull/35765)\n\n*   Fix awslogs batch size calculation for large logs [moby/moby#35726](https://github.com/moby/moby/pull/35726)\n\n### [Networking](#networking)\n\n*   Windows: Fix to allow docker service to start on Windows VM [docker/libnetwork#1916](https://github.com/docker/libnetwork/pull/1916)\n*   Fix for docker intercepting DNS requests on ICS network [docker/libnetwork#2014](https://github.com/docker/libnetwork/pull/2014)\n\n*   Windows: Added a new network creation driver option [docker/libnetwork#2021](https://github.com/docker/libnetwork/pull/2021)\n\n### [Runtime](#runtime)\n\n*   Validate Mount-specs on container start to prevent missing host-path [moby/moby#35833](https://github.com/moby/moby/pull/35833)\n\n*   Fix overlay2 storage driver inside a user namespace [moby/moby#35794](https://github.com/moby/moby/pull/35794)\n\n*   Zfs: fix busy error on container stop [moby/moby#35674](https://github.com/moby/moby/pull/35674)\n\n*   Fix health checks not using the container's working directory [moby/moby#35845](https://github.com/moby/moby/pull/35845)\n*   Fix VFS graph driver failure to initialize because of failure to setup fs quota [moby/moby#35827](https://github.com/moby/moby/pull/35827)\n*   Fix containerd events being processed twice [moby/moby#35896](https://github.com/moby/moby/pull/35896)\n\n### [Swarm mode](#swarm-mode)\n\n*   Fix published ports not being updated if a service has the same number of host-mode published ports with Published Port 0 [docker/swarmkit#2376](https://github.com/docker/swarmkit/pull/2376)\n\n*   Make the task termination order deterministic [docker/swarmkit#2265](https://github.com/docker/swarmkit/pull/2265)",
    "title": "Docker Engine 18.01 release notes | Docker Docs\n",
    "description": "",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/swarm-tutorial/drain-node/",
    "markdown": "# Drain a node on the swarm\n\nIn earlier steps of the tutorial, all the nodes have been running with `Active` availability. The swarm manager can assign tasks to any `Active` node, so up to now all nodes have been available to receive tasks.\n\nSometimes, such as planned maintenance times, you need to set a node to `Drain` availability. `Drain` availability prevents a node from receiving new tasks from the swarm manager. It also means the manager stops tasks running on the node and launches replica tasks on a node with `Active` availability.\n\n> **Important**:\n> \n> Setting a node to `Drain` does not remove standalone containers from that node, such as those created with `docker run`, `docker compose up`, or the Docker Engine API. A node's status, including `Drain`, only affects the node's ability to schedule swarm service workloads.\n\n1.  If you haven't already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named `manager1`.\n    \n2.  Verify that all your nodes are actively available.\n    \n3.  If you aren't still running the `redis` service from the [rolling update](https://docs.docker.com/engine/swarm/swarm-tutorial/rolling-update/) tutorial, start it now:\n    \n4.  Run `docker service ps redis` to see how the swarm manager assigned the tasks to different nodes:\n    \n    In this case the swarm manager distributed one task to each node. You may see the tasks distributed differently among the nodes in your environment.\n    \n5.  Run `docker node update --availability drain <NODE-ID>` to drain a node that had a task assigned to it:\n    \n6.  Inspect the node to check its availability:\n    \n    The drained node shows `Drain` for `Availability`.\n    \n7.  Run `docker service ps redis` to see how the swarm manager updated the task assignments for the `redis` service:\n    \n    The swarm manager maintains the desired state by ending the task on a node with `Drain` availability and creating a new task on a node with `Active` availability.\n    \n8.  Run `docker node update --availability active <NODE-ID>` to return the drained node to an active state:\n    \n9.  Inspect the node to see the updated state:\n    \n    When you set the node back to `Active` availability, it can receive new tasks:\n    \n    *   during a service update to scale up\n    *   during a rolling update\n    *   when you set another node to `Drain` availability\n    *   when a task fails on another active node\n\nNext, you'll learn how to use a Swarm mode routing mesh",
    "title": "Drain a node on the swarm | Docker Docs\n",
    "description": "Drain nodes on the swarm",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/cache/invalidation/",
    "markdown": "# Build cache invalidation | Docker Docs\n\nWhen building an image, Docker steps through the instructions in your Dockerfile, executing each in the order specified. For each instruction, Docker checks whether it can reuse the instruction from the build cache.\n\nThe basic rules of build cache invalidation are as follows:\n\n*   Starting with a base image that's already in the cache, the next instruction is compared against all child images derived from that base image to see if one of them was built using the exact same instruction. If not, the cache is invalidated.\n    \n*   In most cases, simply comparing the instruction in the Dockerfile with one of the child images is sufficient. However, certain instructions require more examination and explanation.\n    \n*   For the `ADD` and `COPY` instructions, the modification time and size file metadata is used to determine whether cache is valid. During cache lookup, cache is invalidated if the file metadata has changed for any of the files involved.\n    \n*   Aside from the `ADD` and `COPY` commands, cache checking doesn't look at the files in the container to determine a cache match. For example, when processing a `RUN apt-get -y update` command the files updated in the container aren't examined to determine if a cache hit exists. In that case just the command string itself is used to find a match.\n    \n\nOnce the cache is invalidated, all subsequent Dockerfile commands generate new images and the cache isn't used.\n\nIf your build contains several layers and you want to ensure the build cache is reusable, order the instructions from less frequently changed to more frequently changed where possible.\n\nThe cache for `RUN` instructions isn't invalidated automatically between builds. Suppose you have a step in your Dockerfile to install `curl`:\n\nThis doesn't mean that the version of `curl` in your image is always up-to-date. Rebuilding the image one week later will still get you the same packages as before. To force a re-execution of the `RUN` instruction, you can:\n\n*   Make sure that a layer before it has changed\n*   Clear the build cache ahead of the build using [`docker builder prune`](https://docs.docker.com/reference/cli/docker/builder/prune/)\n*   Use the `--no-cache` or `--no-cache-filter` options\n\nThe `--no-cache-filter` option lets you specify a specific build stage to invalidate the cache for:\n\nThe contents of build secrets are not part of the build cache. Changing the value of a secret doesn't result in cache invalidation.\n\nIf you want to force cache invalidation after changing a secret value, you can pass a build argument with an arbitrary value that you also change when changing the secret. Build arguments do result in cache invalidation.\n\nProperties of secrets such as IDs and mount paths do participate in the cache checksum, and result in cache invalidation if changed.",
    "title": "Build cache invalidation | Docker Docs\n",
    "description": "Dig into the details abouw how cache invalidation works for Docker's build cache",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/cache/garbage-collection/",
    "markdown": "# Build garbage collection | Docker Docs\n\nWhile [`docker builder prune`](https://docs.docker.com/reference/cli/docker/builder/prune/) or [`docker buildx prune`](https://docs.docker.com/reference/cli/docker/buildx/prune/) commands run at once, garbage collection runs periodically and follows an ordered list of prune policies.\n\nGarbage collection runs in the BuildKit daemon. The daemon clears the build cache when the cache size becomes too big, or when the cache age expires. The following sections describe how you can configure both the size and age parameters by defining garbage collection policies.\n\nDepending on the [driver](https://docs.docker.com/build/drivers/) used by your builder instance, the garbage collection will use a different configuration file.\n\nIf you're using the [`docker` driver](https://docs.docker.com/build/drivers/docker/), garbage collection can be configured in the [Docker Daemon configuration](https://docs.docker.com/reference/cli/dockerd/#daemon-configuration-file). file:\n\nFor other drivers, garbage collection can be configured using the [BuildKit configuration](https://docs.docker.com/build/buildkit/toml-configuration/) file:\n\nDefault garbage collection policies apply to all builders if not set:\n\n*   `rule#0`: if build cache uses more than 512MB delete the most easily reproducible data after it has not been used for 2 days.\n*   `rule#1`: remove any data not used for 60 days.\n*   `rule#2`: keep the unshared build cache under cap.\n*   `rule#3`: if previous policies were insufficient start deleting internal data to keep build cache under cap.\n\n> **Note**\n> \n> `Keep Bytes` defaults to 10% of the size of the disk. If the disk size cannot be determined, it uses 2GB as a fallback.",
    "title": "Build garbage collection | Docker Docs\n",
    "description": "Learn about garbage collection in the BuildKit daemon",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/ingress/",
    "markdown": "# Use Swarm mode routing mesh\n\nDocker Engine Swarm mode makes it easy to publish ports for services to make them available to resources outside the swarm. All nodes participate in an ingress routing mesh. The routing mesh enables each node in the swarm to accept connections on published ports for any service running in the swarm, even if there's no task running on the node. The routing mesh routes all incoming requests to published ports on available nodes to an active container.\n\nTo use the ingress network in the swarm, you need to have the following ports open between the swarm nodes before you enable Swarm mode:\n\n*   Port `7946` TCP/UDP for container network discovery.\n*   Port `4789` UDP (configurable) for the container ingress network.\n\nWhen setting up networking in a Swarm, special care should be taken. Consult the [tutorial](https://docs.docker.com/engine/swarm/swarm-tutorial/#open-protocols-and-ports-between-the-hosts) for an overview.\n\nYou must also open the published port between the swarm nodes and any external resources, such as an external load balancer, that require access to the port.\n\nYou can also [bypass the routing mesh](#bypass-the-routing-mesh) for a given service.\n\nUse the `--publish` flag to publish a port when you create a service. `target` is used to specify the port inside the container, and `published` is used to specify the port to bind on the routing mesh. If you leave off the `published` port, a random high-numbered port is bound for each service task. You need to inspect the task to determine the port.\n\n> **Note**\n> \n> The older form of this syntax is a colon-separated string, where the published port is first and the target port is second, such as `-p 8080:80`. The new syntax is preferred because it is easier to read and allows more flexibility.\n\nThe `<PUBLISHED-PORT>` is the port where the swarm makes the service available. If you omit it, a random high-numbered port is bound. The `<CONTAINER-PORT>` is the port where the container listens. This parameter is required.\n\nFor example, the following command publishes port 80 in the nginx container to port 8080 for any node in the swarm:\n\nWhen you access port 8080 on any node, Docker routes your request to an active container. On the swarm nodes themselves, port 8080 may not actually be bound, but the routing mesh knows how to route the traffic and prevents any port conflicts from happening.\n\nThe routing mesh listens on the published port for any IP address assigned to the node. For externally routable IP addresses, the port is available from outside the host. For all other IP addresses the access is only available from within the host.\n\n![Service ingress image](https://docs.docker.com/engine/swarm/images/ingress-routing-mesh.webp)\n\nYou can publish a port for an existing service using the following command:\n\nYou can use `docker service inspect` to view the service's published port. For instance:\n\nThe output shows the `<CONTAINER-PORT>` (labeled `TargetPort`) from the containers and the `<PUBLISHED-PORT>` (labeled `PublishedPort`) where nodes listen for requests for the service.\n\n### [Publish a port for TCP only or UDP only](#publish-a-port-for-tcp-only-or-udp-only)\n\nBy default, when you publish a port, it is a TCP port. You can specifically publish a UDP port instead of or in addition to a TCP port. When you publish both TCP and UDP ports, if you omit the protocol specifier, the port is published as a TCP port. If you use the longer syntax (recommended), set the `protocol` key to either `tcp` or `udp`.\n\n#### [TCP only](#tcp-only)\n\nLong syntax:\n\nShort syntax:\n\n#### [TCP and UDP](#tcp-and-udp)\n\nLong syntax:\n\nShort syntax:\n\n#### [UDP only](#udp-only)\n\nLong syntax:\n\nShort syntax:\n\nBy default, swarm services which publish ports do so using the routing mesh. When you connect to a published port on any swarm node (whether it is running a given service or not), you are redirected to a worker which is running that service, transparently. Effectively, Docker acts as a load balancer for your swarm services.\n\nYou can bypass the routing mesh, so that when you access the bound port on a given node, you are always accessing the instance of the service running on that node. This is referred to as `host` mode. There are a few things to keep in mind.\n\n*   If you access a node which is not running a service task, the service does not listen on that port. It is possible that nothing is listening, or that a completely different application is listening.\n    \n*   If you expect to run multiple service tasks on each node (such as when you have 5 nodes but run 10 replicas), you cannot specify a static target port. Either allow Docker to assign a random high-numbered port (by leaving off the `published`), or ensure that only a single instance of the service runs on a given node, by using a global service rather than a replicated one, or by using placement constraints.\n    \n\nTo bypass the routing mesh, you must use the long `--publish` service and set `mode` to `host`. If you omit the `mode` key or set it to `ingress`, the routing mesh is used. The following command creates a global service using `host` mode and bypassing the routing mesh.\n\nYou can configure an external load balancer for swarm services, either in combination with the routing mesh or without using the routing mesh at all.\n\n### [Using the routing mesh](#using-the-routing-mesh)\n\nYou can configure an external load balancer to route requests to a swarm service. For example, you could configure [HAProxy](https://www.haproxy.org/) to balance requests to an nginx service published to port 8080.\n\n![Ingress with external load balancer image](https://docs.docker.com/engine/swarm/images/ingress-lb.webp)\n\nIn this case, port 8080 must be open between the load balancer and the nodes in the swarm. The swarm nodes can reside on a private network that is accessible to the proxy server, but that is not publicly accessible.\n\nYou can configure the load balancer to balance requests between every node in the swarm even if there are no tasks scheduled on the node. For example, you could have the following HAProxy configuration in `/etc/haproxy/haproxy.cfg`:\n\nWhen you access the HAProxy load balancer on port 80, it forwards requests to nodes in the swarm. The swarm routing mesh routes the request to an active task. If, for any reason the swarm scheduler dispatches tasks to different nodes, you don't need to reconfigure the load balancer.\n\nYou can configure any type of load balancer to route requests to swarm nodes. To learn more about HAProxy, see the [HAProxy documentation](https://cbonte.github.io/haproxy-dconv/).\n\n### [Without the routing mesh](#without-the-routing-mesh)\n\nTo use an external load balancer without the routing mesh, set `--endpoint-mode` to `dnsrr` instead of the default value of `vip`. In this case, there is not a single virtual IP. Instead, Docker sets up DNS entries for the service such that a DNS query for the service name returns a list of IP addresses, and the client connects directly to one of these.\n\nYou can't use `--endpoint-mode dnsrr` together with `--publish mode=ingress`. You must run your own load balancer in front of the service. A DNS query for the service name on the Docker host returns a list of IP addresses for the nodes running the service. Configure your load balancer to consume this list and balance the traffic across the nodes. See [Configure service discovery](https://docs.docker.com/engine/swarm/networking/#configure-service-discovery).\n\n*   [Deploy services to a swarm](https://docs.docker.com/engine/swarm/services/)",
    "title": "Use Swarm mode routing mesh | Docker Docs\n",
    "description": "Use the routing mesh to publish services externally to a swarm",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/cache/backends/",
    "markdown": "# Cache storage backends | Docker Docs\n\nTo ensure fast builds, BuildKit automatically caches the build result in its own internal cache. Additionally, BuildKit also supports exporting build cache to an external location, making it possible to import in future builds.\n\nAn external cache becomes almost essential in CI/CD build environments. Such environments usually have little-to-no persistence between runs, but it's still important to keep the runtime of image builds as low as possible.\n\nThe default `docker` driver supports the `inline`, `local`, `registry`, and `gha` cache backends, but only if you have enabled the [containerd image store](https://docs.docker.com/desktop/containerd/). Other cache backends require you to select a different [driver](https://docs.docker.com/build/drivers/).\n\n> **Warning**\n> \n> If you use secrets or credentials inside your build process, ensure you manipulate them using the dedicated [`--secret` option](https://docs.docker.com/reference/cli/docker/buildx/build/#secret). Manually managing secrets using `COPY` or `ARG` could result in leaked credentials.\n\nBuildx supports the following cache storage backends:\n\n*   `inline`: embeds the build cache into the image.\n    \n    The inline cache gets pushed to the same location as the main output result. This only works with the [`image` exporter](https://docs.docker.com/build/exporters/image-registry/).\n    \n*   `registry`: embeds the build cache into a separate image, and pushes to a dedicated location separate from the main output.\n    \n*   `local`: writes the build cache to a local directory on the filesystem.\n    \n*   `gha`: uploads the build cache to [GitHub Actions cache](https://docs.github.com/en/rest/actions/cache) (beta).\n    \n*   `s3`: uploads the build cache to an [AWS S3 bucket](https://aws.amazon.com/s3/) (unreleased).\n    \n*   `azblob`: uploads the build cache to [Azure Blob Storage](https://azure.microsoft.com/en-us/services/storage/blobs/) (unreleased).\n    \n\nTo use any of the cache backends, you first need to specify it on build with the [`--cache-to` option](https://docs.docker.com/reference/cli/docker/buildx/build/#cache-to) to export the cache to your storage backend of choice. Then, use the [`--cache-from` option](https://docs.docker.com/reference/cli/docker/buildx/build/#cache-from) to import the cache from the storage backend into the current build. Unlike the local BuildKit cache (which is always enabled), all of the cache storage backends must be explicitly exported to, and explicitly imported from.\n\nExample `buildx` command using the `registry` backend, using import and export cache:\n\n> **Warning**\n> \n> As a general rule, each cache writes to some location. No location can be written to twice, without overwriting the previously cached data. If you want to maintain multiple scoped caches (for example, a cache per Git branch), then ensure that you use different locations for exported cache.\n\nBuildKit currently only supports [a single cache exporter](https://github.com/moby/buildkit/pull/3024). But you can import from as many remote caches as you like. For example, a common pattern is to use the cache of both the current branch and the main branch. The following example shows importing cache from multiple locations using the registry cache backend:\n\nThis section describes some configuration options available when generating cache exports. The options described here are common for at least two or more backend types. Additionally, the different backend types support specific parameters as well. See the detailed page about each backend type for more information about which configuration parameters apply.\n\nThe common parameters described here are:\n\n*   [Cache mode](#cache-mode)\n*   [Cache compression](#cache-compression)\n*   [OCI media type](#oci-media-types)\n\n### [Cache mode](#cache-mode)\n\nWhen generating a cache output, the `--cache-to` argument accepts a `mode` option for defining which layers to include in the exported cache. This is supported by all cache backends except for the `inline` cache.\n\nMode can be set to either of two options: `mode=min` or `mode=max`. For example, to build the cache with `mode=max` with the registry backend:\n\nThis option is only set when exporting a cache, using `--cache-to`. When importing a cache (`--cache-from`) the relevant parameters are automatically detected.\n\nIn `min` cache mode (the default), only layers that are exported into the resulting image are cached, while in `max` cache mode, all layers are cached, even those of intermediate steps.\n\nWhile `min` cache is typically smaller (which speeds up import/export times, and reduces storage costs), `max` cache is more likely to get more cache hits. Depending on the complexity and location of your build, you should experiment with both parameters to find the results that work best for you.\n\n### [Cache compression](#cache-compression)\n\nThe cache compression options are the same as the [exporter compression options](https://docs.docker.com/build/exporters/#compression). This is supported by the `local` and `registry` cache backends.\n\nFor example, to compress the `registry` cache with `zstd` compression:\n\n### [OCI media types](#oci-media-types)\n\nThe cache OCI options are the same as the [exporter OCI options](https://docs.docker.com/build/exporters/#oci-media-types). These are supported by the `local` and `registry` cache backends.\n\nFor example, to export OCI media type cache, use the `oci-mediatypes` property:\n\nThis property is only meaningful with the `--cache-to` flag. When fetching cache, BuildKit will auto-detect the correct media types to use.",
    "title": "Cache storage backends | Docker Docs\n",
    "description": "Cache backends let you manage your build cache externally. External cache is useful to create a shared cache that can help speed up inner loop and CI builds. ",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/17.12/",
    "markdown": "# Docker Engine 17.12 release notes\n\n2018-02-27\n\n### [Client](#client)\n\n*   Fix `node-generic-resource` typo [moby/moby#35970](https://github.com/moby/moby/pull/35970) and [moby/moby#36125](https://github.com/moby/moby/pull/36125)\n\n*   Return errors from daemon on stack deploy configs create/update [docker/cli#757](https://github.com/docker/cli/pull/757)\n\n### [Logging](#logging)\n\n*   awslogs: fix batch size calculation for large logs [moby/moby#35726](https://github.com/moby/moby/pull/35726)\n\n*   Support a proxy in splunk log driver [moby/moby#36220](https://github.com/moby/moby/pull/36220)\n\n### [Networking](#networking)\n\n*   Fix ingress network when upgrading from 17.09 to 17.12 [moby/moby#36003](https://github.com/moby/moby/pull/36003)\n\n*   Add verbose info to partial overlay ID [moby/moby#35989](https://github.com/moby/moby/pull/35989)\n\n*   Fix IPv6 networking being deconfigured if live-restore is being enabled [docker/libnetwork#2043](https://github.com/docker/libnetwork/pull/2043)\n*   Fix watchMiss thread context [docker/libnetwork#2051](https://github.com/docker/libnetwork/pull/2051)\n\n### [Packaging](#packaging)\n\n*   Set TasksMax in docker.service [docker/docker-ce-packaging#78](https://github.com/docker/docker-ce-packaging/pull/78)\n\n### [Runtime](#runtime)\n\n*   Bump Golang to 1.9.4\n*   Bump containerd to 1.0.1\n\n*   Fix dockerd not being able to reconnect to containerd when it is restarted [moby/moby#36173](https://github.com/moby/moby/pull/36173)\n*   Fix containerd events from being processed twice [moby/moby#35891](https://github.com/moby/moby/issues/35891)\n*   Fix vfs graph driver failure to initialize because of failure to setup fs quota [moby/moby#35827](https://github.com/moby/moby/pull/35827)\n*   Fix regression of health check not using container's working directory [moby/moby#35845](https://github.com/moby/moby/pull/35845)\n*   Honor `DOCKER_RAMDISK` with containerd 1.0 [moby/moby#35957](https://github.com/moby/moby/pull/35957)\n*   Update runc to fix hang during start and exec [moby/moby#36097](https://github.com/moby/moby/pull/36097)\n*   Windows: Vendor of Microsoft/hcsshim @v.0.6.8 partial fix for import layer failing [moby/moby#35924](https://github.com/moby/moby/pull/35924)\n\n*   Do not make graphdriver homes private mounts [moby/moby#36047](https://github.com/moby/moby/pull/36047)\n*   Use rslave propagation for mounts from daemon root [moby/moby#36055](https://github.com/moby/moby/pull/36055)\n*   Set daemon root to use shared mount propagation [moby/moby#36096](https://github.com/moby/moby/pull/36096)\n*   Validate that mounted paths exist when container is started, not just during creation [moby/moby#35833](https://github.com/moby/moby/pull/35833)\n*   Add `REMOVE` and `ORPHANED` to TaskState [moby/moby#36146](https://github.com/moby/moby/pull/36146)\n\n*   Fix issue where network inspect does not show Created time for networks in swarm scope [moby/moby#36095](https://github.com/moby/moby/pull/36095)\n\n*   Nullify container read write layer upon release [moby/moby#36130](https://github.com/moby/moby/pull/36160) and [moby/moby#36343](https://github.com/moby/moby/pull/36242)\n\n### [Swarm](#swarm)\n\n*   Remove watchMiss from swarm mode [docker/libnetwork#2047](https://github.com/docker/libnetwork/pull/2047)\n\n### [Known Issues](#known-issues)\n\n*   Health check no longer uses the container's working directory [moby/moby#35843](https://github.com/moby/moby/issues/35843)\n*   Errors not returned from client in stack deploy configs [moby/moby#757](https://github.com/docker/cli/pull/757)\n*   Docker cannot use memory limit when using systemd options [moby/moby#35123](https://github.com/moby/moby/issues/35123)\n\n2017-12-27\n\n### [Known Issues](#known-issues-1)\n\n*   AWS logs batch size calculation [moby/moby#35726](https://github.com/moby/moby/pull/35726)\n*   Health check no longer uses the container's working directory [moby/moby#35843](https://github.com/moby/moby/issues/35843)\n*   Errors not returned from client in stack deploy configs [moby/moby#757](https://github.com/docker/cli/pull/757)\n*   Daemon aborts when project quota fails [moby/moby#35827](https://github.com/moby/moby/pull/35827)\n*   Docker cannot use memory limit when using systemd options [moby/moby#35123](https://github.com/moby/moby/issues/35123)\n\n### [Builder](#builder)\n\n*   Fix build cache hash for broken symlink [moby/moby#34271](https://github.com/moby/moby/pull/34271)\n*   Fix long stream sync [moby/moby#35404](https://github.com/moby/moby/pull/35404)\n*   Fix dockerfile parser failing silently on long tokens [moby/moby#35429](https://github.com/moby/moby/pull/35429)\n\n### [Client](#client-1)\n\n*   Remove secret/config duplication in cli/compose [docker/cli#671](https://github.com/docker/cli/pull/671)\n*   Add `--local` flag to `docker trust sign` [docker/cli#575](https://github.com/docker/cli/pull/575)\n*   Add `docker trust inspect` [docker/cli#694](https://github.com/docker/cli/pull/694)\n\n*   Add `name` field to secrets and configs to allow interpolation in Compose files [docker/cli#668](https://github.com/docker/cli/pull/668)\n*   Add `--isolation` for setting swarm service isolation mode [docker/cli#426](https://github.com/docker/cli/pull/426)\n\n*   Remove deprecated \"daemon\" subcommand [docker/cli#689](https://github.com/docker/cli/pull/689)\n\n*   Fix behaviour of `rmi -f` with unexpected errors [docker/cli#654](https://github.com/docker/cli/pull/654)\n\n*   Integrated Generic resource in service create [docker/cli#429](https://github.com/docker/cli/pull/429)\n\n*   Fix external networks in stacks [docker/cli#743](https://github.com/docker/cli/pull/743)\n\n*   Remove support for referencing images by image shortid [docker/cli#753](https://github.com/docker/cli/pull/753) and [moby/moby#35790](https://github.com/moby/moby/pull/35790)\n*   Use commit-sha instead of tag for containerd [moby/moby#35770](https://github.com/moby/moby/pull/35770)\n\n### [Documentation](#documentation)\n\n*   Update API version history for 1.35 [moby/moby#35724](https://github.com/moby/moby/pull/35724)\n\n### [Logging](#logging-1)\n\n*   Logentries driver line-only=true \\[\\]byte output fix [moby/moby#35612](https://github.com/moby/moby/pull/35612)\n*   Logentries line-only logopt fix to maintain backwards compatibility [moby/moby#35628](https://github.com/moby/moby/pull/35628)\n\n*   Add `--until` flag for docker logs [moby/moby#32914](https://github.com/moby/moby/pull/32914)\n*   Add gelf log driver plugin to Windows build [moby/moby#35073](https://github.com/moby/moby/pull/35073)\n\n*   Set timeout on splunk batch send [moby/moby#35496](https://github.com/moby/moby/pull/35496)\n*   Update Graylog2/go-gelf [moby/moby#35765](https://github.com/moby/moby/pull/35765)\n\n### [Networking](#networking-1)\n\n*   Move load balancer sandbox creation/deletion into libnetwork [moby/moby#35422](https://github.com/moby/moby/pull/35422)\n*   Only chown network files within container metadata [moby/moby#34224](https://github.com/moby/moby/pull/34224)\n*   Restore error type in FindNetwork [moby/moby#35634](https://github.com/moby/moby/pull/35634)\n\n*   Fix consumes MIME type for NetworkConnect [moby/moby#35542](https://github.com/moby/moby/pull/35542)\n\n*   Added support for persisting Windows network driver specific options [moby/moby#35563](https://github.com/moby/moby/pull/35563)\n\n*   Fix timeout on netlink sockets and watchmiss leak [moby/moby#35677](https://github.com/moby/moby/pull/35677)\n\n*   New daemon config for networking diagnosis [moby/moby#35677](https://github.com/moby/moby/pull/35677)\n\n*   Clean up node management logic [docker/libnetwork#2036](https://github.com/docker/libnetwork/pull/2036)\n*   Allocate VIPs when endpoints are restored [docker/swarmkit#2474](https://github.com/docker/swarmkit/pull/2474)\n\n### [Runtime](#runtime-1)\n\n*   Update to containerd v1.0.0 [moby/moby#35707](https://github.com/moby/moby/pull/35707)\n*   Have VFS graphdriver use accelerated in-kernel copy [moby/moby#35537](https://github.com/moby/moby/pull/35537)\n*   Introduce `workingdir` option for docker exec [moby/moby#35661](https://github.com/moby/moby/pull/35661)\n*   Bump Go to 1.9.2 [moby/moby#33892](https://github.com/moby/moby/pull/33892) [docker/cli#716](https://github.com/docker/cli/pull/716)\n*   `/dev` should not be readonly with `--readonly` flag [moby/moby#35344](https://github.com/moby/moby/pull/35344)\n\n*   Add custom build-time Graphdrivers priority list [moby/moby#35522](https://github.com/moby/moby/pull/35522)\n\n*   LCOW: CLI changes to add platform flag - pull, run, create and build [docker/cli#474](https://github.com/docker/cli/pull/474)\n*   Fix width/height on Windows for `docker exec` [moby/moby#35631](https://github.com/moby/moby/pull/35631)\n*   Detect overlay2 support on pre-4.0 kernels [moby/moby#35527](https://github.com/moby/moby/pull/35527)\n*   Devicemapper: remove container rootfs mountPath after umount [moby/moby#34573](https://github.com/moby/moby/pull/34573)\n*   Disallow overlay/overlay2 on top of NFS [moby/moby#35483](https://github.com/moby/moby/pull/35483)\n\n*   Fix potential panic during plugin set. [moby/moby#35632](https://github.com/moby/moby/pull/35632)\n*   Fix some issues with locking on the container [moby/moby#35501](https://github.com/moby/moby/pull/35501)\n*   Fixup some issues with plugin refcounting [moby/moby#35265](https://github.com/moby/moby/pull/35265)\n\n*   Add missing lock in ProcessEvent [moby/moby#35516](https://github.com/moby/moby/pull/35516)\n*   Add vfs quota support [moby/moby#35231](https://github.com/moby/moby/pull/35231)\n\n*   Skip empty directories on prior graphdriver detection [moby/moby#35528](https://github.com/moby/moby/pull/35528)\n*   Skip xfs quota tests when running in user namespace [moby/moby#35526](https://github.com/moby/moby/pull/35526)\n\n*   Added SubSecondPrecision to config option. [moby/moby#35529](https://github.com/moby/moby/pull/35529)\n\n*   Update fsnotify to fix deadlock in removing watch [moby/moby#35453](https://github.com/moby/moby/pull/35453)\n\n*   Fix \"duplicate mount point\" when `--tmpfs /dev/shm` is used [moby/moby#35467](https://github.com/moby/moby/pull/35467)\n*   Fix honoring tmpfs-size for user `/dev/shm` mount [moby/moby#35316](https://github.com/moby/moby/pull/35316)\n*   Fix EBUSY errors under overlayfs and v4.13+ kernels [moby/moby#34948](https://github.com/moby/moby/pull/34948)\n\n*   Container: protect health monitor channel [moby/moby#35482](https://github.com/moby/moby/pull/35482)\n*   Container: protect the health status with mutex [moby/moby#35517](https://github.com/moby/moby/pull/35517)\n*   Container: update real-time resources [moby/moby#33731](https://github.com/moby/moby/pull/33731)\n*   Create labels when volume exists only remotely [moby/moby#34896](https://github.com/moby/moby/pull/34896)\n\n*   Fix leaking container/exec state [moby/moby#35484](https://github.com/moby/moby/pull/35484)\n\n*   Disallow using legacy (v1) registries [moby/moby#35751](https://github.com/moby/moby/pull/35751) and [docker/cli#747](https://github.com/docker/cli/pull/747)\n\n*   Windows: Fix case insensitive filename matching against builder cache [moby/moby#35793](https://github.com/moby/moby/pull/35793)\n*   Fix race conditions around process handling and error checks [moby/moby#35809](https://github.com/moby/moby/pull/35809)\n\n*   Ensure containers are stopped on daemon startup [moby/moby#35805](https://github.com/moby/moby/pull/35805)\n*   Follow containerd namespace conventions [moby/moby#35812](https://github.com/moby/moby/pull/35812)\n\n### [Swarm Mode](#swarm-mode)\n\n*   Added support for swarm service isolation mode [moby/moby#34424](https://github.com/moby/moby/pull/34424)\n\n*   Fix task clean up for tasks that are complete [docker/swarmkit#2477](https://github.com/docker/swarmkit/pull/2477)\n\n### [Packaging](#packaging-1)\n\n*   Add Packaging for Fedora 27 [docker/docker-ce-packaging#59](https://github.com/docker/docker-ce-packaging/pull/59)\n\n*   Change default versioning scheme to 0.0.0-dev unless specified for packaging [docker/docker-ce-packaging#67](https://github.com/docker/docker-ce-packaging/pull/67)\n*   Pass Version to engine static builds [docker/docker-ce-packaging#70](https://github.com/docker/docker-ce-packaging/pull/70)\n\n*   Added support for aarch64 on Debian (stretch/jessie) and Ubuntu Zesty or newer [docker/docker-ce-packaging#35](https://github.com/docker/docker-ce-packaging/pull/35)",
    "title": "Docker Engine 17.12 release notes | Docker Docs\n",
    "description": "",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/17.11/",
    "markdown": "# Docker Engine 17.11 release notes\n\n**Important**: Docker CE 17.11 is the first Docker release based on [containerd 1.0 beta](https://github.com/containerd/containerd/releases/tag/v1.0.0-beta.2). Docker CE 17.11 and later don't recognize containers started with previous Docker versions. If using [Live Restore](https://docs.docker.com/config/containers/live-restore/), you must stop all containers before upgrading to Docker CE 17.11. If you don't, any containers started by Docker versions that predate 17.11 aren't recognized by Docker after the upgrade and keep running, un-managed, on the system.",
    "title": "Docker Engine 17.11 release notes | Docker Docs\n",
    "description": "",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/",
    "markdown": "# How nodes work | Docker Docs\n\nSwarm mode lets you create a cluster of one or more Docker Engines called a swarm. A swarm consists of one or more nodes: physical or virtual machines running Docker Engine.\n\nThere are two types of nodes: [managers](#manager-nodes) and [workers](#worker-nodes).\n\n![Swarm mode cluster](https://docs.docker.com/engine/swarm/images/swarm-diagram.webp)\n\nIf you haven't already, read through the [Swarm mode overview](https://docs.docker.com/engine/swarm/) and [key concepts](https://docs.docker.com/engine/swarm/key-concepts/).\n\nManager nodes handle cluster management tasks:\n\n*   Maintaining cluster state\n*   Scheduling services\n*   Serving Swarm mode [HTTP API endpoints](https://docs.docker.com/engine/api/)\n\nUsing a [Raft](https://raft.github.io/raft.pdf) implementation, the managers maintain a consistent internal state of the entire swarm and all the services running on it. For testing purposes it is OK to run a swarm with a single manager. If the manager in a single-manager swarm fails, your services continue to run, but you need to create a new cluster to recover.\n\nTo take advantage of Swarm mode's fault-tolerance features, we recommend you implement an odd number of nodes according to your organization's high-availability requirements. When you have multiple managers you can recover from the failure of a manager node without downtime.\n\n*   A three-manager swarm tolerates a maximum loss of one manager.\n    \n*   A five-manager swarm tolerates a maximum simultaneous loss of two manager nodes.\n    \n*   An odd number `N` of manager nodes in the cluster tolerates the loss of at most `(N-1)/2` managers. Docker recommends a maximum of seven manager nodes for a swarm.\n    \n    > **Important**\n    > \n    > Adding more managers does NOT mean increased scalability or higher performance. In general, the opposite is true.\n    \n\nWorker nodes are also instances of Docker Engine whose sole purpose is to execute containers. Worker nodes don't participate in the Raft distributed state, make scheduling decisions, or serve the swarm mode HTTP API.\n\nYou can create a swarm of one manager node, but you cannot have a worker node without at least one manager node. By default, all managers are also workers. In a single manager node cluster, you can run commands like `docker service create` and the scheduler places all tasks on the local engine.\n\nTo prevent the scheduler from placing tasks on a manager node in a multi-node swarm, set the availability for the manager node to `Drain`. The scheduler gracefully stops tasks on nodes in `Drain` mode and schedules the tasks on an `Active` node. The scheduler does not assign new tasks to nodes with `Drain` availability.\n\nRefer to the [`docker node update`](https://docs.docker.com/reference/cli/docker/node/update/) command line reference to see how to change node availability.\n\nYou can promote a worker node to be a manager by running `docker node promote`. For example, you may want to promote a worker node when you take a manager node offline for maintenance. See [node promote](https://docs.docker.com/reference/cli/docker/node/promote/).\n\nYou can also demote a manager node to a worker node. See [node demote](https://docs.docker.com/reference/cli/docker/node/demote/).\n\n*   Read about how Swarm mode [services](https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/) work.\n*   Learn how [PKI](https://docs.docker.com/engine/swarm/how-swarm-mode-works/pki/) works in Swarm mode.",
    "title": "How nodes work | Docker Docs\n",
    "description": "How swarm nodes work",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/cache/backends/inline/",
    "markdown": "# Inline cache | Docker Docs\n\nThe `inline` cache storage backend is the simplest way to get an external cache and is easy to get started using if you're already building and pushing an image.\n\nThe downside of inline cache is that it doesn't scale with multi-stage builds as well as the other drivers do. It also doesn't offer separation between your output artifacts and your cache output. This means that if you're using a particularly complex build flow, or not exporting your images directly to a registry, then you may want to consider the [registry](https://docs.docker.com/build/cache/backends/registry/) cache.\n\nNo additional parameters are supported for the `inline` cache.\n\nTo export cache using `inline` storage, pass `type=inline` to the `--cache-to` option:\n\nAlternatively, you can also export inline cache by setting the build argument `BUILDKIT_INLINE_CACHE=1`, instead of using the `--cache-to` flag:\n\nTo import the resulting cache on a future build, pass `type=registry` to `--cache-from` which lets you extract the cache from inside a Docker image in the specified registry:\n\nFor an introduction to caching see [Docker build cache](https://docs.docker.com/build/cache/).\n\nFor more information on the `inline` cache backend, see the [BuildKit README](https://github.com/moby/buildkit#inline-push-image-and-cache-together).",
    "title": "Inline cache | Docker Docs\n",
    "description": "Embed the build cache into the image",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/17.10/",
    "markdown": "# Docker Engine 17.10 release notes\n\n**Important**: Starting with this release, `docker service create`, `docker service update`, `docker service scale` and `docker service rollback` use non-detached mode as default, use `--detach` to keep the old behaviour.",
    "title": "Docker Engine 17.10 release notes | Docker Docs\n",
    "description": "",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/17.09/",
    "markdown": "# Docker Engine 17.09 release notes\n\n2017-12-07\n\n### [Builder](#builder)\n\n*   Fix config leakage on shared parent stage [moby/moby#33753](https://github.com/moby/moby/issues/33753)\n*   Warn on empty continuation lines only, not on comment-only lines [moby/moby#35004](https://github.com/moby/moby/pull/35004)\n\n### [Client](#client)\n\n*   Set API version on Client even when Ping fails [docker/cli#546](https://github.com/docker/cli/pull/546)\n\n### [Networking](#networking)\n\n*   Overlay fix for transient IP reuse [docker/libnetwork#2016](https://github.com/docker/libnetwork/pull/2016)\n*   Fix reapTime logic in NetworkDB and handle DNS cleanup for attachable container [docker/libnetwork#2017](https://github.com/docker/libnetwork/pull/2017)\n*   Disable hostname lookup on chain exists check [docker/libnetwork#2019](https://github.com/docker/libnetwork/pull/2019)\n*   Fix lint issues [docker/libnetwork#2020](https://github.com/docker/libnetwork/pull/2020)\n*   Restore error type in FindNetwork [moby/moby#35634](https://github.com/moby/moby/pull/35634)\n\n### [Runtime](#runtime)\n\n*   Protect `health monitor` Go channel [moby/moby#35482](https://github.com/moby/moby/pull/35482)\n*   Fix leaking container/exec state [moby/moby#35484](https://github.com/moby/moby/pull/35484)\n*   Add /proc/scsi to masked paths (patch to work around [CVE-2017-16539](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-16539) [moby/moby/#35399](https://github.com/moby/moby/pull/35399)\n*   Vendor tar-split: fix to prevent memory exhaustion issue that could crash Docker daemon [moby/moby/#35424](https://github.com/moby/moby/pull/35424) Fixes [CVE-2017-14992](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-14992)\n*   Fix P/Z HubPullSuite tests [moby/moby#34837](https://github.com/moby/moby/pull/34837)\n\n*   Windows: Add support for version filtering on pull [moby/moby#35090](https://github.com/moby/moby/pull/35090)\n\n*   Windows: Stop filtering Windows manifest lists by version [moby/moby#35117](https://github.com/moby/moby/pull/35117)\n*   Use rslave instead of rprivate in chroot archive [moby/moby/#35217](https://github.com/moby/moby/pull/35217)\n*   Remove container rootfs mountPath after unmount [moby/moby#34573](https://github.com/moby/moby/pull/34573)\n*   Fix honoring tmpfs size of user /dev/shm mount [moby/moby#35316](https://github.com/moby/moby/pull/35316)\n*   Don't abort when setting may\\_detach\\_mounts (log the error instead) [moby/moby#35172](https://github.com/moby/moby/pull/35172)\n*   Fix version comparison when negotiating the API version [moby/moby#35008](https://github.com/moby/moby/pull/35008)\n\n### [Swarm mode](#swarm-mode)\n\n*   Increase gRPC request timeout when sending snapshots [docker/swarmkit#2404](https://github.com/docker/swarmkit/pull/2404)\n\n*   Fix node filtering when there is no log driver [docker/swarmkit#2442](https://github.com/docker/swarmkit/pull/2442)\n*   Add an error on attempt to change cluster name [docker/swarmkit/#2454](https://github.com/docker/swarmkit/pull/2454)\n*   Delete node attachments when node is removed [docker/swarmkit/#2456](https://github.com/docker/swarmkit/pull/2456)\n*   Provide custom gRPC dialer to override default proxy dialer [docker/swarmkit/#2457](https://github.com/docker/swarmkit/pull/2457)\n*   Avoids recursive readlock on swarm info [moby/moby#35388](https://github.com/moby/moby/pull/35388)\n\n2017-09-26\n\n### [Builder](#builder-1)\n\n*   Add `--chown` flag to `ADD/COPY` commands in Dockerfile [moby/moby#34263](https://github.com/moby/moby/pull/34263)\n\n*   Fix cloning unneeded files while building from git repositories [moby/moby#33704](https://github.com/moby/moby/pull/33704)\n\n### [Client](#client-1)\n\n*   Allow extension fields in the v3.4 version of the compose format [docker/cli#452](https://github.com/docker/cli/pull/452)\n*   Make compose file allow to specify names for non-external volume [docker/cli#306](https://github.com/docker/cli/pull/306)\n*   Support `--compose-file -` as stdin [docker/cli#347](https://github.com/docker/cli/pull/347)\n*   Support `start_period` for healthcheck in Docker Compose [docker/cli#475](https://github.com/docker/cli/pull/475)\n\n*   Add support for `stop-signal` in docker stack commands [docker/cli#388](https://github.com/docker/cli/pull/388)\n*   Add support for update order in compose deployments [docker/cli#360](https://github.com/docker/cli/pull/360)\n*   Add ulimits to unsupported compose fields [docker/cli#482](https://github.com/docker/cli/pull/482)\n*   Add `--format` to `docker-search` [docker/cli#440](https://github.com/docker/cli/pull/440)\n\n*   Show images digests when `{{.Digest}}` is in format [docker/cli#439](https://github.com/docker/cli/pull/439)\n*   Print output of `docker stack rm` on `stdout` instead of `stderr` [docker/cli#491](https://github.com/docker/cli/pull/491)\n\n*   Fix `docker history --format {{json .}}` printing human-readable timestamps instead of ISO8601 when `--human=true` [docker/cli#438](https://github.com/docker/cli/pull/438)\n*   Fix idempotence of `docker stack deploy` when secrets or configs are used [docker/cli#509](https://github.com/docker/cli/pull/509)\n*   Fix presentation of random host ports [docker/cli#404](https://github.com/docker/cli/pull/404)\n*   Fix redundant service restarts when service created with multiple secrets [moby/moby#34746](https://github.com/moby/moby/issues/34746)\n\n### [Logging](#logging)\n\n*   Fix Splunk logger not transmitting log data when tag is empty and raw-mode is used [moby/moby#34520](https://github.com/moby/moby/pull/34520)\n\n### [Networking](#networking-1)\n\n*   Add the control plane MTU option in the daemon config [moby/moby#34103](https://github.com/moby/moby/pull/34103)\n*   Add service virtual IP to sandbox's loopback address [docker/libnetwork#1877](https://github.com/docker/libnetwork/pull/1877)\n\n### [Runtime](#runtime-1)\n\n*   Graphdriver: promote overlay2 over aufs [moby/moby#34430](https://github.com/moby/moby/pull/34430)\n*   LCOW: Additional flags for VHD boot [moby/moby#34451](https://github.com/moby/moby/pull/34451)\n*   LCOW: Don't block export [moby/moby#34448](https://github.com/moby/moby/pull/34448)\n*   LCOW: Dynamic sandbox management [moby/moby#34170](https://github.com/moby/moby/pull/34170)\n*   LCOW: Force Hyper-V Isolation [moby/moby#34468](https://github.com/moby/moby/pull/34468)\n*   LCOW: Move toolsScratchPath to /tmp [moby/moby#34396](https://github.com/moby/moby/pull/34396)\n*   LCOW: Remove hard-coding [moby/moby#34398](https://github.com/moby/moby/pull/34398)\n*   LCOW: WORKDIR correct handling [moby/moby#34405](https://github.com/moby/moby/pull/34405)\n*   Windows: named pipe mounts [moby/moby#33852](https://github.com/moby/moby/pull/33852)\n\n*   Fix \"permission denied\" errors when accessing volume with SELinux enforcing mode [moby/moby#34684](https://github.com/moby/moby/pull/34684)\n*   Fix layers size reported as `0` in `docker system df` [moby/moby#34826](https://github.com/moby/moby/pull/34826)\n*   Fix some \"device or resource busy\" errors when removing containers on RHEL 7.4 based kernels [moby/moby#34886](https://github.com/moby/moby/pull/34886)\n\n### [Swarm mode](#swarm-mode-1)\n\n*   Include whether the managers in the swarm are autolocked as part of `docker info` [docker/cli#471](https://github.com/docker/cli/pull/471)\n\n*   Add 'docker service rollback' subcommand [docker/cli#205](https://github.com/docker/cli/pull/205)\n\n*   Fix managers failing to join if the gRPC snapshot is larger than 4MB [docker/swarmkit#2375](https://github.com/docker/swarmkit/pull/2375)\n*   Fix \"permission denied\" errors for configuration file in SELinux-enabled containers [moby/moby#34732](https://github.com/moby/moby/pull/34732)\n*   Fix services failing to deploy on ARM nodes [moby/moby#34021](https://github.com/moby/moby/pull/34021)\n\n### [Packaging](#packaging)\n\n*   Build scripts for ppc64el on Ubuntu [docker/docker-ce-packaging#43](https://github.com/docker/docker-ce-packaging/pull/43)\n\n### [Deprecation](#deprecation)\n\n*   Remove deprecated `--enable-api-cors` daemon flag [moby/moby#34821](https://github.com/moby/moby/pull/34821)",
    "title": "Docker Engine 17.09 release notes | Docker Docs\n",
    "description": "",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/cache/backends/local/",
    "markdown": "# Local cache | Docker Docs\n\nThe `local` cache store is a simple cache option that stores your cache as files in a directory on your filesystem, using an [OCI image layout](https://github.com/opencontainers/image-spec/blob/main/image-layout.md) for the underlying directory structure. Local cache is a good choice if you're just testing, or if you want the flexibility to self-manage a shared storage solution.\n\nThe following table describes the available CSV parameters that you can pass to `--cache-to` and `--cache-from`.\n\n| Name | Option | Type | Default | Description |\n| --- | --- | --- | --- | --- |\n| `src` | `cache-from` | String |     | Path of the local directory where cache gets imported from. |\n| `digest` | `cache-from` | String |     | Digest of manifest to import, see [cache versioning](#cache-versioning). |\n| `dest` | `cache-to` | String |     | Path of the local directory where cache gets exported to. |\n| `mode` | `cache-to` | `min`,`max` | `min` | Cache layers to export, see [cache mode](https://docs.docker.com/build/cache/backends/#cache-mode). |\n| `oci-mediatypes` | `cache-to` | `true`,`false` | `true` | Use OCI media types in exported manifests, see [OCI media types](https://docs.docker.com/build/cache/backends/#oci-media-types). |\n| `compression` | `cache-to` | `gzip`,`estargz`,`zstd` | `gzip` | Compression type, see [cache compression](https://docs.docker.com/build/cache/backends/#cache-compression). |\n| `compression-level` | `cache-to` | `0..22` |     | Compression level, see [cache compression](https://docs.docker.com/build/cache/backends/#cache-compression). |\n| `force-compression` | `cache-to` | `true`,`false` | `false` | Forcibly apply compression, see [cache compression](https://docs.docker.com/build/cache/backends/#cache-compression). |\n| `ignore-error` | `cache-to` | Boolean | `false` | Ignore errors caused by failed cache exports. |\n\nIf the `src` cache doesn't exist, then the cache import step will fail, but the build continues.\n\nThis section describes how versioning works for caches on a local filesystem, and how you can use the `digest` parameter to use older versions of cache.\n\nIf you inspect the cache directory manually, you can see the resulting OCI image layout:\n\nLike other cache types, local cache gets replaced on export, by replacing the contents of the `index.json` file. However, previous caches will still be available in the `blobs` directory. These old caches are addressable by digest, and kept indefinitely. Therefore, the size of the local cache will continue to grow (see [`moby/buildkit#1896`](https://github.com/moby/buildkit/issues/1896) for more information).\n\nWhen importing cache using `--cache-to`, you can specify the `digest` parameter to force loading an older version of the cache, for example:\n\nFor an introduction to caching see [Docker build cache](https://docs.docker.com/build/cache/).\n\nFor more information on the `local` cache backend, see the [BuildKit README](https://github.com/moby/buildkit#local-directory-1).",
    "title": "Local cache | Docker Docs\n",
    "description": "Manage build cache with Amazon S3 buckets",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/engine/release-notes/17.07/",
    "markdown": "# Docker Engine 17.07 release notes\n\n2017-08-29\n\n### [API & Client](#api--client)\n\n*   Add support for proxy configuration in config.json [docker/cli#93](https://github.com/docker/cli/pull/93)\n*   Enable pprof/debug endpoints by default [moby/moby#32453](https://github.com/moby/moby/pull/32453)\n*   Passwords can now be passed using `STDIN` using the new `--password-stdin` flag on `docker login` [docker/cli#271](https://github.com/docker/cli/pull/271)\n\n*   Add `--detach` to docker scale [docker/cli#243](https://github.com/docker/cli/pull/243)\n\n*   Prevent `docker logs --no-stream` from hanging due to non-existing containers [moby/moby#34004](https://github.com/moby/moby/pull/34004)\n\n*   Fix `docker stack ps` printing error to `stdout` instead of `stderr` [docker/cli#298](https://github.com/docker/cli/pull/298)\n\n*   Fix progress bar being stuck on `docker service create` if an error occurs during deploy [docker/cli#259](https://github.com/docker/cli/pull/259)\n*   Improve presentation of progress bars in interactive mode [docker/cli#260](https://github.com/docker/cli/pull/260) [docker/cli#237](https://github.com/docker/cli/pull/237)\n*   Print a warning if `docker login --password` is used, and recommend `--password-stdin` [docker/cli#270](https://github.com/docker/cli/pull/270)\n*   Make API version negotiation more robust [moby/moby#33827](https://github.com/moby/moby/pull/33827)\n*   Hide `--detach` when connected to daemons older than Docker 17.05 [docker/cli#219](https://github.com/docker/cli/pull/219)\n\n*   Add `scope` filter in `GET /networks/(id or name)` [moby/moby#33630](https://github.com/moby/moby/pull/33630)\n\n### [Builder](#builder)\n\n*   Implement long running interactive session and sending build context incrementally [moby/moby#32677](https://github.com/moby/moby/pull/32677) [docker/cli#231](https://github.com/docker/cli/pull/231) [moby/moby#33859](https://github.com/moby/moby/pull/33859)\n*   Warn on empty continuation lines [moby/moby#33719](https://github.com/moby/moby/pull/33719)\n\n*   Fix `.dockerignore` entries with a leading `/` not matching anything [moby/moby#32088](https://github.com/moby/moby/pull/32088)\n\n### [Logging](#logging)\n\n*   Fix wrong filemode for rotate log files [moby/moby#33926](https://github.com/moby/moby/pull/33926)\n*   Fix stderr logging for journald and syslog [moby/moby#33832](https://github.com/moby/moby/pull/33832)\n\n### [Runtime](#runtime)\n\n*   Allow stopping of paused container [moby/moby#34027](https://github.com/moby/moby/pull/34027)\n\n*   Add quota support for the overlay2 storage driver [moby/moby#32977](https://github.com/moby/moby/pull/32977)\n\n*   Remove container locks on `docker ps` [moby/moby#31273](https://github.com/moby/moby/pull/31273)\n*   Store container names in memdb [moby/moby#33886](https://github.com/moby/moby/pull/33886)\n*   Fix race condition between `docker exec` and `docker pause` [moby/moby#32881](https://github.com/moby/moby/pull/32881)\n*   Devicemapper: Rework logging and add `--storage-opt dm.libdm_log_level` [moby/moby#33845](https://github.com/moby/moby/pull/33845)\n*   Devicemapper: Prevent \"device in use\" errors if deferred removal is enabled, but not deferred deletion [moby/moby#33877](https://github.com/moby/moby/pull/33877)\n*   Devicemapper: Use KeepAlive to prevent tasks being garbage-collected while still in use [moby/moby#33376](https://github.com/moby/moby/pull/33376)\n*   Report intermediate prune results if prune is cancelled [moby/moby#33979](https://github.com/moby/moby/pull/33979)\n\n*   Fix run `docker rename <container-id> new_name` concurrently resulting in the having multiple names [moby/moby#33940](https://github.com/moby/moby/pull/33940)\n\n*   Fix file-descriptor leak and error handling [moby/moby#33713](https://github.com/moby/moby/pull/33713)\n\n*   Fix SIGSEGV when running containers [docker/cli#303](https://github.com/docker/cli/pull/303)\n\n*   Prevent a goroutine leak when healthcheck gets stopped [moby/moby#33781](https://github.com/moby/moby/pull/33781)\n*   Image: Improve store locking [moby/moby#33755](https://github.com/moby/moby/pull/33755)\n*   Fix Btrfs quota groups not being removed when container is destroyed [moby/moby#29427](https://github.com/moby/moby/pull/29427)\n*   Libcontainerd: fix defunct containerd processes not being properly reaped [moby/moby#33419](https://github.com/moby/moby/pull/33419)\n*   Preparations for Linux Containers on Windows\n    *   LCOW: Dedicated scratch space for service VM utilities [moby/moby#33809](https://github.com/moby/moby/pull/33809)\n    *   LCOW: Support most operations excluding remote filesystem [moby/moby#33241](https://github.com/moby/moby/pull/33241) [moby/moby#33826](https://github.com/moby/moby/pull/33826)\n    *   LCOW: Change directory from lcow to \"Linux Containers\" [moby/moby#33835](https://github.com/moby/moby/pull/33835)\n    *   LCOW: pass command arguments without extra quoting [moby/moby#33815](https://github.com/moby/moby/pull/33815)\n    *   LCOW: Updates necessary due to platform schema change [moby/moby#33785](https://github.com/moby/moby/pull/33785)\n\n### [Swarm mode](#swarm-mode)\n\n*   Initial support for plugable secret backends [moby/moby#34157](https://github.com/moby/moby/pull/34157) [moby/moby#34123](https://github.com/moby/moby/pull/34123)\n*   Sort swarm stacks and nodes using natural sorting [docker/cli#315](https://github.com/docker/cli/pull/315)\n*   Make engine support cluster config event [moby/moby#34032](https://github.com/moby/moby/pull/34032)\n*   Only pass a join address when in the process of joining a cluster [moby/moby#33361](https://github.com/moby/moby/pull/33361)\n*   Fix error during service creation if a network with the same name exists both as \"local\" and \"swarm\" scoped network [docker/cli#184](https://github.com/docker/cli/pull/184)\n*   (experimental) Add support for plugins on swarm [moby/moby#33575](https://github.com/moby/moby/pull/33575)",
    "title": "Docker Engine 17.07 release notes | Docker Docs\n",
    "description": "",
    "languageCode": "en"
  },
  {
    "url": "https://docs.docker.com/build/cache/backends/registry/",
    "markdown": "# Registry cache | Docker Docs\n\nThe `registry` cache storage can be thought of as an extension to the `inline` cache. Unlike the `inline` cache, the `registry` cache is entirely separate from the image, which allows for more flexible usage - `registry`\\-backed cache can do everything that the inline cache can do, and more:\n\n*   Allows for separating the cache and resulting image artifacts so that you can distribute your final image without the cache inside.\n*   It can efficiently cache multi-stage builds in `max` mode, instead of only the final stage.\n*   It works with other exporters for more flexibility, instead of only the `image` exporter.\n\nThis cache storage backend is not supported with the default `docker` driver. To use this feature, create a new builder using a different driver. See [Build drivers](https://docs.docker.com/build/drivers/) for more information.\n\nUnlike the simpler `inline` cache, the `registry` cache supports several configuration parameters:\n\nThe following table describes the available CSV parameters that you can pass to `--cache-to` and `--cache-from`.\n\n| Name | Option | Type | Default | Description |\n| --- | --- | --- | --- | --- |\n| `ref` | `cache-to`,`cache-from` | String |     | Full name of the cache image to import. |\n| `mode` | `cache-to` | `min`,`max` | `min` | Cache layers to export, see [cache mode](https://docs.docker.com/build/cache/backends/#cache-mode). |\n| `oci-mediatypes` | `cache-to` | `true`,`false` | `true` | Use OCI media types in exported manifests, see [OCI media types](https://docs.docker.com/build/cache/backends/#oci-media-types). |\n| `compression` | `cache-to` | `gzip`,`estargz`,`zstd` | `gzip` | Compression type, see [cache compression](https://docs.docker.com/build/cache/backends/#cache-compression). |\n| `compression-level` | `cache-to` | `0..22` |     | Compression level, see [cache compression](https://docs.docker.com/build/cache/backends/#cache-compression). |\n| `force-compression` | `cache-to` | `true`,`false` | `false` | Forcibly apply compression, see [cache compression](https://docs.docker.com/build/cache/backends/#cache-compression). |\n| `ignore-error` | `cache-to` | Boolean | `false` | Ignore errors caused by failed cache exports. |\n\nYou can choose any valid value for `ref`, as long as it's not the same as the target location that you push your image to. You might choose different tags (e.g. `foo/bar:latest` and `foo/bar:build-cache`), separate image names (e.g. `foo/bar` and `foo/bar-cache`), or even different repositories (e.g. `docker.io/foo/bar` and `ghcr.io/foo/bar`). It's up to you to decide the strategy that you want to use for separating your image from your cache images.\n\nIf the `--cache-from` target doesn't exist, then the cache import step will fail, but the build continues.\n\nFor an introduction to caching see [Docker build cache](https://docs.docker.com/build/cache/).\n\nFor more information on the `registry` cache backend, see the [BuildKit README](https://github.com/moby/buildkit#registry-push-image-and-cache-separately).",
    "title": "Registry cache | Docker Docs\n",
    "description": "Manage build cache with an OCI registry",
    "languageCode": "en"
  }
]