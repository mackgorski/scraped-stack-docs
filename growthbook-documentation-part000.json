[
  {
    "url": "https://docs.growthbook.io/",
    "markdown": "# GrowthBook Documentation | GrowthBook Docs\n\n## Introduction\n\nGrowthBook is an open-source platform for feature flagging and A/B testing built for data teams, engineers, and product managers. It's great whether you're looking to just analyze experiment results or looking to make it easier to deploy code.\n\n### Quick Links[​](#quick-links \"Direct link to Quick Links\")\n\n## Our Goals[​](#our-goals \"Direct link to Our Goals\")\n\nCompanies invest thousands of hours building internal tools for feature flagging and experimentation (A/B testing). They do this to run these systems on their own infrastructure, utilize their own data, and ensure deep integration with their code.\n\nGrowthBook gives data, engineering, and product teams the power of a customizable platform without needing to build it themselves.\n\n*   We believe that **feature flagging** is the best way to release features, and **A/B testing** is the best way to measure their impact.\n    \n*   We believe A/B testing should sit on top of your **existing data and metrics**, wherever they live and however they are defined.\n    \n*   We believe in **data transparency**. See the SQL behind every query, export results as a Jupyter notebook, and view our [stats engines on GitHub](https://github.com/growthbook/growthbook/tree/main/packages/stats).\n    \n*   We are fanatical about **performance**. Our [SDKs](https://docs.growthbook.io/lib) are crazy fast, lightweight, and evaluate everything locally with no network requests.\n    \n*   We believe in **open source**. GrowthBook is open source and free to use. You can run it on your own infrastructure or use our hosted version.\n    \n*   We believe in **privacy & security**. We don't collect any data about your users, and you can run GrowthBook on your own infrastructure.\n    \n*   We believe good ideas come from everywhere. GrowthBook gives you feature flags, making it easy to **test everything** and seamlessly integrate experimentation into your process.\n    \n\nUse the menu or the **Previous**/**Next** links to navigate these docs.\n\n[Join us on Slack](https://slack.growthbook.io/?ref=docs-home) if you need help, want to chat, or are thinking of a new feature. We're here to help—and to make GrowthBook even better.",
    "title": "GrowthBook Documentation | GrowthBook Docs",
    "description": "GrowthBook is an open-source platform for feature flagging and A/B testing built for data teams, engineers, and product managers.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/opensearch.xml",
    "markdown": null,
    "title": "",
    "description": null,
    "languageCode": null
  },
  {
    "url": "https://docs.growthbook.io/using",
    "markdown": "# Using GrowthBook | GrowthBook Docs\n\n## Guide on using GrowthBook\n\n## Introduction[​](#introduction \"Direct link to Introduction\")\n\nIn today's data-driven world, businesses of all sizes rely on A/B testing to make data-driven decisions. A/B testing, also known as split testing, has come a long way from a simple tool to optimize websites, and is often used as a powerful tool to determine the impact of any changes to your application. By measuring how your user behavior and engagement changes in a controlled manner, you can determine causally if your hypothesis is correct, and make informed data-driven decisions that improve user experience, increase conversions, and drive growth.\n\nThis document is intended to be an open source and continuously updated guide to A/B testing. Whether you're a seasoned expert at running experiments, or just starting out, this book will provide you with the knowledge and skills you need to run a successful A/B testing program, with a specific focus on GrowthBook, an open source feature flagging and A/B testing platform.\n\nIn the following chapters, we'll start with an overview of what A/B testing is, and familiarize you with the terms that are commonly used. We'll cover the basics of statistical significance, sample size, and other key concepts that are essential for understanding A/B testing. Next, we'll cover the best practices for running an A/B test, followed by some of the common mistakes and pitfalls that can affect experiment programs. Finally, we'll go beyond individual A/B tests and talk about how to run an experimentation program, and then specifics of how to do this well with GrowthBook.\n\nWe hope after reading this guide, you'll understand that A/B testing is a critical tool for determining causal impact of the changes you make, as well as optimizing flows. By making informed data-driven decisions, you can improve user experience, increase conversions, and drive growth. With the open source A/B testing tool, GrowthBook, you have a powerful and flexible platform that can help you run experiments quickly and easily. We hope that this guide will give you the knowledge and skills you need to run a successful A/B testing program and make data-driven decisions. Whether you're a developer, product manager, data scientist, marketer, or business owner, A/B testing can help you achieve your goals and drive growth.\n\n## Contents[​](#contents \"Direct link to Contents\")\n\n*   [Fundamentals of AB Testing](https://docs.growthbook.io/using/fundamentals)\n*   [Experimentation Best Practices](https://docs.growthbook.io/using/experimentation-best-practices)\n*   [Experimentation Common Problems](https://docs.growthbook.io/using/experimentation-problems)\n*   [Experimentation As Part of Your Development Process](https://docs.growthbook.io/using/product-development)\n*   [Experimenting in GrowthBook](https://docs.growthbook.io/using/experimenting)\n*   [GrowthBook Organization Best Practices](https://docs.growthbook.io/using/growthbook-best-practices)\n*   [Securing GrowthBook](https://docs.growthbook.io/using/security)\n*   [Experimentation Programs](https://docs.growthbook.io/using/programs)\n\n## Other resources[​](#other-resources \"Direct link to Other resources\")\n\nAt GrowthBook we highly recommended the book: \"Trustworthy Online Controlled Experiments: A Practical Guide to A/B Testing\" by Ron Kohavi, Diane Tang, and Ya Xu. It is available on Amazon or on Ronny's site at [https://www.exp-platform.com/Documents/GuideControlledExperiments.pdf](https://www.exp-platform.com/Documents/GuideControlledExperiments.pdf)",
    "title": "Using GrowthBook | GrowthBook Docs",
    "description": "Introduction",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/overview",
    "markdown": "# An overview of the GrowthBook Platform\n\n## What is GrowthBook?\n\nGrowthBook is a modular platform. You can use it for either Feature Flags, Experiment Analysis, or both.\n\n[**Feature Flags**](https://docs.growthbook.io/app/features) you create in the GrowthBook UI are published to our API as a JSON file. Pass this JSON into our SDKs and use the feature flags throughout your code. If a feature is running as part of an A/B test, we'll fire a tracking callback in the SDK so you can record that event in your data warehouse or analytics platform for later analysis.\n\n[**Experiment Analysis**](https://docs.growthbook.io/app/experiment-configuration) queries your data warehouse for raw experiment data and runs it through our stats engine to produce a report. No raw user-level events or PII are ever sent to GrowthBook. We only get back aggregate info instead (sums, sums of squares, etc.).\n\n![GrowthBook: How it Works Diagram](https://docs.growthbook.io/assets/images/feature-flagging-experimentation-diagram-766-79a603a8de022d325d6e6e7f0cd52d3f.png)\n\n## Feature Flags[​](#feature-flags \"Direct link to Feature Flags\")\n\n[Feature flags](https://docs.growthbook.io/app/features) are a very powerful developer tool. They give you deep control over how and when new functionality is released to your users.\n\nGrowthBook supports 4 types of features:\n\n*   **Boolean (on/off)**\n*   **Number**\n*   **String**\n*   **JSON**\n\nUsing features in your code is easy. Here's an example from our Javascript SDK:\n\n```\n// For boolean featuresif (growthbook.isOn(\"my-feature\")) {  // ... Do something}// For number, string, and JSON featuresconst value = growthbook.getFeatureValue(\"other-feature\", \"fallback\");\n```\n\nGrowthBook also supports multiple environments, so you can, for example, have a feature enabled in **dev** but not **production**.\n\nYou can also change the value of a feature with **Override Rules**. The following types of rules are supported:\n\n*   **Forced Value** - Choose a subset of users based on targeting attributes and assign them all the same value\n*   **Percentage Rollout** - Use random sampling to roll out a new feature value to a percent of users\n*   **A/B Experiment** - Run a controlled A/B test between 2 or more feature values\n\nAll features for an environment are packaged together into a single JSON file. All you need to do is pass this into our [SDKs](https://docs.growthbook.io/lib) along with [user targeting attributes](https://docs.growthbook.io/features/targeting).\n\nRead more about [features here](https://docs.growthbook.io/app/features).\n\n## Experiment Analysis[​](#experiment-analysis \"Direct link to Experiment Analysis\")\n\nGrowthBook needs to connect to your [Data Source](https://docs.growthbook.io/warehouses) in order to query experiment results. We support all of the popular SQL data warehouses in addition to Mixpanel and Google Analytics. GrowthBook is extremely flexible and can support almost any schema structure with a little bit of configuration.\n\n![Data warehouses supported by GrowthBook](https://docs.growthbook.io/assets/images/GrowthBook-supported-DB-766-085e81b3b1c0eca0a0a3b88a05aba730.png)\n\nOnce connected to a data source, you need to build a re-usable library of [Metrics](https://docs.growthbook.io/app/metrics). Metrics are what your experiments are trying to improve. Metrics are defined via SQL (if your data source supports it) or a simple query builder. The following types are supported:\n\n*   **binomial** - simple yes/no conversion metrics (e.g. `started trial`, `bounce rate`, `purchased`)\n*   **count** - when the number or magnitude of conversions matters (e.g. `downloads per user`, `points earned`)\n*   **revenue** - the amount of revenue earned (e.g. `revenue per user`, `average order value`)\n*   **duration** - the time it takes to do something (e.g. `page load time`, `time on site`)\n\nOnce these are metrics are set up, you can import experiments and start analyzing the results. GrowthBook uses a [Bayesian statistics engine](https://docs.growthbook.io/statistics/overview) to determine the probability that a variation is better than the control, as well as how much better it is and how risky it is to stop the experiment now.\n\n![Results Table](https://docs.growthbook.io/assets/images/results-table-781167fd137533b109a3d111851125bf.png)\n\nYour data team can drill down into results by custom [dimensions](https://docs.growthbook.io/app/dimensions), view the raw SQL that GrowthBook is running on your data warehouse, and export results to a Jupyter notebook for even deeper analysis.\n\nRead more about [experiments here](https://docs.growthbook.io/experiments).\n\n## Use Cases[​](#use-cases \"Direct link to Use Cases\")\n\nThere are typically three reasons that teams use GrowthBook.\n\n### 1\\. Full Experimentation Platform[​](#1-full-experimentation-platform \"Direct link to 1. Full Experimentation Platform\")\n\nIn this use case, companies use Feature Flags and our SDKs to run experiments in their applications. Then they use our Experiment Analysis to look at the results and decide on a winner.\n\nThis is best for companies that are either just starting with experimentation or want to completely switch away from their current way of doing things.\n\n### 2\\. Feature Flags Only[​](#2-feature-flags-only \"Direct link to 2. Feature Flags Only\")\n\nIn this use case, companies don't run experiments at all and just use GrowthBook feature flags within their engineering team.\n\nThis is best for companies that don't have enough traffic to run full experiments, but still want all of the benefits that feature flags provide. It's also good for companies that know they will want to run experiments in the future and want to start instrumenting their applications today to get ready.\n\n### 3\\. Experiment Analysis Only[​](#3-experiment-analysis-only \"Direct link to 3. Experiment Analysis Only\")\n\nIn this use case, companies are already running experiments and analyzing results usually with either a home-built reporting system or by manually creating Jupyter notebooks. They use GrowthBook to automate and improve the analysis process to save time and make better decisions.\n\nThis is best for companies that already have a robust process for running experiments and just need a little help analyzing results at scale.\n\n## Next Steps[​](#next-steps \"Direct link to Next Steps\")",
    "title": "An overview of the GrowthBook Platform | GrowthBook Docs",
    "description": "What is GrowthBook and how does it work? Learn about the GrowthBook platform and how it can help you grow your business.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/quick-start",
    "markdown": "# Quick Start Guide to GrowthBook\n\nThis guide walks you through the basics of a full integration of GrowthBook for both feature flagging and A/B testing. You can use GrowthBook for feature flags, running no-code experiments with a visual editor, analyzing experiment results, or any combination of the above. Feel free to skip to the sections that best apply to your use case.\n\nnote\n\nIn our documentation, we use **A/B test** and **experiment** interchangeably.\n\n## Set Up GrowthBook[​](#set-up-growthbook \"Direct link to Set Up GrowthBook\")\n\nUse GrowthBook hosted on our **cloud** or **self-host** it. For the easiest setup, [sign up for a free account](https://app.growthbook.io/). If you prefer to self-host, follow the [instructions here](https://docs.growthbook.io/self-host) or on our GitHub page.\n\nOnce you have a GrowthBook account set up, you're ready to start feature flagging and experimenting!\n\n## Feature Flags[​](#feature-flags \"Direct link to Feature Flags\")\n\n### Step 1. Add an SDK Connection[​](#step-1-add-an-sdk-connection \"Direct link to Step 1. Add an SDK Connection\")\n\nTo use Feature Flags, use an SDK Connection to connect GrowthBook to your app.\n\nFrom the menu, choose **SDK Configuration** → **SDK Connections**. Then, click **Add SDK Connection**.\n\nName your SDK connection, select the language you're using in your application, and configure additional options. Don't worry! These settings can be changed at any time. To use GrowthBook with multiple languages, create a separate SDK Connection for each one.\n\n![New SDK Connection](https://docs.growthbook.io/images/quick-start/quick-start-new-sdk-connection.png)\n\nWith the SDK Connection created, you're now ready to install the SDK in your application.\n\n### Step 2. Integrate GrowthBook Into Your Application[​](#step-2-integrate-growthbook-into-your-application \"Direct link to Step 2. Integrate GrowthBook Into Your Application\")\n\nUse GrowthBook SDKs to evaluate feature flags and run experiments. Tailored instructions based on your selected language and settings will guide you through the installation process. The [full SDK docs](https://docs.growthbook.io/lib) are also available.\n\nThe basics of installing the SDKs are:\n\n*   Grab the [GrowthBook SDK](https://docs.growthbook.io/lib) package for your language.\n*   Add the basic initialization code to your application.\n*   Make sure `clientKey` and `apiHost` are set correctly.\n*   Optionally, add any targeting attributes you wish to use for feature flags and experiments.\n\ntip\n\nIf your application has multiple languages or platforms, you can create a separate SDK Connection for each one. GrowthBook features and experiments will work the same across all languages, platforms, and environments!\n\n### Step 3. Create a Feature Flag[​](#step-3-create-a-feature-flag \"Direct link to Step 3. Create a Feature Flag\")\n\nOn the **Features** page, create your first feature flag.\n\n![Create Feature](https://docs.growthbook.io/images/features/feature-create-feature-1.png)\n\nThe **Feature Key** is what you will reference in your application and cannot be changed later.\n\nFeature flags in GrowthBook are robust, supporting advanced [targeting](https://docs.growthbook.io/features/targeting), powerful [rule evaluation](https://docs.growthbook.io/features/rules), [pre-requisite features](https://docs.growthbook.io/features/prerequisites), JSON schema validation, and more. In this quick start, we'll just stick with a simple boolean feature flag that is always `on` or `off` for everyone.\n\n### Step 4. Use the Feature in Your Application[​](#step-4-use-the-feature-in-your-application \"Direct link to Step 4. Use the Feature in Your Application\")\n\nWhen you create your first feature, you'll see instructions on how to use it in your application. Here's an example using our JavaScript SDK:\n\n```\nif (gb.isOn(\"my-feature\")) {    console.log(\"It's On!\")}\n```\n\nIt really is that simple to get started! For next steps, we recommend reading our [Feature Flag Basics](https://docs.growthbook.io/features/basics) page, which goes into more depth.\n\nFeature flags are the foundation for powerful experimentation. In the next section, we show you how to use them to run no-code experimentation using our Visual Editor. Need more advanced options? Dive into our [complete guide for code-based experimentation](https://docs.growthbook.io/feature-flag-experiments).\n\n## No-Code Experimentation[​](#no-code-experimentation \"Direct link to No-Code Experimentation\")\n\n### Step 1. Create an SDK Connection[​](#step-1-create-an-sdk-connection \"Direct link to Step 1. Create an SDK Connection\")\n\nNavigate to **SDK Configuration** → **SDK Connections**. Then, add a new SDK Connection. For the language, choose any no/low-code options: **Webflow**, **Wordpress**, **Shopify**, or **Script Tag**.\n\n![Add SDK Connection](https://docs.growthbook.io/assets/images/webflow-sdk-connection-e862e170a41e8efc1a1496130070b738.png)\n\n### Step 2. Add the Script Tag to Your Website's Head[​](#step-2-add-the-script-tag-to-your-websites-head \"Direct link to Step 2. Add the Script Tag to Your Website's Head\")\n\nWhen you create an SDK Connection, GrowthBook displays tailored instructions based on your no-code platform and settings. Typically, these instructions involve adding a single script tag to the head of your website. It will look something like the example below (replace `YOUR_CLIENT_KEY` with your uniquely generated client ID):\n\n```\n<script async  data-client-key=\"YOUR_CLIENT_KEY\"  src=\"https://cdn.jsdelivr.net/npm/@growthbook/growthbook/dist/bundles/auto.min.js\"></script>\n```\n\n### Step 3. Install the GrowthBook Chrome Extension[​](#step-3-install-the-growthbook-chrome-extension \"Direct link to Step 3. Install the GrowthBook Chrome Extension\")\n\nBefore using the Visual Editor, you must [install our Chrome Extension](https://chromewebstore.google.com/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia).\n\nThis extension enables you to make changes to your website by pointing and clicking. Use it to test different headlines, CTA text, hero images, and more.\n\n### Step 4. Create a New Visual Experiment[​](#step-4-create-a-new-visual-experiment \"Direct link to Step 4. Create a New Visual Experiment\")\n\nTo use the visual editor, add a new experiment. Go to **Experiments** and click **Add Experiment**.\n\n![Design a new experiment](https://docs.growthbook.io/assets/images/add-experiment-modal-15681f50cca71852a1723562ee4bd078.png)\n\nChoose **Design a New Experiment**. Then, fill out the fields (hypothesis, variation names, goal metrics, etc.). Don't worry, you can change these values later.\n\nOnce you created an experiment, you will be prompted to launch the Visual Editor.\n\nUse the editor to make changes to your site. To return to GrowthBook, click the **Done** button. We have an entire guide dedicated to [setting up and using the Visual Editor](https://docs.growthbook.io/app/visual), so check it out if you get stuck or want to try some of the more advanced features like drag-and-drop reordering.\n\n### Step 5. Start Your Experiment![​](#step-5-start-your-experiment \"Direct link to Step 5. Start Your Experiment!\")\n\nWhen you are ready, click the **Start Experiment** button. Within seconds, GrowthBook will begin to bucket users into your variations. You can just as easily stop or make changes if needed.\n\nFollow the Experiment Analysis section below to learn how to connect GrowthBook to your data and view results. Depending on the analytics tool and data warehouse that you use, it can take up to 24 hours for results to start showing up after you start an experiment.\n\n## Experiment Analysis[​](#experiment-analysis \"Direct link to Experiment Analysis\")\n\n### Step 1. Connect to Your Data Warehouse[​](#step-1-connect-to-your-data-warehouse \"Direct link to Step 1. Connect to Your Data Warehouse\")\n\nGrowthBook is warehouse native: it connects to your data warehouse and queries it to get the results of your experiments. We support all the popular SQL data warehouses such as BigQuery, Snowflake, Postgres, MySQL, Redshift, Databricks, and even Mixpanel. GrowthBook is extremely flexible and can support almost any schema structure with a bit of configuration.\n\n**Don't have a data warehouse?**\n\nTo connect GrowthBook to your data warehouse, add a data source. Go to **Metrics and Data** → **Data Sources**. From here, click **Add Data Source**. Follow the instructions to connect to your data warehouse and event trackers. Providing your data warehouse information enables GrowthBook to connect to your data warehouse and execute queries. The event tracker information allows GrowthBook to generate more accurate SQL templates given the schema the event tracker uses.\n\nAdditional guides on [how to set up the data source for your specific data warehouse](https://docs.growthbook.io/warehouses) are available.\n\n### Step 2. Add a Metric or Two[​](#step-2-add-a-metric-or-two \"Direct link to Step 2. Add a Metric or Two\")\n\nGrowthBook needs to know what metrics you want to measure for your experiments. For the easiest setup, we recommend using Fact Tables. Most users create a Fact Table for each type of event (Sign Up, Purchase, etc.). With Fact Tables in place, you can then quickly create a library of metrics (Sign-Up Rate, Revenue per User, Items per Order, etc.).\n\nGo to **Metrics and Data** → **Fact Tables**. Click **Add a Fact Table** and edit the default SQL if needed. Here's an example SQL query for an Orders fact table.\n\n```\nSELECT  user_id,  timestamp,  qty,  amountFROM orders\n```\n\nOnce the fact table is created, you can easily add metrics on top of it. For example, consider a simple proportion metric, which measures the percentage of experiment users who complete an action at least once. In this case, it'd measure the percentage of users who made a purchase.\n\nMetrics in GrowthBook are powerful and have many advanced settings. Read about them on our [Fact Tables page](https://docs.growthbook.io/app/fact-tables).\n\n### Step 3. View Experiment Results[​](#step-3-view-experiment-results \"Direct link to Step 3. View Experiment Results\")\n\nGo to the **Experiments** page. If you implemented an experiment using feature flags or our Visual Editor, your experiment will already be listed. Click through to it. If you ran your experiment outside of GrowthBook instead, that's fine, too! Add a new experiment and select the **Analyze Existing** option.\n\nOnce inside your experiment, go to the **Results** tab. Edit your analysis settings and pick the metrics you created earlier. The results will show up in a table like this:\n\n![Results Table](https://docs.growthbook.io/assets/images/results-table-781167fd137533b109a3d111851125bf.png)\n\nWe have an [entire page in our docs](https://docs.growthbook.io/app/experiment-results) just about these results and how to interpret them.\n\n## Next Steps[​](#next-steps \"Direct link to Next Steps\")",
    "title": "Quick Start Guide to GrowthBook | GrowthBook Docs",
    "description": "The basic instructions for getting started with GrowthBook",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/app/features",
    "markdown": "# Feature Flags | GrowthBook Docs\n\nFeature Flags enable you to change your application's behavior from within the GrowthBook UI. For example, turn on/off a sales banner or change the title of your pricing page.\n\nYou can set a global value for everyone, use advanced targeting to assign values to users, and run experiments to see which value is better.\n\nFeature flags aren't limited to front-end changes. Use them on your back-end to gradually release a new ML model or enable new fields in an API response.\n\n## Why use Feature Flags?[​](#why-use-feature-flags \"Direct link to Why use Feature Flags?\")\n\nFeature flags are a powerful tool for decoupling code deploys from feature releases. This enables you to release code more frequently and with less risk. It also enables you to do things like easily launch any new feature to a specific subset of users (like beta users), gradually roll out a new features, or turn any feature into an A/B test (experiment).\n\n## How to get started with Feature Flags?[​](#how-to-get-started-with-feature-flags \"Direct link to How to get started with Feature Flags?\")\n\n1.  Create an [SDK Connection](#sdk-connections) in GrowthBook\n2.  See [Feature Flag Basics](https://docs.growthbook.io/features/basics) to learn the fundamentals and see the types of features we support (boolean, number, string, JSON)\n3.  Learn about [Targeting](https://docs.growthbook.io/features/targeting) to target features to users with certain attributes\n4.  Add [Override Rules](https://docs.growthbook.io/features/rules) to target users with a Forced Value, rollout your feature to a percentage of users, or run an experiment\n5.  Learn about [Scheduling](https://docs.growthbook.io/features/scheduling) features and different feature [Environments](https://docs.growthbook.io/features/environments)\n\n## SDK Connections[​](#sdk-connections \"Direct link to SDK Connections\")\n\nIn order to use feature flags in your application, you need to create an **SDK Connection** in GrowthBook.\n\nAt a high level, the SDK Connection generates a unique clientKey which grants read-only access to feature flags in a specific environment. The SDKs use this to fetch feature flag states and override rules from the GrowthBook API.\n\nOn GrowthBook Cloud, we have a global CDN in front of the API ([https://cdn.growthbook.io](https://cdn.growthbook.io/)) to ensure low latency responses from anywhere in the world. The CDN has a 30-second TTL, so changes to a feature may take a little time to be reflected.\n\n### GrowthBook Proxy[​](#growthbook-proxy \"Direct link to GrowthBook Proxy\")\n\nWe also offer a pre-built proxy server you can deploy on your own infrastructure. This can be put in front of either GrowthBook Cloud or a self-hosted GrowthBook instance.\n\nThe GrowthBook Proxy offers the following benefits:\n\n*   Fast - Requests served from an in-memory cache close to your app servers\n*   Scalable - A single Proxy server can handle over 10,000 reqs/second. Horizontally scale for more\n*   Responsive - Changes in GrowthBook are rolled out to users in under a second\n\nYou can read more about the GrowthBook Proxy [here](https://docs.growthbook.io/self-host/proxy).",
    "title": "Feature Flags | GrowthBook Docs",
    "description": "Learn about feature flags and how to use them in your application.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/experiments",
    "markdown": "# Running Experiments on GrowthBook | GrowthBook Docs\n\nGrowthBook has a few different ways to run experiments or AB tests depending on your needs. This guide will walk you through the different ways of running experiments on GrowthBook.\n\n## Server Side and Mobile Experiments[​](#server-side-and-mobile-experiments \"Direct link to Server Side and Mobile Experiments\")\n\nServer-side A/B testing, also known as backend or server-side experimentation, is a technique used in software development and web applications to test measure the impact of any code changes or new features. The changes may impact both the user interface and the backend of the application, but the decision about what version to serve a user is decided on the server. This has a number of advantages over client side experiments, specifically, that it allows you to run very complex tests that may involve a lot of different parts of the code, and span multiple parts of your application. It also avoids any issues with flickering that can happen with client side testing.\n\n### Feature Flag Experiments[​](#feature-flag-experiments \"Direct link to Feature Flag Experiments\")\n\nWith GrowthBook, the easiest way to do server-side testing is by using feature flags. Each feature flag has conditional logic ([rules](https://docs.growthbook.io/features/rules)) which controls how a feature should be shown, and if a feature should be shown as part of an experiment. GrowthBook also lets you target any feature or rule based on the [targeting attributes](https://docs.growthbook.io/features/targeting) you define. With GrowthBook, you can add an experiment rule to a feature that will randomly assign the users based on some hashing attribute into one of your experiment variations. You can read more about feature flag experiment rules [here](https://docs.growthbook.io/features/rules), or more details on running an [experiment with feature flags](https://docs.growthbook.io/feature-flag-experiments).\n\n### Inline Experiments[​](#inline-experiments \"Direct link to Inline Experiments\")\n\nYou can also run server-side experiments by using inline experiments directly with our SDK. This requires no 3rd party requests, as the experiment conditions and settings can be written directly into the code. How you implement in-line experiments depends on the SDK language you're using, you can read more about this from our [SDKs pages](https://docs.growthbook.io/lib).\n\n## Client Side (Browser) Experiments[​](#client-side-browser-experiments \"Direct link to Client Side (Browser) Experiments\")\n\nClient-side A/B testing, also known as frontend or client-side experimentation, is a way to test visual changes to your application. The server returns the same code to all users, and the experiment assignments and variations are handled by the client, typically in [Javascript](https://docs.growthbook.io/lib/js) or [React](https://docs.growthbook.io/lib/react).\n\nWhen the client loads your application, our SDK will check to see if the user should be part of any experiments, and if so, assign them and the client code will serve that variations treatment to them. GrowthBook's client side SDKs can handle all of this for you, and you can also serve client-side A/B test via our feature flags, or using our visual editor.\n\nClient-side A/B tests are great for testing visual changes to your application, but they do have some drawbacks. One of the most common issues is caused by the delay in loading the specific variation to a user, which may cause a flash or flickering as the experiment loads. This can be reduced by using inline-experiments, or by moving the GrowthBook SDK code higher in the code so it loads at the same time or before the page. Sometimes the hashing attribute may not be available until your tracking software has loaded, and you may need to use a custom tracking id.\n\n### Feature Flags[​](#feature-flags \"Direct link to Feature Flags\")\n\nGrowthBook's feature flags can work just as well from the client/browser as it does server side. The feature flag's conditional logic ([rules](https://docs.growthbook.io/features/rules)) controls how a feature should be shown, and if a feature should be shown as part of an experiment. The same targeting and override rules apply exactly the same to client-side experimentation.\n\n### Inline Experiments[​](#inline-experiments-1 \"Direct link to Inline Experiments\")\n\nJust like with inline server-side experiments, you can run experiments inline on the client. This requires no 3rd party requests, as the experiment conditions and settings can be written directly into the code, and processed by the SDK. How you implement in-line experiments depends on the SDK language you're using, you can read more about this from our [SDKs pages](https://docs.growthbook.io/lib).\n\n### Visual Editor (WYSIWYG) Experiments[​](#visual-editor-wysiwyg-experiments \"Direct link to Visual Editor (WYSIWYG) Experiments\")\n\nGrowthBook has a visual editor for running experiments on the front-end of your website without requiring any code changes. Our visual editor uses the same client-side SDK used for feature flags and A/B testing.\n\n## API / ML Experiments[​](#api--ml-experiments \"Direct link to API / ML Experiments\")\n\nGrowthBook's SDKs works well with anywhere code can run, and as such you can use it in the API or when running machine learning models. And, with our deterministic hashing method for assignment, you can even be sure users get assigned the same variation across your platform without needing to store state from GrowthBook.\n\n## Custom Assignment or 3rd Party Experiments[​](#custom-assignment-or-3rd-party-experiments \"Direct link to Custom Assignment or 3rd Party Experiments\")\n\nGrowthBook is a modular platform and can be used for experiment analysis if you are using custom assignment code or another experimentation system for randomization of users into variations. As long as the exposure/assignment information is available from within your data warehouse, you can use GrowthBook to analyse the results of your experiments.\n\n## How GrowthBook Assigns Users to Experiments[​](#how-growthbook-assigns-users-to-experiments \"Direct link to How GrowthBook Assigns Users to Experiments\")\n\nGrowthBook uses a consistent hashing algorithm to assign users to experiments. This means that the same user will always get the same variation given the same experiment settings (experiment key, and user hashing id). This is useful because it means that you can run experiments across multiple pages, or even multiple applications, and the user will always get the same variation. It also means that GrowthBook stores no state, and requires no additional cookies. It's important to note that none of these implies that GrowthBook exposes a mechanism known as sticky-bucketing. It's all about the consistent evaluation of variations based on the particular experiment settings.\n\n## Best Practices[​](#best-practices \"Direct link to Best Practices\")\n\n### Running A/A Tests[​](#running-aa-tests \"Direct link to Running A/A Tests\")\n\nAn A/A test is the same as an A/B test, but each variation has no actual difference in the application. This lets you test out that your systems are working correctly, as you should see no significant differences between the variations. We suggest that you first an A/A test to validate your experimentation implementation is correctly splitting traffic, and producing statistically valid results.\n\n### When to Expose Users to Experiments[​](#when-to-expose-users-to-experiments \"Direct link to When to Expose Users to Experiments\")\n\nWhen running an experiment it is best if you can only expose users as close to the actual treatment exposure as possible. This means that if you're testing something like new signup flow, you don't expose all users, including those who never open that window. Including users who did not see the treatment will increase the noise and reduce the ability to detect any differences.\n\nIf assignment is unavoidably separated from exposure, you can use an activation metric to filter out these un-exposed users from the analysis.\n\n### Avoiding Flickering[​](#avoiding-flickering \"Direct link to Avoiding Flickering\")\n\nFlickering with front end or client-side A/B tests is an artifact from all client-side A/B testing tools. This is caused by a delay in loading the specific variation for a user, which may cause a flash or flickering as the experiment loads. This can be reduced by using inline-experiments, or by moving the GrowthBook SDK code higher in the code file, or using server side A/B tests.\n\nThere are a few other ways to reduce flickering that some platforms utilize. One common \"flicker free\" technique is to load a white overlay, or just hide parts of the page, as the page loads. The result is that users cannot see any flickering that may be happening beneath the overlay as the variations are loaded.\n\n### Sample Size[​](#sample-size \"Direct link to Sample Size\")\n\nUnderstanding experiment power and MDE are important to predict how many samples are required. There are numerous online calculators that can be used to help you predict the sample size. Typical rule of thumb for the lowest number of samples required is that you want at least 200 conversion events per variation. So for example if you have a registration page which has a 10% conversion rate, and you have a 2 way (A and B) experiment that is looking to improve the member registrations, you will want to expose the experiment to at least 4,000 people (2000 per variation).\n\n### Test Duration[​](#test-duration \"Direct link to Test Duration\")\n\nDue to the natural variability in traffic day to day and hour to hour, experimentation teams will often set a minimum test duration within which a test cannot be called. This helps you avoid optimizing a product for just the users that happen to visit when the test is started. For example, if the weekend traffic of your product is different from the traffic during the week, if you started a test on Friday and ended it on Monday, you may not get a complete picture of the impact your changes have to your weekday traffic.\n\nTypical test durations are 1 to 2 weeks, and usually care needs to be taken over holidays. You may also find that a test would need to run for a month or more to get the power required for the experiment. Very long running tests can be hard to justify as you have to keep the variations of the experiment unchanged for duration, and this may limit your team's velocity towards potentially higher impact changes.\n\n### Interaction Effects and Mutual Exclusion[​](#interaction-effects-and-mutual-exclusion \"Direct link to Interaction Effects and Mutual Exclusion\")\n\nWhen you start having the ability to run a lot of A/B tests, you may start worrying about how tests running in parallel may interact and effect the other results. For example you may want to test a change in the CTA button on your purchase page, and also test changing the price. It can be difficult to figure out if any two tests will meaningfully interact, and many will run the tests in serial in an abundance of caution.\n\nHowever, meaningful interactions are actually quite rare, and keeping a higher rate of experimentation is usually more beneficial. You can run analysis after the experiments to see if there were any interaction effects which would change your conclusions. If you need to run mutually exclusive tests, you can use GrowthBook’s namespace feature.\n\n### Experimentation Frequency[​](#experimentation-frequency \"Direct link to Experimentation Frequency\")\n\nHaving a high frequency of A/B testing is important for running a success experimentation program. The main reasons why experimentation frequency is important are:\n\n*   **Maximizing chances**: Since success rates are typically low for any given experiment, and large changes are even more rare, by having a high frequency of A/B testing you are maximizing your chance of having impactful experiments.\n*   **Continuous improvement**: A high frequency of A/B testing allows you to continuously improve your website or application. By testing small changes frequently, you can quickly identify and implement changes that improve user experience, engagement, and conversion rates.\n*   **Adaptability**: A high frequency of A/B testing allows you to quickly adapt to changes in user behavior, market trends, or other external factors that may impact your website or application. By testing frequently, you can identify and respond to these changes more quickly, ensuring that your site or app remains relevant and effective.\n*   **Avoiding stagnation**: A high frequency of A/B testing can help you avoid stagnation and complacency. By continually testing and experimenting, you can avoid falling into a rut or becoming overly attached to a specific design or strategy, and instead remain open to new ideas and approaches.",
    "title": "Running Experiments on GrowthBook | GrowthBook Docs",
    "description": "Understanding the ways to run experiments with GrowthBook",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/warehouses",
    "markdown": "# Connecting to your data warehouse\n\n## Overview[​](#overview \"Direct link to Overview\")\n\nOne of the major benefits of Growthbook is that your data remains securely stored in your data warehouse, and only the aggregated statistics are transmitted to GrowthBook servers or your self-hosted environment.\n\n## Preparing your data warehouse[​](#preparing-your-data-warehouse \"Direct link to Preparing your data warehouse\")\n\nYour data should be safe from modification as GrowthBook only runs `SELECT` queries (or the equivalent for non-SQL data sources). Still we still always recommend creating read-only users with as few permissions as possible - ideally just read permissions on the tables with the data that needs to be aggregated.\n\nIf you are using GrowthBook Cloud ([https://app.growthbook.io](https://app.growthbook.io/)), make sure to whitelist the ip address `52.70.79.40` if applicable.\n\n## Saving your connection configuration on Growthbook Cloud or your self hosted server[​](#saving-your-connection-configuration-on-growthbook-cloud-or-your-self-hosted-server \"Direct link to Saving your connection configuration on Growthbook Cloud or your self hosted server\")\n\nThe data source connection info is encrypted twice - once within the app and again by the database when persisting to disk. Most data sources have straight forward connection parameters like host, port, username, and password. However some are slightly more involved and is convered in the guides below.\n\n## Connection guides[​](#connection-guides \"Direct link to Connection guides\")\n\n*   [AWS Athena](https://docs.growthbook.io/warehouses/athena)\n*   [BigQuery](https://docs.growthbook.io/guide/bigquery)\n*   [ClickHouse](https://docs.growthbook.io/warehouses/clickhouse)\n*   [Databricks](https://docs.growthbook.io/warehouses/databricks)\n*   [Mixpanel](https://docs.growthbook.io/warehouses/mixpanel)\n*   [MsSQL/SQL Server](https://docs.growthbook.io/warehouses/ms-sql-or-sql-server)\n*   [MySQL/MariaDB](https://docs.growthbook.io/warehouses/mysql-or-mariadb)\n*   [Postgres](https://docs.growthbook.io/warehouses/postgres)\n*   [PrestoDB or Trino](https://docs.growthbook.io/warehouses/prestodb-or-trino)\n*   [Redshift](https://docs.growthbook.io/warehouses/redshift)\n*   [Snowflake](https://docs.growthbook.io/warehouses/snowflake)",
    "title": "Connecting to your data warehouse | GrowthBook Docs",
    "description": "This document outlines the steps needed to connect GrowthBook to your data warehouse.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/lib/",
    "markdown": "# GrowthBook SDKs | GrowthBook Docs\n\nWe offer official SDKs for many popular languages and frameworks:\n\n*   [Javascript/Typescript](https://docs.growthbook.io/lib/js)\n*   [React](https://docs.growthbook.io/lib/react)\n*   [Vue](https://docs.growthbook.io/lib/vue)\n*   [HTML Script Tag](https://docs.growthbook.io/lib/script-tag)\n*   [Node.js](https://docs.growthbook.io/lib/node)\n*   [PHP](https://docs.growthbook.io/lib/php)\n*   [Ruby](https://docs.growthbook.io/lib/ruby)\n*   [Python](https://docs.growthbook.io/lib/python)\n*   [Go](https://docs.growthbook.io/lib/go)\n*   [Java](https://docs.growthbook.io/lib/java)\n*   [C#](https://docs.growthbook.io/lib/csharp)\n*   [Elixir](https://docs.growthbook.io/lib/elixir)\n*   [Kotlin (Android)](https://docs.growthbook.io/lib/kotlin)\n*   [Swift](https://docs.growthbook.io/lib/swift)\n*   [Flutter](https://docs.growthbook.io/lib/flutter)\n*   [React Native](https://docs.growthbook.io/lib/react-native)\n\nThere is also a guide if you want to [build your own](https://docs.growthbook.io/lib/build-your-own).\n\nIt's not required to use any of these libraries. The only requirement is that you track in your datasource when users are put into an experiment and which variation they received.",
    "title": "GrowthBook SDKs | GrowthBook Docs",
    "description": "Learn about GrowthBook's supported SDKs",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/lib/node",
    "markdown": "# Node.js SDK | GrowthBook Docs\n\nWe officially support Node 18 and above.\n\n## Installation[​](#installation \"Direct link to Installation\")\n\nInstall with a package manager\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save @growthbook/growthbook\n```\n\n## Quick Usage[​](#quick-usage \"Direct link to Quick Usage\")\n\nGrowthBook instances are scoped to a single incoming request. The easiest way to do this is with Middleware:\n\n```\n// Example using Expressapp.use(function(req, res, next) {  // Create a GrowthBook instance and store in the request  req.growthbook = new GrowthBook({    apiHost: \"https://cdn.growthbook.io\",    clientKey: \"sdk-abc123\"  });  // TODO: Add user targeting attributes from cookies, headers, etc.  req.growthbook.setAttributes({    id: req.user?.id  });  // Clean up at the end of the request  res.on('close', () => req.growthbook.destroy());  // Wait for features to load (will be cached in-memory for future requests)  req.growthbook.init({timeout: 1000}).then(() => next())});\n```\n\nThen, you can access the GrowthBook instance from any route:\n\n```\napp.get(\"/\", (req, res) => {  const gb = req.growthbook;  // Boolean on/off flag  if (gb.isOn(\"my-feature\")) {    // Do something  }  // String/Number/JSON flag  const value = gb.getFeatureValue(\"my-string-feature\", \"fallback\");  console.log(value);})\n```\n\n## Loading Features and Experiments[​](#loading-features-and-experiments \"Direct link to Loading Features and Experiments\")\n\nIn order for the GrowthBook SDK to work, it needs to have feature and experiment definitions from the GrowthBook API. There are a few ways to get this data into the SDK.\n\n### Built-in Fetching and Caching[​](#built-in-fetching-and-caching \"Direct link to Built-in Fetching and Caching\")\n\nIf you pass an `apiHost` and `clientKey` into the GrowthBook constructor, it will handle the network requests, caching, retry logic, etc. for you automatically.\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",});// Wait for features to be downloaded with a timeout (in ms)gb.init({ timeout: 2000 }).then(() => next())\n```\n\nThe network request to download features is cached in memory and uses a stale-while-revalidate (SWR) pattern. So the first call to `gb.init()` may be slow, but all subsequent calls should resolve immediately.\n\n#### Error Handling[​](#error-handling \"Direct link to Error Handling\")\n\nIn the case of network issues that prevent the features from downloading in time, the `init` call will not throw an error. Instead, it will stay in the default state where every feature evaluates to `null`.\n\nYou can still get access to the error if needed:\n\n```\nconst res = await gb.init({  timeout: 1000});console.log(res);\n```\n\nThe return value has 3 properties:\n\n*   **status** - `true` if the GrowthBook instance was populated with features/experiments. Otherwise `false`\n*   **source** - Where this result came from. One of the following values: `network`, `cache`, `init`, `error`, or `timeout`\n*   **error** - If status is `false`, this will contain an `Error` object with more details about the error\n\n### Custom Integration[​](#custom-integration \"Direct link to Custom Integration\")\n\nIf you prefer to handle the network and caching logic yourself, you can pass in a full JSON \"payload\" directly into the SDK. For example, you might store features in Postgres or Redis.\n\n```\nawait gb.init({  payload: {    features: {      \"feature-1\": {...},      \"feature-2\": {...},      \"another-feature\": {...},    }  }})\n```\n\nThe data structure for \"payload\" is exactly the same as what is returned by the GrowthBook SDK endpoints and webhooks.\n\nNote: you don't need to specify `clientKey` or `apiHost` on your GrowthBook instance since no network requests are being made in this case.\n\n#### Synchronous Init[​](#synchronous-init \"Direct link to Synchronous Init\")\n\nThere is a alternate synchronous version of init named `initSync`, which can be useful in some environments. There are some restrictions/differences:\n\n*   You MUST pass in `payload`\n*   The `payload` MUST NOT have encrypted features or experiments\n*   If you use sticky bucketing, you MUST pass `stickyBucketAssignmentDocs` into your GrowthBook constructor\n*   The return value is the GrowthBook instance to enable easy method chaining\n\n## Streaming Updates[​](#streaming-updates \"Direct link to Streaming Updates\")\n\nThe GrowthBook SDK supports streaming with Server-Sent Events (SSE). When enabled, changes to features within GrowthBook will be streamed to the SDK in realtime as they are published. This is only supported on GrowthBook Cloud or if running a GrowthBook Proxy Server.\n\nNode.js does not natively support SSE, but there is a small library you can install:\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save eventsource\n```\n\nThen, do the following during app startup:\n\n```\nconst { setPolyfills, prefetchPayload } = require(\"@growthbook/growthbook\");// Configure GrowthBook to use the eventsource librarysetPolyfills({  EventSource: require(\"eventsource\"),});// Start a streaming connectionprefetchPayload({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  streaming: true}).then(() => console.log(\"Streaming connection open!\"))\n```\n\nThis will make an initial network request to download the features payload from the GrowthBook API. Then, it will open a streaming connection to listen to updates.\n\nWhen a new GrowthBook instance is created in your middleware, it will use the latest available payload. The payload for this GrowthBook instance will be locked and frozen, so you don't have to worry about the payload changing mid-request and causing weird edge cases in your app.\n\n## Caching[​](#caching \"Direct link to Caching\")\n\nThe JavaScript SDK has 2 caching layers:\n\n1.  In-memory cache (enabled by default)\n2.  Persistent localStorage cache (disabled by default, requires configuration)\n\n### Configuring Local Storage[​](#configuring-local-storage \"Direct link to Configuring Local Storage\")\n\nHere is an example of using Redis as your persistent localStorage cache:\n\n```\nconst { setPolyfills } = require(\"@growthbook/growthbook\");setPolyfills({  localStorage: {    // Example using Redis    getItem: (key) => redisClient.get(key),    setItem: (key, value) => redisClient.set(key, value),  }});\n```\n\n### Cache Settings[​](#cache-settings \"Direct link to Cache Settings\")\n\nThere are a number of cache settings you can configure within GrowthBook.\n\nBelow are all of the default values. You can call `configureCache` with a subset of these fields and the rest will keep their default values.\n\n```\nimport { configureCache } from \"@growthbook/growthbook\";configureCache({  // The localStorage key the cache will be stored under  cacheKey: \"gbFeaturesCache\",  // Consider features stale after this much time (60 seconds default)  staleTTL: 1000 * 60,  // Cached features older than this will be ignored (24 hours default)  maxAge: 1000 * 60 * 60 * 24,  // Set to `true` to completely disable both in-memory and persistent caching  disableCache: false,})\n```\n\n## Experimentation (A/B Testing)[​](#experimentation-ab-testing \"Direct link to Experimentation (A/B Testing)\")\n\nIn order to run A/B tests, you need to set up a tracking callback function. This is called every time a user is put into an experiment and can be used to track the exposure event in your analytics system (Segment, Mixpanel, GA, etc.).\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  trackingCallback: (experiment, result) => {    // Example using Segment    analytics.track(\"Experiment Viewed\", {      experimentId: experiment.key,      variationId: result.key,    });  },});\n```\n\n### Feature Flag Experiments[​](#feature-flag-experiments \"Direct link to Feature Flag Experiments\")\n\nThere is nothing special you have to do for feature flag experiments. Just evaluate the feature flag like you would normally do. If the user is put into an experiment as part of the feature flag, it will call the `trackingCallback` automatically in the background.\n\n```\n// If this has an active experiment and the user is included,// it will call trackingCallback automaticallyconst newLogin = gb.isOn(\"new-signup-form\");\n```\n\nIf the experiment came from a feature rule, `result.featureId` in the trackingCallback will contain the feature id, which may be useful for tracking/logging purposes.\n\n### Deferred Tracking[​](#deferred-tracking \"Direct link to Deferred Tracking\")\n\nSometimes, you aren't able to track analytics events from Node.js and you need to do it from the front-end instead.\n\nIf that is the case for your app, do not specify a `trackingCallback` in the constructor. This will queue up tracking calls in the GrowthBook instance.\n\nYou can export the queued tracking calls with the `getDeferredTrackingCalls()` method. The result is a serializable JSON object:\n\n```\nconst tracks = gb.getDeferredTrackingCalls();\n```\n\nSend those down to your front-end and you can fire them in one of two ways:\n\n#### If Using GrowthBook on the Front-End[​](#if-using-growthbook-on-the-front-end \"Direct link to If Using GrowthBook on the Front-End\")\n\nIf you are already using the JavaScript or React SDK on the front-end, you can import with `setDeferredTrackingCalls`. This does not fire them automatically. You must call `fireDeferredTrackingCalls` after.\n\n```\ngb.setDeferredTrackingCalls(tracks);gb.fireDeferredTrackingCalls();\n```\n\nThis will use the `trackingCallback` configured on your front-end GrowthBook instance.\n\n#### Standalone Tracker[​](#standalone-tracker \"Direct link to Standalone Tracker\")\n\nIf you do NOT have a client-side GrowthBook instance, you can still fire these tracking calls with a small custom client-side script:\n\n```\ntracks.forEach(({experiment, result}) => {  // Example using Segment.io  analytics.track(\"Experiment Viewed\", {    experimentId: experiment.key,    variationId: result.key,  });})\n```\n\n### Sticky Bucketing[​](#sticky-bucketing \"Direct link to Sticky Bucketing\")\n\nSticky bucketing ensures that users see the same experiment variant, even when user session, user login status, or experiment parameters change. See the [Sticky Bucketing docs](https://docs.growthbook.io/app/sticky-bucketing) for more information. If your organization and experiment supports sticky bucketing, you must implement an instance of the `StickyBucketService` to use Sticky Bucketing. The JS SDK exports several implementations of this service for common use cases, or you may build your own:\n\n*   `ExpressCookieStickyBucketService` — For NodeJS/Express controller-level bucket persistence using browser cookies; intended to be interoperable with `BrowserCookieStickyBucketService`. Assumes `cookie-parser` is implemented (can be polyfilled). Cookie attributes can also be configured.\n    \n*   `RedisStickyBucketService` — For NodeJS Redis-based bucket persistence. Requires an `ioredis` Redis client instance to be passed in.\n    \n*   Build your own — Implement the abstract `StickyBucketService` class and connect to your own data store, or custom wrap multiple service implementations (ex: read/write to both cookies and Redis).\n    \n\nImplementing most StickyBucketService implementations is straightforward and works with minimal setup. For instance, to use the `ExpressCookieStickyBucketService`:\n\n```\nconst { ExpressCookieStickyBucketService } = require(\"@growthbook/growthbook\");app.use(function(req, res, next) {  // Create a GrowthBook instance and store in the request  req.growthbook = new GrowthBook({    apiHost: \"https://cdn.growthbook.io\",    clientKey: \"sdk-abc123\",    stickyBucketService: new ExpressCookieStickyBucketService({      req,      res    }),  })})\n```\n\n## TypeScript[​](#typescript \"Direct link to TypeScript\")\n\nWhen used in a TypeScript project, GrowthBook includes basic type inference out of the box:\n\n```\n// Type will be `string` based on the fallback provided (\"blue\")const color = gb.getFeatureValue(\"button-color\", \"blue\");// You can manually specify types as well// feature.value will be type `number`const feature = gb.evalFeature<number>(\"font-size\");console.log(feature.value);// Experiments will use the variations to infer the return value// result.value will be type \"string\"const result = gb.run({  key: \"my-test\",  variations: [\"blue\", \"green\"],});\n```\n\n### Strict Typing[​](#strict-typing \"Direct link to Strict Typing\")\n\nIf you want to enforce stricter types in your application, you can do that when creating the GrowthBook instance:\n\n```\n// Define all your feature flags and types hereinterface AppFeatures {  \"button-color\": string;  \"font-size\": number;  \"newForm\": boolean;}// Pass into the GrowthBook instanceconst gb = new GrowthBook<AppFeatures>({  ...});\n```\n\nNow, all feature flag methods will be strictly typed.\n\n```\n// feature.value will by type `number`const feature = gb.evalFeature(\"font-size\");console.log(feature.value);// Typos will cause compile-time errorsgb.isOn(\"buton-color\"); // \"buton\" instead of \"button\"\n```\n\nInstead of defining the `AppFeatures` interface manually like above, you can auto-generate it from your GrowthBook account using the [GrowthBook CLI](https://docs.growthbook.io/tools/cli).\n\n## Updating[​](#updating \"Direct link to Updating\")\n\nAs a general philosophy, we aim to keep the SDK 100% backwards compatible at all times. View the [Changelog](https://github.com/growthbook/growthbook/blob/main/packages/sdk-js/CHANGELOG.md) for a complete list of all SDK changes.\n\n## GrowthBook Instance (reference)[​](#growthbook-instance-reference \"Direct link to GrowthBook Instance (reference)\")\n\n### Attributes[​](#attributes \"Direct link to Attributes\")\n\nYou can specify attributes about the current user and request. These are used for two things:\n\n1.  Feature targeting (e.g. paid users get one value, free users get another)\n2.  Assigning persistent variations in A/B tests (e.g. user id \"123\" always gets variation B)\n\nThe following are some commonly used attributes, but use whatever makes sense for your application.\n\n```\nnew GrowthBook({  attributes: {    id: \"123\",    loggedIn: true,    deviceId: \"abc123def456\",    company: \"acme\",    paid: false,    url: \"/pricing\",    browser: \"chrome\",    mobile: false,    country: \"US\",  },});\n```\n\n#### Updating Attributes[​](#updating-attributes \"Direct link to Updating Attributes\")\n\nIf attributes change, you can call `setAttributes()` to update. This will completely overwrite any existing attributes. To do a partial update, use the following pattern:\n\n```\ngb.setAttributes({  // Only update the `url` attribute, keep the rest the same  ...gb.getAttributes(),  url: \"/new-page\"})\n```\n\n#### Secure Attributes[​](#secure-attributes \"Direct link to Secure Attributes\")\n\nWhen _secure attribute hashing_ is enabled, all targeting conditions in the SDK payload referencing attributes with datatype `secureString` or `secureString[]` will be anonymized via SHA-256 hashing. This allows you to safely target users based on sensitive attributes. You must enable this feature in your SDK Connection for it to take effect.\n\nIf your SDK Connection has secure attribute hashing enabled, you will need to manually hash any `secureString` or `secureString[]` attributes that you pass into the GrowthBook SDK.\n\nTo hash an attribute, use a cryptographic library with SHA-256 support, and compute the SHA-256 hashed value of your attribute _plus_ your organization's secure attribute salt.\n\n```\nconst salt = \"f09jq3fij\"; // Your organization's secure attribute salt (see Organization Settings)// hashing a secureString attributeconst userEmail = sha256(salt + user.email);// hashing an secureString[] attributeconst userTags = user.tags.map(tag => sha256(salt + tag));gb.setAttributes({  id: user.id,  loggedIn: true,  email: userEmail,  tags: userTags,});await gb.init();// In this example, we are using Node.js's built-in crypto libraryfunction sha256(str) {  return crypto.createHash(\"sha256\").update(str).digest(\"hex\");}\n```\n\n### Feature Usage Callback[​](#feature-usage-callback \"Direct link to Feature Usage Callback\")\n\nGrowthBook can fire a callback whenever a feature is evaluated for a user. This can be useful to update 3rd party tools like NewRelic or DataDog.\n\n```\nnew GrowthBook({  onFeatureUsage: (featureKey, result) => {    console.log(\"feature\", featureKey, \"has value\", result.value);  },});\n```\n\nThe `result` argument is the same thing returned from `gb.evalFeature`.\n\nNote: If you evaluate the same feature multiple times (and the value doesn't change), the callback will only be fired the first time.\n\n### evalFeature[​](#evalfeature \"Direct link to evalFeature\")\n\nIn addition to the `isOn` and `getFeatureValue` helper methods, there is the `evalFeature` method that gives you more detailed information about why the value was assigned to the user.\n\n```\n// Get detailed information about the feature evaluationconst result = gb.evalFeature(\"my-feature\");// The value of the feature (or `null` if not defined)console.log(result.value);// Why the value was assigned to the user// One of: `override`, `unknownFeature`, `defaultValue`, `force`, or `experiment`console.log(result.source);// The string id of the rule (if any) which was usedconsole.log(result.ruleId);// Information about the experiment (if any) which was usedconsole.log(result.experiment);// The result of the experiment (or `undefined`)console.log(result.experimentResult);\n```\n\n### Inline Experiments[​](#inline-experiments \"Direct link to Inline Experiments\")\n\nInstead of declaring all features up-front in the context and referencing them by ids in your code, you can also just run an experiment directly. This is done with the `gb.run` method:\n\n```\n// These are the only required optionsconst { value } = gb.run({  key: \"my-experiment\",  variations: [\"red\", \"blue\", \"green\"],});\n```\n\n#### Customizing the Traffic Split[​](#customizing-the-traffic-split \"Direct link to Customizing the Traffic Split\")\n\nBy default, this will include all traffic and do an even split between all variations. There are 2 ways to customize this behavior:\n\n```\n// Option 1: Using weights and coveragegb.run({  key: \"my-experiment\",  variations: [\"red\", \"blue\", \"green\"],  // Only include 10% of traffic  coverage: 0.1,  // Split the included traffic 50/25/25 instead of the default 33/33/33  weights: [0.5, 0.25, 0.25],});// Option 2: Specifying rangesgb.run({  key: \"my-experiment\",  variations: [\"red\", \"blue\", \"green\"],  // Identical to the above  // 5% of traffic in A, 2.5% each in B and C  ranges: [    [0, 0.05],    [0.5, 0.525],    [0.75, 0.775],  ],});\n```\n\n#### Hashing[​](#hashing \"Direct link to Hashing\")\n\nWe use deterministic hashing to assign a variation to a user. We hash together the user's id and experiment key, which produces a number between `0` and `1`. Each variation is assigned a range of numbers, and whichever one the user's hash value falls into will be assigned.\n\nYou can customize this hashing behavior:\n\n```\ngb.run({  key: \"my-experiment\",  variations: [\"A\", \"B\"],  // Which hashing algorithm to use  // Version 2 is the latest and the one we recommend  hashVersion: 2,  // Use a different seed instead of the experiment key  seed: \"abcdef123456\",  // Use a different user attribute (default is `id`)  hashAttribute: \"device_id\",});\n```\n\n**Note**: For backwards compatibility, if no `hashVersion` is specified, it will fall back to using version `1`, which is deprecated. In the future, version `2` will become the default. We recommend specifying version `2` now for all new experiments to avoid migration issues down the line.\n\n#### Meta Info[​](#meta-info \"Direct link to Meta Info\")\n\nYou can also define meta info for the experiment and/or variations. These do not affect the behavior, but they are passed through to the `trackingCallback`, so they can be used to annotate events.\n\n```\ngb.run({  key: \"results-per-page\",  variations: [10, 20],  // Experiment meta info  name: \"Results per Page\",  phase: \"full-traffic\"  // Variation meta info  meta: [    {      key: \"control\",      name: \"10 Results per Page\",    },    {      key: \"variation\",      name: \"20 Results per Page\",    },  ]})\n```\n\n#### Mutual Exclusion[​](#mutual-exclusion \"Direct link to Mutual Exclusion\")\n\nSometimes you want to run multiple conflicting experiments at the same time. You can use the `filters` setting to run mutually exclusive experiments.\n\nWe do this using deterministic hashing to assign users a value between 0 and 1 for each filter.\n\n```\n// Will include 60% of users - ones with a hash between 0 and 0.6gb.run({  key: \"experiment-1\",  variation: [0, 1],  filters: [    {      seed: \"pricing\",      attribute: \"id\",      ranges: [[0, 0.6]]    }  ]});// Will include the other 40% of users - ones with a hash between 0.6 and 1gb.run({  key: \"experiment-2\",  variation: [0, 1],  filters: [    {      seed: \"pricing\",      attribute: \"id\",      ranges: [[0.6, 1.0]]    }  ]});\n```\n\n**Note** - If a user is excluded from an experiment due to a filter, the rule will be skipped and the next matching rule will be used instead.\n\n#### Holdout Groups[​](#holdout-groups \"Direct link to Holdout Groups\")\n\nTo use global holdout groups, use a nested experiment design:\n\n```\n// The value will be `true` if in the holdout group, otherwise `false`const holdout = gb.run({  key: \"holdout\",  variations: [true, false],  // 10% of users in the holdout group  weights: [0.1, 0.9]});// Only run your main experiment if the user is NOT in the holdoutif (!holdout.value) {  const res = gb.run({    key: \"my-experiment\",    variations: [\"A\", \"B\"]  })}\n```\n\n#### Targeting Conditions[​](#targeting-conditions \"Direct link to Targeting Conditions\")\n\nYou can also define targeting conditions that limit which users are included in the experiment. These conditions are evaluated against the `attributes` passed into the GrowthBook context. The syntax for conditions is based on the MongoDB query syntax and is straightforward to read and write.\n\nFor example, if the attributes are:\n\n```\n{  \"id\": \"123\",  \"browser\": {    \"vendor\": \"firefox\",    \"version\": 94  },  \"country\": \"CA\"}\n```\n\nThe following condition would evaluate to `true` and the user would be included in the experiment:\n\n```\ngb.run({  key: \"my-experiment\",  variation: [0, 1],  condition: {    \"browser.vendor\": \"firefox\",    \"country\": {      \"$in\": [\"US\", \"CA\", \"IN\"]    }  }})\n```\n\n#### Inline Experiment Return Value[​](#inline-experiment-return-value \"Direct link to Inline Experiment Return Value\")\n\nA call to `gb.run(experiment)` returns an object with a few useful properties:\n\n```\nconst {  value,  key,  name,  variationId,  inExperiment,  hashUsed,  hashAttribute,  hashValue,} = gb.run({  key: \"my-experiment\",  variations: [\"A\", \"B\"],});// If user is included in the experimentconsole.log(inExperiment); // true or false// The index of the assigned variationconsole.log(variationId); // 0 or 1// The value of the assigned variationconsole.log(value); // \"A\" or \"B\"// The key and name of the assigned variation (if specified in `meta`)console.log(key); // \"0\" or \"1\"console.log(name); // \"\"// If the variation was randomly assigned by hashingconsole.log(hashUsed);// The user attribute that was hashedconsole.log(hashAttribute); // \"id\"// The value of that attributeconsole.log(hashValue); // e.g. \"123\"\n```\n\nThe `inExperiment` flag will be false if the user was excluded from being part of the experiment for any reason (e.g. failed targeting conditions).\n\nThe `hashUsed` flag will only be true if the user was randomly assigned a variation. If the user was forced into a specific variation instead, this flag will be false.\n\n## Feature Definitions (reference)[​](#feature-definitions-reference \"Direct link to Feature Definitions (reference)\")\n\nThe feature definition JSON file contains information about all of the features in your application.\n\nEach feature consists of a unique key, a list of possible values, and rules for how to assign those values to users.\n\n```\n{  \"feature-1\": {...},  \"feature-2\": {...},  \"another-feature\": {...},}\n```\n\n### Basic Feature[​](#basic-feature \"Direct link to Basic Feature\")\n\nAn empty feature always has the value `null`:\n\n#### Default Values[​](#default-values \"Direct link to Default Values\")\n\nYou can change the default assigned value with the `defaultValue` property:\n\n```\n{  \"my-feature\": {    defaultValue: \"green\"  }}\n```\n\n### Override Rules[​](#override-rules \"Direct link to Override Rules\")\n\nYou can override the default value with **rules**.\n\nRules give you fine-grained control over how feature values are assigned to users. There are 2 types of feature rules: `force` and `experiment`. Force rules give the same value to everyone. Experiment rules assign values to users randomly.\n\n#### Rule Ids[​](#rule-ids \"Direct link to Rule Ids\")\n\nRules can specify a unique identifier with the `id` property. This can help with debugging and QA by letting you see exactly why a specific value was assigned to a user.\n\n#### Rule Conditions[​](#rule-conditions \"Direct link to Rule Conditions\")\n\nRules can optionally define targeting conditions that limit which users the rule applies to. These conditions are evaluated against the `attributes` passed into the GrowthBook context. The syntax for conditions is based on the MongoDB query syntax and is straightforward to read and write.\n\nFor example, if the attributes are:\n\n```\n{  \"id\": \"123\",  \"browser\": {    \"vendor\": \"firefox\",    \"version\": 94  },  \"country\": \"CA\"}\n```\n\nThe following condition would evaluate to `true`:\n\n```\n{  \"browser.vendor\": \"firefox\",  \"country\": {    \"$in\": [\"US\", \"CA\", \"IN\"]  }}\n```\n\nIf a condition evaluates to `false`, the rule will be skipped. This means you can chain rules together with different conditions to support even the most complex use cases.\n\n#### Force Rules[​](#force-rules \"Direct link to Force Rules\")\n\nForce rules do what you'd expect - force a specific value for the feature\n\n```\n// Firefox users in the US or Canada get \"green\"// Everyone else gets the default \"blue\"{  \"button-color\": {    defaultValue: \"blue\",    rules: [      {        id: \"rule-123\",        condition: {          browser: \"firefox\",          country: {            $in: [\"US\", \"CA\"]          }        },        force: \"green\"      }    ],  }}\n```\n\n##### Gradual Rollouts[​](#gradual-rollouts \"Direct link to Gradual Rollouts\")\n\nYou can specify a `range` for your rule, which determines what percent of users will get the rule applied to them. Users who do not get the rule applied will fall through to the next matching rule (or default value). You can also specify a `seed` that will be used for hashing.\n\nIn order to figure out if a user is included or not, we use deterministic hashing. By default, we use the user attribute `id` for this, but you can override this by specifying `hashAttribute` for the rule:\n\nThis is useful for gradually rolling out features to users (start with a small range and slowly increase).\n\n```\n{  \"new-feature\": {    defaultValue: false,    rules: [      {        force: true,        hashAttribute: \"device-id\",        seed: 'new-feature-rollout-abcdef123',        // 20% of users        range: [0, 0.2]        // Increase to 40%:        // range: [0, 0.4]      }    ]  }}\n```\n\n#### Experiment Rules[​](#experiment-rules \"Direct link to Experiment Rules\")\n\nExperiment rules let you adjust the percent of users who get randomly assigned to each variation. This can either be used for hypothesis-driven A/B tests or to simply mitigate risk by gradually rolling out new features to your users.\n\n```\n// Each variation gets assigned to a random 1/3rd of users{  \"image-size\": {    rules: [      {        variations: [\"small\", \"medium\", \"large\"]      }    ]  }}\n```\n\n##### Customizing the Traffic Split[​](#customizing-the-traffic-split-1 \"Direct link to Customizing the Traffic Split\")\n\nBy default, an experiment rule will include all traffic and do an even split between all variations. There are 2 ways to customize this behavior:\n\n```\n// Option 1: Using weights and coverage{  variations: [\"red\", \"blue\", \"green\"],  // Only include 10% of traffic  coverage: 0.1,  // Split the included traffic 50/25/25 instead of the default 33/33/33  weights: [0.5, 0.25, 0.25]}// Option 2: Specifying ranges{  variations: [\"red\", \"blue\", \"green\"],  // Identical to the above  // 5% of traffic in A, 2.5% each in B and C  ranges: [    [0, 0.05],    [0.5, 0.525],    [0.75, 0.775]  ]}\n```\n\nA user is assigned a number from 0 to 1 and whichever variation's range includes their number will be assigned to them.\n\n##### Variation Meta Info[​](#variation-meta-info \"Direct link to Variation Meta Info\")\n\nYou can use the `meta` setting to provide additional info about the variations such as name.\n\n```\n{  \"image-size\": {    rules: [      {        variations: [\"sm\", \"md\", \"lg\"],        ranges: [          [0, 0.5],          [0.5, 0.75],          [0.75, 1.0]        ],        meta: [          {            key: \"control\",            name: \"Small\",          },          {            key: \"v1\",            name: \"Medium\",          },          {            key: \"v2\",            name: \"Large\",          }        ]      }    ]  }}\n```\n\n##### Tracking Key and Name[​](#tracking-key-and-name \"Direct link to Tracking Key and Name\")\n\nWhen a user is assigned a variation, we call the `trackingCallback` function so you can record the exposure with your analytics event tracking system. By default, we use the feature id to identify the experiment, but this can be overridden if needed with the `key` setting. You can also optionally provide a human-readable name.\n\n```\n{  \"feature-1\": {    rules: [      {        // Use \"my-experiment\" as the key instead of \"feature-1\"        key: \"my-experiment\",        name: \"My Experiment\",        variations: [\"A\", \"B\"]      }    ]  },}\n```\n\n##### Hash Attribute[​](#hash-attribute \"Direct link to Hash Attribute\")\n\nWe use deterministic hashing to make sure the same user always gets assigned the same value. By default, we use the attribute `id`, but this can be overridden with the `hashAttribute` setting:\n\n```\nconst gb = new GrowthBook({  attributes: {    id: \"123\",    company: \"acme\",  },  features: {    \"my-feature\": {      rules: [        // All users with the same \"company\" value        // will be assigned the same variation        {          variations: [\"A\", \"B\"],          hashAttribute: \"company\",        },        // If \"company\" is empty for the user (e.g. if they are logged out)        // The experiment will be skipped and fall through to this next rule        {          force: \"A\",        },      ],    },  },});\n```\n\n##### Filters[​](#filters \"Direct link to Filters\")\n\nSometimes you want to run multiple conflicting experiments at the same time. You can use the `filters` setting to run mutually exclusive experiments.\n\nWe do this using deterministic hashing to assign users a value between 0 and 1 for each filter.\n\n```\n{  \"feature1\": {    rules: [      // Will include 60% of users - ones with a hash between 0 and 0.6      {        variations: [false, true],        filters: [          {            seed: \"pricing\",            attribute: \"id\",            ranges: [[0, 0.6]]          }        ]      }    ]  },  \"feature2\": {    rules: [      // Will include the other 40% of users - ones with a hash between 0.6 and 1      {        variations: [false, true],        filters: [          {            seed: \"pricing\",            attribute: \"id\",            ranges: [[0.6, 1.0]]          }        ]      },    ]  }}\n```\n\n**Note** - If a user is excluded from an experiment due to a filter, the rule will be skipped and the next matching rule will be used instead.\n\n## Examples[​](#examples \"Direct link to Examples\")\n\n*   [Typescript example app with strict typing](https://github.com/growthbook/examples/tree/main/vanilla-typescript) .",
    "title": "Node.js SDK | GrowthBook Docs",
    "description": "GrowthBook SDK for Node.js",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/lib/script-tag",
    "markdown": "# HTML Script Tag | GrowthBook Docs\n\nWe provide an HTML `<script>` tag option for easily integrating GrowthBook into any website.\n\nThis option is quick and straightforward to use and does not require coding knowledge to implement.\n\n## Installation[​](#installation \"Direct link to Installation\")\n\nFor this, you will need a **Client Key** from an SDK Connection within GrowthBook. This will start with `sdk-`.\n\nAdd the following script tag to your website and replace `YOUR_CLIENT_KEY_HERE` with your actual Client Key:\n\n```\n<script async  data-client-key=\"YOUR_CLIENT_KEY_HERE\"  src=\"https://cdn.jsdelivr.net/npm/@growthbook/growthbook/dist/bundles/auto.min.js\"></script>\n```\n\nOr, if you can't add `data-*` attributes (e.g. in Google Tag Manager), you can use this alternate version:\n\n```\n<script>(function(s) {  s=document.createElement('script'); s.async=true;  s.dataset.clientKey=\"YOUR_CLIENT_KEY_HERE\";  s.src=\"https://cdn.jsdelivr.net/npm/@growthbook/growthbook/dist/bundles/auto.min.js\";  document.head.appendChild(s);})();</script>\n```\n\nFor best performance, we recommend adding this script tag directly before the closing `</head>` tag, however it is also possible to load through something like Google Tag Manager if that is your only option.\n\n### Optional Configuration Settings[​](#optional-configuration-settings \"Direct link to Optional Configuration Settings\")\n\nBesides the Client Key, there are some additional settings you can define with `data-` attributes on the script tag:\n\n*   `data-api-host` - Defaults to GrowthBook Cloud's [https://cdn.growthbook.io](https://cdn.growthbook.io/). This must be set to your own domain instead if self-hosting or using the GrowthBook Proxy.\n*   `data-decryption-key` - Required if you enabled encryption in your SDK Connection settings in GrowthBook\n\nAll other settings can be defined with a `window.growthbook_config` object BEFORE you load the script tag. This accepts the same settings as our [JavaScript SDK](https://docs.growthbook.io/lib/js). Here's an example:\n\n```\n<script>window.growthbook_config = window.growthbook_config || {};// Disable streaming updateswindow.growthbook_config.backgroundSync = false;</script>\n```\n\nIf you need low level access to the GrowthBook SDK instance for any reason, you can use a callback function. This will be called as soon as the GrowthBook SDK instance is ready. If you push to the queue after GrowthBook has already loaded, the callback will be invoked immediately.\n\n```\n<script>window.growthbook_queue = window.growthbook_queue || [];window.growthbook_queue.push((gb) => {  // Do whatever you need with the GrowthBook instance here  console.log(gb.getAttributes());})</script>\n```\n\n## Targeting Attributes[​](#targeting-attributes \"Direct link to Targeting Attributes\")\n\nThe following targeting attributes are set automatically and available for use.\n\n*   `id` - creates a long-lived `gbuuid` cookie if it doesn't exist already\n*   `url`\n*   `path`\n*   `host`\n*   `query`\n*   `pageTitle`\n*   `deviceType` - either `mobile` or `desktop`\n*   `browser` - one of `chrome`, `edge`, `firefox`, `safari`, or `unknown`\n*   `utmSource`\n*   `utmMedium`\n*   `utmCampaign`\n*   `utmTerm`\n*   `utmContent`\n\nIn addition, if you use Google Tag Manager, any variables you set in your Data Layer will also be set here and available for targeting.\n\n### Adding Custom Attributes[​](#adding-custom-attributes \"Direct link to Adding Custom Attributes\")\n\nYou can include your own custom attributes by adding the following BEFORE the GrowthBook snippet:\n\n```\n<script>window.growthbook_config = window.growthbook_config || {};window.growthbook_config.attributes = {    country: \"US\",    otherCustomAttribute: 12,}</script>\n```\n\nYou can also set custom attributes later, after the script tag has been added. Please note, this may cause flickering in your experiments if you reference these custom attributes in your experiment targeting.\n\n```\n<script>window.growthbook_queue = window.growthbook_queue || [];window.growthbook_queue.push((gb) => {  gb.updateAttributes({    country: \"US\",    otherCustomAttribute: 12,  });});</script>\n```\n\n### Refreshing Auto Attributes[​](#refreshing-auto-attributes \"Direct link to Refreshing Auto Attributes\")\n\nThe GrowthBook snippet will automatically watch for URL changes and update attributes when that happens. If you would like more control over this behavior, you can manually trigger updates at any time by firing a `growthbookrefresh` event from JavaScript. For example:\n\n```\ndocument.dispatchEvent(new CustomEvent(\"growthbookrefresh\"));\n```\n\n## Tracking Experiment Views[​](#tracking-experiment-views \"Direct link to Tracking Experiment Views\")\n\nWhen a user views an experiment, a tracking event is fired. There is built-in support for Segment.io (`analytics.js`), GA4 (`gtag`), and Google Tag Manager (`dataLayer`).\n\n### Segment.io[​](#segmentio \"Direct link to Segment.io\")\n\nGrowthBook will automatically fire an event using `window.analytics.track` if it's present on the page. The event name is `Experiment Viewed` and it has two properties: `experiment_id` and `variation_id`.\n\nThere is no additional configuration needed.\n\n### GA4 (`gtag`)[​](#ga4-gtag \"Direct link to ga4-gtag\")\n\nGrowthBook will automatically fire an event using Google Analytic 4's `window.gtag` if it's present on the page. The event name is `experiment_viewed` and it has two properties: `experiment_id` and `variation_id`.\n\nThere is no additional configuration needed.\n\n### Google Tag Manager[​](#google-tag-manager \"Direct link to Google Tag Manager\")\n\nWe send the following event to the Data Layer. You will need to add a trigger based on this and forward it on to your analytics tool of choice.\n\n```\n{    \"event\": \"experiment_viewed\",    \"experiment_id\": \"...\",    \"variation_id\": \"...\"}\n```\n\nWe have a walkthrough tutorial on how to configure this in our [GTM Guide](https://docs.growthbook.io/guide/google-tag-manager-and-growthbook#tracking-via-datalayer-and-gtm)\n\n### Mixpanel[​](#mixpanel \"Direct link to Mixpanel\")\n\nTo work with Mixpanel, we have to set the ID as an attribute for GrowthBook, and also add the custom event tracking callback. Below is an example of how to set up GrowthBook with Mixpanel. The script initializes Mixpanel (which you probably already have) and then sets the Mixpanel distinct ID to a GrowthBook `id` attribute once it has loaded. Then the script defines a trackingCallback to log the experiment exposure event to Mixpanel.\n\n```\n<script>window.growthbook_config = window.growthbook_config || {};mixpanel.init(\"[YOUR PROJECT TOKEN]\", {  debug: true,  loaded: function (mx) {    window.growthbook_queue = window.growthbook_queue || [];    window.growthbook_queue.push((gb) => {     gb.setAttributes({       ...gb.getAttributes(),       id: mx.get_distinct_id(),     });   })  },});window.growthbook_config.trackingCallback = (experiment, result) => {    mixpanel.track(\"$experiment_started\", {      \"Experiment name\": experiment.key,      \"Variant name\": result.variationId,      $source: \"growthbook\",    });</script><!-- then load the GrowthBook SDK --><script async  data-client-key=\"YOUR_CLIENT_KEY_HERE\"  src=\"https://cdn.jsdelivr.net/npm/@growthbook/growthbook/dist/bundles/auto.min.js\"></script>\n```\n\n### Others[​](#others \"Direct link to Others\")\n\nFor any other event tracking system (or if the built-in ones above do not meet your requirements), you can define your own custom tracking callback function. This must be defined _BEFORE_ loading the main GrowthBook snippet on the page.\n\n```\n<script>window.growthbook_config = window.growthbook_config || {};window.growthbook_config.trackingCallback = (experiment, result) => {  customEventTracker(\"Viewed Experiment\", {    experiment_id: experiment.key,    variation_id: result.key  })};</script>\n```\n\n## Sticky Bucketing[​](#sticky-bucketing \"Direct link to Sticky Bucketing\")\n\nThis SDK supports [Sticky Bucketing](https://docs.growthbook.io/app/sticky-bucketing), but it is disabled by default. To enable, add the following to your script tag:\n\n```\ndata-use-sticky-bucket-service=\"cookie\"\n```\n\nThere are 2 possible values:\n\n*   **cookie** - Persist in a cookie that is shared between the browser and your server\n*   **localStorage** - Persist in the browser's localStorage, which is never sent to your server\n\nYou can also customize the key we use to store sticky buckets by adding a prefix:\n\n```\ndata-sticky-bucket-prefix=\"my_prefix\"\n```\n\n## Using Feature Flags[​](#using-feature-flags \"Direct link to Using Feature Flags\")\n\nYou can use feature flags with this SDK, but it does require some manual coding work. Here is an example:\n\n```\n<script>// Wait for the GrowthBook SDK to load before runningwindow.growthbook_queue = window.growthbook_queue || [];window.growthbook_queue.push((gb) => {  // Function that uses feature flags to make changes to the page  const applyFeatureFlags = () => {    if(gb.isOn(\"dark-mode\")) {      document.documentElement.classList.add(\"dark\");    } else {      document.documentElement.classList.remove(\"dark\");    }  }  // Call your function initially plus whenever new data is received  applyFeatureFlags();  document.addEventListener(\"growthbookdata\", applyFeatureFlags)});</script>\n```\n\nBy default, this SDK persists a random unique identifier in a first-party cookie named `gbuuid`. This cookie is required to provide a consistent user experience to your visitors. Without this cookie, if you run an A/B test, a visitor might be re-bucketed into a different variation every time they visit your website.\n\nThe `gbuuid` cookie does not contain any Personally Identifiable Information (it's just a randomly generated id). It is a first-party cookie that is never shared with any third-party services, not even GrowthBook itself. However, we still recommend adding this to your site's cookie policy if you have one.\n\n### Delay Storing the Cookie Until Consent is Granted[​](#delay-storing-the-cookie-until-consent-is-granted \"Direct link to Delay Storing the Cookie Until Consent is Granted\")\n\nIf you must delay persisting the `gbuuid` cookie until a user consents, you can add a `data-no-auto-cookies` attribute to the script tag.\n\nThis will still generate a UUID for the user, but will not persist it. That means, if the user refreshes the page, they will have a new random UUID generated.\n\nYou have the option to manually persist this cookie at any time, for example when a user grants consent on your cookie banner. All you need to do is fire this custom event from javascript:\n\n```\ndocument.dispatchEvent(new CustomEvent(\"growthbookpersist\"));\n```\n\n## Content Security Policy (CSP)[​](#content-security-policy-csp \"Direct link to Content Security Policy (CSP)\")\n\nIf your site uses a Content Security Policy, you may need to make a few changes to the `script-src` directive for this SDK to load and run on your site.\n\nFirst, make sure to add `https://cdn.jsdelivr.net` so the script itself can load. If this isn't possible, you can save the contents of the script and host it on your own domain instead. Just note that doing that means you will no longer get automatic updates when we make improvements to the script tag.\n\nSecond, if you plan to use the Visual Editor to inject custom javascript into your site, you need to allow both `usafe-inline` and `unsafe-eval`. If this isn't possible, we have an alternative using nonces (see below).\n\n### Using Script Nonces[​](#using-script-nonces \"Direct link to Using Script Nonces\")\n\nAs an alternative to allowing `unsafe-inline`, we support \"nonces\", although this requires some very technical and custom configuration to hook up. This is only required if you plan to use the Visual Editor to inject custom javascript into your site.\n\nYou will still need to allow `usafe-eval` due to how our Visual Editor works under-the-hood.\n\nFirst, you will need to generate a unique nonce value for every request and add it to your CSP header. This can be done on the edge such as with a Cloudflare Worker.\n\nLastly, you will also need to inject the following into your page's `<head>` BEFORE you load the GrowthBook snippet. This can be accomplished in the same edge worker. Replace all instances of `$NONCE` with the unique nonce value you generated.\n\n```\n<script nonce=\"$NONCE\">window.growthbook_config = window.growthbook_config || {};window.growthbook_config.jsInjectionNonce = \"$NONCE\";</script>\n```",
    "title": "HTML Script Tag | GrowthBook Docs",
    "description": "Load the GrowthBook SDK in any website or low code platform",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/lib/kotlin",
    "markdown": "# Kotlin SDK | GrowthBook Docs\n\n## Kotlin (Android)\n\nThis SDK supports both Java and Kotlin Android apps using Android SDK 21 and above.\n\n## Installation[​](#installation \"Direct link to Installation\")\n\n```\nrepositories {    mavenCentral()}dependencies {    implementation 'io.growthbook.sdk:GrowthBook:1.1.58'}\n```\n\n## Quick Usage[​](#quick-usage \"Direct link to Quick Usage\")\n\nTo create a GrowthBook SDK instance, use `GBSDKBuilder`. Then, you can evaluate feature flags or run experiments.\n\n```\n// User attributes for targeting and assigning users to experiment variationsval attrs = HashMap<String, Any>()attrs.put(\"id\", \"123\")attrs.put(\"env\", \"dev\")attrs.put(\"betaUser\", true)val gb = GBSDKBuilder(  // Fetch and cache feature definitions from GrowthBook API  // If self-hosting, we recommend using a CDN in production  apiKey = \"key_123abc\",  hostURL = \"https://cdn.growthbook.io/\",  attributes = attrs,  trackingCallback = { gbExperiment, gbExperimentResult ->    // TODO: track in your analytics system    print(\"Viewed Experiment\")    print(\"Experiment Id: \" + gbExperiment.key)    print(\"Variation Id: \" + gbExperimentResult.variationId)  },  networkDispatcher = DefaultGBNetworkClient(),  encryptionKey = \"insert_your_encription_key_if_you_are_using_encryption\",).initialize()\n```\n\nIf you need to set or update attributes asynchronously, you can do so with `setAttributes()`. This will completely overwrite the attributes object with whatever you pass in. Also, be aware that changing attributes may change the assigned feature values. This can be disorienting to users if not handled carefully.\n\nIf you are accessing features the first time there will be no features right after `initialize()` method call because features are not got from Backend yet. If you need to access features as soon as possible, you need to use `GBCacheRefreshHandler`. You can pass your implementation of `GBCacheRefreshHandler` through `setRefreshHandler()` method. Code snippet:\n\n```\nclass ForExampleMainActivity {    var growthBookSDK: GrowthBookSDK? = null    fun someInitMethodForExampleOnStart() {        val gbSdkBuilder = GBSDKBuilder(            ....        )        gbSdkBuilder.setRefreshHandler { isRefreshed, gbError ->            // access your features            growthBookSDK?.feature(\"your_feature_key\").on        }        growthBookSDK = gbSdkBuilder.initialize()    }}\n```\n\n## Using Features[​](#using-features \"Direct link to Using Features\")\n\nThe `feature` method takes a String feature name and returns a `FeatureResult` object with a few useful properties:\n\n*   **value** (`Any`) - The assigned value of the feature\n*   **on** (`Boolean`) - The value cast to a boolean\n*   **off** (`Boolean`) - The value cast to a boolean and then negated\n*   **source** (`String`) - Why the value was assigned to the user. One of \"unknownFeature\", \"defaultValue\", \"force\", or \"experiment\"\n\nWhen the source is \"experiment\", there are 2 additional properties that tell you which experiment was used and more details about the result of the experiment:\n\n*   **experiment** (`GBExperiment`)\n*   **experimentResult** (`GBExperimentResult`)\n\nHere are some examples:\n\n```\nval feature = gb.feature(\"my-feature\")// Do something if feature is truthyif (feature.on) { }// Do something if feature is falsyif (feature.off) { }// Print the actual value of the feature// (depending on the feature, might be a string, number, boolean, etc.)println(feature.value)// Print the experiment id used to assign the feature valueif (feature.source == \"experiment\") {  println(feature.experiment.key)}\n```\n\n## Running Inline Experiments[​](#running-inline-experiments \"Direct link to Running Inline Experiments\")\n\nInstead of just using features defined in the GrowthBook API, you can also just run an experiment directly. This is done with the `run` method which takes a `GBExperiment` object as an argument and returns a `GBExperimentResult` object:\n\n```\ncal exp = GBExperiment()exp.key = \"my-experiment\"exp.variations = arrayOf(\"control\", \"variation\")val result = gb.run(exp)// Either \"control\" or \"variation\"println(result.value)\n```\n\nThe `GBExperiment` class has two required properties - `key` and `variations`. There are also a number of optional properties:\n\n*   **key** (`String`) - The unique identifier for this experiment\n*   **variations** (`Any[]`) - Array of variations to decide between\n*   **weights** (`Float[]`) - How to weight traffic between variations. Must add to 1.\n*   **active** (`Boolean`) - If set to false, always return the control (first variation)\n*   **coverage** (`Float`) - What percent of users should be included in the experiment (between 0 and 1, inclusive)\n*   **condition** (`GBCondition`) - Optional targeting condition\n*   **namespace** (`[String, Int, Int]`) - Adds the experiment to a namespace\n*   **force** (`Int`) - All users included in the experiment will be forced into the specific variation index\n*   **hashAttribute** (`String`) - What user attribute should be used to assign variations (defaults to `id`)\n\nThe `GBExperimentResult` object returns the following properties:\n\n*   **inExperiment** (`Boolean`)\n*   **variationId** (`Int`) - The array index of the assigned variation\n*   **value** (`Any`) - The value of the assigned variation\n*   **hashAttribute** (`String`) - The user attribute used to assign a variation\n*   **hashValue** (`String`) - The value of the attribute used to assign a variation\n\n## More Documentation[​](#more-documentation \"Direct link to More Documentation\")\n\nThe GitHub repo for this SDK has more detailed class and method documentation - [https://github.com/growthbook/growthbook-kotlin](https://github.com/growthbook/growthbook-kotlin)",
    "title": "Kotlin SDK | GrowthBook Docs",
    "description": "GrowthBook SDK for Kotlin - Android",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/api",
    "markdown": "# GrowthBook REST API | GrowthBook Docs\n\nDownload OpenAPI specification:[Download](https://api.growthbook.io/api/v1/openapi.yaml)\n\nGrowthBook offers a full REST API for interacting with the GrowthBook application. This is currently in **beta** as we add more authenticated API routes and features.\n\nRequest data can use either JSON or Form data encoding (with proper `Content-Type` headers). All response bodies are JSON-encoded.\n\nThe API base URL for GrowthBook Cloud is `https://api.growthbook.io`. For self-hosted deployments, it is the same as your API\\_HOST environment variable (defaults to `http://localhost:3100`). The rest of these docs will assume you are using GrowthBook Cloud.\n\n## [](#section/Authentication)Authentication\n\nWe support both the HTTP Basic and Bearer authentication schemes for convenience.\n\nYou first need to generate a new API Key in GrowthBook. Different keys have different permissions:\n\n*   **Personal Access Tokens**: These are sensitive and provide the same level of access as the user has to an organization. These can be created by going to `Personal Access Tokens` under the your user menu.\n*   **Secret Keys**: These are sensitive and provide the level of access for the role, which currently is either `admin` or `readonly`. Only Admins with the `manageApiKeys` permission can manage Secret Keys on behalf of an organization. These can be created by going to `Settings -> API Keys`\n\nIf using HTTP Basic auth, pass the Secret Key as the username and leave the password blank:\n\n```\ncurl https://api.growthbook.io/api/v1 \\\n  -u secret_abc123DEF456:\n# The \":\" at the end stops curl from asking for a password\n```\n\nIf using Bearer auth, pass the Secret Key as the token:\n\n```\ncurl https://api.growthbook.io/api/v1 \\\n-H \"Authorization: Bearer secret_abc123DEF456\"\n```\n\n## [](#section/Errors)Errors\n\nThe API may return the following error status codes:\n\n*   **400** - Bad Request - Often due to a missing required parameter\n*   **401** - Unauthorized - No valid API key provided\n*   **402** - Request Failed - The parameters are valid, but the request failed\n*   **403** - Forbidden - Provided API key does not have the required access\n*   **404** - Not Found - Unknown API route or requested resource\n*   **429** - Too Many Requests - You exceeded the rate limit of 60 requests per minute. Try again later.\n*   **5XX** - Server Error - Something went wrong on GrowthBook's end (these are rare)\n\nThe response body will be a JSON object with the following properties:\n\n*   **message** - Information about the error\n\n## [](#tag/projects)Projects\n\nProjects are used to organize your feature flags and experiments\n\n## [](#tag/projects/operation/listProjects)Get all projects\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/projects \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"projects\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"settings\": {`\n            \n            *   `\"statsEngine\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/projects/operation/postProject)Create a single project\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nname\n\nrequired\n\ndescription\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"settings\": {`\n    \n    *   `\"statsEngine\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"project\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"settings\": {`\n        \n        *   `\"statsEngine\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/projects/operation/getProject)Get a single project\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/projects/prj\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"project\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"settings\": {`\n        \n        *   `\"statsEngine\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/projects/operation/putProject)Edit a single project\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nname\n\ndescription\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"settings\": {`\n    \n    *   `\"statsEngine\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"project\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"settings\": {`\n        \n        *   `\"statsEngine\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/projects/operation/deleteProject)Deletes a single project\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-X DELETE https://api.growthbook.io/api/v1/projects/prj\\_\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"deletedId\": \"prj__123abc\"`\n    \n\n`}`\n\n## [](#tag/environments)Environments\n\nGrowthBook comes with one environment by default (production), but you can add as many as you need. When used with feature flags, you can enable/disable feature flags on a per-environment basis.\n\n## [](#tag/environments/operation/listEnvironments)Get the organization's environments\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/environments \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"environments\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"toggleOnList\": true,`\n            \n        *   `\"defaultState\": true,`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/environments/operation/postEnvironment)Create a new environment\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nid\n\nrequired\n\nstring\n\nThe ID of the new environment\n\ndescription\n\nstring\n\nThe description of the new environment\n\ntoggleOnList\n\nbool\n\nShow toggle on feature list\n\ndefaultState\n\nbool\n\nDefault state for new features\n\nprojects\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"toggleOnList\": null,`\n    \n*   `\"defaultState\": null,`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `]`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"environment\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"toggleOnList\": true,`\n        \n    *   `\"defaultState\": true,`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/environments/operation/putEnvironment)Update an environment\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\ndescription\n\nstring\n\nThe description of the new environment\n\ntoggleOnList\n\nboolean\n\nShow toggle on feature list\n\ndefaultState\n\nboolean\n\nDefault state for new features\n\nprojects\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"description\": \"string\",`\n    \n*   `\"toggleOnList\": true,`\n    \n*   `\"defaultState\": true,`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `]`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"environment\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"toggleOnList\": true,`\n        \n    *   `\"defaultState\": true,`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/environments/operation/deleteEnvironment)Deletes a single environment\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-X DELETE https://api.growthbook.io/api/v1/enviromnents/env\\-id \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"deletedId\": \"string\"`\n    \n\n`}`\n\n## [](#tag/features)Feature Flags\n\nControl your feature flags programatically\n\n## [](#tag/features/operation/listFeatures)Get all features\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\nprojectId\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/features \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"features\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"archived\": true,`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"owner\": \"string\",`\n            \n        *   `\"project\": \"string\",`\n            \n        *   `\"valueType\": \"boolean\",`\n            \n        *   `\"defaultValue\": \"string\",`\n            \n        \n        *   `\"environments\": {`\n            \n            *   `\"property1\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\",`\n                    \n                *   `\"draft\": {`\n                    \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"defaultValue\": \"string\",`\n                        \n                    *   `\"rules\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"description\": \"string\",`\n                                \n                            *   `\"condition\": \"string\",`\n                                \n                            *   `\"savedGroupTargeting\": [`\n                                \n                                *   `{`\n                                    \n                                    *   `\"matchType\": null,`\n                                        \n                                    *   `\"savedGroups\": [ ]`\n                                        \n                                    \n                                    `}`\n                                    \n                                \n                                `],`\n                                \n                            *   `\"id\": \"string\",`\n                                \n                            *   `\"enabled\": true,`\n                                \n                            *   `\"type\": \"force\",`\n                                \n                            *   `\"value\": \"string\"`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"definition\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `},`\n                \n            *   `\"property2\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\",`\n                    \n                *   `\"draft\": {`\n                    \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"defaultValue\": \"string\",`\n                        \n                    *   `\"rules\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"description\": \"string\",`\n                                \n                            *   `\"condition\": \"string\",`\n                                \n                            *   `\"savedGroupTargeting\": [`\n                                \n                                *   `{`\n                                    \n                                    *   `\"matchType\": null,`\n                                        \n                                    *   `\"savedGroups\": [ ]`\n                                        \n                                    \n                                    `}`\n                                    \n                                \n                                `],`\n                                \n                            *   `\"id\": \"string\",`\n                                \n                            *   `\"enabled\": true,`\n                                \n                            *   `\"type\": \"force\",`\n                                \n                            *   `\"value\": \"string\"`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"definition\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `},`\n            \n        *   `\"prerequisites\": [`\n            \n            *   `{`\n                \n                *   `\"parentId\": \"string\",`\n                    \n                *   `\"parentCondition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"revision\": {`\n            \n            *   `\"version\": 0,`\n                \n            *   `\"comment\": \"string\",`\n                \n            *   `\"date\": \"2019-08-24T14:15:22Z\",`\n                \n            *   `\"publishedBy\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/features/operation/postFeature)Create a single feature\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nid\n\nrequired\n\nstring non-empty\n\nA unique key name for the feature. Feature keys can only include letters, numbers, hyphens, and underscores.\n\narchived\n\nboolean\n\ndescription\n\nstring\n\nDescription of the feature\n\nowner\n\nrequired\n\nstring\n\nEmail of the person who owns this experiment\n\nproject\n\nstring\n\nAn associated project ID\n\nvalueType\n\nrequired\n\nstring\n\nEnum: \"boolean\" \"string\" \"number\" \"json\"\n\nThe data type of the feature payload. Boolean by default.\n\ndefaultValue\n\nrequired\n\nstring\n\nDefault value when feature is enabled. Type must match `valueType`.\n\ntags\n\nArray of strings\n\nList of associated tags\n\nobject\n\nA dictionary of environments that are enabled for this feature. Keys supply the names of environments. Environments belong to organization and are not specified will be disabled by default.\n\njsonSchema\n\nstring\n\nUse JSON schema to validate the payload of a JSON-type feature value (enterprise only).\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"archived\": true,`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"project\": \"string\",`\n    \n*   `\"valueType\": \"boolean\",`\n    \n*   `\"defaultValue\": \"string\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"environments\": {`\n    \n    *   `\"property1\": {`\n        \n        *   `\"enabled\": true,`\n            \n        *   `\"rules\": [`\n            \n            *   `{`\n                \n                *   `\"description\": \"string\",`\n                    \n                *   `\"condition\": \"string\",`\n                    \n                *   `\"savedGroupTargeting\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"matchType\": \"all\",`\n                            \n                        *   `\"savedGroups\": [`\n                            \n                            *   `\"string\"`\n                                \n                            \n                            `]`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"id\": \"string\",`\n                    \n                *   `\"enabled\": true,`\n                    \n                *   `\"type\": \"force\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"definition\": \"string\",`\n            \n        *   `\"draft\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"property2\": {`\n        \n        *   `\"enabled\": true,`\n            \n        *   `\"rules\": [`\n            \n            *   `{`\n                \n                *   `\"description\": \"string\",`\n                    \n                *   `\"condition\": \"string\",`\n                    \n                *   `\"savedGroupTargeting\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"matchType\": \"all\",`\n                            \n                        *   `\"savedGroups\": [`\n                            \n                            *   `\"string\"`\n                                \n                            \n                            `]`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"id\": \"string\",`\n                    \n                *   `\"enabled\": true,`\n                    \n                *   `\"type\": \"force\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"definition\": \"string\",`\n            \n        *   `\"draft\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `},`\n    \n*   `\"jsonSchema\": \"string\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"feature\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"archived\": true,`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    *   `\"valueType\": \"boolean\",`\n        \n    *   `\"defaultValue\": \"string\",`\n        \n    \n    *   `\"environments\": {`\n        \n        *   `\"property1\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\",`\n                \n            *   `\"draft\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `},`\n            \n        *   `\"property2\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\",`\n                \n            *   `\"draft\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"prerequisites\": [`\n        \n        *   `{`\n            \n            *   `\"parentId\": \"string\",`\n                \n            *   `\"parentCondition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"revision\": {`\n        \n        *   `\"version\": 0,`\n            \n        *   `\"comment\": \"string\",`\n            \n        *   `\"date\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"publishedBy\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/features/operation/getFeature)Get a single feature\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/features/my\\_feature \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"feature\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"archived\": true,`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    *   `\"valueType\": \"boolean\",`\n        \n    *   `\"defaultValue\": \"string\",`\n        \n    \n    *   `\"environments\": {`\n        \n        *   `\"property1\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\",`\n                \n            *   `\"draft\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `},`\n            \n        *   `\"property2\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\",`\n                \n            *   `\"draft\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"prerequisites\": [`\n        \n        *   `{`\n            \n            *   `\"parentId\": \"string\",`\n                \n            *   `\"parentCondition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"revision\": {`\n        \n        *   `\"version\": 0,`\n            \n        *   `\"comment\": \"string\",`\n            \n        *   `\"date\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"publishedBy\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/features/operation/updateFeature)Partially update a feature\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\ndescription\n\nstring\n\nDescription of the feature\n\narchived\n\nboolean\n\nproject\n\nstring\n\nAn associated project ID\n\nowner\n\nstring\n\ndefaultValue\n\nstring\n\ntags\n\nArray of strings\n\nList of associated tags. Will override tags completely with submitted list\n\nobject\n\njsonSchema\n\nstring\n\nUse JSON schema to validate the payload of a JSON-type feature value (enterprise only).\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"description\": \"string\",`\n    \n*   `\"archived\": true,`\n    \n*   `\"project\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"defaultValue\": \"string\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"environments\": {`\n    \n    *   `\"property1\": {`\n        \n        *   `\"enabled\": true,`\n            \n        *   `\"rules\": [`\n            \n            *   `{`\n                \n                *   `\"description\": \"string\",`\n                    \n                *   `\"condition\": \"string\",`\n                    \n                *   `\"savedGroupTargeting\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"matchType\": \"all\",`\n                            \n                        *   `\"savedGroups\": [`\n                            \n                            *   `\"string\"`\n                                \n                            \n                            `]`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"id\": \"string\",`\n                    \n                *   `\"enabled\": true,`\n                    \n                *   `\"type\": \"force\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"definition\": \"string\",`\n            \n        *   `\"draft\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"property2\": {`\n        \n        *   `\"enabled\": true,`\n            \n        *   `\"rules\": [`\n            \n            *   `{`\n                \n                *   `\"description\": \"string\",`\n                    \n                *   `\"condition\": \"string\",`\n                    \n                *   `\"savedGroupTargeting\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"matchType\": \"all\",`\n                            \n                        *   `\"savedGroups\": [`\n                            \n                            *   `\"string\"`\n                                \n                            \n                            `]`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"id\": \"string\",`\n                    \n                *   `\"enabled\": true,`\n                    \n                *   `\"type\": \"force\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"definition\": \"string\",`\n            \n        *   `\"draft\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `},`\n    \n*   `\"jsonSchema\": \"string\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"feature\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"archived\": true,`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    *   `\"valueType\": \"boolean\",`\n        \n    *   `\"defaultValue\": \"string\",`\n        \n    \n    *   `\"environments\": {`\n        \n        *   `\"property1\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\",`\n                \n            *   `\"draft\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `},`\n            \n        *   `\"property2\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\",`\n                \n            *   `\"draft\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"prerequisites\": [`\n        \n        *   `{`\n            \n            *   `\"parentId\": \"string\",`\n                \n            *   `\"parentCondition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"revision\": {`\n        \n        *   `\"version\": 0,`\n            \n        *   `\"comment\": \"string\",`\n            \n        *   `\"date\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"publishedBy\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/features/operation/toggleFeature)Toggle a feature in one or more environments\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nreason\n\nrequired\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"reason\": \"string\",`\n    \n*   `\"environments\": {`\n    \n    *   `\"property1\": true,`\n        \n    *   `\"property2\": true`\n        \n    \n    `}`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"feature\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"archived\": true,`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    *   `\"valueType\": \"boolean\",`\n        \n    *   `\"defaultValue\": \"string\",`\n        \n    \n    *   `\"environments\": {`\n        \n        *   `\"property1\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\",`\n                \n            *   `\"draft\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `},`\n            \n        *   `\"property2\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\",`\n                \n            *   `\"draft\": {`\n                \n                *   `\"enabled\": true,`\n                    \n                *   `\"defaultValue\": \"string\",`\n                    \n                *   `\"rules\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"description\": \"string\",`\n                            \n                        *   `\"condition\": \"string\",`\n                            \n                        *   `\"savedGroupTargeting\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"matchType\": \"all\",`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `],`\n                            \n                        *   `\"id\": \"string\",`\n                            \n                        *   `\"enabled\": true,`\n                            \n                        *   `\"type\": \"force\",`\n                            \n                        *   `\"value\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"definition\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"prerequisites\": [`\n        \n        *   `{`\n            \n            *   `\"parentId\": \"string\",`\n                \n            *   `\"parentCondition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"revision\": {`\n        \n        *   `\"version\": 0,`\n            \n        *   `\"comment\": \"string\",`\n            \n        *   `\"date\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"publishedBy\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/features/operation/getFeatureKeys)Get list of feature keys\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nprojectId\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/feature\\-keys?projectId\\=prj\\_5l652 \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n## [](#tag/data-sources)Data Sources\n\nHow GrowthBook connects and queries your data\n\n## [](#tag/data-sources/operation/listDataSources)Get all data sources\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\nprojectId\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/data\\-sources \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"dataSources\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"type\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"projectIds\": [`\n            \n            *   `\"string\"`\n                \n            \n            `],`\n            \n        *   `\"eventTracker\": \"string\",`\n            \n        *   `\"identifierTypes\": [`\n            \n            *   `{`\n                \n                *   `\"id\": \"string\",`\n                    \n                *   `\"description\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"assignmentQueries\": [`\n            \n            *   `{`\n                \n                *   `\"id\": \"string\",`\n                    \n                *   `\"name\": \"string\",`\n                    \n                *   `\"description\": \"string\",`\n                    \n                *   `\"identifierType\": \"string\",`\n                    \n                *   `\"sql\": \"string\",`\n                    \n                *   `\"includesNameColumns\": true,`\n                    \n                *   `\"dimensionColumns\": [`\n                    \n                    *   `\"string\"`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"identifierJoinQueries\": [`\n            \n            *   `{`\n                \n                *   `\"identifierTypes\": [`\n                    \n                    *   `\"string\"`\n                        \n                    \n                    `],`\n                    \n                *   `\"sql\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"mixpanelSettings\": {`\n            \n            *   `\"viewedExperimentEventName\": \"string\",`\n                \n            *   `\"experimentIdProperty\": \"string\",`\n                \n            *   `\"variationIdProperty\": \"string\",`\n                \n            *   `\"extraUserIdProperty\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/data-sources/operation/getDataSource)Get a single data source\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/data\\-sources/ds\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"dataSource\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"type\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"projectIds\": [`\n        \n        *   `\"string\"`\n            \n        \n        `],`\n        \n    *   `\"eventTracker\": \"string\",`\n        \n    *   `\"identifierTypes\": [`\n        \n        *   `{`\n            \n            *   `\"id\": \"string\",`\n                \n            *   `\"description\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"assignmentQueries\": [`\n        \n        *   `{`\n            \n            *   `\"id\": \"string\",`\n                \n            *   `\"name\": \"string\",`\n                \n            *   `\"description\": \"string\",`\n                \n            *   `\"identifierType\": \"string\",`\n                \n            *   `\"sql\": \"string\",`\n                \n            *   `\"includesNameColumns\": true,`\n                \n            *   `\"dimensionColumns\": [`\n                \n                *   `\"string\"`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"identifierJoinQueries\": [`\n        \n        *   `{`\n            \n            *   `\"identifierTypes\": [`\n                \n                *   `\"string\"`\n                    \n                \n                `],`\n                \n            *   `\"sql\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"mixpanelSettings\": {`\n        \n        *   `\"viewedExperimentEventName\": \"string\",`\n            \n        *   `\"experimentIdProperty\": \"string\",`\n            \n        *   `\"variationIdProperty\": \"string\",`\n            \n        *   `\"extraUserIdProperty\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/metrics)Metrics\n\nMetrics used as goals and guardrails for experiments\n\n## [](#tag/metrics/operation/listMetrics)Get all metrics\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\nprojectId\n\ndatasourceId\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/metrics \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"metrics\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"managedBy\": \"\",`\n            \n        *   `\"dateCreated\": \"string\",`\n            \n        *   `\"dateUpdated\": \"string\",`\n            \n        *   `\"owner\": \"string\",`\n            \n        *   `\"datasourceId\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"type\": \"binomial\",`\n            \n        \n        *   `\"archived\": true,`\n            \n        *   `\"behavior\": {`\n            \n            *   `\"goal\": \"increase\",`\n                \n            *   `\"cappingSettings\": {`\n                \n                *   `\"type\": \"none\",`\n                    \n                *   `\"value\": 0,`\n                    \n                *   `\"ignoreZeros\": true`\n                    \n                \n                `},`\n                \n            *   `\"cap\": 0,`\n                \n            *   `\"capping\": \"absolute\",`\n                \n            *   `\"capValue\": 0,`\n                \n            *   `\"windowSettings\": {`\n                \n                *   `\"type\": \"none\",`\n                    \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowValue\": 0,`\n                    \n                *   `\"windowUnit\": \"hours\"`\n                    \n                \n                `},`\n                \n            *   `\"priorSettings\": {`\n                \n                *   `\"override\": true,`\n                    \n                *   `\"proper\": true,`\n                    \n                *   `\"mean\": 0,`\n                    \n                *   `\"stddev\": 0`\n                    \n                \n                `},`\n                \n            *   `\"conversionWindowStart\": 0,`\n                \n            *   `\"conversionWindowEnd\": 0,`\n                \n            *   `\"riskThresholdSuccess\": 0,`\n                \n            *   `\"riskThresholdDanger\": 0,`\n                \n            *   `\"minPercentChange\": 0,`\n                \n            *   `\"maxPercentChange\": 0,`\n                \n            *   `\"minSampleSize\": 0`\n                \n            \n            `},`\n            \n        *   `\"sql\": {`\n            \n            *   `\"identifierTypes\": [`\n                \n                *   `\"string\"`\n                    \n                \n                `],`\n                \n            *   `\"conversionSQL\": \"string\",`\n                \n            *   `\"userAggregationSQL\": \"string\",`\n                \n            *   `\"denominatorMetricId\": \"string\"`\n                \n            \n            `},`\n            \n        *   `\"sqlBuilder\": {`\n            \n            *   `\"identifierTypeColumns\": [`\n                \n                *   `{`\n                    \n                    *   `\"identifierType\": \"string\",`\n                        \n                    *   `\"columnName\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"tableName\": \"string\",`\n                \n            *   `\"valueColumnName\": \"string\",`\n                \n            *   `\"timestampColumnName\": \"string\",`\n                \n            *   `\"conditions\": [`\n                \n                *   `{`\n                    \n                    *   `\"column\": \"string\",`\n                        \n                    *   `\"operator\": \"string\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `},`\n            \n        *   `\"mixpanel\": {`\n            \n            *   `\"eventName\": \"string\",`\n                \n            *   `\"eventValue\": \"string\",`\n                \n            *   `\"userAggregation\": \"string\",`\n                \n            *   `\"conditions\": [`\n                \n                *   `{`\n                    \n                    *   `\"property\": \"string\",`\n                        \n                    *   `\"operator\": \"string\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/metrics/operation/postMetric)Create a single metric\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\ndatasourceId\n\nrequired\n\nstring\n\nID for the [DataSource](#tag/DataSource_model)\n\nmanagedBy\n\nstring\n\nEnum: \"\" \"api\"\n\nWhere this metric must be managed from. If not set (empty string), it can be managed from anywhere.\n\nowner\n\nstring\n\nName of the person who owns this metric\n\nname\n\nrequired\n\nstring\n\nName of the metric\n\ndescription\n\nstring\n\nDescription of the metric\n\ntype\n\nrequired\n\nstring\n\nEnum: \"binomial\" \"count\" \"duration\" \"revenue\"\n\nType of metric. See [Metrics documentation](https://docs.growthbook.io/app/metrics)\n\ntags\n\nArray of strings\n\nList of tags\n\nprojects\n\nArray of strings\n\nList of project IDs for projects that can access this metric\n\narchived\n\nboolean\n\nobject\n\nobject\n\nPreferred way to define SQL. Only one of `sql`, `sqlBuilder` or `mixpanel` allowed, and at least one must be specified.\n\nobject\n\nAn alternative way to specify a SQL metric, rather than a full query. Using `sql` is preferred to `sqlBuilder`. Only one of `sql`, `sqlBuilder` or `mixpanel` allowed, and at least one must be specified.\n\nobject\n\nOnly use for MixPanel (non-SQL) Data Sources. Only one of `sql`, `sqlBuilder` or `mixpanel` allowed, and at least one must be specified.\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"datasourceId\": \"string\",`\n    \n*   `\"managedBy\": \"\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"type\": \"binomial\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"archived\": true,`\n    \n*   `\"behavior\": {`\n    \n    *   `\"goal\": \"increase\",`\n        \n    *   `\"cappingSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"value\": 0,`\n            \n        *   `\"ignoreZeros\": true`\n            \n        \n        `},`\n        \n    *   `\"cap\": 0,`\n        \n    *   `\"capping\": \"absolute\",`\n        \n    *   `\"capValue\": 0,`\n        \n    *   `\"windowSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"delayHours\": 0,`\n            \n        *   `\"windowValue\": 0,`\n            \n        *   `\"windowUnit\": \"hours\"`\n            \n        \n        `},`\n        \n    *   `\"conversionWindowStart\": 0,`\n        \n    *   `\"conversionWindowEnd\": 0,`\n        \n    *   `\"priorSettings\": {`\n        \n        *   `\"override\": true,`\n            \n        *   `\"proper\": true,`\n            \n        *   `\"mean\": 0,`\n            \n        *   `\"stddev\": 0`\n            \n        \n        `},`\n        \n    *   `\"riskThresholdSuccess\": 0,`\n        \n    *   `\"riskThresholdDanger\": 0,`\n        \n    *   `\"minPercentChange\": 0,`\n        \n    *   `\"maxPercentChange\": 0,`\n        \n    *   `\"minSampleSize\": 0`\n        \n    \n    `},`\n    \n*   `\"sql\": {`\n    \n    *   `\"identifierTypes\": [`\n        \n        *   `\"string\"`\n            \n        \n        `],`\n        \n    *   `\"conversionSQL\": \"string\",`\n        \n    *   `\"userAggregationSQL\": \"string\",`\n        \n    *   `\"denominatorMetricId\": \"string\"`\n        \n    \n    `},`\n    \n*   `\"sqlBuilder\": {`\n    \n    *   `\"identifierTypeColumns\": [`\n        \n        *   `{`\n            \n            *   `\"identifierType\": \"string\",`\n                \n            *   `\"columnName\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"tableName\": \"string\",`\n        \n    *   `\"valueColumnName\": \"string\",`\n        \n    *   `\"timestampColumnName\": \"string\",`\n        \n    *   `\"conditions\": [`\n        \n        *   `{`\n            \n            *   `\"column\": \"string\",`\n                \n            *   `\"operator\": \"string\",`\n                \n            *   `\"value\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `},`\n    \n*   `\"mixpanel\": {`\n    \n    *   `\"eventName\": \"string\",`\n        \n    *   `\"eventValue\": \"string\",`\n        \n    *   `\"userAggregation\": \"string\",`\n        \n    *   `\"conditions\": [`\n        \n        *   `{`\n            \n            *   `\"property\": \"string\",`\n                \n            *   `\"operator\": \"string\",`\n                \n            *   `\"value\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `}`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"metric\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"string\",`\n        \n    *   `\"dateUpdated\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"datasourceId\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"type\": \"binomial\",`\n        \n    \n    *   `\"archived\": true,`\n        \n    *   `\"behavior\": {`\n        \n        *   `\"goal\": \"increase\",`\n            \n        *   `\"cappingSettings\": {`\n            \n            *   `\"type\": \"none\",`\n                \n            *   `\"value\": 0,`\n                \n            *   `\"ignoreZeros\": true`\n                \n            \n            `},`\n            \n        *   `\"cap\": 0,`\n            \n        *   `\"capping\": \"absolute\",`\n            \n        *   `\"capValue\": 0,`\n            \n        *   `\"windowSettings\": {`\n            \n            *   `\"type\": \"none\",`\n                \n            *   `\"delayHours\": 0,`\n                \n            *   `\"windowValue\": 0,`\n                \n            *   `\"windowUnit\": \"hours\"`\n                \n            \n            `},`\n            \n        *   `\"priorSettings\": {`\n            \n            *   `\"override\": true,`\n                \n            *   `\"proper\": true,`\n                \n            *   `\"mean\": 0,`\n                \n            *   `\"stddev\": 0`\n                \n            \n            `},`\n            \n        *   `\"conversionWindowStart\": 0,`\n            \n        *   `\"conversionWindowEnd\": 0,`\n            \n        *   `\"riskThresholdSuccess\": 0,`\n            \n        *   `\"riskThresholdDanger\": 0,`\n            \n        *   `\"minPercentChange\": 0,`\n            \n        *   `\"maxPercentChange\": 0,`\n            \n        *   `\"minSampleSize\": 0`\n            \n        \n        `},`\n        \n    *   `\"sql\": {`\n        \n        *   `\"identifierTypes\": [`\n            \n            *   `\"string\"`\n                \n            \n            `],`\n            \n        *   `\"conversionSQL\": \"string\",`\n            \n        *   `\"userAggregationSQL\": \"string\",`\n            \n        *   `\"denominatorMetricId\": \"string\"`\n            \n        \n        `},`\n        \n    *   `\"sqlBuilder\": {`\n        \n        *   `\"identifierTypeColumns\": [`\n            \n            *   `{`\n                \n                *   `\"identifierType\": \"string\",`\n                    \n                *   `\"columnName\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"tableName\": \"string\",`\n            \n        *   `\"valueColumnName\": \"string\",`\n            \n        *   `\"timestampColumnName\": \"string\",`\n            \n        *   `\"conditions\": [`\n            \n            *   `{`\n                \n                *   `\"column\": \"string\",`\n                    \n                *   `\"operator\": \"string\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `},`\n        \n    *   `\"mixpanel\": {`\n        \n        *   `\"eventName\": \"string\",`\n            \n        *   `\"eventValue\": \"string\",`\n            \n        *   `\"userAggregation\": \"string\",`\n            \n        *   `\"conditions\": [`\n            \n            *   `{`\n                \n                *   `\"property\": \"string\",`\n                    \n                *   `\"operator\": \"string\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/metrics/operation/getMetric)Get a single metric\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/metrics/met\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"metric\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"string\",`\n        \n    *   `\"dateUpdated\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"datasourceId\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"type\": \"binomial\",`\n        \n    \n    *   `\"archived\": true,`\n        \n    *   `\"behavior\": {`\n        \n        *   `\"goal\": \"increase\",`\n            \n        *   `\"cappingSettings\": {`\n            \n            *   `\"type\": \"none\",`\n                \n            *   `\"value\": 0,`\n                \n            *   `\"ignoreZeros\": true`\n                \n            \n            `},`\n            \n        *   `\"cap\": 0,`\n            \n        *   `\"capping\": \"absolute\",`\n            \n        *   `\"capValue\": 0,`\n            \n        *   `\"windowSettings\": {`\n            \n            *   `\"type\": \"none\",`\n                \n            *   `\"delayHours\": 0,`\n                \n            *   `\"windowValue\": 0,`\n                \n            *   `\"windowUnit\": \"hours\"`\n                \n            \n            `},`\n            \n        *   `\"priorSettings\": {`\n            \n            *   `\"override\": true,`\n                \n            *   `\"proper\": true,`\n                \n            *   `\"mean\": 0,`\n                \n            *   `\"stddev\": 0`\n                \n            \n            `},`\n            \n        *   `\"conversionWindowStart\": 0,`\n            \n        *   `\"conversionWindowEnd\": 0,`\n            \n        *   `\"riskThresholdSuccess\": 0,`\n            \n        *   `\"riskThresholdDanger\": 0,`\n            \n        *   `\"minPercentChange\": 0,`\n            \n        *   `\"maxPercentChange\": 0,`\n            \n        *   `\"minSampleSize\": 0`\n            \n        \n        `},`\n        \n    *   `\"sql\": {`\n        \n        *   `\"identifierTypes\": [`\n            \n            *   `\"string\"`\n                \n            \n            `],`\n            \n        *   `\"conversionSQL\": \"string\",`\n            \n        *   `\"userAggregationSQL\": \"string\",`\n            \n        *   `\"denominatorMetricId\": \"string\"`\n            \n        \n        `},`\n        \n    *   `\"sqlBuilder\": {`\n        \n        *   `\"identifierTypeColumns\": [`\n            \n            *   `{`\n                \n                *   `\"identifierType\": \"string\",`\n                    \n                *   `\"columnName\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"tableName\": \"string\",`\n            \n        *   `\"valueColumnName\": \"string\",`\n            \n        *   `\"timestampColumnName\": \"string\",`\n            \n        *   `\"conditions\": [`\n            \n            *   `{`\n                \n                *   `\"column\": \"string\",`\n                    \n                *   `\"operator\": \"string\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `},`\n        \n    *   `\"mixpanel\": {`\n        \n        *   `\"eventName\": \"string\",`\n            \n        *   `\"eventValue\": \"string\",`\n            \n        *   `\"userAggregation\": \"string\",`\n            \n        *   `\"conditions\": [`\n            \n            *   `{`\n                \n                *   `\"property\": \"string\",`\n                    \n                *   `\"operator\": \"string\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/metrics/operation/putMetric)Update a metric\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nmanagedBy\n\nstring\n\nEnum: \"\" \"api\"\n\nWhere this metric must be managed from. If not set (empty string), it can be managed from anywhere.\n\nowner\n\nstring\n\nName of the person who owns this metric\n\nname\n\nstring\n\nName of the metric\n\ndescription\n\nstring\n\nDescription of the metric\n\ntype\n\nstring\n\nEnum: \"binomial\" \"count\" \"duration\" \"revenue\"\n\nType of metric. See [Metrics documentation](https://docs.growthbook.io/app/metrics)\n\ntags\n\nArray of strings\n\nList of tags\n\nprojects\n\nArray of strings\n\nList of project IDs for projects that can access this metric\n\narchived\n\nboolean\n\nobject\n\nobject\n\nPreferred way to define SQL. Only one of `sql`, `sqlBuilder` or `mixpanel` allowed.\n\nobject\n\nAn alternative way to specify a SQL metric, rather than a full query. Using `sql` is preferred to `sqlBuilder`. Only one of `sql`, `sqlBuilder` or `mixpanel` allowed\n\nobject\n\nOnly use for MixPanel (non-SQL) Data Sources. Only one of `sql`, `sqlBuilder` or `mixpanel` allowed.\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"managedBy\": \"\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"type\": \"binomial\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"archived\": true,`\n    \n*   `\"behavior\": {`\n    \n    *   `\"goal\": \"increase\",`\n        \n    *   `\"cappingSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"value\": 0,`\n            \n        *   `\"ignoreZeros\": true`\n            \n        \n        `},`\n        \n    *   `\"cap\": 0,`\n        \n    *   `\"capping\": \"absolute\",`\n        \n    *   `\"capValue\": 0,`\n        \n    *   `\"windowSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"delayHours\": 0,`\n            \n        *   `\"windowValue\": 0,`\n            \n        *   `\"windowUnit\": \"hours\"`\n            \n        \n        `},`\n        \n    *   `\"conversionWindowStart\": 0,`\n        \n    *   `\"conversionWindowEnd\": 0,`\n        \n    *   `\"priorSettings\": {`\n        \n        *   `\"override\": true,`\n            \n        *   `\"proper\": true,`\n            \n        *   `\"mean\": 0,`\n            \n        *   `\"stddev\": 0`\n            \n        \n        `},`\n        \n    *   `\"riskThresholdSuccess\": 0,`\n        \n    *   `\"riskThresholdDanger\": 0,`\n        \n    *   `\"minPercentChange\": 0,`\n        \n    *   `\"maxPercentChange\": 0,`\n        \n    *   `\"minSampleSize\": 0`\n        \n    \n    `},`\n    \n*   `\"sql\": {`\n    \n    *   `\"identifierTypes\": [`\n        \n        *   `\"string\"`\n            \n        \n        `],`\n        \n    *   `\"conversionSQL\": \"string\",`\n        \n    *   `\"userAggregationSQL\": \"string\",`\n        \n    *   `\"denominatorMetricId\": \"string\"`\n        \n    \n    `},`\n    \n*   `\"sqlBuilder\": {`\n    \n    *   `\"identifierTypeColumns\": [`\n        \n        *   `{`\n            \n            *   `\"identifierType\": \"string\",`\n                \n            *   `\"columnName\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"tableName\": \"string\",`\n        \n    *   `\"valueColumnName\": \"string\",`\n        \n    *   `\"timestampColumnName\": \"string\",`\n        \n    *   `\"conditions\": [`\n        \n        *   `{`\n            \n            *   `\"column\": \"string\",`\n                \n            *   `\"operator\": \"string\",`\n                \n            *   `\"value\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `},`\n    \n*   `\"mixpanel\": {`\n    \n    *   `\"eventName\": \"string\",`\n        \n    *   `\"eventValue\": \"string\",`\n        \n    *   `\"userAggregation\": \"string\",`\n        \n    *   `\"conditions\": [`\n        \n        *   `{`\n            \n            *   `\"property\": \"string\",`\n                \n            *   `\"operator\": \"string\",`\n                \n            *   `\"value\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `}`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"updatedId\": \"string\"`\n    \n\n`}`\n\n## [](#tag/metrics/operation/deleteMetric)Deletes a metric\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-X DELETE https://api.growthbook.io/api/v1/metrics/met\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"deletedId\": \"string\"`\n    \n\n`}`\n\n## [](#tag/experiments)Experiments\n\n## [](#tag/experiments/operation/listExperiments)Get all experiments\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\nprojectId\n\ndatasourceId\n\nexperimentId\n\nstring\n\nFilter the returned list by the experiment tracking key (id)\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/experiments \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"experiments\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"project\": \"string\",`\n            \n        *   `\"hypothesis\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        \n        *   `\"owner\": \"string\",`\n            \n        *   `\"archived\": true,`\n            \n        *   `\"status\": \"string\",`\n            \n        *   `\"autoRefresh\": true,`\n            \n        *   `\"hashAttribute\": \"string\",`\n            \n        *   `\"fallbackAttribute\": \"string\",`\n            \n        *   `\"hashVersion\": 1,`\n            \n        *   `\"disableStickyBucketing\": null,`\n            \n        *   `\"bucketVersion\": 0,`\n            \n        *   `\"minBucketVersion\": 0,`\n            \n        *   `\"variations\": [`\n            \n            *   `{`\n                \n                *   `\"variationId\": \"string\",`\n                    \n                *   `\"key\": \"string\",`\n                    \n                *   `\"name\": \"string\",`\n                    \n                *   `\"description\": \"string\",`\n                    \n                *   `\"screenshots\": [`\n                    \n                    *   `\"string\"`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"phases\": [`\n            \n            *   `{`\n                \n                *   `\"name\": \"string\",`\n                    \n                *   `\"dateStarted\": \"string\",`\n                    \n                *   `\"dateEnded\": \"string\",`\n                    \n                *   `\"reasonForStopping\": \"string\",`\n                    \n                *   `\"seed\": \"string\",`\n                    \n                *   `\"coverage\": 0,`\n                    \n                *   `\"trafficSplit\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"variationId\": \"string\",`\n                            \n                        *   `\"weight\": 0`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"namespace\": {`\n                    \n                    *   `\"namespaceId\": \"string\",`\n                        \n                    *   `\"range\": [ ]`\n                        \n                    \n                    `},`\n                    \n                *   `\"targetingCondition\": \"string\",`\n                    \n                *   `\"savedGroupTargeting\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"matchType\": \"all\",`\n                            \n                        *   `\"savedGroups\": [`\n                            \n                            *   `\"string\"`\n                                \n                            \n                            `]`\n                            \n                        \n                        `}`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"settings\": {`\n            \n            *   `\"datasourceId\": \"string\",`\n                \n            *   `\"assignmentQueryId\": \"string\",`\n                \n            *   `\"experimentId\": \"string\",`\n                \n            *   `\"segmentId\": \"string\",`\n                \n            *   `\"queryFilter\": \"string\",`\n                \n            *   `\"inProgressConversions\": \"include\",`\n                \n            *   `\"attributionModel\": \"firstExposure\",`\n                \n            *   `\"statsEngine\": \"bayesian\",`\n                \n            *   `\"goals\": [`\n                \n                *   `{`\n                    \n                    *   `\"metricId\": \"string\",`\n                        \n                    *   `\"overrides\": {`\n                        \n                        *   `\"delayHours\": 0,`\n                            \n                        *   `\"windowHours\": 0,`\n                            \n                        *   `\"window\": \"conversion\",`\n                            \n                        *   `\"winRiskThreshold\": 0,`\n                            \n                        *   `\"loseRiskThreshold\": 0`\n                            \n                        \n                        `}`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"guardrails\": [`\n                \n                *   `{`\n                    \n                    *   `\"metricId\": \"string\",`\n                        \n                    *   `\"overrides\": {`\n                        \n                        *   `\"delayHours\": 0,`\n                            \n                        *   `\"windowHours\": 0,`\n                            \n                        *   `\"window\": \"conversion\",`\n                            \n                        *   `\"winRiskThreshold\": 0,`\n                            \n                        *   `\"loseRiskThreshold\": 0`\n                            \n                        \n                        `}`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"activationMetric\": {`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `},`\n            \n        *   `\"resultSummary\": {`\n            \n            *   `\"status\": \"string\",`\n                \n            *   `\"winner\": \"string\",`\n                \n            *   `\"conclusions\": \"string\",`\n                \n            *   `\"releasedVariationId\": \"string\",`\n                \n            *   `\"excludeFromPayload\": true`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/experiments/operation/postExperiment)Create a single experiment\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\ndatasourceId\n\nrequired\n\nstring\n\nID for the [DataSource](#tag/DataSource_model)\n\nassignmentQueryId\n\nrequired\n\nstring\n\nThe ID property of one of the assignment query objects associated with the datasource\n\ntrackingKey\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\nName of the experiment\n\nproject\n\nstring\n\nProject ID which the experiment belongs to\n\nhypothesis\n\nstring\n\nHypothesis of the experiment\n\ndescription\n\nstring\n\nDescription of the experiment\n\ntags\n\nArray of strings\n\nmetrics\n\nArray of strings\n\nguardrailMetrics\n\nArray of strings\n\nowner\n\nstring\n\nEmail of the person who owns this experiment\n\narchived\n\nboolean\n\nstatus\n\nstring\n\nEnum: \"draft\" \"running\" \"stopped\"\n\nautoRefresh\n\nboolean\n\nhashAttribute\n\nstring\n\nfallbackAttribute\n\nstring\n\nhashVersion\n\nnumber\n\nEnum: 1 2\n\ndisableStickyBucketing\n\nboolean;\n\nbucketVersion\n\nnumber\n\nminBucketVersion\n\nnumber\n\nreleasedVariationId\n\nstring\n\nexcludeFromPayload\n\nboolean\n\ninProgressConversions\n\nstring\n\nEnum: \"loose\" \"strict\"\n\nattributionModel\n\nstring\n\nEnum: \"firstExposure\" \"experimentDuration\"\n\nstatsEngine\n\nstring\n\nEnum: \"bayesian\" \"frequentist\"\n\nrequired\n\nArray of objects \\>= 2 items\n\nArray of objects\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"datasourceId\": \"string\",`\n    \n*   `\"assignmentQueryId\": \"string\",`\n    \n*   `\"trackingKey\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"project\": \"string\",`\n    \n*   `\"hypothesis\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"metrics\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"guardrailMetrics\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"archived\": true,`\n    \n*   `\"status\": \"draft\",`\n    \n*   `\"autoRefresh\": true,`\n    \n*   `\"hashAttribute\": \"string\",`\n    \n*   `\"fallbackAttribute\": \"string\",`\n    \n*   `\"hashVersion\": 1,`\n    \n*   `\"disableStickyBucketing\": null,`\n    \n*   `\"bucketVersion\": 0,`\n    \n*   `\"minBucketVersion\": 0,`\n    \n*   `\"releasedVariationId\": \"string\",`\n    \n*   `\"excludeFromPayload\": true,`\n    \n*   `\"inProgressConversions\": \"loose\",`\n    \n*   `\"attributionModel\": \"firstExposure\",`\n    \n*   `\"statsEngine\": \"bayesian\",`\n    \n*   `\"variations\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"key\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"screenshots\": [`\n            \n            *   `{`\n                \n                *   `\"path\": \"string\",`\n                    \n                *   `\"width\": 0,`\n                    \n                *   `\"height\": 0,`\n                    \n                *   `\"description\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `},`\n        \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"key\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"screenshots\": [`\n            \n            *   `{`\n                \n                *   `\"path\": \"string\",`\n                    \n                *   `\"width\": 0,`\n                    \n                *   `\"height\": 0,`\n                    \n                *   `\"description\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"phases\": [`\n    \n    *   `{`\n        \n        *   `\"name\": \"string\",`\n            \n        *   `\"dateStarted\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateEnded\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"reasonForStopping\": \"string\",`\n            \n        *   `\"seed\": \"string\",`\n            \n        *   `\"coverage\": 0,`\n            \n        *   `\"trafficSplit\": [`\n            \n            *   `{`\n                \n                *   `\"variationId\": \"string\",`\n                    \n                *   `\"weight\": 0`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"namespace\": {`\n            \n            *   `\"namespaceId\": \"string\",`\n                \n            \n            *   `\"enabled\": true`\n                \n            \n            `},`\n            \n        *   `\"targetingCondition\": \"string\",`\n            \n        *   `\"reason\": \"string\",`\n            \n        *   `\"condition\": \"string\",`\n            \n        *   `\"savedGroupTargeting\": [`\n            \n            *   `{`\n                \n                *   `\"matchType\": \"all\",`\n                    \n                *   `\"savedGroups\": [`\n                    \n                    *   `\"string\"`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"experiment\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    *   `\"hypothesis\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    \n    *   `\"owner\": \"string\",`\n        \n    *   `\"archived\": true,`\n        \n    *   `\"status\": \"string\",`\n        \n    *   `\"autoRefresh\": true,`\n        \n    *   `\"hashAttribute\": \"string\",`\n        \n    *   `\"fallbackAttribute\": \"string\",`\n        \n    *   `\"hashVersion\": 1,`\n        \n    *   `\"disableStickyBucketing\": null,`\n        \n    *   `\"bucketVersion\": 0,`\n        \n    *   `\"minBucketVersion\": 0,`\n        \n    *   `\"variations\": [`\n        \n        *   `{`\n            \n            *   `\"variationId\": \"string\",`\n                \n            *   `\"key\": \"string\",`\n                \n            *   `\"name\": \"string\",`\n                \n            *   `\"description\": \"string\",`\n                \n            *   `\"screenshots\": [`\n                \n                *   `\"string\"`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"phases\": [`\n        \n        *   `{`\n            \n            *   `\"name\": \"string\",`\n                \n            *   `\"dateStarted\": \"string\",`\n                \n            *   `\"dateEnded\": \"string\",`\n                \n            *   `\"reasonForStopping\": \"string\",`\n                \n            *   `\"seed\": \"string\",`\n                \n            *   `\"coverage\": 0,`\n                \n            *   `\"trafficSplit\": [`\n                \n                *   `{`\n                    \n                    *   `\"variationId\": \"string\",`\n                        \n                    *   `\"weight\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"namespace\": {`\n                \n                *   `\"namespaceId\": \"string\",`\n                    \n                *   `\"range\": [ ]`\n                    \n                \n                `},`\n                \n            *   `\"targetingCondition\": \"string\",`\n                \n            *   `\"savedGroupTargeting\": [`\n                \n                *   `{`\n                    \n                    *   `\"matchType\": \"all\",`\n                        \n                    *   `\"savedGroups\": [`\n                        \n                        *   `\"string\"`\n                            \n                        \n                        `]`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"settings\": {`\n        \n        *   `\"datasourceId\": \"string\",`\n            \n        *   `\"assignmentQueryId\": \"string\",`\n            \n        *   `\"experimentId\": \"string\",`\n            \n        *   `\"segmentId\": \"string\",`\n            \n        *   `\"queryFilter\": \"string\",`\n            \n        *   `\"inProgressConversions\": \"include\",`\n            \n        *   `\"attributionModel\": \"firstExposure\",`\n            \n        *   `\"statsEngine\": \"bayesian\",`\n            \n        *   `\"goals\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"guardrails\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"activationMetric\": {`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"resultSummary\": {`\n        \n        *   `\"status\": \"string\",`\n            \n        *   `\"winner\": \"string\",`\n            \n        *   `\"conclusions\": \"string\",`\n            \n        *   `\"releasedVariationId\": \"string\",`\n            \n        *   `\"excludeFromPayload\": true`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/experiments/operation/getExperiment)Get a single experiment\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/experiments/exp\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"experiment\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    *   `\"hypothesis\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    \n    *   `\"owner\": \"string\",`\n        \n    *   `\"archived\": true,`\n        \n    *   `\"status\": \"string\",`\n        \n    *   `\"autoRefresh\": true,`\n        \n    *   `\"hashAttribute\": \"string\",`\n        \n    *   `\"fallbackAttribute\": \"string\",`\n        \n    *   `\"hashVersion\": 1,`\n        \n    *   `\"disableStickyBucketing\": null,`\n        \n    *   `\"bucketVersion\": 0,`\n        \n    *   `\"minBucketVersion\": 0,`\n        \n    *   `\"variations\": [`\n        \n        *   `{`\n            \n            *   `\"variationId\": \"string\",`\n                \n            *   `\"key\": \"string\",`\n                \n            *   `\"name\": \"string\",`\n                \n            *   `\"description\": \"string\",`\n                \n            *   `\"screenshots\": [`\n                \n                *   `\"string\"`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"phases\": [`\n        \n        *   `{`\n            \n            *   `\"name\": \"string\",`\n                \n            *   `\"dateStarted\": \"string\",`\n                \n            *   `\"dateEnded\": \"string\",`\n                \n            *   `\"reasonForStopping\": \"string\",`\n                \n            *   `\"seed\": \"string\",`\n                \n            *   `\"coverage\": 0,`\n                \n            *   `\"trafficSplit\": [`\n                \n                *   `{`\n                    \n                    *   `\"variationId\": \"string\",`\n                        \n                    *   `\"weight\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"namespace\": {`\n                \n                *   `\"namespaceId\": \"string\",`\n                    \n                *   `\"range\": [ ]`\n                    \n                \n                `},`\n                \n            *   `\"targetingCondition\": \"string\",`\n                \n            *   `\"savedGroupTargeting\": [`\n                \n                *   `{`\n                    \n                    *   `\"matchType\": \"all\",`\n                        \n                    *   `\"savedGroups\": [`\n                        \n                        *   `\"string\"`\n                            \n                        \n                        `]`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"settings\": {`\n        \n        *   `\"datasourceId\": \"string\",`\n            \n        *   `\"assignmentQueryId\": \"string\",`\n            \n        *   `\"experimentId\": \"string\",`\n            \n        *   `\"segmentId\": \"string\",`\n            \n        *   `\"queryFilter\": \"string\",`\n            \n        *   `\"inProgressConversions\": \"include\",`\n            \n        *   `\"attributionModel\": \"firstExposure\",`\n            \n        *   `\"statsEngine\": \"bayesian\",`\n            \n        *   `\"goals\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"guardrails\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"activationMetric\": {`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"resultSummary\": {`\n        \n        *   `\"status\": \"string\",`\n            \n        *   `\"winner\": \"string\",`\n            \n        *   `\"conclusions\": \"string\",`\n            \n        *   `\"releasedVariationId\": \"string\",`\n            \n        *   `\"excludeFromPayload\": true`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/experiments/operation/updateExperiment)Update a single experiment\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nassignmentQueryId\n\nstring\n\ntrackingKey\n\nstring\n\nname\n\nstring\n\nName of the experiment\n\nproject\n\nstring\n\nProject ID which the experiment belongs to\n\nhypothesis\n\nstring\n\nHypothesis of the experiment\n\ndescription\n\nstring\n\nDescription of the experiment\n\ntags\n\nArray of strings\n\nmetrics\n\nArray of strings\n\nguardrailMetrics\n\nArray of strings\n\nowner\n\nstring\n\nEmail of the person who owns this experiment\n\narchived\n\nboolean\n\nstatus\n\nstring\n\nEnum: \"draft\" \"running\" \"stopped\"\n\nautoRefresh\n\nboolean\n\nhashAttribute\n\nstring\n\nfallbackAttribute\n\nstring\n\nhashVersion\n\nnumber\n\nEnum: 1 2\n\ndisableStickyBucketing\n\nboolean;\n\nbucketVersion\n\nnumber\n\nminBucketVersion\n\nnumber\n\nreleasedVariationId\n\nstring\n\nexcludeFromPayload\n\nboolean\n\ninProgressConversions\n\nstring\n\nEnum: \"loose\" \"strict\"\n\nattributionModel\n\nstring\n\nEnum: \"firstExposure\" \"experimentDuration\"\n\nstatsEngine\n\nstring\n\nEnum: \"bayesian\" \"frequentist\"\n\nArray of objects \\>= 2 items\n\nArray of objects\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"assignmentQueryId\": \"string\",`\n    \n*   `\"trackingKey\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"project\": \"string\",`\n    \n*   `\"hypothesis\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"metrics\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"guardrailMetrics\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"archived\": true,`\n    \n*   `\"status\": \"draft\",`\n    \n*   `\"autoRefresh\": true,`\n    \n*   `\"hashAttribute\": \"string\",`\n    \n*   `\"fallbackAttribute\": \"string\",`\n    \n*   `\"hashVersion\": 1,`\n    \n*   `\"disableStickyBucketing\": null,`\n    \n*   `\"bucketVersion\": 0,`\n    \n*   `\"minBucketVersion\": 0,`\n    \n*   `\"releasedVariationId\": \"string\",`\n    \n*   `\"excludeFromPayload\": true,`\n    \n*   `\"inProgressConversions\": \"loose\",`\n    \n*   `\"attributionModel\": \"firstExposure\",`\n    \n*   `\"statsEngine\": \"bayesian\",`\n    \n*   `\"variations\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"key\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"screenshots\": [`\n            \n            *   `{`\n                \n                *   `\"path\": \"string\",`\n                    \n                *   `\"width\": 0,`\n                    \n                *   `\"height\": 0,`\n                    \n                *   `\"description\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `},`\n        \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"key\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"screenshots\": [`\n            \n            *   `{`\n                \n                *   `\"path\": \"string\",`\n                    \n                *   `\"width\": 0,`\n                    \n                *   `\"height\": 0,`\n                    \n                *   `\"description\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"phases\": [`\n    \n    *   `{`\n        \n        *   `\"name\": \"string\",`\n            \n        *   `\"dateStarted\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateEnded\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"reasonForStopping\": \"string\",`\n            \n        *   `\"seed\": \"string\",`\n            \n        *   `\"coverage\": 0,`\n            \n        *   `\"trafficSplit\": [`\n            \n            *   `{`\n                \n                *   `\"variationId\": \"string\",`\n                    \n                *   `\"weight\": 0`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"namespace\": {`\n            \n            *   `\"namespaceId\": \"string\",`\n                \n            \n            *   `\"enabled\": true`\n                \n            \n            `},`\n            \n        *   `\"targetingCondition\": \"string\",`\n            \n        *   `\"reason\": \"string\",`\n            \n        *   `\"condition\": \"string\",`\n            \n        *   `\"savedGroupTargeting\": [`\n            \n            *   `{`\n                \n                *   `\"matchType\": \"all\",`\n                    \n                *   `\"savedGroups\": [`\n                    \n                    *   `\"string\"`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"experiment\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    *   `\"hypothesis\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    \n    *   `\"owner\": \"string\",`\n        \n    *   `\"archived\": true,`\n        \n    *   `\"status\": \"string\",`\n        \n    *   `\"autoRefresh\": true,`\n        \n    *   `\"hashAttribute\": \"string\",`\n        \n    *   `\"fallbackAttribute\": \"string\",`\n        \n    *   `\"hashVersion\": 1,`\n        \n    *   `\"disableStickyBucketing\": null,`\n        \n    *   `\"bucketVersion\": 0,`\n        \n    *   `\"minBucketVersion\": 0,`\n        \n    *   `\"variations\": [`\n        \n        *   `{`\n            \n            *   `\"variationId\": \"string\",`\n                \n            *   `\"key\": \"string\",`\n                \n            *   `\"name\": \"string\",`\n                \n            *   `\"description\": \"string\",`\n                \n            *   `\"screenshots\": [`\n                \n                *   `\"string\"`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"phases\": [`\n        \n        *   `{`\n            \n            *   `\"name\": \"string\",`\n                \n            *   `\"dateStarted\": \"string\",`\n                \n            *   `\"dateEnded\": \"string\",`\n                \n            *   `\"reasonForStopping\": \"string\",`\n                \n            *   `\"seed\": \"string\",`\n                \n            *   `\"coverage\": 0,`\n                \n            *   `\"trafficSplit\": [`\n                \n                *   `{`\n                    \n                    *   `\"variationId\": \"string\",`\n                        \n                    *   `\"weight\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"namespace\": {`\n                \n                *   `\"namespaceId\": \"string\",`\n                    \n                *   `\"range\": [ ]`\n                    \n                \n                `},`\n                \n            *   `\"targetingCondition\": \"string\",`\n                \n            *   `\"savedGroupTargeting\": [`\n                \n                *   `{`\n                    \n                    *   `\"matchType\": \"all\",`\n                        \n                    *   `\"savedGroups\": [`\n                        \n                        *   `\"string\"`\n                            \n                        \n                        `]`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"settings\": {`\n        \n        *   `\"datasourceId\": \"string\",`\n            \n        *   `\"assignmentQueryId\": \"string\",`\n            \n        *   `\"experimentId\": \"string\",`\n            \n        *   `\"segmentId\": \"string\",`\n            \n        *   `\"queryFilter\": \"string\",`\n            \n        *   `\"inProgressConversions\": \"include\",`\n            \n        *   `\"attributionModel\": \"firstExposure\",`\n            \n        *   `\"statsEngine\": \"bayesian\",`\n            \n        *   `\"goals\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"guardrails\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"activationMetric\": {`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"resultSummary\": {`\n        \n        *   `\"status\": \"string\",`\n            \n        *   `\"winner\": \"string\",`\n            \n        *   `\"conclusions\": \"string\",`\n            \n        *   `\"releasedVariationId\": \"string\",`\n            \n        *   `\"excludeFromPayload\": true`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/experiments/operation/getExperimentResults)Get results for an experiment\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### query Parameters\n\nphase\n\ndimension\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/experiments/exp\\_123abc/results \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"result\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateUpdated\": \"string\",`\n        \n    *   `\"experimentId\": \"string\",`\n        \n    *   `\"phase\": \"string\",`\n        \n    *   `\"dateStart\": \"string\",`\n        \n    *   `\"dateEnd\": \"string\",`\n        \n    *   `\"dimension\": {`\n        \n        *   `\"type\": \"string\",`\n            \n        *   `\"id\": \"string\"`\n            \n        \n        `},`\n        \n    *   `\"settings\": {`\n        \n        *   `\"datasourceId\": \"string\",`\n            \n        *   `\"assignmentQueryId\": \"string\",`\n            \n        *   `\"experimentId\": \"string\",`\n            \n        *   `\"segmentId\": \"string\",`\n            \n        *   `\"queryFilter\": \"string\",`\n            \n        *   `\"inProgressConversions\": \"include\",`\n            \n        *   `\"attributionModel\": \"firstExposure\",`\n            \n        *   `\"statsEngine\": \"bayesian\",`\n            \n        *   `\"goals\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"guardrails\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"activationMetric\": {`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    \n    *   `\"results\": [`\n        \n        *   `{`\n            \n            *   `\"dimension\": \"string\",`\n                \n            *   `\"totalUsers\": 0,`\n                \n            \n            *   `\"metrics\": [`\n                \n                *   `{`\n                    \n                    *   `\"metricId\": \"string\",`\n                        \n                    *   `\"variations\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"variationId\": \"string\",`\n                                \n                            *   `\"users\": 0,`\n                                \n                            *   `\"analyses\": [`\n                                \n                                *   `{`\n                                    \n                                    *   `\"engine\": null,`\n                                        \n                                    *   `\"numerator\": null,`\n                                        \n                                    *   `\"denominator\": null,`\n                                        \n                                    *   `\"mean\": null,`\n                                        \n                                    *   `\"stddev\": null,`\n                                        \n                                    *   `\"percentChange\": null,`\n                                        \n                                    *   `\"ciLow\": null,`\n                                        \n                                    *   `\"ciHigh\": null,`\n                                        \n                                    *   `\"pValue\": null,`\n                                        \n                                    *   `\"risk\": null,`\n                                        \n                                    *   `\"chanceToBeatControl\": null`\n                                        \n                                    \n                                    `}`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `]`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/dimensions)Dimensions\n\nDimensions used during experiment analysis\n\n## [](#tag/dimensions/operation/listDimensions)Get all dimensions\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\ndatasourceId\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/dimensions \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"dimensions\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"dateCreated\": \"string\",`\n            \n        *   `\"dateUpdated\": \"string\",`\n            \n        *   `\"owner\": \"string\",`\n            \n        *   `\"datasourceId\": \"string\",`\n            \n        *   `\"identifierType\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"query\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/dimensions/operation/getDimension)Get a single dimension\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/dimensions/dim\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"dimension\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"string\",`\n        \n    *   `\"dateUpdated\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"datasourceId\": \"string\",`\n        \n    *   `\"identifierType\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"query\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/segments)Segments\n\nSegments used during experiment analysis\n\n## [](#tag/segments/operation/listSegments)Get all segments\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\ndatasourceId\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/segments \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"segments\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"owner\": \"string\",`\n            \n        *   `\"datasourceId\": \"string\",`\n            \n        *   `\"identifierType\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"query\": \"string\",`\n            \n        *   `\"dateCreated\": \"string\",`\n            \n        *   `\"dateUpdated\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/segments/operation/getSegment)Get a single segment\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/segments/seg\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"segment\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"datasourceId\": \"string\",`\n        \n    *   `\"identifierType\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"query\": \"string\",`\n        \n    *   `\"dateCreated\": \"string\",`\n        \n    *   `\"dateUpdated\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/sdk-connections)SDK Connections\n\nClient keys and settings for connecting SDKs to a GrowthBook instance\n\n## [](#tag/sdk-connections/operation/listSdkConnections)Get all sdk connections\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\nprojectId\n\nwithProxy\n\nmultiOrg\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/sdk\\-connections \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"connections\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"organization\": \"string\",`\n            \n        \n        *   `\"sdkVersion\": \"string\",`\n            \n        *   `\"environment\": \"string\",`\n            \n        *   `\"project\": \"string\",`\n            \n        \n        *   `\"encryptPayload\": true,`\n            \n        *   `\"encryptionKey\": \"string\",`\n            \n        *   `\"includeVisualExperiments\": true,`\n            \n        *   `\"includeDraftExperiments\": true,`\n            \n        *   `\"includeExperimentNames\": true,`\n            \n        *   `\"includeRedirectExperiments\": true,`\n            \n        *   `\"key\": \"string\",`\n            \n        *   `\"proxyEnabled\": true,`\n            \n        *   `\"proxyHost\": \"string\",`\n            \n        *   `\"proxySigningKey\": \"string\",`\n            \n        *   `\"sseEnabled\": true,`\n            \n        *   `\"hashSecureAttributes\": true,`\n            \n        *   `\"remoteEvalEnabled\": true`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/sdk-connections/operation/postSdkConnection)Create a single sdk connection\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nname\n\nrequired\n\nstring\n\nlanguage\n\nrequired\n\nstring\n\nsdkVersion\n\nstring\n\nenvironment\n\nrequired\n\nstring\n\nprojects\n\nArray of strings\n\nencryptPayload\n\nboolean\n\nincludeVisualExperiments\n\nboolean\n\nincludeDraftExperiments\n\nboolean\n\nincludeExperimentNames\n\nboolean\n\nincludeRedirectExperiments\n\nboolean\n\nproxyEnabled\n\nboolean\n\nproxyHost\n\nstring\n\nhashSecureAttributes\n\nboolean\n\nremoteEvalEnabled\n\nboolean\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"language\": \"string\",`\n    \n*   `\"sdkVersion\": \"string\",`\n    \n*   `\"environment\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"encryptPayload\": true,`\n    \n*   `\"includeVisualExperiments\": true,`\n    \n*   `\"includeDraftExperiments\": true,`\n    \n*   `\"includeExperimentNames\": true,`\n    \n*   `\"includeRedirectExperiments\": true,`\n    \n*   `\"proxyEnabled\": true,`\n    \n*   `\"proxyHost\": \"string\",`\n    \n*   `\"hashSecureAttributes\": true,`\n    \n*   `\"remoteEvalEnabled\": true`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"sdkConnection\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"organization\": \"string\",`\n        \n    \n    *   `\"sdkVersion\": \"string\",`\n        \n    *   `\"environment\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    \n    *   `\"encryptPayload\": true,`\n        \n    *   `\"encryptionKey\": \"string\",`\n        \n    *   `\"includeVisualExperiments\": true,`\n        \n    *   `\"includeDraftExperiments\": true,`\n        \n    *   `\"includeExperimentNames\": true,`\n        \n    *   `\"includeRedirectExperiments\": true,`\n        \n    *   `\"key\": \"string\",`\n        \n    *   `\"proxyEnabled\": true,`\n        \n    *   `\"proxyHost\": \"string\",`\n        \n    *   `\"proxySigningKey\": \"string\",`\n        \n    *   `\"sseEnabled\": true,`\n        \n    *   `\"hashSecureAttributes\": true,`\n        \n    *   `\"remoteEvalEnabled\": true`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/sdk-connections/operation/getSdkConnection)Get a single sdk connection\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/sdk\\-connections/sdk\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"sdkConnection\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"organization\": \"string\",`\n        \n    \n    *   `\"sdkVersion\": \"string\",`\n        \n    *   `\"environment\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    \n    *   `\"encryptPayload\": true,`\n        \n    *   `\"encryptionKey\": \"string\",`\n        \n    *   `\"includeVisualExperiments\": true,`\n        \n    *   `\"includeDraftExperiments\": true,`\n        \n    *   `\"includeExperimentNames\": true,`\n        \n    *   `\"includeRedirectExperiments\": true,`\n        \n    *   `\"key\": \"string\",`\n        \n    *   `\"proxyEnabled\": true,`\n        \n    *   `\"proxyHost\": \"string\",`\n        \n    *   `\"proxySigningKey\": \"string\",`\n        \n    *   `\"sseEnabled\": true,`\n        \n    *   `\"hashSecureAttributes\": true,`\n        \n    *   `\"remoteEvalEnabled\": true`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/sdk-connections/operation/putSdkConnection)Update a single sdk connection\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nname\n\nstring\n\nlanguage\n\nstring\n\nsdkVersion\n\nstring\n\nenvironment\n\nstring\n\nprojects\n\nArray of strings\n\nencryptPayload\n\nboolean\n\nincludeVisualExperiments\n\nboolean\n\nincludeDraftExperiments\n\nboolean\n\nincludeExperimentNames\n\nboolean\n\nincludeRedirectExperiments\n\nboolean\n\nproxyEnabled\n\nboolean\n\nproxyHost\n\nstring\n\nhashSecureAttributes\n\nboolean\n\nremoteEvalEnabled\n\nboolean\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"language\": \"string\",`\n    \n*   `\"sdkVersion\": \"string\",`\n    \n*   `\"environment\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"encryptPayload\": true,`\n    \n*   `\"includeVisualExperiments\": true,`\n    \n*   `\"includeDraftExperiments\": true,`\n    \n*   `\"includeExperimentNames\": true,`\n    \n*   `\"includeRedirectExperiments\": true,`\n    \n*   `\"proxyEnabled\": true,`\n    \n*   `\"proxyHost\": \"string\",`\n    \n*   `\"hashSecureAttributes\": true,`\n    \n*   `\"remoteEvalEnabled\": true`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"sdkConnection\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"organization\": \"string\",`\n        \n    \n    *   `\"sdkVersion\": \"string\",`\n        \n    *   `\"environment\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    \n    *   `\"encryptPayload\": true,`\n        \n    *   `\"encryptionKey\": \"string\",`\n        \n    *   `\"includeVisualExperiments\": true,`\n        \n    *   `\"includeDraftExperiments\": true,`\n        \n    *   `\"includeExperimentNames\": true,`\n        \n    *   `\"includeRedirectExperiments\": true,`\n        \n    *   `\"key\": \"string\",`\n        \n    *   `\"proxyEnabled\": true,`\n        \n    *   `\"proxyHost\": \"string\",`\n        \n    *   `\"proxySigningKey\": \"string\",`\n        \n    *   `\"sseEnabled\": true,`\n        \n    *   `\"hashSecureAttributes\": true,`\n        \n    *   `\"remoteEvalEnabled\": true`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/visual-changesets)Visual Changesets\n\nGroups of visual changes made by the visual editor to a single page\n\n## [](#tag/visual-changesets/operation/listVisualChangesets)Get all visual changesets\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe experiment id the visual changesets belong to\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/experiments/exp\\_123abc/visual\\-changesets \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"visualChangesets\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"urlPatterns\": [`\n            \n            *   `{`\n                \n                *   `\"include\": true,`\n                    \n                *   `\"type\": \"simple\",`\n                    \n                *   `\"pattern\": null`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"editorUrl\": \"string\",`\n            \n        *   `\"experiment\": \"string\",`\n            \n        *   `\"visualChanges\": [`\n            \n            *   `{`\n                \n                *   `\"description\": \"string\",`\n                    \n                *   `\"css\": \"string\",`\n                    \n                *   `\"js\": \"string\",`\n                    \n                *   `\"variation\": \"string\",`\n                    \n                *   `\"domMutations\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"selector\": \"string\",`\n                            \n                        *   `\"action\": \"append\",`\n                            \n                        *   `\"attribute\": \"string\",`\n                            \n                        *   `\"value\": \"string\",`\n                            \n                        *   `\"parentSelector\": \"string\",`\n                            \n                        *   `\"insertBeforeSelector\": \"string\"`\n                            \n                        \n                        `}`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/visual-changesets/operation/getVisualChangeset)Get a single visual changeset\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### query Parameters\n\nincludeExperiment\n\ninteger\n\nInclude the associated experiment in payload\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/visual\\-changesets/ds\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"visualChangeset\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"urlPatterns\": [`\n        \n        *   `{`\n            \n            *   `\"include\": true,`\n                \n            *   `\"type\": \"simple\",`\n                \n            *   `\"pattern\": null`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"editorUrl\": \"string\",`\n        \n    *   `\"experiment\": \"string\",`\n        \n    *   `\"visualChanges\": [`\n        \n        *   `{`\n            \n            *   `\"description\": \"string\",`\n                \n            *   `\"css\": \"string\",`\n                \n            *   `\"js\": \"string\",`\n                \n            *   `\"variation\": \"string\",`\n                \n            *   `\"domMutations\": [`\n                \n                *   `{`\n                    \n                    *   `\"selector\": \"string\",`\n                        \n                    *   `\"action\": \"append\",`\n                        \n                    *   `\"attribute\": \"string\",`\n                        \n                    *   `\"value\": \"string\",`\n                        \n                    *   `\"parentSelector\": \"string\",`\n                        \n                    *   `\"insertBeforeSelector\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `},`\n    \n*   `\"experiment\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"project\": \"string\",`\n        \n    *   `\"hypothesis\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    \n    *   `\"owner\": \"string\",`\n        \n    *   `\"archived\": true,`\n        \n    *   `\"status\": \"string\",`\n        \n    *   `\"autoRefresh\": true,`\n        \n    *   `\"hashAttribute\": \"string\",`\n        \n    *   `\"fallbackAttribute\": \"string\",`\n        \n    *   `\"hashVersion\": 1,`\n        \n    *   `\"disableStickyBucketing\": null,`\n        \n    *   `\"bucketVersion\": 0,`\n        \n    *   `\"minBucketVersion\": 0,`\n        \n    *   `\"variations\": [`\n        \n        *   `{`\n            \n            *   `\"variationId\": \"string\",`\n                \n            *   `\"key\": \"string\",`\n                \n            *   `\"name\": \"string\",`\n                \n            *   `\"description\": \"string\",`\n                \n            *   `\"screenshots\": [`\n                \n                *   `\"string\"`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"phases\": [`\n        \n        *   `{`\n            \n            *   `\"name\": \"string\",`\n                \n            *   `\"dateStarted\": \"string\",`\n                \n            *   `\"dateEnded\": \"string\",`\n                \n            *   `\"reasonForStopping\": \"string\",`\n                \n            *   `\"seed\": \"string\",`\n                \n            *   `\"coverage\": 0,`\n                \n            *   `\"trafficSplit\": [`\n                \n                *   `{`\n                    \n                    *   `\"variationId\": \"string\",`\n                        \n                    *   `\"weight\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"namespace\": {`\n                \n                *   `\"namespaceId\": \"string\",`\n                    \n                *   `\"range\": [ ]`\n                    \n                \n                `},`\n                \n            *   `\"targetingCondition\": \"string\",`\n                \n            *   `\"savedGroupTargeting\": [`\n                \n                *   `{`\n                    \n                    *   `\"matchType\": \"all\",`\n                        \n                    *   `\"savedGroups\": [`\n                        \n                        *   `\"string\"`\n                            \n                        \n                        `]`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"settings\": {`\n        \n        *   `\"datasourceId\": \"string\",`\n            \n        *   `\"assignmentQueryId\": \"string\",`\n            \n        *   `\"experimentId\": \"string\",`\n            \n        *   `\"segmentId\": \"string\",`\n            \n        *   `\"queryFilter\": \"string\",`\n            \n        *   `\"inProgressConversions\": \"include\",`\n            \n        *   `\"attributionModel\": \"firstExposure\",`\n            \n        *   `\"statsEngine\": \"bayesian\",`\n            \n        *   `\"goals\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"guardrails\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"overrides\": {`\n                    \n                    *   `\"delayHours\": 0,`\n                        \n                    *   `\"windowHours\": 0,`\n                        \n                    *   `\"window\": \"conversion\",`\n                        \n                    *   `\"winRiskThreshold\": 0,`\n                        \n                    *   `\"loseRiskThreshold\": 0`\n                        \n                    \n                    `}`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"activationMetric\": {`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"resultSummary\": {`\n        \n        *   `\"status\": \"string\",`\n            \n        *   `\"winner\": \"string\",`\n            \n        *   `\"conclusions\": \"string\",`\n            \n        *   `\"releasedVariationId\": \"string\",`\n            \n        *   `\"excludeFromPayload\": true`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/visual-changesets/operation/putVisualChangeset)Update a visual changeset\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-XPUT https://api.growthbook.io/api/v1/visual\\-changesets/vc\\_123abc\n  \\-d '{\"editorUrl\": \"https://docs.growthbook.io\", \"urlPatterns\":\"\\[{ ... }\\]\"}' \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"nModified\": 0,`\n    \n*   `\"visualChangeset\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"urlPatterns\": [`\n        \n        *   `{`\n            \n            *   `\"include\": true,`\n                \n            *   `\"type\": \"simple\",`\n                \n            *   `\"pattern\": null`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"editorUrl\": \"string\",`\n        \n    *   `\"experiment\": \"string\",`\n        \n    *   `\"visualChanges\": [`\n        \n        *   `{`\n            \n            *   `\"description\": \"string\",`\n                \n            *   `\"css\": \"string\",`\n                \n            *   `\"js\": \"string\",`\n                \n            *   `\"variation\": \"string\",`\n                \n            *   `\"domMutations\": [`\n                \n                *   `{`\n                    \n                    *   `\"selector\": \"string\",`\n                        \n                    *   `\"action\": \"append\",`\n                        \n                    *   `\"attribute\": \"string\",`\n                        \n                    *   `\"value\": \"string\",`\n                        \n                    *   `\"parentSelector\": \"string\",`\n                        \n                    *   `\"insertBeforeSelector\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `]`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/visual-changesets/operation/postVisualChange)Create a visual change for a visual changeset\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-XPOST https://api.growthbook.io/api/v1/visual\\-changesets/vc\\_123abc/visual\\-change \\\\\n  \\-d '{\"variation\": \"v\\_123abc\", \"domMutations\":\"\\[\\]\"}' \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n## [](#tag/visual-changesets/operation/putVisualChange)Update a visual change for a visual changeset\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\nvisualChangeId\n\nrequired\n\nstring\n\nSpecify a specific visual change\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-XPUT https://api.growthbook.io/api/v1/visual\\-changesets/vc\\_123abc/visual\\-change/vch\\_abc123 \\\\\n  \\-d '{\"variation\": \"v\\_123abc\", \"domMutations\":\"\\[\\]\"}' \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n## [](#tag/saved-groups)Saved Groups\n\nDefined sets of attribute values which can be used with feature rules for targeting features at particular users.\n\n## [](#tag/saved-groups/operation/listSavedGroups)Get all saved group\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/saved\\-groups \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"savedGroups\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"type\": \"condition\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"owner\": \"string\",`\n            \n        *   `\"condition\": \"string\",`\n            \n        *   `\"attributeKey\": \"string\",`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/saved-groups/operation/postSavedGroup)Create a single saved group\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nname\n\nrequired\n\nstring\n\nThe display name of the Saved Group\n\ntype\n\nstring\n\nEnum: \"condition\" \"list\"\n\nThe type of Saved Group (inferred from other arguments if missing)\n\ncondition\n\nstring\n\nWhen type = 'condition', this is the JSON-encoded condition for the group\n\nattributeKey\n\nstring\n\nWhen type = 'list', this is the attribute key the group is based on\n\nvalues\n\nArray of strings\n\nWhen type = 'list', this is the list of values for the attribute key\n\nowner\n\nstring\n\nThe person or team that owns this Saved Group. If no owner, you can pass an empty string.\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"type\": \"condition\",`\n    \n*   `\"condition\": \"string\",`\n    \n*   `\"attributeKey\": \"string\",`\n    \n*   `\"values\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"owner\": \"string\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"savedGroup\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"type\": \"condition\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"condition\": \"string\",`\n        \n    *   `\"attributeKey\": \"string\",`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/saved-groups/operation/getSavedGroup)Get a single saved group\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/saved\\-groups/ds\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"savedGroup\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"type\": \"condition\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"condition\": \"string\",`\n        \n    *   `\"attributeKey\": \"string\",`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/saved-groups/operation/updateSavedGroup)Partially update a single saved group\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nname\n\nstring\n\nThe display name of the Saved Group\n\ncondition\n\nstring\n\nWhen type = 'condition', this is the JSON-encoded condition for the group\n\nvalues\n\nArray of strings\n\nWhen type = 'list', this is the list of values for the attribute key\n\nowner\n\nstring\n\nThe person or team that owns this Saved Group. If no owner, you can pass an empty string.\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"condition\": \"string\",`\n    \n*   `\"values\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"owner\": \"string\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"savedGroup\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"type\": \"condition\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    *   `\"condition\": \"string\",`\n        \n    *   `\"attributeKey\": \"string\",`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/saved-groups/operation/deleteSavedGroup)Deletes a single saved group\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-X DELETE https://api.growthbook.io/api/v1/saved\\-groups/grp\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"deletedId\": \"string\"`\n    \n\n`}`\n\n## [](#tag/organizations)Organizations\n\nOrganizations are used for multi-org deployments where different teams can run their own isolated feature flags and experiments. These endpoints are only via a super-admin's Personal Access Token.\n\n## [](#tag/organizations/operation/listOrganizations)Get all organizations (only for super admins on multi-org Enterprise Plan only)\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nsearch\n\nstring\n\nSearch string to search organization names, owner emails, and external ids by\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/organizations \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"organizations\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"externalId\": \"string\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"ownerEmail\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/organizations/operation/postOrganization)Create a single organization (only for super admins on multi-org Enterprise Plan only)\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nname\n\nrequired\n\nstring\n\nThe name of the organization\n\nexternalId\n\nstring\n\nAn optional identifier that you use within your company for the organization\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"externalId\": \"string\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"organization\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"externalId\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"ownerEmail\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/organizations/operation/putOrganization)Edit a single organization (only for super admins on multi-org Enterprise Plan only)\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nname\n\nstring\n\nThe name of the organization\n\nexternalId\n\nstring\n\nAn optional identifier that you use within your company for the organization\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"externalId\": \"string\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"organization\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"externalId\": \"string\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"ownerEmail\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-tables)Fact Tables\n\nFact Tables describe the shape of your data warehouse tables\n\n## [](#tag/fact-tables/operation/listFactTables)Get all fact tables\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\ndatasourceId\n\nprojectId\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/fact\\-tables \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTables\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"owner\": \"string\",`\n            \n        \n        *   `\"datasource\": \"string\",`\n            \n        *   `\"userIdTypes\": [`\n            \n            *   `\"string\"`\n                \n            \n            `],`\n            \n        *   `\"sql\": \"string\",`\n            \n        *   `\"managedBy\": \"\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/postFactTable)Create a single fact table\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nname\n\nrequired\n\nstring\n\ndescription\n\nstring\n\nDescription of the fact table\n\nowner\n\nstring\n\nThe person who is responsible for this fact table\n\nprojects\n\nArray of strings\n\nList of associated project ids\n\ntags\n\nArray of strings\n\nList of associated tags\n\ndatasource\n\nrequired\n\nstring\n\nThe datasource id\n\nuserIdTypes\n\nrequired\n\nArray of strings\n\nList of identifier columns in this table. For example, \"id\" or \"anonymous\\_id\"\n\nsql\n\nrequired\n\nstring\n\nThe SQL query for this fact table\n\nmanagedBy\n\nstring\n\nEnum: \"\" \"api\"\n\nSet this to \"api\" to disable editing in the GrowthBook UI\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"datasource\": \"string\",`\n    \n*   `\"userIdTypes\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"sql\": \"string\",`\n    \n*   `\"managedBy\": \"\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTable\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    \n    *   `\"datasource\": \"string\",`\n        \n    *   `\"userIdTypes\": [`\n        \n        *   `\"string\"`\n            \n        \n        `],`\n        \n    *   `\"sql\": \"string\",`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/getFactTable)Get a single fact table\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/fact\\-tables/ftb\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTable\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    \n    *   `\"datasource\": \"string\",`\n        \n    *   `\"userIdTypes\": [`\n        \n        *   `\"string\"`\n            \n        \n        `],`\n        \n    *   `\"sql\": \"string\",`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/updateFactTable)Update a single fact table\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nname\n\nstring\n\ndescription\n\nstring\n\nDescription of the fact table\n\nowner\n\nstring\n\nThe person who is responsible for this fact table\n\nprojects\n\nArray of strings\n\nList of associated project ids\n\ntags\n\nArray of strings\n\nList of associated tags\n\nuserIdTypes\n\nArray of strings\n\nList of identifier columns in this table. For example, \"id\" or \"anonymous\\_id\"\n\nsql\n\nstring\n\nThe SQL query for this fact table\n\nmanagedBy\n\nstring\n\nEnum: \"\" \"api\"\n\nSet this to \"api\" to disable editing in the GrowthBook UI\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"userIdTypes\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"sql\": \"string\",`\n    \n*   `\"managedBy\": \"\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTable\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    \n    *   `\"datasource\": \"string\",`\n        \n    *   `\"userIdTypes\": [`\n        \n        *   `\"string\"`\n            \n        \n        `],`\n        \n    *   `\"sql\": \"string\",`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/deleteFactTable)Deletes a single fact table\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-X DELETE https://api.growthbook.io/api/v1/fact\\-tables/ftb\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"deletedId\": \"ftb_123abc\"`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/listFactTableFilters)Get all filters for a fact table\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nfactTableId\n\nrequired\n\nstring\n\nSpecify a specific fact table\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/fact\\-tables/ftb\\_123abc/filters \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTableFilters\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"value\": \"string\",`\n            \n        *   `\"managedBy\": \"\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/postFactTableFilter)Create a single fact table filter\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nfactTableId\n\nrequired\n\nstring\n\nSpecify a specific fact table\n\n##### Request Body schema: application/json\n\nname\n\nrequired\n\ndescription\n\nstring\n\nDescription of the fact table filter\n\nvalue\n\nrequired\n\nstring\n\nThe SQL expression for this filter.\n\nmanagedBy\n\nstring\n\nEnum: \"\" \"api\"\n\nSet this to \"api\" to disable editing in the GrowthBook UI. Before you do this, the Fact Table itself must also be marked as \"api\"\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"value\": \"country = 'US'\",`\n    \n*   `\"managedBy\": \"\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTableFilter\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"value\": \"string\",`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/getFactTableFilter)Get a single fact filter\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nfactTableId\n\nrequired\n\nstring\n\nSpecify a specific fact table\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/fact\\-tables/ftb\\_123abc/filters/flt\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTableFilter\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"value\": \"string\",`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/updateFactTableFilter)Update a single fact table filter\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nfactTableId\n\nrequired\n\nstring\n\nSpecify a specific fact table\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nname\n\ndescription\n\nstring\n\nDescription of the fact table filter\n\nvalue\n\nstring\n\nThe SQL expression for this filter.\n\nmanagedBy\n\nstring\n\nEnum: \"\" \"api\"\n\nSet this to \"api\" to disable editing in the GrowthBook UI. Before you do this, the Fact Table itself must also be marked as \"api\"\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"value\": \"country = 'US'\",`\n    \n*   `\"managedBy\": \"\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTableFilter\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"value\": \"string\",`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/deleteFactTableFilter)Deletes a single fact table filter\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nfactTableId\n\nrequired\n\nstring\n\nSpecify a specific fact table\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-X DELETE https://api.growthbook.io/api/v1/fact\\-tables/ftb\\_123abc/filter/flt\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"deletedId\": \"flt_123abc\"`\n    \n\n`}`\n\n## [](#tag/fact-tables/operation/postBulkImportFacts)Bulk import fact tables, filters, and metrics\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factTables\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"data\": {`\n            \n            *   `\"name\": \"string\",`\n                \n            *   `\"description\": \"string\",`\n                \n            *   `\"owner\": \"string\",`\n                \n            \n            *   `\"datasource\": \"string\",`\n                \n            *   `\"userIdTypes\": [`\n                \n                *   `\"string\"`\n                    \n                \n                `],`\n                \n            *   `\"sql\": \"string\",`\n                \n            *   `\"managedBy\": \"\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"factTableFilters\": [`\n    \n    *   `{`\n        \n        *   `\"factTableId\": \"string\",`\n            \n        *   `\"id\": \"string\",`\n            \n        *   `\"data\": {`\n            \n            *   `\"name\": \"string\",`\n                \n            *   `\"description\": \"string\",`\n                \n            *   `\"value\": \"country = 'US'\",`\n                \n            *   `\"managedBy\": \"\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"factMetrics\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"data\": {`\n            \n            *   `\"name\": \"string\",`\n                \n            *   `\"description\": \"string\",`\n                \n            *   `\"owner\": \"string\",`\n                \n            \n            *   `\"metricType\": \"proportion\",`\n                \n            *   `\"numerator\": {`\n                \n                *   `\"factTableId\": \"string\",`\n                    \n                *   `\"column\": \"string\",`\n                    \n                \n                `},`\n                \n            *   `\"denominator\": {`\n                \n                *   `\"factTableId\": \"string\",`\n                    \n                *   `\"column\": \"string\",`\n                    \n                \n                `},`\n                \n            *   `\"inverse\": true,`\n                \n            *   `\"quantileSettings\": {`\n                \n                *   `\"type\": \"event\",`\n                    \n                *   `\"ignoreZeros\": true,`\n                    \n                *   `\"quantile\": 0.001`\n                    \n                \n                `},`\n                \n            *   `\"cappingSettings\": {`\n                \n                *   `\"type\": \"none\",`\n                    \n                *   `\"value\": 0,`\n                    \n                *   `\"ignoreZeros\": true`\n                    \n                \n                `},`\n                \n            *   `\"windowSettings\": {`\n                \n                *   `\"type\": \"none\",`\n                    \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowValue\": 0,`\n                    \n                *   `\"windowUnit\": \"hours\"`\n                    \n                \n                `},`\n                \n            *   `\"priorSettings\": {`\n                \n                *   `\"override\": true,`\n                    \n                *   `\"proper\": true,`\n                    \n                *   `\"mean\": 0,`\n                    \n                *   `\"stddev\": 0`\n                    \n                \n                `},`\n                \n            *   `\"regressionAdjustmentSettings\": {`\n                \n                *   `\"override\": true,`\n                    \n                *   `\"enabled\": true,`\n                    \n                *   `\"days\": 0`\n                    \n                \n                `},`\n                \n            *   `\"riskThresholdSuccess\": 0,`\n                \n            *   `\"riskThresholdDanger\": 0,`\n                \n            *   `\"minPercentChange\": 0,`\n                \n            *   `\"maxPercentChange\": 0,`\n                \n            *   `\"minSampleSize\": 0,`\n                \n            *   `\"managedBy\": \"\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"success\": true,`\n    \n*   `\"factTablesAdded\": 0,`\n    \n*   `\"factTablesUpdated\": 0,`\n    \n*   `\"factTableFiltersAdded\": 0,`\n    \n*   `\"factTableFiltersUpdated\": 0,`\n    \n*   `\"factMetricsAdded\": 0,`\n    \n*   `\"factMetricsUpdated\": 0`\n    \n\n`}`\n\n## [](#tag/fact-metrics)Fact Metrics\n\nFact Metrics are metrics built on top of Fact Table definitions\n\n## [](#tag/fact-metrics/operation/listFactMetrics)Get all fact metrics\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### query Parameters\n\nlimit\n\ninteger\n\nDefault: 10\n\nThe number of items to return\n\noffset\n\ninteger\n\nDefault: 0\n\nHow many items to skip (use in conjunction with limit for pagination)\n\ndatasourceId\n\nprojectId\n\nfactTableId\n\nstring\n\nFilter by Fact Table Id (for ratio metrics, we only look at the numerator)\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/fact\\-metrics \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factMetrics\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"owner\": \"string\",`\n            \n        \n        *   `\"datasource\": \"string\",`\n            \n        *   `\"metricType\": \"proportion\",`\n            \n        *   `\"numerator\": {`\n            \n            *   `\"factTableId\": \"string\",`\n                \n            *   `\"column\": \"string\",`\n                \n            \n            `},`\n            \n        *   `\"denominator\": {`\n            \n            *   `\"factTableId\": \"string\",`\n                \n            *   `\"column\": \"string\",`\n                \n            \n            `},`\n            \n        *   `\"inverse\": true,`\n            \n        *   `\"quantileSettings\": {`\n            \n            *   `\"type\": \"event\",`\n                \n            *   `\"ignoreZeros\": true,`\n                \n            *   `\"quantile\": 0.001`\n                \n            \n            `},`\n            \n        *   `\"cappingSettings\": {`\n            \n            *   `\"type\": \"none\",`\n                \n            *   `\"value\": 0,`\n                \n            *   `\"ignoreZeros\": true`\n                \n            \n            `},`\n            \n        *   `\"windowSettings\": {`\n            \n            *   `\"type\": \"none\",`\n                \n            *   `\"delayHours\": 0,`\n                \n            *   `\"windowValue\": 0,`\n                \n            *   `\"windowUnit\": \"hours\"`\n                \n            \n            `},`\n            \n        *   `\"regressionAdjustmentSettings\": {`\n            \n            *   `\"override\": true,`\n                \n            *   `\"enabled\": true,`\n                \n            *   `\"days\": 0`\n                \n            \n            `},`\n            \n        *   `\"riskThresholdSuccess\": 0,`\n            \n        *   `\"riskThresholdDanger\": 0,`\n            \n        *   `\"minPercentChange\": 0,`\n            \n        *   `\"maxPercentChange\": 0,`\n            \n        *   `\"minSampleSize\": 0,`\n            \n        *   `\"managedBy\": \"\",`\n            \n        *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n            \n        *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"limit\": 0,`\n    \n*   `\"offset\": 0,`\n    \n*   `\"count\": 0,`\n    \n*   `\"total\": 0,`\n    \n*   `\"hasMore\": true,`\n    \n*   `\"nextOffset\": 0`\n    \n\n`}`\n\n## [](#tag/fact-metrics/operation/postFactMetric)Create a single fact metric\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nname\n\nrequired\n\nstring\n\ndescription\n\nstring\n\nowner\n\nstring\n\nprojects\n\nArray of strings\n\ntags\n\nArray of strings\n\nmetricType\n\nrequired\n\nstring\n\nEnum: \"proportion\" \"mean\" \"quantile\" \"ratio\"\n\nrequired\n\nobject\n\nobject\n\nOnly when metricType is 'ratio'\n\ninverse\n\nboolean\n\nSet to true for things like Bounce Rate, where you want the metric to decrease\n\nobject\n\nControls the settings for quantile metrics (mandatory if metricType is \"quantile\")\n\nobject\n\nControls how outliers are handled\n\nobject\n\nControls the conversion window for the metric\n\nobject\n\nControls the bayesian prior for the metric. If omitted, organization defaults will be used.\n\nobject\n\nControls the regression adjustment (CUPED) settings for the metric\n\nriskThresholdSuccess\n\nnumber \\>= 0\n\nThreshold for Risk to be considered low enough, as a proportion (e.g. put 0.0025 for 0.25%).  \nMust be a non-negative number and must not be higher than `riskThresholdDanger`.\n\nriskThresholdDanger\n\nnumber \\>= 0\n\nThreshold for Risk to be considered too high, as a proportion (e.g. put 0.0125 for 1.25%).  \nMust be a non-negative number.\n\nminPercentChange\n\nnumber \\>= 0\n\nMinimum percent change to consider uplift significant, as a proportion (e.g. put 0.005 for 0.5%)\n\nmaxPercentChange\n\nnumber \\>= 0\n\nMaximum percent change to consider uplift significant, as a proportion (e.g. put 0.5 for 50%)\n\nminSampleSize\n\nnumber \\>= 0\n\nmanagedBy\n\nstring\n\nEnum: \"\" \"api\"\n\nSet this to \"api\" to disable editing in the GrowthBook UI\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"metricType\": \"proportion\",`\n    \n*   `\"numerator\": {`\n    \n    *   `\"factTableId\": \"string\",`\n        \n    *   `\"column\": \"string\",`\n        \n    \n    `},`\n    \n*   `\"denominator\": {`\n    \n    *   `\"factTableId\": \"string\",`\n        \n    *   `\"column\": \"string\",`\n        \n    \n    `},`\n    \n*   `\"inverse\": true,`\n    \n*   `\"quantileSettings\": {`\n    \n    *   `\"type\": \"event\",`\n        \n    *   `\"ignoreZeros\": true,`\n        \n    *   `\"quantile\": 0.001`\n        \n    \n    `},`\n    \n*   `\"cappingSettings\": {`\n    \n    *   `\"type\": \"none\",`\n        \n    *   `\"value\": 0,`\n        \n    *   `\"ignoreZeros\": true`\n        \n    \n    `},`\n    \n*   `\"windowSettings\": {`\n    \n    *   `\"type\": \"none\",`\n        \n    *   `\"delayHours\": 0,`\n        \n    *   `\"windowValue\": 0,`\n        \n    *   `\"windowUnit\": \"hours\"`\n        \n    \n    `},`\n    \n*   `\"priorSettings\": {`\n    \n    *   `\"override\": true,`\n        \n    *   `\"proper\": true,`\n        \n    *   `\"mean\": 0,`\n        \n    *   `\"stddev\": 0`\n        \n    \n    `},`\n    \n*   `\"regressionAdjustmentSettings\": {`\n    \n    *   `\"override\": true,`\n        \n    *   `\"enabled\": true,`\n        \n    *   `\"days\": 0`\n        \n    \n    `},`\n    \n*   `\"riskThresholdSuccess\": 0,`\n    \n*   `\"riskThresholdDanger\": 0,`\n    \n*   `\"minPercentChange\": 0,`\n    \n*   `\"maxPercentChange\": 0,`\n    \n*   `\"minSampleSize\": 0,`\n    \n*   `\"managedBy\": \"\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factMetric\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    \n    *   `\"datasource\": \"string\",`\n        \n    *   `\"metricType\": \"proportion\",`\n        \n    *   `\"numerator\": {`\n        \n        *   `\"factTableId\": \"string\",`\n            \n        *   `\"column\": \"string\",`\n            \n        \n        `},`\n        \n    *   `\"denominator\": {`\n        \n        *   `\"factTableId\": \"string\",`\n            \n        *   `\"column\": \"string\",`\n            \n        \n        `},`\n        \n    *   `\"inverse\": true,`\n        \n    *   `\"quantileSettings\": {`\n        \n        *   `\"type\": \"event\",`\n            \n        *   `\"ignoreZeros\": true,`\n            \n        *   `\"quantile\": 0.001`\n            \n        \n        `},`\n        \n    *   `\"cappingSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"value\": 0,`\n            \n        *   `\"ignoreZeros\": true`\n            \n        \n        `},`\n        \n    *   `\"windowSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"delayHours\": 0,`\n            \n        *   `\"windowValue\": 0,`\n            \n        *   `\"windowUnit\": \"hours\"`\n            \n        \n        `},`\n        \n    *   `\"regressionAdjustmentSettings\": {`\n        \n        *   `\"override\": true,`\n            \n        *   `\"enabled\": true,`\n            \n        *   `\"days\": 0`\n            \n        \n        `},`\n        \n    *   `\"riskThresholdSuccess\": 0,`\n        \n    *   `\"riskThresholdDanger\": 0,`\n        \n    *   `\"minPercentChange\": 0,`\n        \n    *   `\"maxPercentChange\": 0,`\n        \n    *   `\"minSampleSize\": 0,`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-metrics/operation/getFactMetric)Get a single fact metric\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl https://api.growthbook.io/api/v1/fact\\-metrics/fact\\_\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factMetric\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    \n    *   `\"datasource\": \"string\",`\n        \n    *   `\"metricType\": \"proportion\",`\n        \n    *   `\"numerator\": {`\n        \n        *   `\"factTableId\": \"string\",`\n            \n        *   `\"column\": \"string\",`\n            \n        \n        `},`\n        \n    *   `\"denominator\": {`\n        \n        *   `\"factTableId\": \"string\",`\n            \n        *   `\"column\": \"string\",`\n            \n        \n        `},`\n        \n    *   `\"inverse\": true,`\n        \n    *   `\"quantileSettings\": {`\n        \n        *   `\"type\": \"event\",`\n            \n        *   `\"ignoreZeros\": true,`\n            \n        *   `\"quantile\": 0.001`\n            \n        \n        `},`\n        \n    *   `\"cappingSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"value\": 0,`\n            \n        *   `\"ignoreZeros\": true`\n            \n        \n        `},`\n        \n    *   `\"windowSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"delayHours\": 0,`\n            \n        *   `\"windowValue\": 0,`\n            \n        *   `\"windowUnit\": \"hours\"`\n            \n        \n        `},`\n        \n    *   `\"regressionAdjustmentSettings\": {`\n        \n        *   `\"override\": true,`\n            \n        *   `\"enabled\": true,`\n            \n        *   `\"days\": 0`\n            \n        \n        `},`\n        \n    *   `\"riskThresholdSuccess\": 0,`\n        \n    *   `\"riskThresholdDanger\": 0,`\n        \n    *   `\"minPercentChange\": 0,`\n        \n    *   `\"maxPercentChange\": 0,`\n        \n    *   `\"minSampleSize\": 0,`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-metrics/operation/updateFactMetric)Update a single fact metric\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n##### Request Body schema: application/json\n\nname\n\nstring\n\ndescription\n\nstring\n\nowner\n\nstring\n\nprojects\n\nArray of strings\n\ntags\n\nArray of strings\n\nmetricType\n\nstring\n\nEnum: \"proportion\" \"mean\" \"quantile\" \"ratio\"\n\nobject\n\nobject\n\nOnly when metricType is 'ratio'\n\ninverse\n\nboolean\n\nSet to true for things like Bounce Rate, where you want the metric to decrease\n\nobject\n\nControls the settings for quantile metrics (mandatory if metricType is \"quantile\")\n\nobject\n\nControls how outliers are handled\n\nobject\n\nControls the conversion window for the metric\n\nobject\n\nControls the regression adjustment (CUPED) settings for the metric\n\nriskThresholdSuccess\n\nnumber \\>= 0\n\nThreshold for Risk to be considered low enough, as a proportion (e.g. put 0.0025 for 0.25%).  \nMust be a non-negative number and must not be higher than `riskThresholdDanger`.\n\nriskThresholdDanger\n\nnumber \\>= 0\n\nThreshold for Risk to be considered too high, as a proportion (e.g. put 0.0125 for 1.25%).  \nMust be a non-negative number.\n\nminPercentChange\n\nnumber \\>= 0\n\nMinimum percent change to consider uplift significant, as a proportion (e.g. put 0.005 for 0.5%)\n\nmaxPercentChange\n\nnumber \\>= 0\n\nMaximum percent change to consider uplift significant, as a proportion (e.g. put 0.5 for 50%)\n\nminSampleSize\n\nnumber \\>= 0\n\nmanagedBy\n\nstring\n\nEnum: \"\" \"api\"\n\nSet this to \"api\" to disable editing in the GrowthBook UI\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"metricType\": \"proportion\",`\n    \n*   `\"numerator\": {`\n    \n    *   `\"factTableId\": \"string\",`\n        \n    *   `\"column\": \"string\",`\n        \n    \n    `},`\n    \n*   `\"denominator\": {`\n    \n    *   `\"factTableId\": \"string\",`\n        \n    *   `\"column\": \"string\",`\n        \n    \n    `},`\n    \n*   `\"inverse\": true,`\n    \n*   `\"quantileSettings\": {`\n    \n    *   `\"type\": \"event\",`\n        \n    *   `\"ignoreZeros\": true,`\n        \n    *   `\"quantile\": 0.001`\n        \n    \n    `},`\n    \n*   `\"cappingSettings\": {`\n    \n    *   `\"type\": \"none\",`\n        \n    *   `\"value\": 0,`\n        \n    *   `\"ignoreZeros\": true`\n        \n    \n    `},`\n    \n*   `\"windowSettings\": {`\n    \n    *   `\"type\": \"none\",`\n        \n    *   `\"delayHours\": 0,`\n        \n    *   `\"windowValue\": 0,`\n        \n    *   `\"windowUnit\": \"hours\"`\n        \n    \n    `},`\n    \n*   `\"regressionAdjustmentSettings\": {`\n    \n    *   `\"override\": true,`\n        \n    *   `\"enabled\": true,`\n        \n    *   `\"days\": 0`\n        \n    \n    `},`\n    \n*   `\"riskThresholdSuccess\": 0,`\n    \n*   `\"riskThresholdDanger\": 0,`\n    \n*   `\"minPercentChange\": 0,`\n    \n*   `\"maxPercentChange\": 0,`\n    \n*   `\"minSampleSize\": 0,`\n    \n*   `\"managedBy\": \"\"`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"factMetric\": {`\n    \n    *   `\"id\": \"string\",`\n        \n    *   `\"name\": \"string\",`\n        \n    *   `\"description\": \"string\",`\n        \n    *   `\"owner\": \"string\",`\n        \n    \n    *   `\"datasource\": \"string\",`\n        \n    *   `\"metricType\": \"proportion\",`\n        \n    *   `\"numerator\": {`\n        \n        *   `\"factTableId\": \"string\",`\n            \n        *   `\"column\": \"string\",`\n            \n        \n        `},`\n        \n    *   `\"denominator\": {`\n        \n        *   `\"factTableId\": \"string\",`\n            \n        *   `\"column\": \"string\",`\n            \n        \n        `},`\n        \n    *   `\"inverse\": true,`\n        \n    *   `\"quantileSettings\": {`\n        \n        *   `\"type\": \"event\",`\n            \n        *   `\"ignoreZeros\": true,`\n            \n        *   `\"quantile\": 0.001`\n            \n        \n        `},`\n        \n    *   `\"cappingSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"value\": 0,`\n            \n        *   `\"ignoreZeros\": true`\n            \n        \n        `},`\n        \n    *   `\"windowSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"delayHours\": 0,`\n            \n        *   `\"windowValue\": 0,`\n            \n        *   `\"windowUnit\": \"hours\"`\n            \n        \n        `},`\n        \n    *   `\"regressionAdjustmentSettings\": {`\n        \n        *   `\"override\": true,`\n            \n        *   `\"enabled\": true,`\n            \n        *   `\"days\": 0`\n            \n        \n        `},`\n        \n    *   `\"riskThresholdSuccess\": 0,`\n        \n    *   `\"riskThresholdDanger\": 0,`\n        \n    *   `\"minPercentChange\": 0,`\n        \n    *   `\"maxPercentChange\": 0,`\n        \n    *   `\"minSampleSize\": 0,`\n        \n    *   `\"managedBy\": \"\",`\n        \n    *   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/fact-metrics/operation/deleteFactMetric)Deletes a single fact metric\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### path Parameters\n\nid\n\nrequired\n\nstring\n\nThe id of the requested resource\n\n### Responses\n\n### Request samples\n\n*   cURL\n\ncurl \\-X DELETE https://api.growthbook.io/api/v1/fact\\-metrics/fact\\_\\_123abc \\\\\n  \\-u secret\\_abc123DEF456:\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"deletedId\": \"fact__123abc\"`\n    \n\n`}`\n\n## [](#tag/code-references)Code References\n\n## [](#tag/code-references/operation/postCodeRefs)Submit list of code references\n\n##### Authorizations:\n\n_bearerAuth__basicAuth_\n\n##### Request Body schema: application/json\n\nbranch\n\nrequired\n\nrepoName\n\nrequired\n\nrequired\n\n### Responses\n\n### Request samples\n\n*   Payload\n*   cURL\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"branch\": \"string\",`\n    \n*   `\"repoName\": \"string\",`\n    \n*   `\"refs\": [`\n    \n    *   `{`\n        \n        *   `\"filePath\": \"string\",`\n            \n        *   `\"startingLineNumber\": 0,`\n            \n        *   `\"lines\": \"string\",`\n            \n        *   `\"flagKey\": \"string\",`\n            \n        *   `\"contentHash\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n### Response samples\n\n*   200\n\nContent type\n\napplication/json\n\n`{`\n\n*   `\"featuresUpdated\": [`\n    \n    *   `\"string\"`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/DataSource_model)DataSource\n\nid\n\nrequired\n\nstring\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\ntype\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\ndescription\n\nrequired\n\nstring\n\nprojectIds\n\nrequired\n\nArray of strings\n\neventTracker\n\nrequired\n\nstring\n\nrequired\n\nArray of objects\n\nrequired\n\nArray of objects\n\nrequired\n\nArray of objects\n\nobject\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"type\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"projectIds\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"eventTracker\": \"string\",`\n    \n*   `\"identifierTypes\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"description\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"assignmentQueries\": [`\n    \n    *   `{`\n        \n        *   `\"id\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"identifierType\": \"string\",`\n            \n        *   `\"sql\": \"string\",`\n            \n        *   `\"includesNameColumns\": true,`\n            \n        *   `\"dimensionColumns\": [`\n            \n            *   `\"string\"`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"identifierJoinQueries\": [`\n    \n    *   `{`\n        \n        *   `\"identifierTypes\": [`\n            \n            *   `\"string\"`\n                \n            \n            `],`\n            \n        *   `\"sql\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"mixpanelSettings\": {`\n    \n    *   `\"viewedExperimentEventName\": \"string\",`\n        \n    *   `\"experimentIdProperty\": \"string\",`\n        \n    *   `\"variationIdProperty\": \"string\",`\n        \n    *   `\"extraUserIdProperty\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/Dimension_model)Dimension\n\nid\n\nrequired\n\nstring\n\ndateCreated\n\nrequired\n\nstring\n\ndateUpdated\n\nrequired\n\nstring\n\nowner\n\nrequired\n\nstring\n\ndatasourceId\n\nrequired\n\nstring\n\nidentifierType\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\nquery\n\nrequired\n\nstring\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"dateCreated\": \"string\",`\n    \n*   `\"dateUpdated\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"datasourceId\": \"string\",`\n    \n*   `\"identifierType\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"query\": \"string\"`\n    \n\n`}`\n\n## [](#tag/Environment_model)Environment\n\nid\n\nrequired\n\ndescription\n\nrequired\n\ntoggleOnList\n\nrequired\n\ndefaultState\n\nrequired\n\nprojects\n\nrequired\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"toggleOnList\": true,`\n    \n*   `\"defaultState\": true,`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/Experiment_model)Experiment\n\nid\n\nrequired\n\nstring\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\nname\n\nrequired\n\nstring\n\nproject\n\nrequired\n\nstring\n\nhypothesis\n\nrequired\n\nstring\n\ndescription\n\nrequired\n\nstring\n\ntags\n\nrequired\n\nArray of strings\n\nowner\n\nrequired\n\nstring\n\narchived\n\nrequired\n\nboolean\n\nstatus\n\nrequired\n\nstring\n\nautoRefresh\n\nrequired\n\nboolean\n\nhashAttribute\n\nrequired\n\nstring\n\nfallbackAttribute\n\nstring\n\nhashVersion\n\nrequired\n\nnumber\n\nEnum: 1 2\n\ndisableStickyBucketing\n\nboolean;\n\nbucketVersion\n\nnumber\n\nminBucketVersion\n\nnumber\n\nrequired\n\nArray of objects\n\nrequired\n\nArray of objects\n\nrequired\n\nobject (ExperimentAnalysisSettings)\n\nobject\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"project\": \"string\",`\n    \n*   `\"hypothesis\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"archived\": true,`\n    \n*   `\"status\": \"string\",`\n    \n*   `\"autoRefresh\": true,`\n    \n*   `\"hashAttribute\": \"string\",`\n    \n*   `\"fallbackAttribute\": \"string\",`\n    \n*   `\"hashVersion\": 1,`\n    \n*   `\"disableStickyBucketing\": null,`\n    \n*   `\"bucketVersion\": 0,`\n    \n*   `\"minBucketVersion\": 0,`\n    \n*   `\"variations\": [`\n    \n    *   `{`\n        \n        *   `\"variationId\": \"string\",`\n            \n        *   `\"key\": \"string\",`\n            \n        *   `\"name\": \"string\",`\n            \n        *   `\"description\": \"string\",`\n            \n        *   `\"screenshots\": [`\n            \n            *   `\"string\"`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"phases\": [`\n    \n    *   `{`\n        \n        *   `\"name\": \"string\",`\n            \n        *   `\"dateStarted\": \"string\",`\n            \n        *   `\"dateEnded\": \"string\",`\n            \n        *   `\"reasonForStopping\": \"string\",`\n            \n        *   `\"seed\": \"string\",`\n            \n        *   `\"coverage\": 0,`\n            \n        *   `\"trafficSplit\": [`\n            \n            *   `{`\n                \n                *   `\"variationId\": \"string\",`\n                    \n                *   `\"weight\": 0`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"namespace\": {`\n            \n            *   `\"namespaceId\": \"string\",`\n                \n            *   `\"range\": [ ]`\n                \n            \n            `},`\n            \n        *   `\"targetingCondition\": \"string\",`\n            \n        *   `\"savedGroupTargeting\": [`\n            \n            *   `{`\n                \n                *   `\"matchType\": \"all\",`\n                    \n                *   `\"savedGroups\": [`\n                    \n                    *   `\"string\"`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"settings\": {`\n    \n    *   `\"datasourceId\": \"string\",`\n        \n    *   `\"assignmentQueryId\": \"string\",`\n        \n    *   `\"experimentId\": \"string\",`\n        \n    *   `\"segmentId\": \"string\",`\n        \n    *   `\"queryFilter\": \"string\",`\n        \n    *   `\"inProgressConversions\": \"include\",`\n        \n    *   `\"attributionModel\": \"firstExposure\",`\n        \n    *   `\"statsEngine\": \"bayesian\",`\n        \n    *   `\"goals\": [`\n        \n        *   `{`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"guardrails\": [`\n        \n        *   `{`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"activationMetric\": {`\n        \n        *   `\"metricId\": \"string\",`\n            \n        *   `\"overrides\": {`\n            \n            *   `\"delayHours\": 0,`\n                \n            *   `\"windowHours\": 0,`\n                \n            *   `\"window\": \"conversion\",`\n                \n            *   `\"winRiskThreshold\": 0,`\n                \n            *   `\"loseRiskThreshold\": 0`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `},`\n    \n*   `\"resultSummary\": {`\n    \n    *   `\"status\": \"string\",`\n        \n    *   `\"winner\": \"string\",`\n        \n    *   `\"conclusions\": \"string\",`\n        \n    *   `\"releasedVariationId\": \"string\",`\n        \n    *   `\"excludeFromPayload\": true`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/ExperimentAnalysisSettings_model)ExperimentAnalysisSettings\n\ndatasourceId\n\nrequired\n\nstring\n\nassignmentQueryId\n\nrequired\n\nstring\n\nexperimentId\n\nrequired\n\nstring\n\nsegmentId\n\nrequired\n\nstring\n\nqueryFilter\n\nrequired\n\nstring\n\ninProgressConversions\n\nrequired\n\nany\n\nEnum: \"include\" \"exclude\"\n\nattributionModel\n\nrequired\n\nany\n\nEnum: \"firstExposure\" \"experimentDuration\"\n\nstatsEngine\n\nrequired\n\nany\n\nEnum: \"bayesian\" \"frequentist\"\n\nrequired\n\nArray of objects (ExperimentMetric)\n\nrequired\n\nArray of objects (ExperimentMetric)\n\nobject (ExperimentMetric)\n\n`{`\n\n*   `\"datasourceId\": \"string\",`\n    \n*   `\"assignmentQueryId\": \"string\",`\n    \n*   `\"experimentId\": \"string\",`\n    \n*   `\"segmentId\": \"string\",`\n    \n*   `\"queryFilter\": \"string\",`\n    \n*   `\"inProgressConversions\": \"include\",`\n    \n*   `\"attributionModel\": \"firstExposure\",`\n    \n*   `\"statsEngine\": \"bayesian\",`\n    \n*   `\"goals\": [`\n    \n    *   `{`\n        \n        *   `\"metricId\": \"string\",`\n            \n        *   `\"overrides\": {`\n            \n            *   `\"delayHours\": 0,`\n                \n            *   `\"windowHours\": 0,`\n                \n            *   `\"window\": \"conversion\",`\n                \n            *   `\"winRiskThreshold\": 0,`\n                \n            *   `\"loseRiskThreshold\": 0`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"guardrails\": [`\n    \n    *   `{`\n        \n        *   `\"metricId\": \"string\",`\n            \n        *   `\"overrides\": {`\n            \n            *   `\"delayHours\": 0,`\n                \n            *   `\"windowHours\": 0,`\n                \n            *   `\"window\": \"conversion\",`\n                \n            *   `\"winRiskThreshold\": 0,`\n                \n            *   `\"loseRiskThreshold\": 0`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"activationMetric\": {`\n    \n    *   `\"metricId\": \"string\",`\n        \n    *   `\"overrides\": {`\n        \n        *   `\"delayHours\": 0,`\n            \n        *   `\"windowHours\": 0,`\n            \n        *   `\"window\": \"conversion\",`\n            \n        *   `\"winRiskThreshold\": 0,`\n            \n        *   `\"loseRiskThreshold\": 0`\n            \n        \n        `}`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/ExperimentMetric_model)ExperimentMetric\n\n`{`\n\n*   `\"metricId\": \"string\",`\n    \n*   `\"overrides\": {`\n    \n    *   `\"delayHours\": 0,`\n        \n    *   `\"windowHours\": 0,`\n        \n    *   `\"window\": \"conversion\",`\n        \n    *   `\"winRiskThreshold\": 0,`\n        \n    *   `\"loseRiskThreshold\": 0`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/ExperimentResults_model)ExperimentResults\n\nid\n\nrequired\n\nstring\n\ndateUpdated\n\nrequired\n\nstring\n\nexperimentId\n\nrequired\n\nstring\n\nphase\n\nrequired\n\nstring\n\ndateStart\n\nrequired\n\nstring\n\ndateEnd\n\nrequired\n\nstring\n\nrequired\n\nobject\n\nrequired\n\nobject (ExperimentAnalysisSettings)\n\nqueryIds\n\nrequired\n\nArray of strings\n\nrequired\n\nArray of objects\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"dateUpdated\": \"string\",`\n    \n*   `\"experimentId\": \"string\",`\n    \n*   `\"phase\": \"string\",`\n    \n*   `\"dateStart\": \"string\",`\n    \n*   `\"dateEnd\": \"string\",`\n    \n*   `\"dimension\": {`\n    \n    *   `\"type\": \"string\",`\n        \n    *   `\"id\": \"string\"`\n        \n    \n    `},`\n    \n*   `\"settings\": {`\n    \n    *   `\"datasourceId\": \"string\",`\n        \n    *   `\"assignmentQueryId\": \"string\",`\n        \n    *   `\"experimentId\": \"string\",`\n        \n    *   `\"segmentId\": \"string\",`\n        \n    *   `\"queryFilter\": \"string\",`\n        \n    *   `\"inProgressConversions\": \"include\",`\n        \n    *   `\"attributionModel\": \"firstExposure\",`\n        \n    *   `\"statsEngine\": \"bayesian\",`\n        \n    *   `\"goals\": [`\n        \n        *   `{`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"guardrails\": [`\n        \n        *   `{`\n            \n            *   `\"metricId\": \"string\",`\n                \n            *   `\"overrides\": {`\n                \n                *   `\"delayHours\": 0,`\n                    \n                *   `\"windowHours\": 0,`\n                    \n                *   `\"window\": \"conversion\",`\n                    \n                *   `\"winRiskThreshold\": 0,`\n                    \n                *   `\"loseRiskThreshold\": 0`\n                    \n                \n                `}`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"activationMetric\": {`\n        \n        *   `\"metricId\": \"string\",`\n            \n        *   `\"overrides\": {`\n            \n            *   `\"delayHours\": 0,`\n                \n            *   `\"windowHours\": 0,`\n                \n            *   `\"window\": \"conversion\",`\n                \n            *   `\"winRiskThreshold\": 0,`\n                \n            *   `\"loseRiskThreshold\": 0`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `},`\n    \n*   `\"queryIds\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"results\": [`\n    \n    *   `{`\n        \n        *   `\"dimension\": \"string\",`\n            \n        *   `\"totalUsers\": 0,`\n            \n        \n        *   `\"metrics\": [`\n            \n            *   `{`\n                \n                *   `\"metricId\": \"string\",`\n                    \n                *   `\"variations\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"variationId\": \"string\",`\n                            \n                        *   `\"users\": 0,`\n                            \n                        *   `\"analyses\": [`\n                            \n                            *   `{`\n                                \n                                *   `\"engine\": \"bayesian\",`\n                                    \n                                *   `\"numerator\": 0,`\n                                    \n                                *   `\"denominator\": 0,`\n                                    \n                                *   `\"mean\": 0,`\n                                    \n                                *   `\"stddev\": 0,`\n                                    \n                                *   `\"percentChange\": 0,`\n                                    \n                                *   `\"ciLow\": 0,`\n                                    \n                                *   `\"ciHigh\": 0,`\n                                    \n                                *   `\"pValue\": 0,`\n                                    \n                                *   `\"risk\": 0,`\n                                    \n                                *   `\"chanceToBeatControl\": 0`\n                                    \n                                \n                                `}`\n                                \n                            \n                            `]`\n                            \n                        \n                        `}`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/FactMetric_model)FactMetric\n\nid\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\ndescription\n\nrequired\n\nstring\n\nowner\n\nrequired\n\nstring\n\nprojects\n\nrequired\n\nArray of strings\n\ntags\n\nrequired\n\nArray of strings\n\ndatasource\n\nrequired\n\nstring\n\nmetricType\n\nrequired\n\nstring\n\nEnum: \"proportion\" \"mean\" \"quantile\" \"ratio\"\n\nrequired\n\nobject\n\nobject\n\ninverse\n\nrequired\n\nboolean\n\nSet to true for things like Bounce Rate, where you want the metric to decrease\n\nobject\n\nControls the settings for quantile metrics (mandatory if metricType is \"quantile\")\n\nrequired\n\nobject\n\nControls how outliers are handled\n\nrequired\n\nobject\n\nControls the conversion window for the metric\n\nrequired\n\nobject\n\nControls the regression adjustment (CUPED) settings for the metric\n\nriskThresholdSuccess\n\nrequired\n\nnumber\n\nriskThresholdDanger\n\nrequired\n\nnumber\n\nminPercentChange\n\nrequired\n\nnumber\n\nmaxPercentChange\n\nrequired\n\nnumber\n\nminSampleSize\n\nrequired\n\nnumber\n\nmanagedBy\n\nrequired\n\nstring\n\nEnum: \"\" \"api\"\n\nWhere this fact metric must be managed from. If not set (empty string), it can be managed from anywhere.\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"datasource\": \"string\",`\n    \n*   `\"metricType\": \"proportion\",`\n    \n*   `\"numerator\": {`\n    \n    *   `\"factTableId\": \"string\",`\n        \n    *   `\"column\": \"string\",`\n        \n    \n    `},`\n    \n*   `\"denominator\": {`\n    \n    *   `\"factTableId\": \"string\",`\n        \n    *   `\"column\": \"string\",`\n        \n    \n    `},`\n    \n*   `\"inverse\": true,`\n    \n*   `\"quantileSettings\": {`\n    \n    *   `\"type\": \"event\",`\n        \n    *   `\"ignoreZeros\": true,`\n        \n    *   `\"quantile\": 0.001`\n        \n    \n    `},`\n    \n*   `\"cappingSettings\": {`\n    \n    *   `\"type\": \"none\",`\n        \n    *   `\"value\": 0,`\n        \n    *   `\"ignoreZeros\": true`\n        \n    \n    `},`\n    \n*   `\"windowSettings\": {`\n    \n    *   `\"type\": \"none\",`\n        \n    *   `\"delayHours\": 0,`\n        \n    *   `\"windowValue\": 0,`\n        \n    *   `\"windowUnit\": \"hours\"`\n        \n    \n    `},`\n    \n*   `\"regressionAdjustmentSettings\": {`\n    \n    *   `\"override\": true,`\n        \n    *   `\"enabled\": true,`\n        \n    *   `\"days\": 0`\n        \n    \n    `},`\n    \n*   `\"riskThresholdSuccess\": 0,`\n    \n*   `\"riskThresholdDanger\": 0,`\n    \n*   `\"minPercentChange\": 0,`\n    \n*   `\"maxPercentChange\": 0,`\n    \n*   `\"minSampleSize\": 0,`\n    \n*   `\"managedBy\": \"\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n    \n\n`}`\n\n## [](#tag/FactTable_model)FactTable\n\nid\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\ndescription\n\nrequired\n\nstring\n\nowner\n\nrequired\n\nstring\n\nprojects\n\nrequired\n\nArray of strings\n\ntags\n\nrequired\n\nArray of strings\n\ndatasource\n\nrequired\n\nstring\n\nuserIdTypes\n\nrequired\n\nArray of strings\n\nsql\n\nrequired\n\nstring\n\nmanagedBy\n\nrequired\n\nstring\n\nEnum: \"\" \"api\"\n\nWhere this fact table must be managed from. If not set (empty string), it can be managed from anywhere.\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"datasource\": \"string\",`\n    \n*   `\"userIdTypes\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"sql\": \"string\",`\n    \n*   `\"managedBy\": \"\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n    \n\n`}`\n\n## [](#tag/FactTableFilter_model)FactTableFilter\n\nid\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\ndescription\n\nrequired\n\nstring\n\nvalue\n\nrequired\n\nstring\n\nmanagedBy\n\nrequired\n\nstring\n\nEnum: \"\" \"api\"\n\nWhere this fact table filter must be managed from. If not set (empty string), it can be managed from anywhere.\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"value\": \"string\",`\n    \n*   `\"managedBy\": \"\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\"`\n    \n\n`}`\n\n## [](#tag/Feature_model)Feature\n\nid\n\nrequired\n\nstring\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\narchived\n\nrequired\n\nboolean\n\ndescription\n\nrequired\n\nstring\n\nowner\n\nrequired\n\nstring\n\nproject\n\nrequired\n\nstring\n\nvalueType\n\nrequired\n\nstring\n\nEnum: \"boolean\" \"string\" \"number\" \"json\"\n\ndefaultValue\n\nrequired\n\nstring\n\ntags\n\nrequired\n\nArray of strings\n\nrequired\n\nobject\n\nArray of objects\n\nrequired\n\nobject\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"archived\": true,`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"project\": \"string\",`\n    \n*   `\"valueType\": \"boolean\",`\n    \n*   `\"defaultValue\": \"string\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"environments\": {`\n    \n    *   `\"property1\": {`\n        \n        *   `\"enabled\": true,`\n            \n        *   `\"defaultValue\": \"string\",`\n            \n        *   `\"rules\": [`\n            \n            *   `{`\n                \n                *   `\"description\": \"string\",`\n                    \n                *   `\"condition\": \"string\",`\n                    \n                *   `\"savedGroupTargeting\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"matchType\": \"all\",`\n                            \n                        *   `\"savedGroups\": [`\n                            \n                            *   `\"string\"`\n                                \n                            \n                            `]`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"id\": \"string\",`\n                    \n                *   `\"enabled\": true,`\n                    \n                *   `\"type\": \"force\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"definition\": \"string\",`\n            \n        *   `\"draft\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `},`\n        \n    *   `\"property2\": {`\n        \n        *   `\"enabled\": true,`\n            \n        *   `\"defaultValue\": \"string\",`\n            \n        *   `\"rules\": [`\n            \n            *   `{`\n                \n                *   `\"description\": \"string\",`\n                    \n                *   `\"condition\": \"string\",`\n                    \n                *   `\"savedGroupTargeting\": [`\n                    \n                    *   `{`\n                        \n                        *   `\"matchType\": \"all\",`\n                            \n                        *   `\"savedGroups\": [`\n                            \n                            *   `\"string\"`\n                                \n                            \n                            `]`\n                            \n                        \n                        `}`\n                        \n                    \n                    `],`\n                    \n                *   `\"id\": \"string\",`\n                    \n                *   `\"enabled\": true,`\n                    \n                *   `\"type\": \"force\",`\n                    \n                *   `\"value\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"definition\": \"string\",`\n            \n        *   `\"draft\": {`\n            \n            *   `\"enabled\": true,`\n                \n            *   `\"defaultValue\": \"string\",`\n                \n            *   `\"rules\": [`\n                \n                *   `{`\n                    \n                    *   `\"description\": \"string\",`\n                        \n                    *   `\"condition\": \"string\",`\n                        \n                    *   `\"savedGroupTargeting\": [`\n                        \n                        *   `{`\n                            \n                            *   `\"matchType\": \"all\",`\n                                \n                            *   `\"savedGroups\": [`\n                                \n                                *   `\"string\"`\n                                    \n                                \n                                `]`\n                                \n                            \n                            `}`\n                            \n                        \n                        `],`\n                        \n                    *   `\"id\": \"string\",`\n                        \n                    *   `\"enabled\": true,`\n                        \n                    *   `\"type\": \"force\",`\n                        \n                    *   `\"value\": \"string\"`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"definition\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `}`\n        \n    \n    `},`\n    \n*   `\"prerequisites\": [`\n    \n    *   `{`\n        \n        *   `\"parentId\": \"string\",`\n            \n        *   `\"parentCondition\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"revision\": {`\n    \n    *   `\"version\": 0,`\n        \n    *   `\"comment\": \"string\",`\n        \n    *   `\"date\": \"2019-08-24T14:15:22Z\",`\n        \n    *   `\"publishedBy\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/FeatureDefinition_model)FeatureDefinition\n\ndefaultValue\n\nrequired\n\nstring or number or array or object or null\n\n`{`\n\n*   `\"defaultValue\": \"string\",`\n    \n*   `\"rules\": [`\n    \n    *   `{`\n        \n        *   `\"force\": \"string\",`\n            \n        \n        *   `\"variations\": [`\n            \n            *   `\"string\"`\n                \n            \n            `],`\n            \n        *   `\"hashAttribute\": \"string\",`\n            \n        \n        *   `\"key\": \"string\",`\n            \n        *   `\"coverage\": 0,`\n            \n        *   `\"condition\": { }`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/FeatureEnvironment_model)FeatureEnvironment\n\nenabled\n\nrequired\n\ndefaultValue\n\nrequired\n\nrequired\n\nArray of any (FeatureRule)\n\ndefinition\n\nstring\n\nA JSON stringified [FeatureDefinition](#tag/FeatureDefinition_model)\n\n`{`\n\n*   `\"enabled\": true,`\n    \n*   `\"defaultValue\": \"string\",`\n    \n*   `\"rules\": [`\n    \n    *   `{`\n        \n        *   `\"description\": \"string\",`\n            \n        *   `\"condition\": \"string\",`\n            \n        *   `\"savedGroupTargeting\": [`\n            \n            *   `{`\n                \n                *   `\"matchType\": \"all\",`\n                    \n                *   `\"savedGroups\": [`\n                    \n                    *   `\"string\"`\n                        \n                    \n                    `]`\n                    \n                \n                `}`\n                \n            \n            `],`\n            \n        *   `\"id\": \"string\",`\n            \n        *   `\"enabled\": true,`\n            \n        *   `\"type\": \"force\",`\n            \n        *   `\"value\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"definition\": \"string\",`\n    \n*   `\"draft\": {`\n    \n    *   `\"enabled\": true,`\n        \n    *   `\"defaultValue\": \"string\",`\n        \n    *   `\"rules\": [`\n        \n        *   `{`\n            \n            *   `\"description\": \"string\",`\n                \n            *   `\"condition\": \"string\",`\n                \n            *   `\"savedGroupTargeting\": [`\n                \n                *   `{`\n                    \n                    *   `\"matchType\": \"all\",`\n                        \n                    *   `\"savedGroups\": [`\n                        \n                        *   `\"string\"`\n                            \n                        \n                        `]`\n                        \n                    \n                    `}`\n                    \n                \n                `],`\n                \n            *   `\"id\": \"string\",`\n                \n            *   `\"enabled\": true,`\n                \n            *   `\"type\": \"force\",`\n                \n            *   `\"value\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"definition\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/FeatureExperimentRefRule_model)FeatureExperimentRefRule\n\ndescription\n\nrequired\n\nstring\n\nid\n\nrequired\n\nstring\n\nenabled\n\nrequired\n\nboolean\n\ntype\n\nrequired\n\nstring\n\nValue: \"experiment-ref\"\n\ncondition\n\nstring\n\nrequired\n\nArray of objects\n\nexperimentId\n\nrequired\n\nstring\n\n`{`\n\n*   `\"description\": \"string\",`\n    \n*   `\"id\": \"string\",`\n    \n*   `\"enabled\": true,`\n    \n*   `\"type\": \"experiment-ref\",`\n    \n*   `\"condition\": \"string\",`\n    \n*   `\"variations\": [`\n    \n    *   `{`\n        \n        *   `\"value\": \"string\",`\n            \n        *   `\"variationId\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"experimentId\": \"string\"`\n    \n\n`}`\n\n## [](#tag/FeatureExperimentRule_model)FeatureExperimentRule\n\ndescription\n\nrequired\n\nstring\n\ncondition\n\nrequired\n\nstring\n\nid\n\nrequired\n\nstring\n\nenabled\n\nrequired\n\nboolean\n\ntype\n\nrequired\n\nstring\n\nValue: \"experiment\"\n\ntrackingKey\n\nstring\n\nhashAttribute\n\nstring\n\nfallbackAttribute\n\nstring\n\ndisableStickyBucketing\n\nboolean;\n\nbucketVersion\n\nnumber\n\nminBucketVersion\n\nnumber\n\nnamespace\n\nobect\n\ncoverage\n\nnumber\n\nArray of objects\n\n`{`\n\n*   `\"description\": \"string\",`\n    \n*   `\"condition\": \"string\",`\n    \n*   `\"id\": \"string\",`\n    \n*   `\"enabled\": true,`\n    \n*   `\"type\": \"experiment\",`\n    \n*   `\"trackingKey\": \"string\",`\n    \n*   `\"hashAttribute\": \"string\",`\n    \n*   `\"fallbackAttribute\": \"string\",`\n    \n*   `\"disableStickyBucketing\": null,`\n    \n*   `\"bucketVersion\": 0,`\n    \n*   `\"minBucketVersion\": 0,`\n    \n*   `\"namespace\": null,`\n    \n*   `\"coverage\": 0,`\n    \n*   `\"value\": [`\n    \n    *   `{`\n        \n        *   `\"value\": \"string\",`\n            \n        *   `\"weight\": 0,`\n            \n        *   `\"name\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/FeatureForceRule_model)FeatureForceRule\n\ndescription\n\nrequired\n\nstring\n\ncondition\n\nrequired\n\nstring\n\nArray of objects\n\nid\n\nrequired\n\nstring\n\nenabled\n\nrequired\n\nboolean\n\ntype\n\nrequired\n\nstring\n\nValue: \"force\"\n\nvalue\n\nrequired\n\nstring\n\n`{`\n\n*   `\"description\": \"string\",`\n    \n*   `\"condition\": \"string\",`\n    \n*   `\"savedGroupTargeting\": [`\n    \n    *   `{`\n        \n        *   `\"matchType\": \"all\",`\n            \n        *   `\"savedGroups\": [`\n            \n            *   `\"string\"`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"id\": \"string\",`\n    \n*   `\"enabled\": true,`\n    \n*   `\"type\": \"force\",`\n    \n*   `\"value\": \"string\"`\n    \n\n`}`\n\n## [](#tag/FeatureRolloutRule_model)FeatureRolloutRule\n\ndescription\n\nrequired\n\nstring\n\ncondition\n\nrequired\n\nstring\n\nArray of objects\n\nid\n\nrequired\n\nstring\n\nenabled\n\nrequired\n\nboolean\n\ntype\n\nrequired\n\nstring\n\nValue: \"rollout\"\n\nvalue\n\nrequired\n\nstring\n\ncoverage\n\nrequired\n\nnumber\n\nhashAttribute\n\nrequired\n\nstring\n\n`{`\n\n*   `\"description\": \"string\",`\n    \n*   `\"condition\": \"string\",`\n    \n*   `\"savedGroupTargeting\": [`\n    \n    *   `{`\n        \n        *   `\"matchType\": \"all\",`\n            \n        *   `\"savedGroups\": [`\n            \n            *   `\"string\"`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"id\": \"string\",`\n    \n*   `\"enabled\": true,`\n    \n*   `\"type\": \"rollout\",`\n    \n*   `\"value\": \"string\",`\n    \n*   `\"coverage\": 0,`\n    \n*   `\"hashAttribute\": \"string\"`\n    \n\n`}`\n\n## [](#tag/FeatureRule_model)FeatureRule\n\ndescription\n\nrequired\n\nstring\n\ncondition\n\nrequired\n\nstring\n\nArray of objects\n\nid\n\nrequired\n\nstring\n\nenabled\n\nrequired\n\nboolean\n\ntype\n\nrequired\n\nstring\n\nforce\n\nvalue\n\nrequired\n\nstring\n\n`{`\n\n*   `\"description\": \"string\",`\n    \n*   `\"condition\": \"string\",`\n    \n*   `\"savedGroupTargeting\": [`\n    \n    *   `{`\n        \n        *   `\"matchType\": \"all\",`\n            \n        *   `\"savedGroups\": [`\n            \n            *   `\"string\"`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"id\": \"string\",`\n    \n*   `\"enabled\": true,`\n    \n*   `\"type\": \"force\",`\n    \n*   `\"value\": \"string\"`\n    \n\n`}`\n\n## [](#tag/Metric_model)Metric\n\nid\n\nrequired\n\nstring\n\nmanagedBy\n\nrequired\n\nstring\n\nEnum: \"\" \"api\" \"config\"\n\nWhere this metric must be managed from. If not set (empty string), it can be managed from anywhere.\n\ndateCreated\n\nrequired\n\nstring\n\ndateUpdated\n\nrequired\n\nstring\n\nowner\n\nrequired\n\nstring\n\ndatasourceId\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\ndescription\n\nrequired\n\nstring\n\ntype\n\nrequired\n\nstring\n\nEnum: \"binomial\" \"count\" \"duration\" \"revenue\"\n\ntags\n\nrequired\n\nArray of strings\n\nprojects\n\nrequired\n\nArray of strings\n\narchived\n\nrequired\n\nboolean\n\nrequired\n\nobject\n\nobject\n\nobject\n\nobject\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"managedBy\": \"\",`\n    \n*   `\"dateCreated\": \"string\",`\n    \n*   `\"dateUpdated\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"datasourceId\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"type\": \"binomial\",`\n    \n*   `\"tags\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"archived\": true,`\n    \n*   `\"behavior\": {`\n    \n    *   `\"goal\": \"increase\",`\n        \n    *   `\"cappingSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"value\": 0,`\n            \n        *   `\"ignoreZeros\": true`\n            \n        \n        `},`\n        \n    *   `\"cap\": 0,`\n        \n    *   `\"capping\": \"absolute\",`\n        \n    *   `\"capValue\": 0,`\n        \n    *   `\"windowSettings\": {`\n        \n        *   `\"type\": \"none\",`\n            \n        *   `\"delayHours\": 0,`\n            \n        *   `\"windowValue\": 0,`\n            \n        *   `\"windowUnit\": \"hours\"`\n            \n        \n        `},`\n        \n    *   `\"priorSettings\": {`\n        \n        *   `\"override\": true,`\n            \n        *   `\"proper\": true,`\n            \n        *   `\"mean\": 0,`\n            \n        *   `\"stddev\": 0`\n            \n        \n        `},`\n        \n    *   `\"conversionWindowStart\": 0,`\n        \n    *   `\"conversionWindowEnd\": 0,`\n        \n    *   `\"riskThresholdSuccess\": 0,`\n        \n    *   `\"riskThresholdDanger\": 0,`\n        \n    *   `\"minPercentChange\": 0,`\n        \n    *   `\"maxPercentChange\": 0,`\n        \n    *   `\"minSampleSize\": 0`\n        \n    \n    `},`\n    \n*   `\"sql\": {`\n    \n    *   `\"identifierTypes\": [`\n        \n        *   `\"string\"`\n            \n        \n        `],`\n        \n    *   `\"conversionSQL\": \"string\",`\n        \n    *   `\"userAggregationSQL\": \"string\",`\n        \n    *   `\"denominatorMetricId\": \"string\"`\n        \n    \n    `},`\n    \n*   `\"sqlBuilder\": {`\n    \n    *   `\"identifierTypeColumns\": [`\n        \n        *   `{`\n            \n            *   `\"identifierType\": \"string\",`\n                \n            *   `\"columnName\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `],`\n        \n    *   `\"tableName\": \"string\",`\n        \n    *   `\"valueColumnName\": \"string\",`\n        \n    *   `\"timestampColumnName\": \"string\",`\n        \n    *   `\"conditions\": [`\n        \n        *   `{`\n            \n            *   `\"column\": \"string\",`\n                \n            *   `\"operator\": \"string\",`\n                \n            *   `\"value\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `},`\n    \n*   `\"mixpanel\": {`\n    \n    *   `\"eventName\": \"string\",`\n        \n    *   `\"eventValue\": \"string\",`\n        \n    *   `\"userAggregation\": \"string\",`\n        \n    *   `\"conditions\": [`\n        \n        *   `{`\n            \n            *   `\"property\": \"string\",`\n                \n            *   `\"operator\": \"string\",`\n                \n            *   `\"value\": \"string\"`\n                \n            \n            `}`\n            \n        \n        `]`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/Organization_model)Organization\n\nid\n\nstring\n\nThe Growthbook unique identifier for the organization\n\nexternalId\n\nstring\n\nAn optional identifier that you use within your company for the organization\n\ndateCreated\n\nstring <date-time\\>\n\nThe date the organization was created\n\nname\n\nstring\n\nThe name of the organization\n\nownerEmail\n\nstring\n\nThe email address of the organization owner\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"externalId\": \"string\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"ownerEmail\": \"string\"`\n    \n\n`}`\n\n## [](#tag/Project_model)Project\n\nid\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\ndescription\n\nstring\n\nobject\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"description\": \"string\",`\n    \n*   `\"settings\": {`\n    \n    *   `\"statsEngine\": \"string\"`\n        \n    \n    `}`\n    \n\n`}`\n\n## [](#tag/SavedGroup_model)SavedGroup\n\nid\n\nrequired\n\nstring\n\ntype\n\nrequired\n\nstring\n\nEnum: \"condition\" \"list\"\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\nname\n\nrequired\n\nstring\n\nowner\n\nstring\n\ncondition\n\nstring\n\nWhen type = 'condition', this is the JSON-encoded condition for the group\n\nattributeKey\n\nstring\n\nWhen type = 'list', this is the attribute key the group is based on\n\nvalues\n\nArray of strings\n\nWhen type = 'list', this is the list of values for the attribute key\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"type\": \"condition\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"condition\": \"string\",`\n    \n*   `\"attributeKey\": \"string\",`\n    \n*   `\"values\": [`\n    \n    *   `\"string\"`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/SdkConnection_model)SdkConnection\n\nid\n\nrequired\n\nstring\n\ndateCreated\n\nrequired\n\nstring <date-time\\>\n\ndateUpdated\n\nrequired\n\nstring <date-time\\>\n\nname\n\nrequired\n\nstring\n\norganization\n\nrequired\n\nstring\n\nlanguages\n\nrequired\n\nArray of strings\n\nsdkVersion\n\nstring\n\nenvironment\n\nrequired\n\nstring\n\nproject\n\nrequired\n\nstring\n\nUse 'projects' instead. This is only for backwards compatibility and contains the first project only.\n\nprojects\n\nArray of strings\n\nencryptPayload\n\nrequired\n\nboolean\n\nencryptionKey\n\nrequired\n\nstring\n\nincludeVisualExperiments\n\nboolean\n\nincludeDraftExperiments\n\nboolean\n\nincludeExperimentNames\n\nboolean\n\nincludeRedirectExperiments\n\nboolean\n\nkey\n\nrequired\n\nstring\n\nproxyEnabled\n\nrequired\n\nboolean\n\nproxyHost\n\nrequired\n\nstring\n\nproxySigningKey\n\nrequired\n\nstring\n\nsseEnabled\n\nboolean\n\nhashSecureAttributes\n\nboolean\n\nremoteEvalEnabled\n\nboolean\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"dateCreated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"dateUpdated\": \"2019-08-24T14:15:22Z\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"organization\": \"string\",`\n    \n*   `\"languages\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"sdkVersion\": \"string\",`\n    \n*   `\"environment\": \"string\",`\n    \n*   `\"project\": \"string\",`\n    \n*   `\"projects\": [`\n    \n    *   `\"string\"`\n        \n    \n    `],`\n    \n*   `\"encryptPayload\": true,`\n    \n*   `\"encryptionKey\": \"string\",`\n    \n*   `\"includeVisualExperiments\": true,`\n    \n*   `\"includeDraftExperiments\": true,`\n    \n*   `\"includeExperimentNames\": true,`\n    \n*   `\"includeRedirectExperiments\": true,`\n    \n*   `\"key\": \"string\",`\n    \n*   `\"proxyEnabled\": true,`\n    \n*   `\"proxyHost\": \"string\",`\n    \n*   `\"proxySigningKey\": \"string\",`\n    \n*   `\"sseEnabled\": true,`\n    \n*   `\"hashSecureAttributes\": true,`\n    \n*   `\"remoteEvalEnabled\": true`\n    \n\n`}`\n\n## [](#tag/Segment_model)Segment\n\nid\n\nrequired\n\nstring\n\nowner\n\nrequired\n\nstring\n\ndatasourceId\n\nrequired\n\nstring\n\nidentifierType\n\nrequired\n\nstring\n\nname\n\nrequired\n\nstring\n\nquery\n\nrequired\n\nstring\n\ndateCreated\n\nrequired\n\nstring\n\ndateUpdated\n\nrequired\n\nstring\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"owner\": \"string\",`\n    \n*   `\"datasourceId\": \"string\",`\n    \n*   `\"identifierType\": \"string\",`\n    \n*   `\"name\": \"string\",`\n    \n*   `\"query\": \"string\",`\n    \n*   `\"dateCreated\": \"string\",`\n    \n*   `\"dateUpdated\": \"string\"`\n    \n\n`}`\n\n## [](#tag/VisualChange_model)VisualChange\n\ndescription\n\ncss\n\njs\n\nvariation\n\nrequired\n\n`{`\n\n*   `\"description\": \"string\",`\n    \n*   `\"css\": \"string\",`\n    \n*   `\"js\": \"string\",`\n    \n*   `\"variation\": \"string\",`\n    \n*   `\"domMutations\": [`\n    \n    *   `{`\n        \n        *   `\"selector\": \"string\",`\n            \n        *   `\"action\": \"append\",`\n            \n        *   `\"attribute\": \"string\",`\n            \n        *   `\"value\": \"string\",`\n            \n        *   `\"parentSelector\": \"string\",`\n            \n        *   `\"insertBeforeSelector\": \"string\"`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`\n\n## [](#tag/VisualChangeset_model)VisualChangeset\n\nid\n\nrequired\n\neditorUrl\n\nrequired\n\nexperiment\n\nrequired\n\nrequired\n\n`{`\n\n*   `\"id\": \"string\",`\n    \n*   `\"urlPatterns\": [`\n    \n    *   `{`\n        \n        *   `\"include\": true,`\n            \n        *   `\"type\": \"simple\",`\n            \n        *   `\"pattern\": null`\n            \n        \n        `}`\n        \n    \n    `],`\n    \n*   `\"editorUrl\": \"string\",`\n    \n*   `\"experiment\": \"string\",`\n    \n*   `\"visualChanges\": [`\n    \n    *   `{`\n        \n        *   `\"description\": \"string\",`\n            \n        *   `\"css\": \"string\",`\n            \n        *   `\"js\": \"string\",`\n            \n        *   `\"variation\": \"string\",`\n            \n        *   `\"domMutations\": [`\n            \n            *   `{`\n                \n                *   `\"selector\": \"string\",`\n                    \n                *   `\"action\": \"append\",`\n                    \n                *   `\"attribute\": \"string\",`\n                    \n                *   `\"value\": \"string\",`\n                    \n                *   `\"parentSelector\": \"string\",`\n                    \n                *   `\"insertBeforeSelector\": \"string\"`\n                    \n                \n                `}`\n                \n            \n            `]`\n            \n        \n        `}`\n        \n    \n    `]`\n    \n\n`}`",
    "title": "GrowthBook REST API | GrowthBook Docs",
    "description": "GrowthBook offers a full REST API for interacting with the GrowthBook application. This is currently in **beta** as we add more authenticated API routes and features.\n\nRequest data can use either JSON or Form data encoding (with proper `Content-Type` headers). All response bodies are JSON-encoded.\n\nThe API base URL for GrowthBook Cloud is `https://api.growthbook.io`. For self-hosted deployments, it is the same as your API_HOST environment variable (defaults to `http://localhost:3100`). The rest of these docs will assume you are using GrowthBook Cloud.\n\n## Authentication\n\nWe support both the HTTP Basic and Bearer authentication schemes for convenience.\n\nYou first need to generate a new API Key in GrowthBook. Different keys have different permissions:\n\n- **Personal Access Tokens**: These are sensitive and provide the same level of access as the user has to an organization. These can be created by going to `Personal Access Tokens` under the your user menu.\n- **Secret Keys**: These are sensitive and provide the level of access for the role, which currently is either `admin` or `readonly`. Only Admins with the `manageApiKeys` permission can manage Secret Keys on behalf of an organization. These can be created by going to `Settings -> API Keys`\n\nIf using HTTP Basic auth, pass the Secret Key as the username and leave the password blank:\n\n```bash\ncurl https://api.growthbook.io/api/v1 \\\n  -u secret_abc123DEF456:\n# The \":\" at the end stops curl from asking for a password\n```\n\nIf using Bearer auth, pass the Secret Key as the token:\n\n```bash\ncurl https://api.growthbook.io/api/v1 \\\n-H \"Authorization: Bearer secret_abc123DEF456\"\n```\n\n## Errors\n\nThe API may return the following error status codes:\n\n- **400** - Bad Request - Often due to a missing required parameter\n- **401** - Unauthorized - No valid API key provided\n- **402** - Request Failed - The parameters are valid, but the request failed\n- **403** - Forbidden - Provided API key does not have the required access\n- **404** - Not Found - Unknown API route or requested resource\n- **429** - Too Many Requests - You exceeded the rate limit of 60 requests per minute. Try again later.\n- **5XX** - Server Error - Something went wrong on GrowthBook's end (these are rare)\n\nThe response body will be a JSON object with the following properties:\n\n- **message** - Information about the error\n",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/lib/edge/cloudflare",
    "markdown": "# Cloudflare Workers Edge App & SDK\n\n## Overview[​](#overview \"Direct link to Overview\")\n\nGrowthBook currently supports two levels of integration with most edge workers, including Cloudflare:\n\n1.  Our turnkey Edge App\n    \n    *   Automatically run server-side or hybrid [Visual Experiments](https://docs.growthbook.io/app/visual) without redraw flicker.\n    *   Automatically run server-side or hybrid [URL Redirect Experiments](https://docs.growthbook.io/app/url-redirects) without flicker or delay.\n    *   Optionally inject the JavaScript SDK with hydrated payload, allowing the front-end to pick up where the edge left off without any extra network requests. We use an enhanced version of our [HTML Script Tag](https://docs.growthbook.io/lib/script-tag) for this purpose.\n2.  Support for edge apps using our JavaScript SDK\n    \n    *   Enhanced support and examples for using our JavaScript SDK in an edge environment\n\nRegardless of your use case, our Cloudflare integration makes easy to synchronize feature and experiment values between GrowthBook and Cloudflare's KV store. This eliminates the network request to the GrowthBook API, unlocking blazingly fast edge-side and client-side SDK performance.\n\n## References[​](#references \"Direct link to References\")\n\n*   Our Cloudflare Workers SDK repository, which supports the above use cases, is [here](https://github.com/growthbook/growthbook-proxy/tree/main/packages/lib/edge-cloudflare)\n*   A turnkey implementation of the Edge App (compatible with Wrangler) is [here](https://github.com/growthbook/growthbook-proxy/tree/main/packages/lib/edge-cloudflare/example)\n*   You may find it useful to review our [JavaScript SDK](https://docs.growthbook.io/lib/js). Many of the concepts which apply to both on-edge and injected frontend SDKs are based on our JS SDK.\n\n## Worker Configuration[​](#worker-configuration \"Direct link to Worker Configuration\")\n\ntip\n\nThis tutorial assumes some familiarity with building and deploying Cloudflare Worker applications. You can quickly get up to speed by following the Cloudflare Workers [Getting Started](https://developers.cloudflare.com/workers/get-started/guide/) guide.\n\nYou may either use our turnkey Edge App for Cloudflare Workers or build your own app from scratch using our JavaScript and Cloudflare SDKs.\n\n## Turnkey Edge App[​](#turnkey-edge-app \"Direct link to Turnkey Edge App\")\n\nOur Edge App runs as a smart proxy layer between your application and your end users. In absence of Visual or URL Redirect experiments, the Edge App will simply proxy the user request to your site and return the response, optionally injecting a fully-bootstrapped JavaScript SDK onto the rendered HTML page. If the request URL matches an Visual or URL Redirect experiment and the targeting conditions are satisfied, the Edge App may also perform one or more URL redirects behind the scenes (the public-facing URL does not change) and/or mutate the DOM for Visual Experiments.\n\nURL Redirects on edge\n\nThe Edge App defaults to running URL Redirect Experiments in the browser only. This is because edge redirects load a separate page's content without altering the URL. After the redirect, some sites may experience problems with loading assets or endpoints with relative paths.\n\nYou can enable URL Redirects on edge by setting environment variable `RUN_URL_REDIRECT_EXPERIMENTS` ([see below](#environment-variables)).\n\nSetting up our turnkey Edge App is simple. Assuming that you have a basic Worker application set up, simply install the SDK and implement our custom request handler. Or if you prefer, you may pull down our fully-functional [example implementation](https://github.com/growthbook/growthbook-proxy/tree/main/packages/lib/edge-cloudflare/example) and follow along.\n\n### Install the SDK[​](#install-the-sdk \"Direct link to Install the SDK\")\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save @growthbook/edge-cloudflare\n```\n\n### Implement the Edge App request handler[​](#implement-the-edge-app-request-handler \"Direct link to Implement the Edge App request handler\")\n\nA basic implementation of our Edge App only requires a few lines of code:\n\n```\nimport { handleRequest } from \"@growthbook/edge-cloudflare\";export default {  fetch: async function (request, env, ctx) {    return await handleRequest(request, env);  },};\n```\n\n### Configure the Edge App[​](#configure-the-edge-app \"Direct link to Configure the Edge App\")\n\nUse a combination of environment variables and optional runtime configuration to add required fields and to customize the Edge App behavior.\n\n#### Environment variables[​](#environment-variables \"Direct link to Environment variables\")\n\nEdit your `wrangler.toml` file and, at minimum, add these required fields:\n\n```\n[vars]PROXY_TARGET=\"https://internal.mysite.io\"  # The non-edge URL to your websiteGROWTHBOOK_API_HOST=\"https://cdn.growthbook.io\"GROWTHBOOK_CLIENT_KEY=\"sdk-abc123\"GROWTHBOOK_DECRYPTION_KEY=\"key_abc123\"  # Only include for encrypted SDK Connections\n```\n\nYou may want to further customize the app. Here is a list of common customization variables:\n\n```\n# Disable or change the rendering behavior of Visual Experiments:# ==========RUN_VISUAL_EDITOR_EXPERIMENTS=\"everywhere\"|\"edge\"|\"browser\"|\"skip\"  # default: \"everywhere\"# URL Redirect Experiments are disabled on edge by default. Because the URL does not change, some sites# may experience problems with loading assets or endpoints with relative paths:# ==========RUN_URL_REDIRECT_EXPERIMENTS=\"everywhere\"|\"edge\"|\"browser\"|\"skip\"  # default: \"browser\"RUN_CROSS_ORIGIN_URL_REDIRECT_EXPERIMENTS=\"everywhere\"|\"edge\"|\"browser\"|\"skip\"  # default: \"browser\"# Mutate browser URL via window.history.replaceState() to reflect the new URL:INJECT_REDIRECT_URL_SCRIPT=\"true\"  # default \"true\".# Do not inject a bootstrapped JavaScript SDK onto the page:# ==========DISABLE_INJECTIONS=\"true\"  # default \"false\"# Customize the edge or injected browser SDK behavior:# ==========ENABLE_STREAMING=\"true\"  # default \"false\". Streaming SSE updates on browser.ENABLE_STICKY_BUCKETING=\"true\"  # default \"false\". Use cookie-based sticky bucketing on edge and browser.\n```\n\n#### Runtime configuration[​](#runtime-configuration \"Direct link to Runtime configuration\")\n\nYou may want to provide context to your edge app at runtime rather than using environment variables. For example, if you have additional [targeting attributes](https://docs.growthbook.io/lib/js#attributes) available, you may inject them by modifying your request handler code:\n\n```\nimport { handleRequest } from \"@growthbook/edge-cloudflare\";import { parse } from \"cookie\";export default {  fetch: async function (request, env, ctx) {    const cookie = parse(request.headers.get(\"Cookie\") || \"\");    const config = {      attributes: {        userType: cookie[\"userId\"] ? \"logged in\" : \"anonymous\"      }    };    return await handleRequest(request, env, config);  },};\n```\n\n#### More customization options[​](#more-customization-options \"Direct link to More customization options\")\n\nFor a full list of customizations, view our vendor-agnostic [Edge Utility repository](https://github.com/growthbook/growthbook-proxy/tree/main/packages/lib/edge-utils) .\n\n### Set up a Payload Cache[​](#set-up-a-payload-cache \"Direct link to Set up a Payload Cache\")\n\nYou can configure GrowthBook payload caching by using a [Cloudflare KV](https://developers.cloudflare.com/kv/reference/how-kv-works/) store. This eliminates network requests from your edge to GrowthBook which speeds up page delivery while reducing network costs.\n\nOur Cloudflare Edge App will automatically use either webhook-based or just-in-time payload caching (or both) depending on how you've set up your KV namespaces, bindings, and SDK Webhooks.\n\nMore information about setting up your payload cache can be found in the [Payload Caching with Cloudflare KV Store](#payload-caching-with-cloudflare-kv-store) doc section below.\n\n### Tracking Experiment Views[​](#tracking-experiment-views \"Direct link to Tracking Experiment Views\")\n\nRunning A/B tests requires a [tracking callback](https://docs.growthbook.io/lib/js#experimentation-ab-testing). Our turnkey Edge App defaults to using built-in front-end tracking. The tracking call automatically integrates with Segment.io, GA4, and Google Tag Manager by using the mechanism outlined in our [HTML Script Tag](https://docs.growthbook.io/lib/script-tag#tracking-experiment-views). In order to do this, the app keeps track of tracking calls triggered on edge and injects them into the front-end SDK to be automatically triggered on page load.\n\nYou may wish to either customize front-end tracking or switch to edge tracking (or use both concurrently if running hybrid edge + front-end experiments).\n\nWhy might you be interested in tracking on edge? Tracking on an edge or backend environment allows you to ensure the callback is fired before any differentiation across variations, eliminating experimental bias. While not eliminating this risk, the default injected front-end tracking introduced by our Edge App does reduce this risk relative to solely using a front-end SDK.\n\nTo change the front-end tracking callback, set the `GROWTHBOOK_TRACKING_CALLBACK` to your custom tracking JS code:\n\n```\n# todo: replace with your own tracking libraryGROWTHBOOK_TRACKING_CALLBACK=\"(experiment, results) => { console.log('browser tracking callback', {experiment, results}); }\"\n```\n\nTo track on edge, you must inject your own tracking callback into the edge request handler code. Any experiments that run on edge will use the edge tracking callback and not the front-end callback (hybrid edge + front-end experiments being an exception):\n\n```\nimport { handleRequest } from \"@growthbook/edge-cloudflare\";export default {  fetch: async function (request, env, ctx) {    const config = {      edgeTrackingCallback: (experiment, results) => {        // todo: replace with your tracking library        console.log('edge tracking callback', {experiment, results});      }    };    return await handleRequest(request, env, config);  },};\n```\n\n### Targeting Attributes[​](#targeting-attributes \"Direct link to Targeting Attributes\")\n\nThe following targeting attributes are set automatically by the Edge App.\n\n*   `id` - creates a long-lived `gbuuid` cookie if it doesn't exist already\n*   `url`\n*   `path`\n*   `host`\n*   `query`\n*   `pageTitle`\n*   `deviceType` - either `mobile` or `desktop`\n*   `browser` - one of `chrome`, `edge`, `firefox`, `safari`, or `unknown`\n*   `utmSource`\n*   `utmMedium`\n*   `utmCampaign`\n*   `utmTerm`\n*   `utmContent`\n\nYou can customize both the primary identifier name (`id`) and cookie name (`gbuuid`) by setting the `UUID_KEY` and `UUID_COOKIE_NAME` environment variables respectively.\n\nAs shown in the [runtime configuration](#runtime-configuration) section above, you can also pass custom attributes via runtime config. You can also skip automatic attribute generation and rely solely on custom attributes by setting the environment variable `SKIP_AUTO_ATTRIBUTES=\"true\"`.\n\n### Routing[​](#routing \"Direct link to Routing\")\n\nBy default, the Edge App will process all `GET` requests (other HTTP verbs are proxied through without running through our app logic).\n\nIt is generally preferable to configure your routing rules outside of our Edge App. For instance, you may only want to invoke the Edge App at `https://yourdomain.io/landing-page`. You can configure Cloudflare routing by following the Cloudflare Workers [Routes](https://developers.cloudflare.com/workers/configuration/routing/routes/) documentation.\n\nThere may be situations when you will need to provide finer-grained routing / URL targeting rules within our Edge App. You will need to include a JSON encoded string of route rules in your `ROUTES` environment variable.\n\nFor instance, you may want to do a proxy pass-through (do not process) for `mysite.io/account/*` or `mysite.io/settings/*`. Your routes may look like this:\n\n```\nROUTES='[{ \"pattern\":\"mysite.io/account/*\", \"behavior\":\"proxy\" }, { \"pattern\":\"mysite.io/settings/*\", \"behavior\":\"proxy\" }]'\n```\n\nA route uses the following interface, with many of the properties being optional:\n\n```\n{  pattern: string;  type?: \"regex\" | \"simple\";  // default: \"simple\"  behavior?: \"intercept\" | \"proxy\" | \"error\";  // default: \"intercept\"  includeFileExtensions?: boolean;  // Include requests to filenames like \"*.jpg\". default: false (pass-through).  statusCode?: number; // Alter the status code (default is 404 when using \"error\")  body?: string; // Alter the body (for setting an error message body)}\n```\n\nWhen multiple routes are included in your `ROUTES` array, only the first match is used.\n\n### Cookie Policy and GDPR[​](#cookie-policy-and-gdpr \"Direct link to Cookie Policy and GDPR\")\n\nBy default, the Edge App will persist a random unique identifier in a first-party cookie named `gbuuid`. Its purpose is to provide a consistent user experience to your visitors by preventing them from being re-bucketed into different A/B test variations. It follows the same mechanism as discussed in our [HTML Script Tag docs](https://docs.growthbook.io/lib/script-tag#cookie-policy-and-gdpr).\n\n#### Delay Storing the Cookie Until Consent is Granted[​](#delay-storing-the-cookie-until-consent-is-granted \"Direct link to Delay Storing the Cookie Until Consent is Granted\")\n\nIf you must delay persisting the `gbuuid` cookie until a user consents, you can set the environment variable `NO_AUTO_COOKIES=\"true\"`.\n\nThis will still generate a UUID for the user, but will not persist it. That means, if the user refreshes the page, they will have a new random UUID generated.environment\n\nYou have the option to manually persist this cookie at any time, for example when a user grants consent on your cookie banner. All you need to do is fire this custom event from javascript on the rendered page:\n\n```\ndocument.dispatchEvent(new CustomEvent(\"growthbookpersist\"));\n```\n\nnote\n\nIf you are using Sticky Bucketing, a persistent sticky bucket assignments cookie will automatically be generated. If you require user permission before writing cookies, you should:\n\n*   Either do not enable Sticky Bucketing on edge (do not use `ENABLE_STICKY_BUCKETING`)\n*   Or only enable Sticky Bucketing per each user via runtime configuration. (only pass `config.enableStickyBucketing: true` if user has consented — identifiable by checking for presence of the `gbuuid` cookie).\n\n## Manual SDK Integration on Edge[​](#manual-sdk-integration-on-edge \"Direct link to Manual SDK Integration on Edge\")\n\nYou may be interested in building your own edge application using the GrowthBook SDK and not using our turnkey Edge App. Or you may want to do custom feature flagging on specific routes while running our Edge App on other routes.\n\nTo use the GrowthBook on edge, simply include our standard [JavaScript SDK](https://docs.growthbook.io/lib/js) (`@growthbook/growthbook` NPM package).\n\nIn our `@growthbook/edge-cloudflare` NPM package, we export a few Cloudflare-specific utility functions to simplify SDK payload caching (we discuss payload caching strategies in the subsequent doc section).\n\n```\nimport { GrowthBook, setPolyfills } from \"@growthbook/growthbook\";import { getPayloadFromKV, getKVLocalStoragePolyfill } from \"@growthbook/edge-cloudflare\";export default {  async fetch(request) {    // 1. Init the GrowthBook SDK and choose an optional caching strategy    // A. Use the KV as a managed payload store to eliminate SDK requests to the GrowthBook API entirely.    // Requires setting up an SDK Webhook.    const payload = await getPayloadFromKV(env);    const growthbook = new GrowthBook(gbContext);    await growthbook.init({ payload: payload });    // B. Or provide a KV cache layer so that the GrowthBook SDK doesn't need to make as many requests    // to the GrowthBook API. No SDK Webhook needed.    const localStoragePolyfill = getKVLocalStoragePolyfill(env);    setPolyfills({ localStorage: localStoragePolyfill });    await growthbook.init();    // 2. Start feature flagging    if (growthbook.isOn(\"my-feature\")) {      return new Response(\"<h1>foo</h1>\");    }    return new Response(\"<h1>bar</h1>\");  }}\n```\n\n## Payload Caching with Cloudflare KV Store[​](#payload-caching-with-cloudflare-kv-store \"Direct link to Payload Caching with Cloudflare KV Store\")\n\nBy default, the Edge App will make a network request to the GrowthBook API on each user request in order to fetch the current feature and experiment values. This is a blocking call that delays page delivery. There is an in-memory short-lived cache layer on this call, but it won't always protect you.\n\nConvenient solutions this problem are realized through [Cloudflare KV](https://developers.cloudflare.com/kv/reference/how-kv-works/) , an on-edge key-val store which we can leverage for persistent payload caching. There are 2 levels of KV integration available:\n\n1.  You can either completely eliminate the blocking call to the GrowthBook API by implementing a GrowthBook-to-Cloudflare-KV push model via **SDK Webhooks**.\n2.  Alternatively, you can eliminate most of these network requests by using Cloudflare KV as a just-in-time payload cache.\n\nYou can also use either of these strategies in your own manual SDK integration via the `getPayloadFromKV` and `getKVLocalStoragePolyfill` utility functions.\n\n### Configuring the KV store[​](#configuring-the-kv-store \"Direct link to Configuring the KV store\")\n\nCreate a Cloudflare KV namespace for your worker to interface with. You can do this either using the Cloudflare dashboard or via Wrangler commands. By default, the GrowthBook Edge App and KV utility functions use the following KV namespaces; you only need to choose one, not both, depending on your desired level of integration:\n\n1.  KV stored payloads: `KV_GB_PAYLOAD`\n2.  KV payload cache: `KV_GB_CACHE`\n\nFor KV stored payloads (1), we also assume a KV key of `\"gb_payload\"`. You will likely not need to modify this, but for manual implementations both the namespace and key can be specified in the utility functions.\n\nYou must also create a KV binding so that your Cloudflare Worker can access the KV namespace. Edit your `wrangler.toml` file to add the binding:\n\n```\n# You probably do not need both bindings:kv_namespaces = [  { binding = \"KV_GB_PAYLOAD\", id = \"abcdefg1234567\" },  { binding = \"KV_GB_CACHE\", id = \"qwertyuiop12345\" }][vars]...\n```\n\n### Configuring a SDK Webhook[​](#configuring-a-sdk-webhook \"Direct link to Configuring a SDK Webhook\")\n\nFor KV stored payloads (1), we eliminate network requests from edge to GrowthBook by using a GrowthBook SDK Webhook to push the SDK payload to the KV store on change.\n\n1.  Create an [SDK Webhook](https://docs.growthbook.io/app/webhooks/sdk-webhooks) on the same SDK Connection that you are using for edge integration. You do not need to worry about the receiving end of the webhook (verifying GrowthBook signatures, etc).\n2.  Set the **Endpoint URL** to the Cloudflare's REST API endpoint for KV. At the time of writing, it follows this format:\n\n```\nhttps://api.cloudflare.com/client/v4/accounts/{accountId}/storage/kv/namespaces/{namespaceId}/values/gb_payload\n```\n\n3.  Change the **Method** to `PUT`.\n4.  Add appropriate authorization header:\n\n```\n{  \"Authorization\": \"Bearer YOUR_CF_REST_API_TOKEN\"}\n```\n\n5.  Set the **Payload format** to \"SDK Payload only\".\n\nNow whenever feature and experiment values change, your Cloudflare worker will have immediate access to the latest values. You can also test the webhook by using the \"Test Webhook\" button on the SDK Connection page.",
    "title": "Cloudflare Workers Edge App & SDK | GrowthBook Docs",
    "description": "GrowthBook SDK for Cloudflare Workers",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/lib/build-your-own",
    "markdown": "# Build Your Own | GrowthBook Docs\n\n**Latest spec version: 0.7.0 [View Changelog](#changelog)**\n\nThis guide is meant for library authors looking to build a GrowthBook SDK in a currently unsupported language.\n\nAll libraries should follow this specification as closely as the language permits to maintain consistency and make updates and maintenance easier.\n\nAt the end of this guide is an extensive test suite with over 400 language-agnostic unit tests in JSON format. All SDKs must pass 100% of these test cases. It's recommended to add additional manual unit tests as needed on top of these.\n\n## Data structures[​](#data-structures \"Direct link to Data structures\")\n\nHere are a number of important data structures in GrowthBook SDKs, listed alphabetically.\n\n### Attributes[​](#attributes \"Direct link to Attributes\")\n\n**Attributes** are an arbitrary JSON object containing user and request attributes. Here's an example:\n\n```\n{  \"id\": \"123\",  \"anonId\": \"abcdef\",  \"company\": \"growthbook\",  \"url\": \"/pricing\",  \"country\": \"US\",  \"browser\": \"firefox\",  \"age\": 25,  \"beta\": true,  \"account\": {    \"plan\": \"team\",    \"seats\": 10  }}\n```\n\n### BucketRange[​](#bucketrange \"Direct link to BucketRange\")\n\nA tuple that describes a range of the numberline between `0` and `1`.\n\nThe tuple has 2 parts, both floats - the start of the range and the end. For example:\n\n### Condition[​](#condition \"Direct link to Condition\")\n\nA **Condition** is evaluated against **Attributes** and used to target features/experiments to specific users.\n\nThe syntax is inspired by MongoDB queries. Here is an example:\n\n```\n{  \"country\": \"US\",  \"browser\": {    \"$in\": [\"firefox\", \"chrome\"]  },  \"email\": {    \"$not\": {      \"$regex\": \"@gmail.com$\"    }  }}\n```\n\n### ParentCondition[​](#parentcondition \"Direct link to ParentCondition\")\n\nA **ParentCondition** defines a prerequisite. It consists of a parent feature's **id** (`string`), a **condition** (`Condition`), and an optional **gate** (`boolean`) flag.\n\nInstead of evaluating against attributes, the condition evaluates against the returned value of the parent feature. The condition will always reference a \"value\" property. Here is an example of a gating prerequisite where the parent feature must be on (`true`)\n\n```\n{  \"id\": \"parent-feature\",  \"condition\": {    \"value\": {      \"$eq\": true    }  },  \"gate\": true}\n```\n\n### Context[​](#context \"Direct link to Context\")\n\n**Context** object passed into the GrowthBook constructor. Has a number of optional properties:\n\n*   **enabled** (`boolean`) - Switch to globally disable all experiments. Default true.\n*   **apiHost** (`string`) - The GrowthBook API Host. Optional\n*   **clientKey** (`string`) - The key used to fetch features from the GrowthBook API. Optional\n*   **decryptionKey** (`string`) - The key used to decrypt encrypted features from the API. Optional\n*   **attributes** (`Attributes`) - Map of user attributes that are used to assign variations\n*   **url** (`string`) - The URL of the current page\n*   **features** (`FeatureMap`) - Feature definitions (usually pulled from an API or cache)\n*   **forcedVariations** (`ForcedVariationsMap`) - Force specific experiments to always assign a specific variation (used for QA)\n*   **qaMode** (`boolean`) - If true, random assignment is disabled and only explicitly forced variations are used.\n*   **trackingCallback** (`TrackingCallback`) - A function that takes `experiment` and `result` as arguments.\n\n### Experiment[​](#experiment \"Direct link to Experiment\")\n\nDefines a single **Experiment**. Has a number of properties:\n\n*   **key** (`string`) - The globally unique identifier for the experiment\n*   **variations** (`any[]`) - The different variations to choose between\n*   **weights** (`float[]`) - How to weight traffic between variations. Must add to 1.\n*   **active** (`boolean`) - If set to false, always return the control (first variation)\n*   **coverage** (`float`) - What percent of users should be included in the experiment (between 0 and 1, inclusive)\n*   **ranges** (`BucketRange[]`) - Array of ranges, one per variation\n*   **condition** (`Condition`) - Optional targeting condition\n*   **namespace** (`Namespace`) - Adds the experiment to a namespace\n*   **force** (`integer`) - All users included in the experiment will be forced into the specific variation index\n*   **hashAttribute** (`string`) - What user attribute should be used to assign variations (defaults to `id`)\n*   **fallbackAttribute** (`string`) - When using sticky bucketing, can be used as a fallback to assign variations\n*   **hashVersion** (`integer`) - The hash version to use (default to `1`)\n*   **meta** (`VariationMeta[]`) - Meta info about the variations\n*   **filters** (`Filter[]`) - Array of filters to apply\n*   **seed** (`string`) - The hash seed to use\n*   **name** (`string`) - Human-readable name for the experiment\n*   **phase** (`string`) - Id of the current experiment phase\n*   **disableStickyBucketing** (`boolean`) - If true, sticky bucketing will be disabled for this experiment. (Note: sticky bucketing is only available if a StickyBucketingService is provided in the Context)\n*   **bucketVersion** (`integer`) - An sticky bucket version number that can be used to force a re-bucketing of users (default to `0`)\n*   **minBucketVersion** (`integer`) - Any users with a sticky bucket version less than this will be excluded from the experiment\n\nThe only required properties are `key` and `variations`. Everything else is optional.\n\n### ExperimentResult[​](#experimentresult \"Direct link to ExperimentResult\")\n\nThe result of running an **Experiment** given a specific **Context**\n\n*   **inExperiment** (`boolean`) - Whether or not the user is part of the experiment\n*   **variationId** (`int`) - The array index of the assigned variation\n*   **value** (`any`) - The array value of the assigned variation\n*   **hashUsed** (`boolean`) - If a hash was used to assign a variation\n*   **hashAttribute** (`string`) - The user attribute used to assign a variation\n*   **hashValue** (`string`) - The value of that attribute\n*   **featureId** (`string` or `null`) - The id of the feature (if any) that the experiment came from\n*   **key** (`string`) - The unique key for the assigned variation\n*   **bucket** (`float`) - The hash value used to assign a variation (float from `0` to `1`)\n*   **name** (`string` or `null`) - The human-readable name of the assigned variation\n*   **passthrough** (`boolean`) - Used for holdout groups\n*   **stickyBucketUsed** (`boolean`) - If sticky bucketing was used to assign a variation\n\nThe `variationId` and `value` should always be set, even when `inExperiment` is false.\n\nThe `hashAttribute` and `hashValue` should always be set, even when `hashUsed` is false.\n\nThe `key` should always be set, even if `experiment.meta` is not defined or incomplete. In that case, convert the variation's array index to a string (e.g. `0` -> `\"0\"`) and use that as the `key` instead.\n\n### Feature[​](#feature \"Direct link to Feature\")\n\nA **Feature** object consists of a default value plus rules that can override the default.\n\n*   **defaultValue** (`any`) - The default value (should use `null` if not specified)\n*   **rules** (`FeatureRule[]`) - Array of **FeatureRule** objects that determine when and how the defaultValue gets overridden\n\n### FeatureMap[​](#featuremap \"Direct link to FeatureMap\")\n\nA hash or map of **Feature** objects. Keys are string ids for the features. Values are **Feature** objects. For example:\n\n```\n{  \"feature-1\": {    \"defaultValue\": false  },  \"my_other_feature\": {    \"defaultValue\": 1,    \"rules\": [      {        \"force\": 2      }    ]  }}\n```\n\n### FeatureResult[​](#featureresult \"Direct link to FeatureResult\")\n\nThe result of evaluating a **Feature**. Has a number of properties:\n\n*   **value** (`any`) - The assigned value of the feature\n*   **on** (`boolean`) - The assigned value cast to a boolean\n*   **off** (`boolean`) - The assigned value cast to a boolean and then negated\n*   **source** (`enum`) - One of \"unknownFeature\", \"defaultValue\", \"force\", or \"experiment\"\n*   **experiment** (`Experiment` or `null`) - When source is \"experiment\", this will be an Experiment object\n*   **experimentResult** (`ExperimentResult` or `null`) - When source is \"experiment\", this will be an ExperimentResult object\n\n### FeatureRule[​](#featurerule \"Direct link to FeatureRule\")\n\nOverrides the defaultValue of a **Feature**. Has a number of optional properties\n\n*   **id** (`string`) - Optional rule id, reserved for future use\n*   **condition** (`Condition`) - Optional targeting condition\n*   **parentConditions** (`ParentCondition[]`) - Each item defines a prerequisite where a `condition` must evaluate against a parent feature's value (identified by `id`). If `gate` is true, then this is a blocking feature-level prerequisite; otherwise it applies to the current rule only.\n*   **coverage** (`float`) - What percent of users should be included in the experiment (between 0 and 1, inclusive)\n*   **force** (`any`) - Immediately force a specific value (ignore every other option besides condition and coverage)\n*   **variations** (`any[]`) - Run an experiment (A/B test) and randomly choose between these variations\n*   **key** (`string`) - The globally unique tracking key for the experiment (default to the feature key)\n*   **weights** (`float[]`) - How to weight traffic between variations. Must add to 1.\n*   **namespace** (`Namespace`) - Adds the experiment to a namespace\n*   **hashAttribute** (`string`) - What user attribute should be used to assign variations (defaults to `id`)\n*   **hashVersion** (`integer`) - The hash version to use (default to `1`)\n*   **range** (`BucketRange`) - A more precise version of `coverage`\n*   **ranges** (`BucketRange[]`) - Ranges for experiment variations\n*   **meta** (`VariationMeta[]`) - Meta info about the experiment variations\n*   **filters** (`Filter[]`) - Array of filters to apply to the rule\n*   **seed** (`string`) - Seed to use for hashing\n*   **name** (`string`) - Human-readable name for the experiment\n*   **phase** (`string`) - The phase id of the experiment\n*   **tracks** (`TrackData[]`) - Array of tracking calls to fire\n\n### Filter[​](#filter \"Direct link to Filter\")\n\nObject used for mutual exclusion and filtering users out of experiments based on random hashes. Has the following properties:\n\n*   **seed** (`string`) - The seed used in the hash\n*   **ranges** (`BucketRange[]`) - Array of ranges that are included\n*   **hashVersion** (`integer`) - The hash version to use (default to `2`)\n*   **attribute** (`string`, optional) - The attribute to use (default to `\"id\"`)\n\n### ForcedVariationsMap[​](#forcedvariationsmap \"Direct link to ForcedVariationsMap\")\n\nA hash or map that forces an **Experiment** to always assign a specific variation. Useful for QA.\n\nKeys are the experiment key, values are the array index of the variation. For example:\n\n```\n{  \"my-test\": 0,  \"other-test\": 1}\n```\n\n### Namespace[​](#namespace \"Direct link to Namespace\")\n\nA tuple that specifies what part of a namespace an experiment includes. If two experiments are in the same namespace and their ranges don't overlap, they wil be mutually exclusive.\n\nThe tuple has 3 parts:\n\n1.  The namespace id (`string`)\n2.  The beginning of the range (`float`, between `0` and `1`)\n3.  The end of the range (`float`, between `0` and `1`)\n\nFor example:\n\n### TrackingCallback[​](#trackingcallback \"Direct link to TrackingCallback\")\n\nA callback function that is executed every time a user is included in an **Experiment**. Here's an example:\n\n```\nfunction track(experiment, result) {  analytics.track(\"Experiment Viewed\", {    experimentId: experiment.key,    variationId: result.variationId,  });}\n```\n\n### TrackData[​](#trackdata \"Direct link to TrackData\")\n\nUsed for remote feature evaluation to trigger the `TrackingCallback`. An object with 2 properties:\n\n*   **experiment** - `Experiment`\n*   **result** - `ExperimentResult`\n\n### VariationMeta[​](#variationmeta \"Direct link to VariationMeta\")\n\nMeta info about an experiment variation. Has the following properties:\n\n*   **key** (`string`, optional) - A unique key for this variation\n*   **name** (`string`, optional) - A human-readable name for this variation\n*   **passthrough** (`boolean`, optional) - Used to implement holdout groups\n\n## Helper Functions[​](#helper-functions \"Direct link to Helper Functions\")\n\nThere are some helper functions which are used a few times throughout the SDK.\n\n### hash(seed: string, value: string, version: integer): float|null[​](#hashseed-string-value-string-version-integer-floatnull \"Direct link to hash(seed: string, value: string, version: integer): float|null\")\n\nHashes a string to a float between 0 and 1.\n\nUses the simple [Fowler–Noll–Vo](https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function) algorithm, specifically fnv32a. An implementation of this is available in most languages already, and if not it's only a few lines of code to implement yourself. Fnv32a returns an integer, so we convert that to a float using a modulus.\n\nThe original hash version (1) had a flaw that caused bias when running experiments in parallel.\n\n```\n// New hashing algorithmif (version === 2) {  n = fnv32a(fnv32a(seed + value) + \"\");  return (n % 10000) / 10000;}// Original hashing algorithm (with a bias flaw)else if (version === 1) {  n = fnv32a(value + seed);  return (n % 1000) / 1000;}return null;\n```\n\n**Note**: It's important to use the exact hashing algorithms outlined here so all SDKs behave identically.\n\n### inRange(n: float, range: BucketRange): boolean[​](#inrangen-float-range-bucketrange-boolean \"Direct link to inRange(n: float, range: BucketRange): boolean\")\n\nDetermines if a number `n` is within the provided range.\n\n```\nreturn n >= range[0] && n < range[1]>;\n```\n\n### inNamespace(userId: string, namespace: Namespace): boolean[​](#innamespaceuserid-string-namespace-namespace-boolean \"Direct link to inNamespace(userId: string, namespace: Namespace): boolean\")\n\nThis checks if a userId is within an experiment namespace or not.\n\nThe `namespace` argument is a tuple with 3 parts: id (string), start (float), and end (float).\n\n1.  Hash the userId and namespace name with two underscores as a delimiter\n    \n    ```\n    n = hash(\"__\" + namespace[0], userId, 1);\n    ```\n    \n2.  Return if hash is greater than (inclusive) the namespace start and less than (exclusive) the namespace end:\n    \n    ```\n    return n >= namespace[1] && n < namespace[2];\n    ```\n    \n\n### getEqualWeights(numVariations: integer): float\\[\\][​](#getequalweightsnumvariations-integer-float \"Direct link to getEqualWeights(numVariations: integer): float[]\")\n\nReturns an array of floats with `numVariations` items that are all equal and sum to 1. For example, `getEqualWeights(2)` would return `[0.5, 0.5]`.\n\nIt's ok if the sum is slightly off due to rounding. So a sum of `0.9999999` is fine for example.\n\n1.  If numVariations is less than 1, return empty array\n2.  Create array with a length of `numVariations`\n3.  Fill the array with `1.0/numVariations` and return\n\n### getBucketRanges(numVariations: integer, coverage: float, weights: float\\[\\]): BucketRange\\[\\][​](#getbucketrangesnumvariations-integer-coverage-float-weights-float-bucketrange \"Direct link to getBucketRanges(numVariations: integer, coverage: float, weights: float[]): BucketRange[]\")\n\nThis converts and experiment's coverage and variation weights into an array of bucket ranges.\n\n`numVariations` is an integer, `coverage` is a float, and `weights` is an array of floats.\n\n1.  Clamp the value of `coverage` to between 0 and 1 inclusive.\n    \n    ```\n    if (coverage < 0) coverage = 0;if (coverage > 1) coverage = 1;\n    ```\n    \n2.  Default to equal weights if the weights don't match the number of variations.\n    \n    ```\n    if (weights.length != numVariations) {  weights = getEqualWeights(numVariations);}\n    ```\n    \n3.  Default to equal weights if the sum is not equal `1` (or close enough when rounding errors are factored in):\n    \n    ```\n    if (sum(weights) < 0.99 || sum(weights) > 1.01) {  weights = getEqualWeights(numVariations);}\n    ```\n    \n4.  Convert weights to ranges and return\n    \n    ```\n    cumulative = 0;ranges = [];for (w in weights) {  start = cumulative;  cumulative += w;  ranges.push([start, start + coverage * w]);}return ranges;\n    ```\n    \n\nSome examples:\n\n*   `getBucketRanges(2, 1, [0.5, 0.5])` -> `[[0, 0.5], [0.5, 1]]`\n*   `getBucketRanges(2, 0.5, [0.4, 0.6])` -> `[[0, 0.2], [0.4, 0.7]]`\n\n### chooseVariation(n: float, ranges: BucketRange\\[\\]): integer[​](#choosevariationn-float-ranges-bucketrange-integer \"Direct link to chooseVariation(n: float, ranges: BucketRange[]): integer\")\n\nGiven a hash and bucket ranges, assign one of the bucket ranges.\n\n1.  Loop through ranges\n    1.  If n is within the range, return the range index\n        \n        ```\n        if (inRange(n, ranges[i])) {  return i;}\n        ```\n        \n2.  Return `-1` if it makes it through the whole ranges array without returning\n\nIf multiple ranges match, return the first matching one.\n\n### getQueryStringOverride(id: string, url: string, numVariations: integer): null|integer[​](#getquerystringoverrideid-string-url-string-numvariations-integer-nullinteger \"Direct link to getQueryStringOverride(id: string, url: string, numVariations: integer): null|integer\")\n\nThis checks if an experiment variation is being forced via a URL query string. This may not be applicable for all SDKs (e.g. mobile).\n\nAs an example, if the id is `my-test` and url is `http://localhost/?my-test=1`, you would return `1`.\n\nIf possible, you should use a proper URL parsing library vs relying on simple regexes.\n\nReturn `null` if any of these are true:\n\n*   There is no querystring\n*   The id is not a key in the querystring\n*   The variation is not an integer\n*   The variation is less than 0 or greater than or equal to numVariations\n\n### decrypt(encryptedString: string, decryptionKey: string): string[​](#decryptencryptedstring-string-decryptionkey-string-string \"Direct link to decrypt(encryptedString: string, decryptionKey: string): string\")\n\nThis decrypts a string using the AES-CBC 128KB algorithm. This is used if the GrowthBook App is configured to encrypt feature flag definitions.\n\nHere's an example in PHP:\n\n```\nfunction decrypt(string $encryptedString, string $decryptionKey) {  // Split the string into two parts, delimited by \".\"  list($iv, $cipherText) = explode(\".\", $encryptedString, 2);  // The Initialization Vector (iv) is base64 encoded  $iv = base64_decode($iv);  // Decrypt using the AES-CBC 128kb algorithm  // Will throw an Exception if unable to decrypt  return openssl_decrypt($cipherText, \"aes-128-cbc\", $decryptionKey, 0, $iv);}\n```\n\nThe return value will be a JSON-encoded string. If an error occurs, you can throw an exception (or whatever is typically used for error handling).\n\n## Evaluating Conditions[​](#evaluating-conditions \"Direct link to Evaluating Conditions\")\n\nIn addition to the helper functions above, there are a number of methods related to evaluating targeting conditions.\n\nThere is only one public method `evalCondition` and everything else is a private helper function.\n\n### public evalCondition(attributes: Attributes, condition: Condition): boolean[​](#public-evalconditionattributes-attributes-condition-condition-boolean \"Direct link to public evalCondition(attributes: Attributes, condition: Condition): boolean\")\n\nThis is the main function used to evaluate a condition. It loops through the condition key/value pairs and checks each entry:\n\n1.  If condition key is `$or`, check if `evalOr(attributes, condition[\"$or\"])` is false. If so, break out of the loop and return false\n2.  If condition key is `$nor`, check if `!evalOr(attributes, condition[\"$nor\"])` is false. If so, break out of the loop and return false\n3.  If condition key is `$and`, check if `evalAnd(attributes, condition[\"$and\"])` is false. If so, break out of the loop and return false\n4.  If condition key is `$not`, check if `!evalCondition(attributes, condition[\"$not\"])` is false. If so, break out of the loop and return false\n5.  Otherwise, check if `evalConditionValue(value, getPath(attributes, key))` is false. If so, break out of the loop and return false\n\nIf none of the entries failed their checks, `evalCondition` returns true\n\n### private evalOr(attributes: Attributes, conditions: Condition\\[\\]): boolean[​](#private-evalorattributes-attributes-conditions-condition-boolean \"Direct link to private evalOr(attributes: Attributes, conditions: Condition[]): boolean\")\n\n`conditions` is an array of Condition objects\n\n1.  If conditions is empty, return true\n2.  Loop through conditions\n    1.  If `evalCondition(attributes, conditions[i])` is true, break out of the loop and return true\n3.  Return false\n\n### private evalAnd(attributes: Attributes, conditions: Condition\\[\\]): boolean[​](#private-evalandattributes-attributes-conditions-condition-boolean \"Direct link to private evalAnd(attributes: Attributes, conditions: Condition[]): boolean\")\n\n`conditions` is an array of Condition objects\n\n1.  Loop through conditions\n    1.  If `evalCondition(attributes, conditions[i])` is false, break out of the loop and return false\n2.  Return true\n\n### private isOperatorObject(obj): boolean[​](#private-isoperatorobjectobj-boolean \"Direct link to private isOperatorObject(obj): boolean\")\n\nThis accepts a parsed JSON object as input and returns `true` if every key in the object starts with `$`.\n\n*   `{\"$gt\": 1}` -> `true`\n*   `{\"$gt\": 1, \"$lt\": 10}` -> `true`\n*   `{\"foo\": \"bar\"}` -> `false`\n*   `{\"$gt\": 1, \"foo\": \"bar\"}` -> `false`\n\nIf the object is empty and has no keys, this should also return true.\n\n### private getType(attributeValue): string[​](#private-gettypeattributevalue-string \"Direct link to private getType(attributeValue): string\")\n\nThis returns the data type of the passed in argument.\n\nThe valid types to return are:\n\n*   `string`\n*   `number`\n*   `boolean`\n*   `array`\n*   `object`\n*   `null`\n*   `undefined`\n*   `unknown`\n\nThe difference between `null` and `undefined` can be illustrated as follows:\n\n```\nobj = JSON.parse('{\"foo\": null}');getType(obj[\"foo\"]); // nullgetType(obj[\"bar\"]); // undefined\n```\n\nThe value `unknown` is there just in case you can't figure out the data type for whatever reason. It will never be used in most implementations.\n\n### private getPath(attributes: Attributes, path: string): any[​](#private-getpathattributes-attributes-path-string-any \"Direct link to private getPath(attributes: Attributes, path: string): any\")\n\nGiven attributes and a dot-separated path string, return the value at that path (or `null`/`undefined` if the path doesn't exist)\n\nGiven the input:\n\n```\n{  \"name\": \"john\",  \"job\": {    \"title\": \"developer\"  }}\n```\n\nIt should return:\n\n*   `getPath(input, \"name\")` -> `\"john\"`\n*   `getPath(input, \"job.title\")` -> `\"developer\"`\n*   `getPath(input, \"job.company\")` -> `null` or `undefined`\n\n### private evalConditionValue(conditionValue, attributeValue): boolean[​](#private-evalconditionvalueconditionvalue-attributevalue-boolean \"Direct link to private evalConditionValue(conditionValue, attributeValue): boolean\")\n\n1.  If `conditionValue` is an object and `isOperatorObject(conditionValue)` is true\n    1.  Loop over each key/value pair\n        1.  If `evalOperatorCondition(key, attributeValue, value)` is false, return false\n    2.  Return true\n2.  Else, do a deep comparison between `attributeValue` and `conditionValue`. Return true if equal, false if not.\n\n### private elemMatch(conditionValue, attributeValue): boolean[​](#private-elemmatchconditionvalue-attributevalue-boolean \"Direct link to private elemMatch(conditionValue, attributeValue): boolean\")\n\nThis checks if `attributeValue` is an array, and if so at least one of the array items must match the condition\n\n1.  If `attributeValue` is not an array, return false\n2.  Loop through items in `attributeValue`\n    1.  If `isOperatorObject(conditionValue)`\n        1.  If `evalConditionValue(conditionValue, item)`, break out of loop and return true\n    2.  Else if `evalCondition(item, conditionValue)`, break out of loop and return true\n3.  Return false\n\n### private paddedVersionString(input): string[​](#private-paddedversionstringinput-string \"Direct link to private paddedVersionString(input): string\")\n\nThis function can be used to help with the evaluation of the version string comparsion.\n\nThere are 6 operators that are used for comparing version strings, e.g. `v1.2.3` or `1.2.3`:\n\nCondition\n\nComparison\n\nDescription\n\n`$veq`\n\n`==`\n\nVersions are equal\n\n`$vne`\n\n`!=`\n\nVersions are not equal\n\n`$vlt`\n\n`<`\n\nThe first version is lesser than the second version\n\n`$vlte`\n\n`<=`\n\nThe first version is lesser than or equal to the second version\n\n`$vgt`\n\n`>`\n\nThe first version is greater than the second version\n\n`$vgte`\n\n`>=`\n\nThe first version is greater than or equal to the second version\n\nRules:\n\n*   Segments are separated by `.` and `-` characters\n*   Segments should be compared alphanumerically from the left-most segment\n    *   Digit-only segments should be left-padded with a space so that they have the same number of characters.\n*   A leading `v` in a version string should be ignored\n*   Semantic version syntax used to denote build information (as denoted by a `+`, e.g. `+mybuild`) should be ignored for comparisons.\n\nHere's an example:\n\n```\nexport function paddedVersionString(input: string): string {  // Remove build info and leading `v` if any  // Split version into parts (both core version numbers and pre-release tags)  // \"v1.2.3-rc.1+build123\" -> [\"1\",\"2\",\"3\",\"rc\",\"1\"]  const parts = input.replace(/(^v|\\+.*$)/g, \"\").split(/[-.]/);  // If it's SemVer without a pre-release, add `~` to the end  // [\"1\",\"0\",\"0\"] -> [\"1\",\"0\",\"0\",\"~\"]  // \"~\" is the largest ASCII character, so this will make \"1.0.0\" greater than \"1.0.0-beta\" for example  if (parts.length === 3) {    parts.push(\"~\");  }  // Left pad each numeric part with spaces so string comparisons will work (\"9\">\"10\", but \" 9\"<\"10\")  // Then, join back together into a single string  return parts    .map((v) => (v.match(/^[0-9]+$/) ? v.padStart(5, \" \") : v))    .join(\"-\");}\n```\n\n### private isIn(conditionValue, actualValue): boolean[​](#private-isinconditionvalue-actualvalue-boolean \"Direct link to private isIn(conditionValue, actualValue): boolean\")\n\nChecks to see if `actualValue` is in the `conditionValue` array. This implements the `$in` and `$nin` operators.\n\n1.  If `actualValue` is an array\n    1.  Return `true` if the intersection between `actualValue` and `conditionValue` has at least 1 element. Otherwise, return `false`.\n2.  Else\n    1.  Return `true` if `conditionValue` contains `actualValue`. Otherwise, return `false`.\n\n### private evalOperatorCondition(operator, attributeValue, conditionValue)[​](#private-evaloperatorconditionoperator-attributevalue-conditionvalue \"Direct link to private evalOperatorCondition(operator, attributeValue, conditionValue)\")\n\nThis function is just a case statement that handles all the possible operators\n\nThere are basic comparison operators in the form `attributeValue {op} conditionValue`:\n\n*   `$eq` ==\n*   `$ne` != (not equals)\n*   `$lt` <\n*   `$lte` <=\n*   `$gt` >\n*   `$gte` >=\n*   `$regex` ~ (regex match)\n\nThere are 3 operators where conditionValue is an array. All of these should return `false` if `conditionValue` is not an array for whatever reason.\n\n*   `$in`\n    1.  Return `isIn(conditionValue, attributeValue)`\n*   `$nin`\n    1.  Return `not isIn(conditionValue, attributeValue)`\n*   `$all`\n    1.  If attributeValue is not an array, return `false`\n    2.  Loop through conditionValue array\n        1.  If none of the elements in the attributeValue array pass `evalConditionValue(conditionValue[i], attributeValue[j])`, return false\n    3.  Return true\n\nThere are 2 operators where attributeValue is an array:\n\n*   `$elemMatch`\n    1.  Return `elemMatch(conditionValue, attributeValue)`\n*   `$size`\n    1.  If attributeValue is not an array, return false\n    2.  Return `evalConditionValue(conditionValue, attributeValue.length)`\n\nThere are 3 other operators:\n\n*   `$exists`\n    1.  If conditionValue is false, return true if attributeValue is null or undefined\n    2.  Else, return true if attributeValue is NOT null or undefined\n    3.  Return false by default\n*   `$type`\n    1.  Return `getType(attributeValue) == conditionValue`\n*   `$not`\n    1.  Return `!evalConditionValue(conditionValue, attributeValue)`\n\nThere are 6 operators that are used for comparing version strings, e.g. `v1.2.3` or `1.2.3`. See [paddedVersionString(input)](#private-paddedversionstringinput-string) for details.\n\nIf operator doesn't match any of these, return false and potentially log the error for debug purposes.\n\n## GrowthBook Class[​](#growthbook-class \"Direct link to GrowthBook Class\")\n\nThe GrowthBook class is the main export of the SDK.\n\n### constructor[​](#constructor \"Direct link to constructor\")\n\nThe constructor takes a Context object and stores the properties for later. Nothing else needs to be done during initialization.\n\nThis class has a few helper methods as well as 2 main public methods - `evalFeature` and `run`.\n\n### Getters and Setters[​](#getters-and-setters \"Direct link to Getters and Setters\")\n\nThere should be simple getters and setters for a few of the context properties:\n\n*   `attributes`\n*   `features`\n*   `forcedVariations`\n*   `url`\n*   `enabled`\n\n### private getFeatureResult(value, source, experiment, experimentResult): FeatureResult[​](#private-getfeatureresultvalue-source-experiment-experimentresult-featureresult \"Direct link to private getFeatureResult(value, source, experiment, experimentResult): FeatureResult\")\n\nThis is a helper method to create a `FeatureResult` object. The first two arguments, `value`, and `source` are required. The last two, `experiment` and `experimentResult` are optional and should default to `null`.\n\nBesides the passed-in arguments, there are two derived values - `on` and `off`, which are just the value cast to booleans.\n\nvalue can be any JSON type. Only the following values are considered to be \"falsy\":\n\n*   `null`\n*   `false`\n*   `\"\"`\n*   `0`\n\nEverything else is considered \"truthy\", including empty arrays and objects.\n\nIf value is \"truthy\", then `on` should be true and `off` should be false. If the value is \"falsy\", then they should take opposite values.\n\n### private isFilteredOut(filters: Filters\\[\\]): boolean[​](#private-isfilteredoutfilters-filters-boolean \"Direct link to private isFilteredOut(filters: Filters[]): boolean\")\n\nThis is a helper method to evaluate `filters` for both feature flags and experiments.\n\n1.  Loop through filters array\n    \n    1.  Get the hashAttribute and hashValue\n    \n    ```\n    hashAttribute = filter.attribute || \"id\";hashValue = context.attributes[hashAttribute] || \"\";\n    ```\n    \n    2.  If hashValue is empty, return `true`\n    3.  Determine the bucket for the user\n        \n        ```\n        n = hash(filter.seed, hashValue, filter.hashVersion || 2);\n        ```\n        \n    4.  If `inRange(n, range)` is false for every range in `filter.ranges`, return `true`\n2.  If you made it through the entire array without returning early, return `false` now\n\n### private isIncludedInRollout(seed: string, hashAttribute: string | null, range: BucketRange | null, coverage: float | null, hashVersion: integer | null): boolean[​](#private-isincludedinrolloutseed-string-hashattribute-string--null-range-bucketrange--null-coverage-float--null-hashversion-integer--null-boolean \"Direct link to private isIncludedInRollout(seed: string, hashAttribute: string | null, range: BucketRange | null, coverage: float | null, hashVersion: integer | null): boolean\")\n\nDetermines if the user is part of a gradual feature rollout.\n\n1.  Either `coverage` or `range` are required. If both are `null`, return `true` immediately\n    \n2.  If `range` is null and `coverage` is zero, return `false` immediately. This catches an edge case where the bucket is zero and users are let through when they shouldn't be\n    \n3.  Get the hashAttribute and hashValue\n    \n    ```\n    hashAttribute = hashAttribute || \"id\";hashValue = context.attributes[hashAttribute] || \"\";\n    ```\n    \n4.  If `hashValue` is empty, return `false` immediately\n    \n5.  Determine the bucket for the user\n    \n    ```\n    n = hash(seed, hashValue, hashVersion || 1)\n    ```\n    \n6.  Check if user is included\n    \n    ```\n    if (range) { return inRange(n, range)}else if (coverage !== null) { return n <= coverage}return true\n    ```\n    \n\n### private getExperimentResult(experiment, variationIndex, hashUsed, featureId, bucket): ExperimentResult[​](#private-getexperimentresultexperiment-variationindex-hashused-featureid-bucket-experimentresult \"Direct link to private getExperimentResult(experiment, variationIndex, hashUsed, featureId, bucket): ExperimentResult\")\n\nThis is a helper method to create an `ExperimentResult` object. The arguments are:\n\n*   `experiment` - Experiment object (required)\n*   `variationIndex` - The assigned variation index (optional, default to `-1`)\n*   `hashUsed` - Whether or not the hash was used to assign a variation (optional, default to `false`)\n*   `featureId` - The id of the feature (if any) that the experiment came from (optional, default to `null`)\n*   `bucket` - The hash bucket value for the user. Float from `0` to `1` (optional, default to `null`)\n\nThe method is pretty simple:\n\n1.  Handle case when user is not in the experiment (e.g. variationIndex = -1)\n    \n    ```\n    // By default, assume everyone is in the experimentlet inExperiment = true;// If the variation is invalid, use the baseline and set the inExperiment flag to falseif (variationIndex < 0 || variationIndex >= experiment.variations.length) {  variationIndex = 0;  inExperiment = false;}\n    ```\n    \n2.  Get the hashAttribute and hashValue\n    \n    ```\n    hashAttribute = experiment.hashAttribute || \"id\";hashValue = context.attributes[hashAttribute] || \"\";\n    ```\n    \n3.  Get meta info for the assigned variation (if any)\n    \n    ```\n    meta = experiment.meta ? experiment.meta[variationIndex] : null\n    ```\n    \n4.  Build return object\n    \n    ```\n    res = {  key: (meta && meta.key) ? meta.key : (\"\" + variationIndex),  featureId: featureId,  inExperiment: inExperiment,  hashUsed: hashUsed,  variationId: variationIndex,  value: experiment.variations[variationIndex],  hashAttribute: hashAttribute,  hashvalue: hashValue,};\n    ```\n    \n5.  Add optional properties and return\n    \n    ```\n    if (meta && meta.name) res.name = meta.name;if (meta && meta.passthrough) res.passthrough = true;if (bucket !== null) res.bucket = bucket;return res;\n    ```\n    \n\n### public evalFeature(key: string): FeatureResult[​](#public-evalfeaturekey-string-featureresult \"Direct link to public evalFeature(key: string): FeatureResult\")\n\nThe `evalFeature` method takes a single string argument, which is the unique identifier for the feature and returns a `FeatureResult` object.\n\n```\ngrowthbook = new GrowthBook(context);myFeature = growthbook.evalFeature(\"my-feature\");\n```\n\nThere are a few ordered steps to evaluate a feature\n\n1.  If the key doesn't exist in `context.features`\n    1.  Return `getFeatureResult(null, \"unknownFeature\")`\n2.  Loop through the feature rules (if any)\n    1.  If the rule has `parentConditions` (prerequisites) defined, loop through each one:\n        1.  Call `evalFeature` on the parent condition\n            *   If a cycle is detected, break out of feature evaluation and return `getFeatureResult(null, \"cyclicPrerequisite\")`\n        2.  Using the evaluated parent's result, create an object\n            \n            ```\n            const evalObj = { \"value\": parentResult.value }\n            ```\n            \n        3.  Evaluate this object against the parentCondition's condition:\n            \n            ```\n            evalCondition(evalObj, parentResult.value);\n            ```\n            \n        4.  If any of the parentConditions fail evaluation then:\n            *   If `parentCondition.gate` is true (a blocking prerequisite), return `getFeatureResult(null, \"prerequisite\")`\n            *   Otherwise, skip this rule and continue to the next one\n    2.  If the rule has `filters` defined\n        1.  if `isFilteredOut(rule.filters)`, skip this rule and continue to the next one\n    3.  If the rule has a `condition`\n        1.  If `evalCondition(context.attributes, rule.condition)` is false, skip this rule and continue to the next one\n    4.  If `rule.force` is set\n        1.  If not `isIncludedInRollout`, skip this rule and continue to the next one\n            \n            ```\n            if (!isIncludedInRollout(  rule.seed || featureKey,  rule.hashAttribute,  rule.range,  rule.coverage,  rule.hashVersion)) { continue;}\n            ```\n            \n        2.  If `rule.tracks` is set, fire the `TrackingCallback` for each element in the `rule.tracks` array.\n        3.  Return `getFeatureResult(rule.force, \"force\")`\n    5.  Otherwise, convert the rule to an Experiment object\n        \n        ```\n        const exp = {  variations: rule.variations,  key: rule.key || featureKey,};\n        ```\n        \n    6.  Copy over additional settings from the rule to `exp` if defined:\n        *   `coverage`\n        *   `weights`\n        *   `hashAttribute`\n        *   `fallbackAttribute`\n        *   `disableStickyBucketing`\n        *   `bucketVersion`\n        *   `minBucketVersion`\n        *   `namespace`\n        *   `meta`\n        *   `ranges`\n        *   `name`\n        *   `phase`\n        *   `seed`\n        *   `hashVersion`\n        *   `filters`\n        *   `condition`\n    7.  Run the experiment\n    8.  If `result.inExperiment` is false OR `result.passthrough` is true, skip this rule and continue to the next one\n    9.  Otherwise, return\n        \n        ```\n        return getFeatureResult(result.value, \"experiment\", exp, result);\n        ```\n        \n3.  Return `getFeatureResult(feature.defaultValue || null, \"defaultValue\")`\n\n### public run(experiment: Experiment): ExperimentResult[​](#public-runexperiment-experiment-experimentresult \"Direct link to public run(experiment: Experiment): ExperimentResult\")\n\nThe `run` method takes an Experiment object and returns an `ExperimentResult`.\n\nThere are a bunch of ordered steps to run an experiment:\n\n1.  If `experiment.variations` has fewer than 2 variations, return `getExperimentResult(experiment)`\n2.  If `context.enabled` is false, return `getExperimentResult(experiment)`\n3.  If `context.url` exists\n    \n    ```\n    qsOverride = getQueryStringOverride(experiment.key, context.url);if (qsOverride != null) {  return getExperimentResult(experiment, qsOverride);}\n    ```\n    \n4.  Return if forced via context\n    \n    ```\n    if (experiment.key in context.forcedVariations) {  return getExperimentResult(    experiment,    context.forcedVariations[experiment.key]  );}\n    ```\n    \n5.  If `experiment.active` is set to false, return `getExperimentResult(experiment)`\n6.  Get the user hash value and return if empty\n    \n    ```\n    hashAttribute = experiment.hashAttribute || \"id\";hashValue = context.attributes[hashAttribute] || \"\";if (hashValue == \"\") {  if (experiment.fallbackAttribute && context.attributes[experiment.fallbackAttribute]) {    // check if a fallbackAttribute exists (sticky bucketing)    hashAttribute = experiment.fallbackAttribute;    hashValue = context.attributes[hashAttribute];  } else {    // no hashAttribute or fallbackAttribute, return    return getExperimentResult(experiment);  }}\n    ```\n    \n    6.5 If sticky bucketing is permitted, check to see if a sticky bucket value exists. If so, skip steps 7-8.\n7.  Apply filters and namespace\n    1.  If `experiment.filters` is set\n        \n        ```\n        if (isFilteredOut(experiment.filters)) { return getExperimentResult(experiment)}\n        ```\n        \n    2.  Else if `experiment.namespace` is set, return if not in range\n        \n        ```\n        if (!inNamespace(hashValue, experiment.namespace)) { return getExperimentResult(experiment);}\n        ```\n        \n8.  Return if any conditions are not met, return\n    \n    1.  If `experiment.condition` is set, return if it evaluates to false\n    \n    ```\n    if (!evalCondition(context.attributes, experiment.condition)) {  return getExperimentResult(experiment);}\n    ```\n    \n    2.  If `experiment.parentConditions` is set (prerequisites), return if any of them evaluate to false. See the corresponding logic in **evalFeature** for more details. (Note that the `gate` flag should not be set in an experiment)\n    3.  Apply any url targeting based on experiment.urlPatterns, return if no match\n9.  Choose a variation\n    1.  If a sticky bucket value exists, use it.\n        1.  If the found sticky bucket version is blocked (doesn't exceed `experiment.minBucketVersion`), then skip enrollment\n    2.  Else, calculate bucket ranges for the variations and choose one\n        \n        ```\n        ranges = experiment.ranges || getBucketRanges(  experiment.variations.length,  experiment.converage ?? 1,  experiment.weights ?? []);n = hash(  experiment.seed || experiment.key,  hashValue,  experiment.hashVersion || 1);assigned = chooseVariation(n, ranges);\n        ```\n        \n10.  If assigned == `-1`, return `getExperimentResult(experiment)`\n11.  If experiment has a forced variation, return\n    \n    ```\n    if (\"force\" in experiment) {  return getExperimentResult(experiment, experiment.force);}\n    ```\n    \n12.  If `context.qaMode`, return `getExperimentResult(experiment)`\n13.  Build the result object\n    \n    ```\n    result = getExperimentResult(experiment, assigned, true, n);``13.5 If sticky bucketing is permitted, store the sticky bucket value\n    ```\n    \n14.  Fire `context.trackingCallback` if set and the combination of hashAttribute, hashValue, experiment.key, and variationId has not been tracked before\n15.  Return `result`\n\n### Feature helper methods[​](#feature-helper-methods \"Direct link to Feature helper methods\")\n\nThere are 3 tiny helper methods that wrap `evalFeature` for a better developer experience:\n\n```\npublic isOn(key) {  return this.evalFeature(key).on}public isOff(key) {  return this.evalFeature(key).off}public getFeatureValue(key, fallback) {  value = this.evalFeature(key).value  return value === null ? fallback : value}\n```\n\nFor strongly typed languages, you can use generics (if supported) for `getFeatureValue` and coerce the return value to always match the data type of fallback. If generics are not supported, you can use type-specific versions of the function such as `getFeatureValueAsString`.\n\n## Fetching and Caching Features[​](#fetching-and-caching-features \"Direct link to Fetching and Caching Features\")\n\nWhen the Context contains a `clientKey`, the SDK should fetch and cache features automatically.\n\nIf `apiHost` is not specified, default to `https://cdn.growthbook.io`. Make sure to strip and trailing slashes on user-entered hosts (e.g. `http://example.com/` becomes `http://example.com`).\n\nFeatures should be fetched from `{apiHost}/api/features/{clientKey}` and all errors should be handled gracefully. A network error while fetching features should never be a fatal error that stops execution.\n\nThe API responses should be parsed and cached so future GrowthBook instances with the same clientKey can avoid a duplicate network request. The standard cache TTL to use is 60 seconds.\n\nFor best performance, a stale-while-revalidate pattern should be used. If a cache entry is older than the TTL, return the cached value immediately and start a background process to update the cache from the API.\n\nThe initial download should be intiated by a `growthbook.loadFeatures()` method call. This method may take optional parameters, such as `timeout` or `skipCache`, if it makes sense.\n\nThere should be an easy way for the user to wait until features finish loading. Depending on the language, this might be an event emitter, a Promise, a callback, or something similar. Use whatever method is standard for the language.\n\n### Server-Sent Events[​](#server-sent-events \"Direct link to Server-Sent Events\")\n\nThe API response (`/api/features/{clientKey}`) may contain a response header:\n\n> x-sse-support: enabled\n\nIf set to \"enabled\", you are able to subscribe to the API for realtime changes to feature definitions by using the [GrowthBook Proxy](https://docs.growthbook.io/self-host/proxy). This will let you update the cache immediately when a feature changes instead of waiting for the 60s TTL to expire.\n\nThe URL for subscribing to changes is `{apiHost}/sub/{clientKey}`.\n\nSDKs should not attempt to subscribe to the `/sub/` endpoint unless the header `x-sse-support: enabled` is present on the `/api/features` endpoint response.\n\nAn example implementation in JavaScript is below:\n\n```\nconst channel = new EventSource(`${apiHost}/sub/${clientKey}`);channel.addEventListener(\"features\", (event) => {  const data = JSON.parse(event.data);  cache.set(clientKey, data.features);})\n```\n\nSome important things to note:\n\n*   The SDK should implement reconnect logic to support both client and server dropping the connection.\n*   The response will be the same as when fetching from the `/api/features/{clientKey}` endpoint\n\n### Encrypted Features[​](#encrypted-features \"Direct link to Encrypted Features\")\n\nThe `/api/features/{clientKey}` endpoint can have encryption enabled (128-bit AES-CBC). When this is the case, the API response will look like this:\n\n```\n{  \"features\": {},  \"encryptedFeatures\": \"abcdef123456.ghijklmnop789jksdkfaksfadfasdfkahsfa\"}\n```\n\nBefore you can use this response, you will need to decrypt it. This requires the user to set `Context.decryptionKey` when creating the GrowthBook instance.\n\n## Type Hinting[​](#type-hinting \"Direct link to Type Hinting\")\n\nMost languages have some sort of strong typing support, whether in the language itself or via annotations. This helps to reduce errors and is highly encouraged for SDKs.\n\nIf possible, use generics to type the return value. For example, if `experiment.variations` is type `T[]`, then `result.value` should be type `T`. Or, if the fallback of `getFeatureValue` is type `string`, the return type should also be type `string`.\n\n## Handling Errors[​](#handling-errors \"Direct link to Handling Errors\")\n\nThe general rule is to be strict in development and lenient in production.\n\nYou can throw exceptions in development, but someone's production app should never crash because of a call to `growthbook.evalFeature` or `growthbook.run`.\n\nFor the below edge cases in production, just act as if the problematic property didn't exist and ignore errors:\n\n*   `experiment.weights` is a different length from `experiment.variations`\n*   `experiment.weights` adds up to something other than 1\n*   `experiment.coverage` or `feature.coverage` is greater than 1 or less than 0\n*   `context.trackingCallback` throws an error\n*   URL querystring specifies an invalid variation index\n\nFor the below edge cases in production, the experiment should be disabled (everyone gets assigned variation `0`):\n\n*   `experiment.coverage` is less than 0\n*   `experiment.force` specifies an invalid variation index\n*   `context.forcedVariations` specifies an invalid variation index\n*   `experiment.hashAttribute` is an empty string\n\n## Subscriptions[​](#subscriptions \"Direct link to Subscriptions\")\n\nSometimes it's useful to be able to \"subscribe\" to a GrowthBook instance and be alerted every time `growthbook.run` is called. This is different from the tracking callback since it also fires when a user is _not_ included in an experiment.\n\n```\ngrowthbook.subscribe(function (experiment, result) {  // do something});\n```\n\nIt's best to only re-fire the callbacks for an experiment if the result has changed. That means either the `inExperiment` flag has changed or the `variationId` has changed.\n\nIf it makes sense for your language, this function should return an \"unsubscriber\". A simple callback that removes the subscription.\n\n```\nunsubscriber = growthbook.subscribe(...)unsubscriber()\n```\n\nIn addition to subscriptions you may also want to expose a `growthbook.getAllResults` method that returns a map of the latest results indexed by experiment key.\n\n## Memory Management[​](#memory-management \"Direct link to Memory Management\")\n\nSubscriptions and tracking calls require storing references to many objects and functions. If it makes sense for your language, libraries should provide a `growthbook.destroy` method to remove all of these references and release their memory.\n\n## Tests[​](#tests \"Direct link to Tests\")\n\nWe strive to have 100% test coverage for all of our SDKs.\n\nThere is a language-agnostic test suite stored as a JSON file ([https://github.com/growthbook/growthbook/blob/main/packages/sdk-js/test/cases.json](https://github.com/growthbook/growthbook/blob/main/packages/sdk-js/test/cases.json)) with more than 400 unit tests. This extensively tests all of the public methods mentioned above.\n\nThe cases.json file is an object. The keys are the function being tested, and the values are arrays of test cases. The test case arrays structure is different for each function and listed below:\n\n*   **evalCondition**\n    *   name of the test case (string)\n    *   condition\n    *   attributes\n    *   expected return value (boolean)\n    *   definitions for Saved Groups referenced in the test case (object of keys: ID of list -> values: array of members)\n*   **hash**\n    *   seed (string)\n    *   value to hash (string)\n    *   hash version to use (integer)\n    *   expected result (float)\n*   **getBucketRange**\n    *   Name of the test case (string)\n    *   Arguments array (\\[numVariations, coverage, weights or null\\])\n    *   expected result\n*   **feature** (evalFeature)\n    *   name of the test case (string)\n    *   context passed into GrowthBook constructor\n    *   name of the feature (string)\n    *   expected result\n*   **run**\n    *   name of the test case (string)\n    *   context passed into GrowthBook constructor\n    *   experiment object\n    *   expected value\n    *   inExperiment (boolean)\n    *   hashUsed (boolean)\n*   **chooseVariation**\n    *   name of the test case (string)\n    *   n (hash)\n    *   bucket ranges\n    *   expected result\n*   **getQueryStringOverride**\n    *   name of the test case (string)\n    *   experiment key\n    *   url\n    *   numVariations\n    *   expected result\n*   **inNamespace**\n    *   name of the test case (string)\n    *   id\n    *   namespace\n    *   expected result\n*   **getEqualWeights**\n    *   numVariations\n    *   expected result (weights rounded to 8 decimal places)\n*   **decrypt**\n    *   name of the test case (string)\n    *   encrypted text (string)\n    *   decryption key (string)\n    *   expected result (string or `null` if the decryption should fail)\n*   **stickyBucket**\n    *   name of the test case (string)\n    *   context passed into GrowthBook constructor\n    *   array of preexisting sticky bucket assignment docs\n    *   name of the feature (string)\n    *   expected result\n    *   expected sticky bucket assignment docs\n*   **urlRedirect**\n    *   name of the test case (string)\n    *   context passed into GrowthBook constructor\n    *   expected array of result objects\n\nIn addition to the above, you should write custom test cases for things like event subscriptions, tracking callbacks, getters/setters, etc. that are more language-specific.\n\n## Getting Help[​](#getting-help \"Direct link to Getting Help\")\n\nJoin our [Slack community](https://slack.growthbook.io/?ref=docs-buildyourown) if you need help or want to chat. We're also happy to hop on a call and do some pair programming.\n\n## Attribution[​](#attribution \"Direct link to Attribution\")\n\nOpen a [GitHub issue](https://github.com/growthbook/growthbook/issues) with a link to your project and we'll make sure we add it to our docs and give you proper credit for your hard work.\n\n## Changelog[​](#changelog \"Direct link to Changelog\")\n\n*   **v0.1** 2022-05-23\n    *   Don't skip experiment rules that are forced\n*   **v0.2** 2022-07-19\n    *   Add `featureId` to ExperimentResult object\n*   **v0.2.1** 2022-08-01\n    *   Add test case for when an experiment's hashAttribute is `null`\n*   **v0.2.2** 2022-09-08\n    *   Add test case for when an experiment's hashAttribute is an integer\n*   **v0.2.3** 2022-12-06\n    *   Add test case for when an experiment's coverage is set to 0\n*   **v0.3.0** 2023-01-18\n    *   New `apiHost`, `clientKey`, and `decryptionKey` Context properties\n    *   Built-in fetching and caching\n    *   Server Sent Events (SSE) support for realtime feature updates\n*   **v0.4.0** 2023-02-24\n    *   Changed signature of `hash` method and added multiple hashing versions\n    *   New `inRange`, `isIncludedInRollout`, and `isFilteredOut` helper methods\n    *   New `hashVersion`, `range`, `ranges`, `meta`, `filters`, `seed`, `name`, `tracks`, and `phase` properties of FeatureRules\n    *   New `hashVersion`, `ranges`, `meta`, `filters`, `seed`, `name`, and `phase` properties of Experiments\n    *   New `key`, `name`, `bucket`, and `passthrough` fields in Experiment Results\n    *   New `Filter`, `VariationMeta`, and `TrackData` data structures\n*   **v0.4.1** 2023-04-13\n    *   Added `decrypt` function and set of test cases\n    *   `hash` function now returns `null` instead of `-1` when an invalid hashVersion is specified\n    *   Fixed broken feature test case (was using `[0.99]` instead of `0.99` for coverage)\n*   **v0.4.2** 2023-04-30\n    *   Add test cases when targeting condition value is `null`\n*   **v0.5.0** 2023-05-17\n    *   Add support for new version string comparison operators (`$veq`, `$vne`, `$vgt`, `$vgte`, `$vlt`, `$vlte`) and new `paddedVersionString` helper function\n    *   New `isIn` helper function for conditions, plus new evalCondition test cases for `$in` and `$nin` operators when attribute is an array\n*   **v0.5.1** 2023-10-19\n    *   Add 2 new test cases for matching on a `$groups` array attribute\n*   **v0.5.2** 2023-10-30\n    *   Add 3 new test cases for comparison operators to handle more edge cases\n*   **v0.5.3** 2024-01-02\n    *   Experiment conditions are now evaluated within the experiment object\n    *   New `fallbackAttribute`, `disableStickyBucketing`, `bucketVersion`, `minBucketVersion`, properties of FeatureRules\n    *   New `fallbackAttribute`, `disableStickyBucketing`, `bucketVersion`, `minBucketVersion`, properties of Experiments\n    *   Add `stickyBucketUsed` to ExperimentResult object\n*   **v0.5.4** 2024-02-23\n    *   New `parentConditions` property of FeatureRules\n    *   New `parentConditions` property of Experiments\n*   **v0.5.5** 2024-04-09\n    *   Add test cases for URL Redirects\n    *   Add `navigate` method to Context\n    *   Add `persistQueryString` property to Experiment\n    *   Add and improve test cases for StickyBucket\n*   **v0.6.0** 2024-04-30\n    *   Remove `versionCompare` test cases (these are now just included as part of `evalCondition`)\n    *   Tweak to `isIncludedInRollout` to handle an edge case when coverage is zero. Also added test case for this.\n    *   Add `id` property to feature rules (reserved for future use)\n*   **v0.6.1** 2024-05-13\n    *   Update logic in `evalCondition` to allow for and/or/not/nor operators to appear at the same level as other conditions\n    *   Added test cases for multiple operators on the same level\n*   **v0.7.0** 2024-06-25\n    *   New Operators `$inGroup` and `$notInGroup` to check Saved Groups by reference\n    *   Add argument to `evalCondition` for definition of Saved Groups\n    *   Add test cases for `evalCondition`, `feature`, and `run` using the new operators",
    "title": "Build Your Own | GrowthBook Docs",
    "description": "This guide is meant for library authors looking to build a GrowthBook SDK in a currently unsupported language.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/self-host",
    "markdown": "# Self-Hosting GrowthBook | GrowthBook Docs\n\nGrowthBook consists of a NextJS front-end, an ExpressJS API, and a Python stats engine. Everything is bundled together in a single [Docker Image](https://hub.docker.com/r/growthbook/growthbook).\n\nIn addition to the app itself, you will also need a MongoDB instance to store login credentials, cached experiment results, and metadata.\n\ntip\n\nDon't want to install or host the app yourself? [GrowthBook Cloud](https://app.growthbook.io/) is a fully managed version that's free to get started.\n\n## Installation[​](#installation \"Direct link to Installation\")\n\nYou can use **docker-compose** to get started quickly:\n\n```\n# docker-compose.ymlversion: \"3\"services:  mongo:    image: \"mongo:latest\"    environment:      - MONGO_INITDB_ROOT_USERNAME=root      - MONGO_INITDB_ROOT_PASSWORD=password    volumes:      - mongodata:/data/db  growthbook:    image: \"growthbook/growthbook:latest\"    ports:      - \"3000:3000\"      - \"3100:3100\"    depends_on:      - mongo    environment:      - MONGODB_URI=mongodb://root:password@mongo:27017/growthbook?authSource=admin    volumes:      - uploads:/usr/local/src/app/packages/back-end/uploadsvolumes:  uploads:  mongodata:\n```\n\nThen, just run `docker-compose up -d` to start everything and view the app at [http://localhost:3000](http://localhost:3000/)\n\ncaution\n\nThe use of the mongo image within the docker-compose.yml is meant to quickly get a dev or staging environment up and running. For production you may want to use a more scalable and stable solution (ie. AWS DocumentDB, Google Cloud MongoDB Atlas, Azure Cosmos DB for Mongo, etc.) You may also want to have a [Growthbook Proxy](https://docs.growthbook.io/self-host/proxy) running as well for speed, scalability, sercurity, and real-time feature rollouts.\n\nBuilds are published automatically from the [GitHub repo](https://github.com/growthbook/growthbook) main branch. The most recent commit is tagged with `latest`.\n\nGitHub Releases are also tagged using SemVer (e.g. `0.2.1`).\n\nIf you need to reference the image for a specific git commit for any reason, you can use the git shorthash tag (e.g. `git-41278e9`).\n\n## Updating to Latest[​](#updating-to-latest \"Direct link to Updating to Latest\")\n\nIf you are using docker-compose, and assuming you specify the growthbook container with `:latest`, you can update with:\n\n```\ndocker-compose pull growthbookdocker-compose stop growthbookdocker-compose up -d growthbook\n```",
    "title": "Self-Hosting GrowthBook | GrowthBook Docs",
    "description": "Learn how to set a self-hosted version of GrowthBook",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/app/api",
    "markdown": "# API | GrowthBook Docs\n\n## API\n\nbeta\n\nGrowthBook offers a full REST API for interacting with the GrowthBook application. This is currently in **beta** as we add more authenticated API routes and features.\n\n[View REST API Docs](https://docs.growthbook.io/api/)\n\n## SDK Connection Endpoints[​](#sdk-connection-endpoints \"Direct link to SDK Connection Endpoints\")\n\nIn addition to the REST API above, there is one additional readonly endpoint - the SDK Connection Endpoint.\n\nThe SDK Connection Endpoint provides readonly access to a subset of your feature flag data, just enough for the [GrowthBook SDKs](https://docs.growthbook.io/lib) to assign values to users. They are meant to be public and do not require authentication to view.\n\nIn **GrowthBook Cloud**, the SDK Connection Endpoints are served from our global CDN: `https://cdn.growthbook.io/api/features/...`. If you are self-hosting, you can run the [GrowthBook Proxy server](https://docs.growthbook.io/self-host/proxy), which provides built-in caching and performance optimizations.\n\nSDK Connection Endpoints are scoped to a single Environment (e.g. `dev` or `production`) and can also be scoped to a single Project. Manage all of your SDK Connections on the **Features → SDKs** page.\n\nTypescript Type Definition\n\n```\ninterface SDKEndpointResponse {  status: 200;  features: {    [key: string]: FeatureDefinition  }}interface FeatureDefinition {  defaultValue: any;  rules?: FeatureDefinitionRule[];}interface FeatureDefinitionRule {  force?: any;  weights?: number[];  variations?: any[];  hashAttribute?: string;  hashVersion?: number;  seed?: string;  namespace?: [string, number, number];  key?: string;  coverage?: number;  condition?: any;  meta?: VariationMeta[];  name?: string;  phase?: string;}interface VariationMeta = {  passthrough?: boolean;  key?: string;  name?: string;}\n```\n\nExample JSON object\n\n```\n{  \"status\": 200,  \"features\": {    \"feature-key\": {      \"defaultValue\": true    },    \"another-feature\": {      \"defaultValue\": \"blue\",      \"rules\": [        {          \"condition\": {            \"browser\": \"firefox\"          },          \"force\": \"green\"        }      ]    }  }}\n```\n\n### Encryption[​](#encryption \"Direct link to Encryption\")\n\nIf you've enabled encryption for your SDK endpoint, the response format changes:\n\nTypescript Type Definition\n\n```\ninterface SDKEncryptedEndpointResponse {  status: 200;  encryptedFeatures: string;}\n```\n\nExample JSON object\n\n```\n{  \"status\": 200,  \"encryptedFeatures\": \"abcdef123456GHIJKL0987654321...\"}\n```\n\nYou will need to decrypt the features first before passing into the SDK. Our front-end SDKs (Javascript and React) handle this for you automatically and we're in the process of adding built-in support to our other SDKs.",
    "title": "API | GrowthBook Docs",
    "description": "API",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/app/webhooks",
    "markdown": "# Webhooks Overview | GrowthBook Docs\n\nGrowthBook provides a variety of different outbound webhooks, all of which enable push communication from the GrowthBook server to applications. We will briefly discuss the different types of webhooks that GrowthBook supports and when you might want to use them.\n\n### Event Webhooks[​](#event-webhooks \"Direct link to Event Webhooks\")\n\n**See: [Event Webhooks](https://docs.growthbook.io/app/webhooks/event-webhooks)**  \nAccess via: **Settings → Webhooks**\n\nThese trigger when GrowthBook's state changes. For example, sending a detailed message about how a feature was modified or a new experiment was created. Filterable by project, environment, and event type(s).\n\n##### Common Use Cases:[​](#common-use-cases \"Direct link to Common Use Cases:\")\n\n*   Pinging an internal monitoring service\n*   Maintaining a custom audit log\n*   Messaging on Slack or Discord\n\nEvent webhooks can be formatted for Slack and Discord out of the box. For integration details, see:\n\n*   [Slack Integration](https://docs.growthbook.io/integrations/slack)\n*   [Discord Integration](https://docs.growthbook.io/integrations/discord)\n\n### SDK Webhooks[​](#sdk-webhooks \"Direct link to SDK Webhooks\")\n\n**See: [SDK Webhooks](https://docs.growthbook.io/app/webhooks/sdk-webhooks)**  \nAccess via: **SDK Configuration → SDK Connections**, choose a connection, click **Add Webhook**\n\nThese are tightly coupled with your SDK Connections. They trigger whenever the connection's SDK payload (feature and experiment definitions) changes. They can optionally send the new SDK payload.\n\n##### Common Use Cases:[​](#common-use-cases-1 \"Direct link to Common Use Cases:\")\n\n*   Updating or flushing CDN cache\n*   Updating a cache microservice\n*   Pushing feature/experiment updates to your application\n\n### Global SDK Webhooks[​](#global-sdk-webhooks \"Direct link to Global SDK Webhooks\")\n\n**See: [Global SDK Webhooks](https://docs.growthbook.io/app/webhooks/global-sdk-webhooks)**\n\nGlobal SDK Webhooks are limited to self-hosted users only.\n\nThese are similar to SDK webhooks, but are not limited to a single SDK Connection. Instead, GrowthBook will fire _all_ SDK Connection changes to one or more webhooks, which are defined via environment variables.\n\n##### Use Cases:[​](#use-cases \"Direct link to Use Cases:\")\n\n*   For larger organizations, this saves the trouble of needing to manually configure hundreds of individual SDK Webhooks for each connection.\n*   This pattern is especially common for multi-org installations of GrowthBook.\n\n### GrowthBook Proxy Webhook[​](#growthbook-proxy-webhook \"Direct link to GrowthBook Proxy Webhook\")\n\n**See: [GrowthBook Proxy documentation](https://docs.growthbook.io/self-host/proxy)**\n\nSimilar to SDK webhooks, this webhook is a special use webhook for communicating with the GrowthBook Proxy. Unlike SDK webhooks, proxy webhooks are not customizable.\n\n*   Self-hosted users should configure a single global proxy webhook using environment variables.\n*   Cloud users may optionally configure a GrowthBook Proxy webhook for each SDK Connection.\n\n## Notable Mentions[​](#notable-mentions \"Direct link to Notable Mentions\")\n\nLess common or soon-to-be-deprecated webhooks:\n\n### Legacy Webhooks[​](#legacy-webhooks \"Direct link to Legacy Webhooks\")\n\nThese function similarly to SDK Webhooks. They should not be used going forward; existing legacy webhooks will likely be migrated to SDK Webhooks during a future GrowthBook version release.\n\n### Fastly CDN Purge Webhook[​](#fastly-cdn-purge-webhook \"Direct link to Fastly CDN Purge Webhook\")\n\nIf you are using Fastly as your CDN, and have defined surrogate keys for each SDK endpoint, you can pass `FASTLY_SERVICE_ID` and `FASTLY_API_TOKEN` into your environment variables to enable automatic cache purging. However, we recommend using SDK Webhooks for more control and flexibility.",
    "title": "Webhooks Overview | GrowthBook Docs",
    "description": "An overview of the various webhooks that exist in GrowthBook",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/integrations/slack",
    "markdown": "# Slack integration | GrowthBook Docs\n\nThe GrowthBook Slack integration allows you to receive alerts for the events that you care about in a Slack channel of your choosing.\n\nNew\n\nThe GrowthBook Slack integration is a brand new feature. If you experience any issues, let us know either on [Slack](https://slack.growthbook.io/) or [create an issue](https://github.com/growthbook/growthbook-sdk-java/issues).\n\n## Creating and configuring an app in Slack[​](#creating-and-configuring-an-app-in-slack \"Direct link to Creating and configuring an app in Slack\")\n\n### Create a Slack app[​](#create-a-slack-app \"Direct link to Create a Slack app\")\n\nThe first step to setting up the GrowthBook Slack integration is to create a new app under your workspace's owned apps. You will need administrative privileges for your workspace in order to be able to manage apps.\n\nNavigate to your workspace’s apps and choose to create a new app. You can get to that page directly [here](https://api.slack.com/apps?new_app=1).\n\n![](https://docs.growthbook.io/assets/images/slack-create-app-25002ff66d7fbb85e4a823e687053850.png)\n\nName the app and choose the workspace. In this case we are created the app named GrowthBook Alerts and are picking the GrowthBook Dev workspace.\n\n![](https://docs.growthbook.io/assets/images/slack-name-app-choose-workspace-faf55662a5072c9c2eff289b855b0cd2.png)\n\n### Create an Incoming Webhook[​](#create-an-incoming-webhook \"Direct link to Create an Incoming Webhook\")\n\nWe will be alerting via Slack's incoming webhooks functionality. Under the **Basic Information** tab of your app, click on **Incoming Webhooks**.\n\n![](https://docs.growthbook.io/assets/images/slack-incoming-webhooks-d0d8cf0c2975a55681d3eaf042dc5b1b.png)\n\n### Subscribe a channel to alerts[​](#subscribe-a-channel-to-alerts \"Direct link to Subscribe a channel to alerts\")\n\nClick on the button at the bottom of the **Incoming Webhooks** page that says **Add New Webhook to Workspace**.\n\nYou will be asked to install the app into your workspace. Choose the desired channel you'd like to receive notifications in.\n\n![](https://docs.growthbook.io/assets/images/slack-install-flow-41d350633457e3a670be071092e8a91a.png)\n\nOnce you've completed this flow, you will see a URL available for you to copy. Save this value for later.\n\n![](https://docs.growthbook.io/assets/images/slack-copy-webhook-url-486bc547426412808f41155d28f2fff1.png)\n\n## Add the Slack integration to GrowthBook[​](#add-the-slack-integration-to-growthbook \"Direct link to Add the Slack integration to GrowthBook\")\n\nNext step is to login to the GrowthBook app and visit the **Webhooks** tab under **Settings**, also available [here](https://app.growthbook.io/settings/webhooks). You will need privileges to manage webhooks in order for this menu item to be available.\n\nClick the **Create an Event Webhook** button. You should see a modal pop up with some fields for configuring the Slack notification webhook.\n\n![](https://docs.growthbook.io/assets/images/new-webhook-8cf3a4bd099ba7024f022712027542eb.png)\n\nThen, configure the following:\n\n*   **Name**: The name of the integration. In case you have multiple integrations, this can help you tell them apart. This will also show in the contextual text alongside the alerts.\n*   **Endpoint URL**: Copy and paste the webhook URL provided by your slack app.\n*   **Payload**: Select the `Slack` payload.\n*   **Event filters**: You can optionally filter by events you care about. For example, if you only care about when features are deleted, you can choose `feature.deleted` from the list. If you care about all events, leave this blank.\n*   **Environment filters**: You can optionally choose to filter by environment. For example, if you only want to hear about events that are for the production environment, you can choose `production` from the list. For all environments, leave this blank.\n*   **Project filters**: You can optionally choose to filter by project. For example, if you have a project named \"Onboarding V2\" and you only want to alert for that project, you can choose that project from the projects list. For all projects, leave this blank.\n*   **Tag filters**: You can optionally choose to filter by tag. For all events regardless of tag, leave this blank.\n\nAfter configuring all the fields, press **Create** to save your new Slack notification webhook.\n\nYou can also edit these fields at any point if you make a mistake.\n\n![](https://docs.growthbook.io/assets/images/edit-webhook-230f339ce05e40edc9de0b89d8c2fa87.png)\n\n### Adding more alerts[​](#adding-more-alerts \"Direct link to Adding more alerts\")\n\nIf you'd like to be alerted in another Slack channel, you can add another Incoming Webhook in Slack.\n\nThen, you can create new integrations in the GrowthBook dashboard, specifying all of the same information except adding your new webhook URL.\n\n## Testing your alerts[​](#testing-your-alerts \"Direct link to Testing your alerts\")\n\nYou are now ready to test your alerts. First, you can hit the `Test` button on the webhook settings page. This should trigger a test notification.\n\nNext, perform one of the actions you're watching if you've added Event filters. If you haven't added any event filters, the quickest way to test it's working is to either create a new test feature (then delete it if it's not needed), or toggle an environment on or off for an existing feature.",
    "title": "Slack integration | GrowthBook Docs",
    "description": "The GrowthBook Slack integration allows you to receive alerts for the events that you care about in a Slack channel of your choosing.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/account/user-permissions",
    "markdown": "# User & Team Permissions | GrowthBook Docs\n\nIn the context of GrowthBook, a user, or member, is an individual who has access to your organization's GrowthBook account. Each user is assigned a role that determines the level of access they have within the application. GrowthBook offers a range of roles, from `No Access` to `Admin` and even custom roles, each with a specific set of permissions (see below). GrowthBook's user permissions system allows organizations to define the level of access each user has within the application. This granular control ensures that users can only access the resources they need to perform their job, enhancing security and privacy.\n\n## Adding Users[​](#adding-users \"Direct link to Adding Users\")\n\nTeam members can be added to your GrowthBook account via the `Settings` → `Members` page. From this main page, you'll see an \"Invite Member\" button on the right. If you do not see this button, you do not have permission to add members to your organization. Clicking on \"Invite Member\" will open a modal window from which you can choose some options for the new user.\n\n![Inviting members modal](https://docs.growthbook.io/assets/images/invite-member-modal-71e3c65b5cf628d20a53f9da725ca3e4.png)\n\nEach GrowthBook user needs an email address, and you can select what global permissions you want to assign (See below for a full list of permission levels).\n\nInviting a new member to your organization will send an email to that user inviting them to join.\n\nIt is possible for a user to join more than one organization. If the user is a member to multiple organizations, they will see a drop-down next to their email address on the top right of the page, where they can select the organization they want to work in.\n\n### Environment Specific Limits[​](#environment-specific-limits \"Direct link to Environment Specific Limits\")\n\n![Environment Specific Limits](https://docs.growthbook.io/assets/images/user-permissions-env-specific-7676a8e33cbef9a12e5e73b8d190f63b.png)\n\nGrowthBook's user permissions also include environment specific limits. This permission level applies only to `Engineer` and `Experimenter` roles in Pro or Enterprise accounts. It allows you to limit the feature flags and experiments a user can manage to specific environments. For example, you can allow an `Engineer` to create and run experiments in a staging environment, but not in production.\n\n### Project Specific Permissions[​](#project-specific-permissions \"Direct link to Project Specific Permissions\")\n\nBesides the global permissions, you can also assign project-specific permissions to users. This allows you to define a user's default role across all projects and select per-project overrides. For example, a new user could be a `collaborator` by default for all projects, but on the `mobile` project, they could be an `experimenter` so they can manage all feature flags and experiments assigned to that project.\n\n### How permissions are evaluated[​](#how-permissions-are-evaluated \"Direct link to How permissions are evaluated\")\n\nGrowthBook evaluates user permissions based on whether an action is taking place within a specific project. If so, project-level permissions are checked first, followed by the user's global role. If the action is not within a project, only the user's global role is checked.\n\nFor organizations without a Pro or Enterprise account, user permissions are evaluated solely based on their global role.\n\nnote\n\nIf your organization has enabled the setting to allow verified users to automatically join your organization, they will receive the `Collaborator` role by default when they join. However, you can change your organizations' default role at the bottom of the Team page.\n\n### Self-registering and Automatic Approvals[​](#self-registering-and-automatic-approvals \"Direct link to Self-registering and Automatic Approvals\")\n\nIf users create an account with a verified email address that matches the domain of your account owner, they will be presented with an option to join your organization. If you have not selected `Automatically approve new verified users` (which is the default), those users will be listed at the bottom of the page under a section called `Pending Members`. From this list, you'll have the option of approving or deleting these self-registered users.\n\n![Self-registering and Automatic Approvals Toggle](https://docs.growthbook.io/images/using/auto-approve-members.png)\n\nIf you are the account owner, you will see a toggle at the top of the members' page that allows you to automatically approve new members who match your domain. This means that instead of being placed in your `pending members` list, they will automatically join your organization.\n\n### Removing Users[​](#removing-users \"Direct link to Removing Users\")\n\nTo remove a user from your organization, you can click on the three dots next to their name and select `Remove User`. This will remove the user from your organization and revoke their access to all projects and resources within your organization.\n\n## Permissions[​](#permissions \"Direct link to Permissions\")\n\nFine-tuning user permissions in an application like GrowthBook ensures a tailored experience, empowering organizations to grant precisely defined access levels. This granular control not only enhances security but also enables teams to collaborate efficiently while safeguarding sensitive features or data.\n\nOrganizations using GrowthBook have a number of different ways of defining a user's permission level, depending on the organization's plan.\n\nRegardless of the plan, all organizations can assign a global role when inviting a user which defines their permissions across all projects. If you have a Pro or Enterprise account, you can also assign project-level roles for each user.\n\nnote\n\nFor example, you can assign a user the global role of `Collaborator`, allowing them to view features and experiments, add comments, and contribute ideas. You can then assign them an `Experimenter` role for a specific project, which allows them to create and run experiments, but only for that project.\n\nAnd, for our Enterprise organizations, we offer the ability to create `Teams`, which are groups of users, all of which inherit the roles and permissions of the Team they're on.\n\nThe table below lists the roles available in GrowthBook and their associated permissions.\n\n|     | No Access | Read Only | Collaborator | Engineer | Analyst | Experimenter | Admin |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n| Feature Flags | \\-  | View | View  <br>Comment | View  <br>Comment  <br>Add  <br>Edit | View  <br>Comment | View  <br>Comment  <br>Add  <br>Edit | View  <br>Comment  <br>Add  <br>Edit |\n| Experiments | \\-  | View | View  <br>Comment | View  <br>Comment  <br>Edit | View  <br>Comment  <br>Add  <br>Edit  <br>Run Queries | View  <br>Comment  <br>Add  <br>Edit  <br>Run Queries | View  <br>Comment  <br>Add  <br>Edit  <br>Run Queries |\n| Metrics | \\-  | View | View | View | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Dimensions | \\-  | View | View | View | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Segments | \\-  | View | View | View | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Datasources | \\-  | View | View | View | View  <br>Edit\\* | View  <br>Edit\\* | View  <br>Add  <br>Edit |\n| Ideas | \\-  | View | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| SDK Connections | \\-  | View  <br>Add | View  <br>Add | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Attributes | \\-  | View | View | View  <br>Add  <br>Edit | View | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Namespaces | \\-  | View | View | View  <br>Add  <br>Edit | View | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Environments | \\-  | View | View | View  <br>Add  <br>Edit | View | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Saved Groups | \\-  | View | View | View  <br>Add  <br>Edit | View | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Tags | \\-  | \\-  | \\-  | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit | View  <br>Add  <br>Edit |\n| Slack Integration | \\-  | \\-  | \\-  | \\-  | \\-  | \\-  | View  <br>Add  <br>Edit |\n| Manage Projects | \\-  | \\-  | \\-  | \\-  | \\-  | \\-  | Yes |\n| Manage Team | \\-  | \\-  | \\-  | \\-  | \\-  | \\-  | Yes |\n| Manage Plan | \\-  | \\-  | \\-  | \\-  | \\-  | \\-  | Yes |\n| Manage Billing | \\-  | \\-  | \\-  | \\-  | \\-  | \\-  | Yes |\n\n\\*_Limited to editing a subset of data source settings - identifier types, experiment assignment queries, Jupyter Notebook queries and Data Pipeline settings. Editing datasource name, projects, description, and connection parameters requires Admin permissions._\n\n### How does the No Access role work?[​](#how-does-the-no-access-role-work \"Direct link to How does the No Access role work?\")\n\nThe `No Access` role is available to organizations enrolled in an Enterprise plan.\n\nIn some cases, an organization might want to hide certain projects from a user entirely. This is possible with the `No Access` role. The `No Access` role can either be applied as the user's global role, or it can be a project-specific role.\n\nIn the event you want a user to have access to a subset of projects, you can give them a global role of `No Access` and then give project-specific permissions for the projects you want them to be able to view.\n\nIf, however, you only want to hide a certain project from a user, you can assign their project-level role of `No Access` which will make it so the user isn't able to view the project.\n\nIf you need to apply these rules to many users as once, you can create a Team with the permissions needed, and then add users to that team. But, keep in mind, the user's permissions will be a combination of their user permissions, and the permissions of any team their on, so after adding the user to a team, you may want to reduce their user-level permissions to ensure their previous user-level permissions don't override the permissions inherited by the team(s) they're on.\n\nnote\n\nWithin GrowthBook, not all resources are project-specific. For example, `Saved Groups`, `Dimensions`, `Segments`, `Namespaces`, `Environments`, `Presentations`, and `Ideas` all live at the organization level. This means that all users, regardless of role, will be able to view these resources.\n\nIf security of these resources is paramount to your organization, we recommend creating a separate organization, and keeping the resources you want to hide in that organization.\n\n### Teams[​](#teams \"Direct link to Teams\")\n\nEnterprise organizations using GrowthBook can create Teams with distinct capabilities. When setting up a Team, you have the option to define both a global role and project-level roles, much like how you do for individual users. Once a Team is established, multiple users can be added to it. Any user added to a Team will automatically inherit all permissions assigned to that Team. This feature becomes particularly useful when combined with [GrowthBook's SCIM integration](https://docs.growthbook.io/integrations/scim), enabling automated user provisioning and de-provisioning.\n\nTo create a Team, you can go to `Settings` → `Team` via the Sidebar and then select the `Teams` tab at the top of the page. Here, you can create and configure various Teams, before adding members to a Team. When evaluating whether or not a user has permission to perform a certain action, we will merge the user's permissions with the permissions inherited from all the Teams the user is on. So if the user's global role is `Collaborator` but they're on a Team that grants them `Engineer` permissions, that user's permission will then be a merger of the `Collaborator` and `Engineer` roles.\n\n### Custom roles[​](#custom-roles \"Direct link to Custom roles\")\n\nEnterprise organizations using GrowthBook also have the added flexibility of defining custom roles, which enable organizations to fine-tune a role's permissions. These custom roles can be used just like a standard role and can be applied to users and teams at both the global and project levels. A custom role can also be set as your organization's default role, so if you have auto-join enabled, new members will automatically receive the organization's default role, even if it is a custom role.\n\nWhen creating a custom role, you can either create a role from scratch or duplicate an existing role and then update the role's description along with the policies, which control the role's permissions.\n\nOnce created, the name of a custom role cannot be changed. If you need to change the name, you will need to duplicate the role and set the new name before saving. Once saved, you'll need to update users to use this new role.\n\n#### Policies & Permissions[​](#policies--permissions \"Direct link to Policies & Permissions\")\n\nWhen creating and editing custom roles, organizations have the ability to select specific policies for each role, where the policy contains the underlying permissions.\n\nBelow, we've outlined the current policies and their associated permissions. If your use case is not met with the current policies, please let us know by creating a [Github Issue](https://github.com/growthbook/growthbook/issues).\n\n| Policy Group | Policy | Description | Permissions |\n| --- | --- | --- | --- |\n| **Global** | ReadData | View all resources - features, metrics, experiments, data sources, etc. | readData |\n|     | Comments | Add comments to any resource | readData, addComments |\n| **Features** | FeaturesFullAccess | Create, edit, and delete feature flags | readData, manageFeatureDrafts, manageFeatures, manageArchetype, canReview, |\n|     | ArchetypesFullAccess | Create, edit, and delete saved User Archetypes for feature flag debugging | readData, manageArchetype |\n|     | FeaturesBypassApprovals | Bypass required approval checks for feature flag changes | readData, manageFeatureDrafts, manageFeatures, canReview, bypassApprovalChecks |\n| **Experiments** | ExperimentsFullAccess | Create, edit, and delete experiments. Does not include Visual Editor access. | readData, createAnalyses, runQueries |\n|     | VisualEditorFullAccess | Use the Visual Editor to implement experiment changes. | readData, manageVisualChanges |\n|     | superDeleteReports | Delete ad-hoc reports made by other users. Typically assigned to admins only. | readData, superDeleteReport |\n| **Metrics & Data** | DataSourcesFullAccess | Create, edit, and delete data sources | readData, createDatasources, editDatasourceSettings, runQueries |\n|     | DataSourceConfiguration | Edit existing data source configuration settings (identifier types, experiment assignment queries) | readData, editDatasourceSettings, runQueries |\n|     | RunQueries | Execute queries against data sources. Required to refresh experiment results. | readData, runQueries |\n|     | MetricsFullAccess | Create, edit, and delete regular metrics (does not include Fact Metrics) | readData, createMetrics, runQueries |\n|     | FactTablesFullAccess | Create, edit, and delete fact tables, metrics, and filters. | readData, manageFactTables, manageFactMetrics, manageFactFilters, runQueries |\n|     | FactMetricsFullAccess | Create, edit, and delete fact metrics and filters. | readData, manageFactMetrics, manageFactFilters, runQueries |\n|     | DimensionsFullAccess | Create, edit, and delete dimensions | readData, createDimensions, runQueries |\n|     | SegmentsFullAccess | Create, edit, and delete segments | readData, createSegments, runQueries |\n| **Management** | IdeasFullAccess | Create, edit, and delete ideas | readData, createIdeas |\n|     | PresentationsFullAccess | Create, edit, and delete presentations | readData, createPresentations |\n| **SDK Configuration** | SDKPayloadPublish | Make changes that affect data sent to SDKs. For example: edit a saved group, toggle a feature flag, stop an experiment, etc. | readData, publishFeatures, runExperiments |\n|     | SDKConnectionsFullAccess | Create, edit, and delete SDK Connections | readData, manageSDKConnections, manageSDKWebhooks |\n|     | AttributesFullAccess | Create, edit, and delete targeting attributes | readData, manageTargetingAttributes |\n|     | EnvironmentsFullAccess | Create, edit, and delete environments | readData, manageEnvironments |\n|     | NamespacesFullAccess | Create, edit, and delete namespaces | readData, manageNamespaces |\n|     | SavedGroupsFullAccess | Create, edit, and delete saved groups | readData, manageSavedGroups |\n| **Settings** | GeneralSettingsFullAccess | Edit organization general settings | readData, organizationSettings |\n|     | NorthStarMetricFullAccess | Configure North Star metrics | readData, manageNorthStarMetric |\n|     | TeamManagementFullAccess | Invite users, delete users, change user roles, add/remove users from teams. | readData, manageTeam |\n|     | CustomRolesFullAccess | Create, edit, and delete projects | readData, manageProjects |\n|     | ProjectsFullAccess | Create, edit, and delete tags | readData, manageTags |\n|     | TagsFullAccess | Create, edit, and delete API secret keys. Not required to create Personal Access Tokens. | readData, manageApiKeys |\n|     | APIKeysFullAccess | Set up and configure integrations - GitHub, Vercel, etc. | readData, manageIntegrations |\n|     | IntegrationsFullAccess | Create, edit, and delete event-based webhooks. Used for Slack/Discord notifications. | readData, manageEventWebhooks, viewAuditLog |\n|     | EventWebhooksFullAccess | View and edit license key. View invoices and update billing info. | readData, manageBilling |\n|     | BillingFullAccess | View and export audit logs | readData, viewAuditLog |\n|     | AuditLogsFullAccess | Create, edit, and delete custom roles | readData, manageTeam, manageCustomRoles |\n\n#### Deactivating Roles[​](#deactivating-roles \"Direct link to Deactivating Roles\")\n\nAs we do not support the ability for an organization to delete a standard role, we have introduced the ability for enterprise organizations to deactivate both standard and custom roles. When a role is deactivated, we remove the role from the roles dropdown when adding a new user or updating an existing user's role. If you deactivate a role that is assigned to a user, the user will experience no changes to their permission level. The deactivation of the role simply removes it from the role options.\n\nThe only guardrail in place around deactivating roles is that you cannot deactivate your organization's default role.",
    "title": "User & Team Permissions | GrowthBook Docs",
    "description": "GrowthBook's User & Team Permissions",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/integrations/scim",
    "markdown": "# Configuring SCIM for GrowthBook | GrowthBook Docs\n\n## SCIM Integration for Enterprise Organizations\n\nnote\n\nSCIM is only available with an Enterprise plan and requires [Single Sign-On (SSO)](https://docs.growthbook.io/sso) to be enabled. Currently, GrowthBook only supports Okta as the identity provider.\n\nSCIM, or [System for Cross-domain Identity Management](https://scim.cloud/), is the standard for managing users and groups across multiple applications. With SCIM, you can automate the provisioning and deprovisioning of users in your GrowthBook account through your identity provider.\n\nGrowthBook's SCIM integration currently offers the following features:\n\n*   User provisioning\n*   User deprovisioning\n*   Group Push\n\nWhen a user is provisioned, they are added to your GrowthBook organization with your organization's default role. After provisioning, admin users can adjust their roles and permissions via the GrowthBook application as needed. It's important to note that if a user is provisioned through SCIM, they can only be deprovisioned through your identity provider.\n\nGrowthBook does support the ability to optionally [define a role when provisioning a user](#how-to-define-user-role-when-provisioning). Project-level permissions are not supported when provisioning a user via SCIM. That must be done via the GrowthBook application.\n\nWhen a group is added to \"Push Groups\" in your Okta SCIM application, groups and their members will be synced with GrowthBook via a corresponding [Team](https://docs.growthbook.io/account/user-permissions). Please note that only members that have been provisioned into the GrowthBook app will be added to the Team in GrowthBook. For example, if you have a push group with members A, B, and C and only A and B are assigned to GrowthBook on the \"Assignments\" tab, the corresponding team on GrowthBook will only include members A and B. Just like how user provisioning works, new Teams will be set up with your organization's default role. You'll need to adjust the permissions for the Team in GrowthBook. Group removal or membership changes will need to be done through your identity provider.\n\nnote\n\nWe are actively working on adding support for additional identity providers.\n\n## Configuring SCIM Integration[​](#configuring-scim-integration \"Direct link to Configuring SCIM Integration\")\n\n### Okta Setup[​](#okta-setup \"Direct link to Okta Setup\")\n\n1.  Verify that your GrowthBook organization is on an enterprise plan with SSO enabled.\n    \n2.  Log in to your Okta account and go to the Applications page. Select \"Browse App Catalog,\" then search for \"SCIM 2.0 Test App (OAuth Bearer Token).\" Click \"Add Integration\" to add the app to your Okta account.\n    \n\n![](https://docs.growthbook.io/assets/images/GrowthBook-SCIM-Add-Okta-Integration-b8f37987beca197b7b4be77cdb2b557f.png)\n\n3.  Once the app is added, you can change its name, for example, to \"GrowthBook SCIM.\" Click \"Next.\"\n\n![](https://docs.growthbook.io/assets/images/GrowthBook-SCIM-Add-Name-77507b06187378284271efef8d249b92.png)\n\n4.  On the next page, you don't need to modify any settings. Simply click \"Done.\"\n    \n5.  With the application created, click on the \"Provisioning\" tab and select \"Configure API Integration.\"\n    \n\n![](https://docs.growthbook.io/assets/images/GrowthBook-SCIM-Enable-API-Integration-0e476007640d15db9b3ddf1405f53930.png)\n\n6.  Now you can enter the Base URL and your OAUTH Bearer Token.\n\n*   For GrowthBook Cloud users, the Base URL is `https://api.growthbook.io/scim/v2`. If you're self-hosting GrowthBook, the Base URL will be `{YOUR_API_HOST}/scim/v2`.\n*   You can obtain your OAuth Bearer Token by creating a new Secret API Key with an `Admin` role. To do this, go to your GrowthBook account, and in the left navigation, select \"Settings → API Keys.\" We recommend creating a dedicated API key exclusively for your SCIM integration.\n\n7.  After adding your credentials, click \"Test API Credentials\" to ensure they are valid. If they pass the test, click \"Save.\"\n\n![](https://docs.growthbook.io/assets/images/GrowthBook-SCIM-Add-Credentials-e7a549b34df8bb2f37346d19a854bf48.png)\n\n8.  Next, click on the \"To App\" tab and select \"Edit\" to enable \"Create Users\" and \"Deactivate Users.\" Once enabled, click \"Save.\"\n\n![](https://docs.growthbook.io/assets/images/GrowthBook-SCIM-Configure-Options-d338c0b6cfe186252099dfc26fcf95a0.png)\n\n9.  Congratulations! Your application is now set up. You can navigate to the \"Assignments\" tab and assign people to GrowthBook and to the \"Push Groups\" tab to sync groups with GrowthBook Teams.\n\n### How to define user role when provisioning[​](#how-to-define-user-role-when-provisioning \"Direct link to How to define user role when provisioning\")\n\n1.  First, ensure that you've followed the general setup instructions above.\n    \n2.  In Okta, navigate to the Application you created for GrowthBook SCIM, and click on the \"Provisioning\" tab, and scroll to the \"Attribute Mappings\" section, before clicking \"Go to Profile Editor\".\n    \n3.  Then, you'll click \"Add Attribute\" to create a new attribute. with the following details.\n    \n\n*   Data type: string\n*   Display name: GrowthBook Role\n*   Variable name: growthbookRole\n*   External name: growthbookRole\n*   External namespace: urn:ietf:params:scim:schemas:core:2.0:User\n*   Check the box to define an enumerated list of values\n*   Here, you need to add the following enum Options\n    *   Display name: Read only\n    *   Value: readonly\n    *   Display name: Collaborator\n    *   Value: collaborator\n    *   Display name: Engineer\n    *   Value: engineer\n    *   Display name: Analyst\n    *   Value: analyst\n    *   Display name: Experimenter\n    *   Value: experimenter\n    *   Display name: Admin\n    *   Value: admin\n\n![](https://docs.growthbook.io/assets/images/GrowthBook-SCIM-Define-Role-Attribute-535f4808ce87291764954a799dd27889.png)\n\nnote\n\nIt's important each of these values are entered exactly as shown above, including capitalization. If there is a descrepancy, the user's role will fall back to your organizations default role.\n\n4.  Once complete, when you provision a user, you can select their role from the dropdown, and that will be applied to the user in GrowthBook. If you're not sure which role a user should have, you can view GrowthBook role permissions [here](https://docs.growthbook.io/account/user-permissions).\n\n![](https://docs.growthbook.io/assets/images/GrowthBook-SCIM-Define-User-Role-afa348f6755fcebbd16a880b1a68c7ad.png)\n\n## Frequently Asked Questions[​](#frequently-asked-questions \"Direct link to Frequently Asked Questions\")\n\n**What features are supported with SCIM?**\n\nCurrently, GrowthBook supports user provisioning and deprovisioning, and group pushing.\n\n**What identity providers are supported?**\n\nAt present, GrowthBook only supports Okta, but we are actively working on adding support for additional identity providers.\n\n**What happens if I deprovision a user in my identity provider?**\n\nIf a user is deprovisioned in your identity provider, they will be removed from GrowthBook. If they are re-provisioned, they will be added back to GrowthBook, and their role will reset to the organization's default role.\n\n**All the users from my group aren't being synced with my GrowthBook team. What's happening?**\n\nIf you notice that some users that you expect to be in your GrowthBook team from your identity provider are not being added in GrowthBook, double check that those users are assigned to the GrowthBook SCIM application in your identity provider. Only users that are both assigned and withing the group will be synced to the corresponding team.\n\n**What if I already have users in GrowthBook?**\n\nExisting users in GrowthBook will not be affected by SCIM. You can continue to manage them through the GrowthBook application as usual. If you wish to transition them to be managed by your identity provider, you can provision them through your identity provider. As long as the email matches, the existing GrowthBook user will be converted to be managed by your identity provider.\n\n**Does GrowthBook follow SCIM 1.1 or 2.0 Protocol?**\n\nGrowthBook follows the SCIM 2.0 protocol.\n\n**What happens if I provision a user with a role that doesn't exist?**\n\nGrowthBook will fallback to your organization's default role.\n\n**Can I provision a user with project-specific permissions?**\n\nNo, at this time, you can only provision a user's global role. Project-specific permissions must be managed through the GrowthBook application.\n\n**Can I change a user's global role after they've been provisioned?**\n\nYes, you can change a user's global role through the GrowthBook application or via Okta. Please note that if you change a user's global role through the GrowthBook Application, it will then be out-of-date in Okta. If you then update the user in Okta, it will update the user's global role.\n\n**I'm changing the user's role in Okta, but it's not changing in GrowthBook**\n\nIn order for the user's role to be updated in GrowthBook, you must update your Application provisioning to support \"updates\". Please note that the only property GrowthBook supports updating is the `growthBookRole`.",
    "title": "Configuring SCIM for GrowthBook | GrowthBook Docs",
    "description": "Setting up SCIM Integration with GrowthBook",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/sso",
    "markdown": "# SSO Instructions | GrowthBook Docs\n\n## Enterprise SSO\n\nnote\n\nSSO is available as part of our Enterprise plan.\n\nSSO is available on GrowthBook Cloud or Self-hosted via OpenID Connect. If you are using the Cloud, your account representative will help you get this setup, though the steps are mostly the same. To enable SSO on your self hosted GrowthBook instance, you will need an active license key and then you may add the SSO settings for your provider. If your provider is not listed below, you can use the generic Open ID Connect.\n\nFor GrowthBook Cloud, you will need to send your account representative the following: **CLIENT\\_ID**, **CLIENT\\_SECRET**, **EMAIL\\_DOMAIN**, what provider you're using, and for some providers, the **TENANT\\_ID**. You can use the instructions below to get these values.\n\nIf you are self-hosting, you can use the instructions below to create a JSON object with the settings, then it should be JSON encoded and then set to the environment variable `SSO_CONFIG`.\n\n## Generic Open ID Connect[​](#generic-open-id-connect \"Direct link to Generic Open ID Connect\")\n\n*   **LICENSE\\_KEY** - Your signed license key provided by the GrowthBook team\n*   **SSO\\_CONFIG** - A JSON-encoded string that configures SSO (using OpenID Connect). It should be an object with the following keys:\n*   `clientId` (string)\n*   `clientSecret` (string)\n*   `emailDomain` (string, optional) - Allow [auto-joining](https://docs.growthbook.io/account/user-permissions#self-registering-and-automatic-approvals) from a specified email domain.\n*   `metadata` (object)\n*   `issuer` (string)\n*   `authorization_endpoint` (string)\n*   `jwks_uri` (string)\n*   `id_token_signing_alg_values_supported` (array of strings)\n*   `token_endpoint` (string)\n*   `code_challenge_methods_supported` (array of strings)\n*   `logout_endpoint` (string, optional)\n*   `extraQueryParams` (object, optional) - Dictionary of extra query params to be passed along with the `/authorize` OAuth call\n*   `additionalScope` (string, optional) - Additional scopes to include, along with the default value: `openid profile email`\n\nFor SSO, make sure the following callback URL is whitelisted:\n\n*   `{APP_ORIGIN}/oauth/callback`\n\nFor the best SSO user experience, enable offline access and refresh tokens in your Identity Provider.\n\nNote\n\nWith all the SSO providers listed below, replace the all caps values with values from the provider, JSON encode the object, and set to the `SSO_CONFIG` environment variable for GrowthBook.\n\n## SSO Providers[​](#sso-providers \"Direct link to SSO Providers\")\n\n### Okta[​](#okta \"Direct link to Okta\")\n\n```\n{    \"clientId\": \"CLIENT_ID\",    \"clientSecret\": \"CLIENT_SECRET\",    \"emailDomain\": \"EMAIL_DOMAIN\",    \"additionalScope\": \"offline_access\",    \"metadata\": {        \"issuer\": \"BASE_URL\",        \"authorization_endpoint\": \"BASE_URL/oauth2/v1/authorize\",        \"id_token_signing_alg_values_supported\": [            \"RS256\"        ],        \"jwks_uri\": \"BASE_URL/oauth2/v1/keys\",        \"token_endpoint\": \"BASE_URL/oauth2/v1/token\",        \"code_challenge_methods_supported\": [            \"S256\"        ]    }}\n```\n\nSee complete Okta instructions\n\n1.  **Create an OIDC Web application:**  \n    ![](https://docs.growthbook.io/images/guides/SSO-Okta-1.png)\n2.  Allow refresh tokens and specify callback URLs. If you are using the cloud, you can use the following values:\n    \n    *   **Sign-in redirect URIs** - `[https://app.growthbook.io/oauth/callback](https://app.growthbook.io/oauth/callback)`\n    *   **Sign-out redirect URIs** (optional) - `[https://app.growthbook.io](https://app.growthbook.io/)`\n    \n    If you are self-hosting, replace with `[https://app.growthbook.io](https://app.growthbook.io/)` with the value from your `API_HOST`\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Okta-2.png)\n3.  **Require PKCE as additional verification**(optional)  \n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Okta-3.png)  \n    \n    You will need the following in order to configure SSO in GrowthBook:\n    \n    *   `CLIENT_ID`\n    *   `CLIENT_SECRET`\n    *   `BASE_URL`\n    *   `EMAIL_DOMAIN`\n    \n    If using GrowthBook Cloud, send your account representative the above and we will enable SSO on your account.\n    \n    If self-hosting, add the environment settings at the beginning of this section to enable SSO on your instance.\n    \n\n### Google[​](#google \"Direct link to Google\")\n\n```\n{    \"clientId\": \"CLIENT_ID\",    \"clientSecret\": \"CLIENT_SECRET\",    \"emailDomain\": \"EMAIL_DOMAIN\",    \"metadata\": {        \"issuer\": \"https://accounts.google.com\",        \"authorization_endpoint\": \"https://accounts.google.com/o/oauth2/v2/auth\",        \"token_endpoint\": \"https://oauth2.googleapis.com/token\",        \"jwks_uri\": \"https://www.googleapis.com/oauth2/v3/certs\",        \"id_token_signing_alg_values_supported\": [            \"RS256\"        ],        \"code_challenge_methods_supported\": [            \"S256\"        ]    },    \"extraQueryParams\": {        \"access_type\": \"offline\",        \"prompt\": \"consent\"    }}\n```\n\n### Auth0[​](#auth0 \"Direct link to Auth0\")\n\n```\n{    \"clientId\": \"CLIENT_ID\",    \"clientSecret\": \"CLIENT_SECRET\",    \"emailDomain\": \"EMAIL_DOMAIN\",    \"additionalScope\": \"offline_access\",    \"metadata\": {        \"issuer\": \"https://TENANT.auth0.com/\",        \"authorization_endpoint\": \"https://TENANT.auth0.com/authorize\",        \"logout_endpoint\": \"https://TENANT.auth0.com/v2/logout?client_id=CLIENT_ID\",        \"id_token_signing_alg_values_supported\": [            \"HS256\",            \"RS256\"        ],        \"jwks_uri\": \"https://TENANT.auth0.com/.well-known/jwks.json\",        \"token_endpoint\": \"https://TENANT.auth0.com/oauth/token\",        \"code_challenge_methods_supported\": [            \"S256\",            \"plain\"        ],        \"audience\": \"AUDIENCE\"    }}\n```\n\nnote\n\nWhen setting up Auth0, please ensure that you've enabled offline access, and check the `OIDC Compliant` checkbox.\n\n### Azure AD[​](#azure-ad \"Direct link to Azure AD\")\n\n```\n{  \"clientId\": \"CLIENT_ID\",  \"clientSecret\": \"CLIENT_SECRET\",  \"emailDomain\": \"EMAIL_DOMAIN\",  \"additionalScope\": \"offline_access\",  \"metadata\": {    \"token_endpoint\": \"https://login.microsoftonline.com/TENANT_ID/oauth2/v2.0/token\",    \"jwks_uri\": \"https://login.microsoftonline.com/TENANT_ID/discovery/v2.0/keys\",    \"id_token_signing_alg_values_supported\": [\"RS256\"],    \"code_challenge_methods_supported\": [\"S256\"],    \"issuer\": \"https://login.microsoftonline.com/TENANT_ID/v2.0\",    \"authorization_endpoint\": \"https://login.microsoftonline.com/TENANT_ID/oauth2/v2.0/authorize\",    \"logout_endpoint\": \"https://login.microsoftonline.com/TENANT_ID/oauth2/v2.0/logout\"  }}\n```\n\nnote\n\nIn Azure, register an Application, instead of Enterprise, as we use OpenID Connect, not SAML.\n\nSee complete Azure instructions\n\n1.  Register an Application (we use OpenID Connect, so choose regular app, not Enterprise)\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Azure-1.png)\n2.  Enter the redirect URL as APP\\_HOST/oauth/callback\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Azure-2.png)\n3.  Take note of your Application Id (CLIENT\\_ID) and Directory Id (TENANT\\_ID). You will need it later\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Azure-3.png)\n4.  Generate a new Client Secret  \n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Azure-4.png)\n5.  Take note of the Secret Value (CLIENT\\_SECRET). You will need it in the next step\n    \n6.  Construct the JSON configuration for GrowthBook. Replace\n    \n    CLIENT\\_ID\n    \n    , CLIENT\\_SECRET, EMAIL\\_DOMAIN, and TENANT\\_ID, as into the JSON object above.\n7.  Pass the JSON string into the environment variable SSO\\_CONFIG of your GrowthBook container\n    \n\n### OneLogin[​](#onelogin \"Direct link to OneLogin\")\n\n```\n{  \"clientId\": \"CLIENT_ID\",  \"clientSecret\": \"CLIENT_SECRET\",  \"emailDomains\": [    \"EMAIL_DOMAIN\"  ],  \"additionalScope\": \"\",  \"metadata\": {    \"issuer\": \"https://[ONELOGIN_DOMAIN]/oidc/2\",    \"authorization_endpoint\": \"https://[ONELOGIN_DOMAIN]/oidc/2/auth\",    \"token_endpoint\": \"https://[ONELOGIN_DOMAIN]/oidc/2/token\",    \"id_token_signing_alg_values_supported\": [      \"RS256\",      \"HS256\",      \"PS256\"    ],    \"jwks_uri\": \"https://[ONELOGIN_DOMAIN]/oidc/2/certs\",    \"code_challenge_methods_supported\": [      \"S256\"    ],    \"logout_endpoint\": \"https://[ONELOGIN_DOMAIN]/oidc/2/logout\"  }}\n```\n\nSee complete OneLogin instructions\n\n1.  Create a new OIDC Web application. Browse to the Applications section of OneLogin from the top nav, then choose \"Add App\" from the top right.\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Onelogin-1.png)\n2.  When the list of applications opens, search for **\"openid connect\"**. Select the option named **\"OpenID Connect (OIDC)\"**.\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Onelogin-2.png)\n3.  Add the name \"GrowthBook\" (or whatever you would like to name it), an optional description and click save. The first save may not look like anything has happened, but you should see more options on the left menu when successful.\n    \n4.  Click on the \"Configuration\" item in the left nav menu, and enter the following values for the three input fields (note: for self-hosting, replace\n    \n    app.growthbook.io\n    \n    with your own domain)\n    \n    *   **Login URL**:\n        \n        [https://app.growthbook.io](https://app.growthbook.io/)\n        \n    *   **Redirect URIs**:\n        \n        [https://app.growthbook.io/oauth/callback](https://app.growthbook.io/oauth/callback)\n        \n    *   **Post Logout Redirect URIs**:\n        \n        [https://app.growthbook.io](https://app.growthbook.io/)\n        \n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Onelogin-3.png)\n    \n    You can optionally add images for the application from the info if you like. **Click Save**.\n    \n5.  Click on the \"SSO\" item from the left nav menu. Here you need to record the **Client ID** and **Client Secret** and **Issuer URL**\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-Onelogin-4.png)\n    \n    You can leave the other settings as default (Application Type: Web, and Authentication Method: Basic). Click save if you haven't already.\n    \n6.  For self-hosted instances: construct the JSON configuration for GrowthBook. Replace CLIENT\\_ID, CLIENT\\_SECRET, EMAIL\\_DOMAIN, and TENANT\\_ID, as into the JSON object above. The ONELOGIN\\_DOMAIN will be the same domain from your Issuer URL you recorded earlier.\n    \n7.  Pass the JSON string into the environment variable SSO\\_CONFIG of your GrowthBook container\n    \n\n### JumpCloud[​](#jumpcloud \"Direct link to JumpCloud\")\n\n```\n{  \"clientId\": \"CLIENT_ID\",  \"clientSecret\": \"CLIENT_SECRET\",  \"emailDomains\": [    \"EMAIL_DOMAIN\"  ],  \"additionalScope\": \"offline_access\",  \"metadata\": {    \"token_endpoint\": \"https://oauth.id.jumpcloud.com/oauth2/token\",    \"jwks_uri\": \"https://oauth.id.jumpcloud.com/.well-known/jwks.json\",    \"id_token_signing_alg_values_supported\": [      \"RS256\"    ],    \"code_challenge_methods_supported\": [      \"S256\"    ],    \"issuer\": \"https://oauth.id.jumpcloud.com/\",    \"authorization_endpoint\": \"https://oauth.id.jumpcloud.com/oauth2/auth\",    \"logout_endpoint\": \"https://oauth.id.jumpcloud.com/oauth2/sessions/logout\",    \"audience\": \"\"  }}\n```\n\nSee complete JumpCloud instructions\n\n1.  Create a new SSO Application. Browse to the User Authentication → SSO Applications from the left nav. Choose \"Add new Application\" from the top left.\n    \n2.  Choose a custom application by clicking 'select' under `custom application`, then click next then next again to confirm.\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-jumpcloud-1.png)![](https://docs.growthbook.io/images/guides/SSO-jumpcloud-2.png)\n3.  You will then be asked what features you want to enable. Select `Manage Single Sign-On (SSO)`. Then, in the radio buttons, select **\"Configure SSO with OIDC\"**.\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-jumpcloud-3.png)\n4.  Add the name \"GrowthBook\" (or whatever you would like to name it), an optional description and click `next`. When you've confirmed the details, click `Configure Application`.\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-jumpcloud-4.png)![](https://docs.growthbook.io/images/guides/SSO-jumpcloud-5.png)\n5.  This will open a window letting you add additional configuration options for the GrowthBook application. Here are the settings you should set:\n    \n    *   **Grant types**: Select \"Refresh Token\" and Authentication Code\n    *   **Redirect URIs**:\n        \n        [https://app.growthbook.io/oauth/callback](https://app.growthbook.io/oauth/callback)\n        \n    *   **Client Authentication Type**: Client Secret Basic\n    *   **Login URL**:\n        \n        [https://app.growthbook.io](https://app.growthbook.io/)\n        \n    *   **Attribute Mapping**: Select both email and profile. The defaults for the fields that appear are all that is required.\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-jumpcloud-6.png)\n    \n    Once you have made the above settings, click 'Activate' from the bottom bar.\n    \n6.  You'll then be presented with a modal giving you the client id and client secret. Here you need to record the **Client ID** and **Client Secret**\n    \n    ![](https://docs.growthbook.io/images/guides/SSO-jumpcloud-7.png)\n7.  For self-hosted instances, construct the JSON configuration for GrowthBook. Replace CLIENT\\_ID, CLIENT\\_SECRET, and EMAIL\\_DOMAIN, as into the JSON object above.\n    \n8.  Pass the JSON string into the environment variable SSO\\_CONFIG of your GrowthBook container",
    "title": "SSO Instructions | GrowthBook Docs",
    "description": "Configuring GrowthBook for SSO",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/compliance",
    "markdown": "# Compliance | GrowthBook Docs\n\n## Security Compliance\n\nGrowthBook takes security seriously and is compliant with **SOC2**, **GDPR**, and **HIPAA**. We perform regular penetration testing, have an active bug bounty program, and maintain strict controls to protect data privacy.\n\nView our [Trust Center](https://trust.growthbook.io/) to request access to the above ceritifications, as well as our most recent penetration test report, incident response plan, access control policy, and more.",
    "title": "Compliance | GrowthBook Docs",
    "description": "Compliance",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/account/audit-logs",
    "markdown": "# Audit logs | GrowthBook Docs\n\nGrowthBook keeps an audit log of all actions taken on the platform. You can access this page from the Settings → Log in the left navigation.\n\n![Audit log page](https://docs.growthbook.io/images/using/audit-logs.png)\n\nThese logs are useful for auditing what users have done, and figuring out the cause of any issues. These logs are not user editable. For enterprise customers, this log is exportable. We have more filtering options coming soon.",
    "title": "Audit logs | GrowthBook Docs",
    "description": "GrowthBook's Audit Logs",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/guide",
    "markdown": "# How to Guides for installing the platform\n\n## GrowthBook Detailed Guides.\n\nThe following sections contain detailed walkthrough's on how to set up GrowthBook with various technologies.\n\nThis is not a complete list of the ways GrowthBook can be integrated.\n\n## Tutorials[​](#tutorials \"Direct link to Tutorials\")\n\n*   [GrowthBook with Next.js (App Router)](https://docs.growthbook.io/guide/nextjs-app-router)\n*   [GrowthBook with Next.js (Pages Router)](https://docs.growthbook.io/guide/nextjs-and-growthbook)\n*   [GrowthBook with Create React App](https://docs.growthbook.io/guide/create-react-app-and-growthbook)\n*   [GrowthBook with Next.js and Rudderstack](https://docs.growthbook.io/guide/rudderstack-and-nextjs-with-growthbook)\n*   [GrowthBook with Google Tag Manager](https://docs.growthbook.io/guide/google-tag-manager-and-growthbook)\n*   [GrowthBook with Webflow](https://docs.growthbook.io/integrations/webflow)\n*   [GrowthBook with Shopify](https://docs.growthbook.io/integrations/shopify)\n*   [GrowthBook with Wordpress](https://docs.growthbook.io/integrations/wordpress)\n\n## A/B testing guide[​](#ab-testing-guide \"Direct link to A/B testing guide\")\n\n*   [The Open Guide to Successful A/B Testing (pdf)](https://docs.growthbook.io/assets/files/open-guide-to-ab-testing.v1.0-228e9312b957a9716766cd8887b18a11.pdf)",
    "title": "How to Guides for installing the platform | GrowthBook Docs",
    "description": "The following sections contain detailed walkthrough's on how to set up GrowthBook with various technologies.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/faq",
    "markdown": "# FAQ | GrowthBook Docs\n\nBelow are some frequently asked questions about GrowthBook.\n\n## Do users always get assigned the same experiment variation?[​](#do-users-always-get-assigned-the-same-experiment-variation \"Direct link to Do users always get assigned the same experiment variation?\")\n\nGrowthBook SDKs use deterministic hashing to ensure the same user always gets assigned the same variation in an experiment.\n\nIn a nutshell, GrowthBook hashes together the `hashAttribute` (the user attribute used to assign a variation, ex: user id) and the experiment `trackingKey` which produces a decimal between 0 and 1. Each variation is assigned a range of values (e.g. `0 to 0.5` and `0.5 to 1.0`) and the user is assigned to whichever one their hash falls into.\n\nThis does mean, if you change the experiment configuration, some users may switch their assigned variation. For example, if someone has the hash `0.49` and you adjust the weights to a 40/60 experiment, the variation ranges become `0 to 0.4` and `0.4 to 1.0`. In this case, the user was previously in the control group, but will now be in the variation.\n\nGrowthBook will detect issues like this and will remove users who see both variations from the analysis automatically. However, to keep things simple and safe, we recommend not relying on this and treating experiments as immutable once they are running.\n\nIt's important to note that the above only applies when changing the traffic split between variations. If you keep the split the same, but increase the percent of traffic included, users will not switch variations. For example, if you are running a 50/50 experiment on 20% of traffic, the variation ranges will be `0 to 0.1` and `0.5 to 0.6`. Users outside those ranges will be excluded from the experiment. If you increase the percent of traffic to 40%, but keep the 50/50 split, the ranges will become: `0 to 0.2` and `0.5 to 0.7`. As you can see, no users switch variations. Instead, some users who were previously excluded are now part of the experiment.\n\n## What do I use for an \"id\" attribute in the SDK if my users aren't logged in?[​](#what-do-i-use-for-an-id-attribute-in-the-sdk-if-my-users-arent-logged-in \"Direct link to What do I use for an \"id\" attribute in the SDK if my users aren't logged in?\")\n\nIf your application has both logged-in and anonymous users, we recommend using two identifier attributes:\n\n*   `id` which is the database identifier of logged-in users (or empty string for anonymous)\n*   `deviceId` (or `sessionId`, etc.) which is a random anonymous hash, persisted in a cookie or local storage. This should always be set for both anonymous and logged-in users.\n\nIf your application only has anonymous users (e.g. a static marketing site), then we recommend a single `id` attribute which, similar to `deviceId` or `sessionId` above, is a random hash persisted in a cookie or local storage.\n\n## Why is the trackingCallback not firing in the SDK?[​](#why-is-the-trackingcallback-not-firing-in-the-sdk \"Direct link to Why is the trackingCallback not firing in the SDK?\")\n\nThe `trackingCallback` only fires when a user is included in an experiment. If you're expecting to be included and you're still not seeing the callback fire, it's likely for one of the following reasons:\n\n*   You are missing the `hashAttribute` for the experiment. For example, when you are splitting users by \"company\", but the company attribute is empty.\n*   The feature is disabled for the environment you are in (dev/prod)\n*   The experiment has reduced coverage. For example, if it's only running for 10% of users and you are in the 90% that are excluded.\n*   There is another feature rule that is taking precedence over the experiment.\n\nIf you are using the Javascript or React SDK in a browser environment, you can install the [GrowthBook DevTools Chrome Extension](https://chrome.google.com/webstore/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia) to help you debug.\n\n**Note**: To use the plugin, you will need to pass `enableDevMode: true` when creating your GrowthBook instance.\n\n```\nconst growthbook = new GrowthBook({  enableDevMode: true,})\n```\n\n## How do I run an A/B test in GrowthBook?[​](#how-do-i-run-an-ab-test-in-growthbook \"Direct link to How do I run an A/B test in GrowthBook?\")\n\nThe recommended way to run an A/B test is by using Feature Flags and our SDKs.\n\n1.  Create a feature in GrowthBook (e.g. `new-signup-form`) with an A/B Experiment rule\n2.  Use our SDKs to serve the different variations\n    \n    ```\n    if (growthbook.feature(\"new-signup-form\").on) {  // Variation} else {  // Control}\n    ```\n    \n\n## What is the best way to redirect users to a URL based on their experiment variation?[​](#what-is-the-best-way-to-redirect-users-to-a-url-based-on-their-experiment-variation \"Direct link to What is the best way to redirect users to a URL based on their experiment variation?\")\n\nYou can now easily set up URL Redirect experiments within GrowthBook and customize navigation depending on your application. Read more about running a URL Redirect experiment [here](https://docs.growthbook.io/app/url-redirects).\n\n## How much traffic do I need to run A/B tests?[​](#how-much-traffic-do-i-need-to-run-ab-tests \"Direct link to How much traffic do I need to run A/B tests?\")\n\nWhat matters most for A/B testing is not traffic, but conversions. The general rule of thumb is to have at least 100-200 conversions per variation before you might start reaching significance.\n\nSo that means if you do 50 orders per week and that's the metric you are trying to optimize, you'll need to run a simple 2-way A/B test for at least 4-8 weeks. If you run a 3-way test, it will take 6-12 weeks.\n\n## Can I run multiple A/B tests at a time?[​](#can-i-run-multiple-ab-tests-at-a-time \"Direct link to Can I run multiple A/B tests at a time?\")\n\nYes! In fact, we recommend running many experiments in parallel in your application. Most A/B tests fail, so the more shots-on-goal you take, the more likely you are to get a winner. Running tests in parallel is a great way to increase your velocity.\n\nNow it's possible your experiments might have interaction effects, but these are actually pretty rare in practice. One example is if one test is changing the text color on a page and another test is changing the background color. Some users might see end up seeing black text on a black background, which is obviously not ideal. For these rare cases, you can use [Namespaces](https://docs.growthbook.io/features/rules#namespaces) to run mutually exclusive experiments.\n\nAs long as you apply a little common sense to avoid situations like the above, running multiple experiments has low risk and really high reward.\n\n## What is the difference between a Dimension and a Segment?[​](#what-is-the-difference-between-a-dimension-and-a-segment \"Direct link to What is the difference between a Dimension and a Segment?\")\n\nA dimension is a user attribute that can have multiple values. Some examples are `country`, `account_type`, and `browser`.\n\nA segment is a specific group of users. Some examples are `visitors in the US`, `premium users`, and `chrome users`.\n\nDimensions are used to explore experiment results. For example, you can use a `country` dimension to see which countries had the highest conversion rates. Or an `account_type` dimension to see if there was a significant difference in how free vs paid users behaved. Or a `browser` dimension to detect any browser-specific bugs in your implementation.\n\nSegments can apply a filter to results, usually to compensate for bad data. For example, if your experiment was only visible to premium users, but your database inaccurately shows that free users were also included, you could apply a `premium users` segment to only include those who were actually exposed to the test. Ideally, you could just fix the underlying data, but that's often not feasible so segments provide a quick and dirty alternative.\n\n## Which docker image tag should I use when self-hosting?[​](#which-docker-image-tag-should-i-use-when-self-hosting \"Direct link to Which docker image tag should I use when self-hosting?\")\n\nWe recommend using the `latest` tag for both dev and production self-hosted deployments. This tag represents the latest stable build of GrowthBook and is what the Cloud app uses.\n\nSpecific version tags (e.g. `v1.1.0`) are only released periodically (about once a month) and you will miss out on the many bug fixes and features added between major releases.\n\nWe also recommend updating the image regularly. You can do that by downloading the latest image (`docker pull growthbook/growthbook:latest`) and restarting the container.\n\n## What are the hardware requirements for self-hosting GrowthBook?[​](#what-are-the-hardware-requirements-for-self-hosting-growthbook \"Direct link to What are the hardware requirements for self-hosting GrowthBook?\")\n\nThe GrowthBook application is very lightweight and efficient. For most usecases, 2GB of memory is sufficient even for large production deployments.\n\nGrowthBook only deals with aggregate data and the bulk of the processing is offloaded to your data source. Because of this, you can easily analyze terrabytes of data from your laptop or a small container in the cloud.\n\nIf you are using feature flags, **we strongly recommend** adding a caching layer between the GrowthBook API and your application in production. This will also help you stay within the limits of our [Fair Use Policy](https://www.growthbook.io/fair-use). Some of our [code examples](https://github.com/growthbook/examples) implement caching. We offer a pre-built [GrowthBook Proxy server](https://docs.growthbook.io/self-host/proxy) you can run that handles caching and invalidation automatically. You can also setup your own custom system using a CDN or distributed cache like Redis.\n\n## I can't upload to S3/getting 400 error when uploading to S3?[​](#i-cant-upload-to-s3getting-400-error-when-uploading-to-s3 \"Direct link to I can't upload to S3/getting 400 error when uploading to S3?\")\n\n*   Make sure you've correctly set the `S3_BUCKET` and `S3_REGION` environment variables\n*   Enable bucket ACL and set ownership to Bucket owner preferred: [read more here](https://stackoverflow.com/questions/70333681/for-an-amazon-s3-bucket-deplolyent-from-guithub-how-do-i-fix-the-error-accesscon).\n*   Make sure the S3 bucket is publically accessible\n*   Make sure CORS settings are correct. Add your URLs to the AllowedOrigins array or set to \"\\*\"\n\n*   Make sure you are using the React or Javascript SDK\n*   Install the [Chrome DevTools Extension](https://chrome.google.com/webstore/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia)\n*   Pass the `enableDevMode: true` option into the GrowthBook constructor\n\n```\nconst growthbook = new GrowthBook({  enableDevMode: true,})\n```\n\n## My old exported notebook stopped working. How can I fix it?[​](#my-old-exported-notebook-stopped-working-how-can-i-fix-it \"Direct link to My old exported notebook stopped working. How can I fix it?\")\n\nThere's a good chance that the SQL we are exporting and your version of our Python stats library, `gbstats`, are out of sync. In February of 2023 we updated our SQL engines and `gbstats` library to only use sums and sums of squares, rather than averages and standard deviations.\n\nIf the queries in your notebook return averages and standard deviations (using `AVG` and `VAR` SQL operators as part of the `__stats` CTE), then you need to run that notebook with `gbstats` version 0.3.1. You can download this from PyPI [here](https://pypi.org/project/gbstats/0.3.1/) using `pip install gbstats==0.3.1` and ensure that your kernel uses that version of `gbstats`. Ideally in this case you can redownload the notebook and use the new `gbstats` library (0.4.0 or newer). You can download a new notebook by navigating to your experiment in GrowthBook and clicking `Download Notebook` again. This should now use the updated SQL and `gbstats` syntax. Then, if you install `gbstats` 0.4.0 or later, everything should work as expected.\n\nIf the queries in your notebook return sums and sums of squares as part of the `__stats` CTE but your notebook is still erroring, then you probably have an old `gbstats` version installed and need to update to 0.4.0 or later. You can download this from PyPI [here](https://pypi.org/project/gbstats) using `pip install gbstats` and ensure that your kernel uses that version of `gbstats`.\n\n## My features aren't refreshing as expected. What can I do?[​](#my-features-arent-refreshing-as-expected-what-can-i-do \"Direct link to My features aren't refreshing as expected. What can I do?\")\n\nOur SDK's implement a stale-while-revalidate approach to cacheing with a configurable time-to-live (TTL) value.\n\nThis means that if the feature payload is considered stale (i.e. more than the TTL amount of time has passed since it's been updated), **the next request will return the stale features** and refetch an update asynchronously so that on the next request, the features will be up to date. You can learn more about how our SDK's implement this in detail [here](https://docs.growthbook.io/lib/build-your-own#fetching-and-caching-features).\n\nIf you would like something more real-time than this stale-while-revalidate approach, you may want to consider implementing the [GrowthBook Proxy](https://docs.growthbook.io/self-host/proxy) on your self-hosted instance.\n\n## How do I configure environments in the SDK?[​](#how-do-i-configure-environments-in-the-sdk \"Direct link to How do I configure environments in the SDK?\")\n\nWhen you create an SDK connection, it is linked to a specific environment. You can learn more about environments [here](https://docs.growthbook.io/features/environments).\n\n## How do I disable the on-screen celebrations?[​](#how-do-i-disable-the-on-screen-celebrations \"Direct link to How do I disable the on-screen celebrations?\")\n\nThroughout the GrowthBook application, we randomly celebrate key milestones like launching experiments with on-screen confetti. If you'd like to disable this, you can click on your avatar in the top right corner and select \"Edit Profile\". From there, you can disable the toggle for \"Allow Celebrations\". Please note this is persisted in your browser's local storage, so if you clear your browser's local storage, you will need to disable this again.\n\n## How do I make my own identifier?[​](#how-do-i-make-my-own-identifier \"Direct link to How do I make my own identifier?\")\n\nThere are cases when using feature flags client side where the 3rd party identifiers used for assignment will be slow to load, and may cause flickering as some of the DOM rerenders. In these cases, generating your own identifier will make sure that features are assigned correctly when GrowthBook loads. This id that is generated will typically align one to one with the other identifiers, and does not need to be passed outside the SDK (though can be useful for debugging to pass this value in the trackingCallback).\n\nThe code below can be used to generate a unique user id and save it in a cookie for the maximum amount of time allowed. Note, this technique is already included with our HTML/no-code SDK. Please be aware of any cookie policies this code may impact. This id will be unique to the browser and not the user, so if a user switches devices, they will have a different id.\n\n```\nconst getUUID = () => {  const COOKIE_NAME = \"gbuuid\";  const COOKIE_DAYS = 400; // 400 days is the max cookie duration for chrome  // use the browsers crypto.randomUUID if set  const genUUID = () => {    if(window?.crypto?.randomUUID) return window.crypto.randomUUID();    return ([1e7]+-1e3+-4e3+-8e3+-1e11).replace(/[018]/g, c =>      (c ^ crypto.getRandomValues(new Uint8Array(1))[0] & 15 >> c / 4).toString(16)    );  }  const getCookie = (name) => {    let value = `; ${document.cookie}`;    let parts = value.split(`; ${name}=`);    if (parts.length === 2) {      let existing = parts.pop().split(';').shift();      setCookie(name, existing);      return existing;    }  }  const setCookie = (name, value) => {    var d = new Date();    d.setTime(d.getTime() + 24*60*60*1000*COOKIE_DAYS);    document.cookie = name + \"=\" + value + \";path=/;expires=\" + d.toGMTString();  }  // get the existing UUID from cookie if set, otherwise create one and store it in the cookie  let existing = getCookie(COOKIE_NAME);  if(existing) return existing;  const uuid = genUUID();  setCookie(COOKIE_NAME, uuid);  return uuid;}\n```\n\nBelow is the same code, minified:\n\n```\nconst getUUID=()=>{const a=(a,b)=>{var c=new Date;c.setTime(c.getTime()+86400000*400),document.cookie=a+\"=\"+b+\";path=/;expires=\"+c.toGMTString()};let b=(b=>{let c=`; ${document.cookie}`,d=c.split(`; ${b}=`);if(2===d.length){let c=d.pop().split(\";\").shift();return a(b,c),c}})(\"gbuuid\");if(b)return b;const c=(()=>window?.crypto?.randomUUID?window.crypto.randomUUID():\"10000000-1000-4000-8000-100000000000\".replace(/[018]/g,a=>(a^crypto.getRandomValues(new Uint8Array(1))[0]&15>>a/4).toString(16)))();return a(\"gbuuid\",c),c};\n```\n\n* * *\n\n## Can't find your question?[​](#cant-find-your-question \"Direct link to Can't find your question?\")\n\nIf you can't find an answer to your question above, please let us know so we can help you out and improve the docs for future users!\n\nYou can join our [Slack channel](https://slack.growthbook.io/?ref=docs-faq) for the fastest response times.\n\nOr send an email to [hello@growthbook.io](mailto:hello@growthbook.io) if Slack isn't your thing.",
    "title": "FAQ | GrowthBook Docs",
    "description": "Frequently asked questions about GrowthBook.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/using/fundamentals",
    "markdown": "# A/B Testing Fundamentals | GrowthBook Docs\n\nIf you are new to A/B testing, you may find a lot of new terminology. The goal of this section is to help you understand the basics of A/B testing.\n\n## Glossary - Common Experimentation Terms[​](#glossary---common-experimentation-terms \"Direct link to Glossary - Common Experimentation Terms\")\n\n### Control (or Baseline)[​](#control-or-baseline \"Direct link to Control (or Baseline)\")\n\nThe existing version of the product that you are trying to improve upon.\n\n### Variation (or Treatment)[​](#variation-or-treatment \"Direct link to Variation (or Treatment)\")\n\nA new version of the page that you are testing against the Control.\n\n### Hypothesis[​](#hypothesis \"Direct link to Hypothesis\")\n\nFormal way to describe what you are changing and what you think it will do.\n\n### Statistical Significance[​](#statistical-significance \"Direct link to Statistical Significance\")\n\nAn indicator that the difference in performance between the control and treatment groups is unlikely to have occurred by chance.\n\n### Confidence level[​](#confidence-level \"Direct link to Confidence level\")\n\nThe level of certainty we want before the result of a test is statistically significant. A common confidence level used in A/B testing is 95%.\n\n### Sample size[​](#sample-size \"Direct link to Sample size\")\n\nThe number of visitors or users who are included in the A/B test.\n\n### Test duration[​](#test-duration \"Direct link to Test duration\")\n\nThe length of time that the A/B test is run. This can vary depending on the sample size and the desired confidence level.\n\n### Variance[​](#variance \"Direct link to Variance\")\n\nThe degree to which the results of an A/B test vary over time or across different segments of the user base.\n\n## Anatomy of an A/B test[​](#anatomy-of-an-ab-test \"Direct link to Anatomy of an A/B test\")\n\n![Anatomy of an A/B test](https://docs.growthbook.io/assets/images/ab-test-diagram-63db820ea7e29530da0b5847145714d4.png)\n\n|     |     |     |     |     |\n| --- | --- | --- | --- | --- |\n| **Hypothesis**<br><br>Come up with an idea you want to test | **Assignment**<br><br>Randomly split your audience into persistent groups | **Variations**<br><br>Create and show different experiences to each group | **Tracking**<br><br>Record events and behaviors of the two groups | **Results**<br><br>Use statistics to determine if the differences in behavior are significant |\n\n### Hypothesis[​](#hypothesis-1 \"Direct link to Hypothesis\")\n\nGood A/B tests, and really any project, starts with a hypothesis about what you’re trying to do. A good hypothesis should be as simple, specific, and falsifiable as possible.\n\nA good A/B test hypothesis should be:\n\n*   **Specific**: The hypothesis should clearly state what you want to test and what outcome you expect to see.\n*   **Measurable**: The hypothesis should include a metric or metrics that can be used to evaluate the outcome of the test.\n*   **Relevant**: The hypothesis should be relevant to your business goals and objectives.\n*   **Clear**: The hypothesis should be easy to understand and communicate to others.\n*   **Simple**: The fewer variables that are involved in the experiment, the more causality can be implied in the results.\n*   **Falsifiable**: The hypothesis should be something that can be tested using an A/B test to determine the validity of the hypothesis.\n\nOverall, a good A/B test hypothesis should be a clear statement that identifies a specific change you want to make and the expected impact on a measurable outcome, while being grounded in data and relevant to your business goals.\n\n### Audience and Assignments[​](#audience-and-assignments \"Direct link to Audience and Assignments\")\n\nChoose the audience for your experiment. To increase the detectable effect of your experiment, the audience you choose should be as close to the experiment as possible. For example, if you’re focusing on a new user registration form, you should select as your audience just unregistered users. If you were to include all users, you would have users who could not see the experiment, which would increase the noise and reduce the ability to detect an effect. Once you have selected your audience, you will randomize users to one variation or another.\n\n### Variations[​](#variations \"Direct link to Variations\")\n\nAn A/B test can include as many variations as you like. Typically the A variation is the control variation. The variations can have as many changes as you like, but the more you change the less certain you can be what caused the change.\n\n### Tracking[​](#tracking \"Direct link to Tracking\")\n\nTracking is the process of recording events and behaviors that your users do. In the context of AB testing, you want to track events that happen after exposure to the experiment, as these events will be used to determine if there is a change in performance due to being exposed to the experiment. AB testing systems either are \"warehouse native\" (like GrowthBook) as in they use your existing event trackers (like GA, Segment, Rudderstack, etc), or they require you to send event data to them.\n\n### Results[​](#results \"Direct link to Results\")\n\nWith A/B testing we use statistics to determine if the effect we measure on a metric of interest is significantly different across variations. The results of an A/B test on a particular metric can have three possible outcomes: win, loss, or inconclusive. With GrowthBook we offer two different statistical approaches, Frequentist and Bayesian. By default, GrowthBook uses Bayesian statistics. Each method has their pros and cons, but both will provide you with evidence as to how each variation affected your metrics.\n\n## Experimentation Basics[​](#experimentation-basics \"Direct link to Experimentation Basics\")\n\n### Typical success rates[​](#typical-success-rates \"Direct link to Typical success rates\")\n\nA/B testing can be incredibly humbling—one quickly learns how often our intuition about what will be successful with our users is incorrect. Industry wide average success rates are only about 33%. ⅓ of the time our experiments are successful in improving the metrics we intended to improve, ⅓ of the time we have no effect, and ⅓ of the time we hurt those metrics. Furthermore, the more optimized your product is, the lower your success rates tend to be.\n\nBut A/B testing is not only humbling, it can dramatically improve decision making. Rather than thinking we only win 33% of the time, the above statistics really show that A/B tests help us make a clearly right decision about 66% of the time. Of course, shipping a product that won (33% of the time) is a win, but so is not shipping a product that lost (another 33% of the time). Failing fast through experimentation is success in terms of loss avoidance, as you are not shipping products that are hurting your metrics of interest.\n\n### Experiment power[​](#experiment-power \"Direct link to Experiment power\")\n\nWith A/B testing, power analysis refers to whether a test can reliably detect an effect. Specifically, it is often written as the percent of the time a test would detect an effect of a given size with a given number of users. You can also think of the power of a test with respect to the sample size. For example: \"How many times do I need to toss a coin to conclude it is rigged by a certain amount?\"\n\n### Minimal Detectable Effect (MDE)[​](#minimal-detectable-effect-mde \"Direct link to Minimal Detectable Effect (MDE)\")\n\nMinimal Detectable Effect is the minimum difference in performance between the control and treatment groups that can be detected by the A/B test, given a certain statistical significance threshold and power. The MDE is an important consideration when designing an A/B test because if the expected effect size is smaller than the MDE, then the test may not be able to detect a significant difference between the groups, even if one exists. Therefore, it is useful to calculate the MDE based on the desired level of statistical significance, power, and sample size, and ensure that the expected effect size is larger than the MDE in order to ensure that the A/B test is able to accurately detect the difference between the control and treatment groups.\n\n### False Positives (Type I Errors) and False Negatives (Type II Errors)[​](#false-positives-type-i-errors-and-false-negatives-type-ii-errors \"Direct link to False Positives (Type I Errors) and False Negatives (Type II Errors)\")\n\nWhen making decisions about an experiment, we can say that we made the right decision when choosing to ship a winning variation or shut down a losing variation. However, because there is always uncertainty in the world and we rely on statistics, sometimes we make mistakes. Generally, there are two kinds of errors we can make: Type I and Type II errors.\n\n**Type I Errors**: also known as False Positives, these are errors we make when we think the experiment provides us with a clear winner or a clear loser, but in reality the data are not clear enough to make this decision. For example, your metrics all appear to be winners, but in reality the experiment has no effect.\n\n**Type II Errors**: also known as False Negatives, these are errors we make when the data appear inconclusive, but in reality there is a winner or a loser. For example, you run an experiment for as long as you planned to, and the data aren’t showing a clear winner or loser when actually a variation is much better or worse. Type II errors often require you to collect more data or choose blindly rather than provide you with the correct, clear answer\n\n|     |     |     |     |     |\n| --- | --- | --- | --- | --- |\n|     |     | Actual Results |     |     |\n| **Inconclusive** | **Lost** | **Won** |\n| Decision Made | **Inconclusive** | Correct Inference | Type II error  <br>(false negative) | Type II error  <br>(false negative) |\n| **Shut down** | Type I error  <br>(false positive) | Correct Inference | Type I error  <br>(false positive) |\n| **Ship** | Type I error  <br>(false positive) | Type I error  <br>(false positive) | Correct Inference |\n\n### P-Value[​](#p-value \"Direct link to P-Value\")\n\nIn frequentist statistics, a p-value is a measure of the evidence against a null hypothesis. The null hypothesis is the hypothesis that there is no significant difference between two groups, or no relationship between two variables. In the context of A/B testing, the p-value is a statistical measure that indicates whether there is a significant difference between two groups, A and B.\n\nThe p-value is the probability of observing a difference as extreme or more extreme as your actual difference, given there is actually no difference between groups. If the p-value is less than a predetermined level of significance (often 0.05), the result is deemed to be statistically significant as the difference is not likely due to chance.\n\nFor example, let's say that you conduct an A/B test in which you randomly assign users to either group A (the control group) or group B (the experimental group). You measure a specific metric such as conversion rate for each group, and you calculate the p-value to test the hypothesis that there is no difference between the two groups. If the p-value is less than 0.05, the observed difference conversion rate between the two groups is unlikely if there wasn't truly a difference in groups; we say the effect is statistically significant and likely not due to chance.\n\nIt's important to note that p-value alone cannot determine the importance or practical significance of the findings. Additionally, it's essential to consider other factors such as effect size, sample size, and study design when interpreting the results.\n\n### A/A Tests[​](#aa-tests \"Direct link to A/A Tests\")\n\nA/A testing is a form of A/B testing in which instead of serving two different variations, two identical versions of a product or design are tested against each other. In A/A testing, the purpose is not to compare the performance of the two versions, but rather to check the consistency of the testing platform and methodology.\n\nThe idea behind A/A testing is that if the two identical versions of the product or design produce significantly different results, then there may be an issue with the testing platform or methodology that is causing the inconsistency. By running an A/A test, you can identify and address any potential issues before running an A/B test, which can help ensure that the results of the A/B test are reliable and meaningful.\n\nA/A testing is a useful tool for ensuring the accuracy and reliability of A/B tests, and can help improve the trust in the platform, and faith in the quality of the insights and decisions that are based on the results of these tests.\n\n[Read more about running A/A tests in GrowthBook](https://docs.growthbook.io/kb/experiments/aa-tests).\n\n### Interaction effects[​](#interaction-effects \"Direct link to Interaction effects\")\n\nWhen you run more than one test at a time, there is a chance that the tests may interfere with each other. For example, you could have two tests that change the price on two different parts of your product. Some combinations of the two experiments can cause users to see two different prices confused and lose trust in your product. This is an extreme example. A more common example is someone who sees an experiment on the account registration page, and then another test on the checkout page. If the tests are run in parallel, you will have users who see all combinations of variations: **AA, AB, BA**, and **BB**. A _meaningful_ interaction effect would be the combination of AA, for example, out performs the other combinations more than each test alone. If there are interaction effects of tests run in parallel, but they are unlikely to be meaningful. Most often they will just increase the variance of the tests without changing the results.\n\n### Novelty and Primacy Effects[​](#novelty-and-primacy-effects \"Direct link to Novelty and Primacy Effects\")\n\nNovelty and primacy effects are psychological phenomena that can influence the results of A/B testing. The novelty effect refers to the tendency of people to react positively to something new and different. In the context of A/B testing, a new design or feature may initially perform better than an existing design simply because it is new and novel. However, over time, the novelty effect may wear off and the performance of the new design may decrease.\n\nThe primacy effect refers to the tendency of people to remember and give more weight to information that they encounter first. With A/B testing, this can manifest as an initial reduction in the improvement for metrics as users prefer the original treatment of the product.\n\nOne way to mitigate the effects of novelty is to run tests over a longer period of time to allow for the novelty effect to wear off. Another approach is to stagger the rollout of a new design or feature to gradually introduce it to users and avoid a sudden and overwhelming change.\n\nTo account for the primacy effect, you can target or segment an experiment to just new users to ensure that they won’t be influenced by how things used to work. This can help ensure that the results of the test are truly reflective of user behavior and preferences, rather than the order in which designs were presented.",
    "title": "A/B Testing Fundamentals | GrowthBook Docs",
    "description": "If you are new to A/B testing, you may find a lot of new terminology. The goal of this section is to help",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/kb/experiments/troubleshooting-experiments",
    "markdown": "# Troubleshooting Experiments | GrowthBook Docs\n\n## Problem 1: No traffic flowing into the experiment[​](#problem-1-no-traffic-flowing-into-the-experiment \"Direct link to Problem 1: No traffic flowing into the experiment\")\n\nThere are a few common reasons why there may not be any data showing in the Results tab of your experiment's detail page, first among them is a lack of experiment traffic. You'll likely see a banner like this:\n\n![No Data Banner](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAYAAACKCAMAAAAOubhbAAAAw1BMVEXR7PH///++5esKVGC01Nppl5/J5euqzNLL6O0PVmJYipMYW2aTucDP6u/G4+kcXml8p643b3rQ6/CMtLt/qbAxbHakx82nytC62d/D4ee93OHA3uRsmqI9dX9DeYMlY246cnwtaHMUWWVVh5C21tx0oKiZvsVLf4ibv8aWvMNOgYsiYWuIsLeDrLSgxMpcjZYpZnGQt75RhI2GrrV4o6uu0NasztRllJxhkJmx0thHfIVwnaWdwcgRWGLq9vjE5+3T7fIKCp/rAAAUKklEQVR42uzYsY3EMBRDQR8jxS7oy/1XdRUsYKfiTBEPBK8/oJwMQD0ZgHoyAPVkAOrJANSTAagnA1BPBqCeDEA9GYB6MgD1ZADqyQDUkwGoJwNQ71cG5tkBDrGf+ZyBWQGOsuZbBibZ676AQ9xrJ/MlA5OsCzjKSuZDBpYKwHlW1vsMTPYFnObemdcZeIwBONHK8zoDO95BONCd/ToDyQUcKJEBKCcDUE8GoJ4MQD0ZgH926mClYSCKwvCFU6yJLVbQNm0VhC4iA7boVFTw/Z9LV0LASiANpp7/W96Z3YHfHhkA7JEBwB4ZAOyRAcAeGQDskQHAHhkA7JEBwB4ZAOyRAcAeGQDskQHAHhkA7JEBwB4ZAOyRAcAeGQDskQHAHhkA7JEBwB4ZAOyRAcAeGQDskQHAHhkA7JEBwN5AM/BSluMYuFVZPoS9qr7rZant/WYZDf2Mdn1zG8PyWO6ilRPJwHPaTePbPKV5tPUhTeIvjFJKZ43L+uuy+vGrNAt7r1IdPbiS9tFNm9HWhbSIQdnoIlo4mQwUjSUn0qR7Bqqc36OrRc7LQ0+ScuOylzQiA4fMpLfoYZFaeopfTHPeHiED55cqqhiUf5iBYnzkDHyyc+bdyeJQHM45P2UREQFRcEOty6u4ttVa237/rzVDEhJTo9OeWTvH55/2VXIl9948QOzML2BF/ixdoHRDA77Sbtu7Bm5hrZ4T8jdUpP0WuuQGBvDwF2iAHMpr8t/if6gBRNbP04BylzjFXQN/P/qK/EkN/NCi/R81gJcfqIENkczuGtBy14DgroGb2OiNgHeNBsbV+mqaEA2HsD5vKxpImqulaRHK3mwAXdM0CcUtVevT9ucI5p5wXNMc8+rv6sumW7xYAarsLb0GRvLUYpxrwDqEjWbtoqM6plniv80bq6lBLkneG9WSyzvYNDtFeNMMih+u2VjpoojPSIgYxRNivS/roXl2iEUYr+yEZFyFoBnWw72I1S4mRMezU3rd1auxbggP/0qIsX7+RSeTsKzGhNTmqyY9hdp6tWPDNTNKTLNGSDJvTOPrFWnLycTVxi8eTGagCZxM0zSKcONlPVFqJAhaIe0SfdFK5l4WIg5X64QIatPGUz6fUj5djpzre+Np7V4kRO1v+abbWjamNSIx3lf1alsJ2ak+7wsNjE3TlQEO5JKfo4HF6whp8lkDZh85o01yIYEeANgvidBAZ4Ec+4H2UATGiOTsPORk75/2luxE3jo0aNgTcrYhjQjO7IoGljbqZ5cpp1FowHqzkePHakfFW3gmDb2hB3hdl6iMB8jx2JxM4Enus+fNXgaMfDaePgofVCacHrL8PfctQ07E81qXvvLRI0rcc6osjb0WzY1dPLiVPnAK2JjxjCW9oxnCwg9I+QN4JKQJ5GmtAWX30QYwbBHyRE9smC9rzYzmwDTpIefFuFaRCdBmRUzZJPfkjCM4JgtX2gLYqzXi7Nipp6G+aH0Mi0y18iBwngKujzeHzuKd9BARAZtrsPJoS+0uEqL0t3jzPaKx34qauhOPp1iENPJhjUIDdWBafN5HHveCH6QB0gAePmmgOgKQjUSfSJoOAMcDenN+cCsDkKYAenlOB84I+HCcjN08AfbQAexQaXJgSRgb2J28kfKwtJm6edM5jg2MHOfxigZ+PWIYEIaV4Rjy1ZX4AJyhDWSm6CjWUBnt0fEQgDcCcDLUJxkP2J4yAC9XNdDMx3k3okTY8rOKmRFqfQA2ndebTgNqXMkEPB2jOf8mZEK7vg8vZmNKKZDRnZ22Zghr7CfgswZeYG8BOHED8DIA25jo8pIXtwcM81dm+opIDTwDdtR3gI8dkZSdvO6O4zANhBGoBtQaUd7oavUAdF1d0aQGDhk+8pF4/jTpXxoNTACbuq6uJuSiv9mba5t34CPzgDEDMPIAbEtFyAeca6ANVAgjBObkgh+lgWAGhIoGSiNgsg+s9QMwUC54RgpUmq7b3GDID+4D9ZiQ5AiUP+0NrAG/ZRHyngI19SugGTeuh0VecQd2fUySagrMv7A38Gstn2R2wKHQwBtQeQ2ItbIxONNAe4iUvu8OgKP5+8T67GQlQ2TrfIBPI+k14GVPeze5EeUZaImr/oFKDr1qjcRPHjDXa0DGlcyBdJeQuGHDaeen3YOd3/MugZCPiezJntTmPWCmGULDj+zeLnaTcw1k9rJGOpt8uG+6JO4BXW1e5kDm/B4vyC/0U11FpAbawCAmxF072Lr6vYE54NmTplGz1BoVBfRWMSGtAbC6KJqigSxaW8RqjPgcQ2AbdkgnHHrphQaGNPWvzzbQUhKi628fnpcu26S9TAttlIH+uxUcjvyYGuCh8iuxDLE3MINnEcpC/KbwkzRA2h68+FwDs0K3bl8saSHuE81b8Ah28GsUTUhO0MPgkwaO0aBd7OVP1RtGO2HHsiCPxe3BwcE2+IIGgkjchPXRI1wDVi/iKu8CNd5RtKG2TPqrwt+1CBgTyb4ofimK6lc0QIPcjNIWWughYmeadop5pq5OAzKuxErhHEjOE/+ksYNeQDoen3RZXOI6KfCuHeIDM4NQpAYQ8psKDDt0Ag5O2hnNgY91ceaV2xpoACa/t4+aVzUwog2gqZGVAex5PXYQBWrRPmlg22YjWbu0P+DsWdU8XGgA26Rwc09JiK6/fcBusWTZcBLWEVGNZqsCLHnIN3WLcAdMi2eCF6LhR2mAVIF+IDXQAU4BoXQc9NSLppfwRKf0YI4sq9SA2hBd5dGiWPYbatHExoO8oDa/oAHSgM1a4hUICw1IfgHTQgPtCMOYUAZILRHkmUh2eRSJXgMNoo8iOXGJxUCdDW3K5LzrNCDjSqYygTM4Fl/cK/KArFNoYCYzudEO8YE9+ayBVCS5W6wwTzujObAgjBS92xo40h8CvQaYwHQ1qsrVFfb7JaVoqgbE1uGYnX9DTrqq0YBJKMEJiGVC9P3tA3U5q5BN91Xcu55YSC9QNWA4XJGh+DSFH6YBsgHqUgMh+xcvARIiGMv+IxWpAdFcY6kBlRHNl2TI4rgejnQRihFrYPIVDdQcTPgqzSyhAWUbkWugE4nn57bsRstGn0hiYLj/Iw28XokiCfkNaJ2tjC2cQM7rRacBGVdylC9NgHWxuFfi+bMsz454SLVDfGTBhQYeuPREpA3g6mY0ByaiA7LbGgiBWfIHGuAF1tVow3LGUYumakBI1WWBF/KMkksNZITTAJ5kQvT97ctQBxY8giePsS2ePqkBeRWjZxKRa/wgDdS2+NgLDUzydSYXwUG5incJpy41YDTDxqQMnQaCcfWp/vaCTxqYsKeCd6BF/4XHBuMN2HxFA+SI1GVC7pJzDbiHcPXc9YUGNhHQlqfvNTigvSV4BNB7blq3NGDcjsLOpsyeCU753G15K9UBFtc0YBCVE1Dn8XtAyMZnYJkRC4LTAyzNELr3faGBstDAWhjH1c1oDsxFZrzbGkgiwF6s9sFNDUyJQK1RX0mAUrQLDRS2YU9HA2lZMrzQwIlIA7/JhOj728fIlSLs0dpBpgRtkT5FA01gyp4JnomGn6aBfD6+VWjgBYgJZ8VSxqkWXSkf60nw7IOi0UBp4YGjaiAurgRDVotzFl/SwIF9/BMQn2lg2huBwTVA6crTl9BKCtyjTV/bNG9qQB9FsqFPBTFLU4cuXE6G3lc1EOGcuvjUrCY1wH7lt+SaId/QgGZGdN1+VQOk00dO+lb6Iw3oahSpJpVF02jAUDQQIZLHXH5TcGbgo0yIvr99+ITBT6gDBVOvgWBI+zqkAXX8MA3kRS4XGiifFbzOOoYzl6ujOLi2AOzh6eHY9S40MPUAr7fYvEyEBmTZZvSZYMLrMqtwZpX6FzQgrrg+ZkRoIJgASPuPm/JMaiDygKo45Q/5ORuikDRODgC8BDc1cDtKk97eNOAYecSz28jAQf+rGvCBCmfxUJmKRy60pAY6UjzoaIZ8TwPqjL6lAUrpbWADsHd/oAFdjXxkREEU7bYG+M06J7vQwPHskvMiE6Lvb/9s+BYRrR1kSipjvQbIhD4VLHAiWn6cBiwfaPKV/Ux/iC57Vbr8RTSBOPjY0e8NWA6yd/3eAFnCTsg7EIt9QcnXNBAC47PfS+yd3uunvQEYrw4c8eqE3MBtdR3gWdXAUdXA7SjBFuXcUEwOH/DPevFB1cDw+kOBaG/J/gMjDA3Rx+9nznA1Q76hAc2MvqMBjjGtAGje1oCuRjPmNI5atNsaqACmSO+FBnpnc5nIhOj72wcsMTQXdvBBtS3Ra2CcT6w2Qkj0/DQNkNcRtkuWn+pZVwzwYRBBBzI5j+zgPqJAZFTVwBrYiSqpGshTtyRHHq0K1L+tAStDmVSwDaQG3kRfhnKLkIYfJuIB/TYH1j8lmYKTooE/ivKGbdAuVpkP2yWMKXtAXcltLvuqBl7UfWdu6Z4pHFyW+XJHGCpDvq8BZUbf14CkAXRva0BTI+Y0gVq02xrYyUt+91IDTiBX/U4mRN/fvtwCa7GokQig14BQVIWE9OZPz0/TQF5EsJVtjBDxeZn0AEkPI+7oMbttC5zigCCVGqjLv6GRX2arVDBzM9oH9AP7Lu/3w6HD62re0AA7xGuPUCdSAzNRnQepARZsFrCieZ1Ce4cxkcRxW8zQYaurwqvvKRrQR5GMgVYD20B89ySlaYorIFubOg3IPS1GcjgYbPHYr/mh60IDviXWUlkz5Dsa0M1IrwFTpwE3jhO+7D81iwXMVA3oatQCFgFfsGlaUot2UwPGFljxLFxoQFyCjAh2IhOi729fGmUDzJmu1kVzHA5XNbCEZy1QIVf4eRoIToUGyLHQeLIV9RPreVijqfT5wSekBh3+Aq6BfbHmm4UP9umlBt5h7zCqidQfxZWwxaW0JIxfD6FWA2Mgwig508Ck6NTQVjTgzoAuP25gFCvhmUg2xTxrDnzuuw4/IUUDN6OwgeVesSTHI4wOhREH/ALp0962Btc14A6LHjYG8Ix8ynYe0kixrfEx2LDMOsBBM+SbGlBnpNeArIiqgWCILC70VSbneNi6igZ0NQp8+pFsln1N0a5qgLx6sBer1mph+9GlBvhDRQXsYJ4QfX/7KIy9BFIrr90HvFJxwZtd0wB9IBjxbHbeXmKi8AM1QNpeoYEkBWZPsTmJWL4k7gDwn/ev9QFm7OA60Htqt6szRFwDhg17MzXpDqBdbhqtuhPZFxpwU8jgSQY8LsfjeR/8hH4BWbeZ16FtA02dBsgM1C5SAyaQPu+T9xdEUgNFuav8Dn9QN9vrDZDW1GcB76lEjHXE2+ENGM7j9vsMkaoBbRRVlEBJ3o+m3XV7t7Fh77klcGp2xtUo9TQakOv246Xa3i+37PyNCEOLraYNH3PCYhk3uynwohnyXQ2oM9JpQFZE1QDrAH/XJp2lB3tMOGKyoWnIcLoakYMNVHbt925GC6sW7aYGyLsNShb3L/cGRmm3GS8XwChWEqLrbx9pNDrO2/PjCKgWs0vf1p3WxIHd0mhA/AqkQXHFOBGVH6gBUkWRgv0WnIVBFOIIjOM7f4KYgdEttghJufgvDKdOUSVxjy3pgladcUjB6RvCN8CMNTGWWg1MAbTONRC8FUGaqgbI3mF/d5r0wUnVjn22ATgARiv2+QswJhffFOiiSJLR2e5U0AXH4cugMwRj7SsaUAlH4HR5f635ksSUjen4YMwszZDvakCdkUYDsiKXGjAq4LlLm0RhihxThtPVSLYJRiHRFU2vAUprMQKycqL7wnAHhvNLSYimv+mbJa+oOKG4ZXDsObmugV8s49ylW6LyEzVw9oeBnVzNgP8UXLR5mRY8DLgGiNvdsheEBqz6lmmAHOhXxJWYaDTwyv/MvvhAWoUodIsXXjLedA/oG1oNuFv4RGiA/eIDcCZG65MGyI7vOFmNiIrpuUZUDicPQDY7EIZ1HOb/XgYaDeijyMvDigimJ9rfmxLhjBcZAL9JNBqQ7Cs2APvU5DfbPHttB2nCxhgTWoe6qxnyXQ2oM9JpQFZEt0W480cAhpf/VXp18KFo4LJGlNJmJHKvKZpeA5ygnbA7Bv9iP6/VA4DHvZIQTX/zN2OawMGcFMz7tHbHmNzQgJuK79LWqReST/wMDVzHjZtmh+iwSs02Ueg028Gn0R2L/0I3rHTEIq3iA/fqoUbHZT/JNzBaJZfcIui0WgnR0W52Pk0rDr4fZYMP5Y3avjm21G1EdaQeo9Qc6yYiF0Qwbsaubshtvj8jtSJa3FKrdiVqTV8jTU/9GTKcNNv6tdah9pX+5o6w9i21A5K90tlatlIvrlrn/4MG/nYm/7n/3+xfguFgQ/4+pAbuGIvZm7w1L2s08BWkBr6PvNXSc9fAHzH2sCH/Q8pin0zhroG/gQpQz6/2QTUDxv+KBqwehi65wl0Dt9lPZh/5cvm/sXrZ4ord7hr463n1AESV2ZZuwf7zGjAmFe/WzcBdA7epAsia5H9HBKBiEQ13DfwddBZgDF/Jv6CBDgB7Ra5x18AfYD6Ul23y/6Nbef5F/n5aT08uuZNjht2H7u5iV9h6emqRb1B9qpLvYzwcGwdynbsG7ty5c9fAnTt37hq4c+fOXQN37tz5jR07NoIYCIEgKGFhKyC4/KN65wLAeYfqDmJqa2UAkAFABgAZAGQAkAFABgAZAGQAkAFABgAZAGQAkAFABgAZAGQAkAFABgAZAGQAkAHgvxno+B5gnS96nIET+QDrZJxxBir6AdbpqEEGrjQHYJ+MfOcZqNAB2CYjapqB24FOPyGs8WXfCgwycFUGsErWO87AVaeDXzt1TAAACAMwTBr4V8XHNQVrIiKwxLk/gbEBIE4DkKcByNMA5GkA8jQAeRqAPA1AngYgTwOQpwHI0wDkaQDyNAB5GoA8DUCeBiBPA5CnAch7iJe7wXWsVdkAAAAASUVORK5CYII=)\n\nCheck the following to correct a lack of traffic to the experiment:\n\n*   **Ensure the trackingCallback in the SDK is configured correctly.** It should be using the intended tracking library (e.g. Google Analytics \\[GA4\\], Segment, Amplitude) and actually emitting tracking events to your data warehouse.\n*   **Ensure the Hash Attribute identifier is being set for each user.** When you start an experiment in GrowthBook, you need to choose which Attribute to use to assign users to variations, often the user `id`. If you do not set that Attribute when you instantiate the GrowthBook SDK, then users can't be assigned to the right variation and users will default to not entering the experiment at all.\n*   **Ensure the Experiment Assignment Query in your data source is configured correctly.** You can find this query on your data source's detail page.\n\n## Problem 2: SRM errors (traffic imbalance) in the experiment[​](#problem-2-srm-errors-traffic-imbalance-in-the-experiment \"Direct link to Problem 2: SRM errors (traffic imbalance) in the experiment\")\n\nA clue that the traffic to the experiment isn't balanced is the presence of a Sample Ratio Mismatch error, shown as a warning banner at the top of the Results tab.\n\n![SRM Warning](data:image/png;base64,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)\n\nWhenever there is traffic imbalance in your GrowthBook experiment, the cause is usually one (or several) of these problems:\n\n1.  **The trackingCallback is configured incorrectly**, which is causing it to send an event to your data warehouse _only under certain condition_s.\n2.  You are using an **Activation Metric** that is triggered differently by users across variations.\n3.  **The Hash Attribute doesn't match the \"Identifier Type\" in your data source.**\n4.  **You made a change to the experiment targeting after it started, or created a new phase without re-randomizing.**\n\n### Solution 1: Ensure the trackingCallback is triggered unconditionally[​](#solution-1-ensure-the-trackingcallback-is-triggered-unconditionally \"Direct link to Solution 1: Ensure the trackingCallback is triggered unconditionally\")\n\nThe trackingCallback you configure is used by the SDK to send tracking events to your data warehouse whenever a user is exposed to an experiment. Make sure that whether the trackingCallback method sends event data is _not conditional_ on the experiment variation.\n\nAs you create the GrowthBook-related logic in your application code, be careful not to have users in control variations emit trackingCallbacks under more conditions than users who are _not_ bucketed into the control variation. Otherwise, you are likely to have Sample Ratio Mismatch (SRM) issues.\n\nIt is much better to emit a tracking event as soon as possible within the trackingCallback, before doing any other custom logic that may differ across users based on the experiment variations they are exposed to.\n\n### Solution 2: Only use Activation Metrics that do not differ across variations[​](#solution-2-only-use-activation-metrics-that-do-not-differ-across-variations \"Direct link to Solution 2: Only use Activation Metrics that do not differ across variations\")\n\nIf you are using an Activation Metric to filter users that get into your experiment analysis, you may be introducing bias if the Activation Metric is downstream of any differences between users in your variations.\n\nSimilar to the above issue where your trackingCallback fires more for users in one variation than another, if you filter out users based on some activity that differs across variations then you could be introducing bias and causing SRM errors.\n\nThe upshot is that you should not use an Activation Metric lightly. It should be a Metric that is downstream of changes to the user experience caused by the experiment. Imagine you want to check a user variation on page load, but you want to use an Activation Metric to only look at effects once users open the checkout modal where the experiment is. If you have to load more data for users in your test variation, the page may crash or be slower for those users; if this happens before you measure the Activation Metric, then you may be causing traffic imbalance as you will see fewer users in the variation in your experiment sample.\n\nIn fact, using an Activation Metric that is downstream of any difference in variations can cause bias that is not picked up by SRM errors, so you should try to avoid this whenever possible.\n\nBest practices:\n\n*   Try not to use Activation Metrics at all, and instead only use the SDK to look up experiment membership as close as possible to the actual experiment.\n*   If you must use an Activation Metric, make sure it is not downstream of any differences in the user experience caused by the experiment.\n*   Check the Health Tab on your experiment results to see traffic breakdowns by Activation Status to help you understand what your Activation Metric is doing to your sample.\n\n### Solution 3: Ensure the Hash Attribute and Identifier Type match[​](#solution-3-ensure-the-hash-attribute-and-identifier-type-match \"Direct link to Solution 3: Ensure the Hash Attribute and Identifier Type match\")\n\nGrowthBook randomizes users according to the Hash Attribute that you set for each user, often a `user_id`. When you analyze experiments, you set an \"Identifier Type\" that corresponds to columns in your data warehouse. Ideally, the Hash Attribute that you choose for users is both (1) logged to the data warehouse in the trackingCallback, and (2) is used as the \"Identifier Type\" for all of these experiments. By doing this, you establish a 1:1 relationship between the Hash Attribute and the Identifier Type.\n\nFor example, suppose you run experiments and you sometimes randomize users by `device_id` and sometimes randomize by `user_id`, setting the Hash Attribute as `device_id` or `user_id` respectively. You would set up your trackingCallback so that the Identifier Types are logged to your data warehouse with each experiment exposure.\n\nThen, you would also have two Identifier Types in your data source, one for each Hash Attribute (`device_id` and `user_id`), and define Experiment Assignment Queries to query your data source for all the experiments of each Identifier Type.\n\nIf for some reason the Identifier in your data warehouse is different from your Hash Attribute, you could see Multiple Exposure warnings and Sample Ratio Mismatch (SRM) errors, because the ID chosen to randomize users doesn't match the ID on which queries are running in your data warehouse. You would fix this so that there is a 1:1 mapping between the Identifier and Hash Attribute by ensuring the Hash Attributes are always emitted to the data warehouse, and use set these values as the Identifier Types in GrowthBook.\n\n**Why might the Hash Attribute and Identifier Type be different?**\n\nThere are times where it might be beneficial to have the Hash Attribute differ from the Identifier Type. The consequence is that there may be minor traffic imbalance or Multiple Exposures, but you may be willing to accept some slippage in the 1:1 mapping between Identifier Type and Hash Attribute in order to more easily join experiment exposure data with metric data.\n\nFor example, on client-side experiments with Google Analytics (GA4), you may wish to avoid flickering by hashing on some custom ID as we do in our [Script Tag SDK](https://docs.growthbook.io/lib/script-tag) and not wait for the IDs provided by GA4.\n\nWhile you could send this custom ID in your trackingCallback you may prefer to use GA4 identifiers as the Identifier Type instead, because they are already tracked with many of the other GA4 events that you are using as Metrics.\n\n### Solution 4: Minimize Experiment targeting changes while running[​](#solution-4-minimize-experiment-targeting-changes-while-running \"Direct link to Solution 4: Minimize Experiment targeting changes while running\")\n\nWhen you make changes to the targeting of an experiment or created a new phase without re-randomizing users, it's possible that the traffic to the experiment will become imbalanced. This is because the users who were already in the experiment may continue to be in the same variation at differing rates. Whenever creating a new phase, you should re-randomize traffic when possible, and only certain changes to an experiment's targeting conditions can be done without re-randomizing.\n\nYou can read more about the [rules for changing experiment targeting](https://docs.growthbook.io/app/making-experiment-changes) and [carryover bias](https://docs.growthbook.io/kb/experiments/carryover-bias) in our documentation.\n\nIf your experiment is suffering from these issues, unfortunately the only solution may be to restart the experiment (you can do this by creating a new phase and choosing to re-randomize traffic). Of course, some amount of bias and SRM may be preferable to throwing out your data, but this depends on the magnitude of the problem.\n\n## Problem 3: Multiple Exposures[​](#problem-3-multiple-exposures \"Direct link to Problem 3: Multiple Exposures\")\n\nWe default to allowing 1 percent of units (e.g. users) in an experiment have multiple exposures without raising a warning due to the fact that many experimenters have slight mismatches in hashing attributes and warehouse tracking that can cause minor errors. You can adjust this in your organization settings under Settings > General > Experiment Settings.\n\nIf you have multiple exposure errors, the issue is fundamentally caused by a mismatch between the attribute that you are randomizing on (your \"hash attribute\") and the identifier being stored in your data warehouse. You can [read more about this problem and how to solve it here](#solution-3-ensure-the-hash-attribute-and-identifier-type-match).\n\nAnother potential issue is that you made unsafe changes to your experiment targeting and randomization. We attempt to prevent this by having a curated flow for making changes, but we provide you with flexibility to make a whole host of changes that could result in multiple exposures if you choose to override our warnings. YOu can read more about our [rules for changing experiments while running here](https://docs.growthbook.io/app/making-experiment-changes).\n\n## Problem 4: Metric averages don't look as expected[​](#problem-4-metric-averages-dont-look-as-expected \"Direct link to Problem 4: Metric averages don't look as expected\")\n\nIt's important to ensure that the Metric values in the baseline and variation are what you would expect. This helps confirm that the Metrics are set up correctly and that they are joining properly to the Experiment Assignment Queries.\n\nIn the image below, notice that the values look like reasonable, per-user averages. If there is no data or if the values are very different from what you'd expect, consider the solutions below.\n\n![Reasonable Metric Averages](data:image/png;base64,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)\n\n### Solution: Understand the experiment's population[​](#solution-understand-the-experiments-population \"Direct link to Solution: Understand the experiment's population\")\n\nSometimes the Metric values in an experiment may surprise you if you are targeting an experiment to new users (values may be low!) or power users (values may be high!). Each experiment can have different targeting Attributes, and it is totally possible that the values are representing that experiment's population. Consider this before launching into in-depth investigations of your Metric's set-up.\n\n### Solution: Check the Metric's configuration[​](#solution-check-the-metrics-configuration \"Direct link to Solution: Check the Metric's configuration\")\n\nYou can confirm that the Metric is returning the right values in the table rows on a per-user basis. Navigate to the Metric page, edit the SQL for the Metric, and use the Edit SQL interface to run test queries and make modifications to make sure the rows you are getting are what you expect. The results should show the right identifiers, timestamps, and values.\n\nYou should also make sure the [Metric Window](https://docs.growthbook.io/app/metrics#metric-windows) is not too short and not too long, otherwise it could be excluding or including too much data.\n\n### Solution: Make sure your Identifier Types are correct[​](#solution-make-sure-your-identifier-types-are-correct \"Direct link to Solution: Make sure your Identifier Types are correct\")\n\nIf you are seeing some users flow into your experiment but aren't seeing any Metric data, you should ensure that the Metric data is able to join to your experiment exposure data.\n\nThis is illustrated in the image below. Notice the 38,919 total users in the upper left corner, but no data in the \"Baseline\", \"Variation\", or \"Chance to Win\" columns:\n\n![No Metric Values](data:image/png;base64,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)\n\nGrowthBook relies on the Identifier Type in your data source to merge users in your experiment with Metric values. This is accomplished through the Experiment Assignment Query (for users) and the Metric (for Metric values). These Identifier Types must be the same, or linked by a Join Table, to run a query in GrowthBook. While we actually will throw an error if you can't join them, you may still have set up one or the other incorrectly to point to the wrong column, or the data in the columns for your Experiment Assignment Query and Metric may not overlap. It's a good idea to ensure that the values being produced by both queries are what you expect.\n\n### Solution: Understand the overall query logic better[​](#solution-understand-the-overall-query-logic-better \"Direct link to Solution: Understand the overall query logic better\")\n\nYou can view the queries generated by GrowthBook by navigating to the experiment's Results tab, looking on the right side of the page (shown below) and clicking \"View Queries\". You can then use parts of these queries and debug them by running raw SQL in your own data warehouse to make sure that your configuration is correct.\n\n![View Queries Button](https://docs.growthbook.io/assets/images/view-queries-button-18b880bbb11c604d1e5b362668127e3a.png)",
    "title": "Troubleshooting Experiments | GrowthBook Docs",
    "description": "Troubleshooting Experiments",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/using/experimentation-best-practices",
    "markdown": "# Experimentation Best Practices | GrowthBook Docs\n\n## Running experiments[​](#running-experiments \"Direct link to Running experiments\")\n\n### Running Your First Experiment[​](#running-your-first-experiment \"Direct link to Running Your First Experiment\")\n\nWhen you’ve finished integrating your experimentation platform (which for GrowthBook, is adding the SDK to your code), it’s time to start running an experiment. We suggest that you first an A/A test to validate your experimentation implementation is correctly splitting traffic, and producing statistically valid results.\n\n### Sample Sizes[​](#sample-sizes \"Direct link to Sample Sizes\")\n\nUnderstanding experiment power and MDE are important to predict how many samples are required. There are numerous online calculators that can be used to help you predict the sample size. Typical rule of thumb for the lowest number of samples required is that you want at least 100 conversion events per variation. So for example if you have a registration page which has a 10% conversion rate, and you have a 2 way (A and B) experiment that is looking to improve the member registrations, you will want to expose the experiment to at least 2,000 people (1000 per variation).\n\n### Test Duration[​](#test-duration \"Direct link to Test Duration\")\n\nDue to the natural variability in traffic day to day and hour to hour, experimentation teams will often set a minimum test duration within which a test cannot be called. This helps you avoid optimizing a product for just the users that happen to visit when the test is started. For example, if the weekend traffic of your product is different from the traffic during the week, if you started a test on Friday and ended it on Monday, you may not get a complete picture of the impact your changes have to your weekday traffic. Typical test durations are 1 to 2 weeks, and usually care needs to be taken over holidays.\n\nYou may also find that a test would need to run for a month or more to get the power required for the experiment. Very long running tests can be hard to justify as you have to keep the variations of the experiment unchanged for duration, and this may limit your team's velocity towards potentially higher impact changes.\n\n### Interaction Effects and Mutual Exclusion[​](#interaction-effects-and-mutual-exclusion \"Direct link to Interaction Effects and Mutual Exclusion\")\n\nWhen you start having the ability to run a lot of A/B tests, it can be tempting to not want to run tests in parallel in case they have interaction effects (see above). For example you may want to test a change in the CTA button on your purchase page, and also test changing the price. It can be difficult to figure out if any two tests will meaningfully interact, and many will run the tests in serial in an abundance of caution.\n\nHowever, meaningful interactions are actually quite rare, and keeping a higher rate of experimentation is usually more beneficial. You can run analysis after the experiments to see if there were any interaction effects which would change your conclusions (GrowthBook is working on an integrated solution for this). If you need to run mutually exclusive tests, you can use GrowthBook’s [namespace](https://docs.growthbook.io/features/rules#namespaces) feature.\n\n### Experimentation Frequency[​](#experimentation-frequency \"Direct link to Experimentation Frequency\")\n\nHaving a high frequency of A/B testing is important for running a success experimentation program. The main reasons why experimentation frequency is important are:\n\n**Maximizing chances**: Since success rates are typically low for any given experiment, and large changes are even more rare, by having a high frequency of A/B testing you are maximizing your chance of having impactful experiments.\n\n**Continuous improvement**: A high frequency of A/B testing allows you to continuously improve your website or application. By testing small changes frequently, you can quickly identify and implement changes that improve user experience, engagement, and conversion rates.\n\n**Adaptability**: A high frequency of A/B testing allows you to quickly adapt to changes in user behavior, market trends, or other external factors that may impact your website or application. By testing frequently, you can identify and respond to these changes more quickly, ensuring that your site or app remains relevant and effective.\n\n**Avoiding stagnation**: A high frequency of A/B testing can help you avoid stagnation and complacency. By continually testing and experimenting, you can avoid falling into a rut or becoming overly attached to a specific design or strategy, and instead remain open to new ideas and approaches.\n\nQuote\n\n**_“If you want to have good ideas you must have many ideas. Most of them will be wrong, and what you have to learn is which ones to throw away.”_**\n\n\\- Linus Pauling",
    "title": "Experimentation Best Practices | GrowthBook Docs",
    "description": "Running experiments",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/using/product-development",
    "markdown": "# Experimentation-driven product development | GrowthBook Docs\n\nExperimentation-driven product development is a shift in product development from focusing **shipping** new products, to focus on shipping features that have an **impact** on your business. The best way of determining impact is through A/B testing.\n\n_The ideal goal with product-driven experimentation is to test every new feature that is developed._ This level of experimentation often requires adjusting your existing product process.\n\nIf you want to read more about how to make the case for experimentation-driven product development, or the benefits to your culture, you can read our section on [experimentation programs](https://docs.growthbook.io/using/programs).\n\n## Platform integration[​](#platform-integration \"Direct link to Platform integration\")\n\nExperimentation-driven product development requires a tight integration between your product and the experimentation platform. This is important to keep the incremental cost of running an experiment low, while increasing the ability to run a high volume of experiments. The cost can be cost in terms of effort, and cost in terms of actual money. You want to keep these a low as possible and make sure your platform encourages your team to run experiments.\n\nGiven this, many companies choose to build their own experimentation platform. This is a big undertaking, and much harder than it might seem at first. There is also ongoing maintenance costs, as well as the risk in making product decisions on a platform that might have undiscovered bugs.\n\n### Reducing costs[​](#reducing-costs \"Direct link to Reducing costs\")\n\nCosts of running experiments can be broken down into a few categories: the cost of data storage, the cost of engineering time, and the cost of the platform itself. GrowthBook is designed to address these costs directly and allow you to run a lot of experiments. GrowthBook is warehouse native and uses any data you already have. It was also designed to be extremely easy to add an experiment (2 lines of code) and have a high-quality developer experience that reduces engineering costs. GrowthBook itself is open-core and extremely economical to run.\n\n## Product prioritization changes[​](#product-prioritization-changes \"Direct link to Product prioritization changes\")\n\nAs you become aware of HiPPOs effect on your decision-making process and start to move away from this, you need another way to prioritize projects. There are many prioritization frameworks to help with this (we have a [whole section on experimentation prioritization frameworks](https://docs.growthbook.io/using/programs#prioritization)), but the goal the system you choose should be to encourage building smaller testable features, a high frequency of experiments, and to make sure you have a good mix of ideas and sizes of projects.\n\nThis is a big change from the traditional product development process, where we would spend a lot of time trying to predict what features will work, and then spend a lot of time building them. With experimentation-driven product development, we spend less time predicting and guessing and more time testing. This means that we can spend less time building features that don’t work, and more time building features that do work.\n\n### HAMM[​](#hamm \"Direct link to HAMM\")\n\nHAMM is a framework to help you think about experimentation-focused product development. It stands for Hypothesis, Actions, Measure, and MVP. It is one product framework to help increase your learning rate, and build a culture of experimentation.\n\n*   **Hypothesis**: What is the hypothesis you are testing? This should be a clear, falsifiable statement of what you are trying to learn. See our section on how to make good [hypothesis](https://docs.growthbook.io/using/fundamentals#hypothesis-1).\n*   **Actions**: What are the actions you expect your user to take if this hypothesis is true?\n*   **Measure**: What are the metrics that you could measure that would indicate that the user is doing the actions you expect? What might be a counterfactual metric that would indicate that the user is not doing the actions you expect? What are the guardrail metrics that you want to make sure you don't negatively impact?\n*   **MVP**: Given the above, what is the smallest thing you could build to test this hypothesis?\n\nThinking about the HAMM process at the beginning of a project lays the groundwork for a high-quality experiment. You'll have the hypothesis, the metrics, and the success criteria (OEC). With a smaller MVP or MTP (Minimum Testable Products), you can also increase your experimentation rate and therefore your learning rate.\n\n![John Hamm](https://docs.growthbook.io/images/using/jon_hamm-cropped.png)\n\n## Why you're not seeing experiment impacts[​](#why-youre-not-seeing-experiment-impacts \"Direct link to Why you're not seeing experiment impacts\")\n\nQuite often, companies run A/B tests that show positive results, and yet when overall metrics are examined, the impact of these tests is invisible. You might be expecting to see inflection points around the time the experiment was implemented. Here are some reasons why:\n\n*   **Confusing statistics** - Interpreting results can be confusing without a solid grasp of what the statistics are telling.\n*   **Bad practices** - You may be running experiments that are not valid, or are not measuring the right thing. See the Peeking problem.\n*   **Lost in the noise** - The impact of the experiment may be too small to be visible. This is especially true if you are running a lot of experiments - but this is not bad, just hard to see on a macro level.\n*   **Optimizing wrong product** - You might be experimenting with a section of your product that doesn't represent a large fraction of your overall use. Even if you're successful in these areas of the product, the overall impact will be limited by the small fraction of users that you've affected.\n*   **Optimizing wrong metric** - You might be optimizing for a metric that doesn't matter. For example, you might be optimizing for a metric that is not correlated with revenue, your main KPI. This is especially true if you are optimizing for a proxy metric, such as clicks, instead of the actual metric, such as revenue.\n\nYou can read more about this topic on our blog post [Why the impact of A/B testing can seem invisible](https://medium.com/growth-book/why-the-impact-of-a-b-testing-can-seem-invisible-5b2d69efa48)",
    "title": "Experimentation-driven product development | GrowthBook Docs",
    "description": "Experimentation-driven product development is a shift in product development from focusing shipping",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/using/experimentation-problems",
    "markdown": "# Where Experimentation goes wrong | GrowthBook Docs\n\nThe following contains a list of common pitfalls and mistakes that can happen when running A/B tests. It is important to be aware of these issues and to take steps to avoid them in order to ensure that your A/B tests are valid and reliable. It is by no means an exhaustive list.\n\n### Multiple Testing Problem[​](#multiple-testing-problem \"Direct link to Multiple Testing Problem\")\n\nThe multiple testing problem refers to the issue that arises when statistical hypothesis testing is performed on multiple variables simultaneously, leading to an increased likelihood of incorrectly rejecting a true null hypothesis ([Type I error](https://docs.growthbook.io/using/fundamentals#false-positives-type-i-errors-and-false-negatives-type-ii-errors)).\n\nFor example, if you test the same hypothesis at a 5% level of significance for 20 different metrics, the probability of finding at least one statistically significant result by chance alone is around 64%. This probability increases as the number of tests performed increases. This math assumes that the metrics are independent from one another, which in most cases for a digital application there will be some interaction between metrics (ie, page views is most likely related to sales funnel starts, or member registration to purchase events)\n\nTo address this problem, various multiple comparison correction methods can be used, such as the Bonferroni correction, False Discovery Rate (FDR) correction, or the Benjamini-Hochberg procedure. These methods adjust the significance level or the p-value threshold to account for the increased risk of false positives when multiple comparisons are made.\n\nIt's essential to be aware of this issue and select an appropriate correction method when conducting multiple statistical tests to avoid false discoveries and improve the accuracy and reliability of research findings. If you are using a high number of metrics, draw conclusions from the test thoughtfully and if you may consider running a follow up test just to test that one result or metric.\n\n### Texas Sharpshooter Fallacy[​](#texas-sharpshooter-fallacy \"Direct link to Texas Sharpshooter Fallacy\")\n\nThe Texas sharpshooter problem is a cognitive bias that involves cherry-picking data clusters to suit a particular argument, hypothesis, or bias. The name comes from the idea of a Texan marksman shooting at a barn and then painting a target around the cluster of bullet holes to create the appearance of accuracy. As the story goes, he then showed his neighbors and convinced them he was a great shot. It is closely related to the Multiple Testing Problem/Multiple Comparison Problem.\n\nIn the context of data analysis and statistics, the Texas sharpshooter problem refers to the danger of finding apparent patterns or correlations in data purely by chance and then using those patterns as if they were meaningful. This can lead to false conclusions and misguided decision-making. Texas sharpshooter problem is relevant in the sense that if you analyze the results of a test without a clear hypothesis or before setting up the experiment, you may be susceptible to finding patterns that are purely due to random variation. If you analyze the data in multiple ways or look at various subgroups without adjusting for multiple comparisons, you might identify spurious patterns that do not actually represent a true effect.\n\n### P-Hacking[​](#p-hacking \"Direct link to P-Hacking\")\n\nP-hacking, or data dredging, is a statistical fallacy that involves manipulating or analyzing data in various ways until a statistically significant result is achieved. It occurs when researchers or analysts repeatedly test their data using different methodologies or subsets of the data until they find a statistically significant result, even if the observed effect is due to chance.\n\nIn the context of A/B testing, p-hacking can be a significant concern. A/B testing involves comparing at least two versions (A and B) to determine which performs better. The danger of p-hacking arises when analysts, either consciously or unconsciously, explore different metrics, time periods, or subgroups until they find a statistically significant difference between the A and B groups.\n\n### Peeking[​](#peeking \"Direct link to Peeking\")\n\nThe peeking problem refers to the issue of experimenters making decisions about the results of an experiment based on early data. The more often the experiment is looked at, or ‘peeked’, the higher the false positive rates will be, meaning that the results are more likely to be significant by chance alone. Peeking typically applies to Frequentist statistics, which are statistically valid at their predetermined sample size. However, Bayesian statistics can also suffer from peeking depending on how decisions are made on the basis of Bayesian results.\n\nThe peeking problem in A/B testing occurs when the experimenter looks at the data during the experiment and decides to stop the test early based on the observed results, rather than waiting until the predetermined sample size or duration has been reached. This can lead to inflated false positive rates, as the results are more likely to be significant by chance alone if the experimenter stops the test early based on what they see in the data. The more often the experiment is looked at, or ‘peeked’, the higher the false positive rates will be.\n\nTo avoid the peeking problem in A/B testing, it's important to use a predetermined sample size or duration for the experiment and stick to the plan without making any changes based on the observed results. This helps to ensure that the statistical test is valid and that the results are not influenced by experimenter bias.\n\nAnother way to avoid the peeking problem in A/B testing is to use a statistical engine that is less susceptible to peeking, like a Bayesian with custom priors, or to use a method that accounts for peeking like Sequential testing.\n\n### Problems with client side A/B testing[​](#problems-with-client-side-ab-testing \"Direct link to Problems with client side A/B testing\")\n\nClient-side A/B testing is a technique where variations of a web page or application are served to users via JavaScript on the user's device, without requiring any server-side code changes. This technique can offer a fast and flexible way to test different variations of a website or application, but it can also present some potential problems, one of which is known as \"flickering.\"\n\nFlickering is a problem that can occur when the A/B test is implemented in a way that causes the user interface to render the original version, then flash or flicker as the variations are loaded. This can happen when the A/B test code is slow to load or when the A/B testing library is lacking performance. As a result, the user may see the original version of the page briefly before it is replaced with one of the variations being tested, leading to a jarring and confusing user experience. This flickering can lead to inaccurate or unreliable test results. Rather counterintuitively, flickering may have a positive effect on the results, sometimes the flashing may draw a users attention to that variation, and cause an inflation in the effect.\n\nTo avoid flickering in client-side A/B testing, it is important to implement the test code in a way that minimizes the delay between the original page and the variations being tested. This may involve preloading the test code or optimizing the code for faster loading times. GrowthBook’s SDKs are built for very high performance, and allow you to use client side A/B testing code inline, so there are no blocking 3rd party calls.\n\nYou can also use an alternative technique such as server-side testing or redirect-based testing to avoid flickering issues. If loading the SDK in the head does not sufficiently prevent flicking, you can also use an anti-flickering script. These scripts hide the page while the content is loading, and reveal the page after the experiment loaded. The problem with this is that while it technically prevents flickering, it slows how quickly your site appears to load.\n\n### Redirect tests (Split testing)[​](#redirect-tests-split-testing \"Direct link to Redirect tests (Split testing)\")\n\nRedirect-based A/B testing is a technique where users are redirected to different URLs or pages based on the A/B test variation they are assigned to. While this technique can be effective in certain scenarios, it can also present several potential problems that should be considered before implementation.\n\n**SEO**: Redirects can negatively impact SEO, as search engines may not be able to crawl the redirected pages or may see them as duplicate content. This can result in lower search engine rankings and decreased traffic to the site.\n\n**Load times/User experience**: Redirects can increase page load times, as the browser has to make an additional HTTP request to load the redirect page. This can result in slower load times, which can impact user experience, conversion rates, and A/B test outcomes.\n\n**Data accuracy**: Redirects can also impact the accuracy of the test results, as users may drop off or exit the site before completing the desired action due to a slower load time or confusing user experience. It can also be harder technically to fire the tracking event, causing a loss in data.\n\nTo mitigate these problems, it's important to carefully consider whether redirect-based A/B testing is the most appropriate technique for your specific use case. If you do choose to use redirects, it's important to implement them correctly and thoroughly test them to ensure that they do not negatively impact user experience or test results. Additionally, it may be helpful to use other techniques such as server-side testing or client-side testing to supplement redirect-based testing and ensure the accuracy and reliability of the test results like testing on the edge or using middleware to serve different pages.\n\n### Semmelweis Effect[​](#semmelweis-effect \"Direct link to Semmelweis Effect\")\n\nThe Semmelweis effect refers to the tendency of people to reject new evidence or information that challenges their established beliefs or practices. It is named after Ignaz Semmelweis, a Hungarian physician who, in the 19th century, discovered that hand washing could prevent the spread of infectious diseases in hospitals. Despite his findings, he was ridiculed and ignored by his colleagues, and it took many years for his ideas to be accepted and implemented.\n\nIn the context of A/B testing, the Semmelweis effect can manifest in several ways. For example, a company may have a long-standing belief that a certain design or feature is effective and produces good results, and may not want to experiment with it because everyone knows it ‘correct’. Even if an experiment is run against this entrenched belief, and the results of an A/B test challenge established norms, there may be resistance to accept the new evidence and change the established practice.\n\nTo avoid the Semmelweis effect in A/B testing, it is important to approach experimentation with an open mind and a willingness to challenge established beliefs and practices. It is crucial to let the data guide decision-making and to be open to trying new things, even if they go against conventional wisdom or past practices. It is also important to regularly review and evaluate the results of A/B tests to ensure that the company's beliefs and practices are aligned with the latest evidence and insights, and haven’t changed over time.\n\n### Confirmation Bias[​](#confirmation-bias \"Direct link to Confirmation Bias\")\n\nConfirmation bias refers to the tendency to favor information that confirms our preexisting beliefs and to ignore or discount information that contradicts our beliefs. In the context of A/B testing, confirmation bias can lead to flawed decision-making and missed opportunities for optimization.\n\nFor example, if a company believes that a certain website design or feature is effective, they may only run A/B tests that confirm their beliefs and ignore tests that challenge their beliefs. This can lead to a bias towards interpreting data in a way that supports preexisting beliefs, rather than objectively evaluating the results of the tests. Or a PM may believe a new version of their product will be superior, and only acknowledge evidence that confirms this belief.\n\nConfirmation bias can also manifest in the way tests are designed and implemented. If a company designs an A/B test in a way that biases the results towards a particular outcome, such as by using a biased sample or by selecting a suboptimal metric to measure success, it can lead to misleading results that confirm preexisting beliefs.\n\nTo avoid confirmation bias in A/B testing, it is important to approach experimentation with an open and objective mindset. This involves being willing to challenge preexisting beliefs (Semmelweis) and being open to the possibility that the data may contradict those beliefs. It also involves designing tests in a way that is unbiased and that measures the most relevant and meaningful metrics to evaluate success. Having multiple stakeholders review and evaluate the results of A/B tests can help ensure that decisions are based on objective data, rather than personal biases or beliefs.\n\n### HiPPOs[​](#hippos \"Direct link to HiPPOs\")\n\nHiPPO is an acronym for the \"highest paid person's opinion.\" In less data-driven companies, decisions about what product to build or which products to ship are made by HiPPOs. The problem with HiPPOs is that it turns out their opinions are no more likely to be right than anyone else's opinions, and are therefore often wrong. But due to their status they may resist against experimentation to preserve their status or ego. The HiPPO effect is a common problem in many organizations, and it can lead to poor decision-making and missed opportunities for your product.\n\n### Trustworthiness[​](#trustworthiness \"Direct link to Trustworthiness\")\n\nWhen experiment results challenge existing norms or an individual’s beliefs, it can be easy to blame the data. For this reason, having a trustworthy A/B testing platform is extremely important. There must be ways to audit the results, and look into if there was any systemic or specific problem affecting the results of the experiment. Running A/A tests can help build trust that the platform is working correctly. Trust in an experimentation platform is built over time, and care must be taken to not just dismiss results that are counterintuitive.\n\n### Twyman's Law[​](#twymans-law \"Direct link to Twyman's Law\")\n\nTwyman's law is a principle in statistics that states that any data that is measured and collected will contain some degree of error, and that this error is an inherent part of the data. It is named after the British statistician Maurice G. Kendall Twyman.\n\nIn the context of A/B testing, Twyman's law suggests that there will always be some level of variability or uncertainty in the results of an A/B test due to factors such as random chance, sample size, or measurement error. It is often phrased as:\n\n> Any data or figure that looks interesting or different is usually wrong\n\nIf you notice a particularly large or unusual change in the results of an experiment, it is more likely to be the result of a problem with the data or an implementation than an actual result. Before you share the results, make sure that the effects are not the result of an error.\n\n### Goodhart's Law[​](#goodharts-law \"Direct link to Goodhart's Law\")\n\nGoodhart's law is a concept in economics that states that when a measure becomes a target, it ceases to be a good measure. In other words, once a metric becomes the sole focus of attention and effort, it loses its value as an indicator of the desired outcome.\n\nWhen it comes to A/B testing, Goodhart's law can apply in several ways. For example, if a specific metric such as click-through rate or conversion rate becomes the sole focus of an A/B test, it can lead to unintended consequences such as artificially inflating the metric while neglecting other important aspects of the user experience. This can happen because individuals or teams may optimize for the metric being measured rather than focusing on the broader goals of the A/B test, such as improving user engagement or increasing revenue.\n\nTo avoid the negative effects of Goodhart's law in A/B testing, it is important to choose the right metrics to track and analyze, and to use a variety of metrics to evaluate the effectiveness of the test. It is also important to keep in mind the broader goals of the test and to avoid tunnel vision on any one metric. Goodhart's law is more likely to happen when you are using proxy metrics, instead of the real KPIs you’re trying to improve - an example of this might be items added to a cart being used as a proxy for purchases. Also If the proxy metric is not strongly causally linked to the target metric, pressing hard on the proxy may have no effect on the goal metric, or might actually cause the correlation to break.\n\n### Simpson's Paradox[​](#simpsons-paradox \"Direct link to Simpson's Paradox\")\n\nSimpson's paradox is a statistical phenomenon where a trend or pattern appears in different groups of data but disappears or reverses when the groups are combined. In other words, the overall result may be opposite to what the individual subgroups suggest.\n\nThis paradox can arise when a confounding variable (a variable that affects both the independent and dependent variables) is not taken into account while analyzing the data.\n\nSimpson's paradox was famously observed at the University of California, Berkeley in 1973, where it had implications for gender discrimination in graduate school admissions.\n\nAt the time, it was observed that although the overall admission rate for graduate school was higher for men than for women (44% vs. 35%), when the admission rates were broken down by department, the reverse was true for many of the departments, with women having a higher admission rate than men in each department. In the Department of Education, for example, women had a 77% admission rate compared to men's 62% admission rate.\n\nThe paradox was resolved by examining the application data more closely and considering the impact of an important confounding variable, which was the choice of department. It was discovered that women were more likely to apply to departments that were more competitive and had lower admission rates, while men were more likely to apply to less competitive departments with higher admission rates.\n\nWhen the data was reanalyzed, taking into account the departmental differences in admission rates, it was found that women actually had a slightly higher overall admission rate than men, suggesting that there was no discrimination against women in the admissions process. This case study illustrates how Simpson's paradox can occur due to the influence of confounding variables, and how it can lead to misleading conclusions if not properly accounted for in the analysis. To avoid the Simpson's paradox in experimentation, it is essential to analyze the data by considering all relevant variables and subgroups. It is crucial to ensure that the experimental groups are similar in terms of demographics and behavior, and to use statistical techniques that account for confounding variables.\n\n### Ethical considerations[​](#ethical-considerations \"Direct link to Ethical considerations\")\n\nExperimentation judges the outcome of changes by looking at the impact it has on some set of metrics. But the seeming objectivity of the results can hide problems. The simplest way this can go wrong is if your metrics are tracking the wrong things, in which case you’ll have garbage in and garbage out. But it is also possible for the metrics to not capture harm that is being done to some subsets of your population.\n\nExperimentation results work on averages, and this can hide a lot of systemic biases that may exist. There can be a tendency for algorithmic systems to “learn” or otherwise encode real-world biases in their operation, and then further amplify/reinforce those biases.\n\nProduct design has the potential to differentially benefit some groups of users more than others; It is possible to measure this effect and ensure that results account for these groups. Sparse or poor data quality that leads to objective-setting errors and system designs that lead to suboptimal outcomes for many groups of end users. One company that does this very well is the team at LinkedIn, you can read about their approach [here](https://engineering.linkedin.com/blog/2020/building-inclusive-products-through-a-b-testing).",
    "title": "Where Experimentation goes wrong | GrowthBook Docs",
    "description": "The following contains a list of common pitfalls and mistakes that can happen when running A/B tests.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/using/experimenting",
    "markdown": "# Experimenting in GrowthBook | GrowthBook Docs\n\nThe Experiments section in GrowthBook is all about analyzing raw experiment results in a data source. Before analyzing results, you need to actually run the experiment. This can be done in several ways:\n\n*   Feature Flags (most common)\n*   Running an inline experiment directly with our SDKs\n*   Our Visual Editor (beta)\n*   Your own custom variation assignment / bucketing system\n\nWhen you go to add an experiment in GrowthBook, it will first look in your data source for any new experiment ids and prompt you to import them. If none are found, you can enter the experiment settings yourself.\n\n## Experiment Splits[​](#experiment-splits \"Direct link to Experiment Splits\")\n\nWhen you run an experiment, you need to choose who will get the experiment, and what percentage those users should get each variation. In GrowthBook, we allow you to pick overall exposure percentage, as well as customize the split per variation. Yor can also target an experiment at just some attribute values.\n\nGrowthBook uses deterministic hashing to do the assignment. That means that each user’s hashing attribute (usually user id), and the experiment name, are hashed together to get a number from 0 to 1. This number will always be the same for the same set of inputs.\n\nThere is quite often a need to de-risk a new A/B test by running the control at a higher percentage of users than the new variation, for example, 80% of users get the control, and 20% get the new variation. To solve this case, we recommend keeping the experiment spits equal, and adjusting the overall exposure (ie, 20% exposure, 50/50 on each variation, so each variation gets 10%). This way the overall exposure can be ramped up (or down) without having any users potentially switch variations.\n\n## Metric selection[​](#metric-selection \"Direct link to Metric selection\")\n\nGrowthBook lets you choose goal metrics and guardrail metrics. Goal metrics are the metrics you’re trying to improve or measure the impact of the change of your experiment. Guardrail metrics are metrics you’re not necessarily trying to improve, but you don’t want to hurt. With goal metrics we show full statistical changes on the metrics. Guardrail metrics we only show the chance of that metric being worse- if there is a significant chance that the guard rail metric is worse, it will be shown in red, otherwise it will be green.\n\n![GrowthBook Metric Selector](https://docs.growthbook.io/images/using/metrics-modal.png)\n\nIt is best to pick metrics for your experiment that are as close to your treatment as possible, and, if possible, the event itself. For example, if you’re trying to improve a signup rate, you can add product review metrics that are close to that event, like \"signup modal open rate\", and \"signup conversion rate\". You can add as many metrics as you like to your experiment, but we suggest each experiment have only a few primary metrics that are used for making the shipping decision. Adding all your metrics is not recommended, as this can lead to false positives caused by random variations (see [Multiple testing problem](https://docs.growthbook.io/using/experimentation-problems#multiple-testing-problem))\n\nBefore you being a test, you should have selected a primary metric or set of metrics that you are trying to improve. These metrics are often called the OEC for Overall Evaluation Criterion. It is important to have this decided ahead of time so when you look at your experiment results you're not just shopping for metrics that confirm your bias (see [confirmation bias](https://docs.growthbook.io/using/experimentation-problems#confirmation-bias)).\n\nWith GrowthBook, Goal and guardrail metrics can be added retroactively to experiments, as long as the data exists in your data warehouse. This allows you to reprocess old experiments if you add new metrics or redefine a metric.\n\n## Activation metrics[​](#activation-metrics \"Direct link to Activation metrics\")\n\nAssigning your audience to the experiment should happen as close to the test as possible to reduce noise and increase power. However, there are times when running an experiment requires that users be bucketed into variations before knowing that they are actually being exposed to the variation. One common example of this is with website modals, where the modal code needs to be loaded on the page with the experiment variations, but you’re not sure if each user will actually see the modal. With activation metrics you can specify a metric that needs to be present to filter the list of exposed users to just those with that event.\n\n## Sample sizes[​](#sample-sizes \"Direct link to Sample sizes\")\n\nWhen running an experiment you select your goal metrics. Getting enough samples depends on the size of the effect you’re trying to detect. If you think the experiment will have a large effect, the smaller total number of events you need to collect. GrowthBook allows users to set a minimum sample size for each metric where we will hide results before that threshold is reached to avoid premature peeking.\n\n## Test Duration[​](#test-duration \"Direct link to Test Duration\")\n\nWe recommend running an experiment for at least 1 or 2 weeks to capture variations in your traffic. Before a test is significant, GrowthBook will give you an estimated time remaining before it reaches the minimum thresholds. Traffic to your product is likely not uniform, and there may be differences\n\n## Metric Windows[​](#metric-windows \"Direct link to Metric Windows\")\n\nA lot can happen between when a user is exposed to an experiment, and when a metric event is triggered. How you want to attribute that conversion event to the experiment is adjustable within GrowthBook using metric and experiment level settings.\n\nAt the metric level, you can pick three different metric windows:\n\n*   None - uses as much data as possible from the user's exposure until the end of the experiment.\n*   Conversion - uses only data in some window after a user's first exposure. If the metric's conversion window is set to 72 hours, any conversion that happens after that is ignored.\n*   Lookback - uses only data in the last window before an experiment ends.\n\nHere's a representation of how these metric windows work for a hypothetical user: ![Metric Windows](https://docs.growthbook.io/assets/images/metric-windows-024e6a7e756c8cd43f0d35ee221cc089.png)\n\nHere's a second example for a hypothetical User 2, who joins the experiment late. Notice that the conversion window can extend beyond the experiment end date. ![Metric Windows (User 2)](https://docs.growthbook.io/assets/images/metric-windows-user-2-dac5ae6d7345e2211ec13dd5f8869954.png)\n\nYou can override all Conversion windows to be No window at the experiment level using the \"Conversion Window Override\" in the Experiment Analysis Settings.\n\n## Understanding results[​](#understanding-results \"Direct link to Understanding results\")\n\n### Bayesian Results[​](#bayesian-results \"Direct link to Bayesian Results\")\n\nIn GrowthBook the experiment results will look like this.\n\n![GrowthBook Results](https://docs.growthbook.io/assets/images/experiment-results-bayesian-9795c6f96f84948810be08d4fc1e422c.png)\n\nEach row of this table is a different metric. This is a simplified overview of the data. If you want to see the full data, including 'risk', mouse over any of the results.\n\n![GrowthBook Results](https://docs.growthbook.io/assets/images/experiment-results-bayesian-details2-6467b6c748328e614a5b879ef8a12437.png)\n\nRisk tells you how much you are predicted to lose if you choose the selected variation as the winner and you are wrong. You can specify upper risk thresholds (designed to flag high-risk outcomes) and lower risk thresholds (designed to flag low-risk outcomes) in Behavior on the Metrics tab. Red indicates that the treatment variation has risk above the high-risk threshold. Yellow indicates that your risk is between the two thresholds. You can use the dropdown to see the risk of choosing a different winner if you have multiple variations.\n\nValue is the conversion rate or average value per user. In small print you can see the raw numbers used to calculate this.\n\n**Chance to Beat Control** tells you the probability that the variation is better. If you are familiar with Frequentist statistics, you can consider this value 1 - the p value. Anything above the threshold (which by default is set to 95%) is highlighted green indicating a very clear winner. Anything below the threshold (5% by default) is highlighted red, indicating a very clear loser. Anything in between is gray indicating it's inconclusive. If that's the case, there's either no measurable difference or you haven't gathered enough data yet.\n\n**Percent Change** shows how much better/worse the variation is compared to the control. It is a probability density graph and the thicker the area, the more likely the true percent change will be there. As you collect more data, the tails of the graphs will shorten, indicating more certainty around the estimates.\n\n### Frequentist Results[​](#frequentist-results \"Direct link to Frequentist Results\")\n\nYou can also choose to analyze results using a Frequentist engine that conducts simple t-tests for differences in means and displays the commensurate p-values and confidence intervals. If you selected the \"Frequentist\" engine, when you navigate to the results tab to view and update the results, you will see the following results:\n\n![GrowthBook Results - Frequentist](https://docs.growthbook.io/assets/images/experiment-results-frequentist-b5e8df21a43c3e63521999a80206bbbf.png)\n\nEverything is the same as above except for three key changes:\n\n*   There is no longer a risk value, as the concept is not easily replicated in frequentist statistics.\n*   The Chance to Beat Control column has been replaced with the P-value column. The p-value is the probability that the percent change for a variant would have been observed if the true percent change were zero. When the p-value is less than the threshold (default to 0.05) and the percent change is in the preferred direction, we highlight the cell green, indicating it is a clear winner. When the p-value is less than the threshold and the percent change is opposite the preferred direction, we highlight the cell red, indicating the variant is a clear loser on this metric.\n*   We now present a 95% confidence interval rather than a posterior probability density plot.\n\n## Data quality checks[​](#data-quality-checks \"Direct link to Data quality checks\")\n\nGrowthBook performs automatic data quality checks to ensure the statistical inferences are valid and ready for interpretation. You can see all check and monitor the health of your experiments on the experiment **health page**.\n\n### Health Page[​](#health-page \"Direct link to Health Page\")\n\nGrowthBook automatically does data quality checks on all experiments and shows the results on the our _Health Page_.\n\n![Experiment Health Page](https://docs.growthbook.io/images/using/health-page.png)\n\nThis page shows experiment exposure over time, and also all the other health checks we do.\n\n### Sample Ratio Mismatch (SRM)[​](#sample-ratio-mismatch-srm \"Direct link to Sample Ratio Mismatch (SRM)\")\n\nEvery experiment automatically checks for a Sample Ratio Mismatch and will warn you if found. This happens when you expect a certain traffic split (e.g. 50/50) but you see something significantly different (e.g. 46/54). We only show this warning if the p-value is less than 0.001, which means it's extremely unlikely to occur by chance. We will show this warning on the results page, and also on our experiment health page.\n\n![Sample Ratio Mismatch](https://docs.growthbook.io/images/using/srm-check-health-page.png)\n\nLike the warning says, you shouldn't trust the results since they are likely misleading. Instead, find and fix the source of the bug and restart the experiment. You can find more information about potential sources of the problems in our [troubleshooting guide](https://docs.growthbook.io/kb/experiments/troubleshooting-experiments).\n\n### Multiple Exposures[​](#multiple-exposures \"Direct link to Multiple Exposures\")\n\nWe also automatically check each experiment to make sure that too many users have not been exposed to multiple variations of a single experiment. This can happen if the hashing attribute is different from the assignment id used in the report, or for implementation problems.\n\n### Minimum Data Thresholds[​](#minimum-data-thresholds \"Direct link to Minimum Data Thresholds\")\n\nYou can set thresholds per metric to make sure people viewing the results aren’t drawing conclusions too early (e.g. when it’s 5 vs 2 conversions)\n\n### Variation Id Mismatch[​](#variation-id-mismatch \"Direct link to Variation Id Mismatch\")\n\nGrowthBook can detect missing or improperly-tagged rows in your data warehouse. The most common way this can happen if you assign with one parameter, but send a different ID to your warehouse from the trackingCallback call. It may indicate that your variation assignment tracking is not working properly.\n\n### Suspicious Uplift Detection[​](#suspicious-uplift-detection \"Direct link to Suspicious Uplift Detection\")\n\nYou can set thresholds per metric for a maximum percent change. When a metric results is above this, GrowthBook will show an alert. Large uplifts may indicate a bug - see [Twymans Law](https://docs.growthbook.io/using/experimentation-problems#twymans-law).\n\n### Guardrails[​](#guardrails \"Direct link to Guardrails\")\n\nmetrics are ones that you want to keep an eye on, but aren't trying to specifically improve with your experiment. For example, if you are trying to improve page load times, you may add revenue as a guardrail since you don't want to inadvertently harm it.\n\nGuardrail results show up beneath the main table of goal metrics. The full statistics are shown like goal metrics, and similarly they are colored based on \"Chance to Beat Control\". If guardrail metrics become significant, you may want to consider ending the experiment.\n\n![Guardrail Results](https://docs.growthbook.io/assets/images/guardrail-metrics-52c56135d12db6cd370dcfffecdc2951.png)\n\nIf you select the frequentist engine, we instead use yellow to represent a metric moving in the wrong direction at all (regardless of statistical significance), red to represent a metric moving in the wrong direction with a two-sided t-test p-value below 0.05, and green to represent a metric moving in the right direction with a p-value below 0.05. Otherwise the cell is unshaded if the metric is moving in the right direction but not statistically significant at the 0.05 level.\n\n## Digging deeper[​](#digging-deeper \"Direct link to Digging deeper\")\n\nGrowthBook lets you dig into the results to get a better understanding of the likely effect of your change.\n\n### Segmentation[​](#segmentation \"Direct link to Segmentation\")\n\nSegments are applied to experiment results to only show users that match a particular attribute. For example, you might have “country” as a dimension, and create a segment for just “US visitors”. In the experiment you can configure the experiment to just look at one particular segment of users. Segments can be created with SQL from the \"Data and Metrics → Segments\" page.\n\n![Segments](https://docs.growthbook.io/assets/images/segments-page-17eb191d453041d9f79d291d05ec3eed.png)\n\nThere are two ways you can use segments in your experiment results. The first is to use edit the experiment's 'analytics settings' and add one of the segments. The other way is to create a custom ad-hoc reports, and then click on 'customize' and select a segment to apply to the results.\n\n### Dimensions[​](#dimensions \"Direct link to Dimensions\")\n\nGrowthBook lets you break down results by any dimension you know about your users. We automatically let you break down by date, and any additional dimensions can be added either with the exposure query, or with custom SQL from the dimension menu. Some examples of common dimensions are “Browser” or “location”. You can read more about [dimensions here](https://docs.growthbook.io/app/dimensions).\n\n![Dimension Selector](https://docs.growthbook.io/assets/images/dimension-selector-fae643d610ac41d989b24ad64e229d29.png)\n\nIt can be very helpful to look into how specific dimensions of your users are affected by the experiment. For example, you may discover that a specific browser is underperforming compared to the rest, and this may indicate a bug, or something to investigate further. The more metrics and dimensions you look at, the more likely you are to see a false positive. If you find something that looks surprising, it's often worth a dedicated follow-up experiment to verify that it's real.\n\n### Ad-hoc reports[​](#ad-hoc-reports \"Direct link to Ad-hoc reports\")\n\nExperiment reports have a lot of configuration, and sometimes it can be useful to want to adjust these configurations without changing the original report. GrowthBook supports Ad-hoc reports, which are essentially copies of the original report, where you can adjust any of the configuration parameters, such as segments, dates, metrics, even custom SQL to remove outliers.\n\n![Ad-hoc Reports Menu](https://docs.growthbook.io/assets/images/ad-hoc-menu-eab86c8ac6e19aa4bd41d34b81b373ef.png)\n\nAll ad hoc reports created can be shared publicly and live at the bottom of the report, to make sure you capture any derived results.\n\n![Ad-hoc Reports and Publishing](https://docs.growthbook.io/assets/images/ad-hoc-report-saving-9365c19e4e93fae964b6cd231025a304.png)\n\n## Deciding A/B test results[​](#deciding-ab-test-results \"Direct link to Deciding A/B test results\")\n\nHopefully you are analysing your experiment results with your OEC already documented. Even so, when to stop, and how to interpret results may not be straight forward.\n\n### When to stop an experiment[​](#when-to-stop-an-experiment \"Direct link to When to stop an experiment\")\n\nWhen using the Bayesian statistic engine, there are a few methods you can use when stopping a test.\n\n*   significance reached on your primary metrics\n*   metric risk drop below your risk thresholds\n*   guardrail metrics are not affected\n*   test duration reached\n\nIt all depends on what you’re trying to do with the experiment. For example, if you’d like to know what impact your change has, you should use the first method. If you’re doing a design change, and want to make sure you haven’t broken anything on your product, you can use the risk or guard rail approach. You should also make sure that the experiment has run for your minimum test duration (typically 1 or 2 weeks), so that you’re not looking at highly skewed sampling.\n\nFor Frequentist statistics, you should determine the running time of the experiment and stop the test at that fixed horizon to ensure accurate results (see [Peeking](https://docs.growthbook.io/using/experimentation-problems#peeking)) or use Sequential analysis.\n\n### Interpreting results[​](#interpreting-results \"Direct link to Interpreting results\")\n\nIt is quite common to have experiment results with mixed results. Deciding on the results of an experiment in these cases may require some interpretation. As a general rule, you should have one goal metric that is the primary metric you’re trying to improve, and if this metric is up significantly it is generally straightforward to declare a result. If you have a mix and up and down metrics, the decisions are less clear.\n\nOnce you have reached a decision with your experiment, you can click the “mark as finished” link towards the top of the results. This will open a modal where you can document the results, including the result, and observations.\n\nThis creates a card on the top of the experiment results with your conclusion. Please note that currently this marking a test as finished does not stop the test from running. If you are using feature flags to run the experiment, you should also go to the feature and turn off the experiment.\n\n### Inconclusive results[​](#inconclusive-results \"Direct link to Inconclusive results\")\n\nSometimes you may have an experiment that is inconclusive. Generally it is a good idea to have a policy of what to do in these cases. We suggest that your policy should be to revert to the control variant in these cases, unless the new version unlocks some new features.",
    "title": "Experimenting in GrowthBook | GrowthBook Docs",
    "description": "The Experiments section in GrowthBook is all about analyzing raw experiment results in a data source.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/using/growthbook-best-practices",
    "markdown": "# GrowthBook Best Practices | GrowthBook Docs\n\n## Organization[​](#organization \"Direct link to Organization\")\n\nAs you scale up your usage of GrowthBook and start running many experiments, keeping everything organized and easy to find is essential. GrowthBook includes a number of organizational structures to help you scale.\n\n### Organizations[​](#organizations \"Direct link to Organizations\")\n\nThe organization is the highest level structure within GrowthBook. An organization contains everything within your GrowthBook instance: users, data sources, metrics, features, etc. For both cloud and self-hosted users, it is possible for users to join multiple organizations. Users can belong to multiple organizations, but each organization is otherwise entirely independent of the others. For some, complete isolation of the teams or subdivisions within the company may be desired. For example, if your company has two or more largely independent products (e.g., Google has Search and Google Docs), you can set up multiple organizations per product.\n\nFor self-hosted enterprise users, we support multi-organization mode, which also comes with a super-admin account type that can manage users across organizations.\n\n### Environments[​](#environments \"Direct link to Environments\")\n\nIn GrowthBook, you can create as many environments as you need for the feature flags and override rules. Environments are meant to separate how your feature flags and override rules are deployed. Each environment can have one or more SDK API endpoints specified when you create the SDK, allowing you to differentiate the override rules. For example, you might have environments for “Staging”, “QA”, and “Production”. While testing the feature, you can set specific rules to on the \"development\" or \"QA\" environment, and when you're ready, you can move applicable rules to the \"production\" environment.\n\nYou can add an arbitrary number of environments from the SDK Connections → Environments page.\n\n![Environments Page](https://docs.growthbook.io/assets/images/environments-page-604601ebe249b0931dfe040447157633.png)\n\n### Projects[​](#projects \"Direct link to Projects\")\n\nWithin an organization, you can create projects. Projects can help isolate the view of GrowthBook to just the sections that apply for that GrowthBook user. Projects are a great way to organizationally separate features, metrics, experiments, and even data sources by team or product feature. For example, you could have a project “front-end” and one for “back-end”, or by team like “Growth” and “API”. Unlike separate organizations, projects can share data. Projects are managed from the Settings → Projects page.\n\n![Projects Page](https://docs.growthbook.io/assets/images/projects-page-f0374689d7f4e39f1eaa9df350d47431.png)\n\nA use case for using projects is if you have divisions within your product but a centralized data source. We typically see projects used per team or per project within your organization. For example, if you have a mobile app and a website that shares users, but the code bases are different, you will want to create two projects: a _mobile_ project and a _web_ project.\n\nEach of the items within GrowthBook can be assigned to multiple projects. You can have a data source that is part of the ‘mobile’ and ‘web’ projects but not to a ‘marketing’ project. That data source will not be available for users in the 'marketing' project.\n\nTo help keep feature payloads smaller, the SDK endpoint where the feature definitions are returned can be scoped to each project. If using Projects based on features or area of your product, you can use this feature to only return features that pertain to that area. For example, with our “mobile” and “website” example, you can add the project scope to only return features for the project as these are likely to use different code than the other, and you don’t want to expose features unnecessarily.\n\nOne advantage of using projects is that you can adjust permissions and even some statistical settings per project- users can have no access to a project or, inversely, have no general permissions but add a project permission so they can work within their project. If a team prefers to use a frequentist statistical model, this can be adjusted per project.\n\n### Tags[​](#tags \"Direct link to Tags\")\n\nAnother way to organize GrowthBook is with _tags_. With tags, you can quickly filter lists, and select metrics. For example, if you tagged all experiments to do with your checkout flow with the tag “checkout”, you can quickly see this in the list by clicking on ‘filter by tags’ on the experiment list. Tags can be color-coded and managed from our Settings → Tags page. You can add multiple tags per item you are tagging.\n\n![Tags Page](https://docs.growthbook.io/assets/images/tags-page-1af987220eb5c4668698e8ab7d230a5e.png)\n\nMetrics with tags can be used to quickly add all those metrics to an experiment. When creating an experiment or editing the metrics, there is a section titled “Select metric by tag” which will let you add all the metrics by the tag name to both guardrail and goal metrics. This is useful if you want to use a standard set of goal metrics or guardrail metrics for your experiments.\n\nTags are often used to mark sub-features of your product; for example, if you have an e-commerce website, you might want to tag features or experiments with the area they affect, like ‘_pricing_,’ ‘_product page_,’ or ‘_checkout_.’\n\n![Experiments filtered by tag](https://docs.growthbook.io/assets/images/experiments-filtered-by-tag-39ea1da83577ea267a0e3d49147c7000.png)\n\n### Naming[​](#naming \"Direct link to Naming\")\n\nAnother organizing principle you can use is the naming of your experiments and features. Because GrowthBook makes it easy to quickly search the list of features and flags, using naming conventions can be an effective way to organize your project.\n\nWe’ve seen several strategies be successful here, but as a general rule, you’ll want to be as specific as possible with naming features and experiments. For example, you can use <project scope>\\_<project name> or the year, quarter, or section plus the name of the experiment, e.g.: “23-Q4 New user registration modal“ or “23-Team3 Simplified checkout flow”. This lets you quickly see when the experiment was run or which team worked on it.\n\n### Hygiene & Archiving[​](#hygiene--archiving \"Direct link to Hygiene & Archiving\")\n\nAs the number of features and experiments grows, you will want to remove past items that are no longer relevant. Within GrowthBook you can archive and delete. **Deleting** something will permanently remove items from GrowthBook. **Archived** items in GrowthBook won’t be deleted, but they are removed from the main part of the UI and not available for adding to new experiments (for archived metrics). Archived items can also be restored at any time. These methods help you keep your UI clean and relevant.\n\n### Source of Truth[​](#source-of-truth \"Direct link to Source of Truth\")\n\nIf you run an experimentation program for a long enough time, you’ll find yourself with an experiment idea that seems really familiar, and people will wonder, “Didn’t we already test this?” If you don’t have a central repository for all your experiment results, it can be difficult to find if you did test this previously, and even if you did, if what you tested was similar enough to the new idea not to have to test it again.\n\nGrowthBook is designed to help with this by creating a central source for the features you’ve launched and the experiments you’ve run. To help facilitate this, GrowthBook has created a number of features to help you capture meta information.\n\n### Meta Information[​](#meta-information \"Direct link to Meta Information\")\n\nFeatures and experiments can all have metadata attached to them. The purpose of this is to help capture all the meta-information around a feature or experiment that might help contextualize it for posterity and help capture the institutional knowledge that your program generates. This is also very helpful when new members join your team, so they don’t just suggest ideas you’ve run many times already.\n\nFor experiments, you should capture the original idea, any screenshots of similar products, and, most importantly, capture images/screenshots of the control and variants for the experiment. Quite often, someone will suggest an idea you’ve run previously. In these cases, it is vital to be able to find out what exactly you tested previously - it's possible that the new idea is slightly different, or you may decide that it is the same and try testing another idea, or you could decide that your product is substantially different, and the same idea may be worth testing again. To make this decision, it is essential to capture not just the experiment results but the broader context of what your product looked like at the time and the test variants.\n\nGetting your team to document is always a challenge. GrowthBook takes two approaches to help with this. The first is to make it super easy to add documentation directly in the platform you’re already using for the experiment. Secondly, we added launch checklists, which can require that certain files be filled before your team is able to start an experiment.\n\n## Searching[​](#searching \"Direct link to Searching\")\n\nGrowthBook has a powerful search feature that allows you to quickly find the feature, experiment, or metrics. By default, text searches with this search input will search based on the name, description, and other meta information. You can also search using syntax search to search for specific fields.\n\n### Syntax Search[​](#syntax-search \"Direct link to Syntax Search\")\n\nSyntax search allows you to search for specific fields in GrowthBook. The syntax search allows for exact matching, starts with, greater, less, and contains. You can also negate any of the operators using !. Syntax searches are constructed in the format of `[field]:[operator][value]`. You can also combine multiple fields using the same syntax. For example, `name:~pricing status:running` will search for all running experiments with the name containing the string \"pricing\".\n\n| Syntax operator | Description |\n| --- | --- |\n| :   | exact match |\n| :=  | exact match |\n| :~  | contains |\n| :^  | starts with |\n| :>  | greater than |\n| :<  | less than |\n| :!  | negated (exclude matches) |\n| :!= | negated (exclude matches) |\n| :!~ | does not contain |\n| :!^ | does not starts with |\n| :!> | not greater than |\n| :!< | not less than |\n\nYou can also add quotes to search for fields that contain spaces. For example, `name:\"New Feature\"` will search for the name field that contains the text “New Feature”.\n\n### Experiments Syntax Fields[​](#experiments-syntax-fields \"Direct link to Experiments Syntax Fields\")\n\nSyntax fieldDescriptionnameThe experiment name (eg: name:~pricing)key or idThe experiment's tracking key (eg: key:^banner)statusExperiment status, can be one of \"stopped\", \"running\", \"draft\", \"archived\" (eg: status:running)ownerThe creator of the experiment (eg: owner:pat)tagExperiments tagged with this tagprojectThe experiment's projectfeatureThe experiment is linked to the specified featuremetricExperiments that contain the metric specified (eg: metric:~revenue)resultThe experiment result (won, inconclusive, lost, unfinished)variationThe experiment contains a variant with the name specifiedvariationsSearch for the number of variantscreatedThe experiment's creation date, in UTC. The date entered is parsed so supports most formatsupdatedThe date the experiment was updated, in UTC. The date entered is parsed so supports most formatsvariationsSearch for the number of variantsissupports searching on the experiment status, results, and other current states. Supported fields\n\n|     |     |\n| --- | --- |\n| archived | If the experiment is archived |\n| draft | The experiment is in draft status |\n| running | The experiment is running |\n| stopped | The experiment is stopped |\n| won | The experiment been marked as won |\n| lost | The experiment has been maked as lost |\n| inconclusive | The experiment has been marked as inconclusive |\n| visual | The experiment has variants made with the visual editor |\n| redirect | The experiment has a URL redirect experiment |\n\nhassupports searching on the experiment states. Supported fields\n\n|     |     |\n| --- | --- |\n| project | The experiment belongs to at least one project |\n| visualChange | The experiment has a visual editor change |\n| redirect/redirects | The experiment has a URL redirect |\n| feature/features | The experiment has features attached |\n| hypothesis | The experiment has a hypothesis |\n| description | The experiment has a description |\n| screenshots | The experiment has at least one screenshot |\n\n#### Examples[​](#examples \"Direct link to Examples\")\n\n```\nname:~pricing status:running\n```\n\nShow all running experiments with the name containing the string \"pricing\"\n\n```\ntag:checkout result:won updated:>2024-06-05\n```\n\nShow all experiments tagged with \"checkout\" that have been marked as won and were updated after June 5th, 2024\n\n```\nis:archived has:visualChange variations:>2\n```\n\nShow all archived experiments that have a visual change and have more than 2 variations in the experiment\n\n```\nowner:patty has:!hypothesis\n```\n\nShow all experiments owned by Patty that do not have a hypothesis\n\n```\ncreated:<\"dec 22nd, 2023\" has:redirect metrics:~revenue\n```\n\nShow all experiments that have a redirect and were created before December 22nd, 2023 and contain a metric name containing \"revenue\"\n\n### Features Syntax Fields[​](#features-syntax-fields \"Direct link to Features Syntax Fields\")\n\nSyntax fieldDescriptionkeyThe feature's key (name)ownerThe creator of the feature (eg: owner:abby)rulesMatches based on the number of rules (eg: rules:>2)tagFeatures tagged with this tagprojectThe feature's projectversion or revisionThe feature's revision numberexperimentThe feature is linked to the specified experimentcreatedThe feature's creation date, in UTC. Date entered is parsed so supports most formats.\n\n(eg: created:>\"2024-06-05\" or created:<\"dec 22nd, 2023\")\n\nupdatedThe date the feature was updated, in UTC. Date entered is parsed so supports most formatsonShows features that are on for a specific environment (on:production)offShows features that are off for a specific environment (off:dev)issupports searching on the feature status, results, and other current states. Supported fields\n\n|     |     |\n| --- | --- |\n| archived | If the feature is archived |\n| draft | The feature is in draft status |\n| stale | The feature is stale |\n\nhassupports searching on the feature states. Supported fields\n\n|     |     |\n| --- | --- |\n| project | The feature belongs to at least one project |\n| draft or drafts | The feature has a draft |\n| prerequisites or prereqs | The feature has at least one prerequisite flags |\n| validation or schema or jsonSchema | The feature has a JSON schema attached |\n| rule or rules | The feature has at least one rule |\n| experiment or experiments | The feature has at least one experiment rule |\n| rollout or percent | The feature has at least one precentage rollout rule |\n| force or targeting | The feature has at least one force rule |\n\n#### Examples[​](#examples-1 \"Direct link to Examples\")\n\n```\nkey:~pricing on:production\n```\n\nShow all features with the key containing the string \"pricing\" that are `on` in the production environment\n\nShow all features tagged with \"checkout\" that are stale\n\n```\nis:archived has:prerequisites\n```\n\nShow all archived features that have prerequisites\n\n```\nowner:abby has:draft rules:0\n```\n\nShow all features owned by Abby that have a draft and have no rules\n\n```\nupdated:>\"2024-06-05\" has:experiment\n```\n\nShow all features that have experiment rules and were updated after June 5th, 2024",
    "title": "GrowthBook Best Practices | GrowthBook Docs",
    "description": "Organization",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/using/security",
    "markdown": "# Security | GrowthBook Docs\n\nGrowthBook is built with security in mind, and we have made architectural decisions to ensure that your GrowthBook instance can be as secure as possible. You can read about some of our internal security practices [here](https://www.growthbook.io/security) and on out [GitHub](https://github.com/growthbook/growthbook/blob/main/SECURITY.md). This document covers some of the security considerations for administrators when setting up and using GrowthBook.\n\n## Data Security[​](#data-security \"Direct link to Data Security\")\n\nGrowthBook only stores account information for your users with GrowthBook accounts (email and name). For feature flagging, evaluations typically happen within the SDK, so none of your user’s information is sent to GrowthBook. For experiment reporting, we connect to your data warehouse to pull the assignment/exposure and metric information. This data remains in your data warehouse; GrowthBook only stores the aggregate results, such as the total number of users exposed to each variation and other statistical information. No PII is stored or transferred to GrowthBook with the experimentation reports.\n\nThere are some ways where personal information may be stored or exposed with GrowthBook. If you are using GrowthBook on the client side of your application, the rules about how each feature will be exposed to your users are publicly accessible by inspecting network requests. Usually, these rules contain no personal information, but if you are targeting a specific user or set of users, then this information may be visible to malicious users. If you use GrowthBook on the server side, this information is not exposed to the client. For these reasons, targeting based on PII when using GrowthBook client side is not recommended.\n\nIf you have to target based on PII on the client side, GrowthBook has some ways to make this secure. You can use hashed attributes, where the values are hashed before sending, or you can use encrypted attributes, where the payload is encrypted before sending to the client. Keep in mind that encrypted SDK endpoints will have to decrypt the payload before use, and that means if you are using GrowthBook client side, a malicious actor can see the decrypted payload. You can enable encryption when setting up the SDK, and you can select an attribute as 'hashed' when creating the attribute.\n\nFinally, to avoid these issues, you can also use 'remote evaluations' to evaluate flags based on sensitive information without exposing it, even on the client side. With remote evaluations, the SDK will send the user attribute to your server (or ours), and then that attribute is matched against the rules, and then the state of the feature is returned without revealing the targeting rules to the client. The downside of this approach is that each evaluation requires a network request to evaluate the feature, which can slow down your application.\n\n## Data Access[​](#data-access \"Direct link to Data Access\")\n\nGrowthBook requires read-only access to your data warehouse. This connection information is kept encrypted. You can use permissions to help protect access to your data warehouse through the GrowthBook UI. You can assign users who can edit the connection info, SQL queries for the assignment, or metric queries.\n\nData sources can also be scoped to projects to help isolate access to your data warehouse. You can adjust the permissions so that only users who have access to the project and have the proper permission levels can edit those queries. If you require more separation of your data and metrics within GrowthBook, you can create separate cloud organizations, or run GrowthBook in multi-tenant mode (available when self-hosting as part of GrowthBook Enterprise). With this, you can have separate GrowthBook organizations running from one GrowthBook instance. Each organization will have its own data source, metrics, and users. There is a super-admin account type that can manage users across organizations.\n\n## Infrastructure Security[​](#infrastructure-security \"Direct link to Infrastructure Security\")\n\nGrowthBook Cloud is hosted on AWS, in a multi-tenant environment. We use industry-standard security to ensure that your data is secure. If you require additional security, we also offer self-hosted options. When you self-host, no data leaves your infrastructure. We do have anonymous usage tracking enabled by default, but this can be disabled (see [self-hosted](https://docs.growthbook.io/self-host)).\n\n## Self-hosted deployments[​](#self-hosted-deployments \"Direct link to Self-hosted deployments\")\n\nGrowthBook can be self-hosted on your own infrastructure. If self-hosting, we recommend that you keep GrowthBook behind a firewall, and accessible via a VPN. See [self-hosting](https://docs.growthbook.io/self-host) for more information. GrowthBook should also be regularly updated to ensure that you are running the latest version with the latest security patches. GrowthBook updates are backward compatible and can be easily applied with a single command. See [updating GrowthBook](https://docs.growthbook.io/self-host#updating-to-latest)\n\nBefore deploying GrowthBook in production, we recommend that you make sure you've configured GrowthBook correctly:\n\n*   Change the `JWT_SECRET` environment variable. This is used to sign the JWT tokens used for authentication, and needs to be changed from the default.\n*   Change the `ENCRYPTION_KEY` environment variable. This is used to encrypt sensitive data, and should be set to a long random string.\n*   Set the `NODE_ENV` environment variable to `production`. This will enable add additional optimizations and disable some debugging features.\n\n## Audit logs[​](#audit-logs \"Direct link to Audit logs\")\n\nGrowthBook keeps an audit log of all actions taken on the platform. The audit logs is useful if you need to determine what actions as user has done. You can access this page from the Settings → Log in the left navigation. You can read more about audit logs [here](https://docs.growthbook.io/account/audit-logs).",
    "title": "Security | GrowthBook Docs",
    "description": "GrowthBook is built with security in mind, and we have made architectural decisions to ensure that your",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/using/programs",
    "markdown": "# Experimentation Programs | GrowthBook Docs\n\n“Experimentation”, or being more “data driven” can mean a lot of different things for different companies. It can be anything from running 1 test a quarter, to running 10s of thousands of experiments simultaneously. This difference of experimentation sophistication can be thought of with the crawl, walk, run, fly framework (From “Trustworthy Online Controlled Experiments: A Practical Guide to A/B Testing”, Ron Kohavi, Diane Tang, Ya Xu).\n\n**CRAWL - Basic Analytics** Companies at this stage have added some basic event tracking and are starting to get some visibility into their users behavior. They are not running experiments, but the data is used to come up with insights and potential project ideas.\n\n**WALK - Optimizations** After implementing comprehensive event tracking, focus now turns to starting to optimize the user experience on some parts of the product. At this stage, A/B tests may be run manually, limiting the number of possible experiments that can be run. Typically at this stage, depending on the amount of traffic you have, you may be running 1 to 4 tests per month.\n\n**RUN - Common Experimentation** As a company realizes that experimentation is really the only way to causally determine the impact of the work they are doing, they will start to ramp up their ability to run A/B tests. This means adopting or building an experimentation platform. With this, all larger changes made to their product are tested, as well they may have a Growth Team that is focused on optimizing parts of their product. At this stage, a company will be running 5 - 100 A/B Tests/Month. This may also include hiring a data team to help with setting up and interpreting the results.\n\n**FLY - Ubiquitous Experimentation** For companies that make it to the flying stage, A/B testing becomes the default for every feature. Product teams develop success metrics for all new features, and then they are run as an A/B test to determine if they were successful. At this point, A/B tests are able to be run by anyone in the product and engineering organization. Companies at this stage of ubiquitous experimentation can run anywhere from 100 to 10,000+ A/B Tests/Month.\n\n## Making the case for experimentation[​](#making-the-case-for-experimentation \"Direct link to Making the case for experimentation\")\n\nIf your organization doesn't yet experiment often, you may need to make the case for why you should. The best way, when you are working on a project, is to ask your team \"what does success look like for this project?\" and \"How would we measure that success?\" In this case, two things will happen, either they'll give an answer that is not statistically rigorous, like looking at the metrics before and after, or they will say some variation of \"We don't know\". Once you're team realizes that A/B testing is a controlled way to determine causal impact, they'll wonder how they ever built products without it.\n\nThe next pushback you may get is that A/B testing is too hard, or that it will slow down development. This is where you can make the case for GrowthBook. GrowthBook is designed to make A/B testing easy, and to make it so that you can run experiments without slowing down development. We are warehouse native, so we use whatever data you already are tracking, and our SDKs are extremely light weight and developer friendly. The goal at GrowthBook is to make it so easy and cost efficient to run experiments you'll test far more often.\n\nYou can watch a video of making the case for AB testing here:\n\n### Why AB test?[​](#why-ab-test \"Direct link to Why AB test?\")\n\n*   **Quantify Impact** You can determine the impact of any product change you make. There is a big difference between \"we launched feature X on time\" and \"we launched feature X on time and it raised revenue by Y\".\n*   **De-risking** You can de-risk any product change you make with A/B testing. You can test any change you make to your product, and if it doesn't work, you can roll it back. Typically new projects, if they are going to fail, will fail in 3 ways: The project has errors, the project has bugs that unexpectedly effect your metrics/business, or the project has no bugs or errors, but still negatively effects your business. A/B testing will catch all of these issues, and allows you to roll out to a small set of users to limit the impact of a bad feature.\n*   **Limiting investment on bad ideas** As we discussed in our HAMM section - When you focus on building the smallest testable MVP (or MTP) of a product, you can save a lot of time and effort put into a bad idea. You build the MVP and get real users testing it, and if it turns out that you cannot validate the hypothesis behind the idea, then you can move on to other projects, and limit the time spent on ideas that don't work or that will have a negative impact on your business.\n*   **Learning** If you have a well-designed experiment, you can determine causality. If you limit the number of variables that your test has, you can know the exact change drove that change in behavior, and apply these learnings to future projects.\n\n### Why A/B testing programs fail[​](#why-ab-testing-programs-fail \"Direct link to Why A/B testing programs fail\")\n\n*   **Lack of buy-in** If you don't have buy-in from the top, it can be hard to get the resources you need to run a successful experimentation program. You'll need to make the case for why you should experiment, and why you need the resources to do so.\n*   **High cost** Many experimentation systems, especially legacy ones, can be expensive to run or maintain. When the costs are high, you can end up running fewer experiments, and with fewer experiments, the impact is lower. Eventually, a program in this state can atrophy and die.\n*   **Cognitive Dissonance** As you're often getting counter-intuitive results with A/B testing, team members can start to question the platform itself, and may prefer to listen to their gut over the data. This is why building trust in your platform is so important.\n*   **No visibility into the program's impact** Without some measure of the impact of your experimentation program, it can be hard to justify the expense of running it. You'll want to make sure you have a way to measure the impact of your experimentation program.\n\n## Measuring Experiment Program Success[​](#measuring-experiment-program-success \"Direct link to Measuring Experiment Program Success\")\n\nOnce you have added an experimentation program, teams often look for a way to measure the success of that program. There are a few ways you can use to measure the success of your experimentation program, such as universal holdouts, win rate, experimentation frequency and learning rate. Each of these has their own advantages and disadvantages.\n\n### Universal Holdouts[​](#universal-holdouts \"Direct link to Universal Holdouts\")\n\nUniversal holdouts is a method for keeping a certain percentage of your total traffic from seeing any new features or experiments. Users in a universal holdout will continue to get the control version of every test for an extended period of time, even after an experiment is declared, and then those users are compared to users who are getting all the new features and changes. This effectively gives you a cohort of users that are getting your product as it was, say 6 months ago, and comparing it to all the work you’ve done since. This is the gold standard for determining the cumulative impact of every change and experiment, however, it has a number of issues.\n\nTo make universal holdouts work, you need to keep the code that delivers the old versions running and working on your app. This is often very hard to do. Some changes can have a non zero maintenance cost, block larger migrations, or limit other features until the holdout ends. Also, any bugs that arise that only affect one side of the holdouts (either control or in the variations), can bias the results. Finally, due to the typically smaller size of the universal holdout group, it can take longer for these holdout experiments to reach significant values, unless you have a lot of traffic.\n\nGiven the complexity of running universal holdouts, many companies and teams look for other proxy metrics or KPIs to use for measuring experimentation program success.\n\n### Win Rate[​](#win-rate \"Direct link to Win Rate\")\n\nIt can be very tempting to want to measure the experimentation win rate, the number of A/B tests that win over the total number of tests, and optimize your program for the highest win rate possible. However, using this as the KPI for your experiment program will encourage users to not run high risk experiments and creates a perverse incentive for more potentially impactful results (see Goodhart’s Law). Win rate can also hide the benefits of not launching a “losing” test, which is also a “win”.\n\n### Experimentation Frequency[​](#experimentation-frequency \"Direct link to Experimentation Frequency\")\n\nA more useful measure than win rate is optimizing for the number of experiments that are run. This encourages your team to run a lot of tests which increases the chances of any one test producing meaningful results. It may, however, encourage you to run smaller experiments over larger ones, which may not be optimal for producing the best outcomes.\n\n### Learning Rate[​](#learning-rate \"Direct link to Learning Rate\")\n\nSome teams try to optimize for a “learning rate” which is the rate at which you learn something about your product or users through A/B testing. This does not have the frequency or win rate biases, but also is nebulously defined. How do you define learning? Are there different qualities of what you learn?\n\n### KPI Effect[​](#kpi-effect \"Direct link to KPI Effect\")\n\nIf you can pick a few KPIs for your experimentation program, you should be able see the effects of the experiments you run against this. You may not be able to see causality precisely due to the natural variability in the data, and typically small improvements from an A/B test, but by aligning by the graph of this metric to experiments that are run, you may start to see cumulative effects. This is what GrowthBook shows with our North Star metric feature.\n\n## Prioritization[​](#prioritization \"Direct link to Prioritization\")\n\nGiven the typical success rates of experiments, all prioritization frameworks should be taken with a grain of salt. Our preference at GrowthBook is to add as little process as possible and to maximize for a good mix of iterative and innovative ideas.\n\n### Iteration vs Innovation[​](#iteration-vs-innovation \"Direct link to Iteration vs Innovation\")\n\nIt is useful to think of experiment ideas on a graph with one axis being the effort required and the potential impact on the other. If you divide the ideas into two for high effort/impact and low effort/ impact, you’ll end up with the following quadrant.\n\n|     | Low impact | High impact |\n| --- | --- | --- |\n| **High effort** | Danger | Prioritize |\n| **Low effort** | Prioritize | Run now |\n\nThe low effort, high impact ideas you should be running immediately, and similarly the high effort, low impact ideas you may not want to run at all. But this leaves the other two, low effort but low impact (smaller tests), and high effort high impact ideas (big bets). If you over index for smaller test ideas, you can increase your experimentation frequency, but risk not getting larger gains. If you over index for bigger bets, you decrease your experimentation frequency at the hope of larger returns, at the risk of not achieving the smaller wins which can stack up. You can also consider the smaller tests as being “iterative” and the bigger bets as “innovative”.\n\nFinding a good mix of small, iterative tests and bigger bets/innovative tests is the best strategy. What constitutes “good” is up to the team. Some companies will bucket their ideas into these two groups, and then ensure that they are pulling some percentage of ideas from both lists. A healthy mix of large and small ideas are important to a successful experimentation program.\n\n### Prioritization frameworks[​](#prioritization-frameworks \"Direct link to Prioritization frameworks\")\n\nIn the world of A/B testing, figuring out what to test can be particularly challenging. Often prioritization requires a degree of gut instinct which is often incorrect (see success rates). To solve this, some recommend prioritization frameworks, such as ICE and PIE.\n\nnote\n\nNote: Please keep in mind that while these frameworks may be helpful, they can work to give the appearance of objectivity to subjective opinions.\n\n#### ICE[​](#ice \"Direct link to ICE\")\n\nThe ICE prioritization framework is a simple and popular method for prioritizing A/B testing ideas based on their potential impact, confidence, and ease of implementation. Each idea is evaluated on each of these factors and scored on a scale of 1 to 10 and then averaged to determine the overall score for that idea. Here's a brief explanation of the factors:\n\n*   **Impact**: This measures the potential impact of the testing idea on the key metrics or goals of the business. The impact score should reflect the expected magnitude of the effect, as well as the relevance of the metric to the business objectives.\n*   **Confidence**: This measures the level of confidence that the testing idea will have the expected impact. The confidence score should reflect the quality and quantity of the available evidence, as well as any potential risks or uncertainties.\n*   **Ease**: This measures the ease or difficulty of implementing the testing idea. The ease score should reflect the expected effort, time, and resources required to implement the idea. To calculate the ICE score for each testing idea, simply add up the scores for Impact, Confidence, and Ease, and divide by 3:\n\n> ICE score = (Impact + Confidence + Ease) / 3\n\nOnce all testing ideas have been scored using the ICE framework, they can be ranked in descending order based on their ICE score. The highest-ranked ideas are typically considered the most promising and prioritized for implementation.\n\n#### PIE[​](#pie \"Direct link to PIE\")\n\nLike the ICE Framework, the PIE framework is a method for prioritizing A/B testing ideas based on their potential impact, importance to the business, and ease of implementation. Each score is ranked on a 10 point scale.\n\n*   **Potential**: This measures the potential impact of the testing idea on the key metrics or goals of the business. The potential score should reflect the expected magnitude of the effect, as well as the relevance of the metric to the business objectives.\n*   **Importance**: This measures the importance of the testing idea to the business. The importance score should reflect the degree to which the testing idea aligns with the business goals and objectives, and how critical the metric is to achieving those goals.\n*   **Ease**: This measures the ease or difficulty of implementing the testing idea. The ease score should reflect the expected effort, time, and resources required to implement the idea. To calculate the PIE score for each testing idea, simply multiply the scores for Potential, Importance, and Ease together:\n\n> PIE score = Potential x Importance x Ease\n\nOnce all testing ideas have been scored using the PIE framework, they can be ranked in descending order based on their PIE score. The highest-ranked ideas are typically considered the most promising and prioritized for implementation.\n\n### Bias in prioritization[​](#bias-in-prioritization \"Direct link to Bias in prioritization\")\n\nRegardless of what prioritization method you choose, it's quite common to develop a bias for a particular types of ideas within a team. Make sure you're open to ideas that may not fit your preconceived notions of what will work (see [Semmelweis Effect](https://docs.growthbook.io/using/experimentation-problems#semmelweis-effect)). Be mindful of when you're saying \"no\" to an idea if it's based on data or opinion. The goal, in the end, is to improve your business by producing the best product.\n\n## Experimentation Culture[​](#experimentation-culture \"Direct link to Experimentation Culture\")\n\nAdopting experimentation as a key part of being a more data-driven organization has numerous benefits to culture. Specifically around areas of alignment, speed, humility, and collaboration.\n\n### Alignment[​](#alignment \"Direct link to Alignment\")\n\nAdopting a north star metric or KPI that would drive our business success removes a lot of ambiguity about projects because we had clear success metrics. By making sure you have defined success metrics at the start of your planning cycle, you achieve alignment around your goals. This helps reduce the invariable scope creep and pet features from inserting themselves — or at least gives you a framework to say “yes, but not now.” Knowing what success means also allows developers to start integrating the tracking needed to know if the project would be successful from the beginning, which can often be forgotten or only done as an afterthought.\n\n### Speed[​](#speed \"Direct link to Speed\")\n\nWhen adopting an experimentation mindset, the default answer to a difference of opinion becomes “let’s test it” instead of long drawn out ego bruising meetings. This helps reduce personal opinions or bias affecting decisions. Quite often decisions in companies without this mindset are made by whomever is the loudest, or the HiPPOs (Highest Paid Person’s Opinion). By focusing on which metrics defined success, and defaulting to running an experiment, you can remove the ego from the decision process, and move quickly.\n\nExperimentation can also help increase your product velocity by minimizing the time it takes to determine if your new product or feature has product market fit. Most big ideas can be broken down into a small set of assumptions that, if true, would mean your larger idea may be successful. If you can prove or disprove these ideas, you can move more quickly and not waste time on failing ideas (loss avoidance).\n\n### Intellectual humility[​](#intellectual-humility \"Direct link to Intellectual humility\")\n\nAB testing shows us that, in most of the cases, people are bad at predicting user behaviors. When you realize that your opinions may not be correct, you can start to channel your inner Semmelweis and be open to new ideas that challenge any deeply held entrenched norms or beliefs. Having an open mind and intellectual humility for new ideas can make your workplace a more collaborative environment, and produce better products.\n\n### Team collaboration[​](#team-collaboration \"Direct link to Team collaboration\")\n\nWhen you are open to new ideas, you can remove the silos that prevent teams from collaborating well. The goal is to produce the best product as measured by a specific set of metrics. With this alignment, and the openness to new ideas, you can dramatically increase collaboration as good ideas come from anywhere.\n\n## Driving Experimentation Culture[​](#driving-experimentation-culture \"Direct link to Driving Experimentation Culture\")\n\nDeveloping a culture of experimentation can be hard, especially in a company where it has never existed. It requires a lot of buy-in from the top down, and/or a lot of evangelism from the bottom up.\n\n### Top down[​](#top-down \"Direct link to Top down\")\n\nThis is often the easiest way to drive experimentation culture. If the CEO or CTO or CPO says that they want more experimentation, they can make it happen. In these situations, picking the right platform and educating your team becomes the hardest part. You'll want to pick a platform that the developers like to use, that doesn't add unnecessary effort per experiment, and that brings the incremental cost per experiment close to zero. These are some of the reasons we built GrowthBook. If you do decide on GrowthBook, we can also help with educating your team.\n\n### Bottom up[​](#bottom-up \"Direct link to Bottom up\")\n\nIf you don't have buy-in from the top, you can still drive experimentation culture from the bottom up. Typically this starts with one team that wants to start experimenting. They may start with a simple test. Experimentation like this can be contagious, and other teams may start to see the benefits of running experiments. It's important with this approach to make sure that you are sharing your results, both good and bad, and that you are evangelizing the benefits of experimentation.\n\n### Sharing[​](#sharing \"Direct link to Sharing\")\n\nOne great way to get fresh ideas and to help experimentation culture is to share your experiment ideas and results. Our preferred way to present your results is with an experiment review meeting. The premise behind these is to talk about the experiment without revealing the results, and to have people guess about the outcome. Specifically, you talk about the hypothesis and observations as to what and why you are testing, and then talk about the metrics you’re testing against, and then show screen shots of the variations (if applicable). You can have people vote simply by raising their hand. Once you’ve had people guess, you reveal the actual results. This is a great way to help build intellectual humility and also collect new ideas.\n\nGrowthBook has built experiment review meetings directly into the platform. You can create presentation from the management left navigation. You can then share the presentation with your team, and they can vote on the results.\n\n## Organizational Structures[​](#organizational-structures \"Direct link to Organizational Structures\")\n\nAs you start to scale your experimentation program, you’ll want to think about how you want to organize your teams to ensure high frequency and high quality. There are a number of different ways to organize your teams, and we’ll go through some of the most common ones we’ve seen.\n\n### Isolated teams,[​](#isolated-teams \"Direct link to Isolated teams,\")\n\nWhen companies first start experimenting with experimenting, they often start with isolated teams. This can even be one individual on a team.\n\nOne of the problems with this approach is that as an individual, it is hard to have good ideas to test continually, and you may suffer from idea bias, where your experiences and expertise limit the number and type of ideas you test. Another issue is that successes and failures are not shared. As is typical of experiment programs, if you present ideas that are failing at a 60%+ rate, people may think that the team is doing something wrong.\n\nThese isolated teams can be critical in helping grow awareness of experimentation-driven development. However, the isolated team does not scale well, and running the frequency of experiments to see large impacts will be hard. If the team and leadership like the results, you’ll want to expand to one of the other structures.\n\n### Decentralized Teams[​](#decentralized-teams \"Direct link to Decentralized Teams\")\n\nAs awareness of the ease of and insights gained through experimentation, more teams may start experimenting. This is great and increases the frequency of experimentation that you can run. Each team is empowered to design and start their own experiments- this is sometimes referred to as experimentation democratization.\n\nThere can be some downsides with this approach. It can end up like the Wild West, where best practices, data, metrics, and tooling may not be shared from team to team. This can make it hard for teams to ensure consistent quality and trustworthiness of the results.\n\n### Center of Excellence[​](#center-of-excellence \"Direct link to Center of Excellence\")\n\nTo compensate for the problems of decentralized experimentation programs, many companies will switch to a center-of-excellence approach. With this structure, a central experimentation team ensures that experiments follow best practices, have a testable hypothesis, and have selected the right metrics before launching. This team can also ensure that the data looks right as it comes in and that the results are interpreted correctly.\n\nOne of the issues with the center-of-excellence approach is that it can easily become a bottleneck of excellence and limit the number of experiments that are run.\n\n### Hybrid[​](#hybrid \"Direct link to Hybrid\")\n\nCombining the best of the decentralized teams and center-of-excellence is one of the best ways we’ve seen to run experimentation programs. The Hybrid approach involves an experimentation team that oversees the experiments that are run but don’t directly gatekeep the launching of experiments. In this role, the experimentation team serves as advisors to the teams that are running experiments, helps them improve the quality of experiments, and can also help look into any issues that appear. They can also ensure that the platform, metrics, and data are following their standards. This approach aims to have the experimentation team help educate the product teams on best practices and common pitfalls with running experiments.",
    "title": "Experimentation Programs | GrowthBook Docs",
    "description": "“Experimentation”, or being more “data driven” can mean a lot of different things for different",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/app/experiment-configuration",
    "markdown": "# Experiments (Setup) | GrowthBook Docs\n\nThe Experiments section in GrowthBook is all about analyzing raw experiment results in a data source.\n\nBefore [analyzing results](https://docs.growthbook.io/app/experiment-results), you need to actually run the experiment. This can be done in several ways:\n\n*   [Feature Flags](https://docs.growthbook.io/feature-flag-experiments) (most common)\n*   Running an inline experiment directly with our [SDKs](https://docs.growthbook.io/lib)\n*   [URL Redirects](https://docs.growthbook.io/app/url-redirects)\n*   Our [Visual Editor](https://docs.growthbook.io/app/visual)\n*   Your own custom variation assignment / bucketing system\n\nWhen you go to add an experiment in GrowthBook, it will first look in your [data source](https://docs.growthbook.io/warehouses) for any new experiment ids and prompt you to import them. If none are found, you can enter the experiment settings yourself.\n\n## Adding an Experiment[​](#adding-an-experiment \"Direct link to Adding an Experiment\")\n\nYou can add an experiment analysis to GrowthBook in a few ways.\n\n**Starting an Experiment Analysis from a Feature**\n\nThis is the easiest way to start a new analysis if you have a Feature set up. Navigate to the Feature of interest and click \"View results\" in the Experiment Rule of the Feature. Read more about running feature experiments [here](https://docs.growthbook.io/feature-flag-experiments).\n\n**Importing an Experiment Analysis from your Data Source**\n\nYou can also import an analysis directly from your Data Source using your configured Experiment Assignment Source. If you navigate to the Experiment page in the left toolbar and click Add Experiment, you'll see the following panel.\n\n![Experiment Import Modal](https://docs.growthbook.io/images/import-experiment-modal.png)\n\nOn this modal you can either create an experiment using some metadata that we infer from your metric source using the Import buttons on the right hand side. You can also manually create an experiment from scratch.\n\n## Experiment Configuration[​](#experiment-configuration \"Direct link to Experiment Configuration\")\n\nThere are several different ways to configure your experiment analysis.\n\n### Experiment Metadata[​](#experiment-metadata \"Direct link to Experiment Metadata\")\n\nOn the experiment page in the \"Overview\" tab near the top of the page, you can see the experiment name, tags description, hypothesis, and variation metadata. You can edit these fields as you see fit to help describe and categorize your experiment.\n\n### Experiment Targeting and Traffic[​](#experiment-targeting-and-traffic \"Direct link to Experiment Targeting and Traffic\")\n\nYou can also configure targeting and traffic to your experiment's linked feature flags or visual editor changes. These settings do not have any effect on an experiment that is performing analysis only (with the exception of \"experiment key\"). On the \"Overview\" tab, you will see a section called \"Targeting and Traffic\" which allows you to modify these settings, such as:\n\n**Experiment Key** (tracking key) - This is the key that will be used when filtering your experiment assignment source to query experiment exposure data.\n\n**Hashing attribute** - This is the attribute that will be used to hash the user id to determine which variation they will be bucketed into.\n\n**Fallback attribute** (Sticky Bucketing enabled only) - The Fallback attribute be used when the hash attribute is missing or empty. For example falling back to an anonymous cookie identifier instead of a logged-in user id. Which ever attribute is first used to bucket the user into a variation will \"stick\". For example, if the user is logged out when they first view an experiment, it would use the fallback device id. If the user later logs in, it will continue using the bucket from their device id, even though they now have a logged-in id as well.\n\n**Targeting** - Create matching conditions using attributes and saved groups or target by namespaces.\n\n**Traffic** - Choose the percentage of traffic (coverage) and set the relative weights of each variation.\n\n### Analysis Settings[​](#analysis-settings \"Direct link to Analysis Settings\")\n\nHere is where much of your experiment analysis is configured. Many of the fields here have some text explaining how they affect your analysis. Here are a few of them in more detail:\n\n**Experiment Key**\n\n**Activation Metric** - A binomial metric that will filter the users in your analysis to only those who have converted on this binomial metric. This should only be used if activation is expected to be independent of experiment assignment. If an experiment affects the activation metric directly, then there is the potential for bias in your analysis.\n\n**Metric Conversion Windows** - Some of your metrics may have \"conversion windows\" defined for them. For those metrics, we build a window for each user based on when they were first exposed to the experiment. If a user's first exposure to an experiment was recent (for a running experiment) or or near the end of a stopped experiment, they may not have had the full window to convert before the analysis window closes. You may exclude these users with \"In-Progress Conversions\" if you want your experiment averages to only include those who have had the full window to convert.\n\n**Conversion Override**\n\nPreviously called \"Attribution Model\" in the UI, this setting lets you use an experiment level override to disable all conversion windows and instead use the exposure period for a user (from their first exposure until the end of the experiment) as the metric window. You can read more about Metric Windows on the [Metric documentation page](https://docs.growthbook.io/app/metrics).\n\n*   **Respect Conversion Windows** - This setting ensures that all conversion windows on your metrics are respected.\n*   **Ignore Conversion Windows** - This setting overrides all metrics to be as if they had no conversion windows. Lookback windows will not be overriden by this setting.\n\nFor those familiar with he \"Experiment Duration\" attribution model, choosing \"Ignore Conversion Windows\" will work the same way, and you should know that you can now specify the metric window behavior on a metric-by-metric basis (see the [Metric documentation page](https://docs.growthbook.io/app/metrics)).\n\n### Experiment Metrics[​](#experiment-metrics \"Direct link to Experiment Metrics\")\n\nYou can add metrics as goal metrics, guardrail metrics, or both. You also can add \"Metric Overrides\" which provide experiment-specific controls for metrics, allowing you to override the metric's defaults for, for example, metric windows and risk thresholds.\n\n### Experiment Phases[​](#experiment-phases \"Direct link to Experiment Phases\")\n\nExperiment Phases can help you filter the dates used in the experiment analysis. Be very careful using phases. If you move the start date of the phase to past the start date of the experiment (and users were not re-randomized across phases), then your analysis could suffer from [carryover bias](https://docs.growthbook.io/kb/experiments/carryover-bias). It is best to always look at the full history of an experiment if possible.\n\n### Making Changes While Running[​](#making-changes-while-running \"Direct link to Making Changes While Running\")\n\nRead our dedicated guide on [making changes to running experiments](https://docs.growthbook.io/app/making-experiment-changes).",
    "title": "Experiments (Setup) | GrowthBook Docs",
    "description": "Add and configure your experiments.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/kb/experiments/holdouts",
    "markdown": "# Holdout Experiments in GrowthBook | GrowthBook Docs\n\n## What are holdout experiments?[​](#what-are-holdout-experiments \"Direct link to What are holdout experiments?\")\n\nHoldout experiments (holdouts) are an approach to measuring the long term impact of one feature or a set of features. Essentially, you take some set of users and keep them from seeing new features; you then use them as a control group to measure against some other set of users who are getting all of the features you have launched.\n\nWho uses holdouts?\n\nLarge tech companies often use them to measure both the long-term impact of individual features as well as the general evolution of a product that some team owns. We advocate that everyone uses holdouts at some level, even if only to test the long-term impacts of a single feature every now and then, to begin to understand how they work and what they say about the persistence of experiment effects at your company.\n\nWhy would I want to run a holdout?\n\n*   Holdouts are a great way to measure long-term impact. The impact of features changes over time, as does user behavior, and running an experiment for an extended period can help you understand these effects.\n*   Holdouts can help you measure the impact of multiple features at once. Experiments can interact with each other in unexpected ways and these interactions can change as time goes on.\n\nWhy wouldn't I want to run a holdout?\n\n*   Holdouts require you to keep a certain set of users behind the rest in terms of functionality.\n*   Holdouts require you to maintain feature flags in your codebase for their duration.\n*   Holdouts work best for logged-in experimentation, but can still be useful with anonymous traffic.\n\n## Can I run a holdout experiment in GrowthBook?[​](#can-i-run-a-holdout-experiment-in-growthbook \"Direct link to Can I run a holdout experiment in GrowthBook?\")\n\n**Yes!**\n\nHoldouts are a special class of experiment. While the GrowthBook team plans to build dedicated support for holdouts to make them even easier to run, this document will show you how to run them today.\n\n## How to run a holdout experiment in GrowthBook[​](#how-to-run-a-holdout-experiment-in-growthbook \"Direct link to How to run a holdout experiment in GrowthBook\")\n\n### Background[​](#background \"Direct link to Background\")\n\nFor this tutorial, we will assume the following goals:\n\n*   You want to hold out 5% of users from some time period from seeing a set of features (the 5% is customizable)\n*   You want to measure the impact of launching one or more features to the general population\n\nTo achieve these goals we will essentially split our traffic into 2 groups:\n\n1.  10% of traffic: your **holdout** population, split into two sub-groups\n    1.  A **`holdout control`** group here - 5% of global traffic that will never see new features and serves as our holdout control\n    2.  A **`holdout treatment`** group - 5% of global traffic that sees all new features _but only once they are released, not while they are being experimented/tested._\n2.  Our **`general population`** - 90% of traffic that gets experimented on and released to\n\n### 1\\. Create a Holdout Experiment[​](#1-create-a-holdout-experiment \"Direct link to 1. Create a Holdout Experiment\")\n\n1.  Create an experiment called, for example, ”Global Holdout Q1 2024”.\n2.  **Splits:** Set coverage to 10% and then use a 50/50 split (again to achieve our 10% holdout test population, which you can customize).\n\n![Traffic Splits for an Example Holdout Experiment](https://docs.growthbook.io/images/statistics/holdout-splits.png)\n\n3.  **Metrics:** Likely you do not want to use conversion windows with a holdout experiment. Users are going to get exposed to the holdout experiment as soon as you start testing the feature, so conversion windows may expire before you ever actually expose the **holdout treatment** group to the experiment. There are two solutions:\n    1.  Use your regular metrics and set **Conversion Window Override** to **Ignore Conversion Windows** in your Experiment Analysis settings\n    2.  Use metrics that have no conversion window OR use a Lookback Window to only measure the last X days of the holdout. For example, if you want to run a holdout for 2 months, but only measure effects in the last month, you can use metrics with 30 day Lookback Windows (you can use metric overrides within the experiment to do this, or create versions of your metrics that use Lookback Windows).\n4.  Start the experiment, even though it doesn't have any linked features.\n\n### 2\\. Add Holdout Experiment to All Future Features[​](#2-add-holdout-experiment-to-all-future-features \"Direct link to 2. Add Holdout Experiment to All Future Features\")\n\n1.  Create a feature that you want to add to your holdout. Before testing or launching the feature, add the above Holdout Experiment as an experiment rule ABOVE any feature experiment. This will ensure your holdout population never gets the feature until you choose to release it to them.\n2.  Ensure that the `holdout control` and `holdout feature` group get the **same value** as one another, and that this value is the same as the default/control behavior for your feature test in the `general population`.\n3.  To then test your new feature, add an experiment rule to your feature, where the control is getting the same value as the holdout groups.\n\nSee image below for an example of the state the test feature (here called \"New Checkout Flow\") should be in now:\n\n![Feature Rules for an Example Feature Experiment with Holdout](https://docs.growthbook.io/images/statistics/holdout-rules.png)\n\n### 3\\. Launch Features[​](#3-launch-features \"Direct link to 3. Launch Features\")\n\nOnce you are ready to launch your feature, you have to take two steps:\n\n1.  Release the feature in the `general population` as you would normally. You can do this by enabling “Temporary rollout” in your feature experiment (navigate to the experiment, click “Stop Experiment” and then pick the winning variation with temporary rollout enabled) or by editing the feature experiment rule to roll it out to all users more manually.\n2.  Update the holdout experiment rule manually to roll out the winning variation to the **holdout feature group.** Just update the feature flag value that the **holdout feature** group is getting. Then, you'll be in the state below.\n\n![Feature Rules for an Rolled Out Feature with Holdout](https://docs.growthbook.io/images/statistics/holdout-rollout-rules.png)\n\n### 4\\. Monitor your Holdout Experiment![​](#4-monitor-your-holdout-experiment \"Direct link to 4. Monitor your Holdout Experiment!\")\n\nThat's it! Initially, your holdout population will be seeing the same version of the app, so this experiment will show no differences. As you begin rolling out features, you should begin to see differences in the two groups. At a high-level, here's how this set-up would look for one quarter where you ran three tests and rolled out two features:\n\n![Timeline of an Example Holdout Experiment](https://docs.growthbook.io/images/statistics/holdout-overview.png)\n\nA couple of notes:\n\n*   As you can see that double blue and orange shaded region will serve as the full test of both shipped features together. You may even want to extend the measurement period beyond the quarter (where you don't add any new features) in order to let all features be in the holdout test group for a period.\n*   You'll also note that the `holdout feature` group is only getting features once they are released to everyone. This helps keep the measurement of the impact of the features clean, as you are not measuring the impact of the feature being tested with different settings, but rather the impact of the final feature being released. That said, the alternative is also interesting, where you compare `general population` to your `holdout control` group, but that isn't currently supported in GrowthBook.",
    "title": "Holdout Experiments in GrowthBook | GrowthBook Docs",
    "description": "Holdout Experiments",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/app/metrics",
    "markdown": "# Metrics | GrowthBook Docs\n\nMetrics are what your experiments are trying to improve (or at least not hurt). GrowthBook has a very flexible and powerful way to define metrics.\n\ninfo\n\nThere's a brand new way to define metrics in GrowthBook using **Fact Tables**. [Check out the docs](https://docs.growthbook.io/app/fact-tables)\n\n## Conversion Types[​](#conversion-types \"Direct link to Conversion Types\")\n\nMetrics can have different units and statistical distributions. Below are the ones GrowthBook supports:\n\n| Conversion Type | Description | Example | Default aggregation (SQL) |\n| --- | --- | --- | --- |\n| binomial | A simple yes/no conversion | Created Account | 1/0 per unit |\n| count | Sums conversion values per user | Pages per Visit | `SUM(value)` per unit |\n| duration | How much time something takes | Time on Site | `SUM(value)` per unit |\n| revenue | The revenue gained/lost | Revenue per User | `SUM(value)` per unit |\n\nFor experiment analysis, each of these metric types uses some aggregation (often defaulting to `SUM`) per user and then takes an average with respect to the total number of users. In the case of SQL metrics, the only meaningful difference between count, duration, and revenue is how we render the units in the metric and experiment results pages.\n\nnote\n\nRevenue Metrics are displayed in USD by default. You can change your display currency under **Settings** → **General** → **Metric Settings**\n\n## Query settings[​](#query-settings \"Direct link to Query settings\")\n\nFor metrics to work, you need to tell GrowthBook how to query the data from your data source. There are a few ways to do this depending on your data source.\n\n### 1\\. SQL (recommended)[​](#1-sql-recommended \"Direct link to 1. SQL (recommended)\")\n\nIf your data source supports SQL, this is the preferred way to define metrics. You can use joins, subselects, or anything else supported by your SQL dialect.\n\nYour SELECT statement should return one row per \"conversion event\". This may be a page view, a purchase, a session, or something else. The end result should look like this:\n\n| user\\_id | timestamp | value |\n| --- | --- | --- |\n| 123 | 2021-08-23 12:45:14 | 10  |\n| 456 | 2021-08-23 12:45:15 | 5.25 |\n\nMetrics can support one or more types of identifiers. The above example assumes the metric only supports a single id type called `user_id`, but you would add additional columns if you need to support other ones.\n\n#### Non-binomial metrics[​](#non-binomial-metrics \"Direct link to Non-binomial metrics\")\n\nFor count, revenue, and duration metrics metric types, the value represents the count, duration, or revenue from that single conversion event. In the case of multiple rows for a single user, the values will be summed together or we will use a custom aggregation that you can specify.\n\nTherefore a `count` metric can really be any arbitrary metric whose `value` you want to sum at the user level before taking an average per variation.\n\nIf you use Segment to populate your data warehouse, the SQL for a `Revenue per User` metric might look like this:\n\n```\nSELECT  -- Assuming you support 2 identifier types - 'user_id' and 'anonymous_id'  user_id as user_id,  anon_id as anonymous_id,  received_at as timestamp,  grand_total as valueFROM  purchases\n```\n\nIf you wanted to count the number of conversion rows per user, you can simply set `1 as value` in your SQL query and then the default SUM aggregation will count the number of rows per user.\n\n#### Binomial metrics[​](#binomial-metrics \"Direct link to Binomial metrics\")\n\nBinomial metrics don't need a `value` column (the existence of a row means the user converted). You would only need to return the following columns, representing users and when they \"converted\" on this binomial metric:\n\n| user\\_id | timestamp |\n| --- | --- |\n| 789 | 2022-08-23 12:45:14 |\n| 111 | 2022-08-23 12:45:15 |\n\nWhen we go to conduct experiment analysis, any `user_id` that has a conversion in the appropriate time window will be counted as a `1`, while all other users will be counted as a `0`. Then we can compute the proportion of users in an experiment variation who converted.\n\n#### SQL Templates[​](#sql-templates \"Direct link to SQL Templates\")\n\nWe use {{[Handlebars](https://handlebarsjs.com/guide/#language-features)}} to compile the sql into what is actually called to your database. This allows you to create template metrics that can be copied and reused by changing the variable values associate with the metrics.\n\nYou can use the following user configurable variables within SQL templates:\n\n*   **eventName** - The event name associated with this metric. This can then be referenced in your sql template as `{{eventName}}`. Depending upon how your data is structured you can then incorporate it as part of the table name, if each event has its own table, or as part of a where clause limiting the rows returned to where a certain column equals the eventName.\n*   **valueColumn** - The column in your datawarehouse table with the metric data. This can then be referenced in your sql template as `{{valueColumn}}`. For example you might have `{{valueColumn}} as value` to extract out the value from the table.\n\nYou can also use any of the in-built variables that Growthbook automatically sets:\n\n*   **startDate** - `yyyy-MM-dd HH:mm:ss` of the earliest data that needs to be included\n*   **startDateISO** - `yyyy-MM-dd'T'HH:mm:ss.SSS'Z'` of the startDate in ISO format. This can then be used with the `date` helper to achieve whatever [format](#dateformat) you like (ex. `{{date startDateISO \"yyyyMMdd\"}}`)\n*   **endDate** - `yyyy-MM-dd HH:mm:ss` of the latest data that needs to be included\n*   **endDateISO** - `yyyy-MM-dd'T'HH:mm:ss.SSS'Z'` of the endDate in ISO format. This can then be used with the `date` helper to achieve whatever [format](#dateformat) you like (ex. `{{date endDateISO \"yyyyMMdd\"}}`)\n*   **experimentId** - Either a specific experiment id OR `%` if you should include all experiments\n\nYou can also use any of the in-built helper functions:\n\n*   **camelcase \\[str\\]** - ex. `{{camelcase \"My database\"}}` compiles to `myDatabase`.\n*   **dotcase \\[str\\]** - ex. `{{dotcase \"My database\"}}` compiles to `my.database`.\n*   **kebabcase \\[str\\]** - ex. `{{kebabcase \"My database\"}}` compiles to `my-database`.\n*   **lowercase \\[str\\]** - ex. `{{lowercase \"My database\"}}` compiles to `my database`.\n*   **pascalcase \\[str\\]** - ex. `{{pascalcase \"My database\"}}` compiles to `MyDatabase`.\n*   **replace \\[str\\] \\[pattern\\] \\[replacement\\]** - Replace all occurences of a regular expression with something else. ex. `{{replace \"My%%%Database!\" \"\\[^a-zA-Z\\]\" \"\"}}` compiles to `MyDatabase`\n*   **snakecase \\[str\\]** - ex. `{{pascalcase \"My database\"}}` compiles to `my_database`.\n*   **uppercase \\[str\\]** - ex. `{{uppercase \"My database\"}}` compiles to `MY DATABASE`.\n*   **date \\[date\\] \\[format\\]** - Format an ISO date according to this [format](https://date-fns.org/v2.29.3/docs/format), being careful not to mix up months (MM) and minutes (mm). ex. `{{date startDateISO \"yyyyMMdd\"}}` might compile to `20230130`. The most common codes are:\n\n| code | meaning |\n| --- | --- |\n| yyyy | year |\n| MM  | month |\n| dd  | day |\n| HH  | hour |\n| mm  | minutes |\n| ss  | seconds |\n| t   | timestamp |\n\nFor example you could have the following reusable sql template that could be used for many metrics, with only needing to change the valueColumn and eventName variables that will appear within the UI form:\n\n```\nSELECT  user_id as user_id,  received_at as timestamp,  {{valueColumn}} as valueFROM  database.{{snakecase eventName}}WHERE  received_at BETWEEN '{{ startDate }}' AND '{{ endDate }}'\n```\n\nnote\n\nThe inserted values do not have surrounding quotes, so you must add those yourself (e.g. use `'{{&nbsp;startDate&nbsp;}}'` instead of just `{{&nbsp;startDate&nbsp;}}`\n\n#### Denominator (Ratio / Funnel Metrics)[​](#denominator-ratio--funnel-metrics \"Direct link to Denominator (Ratio / Funnel Metrics)\")\n\nBy default, metrics are evaluated against all users in an experiment: `(# users who converted) / (# users in experiment)`\n\nYou can instead choose another metric to use as the denominator.\n\n##### Funnel Metrics[​](#funnel-metrics \"Direct link to Funnel Metrics\")\n\nWhen the denominator is a simple binomial (conversion) metric, then it acts just like an \"activation metric\" in an experiment. It filters the users who are included in the analysis to those who first convert on this denominator metric.\n\nFor example, if you want to look at what percent of users checkout after viewing a cart, it can be described as `% checkout / % viewed cart`. This requires creating two metrics:\n\n1.  `Viewed Cart` - selects all users who viewed a cart\n2.  `Viewed Cart -> Checkout` - selects all users who checked out and picks `Viewed Cart` as the denominator.\n\n##### Ratio Metrics[​](#ratio-metrics \"Direct link to Ratio Metrics\")\n\nWhen the denominator is a count metric, then things are a little different. Instead of acting like a filter, we calculate both metrics and treat the value as a ratio.\n\n*   The mean is `sum(metric) / sum(denominator)`\n*   The standard deviation is calculated using the **Delta method**\n\nFor example, if you want to look at the Average Order Value (AOV), what you're really looking for is `total revenue / number of orders`. This also requires creating two metrics:\n\n1.  `Orders per User` - selects the count of orders for each user\n2.  `AOV` - selects total revenue per user and picks `Orders per User` as the denominator.\n\n##### Quantile Metrics[​](#quantile-metrics \"Direct link to Quantile Metrics\")\n\n[Quantile Metrics](https://docs.growthbook.io/statistics/quantile) are available only as Fact Tables, as described [here](https://docs.growthbook.io/app/fact-tables).\n\n### 2\\. Javascript (Mixpanel only)[​](#2-javascript-mixpanel-only \"Direct link to 2. Javascript (Mixpanel only)\")\n\nWe query Mixpanel data sources using their proprietary JQL language based on Javascript. This allows for extreme flexibility when defining metrics.\n\nAll metrics at minimum need to specify an **Event Name** which must exactly match what is used in Mixpanel. You can use `OR` to match against multiple events. For example `viewed_cart OR purchased`\n\nYou can optionally add **Conditions** which filters the events further based on properties. For example, if Event Name is `Page view`, you can add a condition `path = \"/blog\"`.\n\nCount, duration, and revenue metrics have two additional steps. We first extract all event values for a user into an array and then reduce that array down to a single number, which is the final metric value for the user.\n\n#### Conditions[​](#conditions \"Direct link to Conditions\")\n\nConditions in Mixpanel are very powerful. They consist of a **Property**, an **Operator**, and a **Value**. Multiple conditions are joined with an AND.\n\nThe **Property** can either be the name of an event property or a javascript expression. Some examples:\n\n*   `amount`, equivalent to `event.properties.amount`\n*   `event.time`\n*   `event.properties.city + \", \" + event.properties.country`\n\nThe **Operator** is one of the following:\n\n*   equals\n*   does not equal\n*   is greater than\n*   is greater than or equal to\n*   is less than\n*   is less than or equal to\n*   matches the regex\n*   does not match the regex\n*   custom javascript\n\nThe `custom javascript` operator is special. The **Value** is a javascript expression that evaluates to either `true` or `false` (access the property value with the `value` variable). It lets you do arbitrarily complex filtering. For example:\n\nFor all other operators, the condition should read like an English sentence. For example:\n\n```\n// property operator valuecountry equals US// Will render asevent.properties.country == \"US\"\n```\n\n#### Event Value[​](#event-value \"Direct link to Event Value\")\n\nFor count, revenue, and duration metrics, we need to know what the \"value\" of the event is.\n\nThe **Event Value** is a Javascript expression to extract a value from a raw Mixpanel event. If you are just extracting a single property as-is, you can just enter the property name as a shortcut. Otherwise, you can reference the `event` variable in your expression.\n\nHere are some example Event Value expressions:\n\n*   `grand_total`, equivalent to `event.properties.grand_total`\n*   `1` (hard-code the value to a specific number)\n*   `(event.properties.endTime - event.properties.startTime) / (60 * 60)` (difference in hours between two unix timestamps)\n*   `new Date(event.time).toISOString().substr(0, 10)` (event timestamp in YYYY-MM-DD format)\n\nFor count metrics, you can leave Event Value blank and it will default to hard-coding the value to `1`, which is perfect for when you just want to count the number of events and don't care about specific properties.\n\n#### User Value Aggregation[​](#user-value-aggregation \"Direct link to User Value Aggregation\")\n\nFor count, revenue, and duration metrics, we need to know how to aggregate the event values together, in case a single user has multiple matching events.\n\nThe **User Value Aggregation** is another Javascript expression that reduces an array of Event Values to a single number (or null if the user did not convert). Reference the variable `values` in your expression. There are a few built-in helper functions:\n\n*   `count(values)`\n*   `countDistinct(values)`\n*   `sum(values)`\n*   `min(values)`\n*   `max(values)`\n*   `avg(values)`\n*   `median(values)`\n*   `percentile(values, p)` (p is a number between `0` and `100`)\n\nYou can use your own custom expression too if you want. For example, this is the equivalent of `sum(values)`:\n\n```\nvalues.reduce((sum, n) => sum + n, 0);\n```\n\nIf the aggregation is left blank, we do `sum(values)` by default.\n\n### 3\\. SQL Query Builder (legacy)[​](#3-sql-query-builder-legacy \"Direct link to 3. SQL Query Builder (legacy)\")\n\nThe query builder prompts you for things such as table/column names and constructs a SQL query behind the scenes.\n\nWe only recommend this for extremely simple metrics. Inputting raw SQL is far more flexible.\n\n## Behavior[​](#behavior \"Direct link to Behavior\")\n\nThe behavior tab lets you tweak how the metric is used in experiments. Depending on the metric type and datasource you chose, some or all of the following will be available:\n\n### What is the Goal?[​](#what-is-the-goal \"Direct link to What is the Goal?\")\n\nFor the vast majority of metrics, the goal is to increase the value. But for some metrics like \"Bounce Rate\" and \"Page Load Time\", lower is actually better.\n\nSetting this to \"decrease\" basically inverts the \"Chance to Beat Control\" value in experiment results so that \"beating\" the control means decreasing the value. This will also reverse the red and green coloring on graphs.\n\n### Capped Value[​](#capped-value \"Direct link to Capped Value\")\n\nLarge outliers can have an outsized effect on experiment results. For example, if your normal revenue per user $40 and someone happens to make a $5000 order, whatever variation that person is in will be much more likely \"win\" any experiment because that one order is an outlier.\n\nCapping (also known as winsorization) works by ensuring that all aggregate unit (e.g. user) values are no more than some value. So in the above example, if the cap was $100, the $5000 purchase will still be counted, but the aggregated value for that user will be capped at $100 and will have a much smaller effect on the results. It will still give a boost to whatever variation the person is in, but it won't completely dominate all of the other orders and is unlikely to make a winner just on its own. Another way to think about this is that you are slightly biasing your results by truncating large values, but you are reducing variance to prevent the outsized effect of outliers.\n\nThere are two ways to cap metric values in GrowthBook:\n\n**1\\. Absolute capping** - if set above zero, all aggregated user values will be capped at exactly this value. For example, if the cap is $100 on total revenue per user, then after we sum all of a users orders up, any user with an aggregate sum of greater than $100 will be set to $100.\n\n**2\\. Percentile capping** - when this is set to between 0 and 1, it uses that percentile to select a cap based on the data in your experiment so far. This cap is therefore specific to each experiment and specific to each analysis run in that experiment if new data has come in. It works like so: after we calculate the unit-level aggregate values for all units (e.g. users) during an experiment analysis, we find the specified percentile of these unit-level aggregates and then cap these aggregated values at this percentile. Using the above example, if you were to specify percentile capping with a value of `0.95`, then we find the 95th percentile of total revenue per users (say this turns out to be $135). We then cap those user-level aggregates at $135.\n\nYou can additionally choose to ignore zeros, which will compute the percentile without including any user aggregated zero values. This is useful if you have a lot of zero values and you don't want to have to fine tune the percentile to avoid setting the cap too low.\n\nBecause the percentile cap depends on the data in your experiment, it can be different from experiment to experiment, or even analysis to analysis. To find out what value was actually used for capping you can do the following: on the Experiment Results tab, click the three dot menu in the top right and select \"View Queries\". Each percentile capped metric will have a column with the `main_cap_value` that was used to cap that metric and represents the computed percentile of unit-level aggregate values.\n\n### Metric Windows[​](#metric-windows \"Direct link to Metric Windows\")\n\nWhen used in an experiment, we only consider rows of a Metric where the timestamp is greater than or equal to the first time the user was exposed to the experiment. In other words, if someone purchases something before seeing your experiment, it won't be included in the analysis. This behavior is ideal for the vast majority of metrics, but you can change it with the Metric Delay setting if desired (see below).\n\nThere are three window settings one can use to configure the metric date window. Each of them defines the lower and upper date range of the metric to use for each user:\n\n*   **None** (default)\n    *   Lower bound: user's first exposure plus the metric delay\n    *   Upper bound: experiment end date\n*   **Conversion Window**\n    *   Lower bound: user's first exposure plus the metric delay\n    *   Upper bound: the lower bound + the length of the conversion window\n*   **Lookback Window**\n    *   Lower bound: the experiment end date minus the lookback window OR the user's first exposure plus the metric delay, whichever is later\n    *   Upper bound: experiment end date\n\nHere's a graphical representation of these three window types for a hypothetical User 1: ![Metric Windows](https://docs.growthbook.io/assets/images/metric-windows-024e6a7e756c8cd43f0d35ee221cc089.png)\n\nHere's a second example for a hypothetical User 2, who joins the experiment late. Notice that the conversion window can extend beyond the experiment end date.\n\n![Metric Windows (User 2)](https://docs.growthbook.io/assets/images/metric-windows-user-2-dac5ae6d7345e2211ec13dd5f8869954.png)\n\nWhy might you choose one window over another?\n\n**None** - The simplest. Use all data available. This is useful for using as much data associated with users in your experiment and will combine any behavior that is right after experiment exposure as well as long run behavior within the experiment time frame.\n\n**Conversion window** - Conversion windows allow you to only look at events that are tied to the first exposure to an experiment. This can help if, for example, you are tracking purchases and you only want to measure the effect of an experiment in a checkout flow on purchases made soon after seeing that checkout flow. Using a conversion window can reduce the noise from user behavior not related to an experiment. However, if you set the window too short, you may not capture users that return a few days later and were influenced by the experiment.\n\n**Lookback window** - Lookback windows are good for capturing long run impacts of an experiment on regular behavior like user log ins or page views. They have two main advantages:\n\n(1) You can mitigate the novelty effect of an experiment; if you are testing a new recommendation algorithm, at first users may react a certain way to the experiment, but eventually they may adjust and so may their behavior. In these cases, you may just want to look at the last 14 days of an experiment.\n\n(2) Lookback windows help you focus on the long run effects of an experiment. Much of experimentation is about building a better product; by focusing on impact of an experiment after it has been live for a week or two, you may get a better picture of the long run impact of launching the experiment.\n\nLarger companies who measure long run logged in behavior want to ensure their experiments have lasting effects and often rely on lookback windows to make shipping decisions However, lookback windows may not be right if you are testing a feature on logged-out or anonymous users and are measuring simple purchase conversions or something similar. In these cases, you might end up with many logged-out users who, in the long run, simply have no metric data associated with them.\n\n### Metric Delay[​](#metric-delay \"Direct link to Metric Delay\")\n\nConversions within the first X hours of being put into an experiment are ignored (default = `0`). This is useful for metrics like \"day 2 retention\". In that case, if your underlying table reports whether a user is retained on any given day, you could set a metric delay to `24` hours.\n\n#### Negative metric delays[​](#negative-metric-delays \"Direct link to Negative metric delays\")\n\nThe metric delay can also be negative to include some conversions **before** a user is put into an experiment. For example, a value of `-2` would mean conversions up to 2 hours before will be included. You might be wondering when this would ever be useful.\n\nImagine the average person stays on your site for 60 seconds and your experiment can trigger at any time.\n\nIf you just look at the average time spent after the experiment, the numbers will lose a lot of meaning. A value of `20 seconds` might be horrible if it happened to someone after only 5 seconds on your site since they are staying a lot less time than average. But, that same `20 seconds` might be great if it happened to someone after 55 seconds since their visit is a lot longer than usual. Over time, these things will average out and you can eventually see patterns, but you need an enormous amount of data to get to that point.\n\nIf you set the metric delay to something negative, say `-0.5` (30 minutes), you can reduce the amount of data you need to see patterns. For example, you may see your average go from 60 seconds to 65 seconds.\n\nKeep in mind, these two things are answering slightly different questions. `How much longer do people stay after viewing the experiment?` vs `How much longer is an average session that includes the experiment?`. The first question is more direct and often a more strict test of your hypothesis, but it may not be worth the extra running time.\n\n### Bayesian Priors[​](#bayesian-priors \"Direct link to Bayesian Priors\")\n\nYour organization can set default priors for Bayesian analyses that are used by all metrics.\n\nHowever, you can also set metric specific priors by opening the Edit Metric modal from the Metric page, clicking on Advanced Settings, and turning on the metric override. This will allow you to set a custom prior for that metric.\n\nAdditionally, you can use experiment metric overrides to further customize these priors for each experiment.\n\nYou can read more about Bayesian priors on [our statistical details page](https://docs.growthbook.io/statistics/details).\n\n## Auto Generate Metrics[​](#auto-generate-metrics \"Direct link to Auto Generate Metrics\")\n\nWhen using GrowthBook with certain event trackers, we may be able to generate metrics for you automatically by identifying the unique events tracked by your event tracker. This is currently only supported for a few event trackers (listed below), but we are working to expand this list.\n\nIf you are using one of the supported event trackers and would like to see what metrics we can create for you, head to the `Metrics` page in GrowthBook and select the `Discover Metrics` button.\n\nnote\n\nWhen querying your datasource to identify unique events, we're currently only looking at events in the last 7 days.\n\n### Supported Event Trackers[​](#supported-event-trackers \"Direct link to Supported Event Trackers\")\n\n*   Segment\n*   Rudderstack\n*   Google Analytics 4 (GA4)\n\n## Examples[​](#examples \"Direct link to Examples\")\n\nLet's walk through some examples of creating binomial, count, and retention metrics with GrowthBook. For all of the metrics below, let's pretend we have some table called `events`, which has one row per event tracked to your warehouse. For each row we have the following columns:\n\n*   `user_id` - the id of the user\n*   `timestamp` - the time the event was counted\n*   `event_name` - the name of the event, we'll focus on 'purchase' as a key event types\n*   `value` - the total value of the event, in this case the total value of a purchase\n\nFrom this table, we can build many different metrics:\n\n| Name | Metric Type | SQL | Aggregation | Denominator | Metric Delay | Metric Window |\n| --- | --- | --- | --- | --- | --- | --- |\n| Any Purchase | Binomial | SELECT user\\_id, timestamp FROM events WHERE event\\_name = 'purchase' | n/a |     | 0   |     |\n| Number of Purchases | Count | SELECT user\\_id, timestamp, 1 as value FROM events WHERE event\\_name = 'purchase' | default (SUM) |     | 0   |     |\n| Order Value | Revenue | SELECT user\\_id, timestamp, value FROM events WHERE event\\_name = 'purchase' | default (SUM) |     | 0   |     |\n| Average Order Value | Revenue (ratio) | SELECT user\\_id, timestamp, value FROM events WHERE event\\_name = 'purchase' | default (SUM) | Number of Purchases | 0   |     |\n| 7-Day Retention | Binomial | SELECT user\\_id, timestamp FROM events | n/a |     | 24\\*7=144 hours |     |\n| Active User Last 14d | Binomial | SELECT user\\_id, timestamp FROM events | n/a |     | 0   | Lookback - 14 day |\n\nIf you wanted to only count purchases and purchase values made in the 72 hours after a user's first exposure to an experiment, then you could set the metric window to a conversion window of 72 hours. If you wanted to just count any user who made a purchase any time after experiment exposure, then set the metric window to none.",
    "title": "Metrics | GrowthBook Docs",
    "description": "Learn about defining the metrics you will use in your A/B test results",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/statistics/overview",
    "markdown": "# GrowthBook Statistics | GrowthBook Docs\n\nGrowthBook provides both Bayesian and frequentist approaches to experiment analysis. We default to Bayesian statistics because they provide a more intuitive framework for decision making for most customers, but we provide ample tools to select between both approaches based on your experimentation needs. You can choose between the two statistics engines at the Organization or Project level.\n\n## Bayesian Statistics[​](#bayesian-statistics \"Direct link to Bayesian Statistics\")\n\nBayesian methods provides a few key advantages over frequentist approaches.\n\nFirst, they provide more intuitive results. Instead of p-values and confidence intervals, you get probabilities and distributions of likely outcomes. These values allow you to make statements like _\"there’s a 95% chance this new button is better and a 5% chance it’s worse\"_ while there is no direct analog in a frequentist framework.\n\nSecond, Bayesian methods allow you to write down your prior knowledge about experiment effects to ensure that you do not over-interpret small sample sizes and to benefit from old knowledge to reduce uncertainty in new experiments.\n\nThird, Bayesian results are still valid even if you stop an experiment early. While they can suffer from the same \"peeking\" problems as frequentist statistics, at least the main probabilities and statistical results that you see are not invalidated by stopping early. However, this is something of a difference without a distinction, as the decision to stop an experiment early can still result in inflated false positive rates.\n\nHowever, they can require a bit more fine-tuning to get right; however, in GrowthBook both engines are very similar under the hood so picking one can come largely down to personal preference and familiarity. In fact, tools like CUPED are available for both engines.\n\n### Priors and Posteriors[​](#priors-and-posteriors \"Direct link to Priors and Posteriors\")\n\nAt GrowthBook, we default to an improper, uninformative prior. This means that we do not use prior information to impact your experiment results by default. We do this to ensure that people who want to use the Bayesian engine to the fullest are able to enable proper priors and reap their benefits, but without automatically affecting results when experimenters first begin experimenting with GrowthBook.\n\nA prior works by providing additional information to your analysis for what kinds of results are likely based on past evidence. Our statistics engine will combine it with the actual results from your experiment to come up with our final distribution (our \"posterior\"). This represents the most likely outcomes of your experiment combining prior knowledge and the experiment data. Priors can be very helpful in reducing uncertainty in small sample sizes and in ensuring that you do not over-interpret results that are unlikely to be reliable.\n\nYou can easily turn on proper priors by visiting the organization settings, going to the Bayesian engine settings, and turning on the \"Proper Prior\". By default, we use a Normal distribution with mean 0 and standard deviation 0.3. This prior implies that about 68% of effects are between -30% and 30%, 95% of effects are between -60% and 60%, and the average effect is 0%. In effect, it will shrink positive and negative results towards 0, but eventually will be overcome as more data is collected.\n\nThe choice of 0 and 0.3 corresponds roughly to the distribution of effects that we have actually observed on GrowthBook and is both:\n\n1.  Weak enough to not shrink experiments with large sample sizes\n2.  Strong enough to ensure that experiments with small sample sizes are not over-interpreted\n\nYou can read more about how we use the prior and your experiment data to produce experiment results in our [detailed documentation](https://docs.growthbook.io/statistics/details).\n\n### Inferential Statistics[​](#inferential-statistics \"Direct link to Inferential Statistics\")\n\nGrowthBook uses fast estimation techniques to quickly generate inferential statistics at scale for every metric in an experiment - Chance to Win, Relative Uplift, and Risk (or expected loss).\n\n**Chance to Win** is straight forward. It is simply the probability that a variation is better. You typically want to wait until this reaches 95% (or 5% if it's worse).\n\n**Relative Uplift** is similar to a frequentist Confidence Interval. Instead of showing a fixed 95% interval, we show the full probability distribution using a violin plot:\n\n![Violin plot of a metrics change](data:image/png;base64,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)\n\nWe have found this tends to lead to more accurate interpretations. For example, instead of just reading the above as _\"it’s 17% better\"_, people tend to factor in the error bars (_\"it’s about 17% better, but there’s a lot of uncertainty still\"_).\n\n**Risk** (or expected loss) can be interpreted as _“If I stop the test now and choose X and it’s actually worse, how much am I expected to lose?”_. This is shown as a relative percent change - so if your baseline metric value is $5/user, a 10% risk equates to losing $0.50/user. You can specify your risk tolerance thresholds on a per-metric basis within GrowthBook.\n\nGrowthBook gives the human decision maker everything they need to weigh the results against external factors to determine when to stop an experiment and which variation to declare the winner.\n\n## Frequentist Statistics[​](#frequentist-statistics \"Direct link to Frequentist Statistics\")\n\nFrequentist statistics are are familiar to many practitioners, power much of our statistics engine, and have certain advantages. Their widespread adoption has spurred important developments in variance reduction, heterogeneous treatment effect detection, and indeed corrections to peeking issues (e.g. sequential testing) that make frequentist statistics less problematic and, at times, more valuable.\n\nThe current frequentist engine computes two-sample t-tests for relative percent change; you can reduce variance (via [CUPED](https://docs.growthbook.io/statistics/cuped)) and you can enable [sequential testing](https://docs.growthbook.io/statistics/sequential) to mitigate concerns with peeking.\n\nYou can read more in our [detailed documentation](https://docs.growthbook.io/statistics/details).\n\n## Data Quality Checks[​](#data-quality-checks \"Direct link to Data Quality Checks\")\n\nIn addition, GrowthBook performs automatic data quality checks to ensure the statistical inferences are valid and ready for interpretation. We currently run a number of checks and plan to add even more in the future.\n\n1.  **Sample Ratio Mismatch** (SRM) detects when the traffic split doesn't match what you are expecting (e.g. a 48/52 split when you expect it to be 50/50)\n2.  **Multiple Exposures** which alerts you if too many users were exposed to multiple variations of a single experiment (e.g. someone saw both A and B)\n3.  **Guardrail Metrics** help ensure an experiment isn't inadvertently hurting core metrics like error rate or page load time\n4.  **Minimum Data Thresholds** so you aren't drawing conclusions too early (e.g. when it's 5 vs 2 conversions)\n5.  **Variation Id Mismatch** which can detect missing or improperly-tagged rows in your data warehouse\n6.  **Suspicious Uplift Detection** which alerts you when a metric changes by too much in a single experiment, indicating a likely bug\n\nMany of these checks are customizeable at a per-metric level. So you can, for example, have stricter quality checks for revenue than you have for less important metrics.\n\n## Dimensional Analysis[​](#dimensional-analysis \"Direct link to Dimensional Analysis\")\n\nThere is often a desire to drill down into results to see how segments or dimensions of your users were affected by an A/B test variation. This is especially useful for finding bugs (e.g. if Safari is down, but the other browsers are up) and for identifying ideas for follow-up experiments (e.g. \"European countries seem to be responding really well to this test, let's try a dedicated variation for them\").\n\nHowever, too much slicing and dicing of data can lead to what is known as the Multiple Testing Problem. If you look at the data in enough ways, one of them will look significant just by random chance.\n\nGrowthBook only provides multiple testing corrections for the frequentist engine, but we have a few guardrails at the metric level to ensure that results are only shown when there's at least enough data to reliably learn about a specific dimension.\n\nIn addition, we apply automatic grouping to very high-cardinality dimensions. In the country example, only the top 20 countries will be shown individually. The rest will be lumped together into an `(other)` category.\n\nWe have found this to be a good trade-off between false positives and false negatives.\n\n## Conclusion[​](#conclusion \"Direct link to Conclusion\")\n\nGrowthBook utilizes a combination of Bayesian and frequentist statistics, fast estimation techniques, and data quality checks to robustly analyze A/B tests at scale and provide intuitive results to decision makers. The implementation is fully open source under an MIT license and available on GitHub.",
    "title": "GrowthBook Statistics | GrowthBook Docs",
    "description": "GrowthBook Statistics",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/features/targeting",
    "markdown": "# Feature Flag Targeting | GrowthBook Docs\n\nGrowthBook lets you target a specific feature value or experiment to a subset of your users. This is accomplished with **Attributes**, **Conditions**, **Saved Groups**, and **Prerequisites**.\n\n## Attributes[​](#attributes \"Direct link to Attributes\")\n\nIn order for targeting to work, you must pass attributes into the GrowthBook SDK and also list them in the GrowthBook App.\n\nAttributes are passed into your SDKs as key-value pairs. The keys you use are completely custom and there are no requirements or restrictions. Use whatever makes sense for your application.\n\nHere's an example from our JavaScript SDK:\n\n```\ngrowthbook.setAttributes({  id: \"123\",  email: \"hello@growthbook.io\",  country: \"US\",  url: window.location.href,  userAgent: navigator.userAgent,  admin: true,  age: 50,});\n```\n\nIn addition to passing attributes into the SDK, you also must update the GrowthBook App with these same attribute keys. You can do this under **SDK Connections** → **Attributes**:\n\n![List of targeting attributes](https://docs.growthbook.io/assets/images/edit-targeting-attributes-47e2000d60f8e83e2fcc4a5fafc0236f.png)\n\nnote\n\nThe actual values of the targeting attributes (e.g. the user ids, emails, etc.) are never sent to GrowthBook. They are only stored in memory locally within the SDK. This architecture eliminates huge potential security holes and keeps your user's PII safe and secure.\n\nEach attribute has 4 parts:\n\n*   The **attribute name** itself. This is how the attribute will be referenced in the SDK.\n*   The **data type** of the attribute\n*   Whether it's an **identifier**. Identifiers are attributes which uniquely identify something - typically either a person, account, company, or device- and are used for experiment assignments.\n*   The **projects** that the attribute is associated with. This is useful if some attributes are only relevant to certain projects. If no projects are selected, the attribute will be available for all projects.\n\n### Attribute Data Types[​](#attribute-data-types \"Direct link to Attribute Data Types\")\n\nGrowthBook supports the following attribute data types:\n\n*   Boolean - true or false\n*   Number - Floats or integers\n*   String - freeform text\n*   Enum - When there are only a small list of pre-defined values it could take\n*   Secure String - Like a string, but the values will be hashed before passing to the SDK\n*   Array of Strings - useful for things like \"tags\"\n*   Array of Numbers - useful anytime you have multiple numeric values\n*   Array of Secure Strings - an array of secure strings useful for passing multiple values that you want to keep secure\n\n#### Semantic Version Targeting[​](#semantic-version-targeting \"Direct link to Semantic Version Targeting\")\n\nIn version 2.2, we introduced support for semantic version string comparisons. Without this, the string `1.0.9` will be seen as \"greater\" than `1.0.10`.\n\nTo leverage this feature, you first need to create a version string attribute. Navigate to **SDK Configurations → Attributes** and create or edit a String attribute. In the format dropdown, select: **Version string.**\n\n![Version string attribute](https://docs.growthbook.io/assets/images/targeting-semantic-versions-6b2b834c4e5b39d79b78fea4dff27686.png)\n\nAfter saving, the targeting operators (e.g. `is greater than`) will automatically start using a version-safe comparison function.\n\nnote\n\nThis is only supported in some of our SDKs. Check the release notes for the specific SDK you are using to make sure you have a compatible version installed.\n\n## Targeting Conditions[​](#targeting-conditions \"Direct link to Targeting Conditions\")\n\nGrowthBook provides a nice UI for defining simple targeting conditions using your attributes.\n\n![Simple targeting conditions](https://docs.growthbook.io/assets/images/targeting-simple-f5410567050c007d1838f8522d3e120c.png)\n\n### Advanced Mode[​](#advanced-mode \"Direct link to Advanced Mode\")\n\nIf you need support for something more advanced you can enter targeting conditions with JSON instead by clicking the \"Advanced Mode\" link.\n\nThe JSON structure is inspired by the MongoDB Query syntax. Multiple conditions are always joined with `AND` (except when explicitly using `$or`/`$nor`). Below are all of the supported operators with examples.\n\n*   Key/value pairs for simple equality\n    \n    ```\n    {  \"attribute1\": \"value1\",  \"attribute2\": 123,  \"attribute3\": false}\n    ```\n    \n*   Basic comparison operators for string/number attributes\n    \n    *   `$eq` (equals)\n    *   `$ne` (not equals)\n    *   `$lt` (less than)\n    *   `$lte` (less than or equal to)\n    *   `$gt` (greater than)\n    *   `$gte` (greater than or equal to)\n    *   `$regex` (regular expression match, string attributes only)\n    *   `$in` (in array)\n    *   `$nin` (not in array)\n    \n    ```\n    {  \"foo\": {    \"$gt\": 10,    \"$lte\": 99  },  \"bar\": {    \"$in\": [\"a\",\"b\",\"c\"]  },  \"baz\": {    \"$regex\": \"^test-([0-9]+)$\"  }}\n    ```\n    \n*   Comparison operators for semantic version strings (semver):\n    \n    *   `$veq` (equals)\n    *   `$vne` (not equals)\n    *   `$vlt` (less than)\n    *   `$vlte` (less than or equal to)\n    *   `$vgt` (greater than)\n    *   `$vgte` (greater than or equal to)\n    \n    ```\n    {  \"appVersion\": {    \"$vgt\": \"1.5.6\",    \"$vlte\": \"5.4.0\"  }}\n    ```\n    \n*   Operators for array attributes\n    \n    *   `$elemMatch` (at least one element must match the specified condition)\n    *   `$all` (all of the specified values must exist in the array)\n    *   `$size` (array length must match the specified condition)\n    \n    ```\n    {  \"emails\": {    \"$elemMatch\": {      \"$regex\": \"@gmail.com$\"    }  },  \"hobies\": {    \"$all\": [\"hiking\",\"tennis\",\"chess\"]  },  \"tags\": {    \"$size\": {      \"$gt\": 5    }  }}\n    ```\n    \n*   Misc operators\n    \n    *   `$exists` (tests if the attribute value is null or not)\n    *   `$type` (tests if the attribute's type matches the type specified)\n    *   `$not` (inverts a nested condition)\n    \n    ```\n    {  \"alternateEmail\": {    \"$exists\": true  },  \"foo\": {    \"$type\": \"string\"  },  \"name\": {    \"$not\": {      \"$regex\": \"^J\"    }  }}\n    ```\n    \n*   Logical operators with arbitrary nesting levels\n    \n    *   `$or`\n    *   `$nor`\n    *   `$and`\n    *   `$not`\n    \n    ```\n    {  \"$or\": [    {      \"$not\": {        \"foo\": \"abc\"      }    },    {      \"$and\": [        {\"bar\": true},        {\"baz\": 123}      ]    }  ]}\n    ```\n    \n\nnote\n\nWe use the MongoDB query syntax because it is easy to read and write and is well documented. The conditions are never actually executed against a database. Instead, our SDKs include a light-weight interpreter for this syntax that runs entirely locally.\n\n## Saved Groups[​](#saved-groups \"Direct link to Saved Groups\")\n\nIn addition to targeting by attributes, GrowthBook has also the concept of **Saved Groups**, which makes it easy to target the same group of users across multiple features/experiments.\n\nOnce you define your Saved Groups, you can easily reference them from any Feature rule or Experiment. Updates to saved groups apply immediately and will be instantly propagated to all matching Features and Experiments.\n\n![Saved Group Targeting](https://docs.growthbook.io/assets/images/saved-groups-targeting-6dd14aaec48817bef6fed2cb50df0562.png)\n\nThere are two types of Saved Groups:\n\n*   **ID Lists** - Pick an attribute and define a list of values directly within the GrowthBook UI. For example, you can make an `Admin` group and add the `userId` of all of your admins.\n*   **Condition Groups** - Configure advanced targeting rules based on a user's attributes. For example, \"all users located in the US on a mobile device\".\n\nnote\n\nID Lists are currently limited to a maximum of **100 values**. These values are included directly in the payload sent to your SDKs and large payloads can slow down your application. Support for largers lists is coming soon!\n\n![Saved Groups UI](https://docs.growthbook.io/assets/images/saved-groups-5051a7b6ca99b952e0bfc3c18e957434.png)\n\nnote\n\nGrowthBook 2.7 introduced a naming change. \"Inline Groups\" were renamed to \"ID Lists\". \"Runtime Groups\" were renamed to \"Condition Groups\" and now support arbitrary targeting conditions.\n\nOnly ID Lists can be referenced in the **Target by Attribute** field. Both types of Saved Groups can be referenced with the newer **Saved Group Targeting** field.\n\n## Prerequisite Targeting[​](#prerequisite-targeting \"Direct link to Prerequisite Targeting\")\n\nYou can add prerequisite targeting to any feature or experiment. For more information, see the [Prerequisite Features](https://docs.growthbook.io/features/prerequisites#inline-prerequisite-targeting) page.",
    "title": "Feature Flag Targeting | GrowthBook Docs",
    "description": "Learn about how to target with GrowthBook",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/app/dimensions",
    "markdown": "# Dimensions | GrowthBook Docs\n\nDimensions let you drill down into experiment results. For example, if you define a `browser` dimension, you can see how Safari users behaved vs Chrome.\n\nBe careful, the more dimensions and metrics you look at for an experiment, the more likely you are to see false positives - something that looks significant when it really isn't. For example, if you break out results by country, it's pretty likely that at least one of the 100+ countries in your dataset will be significantly different just by random chance.\n\nIt's best to treat dimensions as an exploratory tool and not something to directly draw conclusions from. The two best use cases are identfying bugs (the `browser` example) and getting ideas for dedicated follow-up experiments.\n\nDimensions are supported for both Mixpanel and SQL data sources.\n\n## SQL[​](#sql \"Direct link to SQL\")\n\nThere are two types of dimensions for SQL data sources: Experiment Dimensions and User Dimensions. Experiment dimensions are more reliable for producing unbiased experiment analyses because we can always know the dimension that is associated with the first experiment exposure for a unit. Using dimension data that could be affected by the experiment (e.g. that is collected _after_ the first experiment exposure) could bias dimension drill-downs. Therefore, use user dimensions with caution, and we suggest using immutable dimensions as your user dimensions (e.g. the first client the user ever used, or the first country the user ever logged in from).\n\nFor all experiment analyses, we only ever choose one dimension per user, to avoid the aforementioned issues with potential bias. For Experiment Dimensions, we select the dimension associated with the user's first exposure event for the experiment. For User Dimensions, we strongly suggest only having one dimension value per user, as we cannot discern what dimension a user had before the experiment. Instead, we simply choose the `MAX(value)` for the user dimension.\n\n### Experiment Dimensions[​](#experiment-dimensions \"Direct link to Experiment Dimensions\")\n\nThese are attributes that are specific to the point-in-time that a user was put into an experiment. For example, `browser` or `referrer`.\n\nInstead of a standalone SQL query, experiment dimensions are simply extra columns you return from the Experiment assignment query defined for your data source.\n\nAs an example, if you set the following as your experiment assignment query:\n\n```\nSELECT  user_id,  received_at as timestamp,  experiment_id,  variation_id,  browserFROM  experiment_viewed\n```\n\nThe first 4 columns are standard, but `browser` is a custom one that can be used as an Experiment Dimension.\n\n#### Configuring Experiment Dimensions[​](#configuring-experiment-dimensions \"Direct link to Configuring Experiment Dimensions\")\n\nTo power the health tab and future automatic dimension results analysis (coming in 2024), you need to configure your Experiment Dimensions. You can do this by clicking the \"Configure Dimensions\" button in the kebab menu next to the exposure query where the Experiment Dimensions are defined:\n\n![Configure Dimensions Option](https://docs.growthbook.io/images/configure-dimensions.png)\n\nIn the modal that pops up, you can run a query to find the top 20 dimension slices for your Experiment Dimensions and save them for use on the health tab.\n\nIf you want to have more control over the pre-defined slices, the best way to do so is to modify the Exposure Query SQL to include a `CASE` statement that defines the dimension slices. For example, if you wanted to have a `browser` dimension with slices for `Chrome`, `Safari`, and `Other`, you could do something like this:\n\n```\nSELECT  user_id,  received_at as timestamp,  experiment_id,  variation_id,  CASE    WHEN browser LIKE '%Chrome%' THEN 'Chrome'    WHEN browser LIKE '%Safari%' THEN 'Safari'    ELSE 'Other'  END as browserFROM  experiment_viewed\n```\n\n### User Dimensions[​](#user-dimensions \"Direct link to User Dimensions\")\n\nThese are attributes of your users that are relatively stable over time, and ideally, do not change over the course of an experiment. For example, `cohort`, `initial age group`, or `first client used`.\n\nA user dimension is defined by a simple SQL query that returns two columns: an identifier and `value`. The name of the identifier column depends on which identifier type the dimension is using. Remember, when using these for analysis, we will pick the `MAX(value)` for each user, and therefore it is best to only have one value per user.\n\nHere's an example SQL:\n\n```\n-- Assumes identifier type is \"user_id\"SELECT  user_id,  plan_type as valueFROM  subscriptions\n```\n\nIt's best to keep the number of unique values for a dimension small if possible to avoid the False Positive issues discussed above. We automatically cap the number at 20, but you can do it yourself if you want more control. Here's an example for a \"country\" dimension:\n\n```\nSELECT  user_id,  (    CASE WHEN country = 'us' THEN 'US'    WHEN country = 'uk' THEN 'UK'    ELSE 'Other' END  ) as valueFROM  users\n```\n\ntip\n\nYou can use SQL template variables in dimension queries just like you can with metrics (excluding metric specific template variables like `eventName` and `valueColumn`). See the [SQL Template Variables](https://docs.growthbook.io/app/metrics#sql-templates) page for more details.\n\n## Mixpanel[​](#mixpanel \"Direct link to Mixpanel\")\n\nFor mixpanel, there is just a single type of dimension that is based on event properties (at this time Mixpanel user properties are not supported).\n\nFor simple dimensions, you can just put the event property name directly. For example: `$browser`.\n\nWe also support complex javascript expressions. For example:\n\n```\nevent.properties.$browser.match(/chrome/i) ? \"Chrome\" : \"Other\"\n```\n\nFor more complex expressions, you can wrap your code in an anonymous function:\n\n```\n(() => {  // ...some complex logic  return dimensionValue})()\n```\n\nYou can also reference the experiment start/end date in your javascript expression. For example, if you add a super event called `userRegistrationDate` that stores a unix timestamp, you could make a `New vs Existing` dimension like this:\n\n```\nevent.properties.userRegistrationDate >= {{ startDateUnix }} ? \"new\" : \"existing\"\n```\n\nThe variables you can reference are:\n\n*   **startDate** - `YYYY-MM-DD HH:mm:ss` of the earliest data that needs to be included\n*   **startYear** - Just the `YYYY` of the startDate\n*   **startMonth** - Just the `MM` of the startDate\n*   **startDay** - Just the `DD` of the startDate\n*   **startDateUnix** - Unix timestamp of the startDate (seconds since Jan 1, 1970)\n*   **endDate** - `YYYY-MM-DD HH:mm:ss` of the latest data that needs to be included\n*   **endYear** - Just the `YYYY` of the endDate\n*   **endMonth** - Just the `MM` of the endDate\n*   **endDay** - Just the `DD` of the endDate\n*   **endDateUnix** - Unix timestamp of the endDate (seconds since Jan 1, 1970)\n*   **experimentId** - Either a specific experiment id OR `%` if you should include all experiments",
    "title": "Dimensions | GrowthBook Docs",
    "description": "Drill down into experiment results",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/features/rules",
    "markdown": "# Feature Flag Override Rules | GrowthBook Docs\n\n## Rules (Force, Rollout, Experimentation)\n\nEvery feature has a default value that is served to all users. The real power comes when you define **override rules** that let you run experiments and/or change the value for specific users.\n\n![Feature override rules UI](https://docs.growthbook.io/images/features/feature-override-rules.png)\n\nOverride rules are defined separately for each environment (e.g. dev and production). This way you can, for example, test an experiment rule in dev first before deploying it to production.\n\nThe first matching rule for a user will be applied, so order matters. If there are no matching rules, the default value will be used.\n\n## Targeting Conditions[​](#targeting-conditions \"Direct link to Targeting Conditions\")\n\nAny rule can specify conditions to limit which users the rule applies to. These conditions are evaluated against the attributes passed into the SDK.\n\nLearn more about [targeting here](https://docs.growthbook.io/features/targeting).\n\n![Rule conditions UI](https://docs.growthbook.io/assets/images/rule-conditions-08cff979d8c5b2b4534d1c73bb137cf7.png)\n\n## Forced Value[​](#forced-value \"Direct link to Forced Value\")\n\nThe simplest type of override rule is a \"Forced Value\" rule. This forces everyone who matches the targeting condition to get a specific value. For example, you could have a feature default to OFF and use force rules to turn it ON for a specific list of countries.\n\n![Force rule UI](https://docs.growthbook.io/images/features/feature-force-rule.png)\n\n## Percentage Rollout[​](#percentage-rollout \"Direct link to Percentage Rollout\")\n\nPercentage Rollout rules let you gradually release a feature value to a random sample of your users.\n\n![Rollout rule UI](https://docs.growthbook.io/images/features/feature-rollout-rule.png)\n\nRollouts are most useful when you want to make sure a new feature doesn't break your app or site. You start by releasing to maybe 10% of users. Then after a while if your metrics look ok, you increase to 30% and so on.\n\nFor rollout rules, you choose a user attribute to use for the random sample. Users with the same attribute value will be treated the same (either included or not included in the rollout). For example, if you choose a \"company\" attribute, then multiple employees in the same company will get the same experience.\n\nnote\n\nPercentage Rollouts do not fire any tracking calls so there's no way to precisely correlate the rollout to changes in your application's metrics. If this is a concern, we recommend Experiment rules (below) instead.\n\n## Experiments[​](#experiments \"Direct link to Experiments\")\n\nThe last type of rule is an Experiment. This randomly splits users into buckets, assigns them different values, and tracks that assignment in your data warehouse or analytics tool.\n\nExperiments are most useful when you aren't sure which value to assign yet.\n\nHere's what an Experiment rule looks like in the GrowthBook UI:\n\n![Experiment rule UI](https://docs.growthbook.io/images/features/feature-experiment-rules.png)\n\nIn the vast majority of cases, you want to split traffic based on either a logged-in user id or some sort of anonymous identifier like a device id or session cookie. As long as the user has the same value for this attribute, they will always get assigned the same variation. In rare cases, you may want to use an attribute such as company or account instead, which ensures all users in a company will see the same thing.\n\nYou can control both the percent of users included and the traffic split between the variations. For example, if you include 50% of users and do a 40/60 split, then 20% will see the first variation, 30% will see the 2nd variation, and the remaining 50% will skip the rule entirely and move onto the next rule (or the default value if there are no more matching rules).\n\nWhen a user is placed in an experiment via the experiment override rule, the SDK will track the experiment assignment in your data warehouse or analytics tool, via the `trackingCallback` method.\n\nYou can analyze the result of a Feature Experiment rule the same way you would any experiment in GrowthBook.\n\n### Namespaces[​](#namespaces \"Direct link to Namespaces\")\n\nIf you have multiple experiments that may conflict with each other (e.g. background color and text color), you can use **namespaces** to make the conflicting experiments mutually exclusive.\n\nUsers are randomly assigned a value from 0 to 1 for each namespace. Each experiment in a namespace has a range of values that it includes. Users are only part of an experiment if their value falls within the experiment's range. So as long as two experiment ranges do not overlap, users will only ever be in at most one of them.\n\n![Namespaces](https://docs.growthbook.io/assets/images/namespaces-373302a7546bd8f44fb1f75fbbee67cb.png)\n\nIn order to use namespaces, simply create a new namespace or modify an existing one in _SDK Configuration → Namespaces_ in the GrowthBook UI's left navigation bar.\n\n## Testing Rules[​](#testing-rules \"Direct link to Testing Rules\")\n\nYou can test your rules in the GrowthBook UI by clicking on the \"Test Feature Rules\" under the rules. This will open a form that will allow you to adjust user attributes and see in real time how the rules will be applied, and what value they'll get. User attributes can also added as JSON objects, by clicking on the JSON tab. You can also expand the results to see more debug information about why each rule was or wasn't applied.\n\n![Test Feature Rules](https://docs.growthbook.io/assets/images/feature-test-rules-7c293b8137a369e7ba50a041e79bd896.gif)\n\n### Archetype[​](#archetype \"Direct link to Archetype\")\n\nArchetypes are a way you can save preset user attributes to see how your if the rules will apply to them. This is useful if you have specific sets of users who you frequently want to target features to. They are automatically shown along with the feature values at the top of the test rules form. Mouse over any value to see more debug information about why that value was returned. Archetypes are part of the GrowthBook Enterprise plan.\n\n![Archetypes](https://docs.growthbook.io/assets/images/feature-archetypes-381713763a216429089bb94e6012d279.png)\n\nFrom the testing form, you can click on the _Save Archetype_ button to open the _Create Archetype_ modal to create new archetypes.",
    "title": "Feature Flag Override Rules | GrowthBook Docs",
    "description": "Learn about feature flag override rules",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/feature-flag-experiments",
    "markdown": "# Feature Flag Experiments | GrowthBook Docs\n\nGrowthBook allows you to run experiments using feature flags. This method of running experiments allows any feature to be released as an A/B test. It is ideal for more complex experiments requiring multiple code changes, or for companies that want to have an experimentation development culture, and determining the impact on your metrics of any feature or code change.\n\n## Running Experiments with Feature Flags[​](#running-experiments-with-feature-flags \"Direct link to Running Experiments with Feature Flags\")\n\nFeature flag experiments are created with an experiment override rule. This experiment rule will randomly assign variations to your users based on the configurations you select. When a user is placed in an experiment via an experiment override rule, the assignment will be tracked in your data warehouse using the `trackingCallback` defined in the SDK implementation.\n\nHere's what an Experiment rule looks like in the GrowthBook UI:\n\n![Experiment rule UI](https://docs.growthbook.io/images/features/feature-experiment-rules.png)\n\nThis modal window allows for a great deal of flexibility and customization in how you run your experiments. Let's go through each of the options:\n\n### Experiment Targeting Conditions[​](#experiment-targeting-conditions \"Direct link to Experiment Targeting Conditions\")\n\nExperiment rules can be targeted at specific user or client attributes. Only users who match the targeting condition will be included in experiment. You can add multiple targeting conditions per rule, and you can add multiple rules per feature, this gives you great flexibility in targeting and customizing your experiment to specific audiences. You can read more about [targeting](https://docs.growthbook.io/features/targeting). By default, all users will be included.\n\n### Tracking Key[​](#tracking-key \"Direct link to Tracking Key\")\n\nThe tracking key used to identify this experiment in the SDK. It is used, along with the user hashing attribute in the persistent hashing algorithm to ensure the users always get randomized into the same treatment group. It is also what is passed to the tracking callback to be tracked in your data warehouse. By default, the tracking key is the same as the feature name, but can be any string. If you change the experiment tracking key users will re-bucketed. The tracking key can be set to the same values in different features or experiment rules to allow for one experiment to have multiple features.\n\n### Assign Variations Based on Attribute[​](#assign-variations-based-on-attribute \"Direct link to Assign Variations Based on Attribute\")\n\nThe value you select here will be hashed along with tracking key to determine which variation the user will be assigned. Only attributes marked as **identifiers** can be used here. In the vast majority of cases, you want to split traffic based on either a logged-in user id or some sort of anonymous identifier like a device id or session cookie. As long as the user has the same value for this attribute, they will always get assigned the same variation.\n\nThe values available here are defined in the GrowthBook UI under the _SDK Configuration → Attributes_ section. Like all attributes in GrowthBook, the users value for this attribute must be defined in the SDK implementation. You can read more about targeting attributes [here](https://docs.growthbook.io/features/targeting).\n\n### Exposure, Variations, and Weights[​](#exposure-variations-and-weights \"Direct link to Exposure, Variations, and Weights\")\n\nHere you can choose the overall traffic you want to see the experiment as well as any custom split percentages. If you assign to less than 100% of the users, the remaining users will skip the rule and fall through to the next matching one (or the default value) instead.\n\nYou may want to run an experiment at a split percentages that weights the control group in order to de-risk the new feature (say 90% control, 10% new treatment). It is best practice in such cases to keep the splits the same, and adjust the overall exposure (ie, 20% overall exposure, 50/50 split for the variations).\n\nMultiple variations can be added to an experiment from this section as well, as long as the feature is not a boolean.\n\nThe bar at the bottom shows the traffic allocation for this experiment.\n\nEach user will have the **tracking key** and **hashing attribute** hashed together to determine which variation they will be assigned. The algorithm is deterministic, and always returns the same value (a number from 0 to 1) as long as the inputs are the same. Changing the split percentages mid-experiment risks having a user switch variations, and could cause multiple exposure warnings. Changing the overall exposure percentage is completely safe.\n\n### Namespaces[​](#namespaces \"Direct link to Namespaces\")\n\nIf you have multiple experiments that may conflict with each other (e.g. background color and text color), you can use **namespaces** to make the conflicting experiments mutually exclusive.\n\nUsers are randomly assigned a value from 0 to 1 for each namespace. Each experiment in a namespace has a range of values that it includes. Users are only part of an experiment if their value falls within the experiment's range. So as long as two experiment ranges do not overlap, users will only ever be in at most one of them.\n\n![Namespaces](https://docs.growthbook.io/assets/images/namespaces-373302a7546bd8f44fb1f75fbbee67cb.png)\n\nBefore you can use namespaces, you must configure them under _SDK Configuration → Namespaces_.\n\n## Experiment Results[​](#experiment-results \"Direct link to Experiment Results\")\n\nOnce you have the experiment rule saved and published the feature will start to apply these settings and randomize your users into the experiment. The results will flow into your data warehouse, as defined by your `trackingCallback`. There is a link to view experiment results on the bottom of each experiment override rule. Read more about [experiment results](https://docs.growthbook.io/app/experiment-results).",
    "title": "Feature Flag Experiments | GrowthBook Docs",
    "description": "Run experiments using feature flags",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/features/prerequisites",
    "markdown": "# Prerequisite Features | GrowthBook Docs\n\nPrerequisite features allow you to control the state of other features, rules, and experiments based on the state of a prerequisite feature.\n\nSome common use cases include:\n\n*   Grouping multiple related features under a single release feature (ex: `release-2.8`) and toggling them all at once\n*   Creating a hierarchy of features which depend on each other and safely enabling them in the correct order, per environment\n*   Only enabling a set of features if the user was bucketed into \"variant 1\" of an experiment\n\nThere are two types of prerequisite features in GrowthBook: **Top-level Prerequisites** (feature gating) and **Inline Prerequisite Targeting** (rule-level and experiment-level gating).\n\n## Top-Level Prerequisites[​](#top-level-prerequisites \"Direct link to Top-Level Prerequisites\")\n\nTop-level prerequisites are defined per dependent feature. They function similarly to a feature's kill switches: if the prerequisite feature is not serving `true` then the dependent feature will not be enabled.\n\nnote\n\n**Top-level Prerequisites** is a GrowthBook Pro and Enterprise feature.\n\n![Top-level prerequisites](https://docs.growthbook.io/images/features/feature-top-level-prerequisites.png)\n\nAdd one or more top-level prerequisites by clicking the \"Add Prerequisite Feature\" button on the feature page and then selecting the feature you want to use as a prerequisite.\n\nIn order for a feature to be eligible to be a top-level prerequisite, it must be a boolean (true/false). Also, it must be in the same project as the dependent feature.\n\n### Prerequisite states and values[​](#prerequisite-states-and-values \"Direct link to Prerequisite states and values\")\n\nA summary of the prerequisite state and value will show while adding or editing a prerequisite, as well as on the dependent feature page.\n\n*   **Deterministic** states (**live** and **not live**) are applied to your features within GrowthBook.\n    *   **Live** prerequisites which are serving `true` will allow their dependent features to be enabled\n    *   **Live** prerequisites which are serving `false` will still block their dependent features (`false` ≠ `true`)\n    *   **Not live** prerequisites will always block their dependent features (they evaluate to `null`, and `null` ≠ `true`)\n\ninfo\n\nPrerequisites with deterministic states work \"out of the box\" regardless of SDK version support.\n\nAny feature that is always \"not live\" will not be seen by the SDK. Any feature that is always \"live\" will no longer reference its prerequisites in the SDK. This means that no SDK-level evaluation of prerequisites is needed (these prerequisites work irrespective of SDK version support).\n\n*   **Schrödinger** state means that the prerequisite's state cannot be determined in advance. It may depend on user attributes or other non-deterministic factors. (This is homage to the physicist Erwin Schrödinger who proposed a thought experiment involving a cat in a box that is both alive and dead at the same time.)\n\ninfo\n\nPrerequisites with a Schrödinger state must be evaluated at runtime in the SDK. Prerequisite evaluation is currently supported in the following SDK versions:\n\n*   JavaScript: `0.34.0+`\n*   React: `0.24.0+`\n\n## Inline Prerequisite Targeting[​](#inline-prerequisite-targeting \"Direct link to Inline Prerequisite Targeting\")\n\nInline prerequisite targeting allows finer-grained control over prerequisite behavior than top-level prerequisites.\n\n1.  Inline prerequisites can be applied at a feature's [override rule](https://docs.growthbook.io/features/rules) level, and can be environment-specific. This comes with the added benefits of feature draft releases and approvals.\n2.  Inline prerequisites can be applied to individual experiments which may not be linked to a specific feature (such as visual experiments).\n3.  Inline prerequisite targeting is not limited to boolean features. You can specify any evaluation condition you'd like (ex: prerequisite value is: greater than 3, in a list of allowed values, or matches a regex pattern). You can even do advanced targeting with JSON.\n\nnote\n\n**Inline Prerequisite Targeting** is a GrowthBook Enterprise feature only.\n\nTo create an inline prerequisite within a feature, simply add prerequisiting targeting to an existing override rule or create a new rule with prerequisite targeting. You can specify one or more prerequisite features within the same project and give each a custom evaluation condition. A similar flow exists while editing the targeting rules of an experiment.\n\n![Inline prerequisite targeting](https://docs.growthbook.io/images/features/feature-inline-prerequisite-targeting.png)\n\n### Inline prerequisite states and values[​](#inline-prerequisite-states-and-values \"Direct link to Inline prerequisite states and values\")\n\nThe same **deterministic** and **Schrödinger** states apply to inline prerequisites as they do to top-level prerequisites ([see above](#prerequisite-states-and-values)). Below is a summary of how they apply to inline prerequisites:\n\n*   **Deterministic** states (**live** and **not live**) are calculated using your evaluation condition, which is **_not_** limited to `is true`. As before, no run-time evaluation of prerequisites is required in the SDK.\n    \n    *   **Live** prerequisites which pass the evaluation condition will allow their dependent rules or experiments to be enabled.\n    *   **Live** prerequisites which fail the evaluation condition will still block their dependent rules or experiments.\n    *   **Not live** prerequisites will generally block the dependent rule or experiment, unless the evaluation condition specifically checks for this (e.g. `is not live`)\n*   **Schrödinger** state prerequisites must be evaluated at runtime in the SDK, and thus a compatible SDK version is required.\n    \n\n## Limitations[​](#limitations \"Direct link to Limitations\")\n\nThere are a few limitations and guardrails within GrowthBook when configuring prerequisites:\n\n1.  Prerequisite features must be in the same project as the dependent feature or experiment.\n2.  You cannot select a prerequisite that would lead to a circular dependency.\n3.  If you don't have an SDK which supports prerequisite evaluation, then you cannot select a prerequisite that is in a Schrödinger state.\n4.  Once a feature has been used as a prerequisite for other features or experiments, you are blocked from deleting, archiving, or changing its projects. To perform these actions, you must first remove the feature from all dependent features and experiments. You can see a list of dependencies on the feature page:\n\n![Prerequisite dependents](https://docs.growthbook.io/images/features/feature-prerequisite-dependents.png)",
    "title": "Prerequisite Features | GrowthBook Docs",
    "description": "Gate features, rules, and experiments by a prerequisite feature",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/features/basics",
    "markdown": "# Feature Flag Basics | GrowthBook Docs\n\n## Basics of Feature Flags\n\n## Feature Keys[​](#feature-keys \"Direct link to Feature Keys\")\n\nEvery feature is defined by a unique **key**. This is what the engineering team will reference in their code when they check the value of a feature. Feature keys **cannot** be changed after they are created, so take care when choosing one. If you make a mistake, you can always delete the feature and create a new one.\n\n![Create Feature](https://docs.growthbook.io/images/features/feature-create-feature-1.png)\n\nFeature keys must only include letters, numbers, hyphens, and underscores.\n\nSome examples of good feature keys:\n\n*   `onboarding-checklist` - ON/OFF flag for a feature\n*   `checkout_button_color` - The color of the checkout button\n*   `resultsPerPage` - Number of search results to show per page\n\n## Default Values[​](#default-values \"Direct link to Default Values\")\n\nEach feature has a default value that is used when there are no matching rules for the user. A feature that is enabled on an environment, with no rules, will use the default value. The default values also depend on the feature type.\n\nUsing features in your code is easy. Here's an example from our Javascript SDK:\n\n```\n// For boolean featuresif (growthbook.isOn(\"my-feature\")) {  // ... Do something}// For number, string, and JSON featuresconst value = growthbook.getFeatureValue(\"other-feature\", \"fallback\");\n```\n\nGrowthBook also supports multiple environments, so you can, for example, have a feature enabled in **dev** but not **production**.\n\nYou can also change the value of a feature with **Override Rules**. The following types of rules are supported:\n\n## Override Rules[​](#override-rules \"Direct link to Override Rules\")\n\nDefault values are overridden by **override rules**. Override rules are used to target specific users or groups of users, or when launching A/B tests.\n\nThere are three kinds of rules we support:\n\n*   [**Forced Value**](https://docs.growthbook.io/features/rules#forced-value) - use targeting attributes to assign a subset of users the same value\n*   [**Percentage Rollout**](https://docs.growthbook.io/features/rules#percentage-rollout) - use random sampling to roll out a feature to a percent of users\n*   [**A/B Experiment**](https://docs.growthbook.io/features/rules#experiments) - run a randomized A/B test between 2 or more feature values\n\nFor more information, see our page on [override rules](https://docs.growthbook.io/features/rules).\n\n## Feature Types[​](#feature-types \"Direct link to Feature Types\")\n\nFeatures can be a simple ON/OFF flag or a more complex data type (strings, numbers or JSON) which can be used for remote configuration. The type of feature you select depends on your use case.\n\nGrowthBook supports 4 types of features:\n\n*   **Boolean (on/off)**\n*   **Number**\n*   **String**\n*   **JSON**\n\n### Boolean (ON/OFF) Flags[​](#boolean-onoff-flags \"Direct link to Boolean (ON/OFF) Flags\")\n\nON/OFF flags can support any of the following use cases:\n\n*   Decouple code deploys and releases\n*   Kill switch for production\n*   Gradual rollout of features\n*   Complex targeting and segmentation of features\n*   Validating feature releases with A/B tests\n\nBoolean feature flags may only have two values, on and off, so they are best used for simple use cases. Boolean feature flags are limited to 2 variations with A/B tests for this reason.\n\nFor example, if you have a checkout button that is currently blue, you could use an boolean flag called `new-button-color` that sets it to red when ON. This is pretty limiting since you can't easily try other colors in the future without changing the code. You may want to use one of the other feature types.\n\n### Number Flags[​](#number-flags \"Direct link to Number Flags\")\n\nSimilar to string flags, number flags support sending arbitrary numeric values to your application.\n\n### String Flags[​](#string-flags \"Direct link to String Flags\")\n\nString flag types support sending arbitrary string values to your application. This is useful for remote configuration, and also for multivariate A/B testing. For our previous example, you could use a string flag named `button-color` where you can easily set the value to 'blue', 'red', 'green', or any other color without changing your code.\n\n### JSON Flags[​](#json-flags \"Direct link to JSON Flags\")\n\nJSON flags support sending arbitrary JSON objects to your application. This is useful for remote configuration, and also when you want to send multiple values down to the SDK or code.\n\nJSON feature flags also support JSON validation, which allows you to validate the JSON object against a JSON schema. This feature is useful for validating the structure of the JSON object before sending it to your application to eliminate chances of typos. Currently, JSON validation is part of our enterprise plan.\n\n## Publishing Changes[​](#publishing-changes \"Direct link to Publishing Changes\")\n\nWhen you make changes to a feature's definition (default value or override rules), a new draft revision of the feature is created automatically. This draft revision is unpublished and is only visible within the GrowthBook UI, not to your users.\n\nYou can continue adding changes to this draft and when you are ready, publish them all at once with an optional commit message.\n\n![Draft Modal](https://docs.growthbook.io/assets/images/feature-publishing-8d4608d720dbe3e47d59e7524e76c42b.png)\n\n### Revisions[​](#revisions \"Direct link to Revisions\")\n\nOnce a draft revision has been published, it becomes locked and you can no longer make changes to it.\n\nIf you need to undo changes and revert back to a previous state, you can do so easily. Use the Revision dropdown to select the version you want to revert to and then click the Revert link. This will let you review the changes that will applied before submitting.\n\n![Feature Revisions](https://docs.growthbook.io/assets/images/revision-dropdown-3ac3d0324a26ba18a1ead20391849427.png)\n\n### Merge Conflicts[​](#merge-conflicts \"Direct link to Merge Conflicts\")\n\nIt's possible to get into a state where your draft has diverged from the live version of a feature. Some changes we are able to merge automatically (e.g. if you change a rule in \"dev\" and someone else changes a rule in \"production\"). For changes that we cannot resolve automatically, you will have to fix the conflicts first before you are able to publish your draft.\n\nWe use a similar process to Version Control Systems like git. For each conflict, you will be shown a diff of the conflict and given a choice of how to proceed.\n\nIn the example below, the Default Value was set to `foo` when you first created your draft. In your draft, you changed the value to `bar`. At the same time, someone else published a new version, changing the value to `hi!!`. So, now you have to choose which change you want to keep.\n\n![Resolve Conflicts](https://docs.growthbook.io/assets/images/resolve-conflicts-3de8879365103c0e01659d30210c7619.png)",
    "title": "Feature Flag Basics | GrowthBook Docs",
    "description": "Learn about the basics of feature flags.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/guide/GA4-google-analytics",
    "markdown": "# GrowthBook and Google Analytics GA4\n\n## A/B Testing with Google Analytics 4 (GA4) and GrowthBook\n\nThis guide walks you through using GrowthBook with Google Analytics 4 (GA4) for A/B testing. There are a few parts to this, connecting GA4 to BigQuery, connecting GrowthBook to BigQuery, and then configuring GrowthBook to track correctly with GA4.\n\ninfo\n\nYou can watch a video version of this guide, largely focused on Google Optimize replacement, here:\n\n## Configuring GrowthBook to use Google Analytics GA4 as a data source[​](#configuring-growthbook-to-use-google-analytics-ga4-as-a-data-source \"Direct link to Configuring GrowthBook to use Google Analytics GA4 as a data source\")\n\nGrowthBook connects to Google Analytics (GA4) via BigQuery. This process is straight forward, and outlined below. You can also find Google's documentation on how to create this link [here](https://support.google.com/analytics/answer/9823238).\n\n### 1\\. Create a BigQuery Project (if you don't have one)[​](#1-create-a-bigquery-project-if-you-dont-have-one \"Direct link to 1. Create a BigQuery Project (if you don't have one)\")\n\nIf you don't have a BigQuery project, you'll need to create one. Go to your [Google Cloud Console](https://console.cloud.google.com/) and create a new project:\n\n![GA4 - BigQuery create project](https://docs.growthbook.io/images/guides/GA4-1-project-list.png)\n\nClick on **_Create new project_** from the right and give your project a name.\n\n![GA4 - BigQuery create project](https://docs.growthbook.io/images/guides/GA4-2-create-project.png)\n\nOnce created, you'll be redirected to the BigQuery dashboard.\n\n![GA4 BigQuery new project dashboard](https://docs.growthbook.io/images/guides/GA4-3-new-project.png)\n\nIf you created a new project, the BigQuery API is automatically enabled. Otherwise, you'll need to enable it manually [here](https://console.cloud.google.com/flows/enableapi?apiid=bigquery)\n\nnote\n\nIf you are just testing GrowthBook with GA4 out, you can use the sandbox project that Google provides for free. When you create a new cloud project the sandbox should be automatically enabled. You can find more information about the sandbox [here](https://cloud.google.com/bigquery/docs/sandbox).\n\n### 2\\. Connect Google Analytics to BigQuery[​](#2-connect-google-analytics-to-bigquery \"Direct link to 2. Connect Google Analytics to BigQuery\")\n\nLog into your Google Analytics account and navigate to the Admin section. From there, make sure you have selected the right property, and scroll down to **_Product Links_** section. Click on the menu named **_BigQuery Links_**\n\n![GA4 BigQuery new project dashboard](https://docs.growthbook.io/images/guides/GA4-4-link-to-bigquery-1.png)\n\nClick on the **_Link_** button. This will open a menu that allows you select the project. Select on the **_Choose a BigQuery Project_** link.\n\n![GA4 BigQuery new project dashboard](https://docs.growthbook.io/images/guides/GA4-5-link-to-bigquery-2.png)\n\nSelect the project you wish to send your GA4 data to:\n\n![GA4 BigQuery connect to project](https://docs.growthbook.io/images/guides/GA4-5-link-to-bigquery-3.png)\n\nThen click **_next_**\n\n![GA4 BigQuery connected to project](https://docs.growthbook.io/images/guides/GA4-5-link-to-bigquery-4.png)\n\nOn the next step you'll be presented with some options about the connection.\n\n![GA4 BigQuery link options](https://docs.growthbook.io/images/guides/GA4-5-link-to-bigquery-5.png)\n\nHere you can choose the frequency of data updates, either daily or streaming. To use Streaming, you'll need a BigQuery account with billing info added. Depending on your use case, daily updates may be sufficient.\n\nOn the final step you'll be asked to confirm your choices. When finished, you should see something like this, verifying that the connection was successful.\n\n![GA4 BigQuery successfully connected](https://docs.growthbook.io/images/guides/GA4-5-link-to-bigquery-6.png)\n\nAnd then your BigQuery link will show up on the listing page:\n\n![GA4 BigQuery successfully connected](https://docs.growthbook.io/images/guides/GA4-5-link-to-bigquery-7.png)\n\nnote\n\nIf you are loading Google Analytics via Google Tag Manager (GTM), you may need to add the custom event to GTM to ensure the data is passed to GA4 from the datalayer. You can add the custom event by following this [section from the GTM guide](https://docs.growthbook.io/guide/google-tag-manager-and-growthbook#tracking-via-datalayer-and-gtm).\n\n### 3\\. Configure BigQuery for GrowthBook[​](#3-configure-bigquery-for-growthbook \"Direct link to 3. Configure BigQuery for GrowthBook\")\n\nYou'll need to give GrowthBook permissions to your BigQuery project so that we can access the data. We have created a guide just for this, which you can find [here](https://docs.growthbook.io/guide/bigquery)\n\n### 4\\. Connect GrowthBook to BigQuery[​](#4-connect-growthbook-to-bigquery \"Direct link to 4. Connect GrowthBook to BigQuery\")\n\nWithin GrowthBook, navigate to the **_Analysis_** section, and then click on the **_Data Sources_** page. Add a new data source, and select **_Google Analytics (GA4)_**.\n\n![GrowthBook connect to GA4](https://docs.growthbook.io/images/guides/GA4-6-add-GA4-datasource.png) ![GrowthBook connect to GA4](https://docs.growthbook.io/images/guides/GA4-6-add-GA4-datasource2.png)\n\nThen add your BigQuery connection info. GrowthBook will pre-populate the SQL queries required to use your GA4 data. You can also add a custom SQL query if you want to use a different table or filter the data in some way as you like.\n\nnote\n\nWhile GrowthBook will pre-populate the SQL queries for you, you may need to adjust the experiment query to match your data depending on the way you are tracking your experiments (see the **_trackingCallback_** below).\n\nOnce connected, you can add any additional metrics or dimensions, and then you can use your GA4 data for your experiments. You can use all your existing events and tracking- GrowthBook only requires one additional tracking call when a user is exposed to an experiment.\n\n## Running experiments with GrowthBook and GA4[​](#running-experiments-with-growthbook-and-ga4 \"Direct link to Running experiments with GrowthBook and GA4\")\n\nWith the data source connected, you can integrate the GrowthBook SDK into your application to run A/B tests. Once implemented, the SDK will do the random assignments and send the experiment exposure event to GA4 based on the settings in the GrowthBook UI.\n\ninfo\n\nWe do have a visual editor for creating experiments as part of our Pro plan. Our visual editor is meant for simple experiments. Experiments that are more complex are best created by writing code with feature flags.\n\n### SDK integration for GA4[​](#sdk-integration-for-ga4 \"Direct link to SDK integration for GA4\")\n\nThe easiest and recommended way to integrate GrowthBook is by using our [Script Tag SDK](https://docs.growthbook.io/lib/script-tag). This SDK will work out-of-the-box with GA4 without any configuration required.\n\nnote\n\nIf your experiment is not firing the `trackingCallback` you can use our [Chrome developer tool](https://chrome.google.com/webstore/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia) to help you debug and make sure the user attributes are being set correctly.\n\nImplementing the experiment variations can be done with code with inline experiments, using the feature flags, or by using our visual editor.",
    "title": "GrowthBook and Google Analytics GA4 | GrowthBook Docs",
    "description": "This guide walks you through using GrowthBook with Google Analytics 4 (GA4) to track your experiments and measure their impact on your business.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/app/visual",
    "markdown": "# Visual Editor | GrowthBook Docs\n\nWith the Visual Editor, users can design A/B tests on their site directly in their browser, run them in production, and analyze results, all without writing a single line of code. To use the Visual Editor, a software developer will need to integrate GrowthBook's [JavaScript](https://docs.growthbook.io/lib/js) SDK, [ReactJS](https://docs.growthbook.io/lib/react) SDK, or [HTML](https://docs.growthbook.io/lib/script-tag) SDK with your application.\n\nIn March 2023, we released version 2.0 of our Visual Editor, which had many improvements.\n\nnote\n\nThe Visual Editor may not work optimally on client-side rendered apps (e.g. React.js, Vue.js). Consider using [Feature Flags](https://docs.growthbook.io/app/features) instead for smoother integration. Contact [support@growthbook.io](mailto:support@growthbook.io) if you have any questions.\n\n## Requirements[​](#requirements \"Direct link to Requirements\")\n\nAll you need to get started is the [GrowthBook Chrome Extension](https://chrome.google.com/webstore/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia) installed on your Chrome Browser.\n\nThe application you want to experiment on **must be a front-end web application viewed in a browser**. Our Visual Editor does not work for mobile apps (Native or ReactNative) or desktop apps (e.g. Electron). For unsupported platforms, we recommend using [Feature Flags](https://docs.growthbook.io/app/features) instead to implement your changes in code.\n\nOnce you've create your first experiment and are ready to deploy to production, there are some additional steps required (see **Deploying to Production** below).\n\n## Creating a Visual Experiment[​](#creating-a-visual-experiment \"Direct link to Creating a Visual Experiment\")\n\nTo use the visual editor, first add a new Experiment. This can be done under **Experiments** in the left nav.\n\n![Design a new experiment](https://docs.growthbook.io/assets/images/add-experiment-modal-15681f50cca71852a1723562ee4bd078.png)\n\nSelect the option to design a new experiment. Then, you'll have a series of fields to fill out (hypothesis, variation names, goal metrics, etc.). Don't worry, these can all be changed later.\n\nOnce you created an experiment, you should be prompted to open the Visual Editor.\n\n### URL Targeting[​](#url-targeting \"Direct link to URL Targeting\")\n\nGrowthBook needs to know what page(s) of your site the experiment should run on.\n\nnote\n\nFor URL Targeting to work, you must pass the `url` targeting attribute into the GrowthBook SDK and also list it in the GrowthBook App. See [Targeting Attributes](https://docs.growthbook.io/features/targeting) to learn more about targeting users with certain attributes.\n\nIf your experiment is going to be on a single static page, enter the full URL and submit (e.g. `https://www.example.com/pricing`).\n\nIf your experiment is going to be on a page with a dynamic URL (e.g. all pages that start with `/post/`), click on the \"Advanced Mode\" link.\n\nYou'll need to enter 2 different URLs.\n\n1.  A single representative URL you want to load in the Visual Editor (e.g. `https://www.example.com/post/my-first-post`)\n2.  A URL targeting pattern to match all of your dynamic URLs\n\nThe targeting pattern supports wildcards (`*`), so for this example, you could enter `/post/*`.\n\ntip\n\nWe recommend sticking with \"Simple\" URL targeting rules (don't be fooled by the name, it's actually really powerful). The other option (Regex) can be useful for really advanced use cases, but it is much harder to write and more error prone.\n\n#### Simple Targeting[​](#simple-targeting \"Direct link to Simple Targeting\")\n\nOur \"simple\" URL targeting option supports the vast majority of use cases and is easy to use. It supports the following features:\n\n*   Match based on full URLs (e.g. `https://www.example.com/pricing`)\n*   Match based on path (e.g. `/pricing`)\n*   Match based on query strings (e.g. `/pricing?utm_source=email`)\n*   Match based on hashes/anchors (e.g. `/pricing#more-info`)\n*   Wildcards (e.g. `/posts/*` will match `/posts/123` AND `/posts/2023/03/30/my-post`)\n*   Ignores leading and trailing slashes (e.g. `pricing`, `/pricing`, and `/pricing/` are identical)\n*   Ignores the protocol (e.g. `https://...` will also match `http://...`)\n*   Ignores extra query string parameters (e.g. `/pricing/?plan=pro` will match `/pricing/?utm_source=email&plan=pro&logged-in=true`)\n\n#### Regex Targeting[​](#regex-targeting \"Direct link to Regex Targeting\")\n\nOur \"regex\" URL targeting option supports full regular expressions. Writing regular expressions for URLs is very error prone, so be careful and make sure you escape all special characters you don't want to be interpreted. Here's a full example:\n\n```\nhttps?:\\/\\/(www\\.)?example\\.com\\/pricing\\/?\n```\n\nYou can also match on just the path:\n\n```\n^\\/pricing\\/(pro|enterprise)\n```\n\n### The Visual Editor[​](#the-visual-editor \"Direct link to The Visual Editor\")\n\nThere are a number of different tools in the Visual Editor.\n\n![The Visual Editor UI](https://docs.growthbook.io/assets/images/visual-editor-ui-6068a707867e0c5c85a962b5bbc49b4f.png)\n\nAt the top is a dropdown where you can select which variation you are currently editing.\n\nBelow that is your toolbar. It has the following tools in order from left to right:\n\n1.  **Interactive Mode** - Click around your site normally\n2.  **Selection Mode** - Point and click to select an element on your site to edit. This is the most common way to make changes.\n3.  **Global CSS** - Inject global CSS styles into the page. Use this to control things like page background color or font size.\n4.  **Custom JavaScript** - Inject Javascript into the page. Use this to create complex variations.\n5.  **Change List** - See a summary of all of the changes you've made to the page so far\n\nWhen you're using the Element Selector, after you pick an element to edit, you'll be able to modify the Inner HTML (i.e. the copy), any attributes (e.g. a link HREF), and the list of CSS classes.\n\nWhen you're finished making changes, click the **Done Editing** button to be taken back to GrowthBook.\n\n### Custom JavaScript[​](#custom-javascript \"Direct link to Custom JavaScript\")\n\nCustom JavaScript is executed as quickly as possible, often times before the page has fully loaded. This gives you the most flexibility in how to implement your experiment.\n\nIf you are making changes to elements on the page, make sure you wait until they exist. Below is a small helper function you can add to the top of your Custom JavaScript to help with this:\n\n```\nfunction waitFor(selector) {  return new Promise(resolve => {    const el = document.querySelector(selector);    if (el) return resolve(el);    const observer = new MutationObserver(() => {        const el = document.querySelector(selector);        if (el) { observer.disconnect(); resolve(el)}    });    observer.observe(document, {childList: true, subtree: true});  });}\n```\n\nThen, you can use it like so:\n\n```\nwaitFor(\".my-element\").then((el) => {  el.innerHTML = \"Hello World!\";});\n```\n\n### Drag and Drop[​](#drag-and-drop \"Direct link to Drag and Drop\")\n\nWhen in Selection Mode, you can select an element and click to **drag and drop** it positionally on the page.\n\n#### Drag and Drop Handle[​](#drag-and-drop-handle \"Direct link to Drag and Drop Handle\")\n\nWhen an element is selected, you will see a floating handle to move it positionally. Alternatively, you can click anywhere on the selected element to move it as well.\n\n![Visual Editor Drag and Drop Handle](https://docs.growthbook.io/assets/images/visual-editor-move-handle-8ec559bb6de95ee475c2c8a1e1f64561.png)\n\nOnce dragging, the cursor will highlight an edge where the dragged element will land. When you release the cursor the element will move to the indicated spot. If you want to undo the move, click the 'Undo' button that is available for elements that have been dragged.\n\n![Visual Editor Drag and Drop Example](https://docs.growthbook.io/assets/images/visual-editor-drag-and-drop-1b1f0fb1762ca3af53c8b7fff1fd85e4.gif)\n\n### Debug Panel[​](#debug-panel \"Direct link to Debug Panel\")\n\nThe Visual Editor now comes with a Debug Panel to help diagnose any issues with your SDK configuration and URL Targeting rules. Use this to help diagnose your own errors, or provide a screenshot to our Support team when reaching out to help provide context.\n\n![Debug Panel](https://docs.growthbook.io/images/visual-editor-debug-panel.png)\n\n## Deploying to Production[​](#deploying-to-production \"Direct link to Deploying to Production\")\n\nBefore you start your first experiment, you will first need to generate a **Client Key** in GrowthBook. You can get this by creating a new SDK Connection (under **SDK Configuration** in the left navigation).\n\n**Important**: Make sure to enable the \"Include Visual Experiments\" toggle. If you forget this step, Visual Editor experiments will not be sent to your application.\n\n![Enable the Visual Editor in your SDK Connection](https://docs.growthbook.io/assets/images/sdk-connection-visual-editor-2b6d4d437c6e8c5f2fd511f52d6905fa.png)\n\nYou can also optionally include Draft Experiments (see below).\n\nOnce you create an SDK Connection, you need to follow the steps to integrate GrowthBook into your website.\n\nThe easiest and recommended way to do this is with our [Script Tag SDK](https://docs.growthbook.io/lib/script-tag), which works out-of-the-box and doesn't require any configuration for most websites. It's also possible to use either our [JavaScript](https://docs.growthbook.io/lib/js) or [ReactJS](https://docs.growthbook.io/lib/react) SDKs, although these do require more up-front work to integrate into your application.\n\nnote\n\nIf you've already been using our front-end SDKs for feature flagging, make sure you:\n\n1.  Update to the latest SDK version\n2.  Follow the \"Visual Editor\" instructions in the SDK docs\n\n### Content Security Policy (CSP) Changes[​](#content-security-policy-csp-changes \"Direct link to Content Security Policy (CSP) Changes\")\n\nIf your website uses a Content Security Policy (CSP), there are some additional changes you'll need to make. This applies to both SDK and pre-build script tag integration.\n\n#### script-src[​](#script-src \"Direct link to script-src\")\n\nChanging the `script-src` directive in your CSP is only required if you are writing custom JavaScript in the Visual Editor. If you are only changing styles or copy using the point-and-click editor, this is not required and you can skip this section.\n\nIf you have the `script-src` directive defined in your website's CSP, you'll need to enable `'unsafe-inline'` and `'unsafe-eval'` in order to leverage the Global JavaScript injection feature of the Visual Editor:\n\n```\nContent-Security-Policy: script-src 'self' 'unsafe-inline' 'unsafe-eval';\n```\n\n##### Using Script Nonces[​](#using-script-nonces \"Direct link to Using Script Nonces\")\n\nAs an alternative to allowing `unsafe-inline`, we support \"nonces\", although this requires some very technical and custom configuration to hook up.\n\nFirst, you will need to generate a unique nonce value for every request and add it to your CSP header. This can be done on the edge such as with a Cloudflare Worker.\n\nThen, you will need to pass this nonce into your GrowthBook SDK as `jsInjectionNonce`.\n\nFor example, if you are using our [Script Tag SDK](https://docs.growthbook.io/lib/script-tag), you can add the following into your page's `<head>` BEFORE you load the GrowthBook snippet. Replace all instances of `$NONCE` with the unique nonce value you generated.\n\n```\n<script nonce=\"$NONCE\">window.growthbook_config = window.growthbook_config || {};window.growthbook_config.jsInjectionNonce = \"$NONCE\";</script>\n```\n\nYou will still need to allow `unsafe-eval`.\n\n## Drafts and QA[​](#drafts-and-qa \"Direct link to Drafts and QA\")\n\nWhile the experiment is still a draft, you can preview variations by adding a querystring to your URL.\n\nnote\n\nThis requires turning on the \"Include Drafts\" toggle for your SDK Connection in GrowthBook.\n\nTo build the QA preview URL, you'll need the **Experiment Id** (viewable on the right side of the experiment page under Settings). You'll also need the variation number you want to preview. `0` is the control, `1` is the 1st variation, etc..\n\nNow, just join these together with an equals sign (e.g. `my-experiment-id=1`). This needs to go in the Querystring part of the URL (after a question mark). Here's a full example:\n\n`https://www.example.com/pricing?my-experiment-id=1`\n\nUntil an experiment is moved out of the \"draft\" phase and started, this is the only way to view it on your site.\n\n## Stopping an Experiment[​](#stopping-an-experiment \"Direct link to Stopping an Experiment\")\n\nWhen your experiment is finished, you can click on the `Stop Experiment` link at the top of results. This will prompt you for several bits of information about why you're stopping and what the conclusion was.\n\nIf your variation won, you can optionally enable a `Temporary Rollout` when stopping. This will continue running your experiment with the same targeting conditions, but send 100% of traffic to the winning variation and disable the `trackingCallback` from being called.\n\nThe reason it's called a \"Temporary\" Rollout is because you don't want to rely on our SDK to implement the winning variation forever. It's best practice to have your engineering team re-implement the changes directly in your site's code. This is for a number of reasons:\n\n1.  Changes implemented in code are rendered quicker, so your site will load faster\n2.  Changes in code will be picked up for SEO\n3.  Changes applied through the visual editor require the SDK to download data from GrowthBook. Although lightweight, these stopped experiments can add up over time and further slow down your site.\n4.  Reduce the chance of conflicts. If two visual editor experiments try to change the same element at the same time, it will not always work as expected. Moving the winning variation to code will avoid this issue.",
    "title": "Visual Editor | GrowthBook Docs",
    "description": "Learn about our visual editor",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/app/datasources",
    "markdown": "# Data Source Configuration | GrowthBook Docs\n\n## Overview[​](#overview \"Direct link to Overview\")\n\nData Sources are how GrowthBook connects to your data warehouse so that it can pull those aggregated statistics in order to compute metrics and experiment results. Each Data Source defines how to connect to your data, what version of SQL to use when querying your data, and can provide templates for what the SQL to connect to your Data Source should look like depending upon which event tracker software you use. GrowthBook works with your existing SQL data, no matter where it is located and no matter what shape or format it is in, whether you have a strongly normalized schema, a single “events” table with JSON fields, or something in between.\n\n## Supported Event Schemas[​](#supported-event-schemas \"Direct link to Supported Event Schemas\")\n\nWhen adding a new Data Source in Growthbook from /datasources page we first guide you to select what event tracker software you use, or you can choose custom if you don't use any of the popular third party event trackers that we support. Telling us which event tracker you use, gives us an idea on the likely shape of your data. This will help us generate the correct sql to extract out the aggregated statistics from your site with as little modification on your end as possible. Here is Growthbook's current list of event trackers that we support with links for more details on how to set them up with GrowthBook:\n\n*   [Amplitude](https://docs.growthbook.io/event-trackers/amplitude)\n*   [CleverTap](https://docs.growthbook.io/event-trackers/clevertap)\n*   [Firebase](https://docs.growthbook.io/event-trackers/firebase)\n*   [Freshpaint](https://docs.growthbook.io/event-trackers/freshpaint)\n*   [Fullstory](https://docs.growthbook.io/event-trackers/fullstory)\n*   [Google Analytics 4 (BigQuery only)](https://docs.growthbook.io/guide/GA4-google-analytics)\n*   [Heap Analytics](https://docs.growthbook.io/event-trackers/heap)\n*   [Jitsu](https://docs.growthbook.io/event-trackers/jitsu)\n*   [Keen IO](https://docs.growthbook.io/event-trackers/keenio)\n*   [Matomo](https://docs.growthbook.io/guide/matomo)\n*   [Mixpanel](https://docs.growthbook.io/guide/mixpanel)\n*   [MParticle](https://docs.growthbook.io/event-trackers/mparticle)\n*   [RudderStack](https://docs.growthbook.io/guide/rudderstack)\n*   [Segment](https://docs.growthbook.io/event-trackers/segment)\n*   [Snowplow](https://docs.growthbook.io/event-trackers/snowplow)\n\nIf you do not use any of those you choose [Custom Data Source](https://docs.growthbook.io/event-trackers/custom) and define some of the sql yourself.\n\n## Configuration Settings[​](#configuration-settings \"Direct link to Configuration Settings\")\n\nOnce you have chosen your event tracker and data source type and successfully connected, you will be given an opportunity to modify your configuration settings. For many applications Growthbook will have choosen the correct configuration settings straight out of the box based upon which event tracker you choose. In some instances, you may need to tweak them slightly, or in the case of using a custom datasource, define them more explicitly.\n\n### Identifier Types[​](#identifier-types \"Direct link to Identifier Types\")\n\nThese are all of the types of identifiers you use to split traffic in an experiment and track metric conversions. Common examples are `user_id`, `anonymous_id`, `device_id`, and `ip_address`.\n\nThere are some cases where a single database column isn't enough to uniquely identify a subject. For example, you might need the combination of `company` and `user_id`. In this case, we recommend creating a synthetic identifier by concatenating all of the fields together. For example, you can create a `company_user` identifier and then in your SQL, select it as follows: `CONCAT(company, user_id) as company_user`.\n\n### Experiment Assignment Queries[​](#experiment-assignment-queries \"Direct link to Experiment Assignment Queries\")\n\nAn experiment assignment query returns which users were part of which experiment, what variation they saw, and when they saw it. Each assignment query is tied to a single identifier type (defined above). You can also have multiple assignment queries if you store that data in different tables, for example, one from your email system and one from your back-end.\n\ntip\n\nAssignment queries are one-half of the queries that are used to generate experiment results, the other being metric queries. Assignment queries can be edited from the `Metrics and Data` → `Data Sources` page.\n\nThe end result of the query should return data like this:\n\n| user\\_id | timestamp | experiment\\_id | variation\\_id |\n| --- | --- | --- | --- |\n| 123 | 2021-08-23-10:53:04 | my-button-test | 0   |\n| 456 | 2021-08-23 10:53:06 | my-button-test | 1   |\n\nThe above assumes the identifier type you are using is `user_id`. If you are using a different identifier, you would use a different column name.\n\nHere's an example query you might use:\n\n```\nSELECT  user_id,  received_at as timestamp,  experiment_id,  variation_idFROM  eventsWHERE  event_type = 'viewed experiment'\n```\n\nMake sure to return the exact column names that GrowthBook is expecting. If your table’s columns use a different name, add an alias in the SELECT list (e.g. `SELECT original_column as new_column`).\n\n#### Duplicate Rows[​](#duplicate-rows \"Direct link to Duplicate Rows\")\n\nIf a user sees an experiment multiple times, you should return multiple rows in your assignment query, one for each time the user was exposed to the experiment.\n\nThis helps us detect when users were exposed to more than one variation, and eventually may be useful in helping build interesting time series.\n\n#### Experiment Dimensions[​](#experiment-dimensions \"Direct link to Experiment Dimensions\")\n\nIn addition to the standard 4 columns above, you can also select additional dimension columns. For example, `browser` or `referrer`. These extra columns can be used to drill down into experiment results.\n\n#### Identifier Join Tables[​](#identifier-join-tables \"Direct link to Identifier Join Tables\")\n\nIf you have multiple identifier types and want to be able to auto-merge them together during analysis, you also need to define identifier join tables. For example, if your experiment is assigned based on `device_id`, but the conversion metric only has a `user_id` column.\n\nThese queries are very simple and just need to return columns for each of the identifier types being joined. For example:\n\n```\nSELECT user_id, device_id FROM logins\n```\n\n#### SQL Templates[​](#sql-templates \"Direct link to SQL Templates\")\n\nWe use {{[Handlebars](https://handlebarsjs.com/guide/#language-features)}} to compile the assignment sql, identity queries, etc. into what is actually called to your database.\n\nYou can use any of the in-built variables that Growthbook automatically sets:\n\n*   **startDate** - `yyyy-MM-dd HH:mm:ss` of the earliest data that needs to be included\n*   **startDateISO** - `yyyy-MM-dd'T'HH:mm:ss.SSS'Z'` of the startDate in ISO format. This can then be used with the `date` helper to achieve whatever [format](#dateformat) you like (ex. `{{date startDateISO \"yyyyMMdd\"}}`)\n*   **endDate** - `yyyy-MM-dd HH:mm:ss` of the latest data that needs to be included\n*   **endDateISO** - `yyyy-MM-dd'T'HH:mm:ss.SSS'Z'` of the endDate in ISO format. This can then be used with the `date` helper to achieve whatever [format](#dateformat) you like (ex. `{{date endDateISO \"yyyyMMdd\"}}`)\n*   **experimentId** - Either a specific experiment id OR `%` if you should include all experiments\n\nYou can also use any of the in-built helper functions:\n\n*   **camelcase \\[str\\]** - ex. `{{camelcase \"My database\"}}` compiles to `myDatabase`.\n*   **dotcase \\[str\\]** - ex. `{{dotcase \"My database\"}}` compiles to `my.database`.\n*   **kebabcase \\[str\\]** - ex. `{{kebabcase \"My database\"}}` compiles to `my-database`.\n*   **lowercase \\[str\\]** - ex. `{{lowercase \"My database\"}}` compiles to `my database`.\n*   **pascalcase \\[str\\]** - ex. `{{pascalcase \"My database\"}}` compiles to `MyDatabase`.\n*   **replace \\[str\\] \\[pattern\\] \\[replacement\\]** - Replace all occurences of a regular expression with something else. ex. `{{replace \"My%%%Database!\" \"\\[^a-zA-Z\\]\" \"\"}}` compiles to `MyDatabase`\n*   **snakecase \\[str\\]** - ex. `{{pascalcase \"My database\"}}` compiles to `my_database`.\n*   **uppercase \\[str\\]** - ex. `{{uppercase \"My database\"}}` compiles to `MY DATABASE`.\n*   **date \\[date\\] \\[format\\]** - Format an ISO date according to this [format](https://date-fns.org/v2.29.3/docs/format), being careful not to mix up months (MM) and minutes (mm). ex. `{{date startDateISO \"yyyyMMdd\"}}` might compile to `20230130`. The most common codes are:\n\n| code | meaning |\n| --- | --- |\n| yyyy | year |\n| MM  | month |\n| dd  | day |\n| HH  | hour |\n| mm  | minutes |\n| ss  | seconds |\n| t   | timestamp |\n\nFor example:\n\n```\nSELECT  user_id,  anonymous_id,  received_at as timestamp,  experiment_id,  variation_idFROM  events_*WHERE  _TABLE_SUFFIX BETWEEN '{{date startDateISO \"yyyyMMdd\"}}' AND '{{date endDateISO \"yyyyMMdd\"}}'  AND event_name = 'experiment_viewed'  AND experiment_id LIKE '{{ experimentId }}'\n```\n\nnote\n\nThe inserted values do not have surrounding quotes, so you must add those yourself (e.g. use `'{{&nbsp;startDate&nbsp;}}'` instead of just `{{&nbsp;startDate&nbsp;}}`)\n\n### Jupyter Notebook Query Runner[​](#jupyter-notebook-query-runner \"Direct link to Jupyter Notebook Query Runner\")\n\nThis setting is only required if you want to export experiment results as a Jupyter Notebook.\n\nThere is no one standard way to store credentials or run SQL queries from Jupyter notebooks, so GrowthBook lets you define your own Python function.\n\nIt needs to be called `runQuery`, accept a single string argument named `sql`, and return a pandas data frame.\n\nHere's an example for a Postgres (or Redshift) data source:\n\n```\nimport osimport psycopg2import pandas as pdfrom sqlalchemy import create_engine, text# Use environment variables or similar for passwords!password = os.getenv('POSTGRES_PW')connStr = f'postgresql+psycopg2://user:{password}@localhost'dbConnection = create_engine(connStr).connect();def runQuery(sql):  return pd.read_sql(text(sql), dbConnection)\n```\n\n**Note:** This python source is stored as plain text in the database. Do not hard-code passwords or sensitive info. Use environment variables (shown above) or another credential store instead.\n\n## Schema Browser[​](#schema-browser \"Direct link to Schema Browser\")\n\nWhen you connect a supported data source to GrowthBook, we automatically generate metadata that is used by our Schema Browser. The Schema Browser is a user-friendly interface that makes writing queries easier as you can easily explore information about the datasource such as databases, schemas, tables, columns, and data types.\n\n![GrowthBook Schema Browser](https://docs.growthbook.io/assets/images/growthbook-schema-browser-40e388a5759c12afef54296d9c0c1980.png)\n\nBelow are the data sources that currently support the Schema Browser:\n\n*   AWS Athena - _Requires a Default Catalog_\n*   BigQuery - _Requires a Project Name and Default Dataset_\n*   ClickHouse\n*   Databricks - _Currently only supported on version 10.2 and above with a Unity Catalog_\n*   MsSQL/SQL Server\n*   MySQL/MariaDB\n*   Postgres\n*   PrestoDB (and Trino) - _Requires a Default Catalog_\n*   Redshift\n*   Snowflake\n\nnote\n\nIf you added a supported data source prior to GrowthBook v2.0, you can generate the schema manually by clicking \"Data Sources\" on the left-nav, selecting the data source, and then clicking the \"View Schema Browser\" button and following the on-screen prompt.",
    "title": "Data Source Configuration | GrowthBook Docs",
    "description": "This document outlines how to configure data source",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/features/environments",
    "markdown": "# Environments | GrowthBook Docs\n\nGrowthBook comes with one environment by default (**production**), but you can add as many as you need on the [Environments page](https://app.growthbook.io/environments) located within the **SDK Configuration** menu.\n\nFeature flags can be enabled and disabled on a per-environment basis. You can also set the default feature state for any new environment. Additionally, you can scope environments to only be available in specific projects, allowing for further control and segmentation over feature delivery.\n\n![A list of environments](https://docs.growthbook.io/assets/images/feature-environments-1-4255235035807c067eca714cfa959cd6.png)\n\nWhen a feature is disabled in an environment, the feature will not be returned via the SDK, and that feature will always evaluate to `null` and ignore any other targeting or override rules.\n\n## Environments and SDKs[​](#environments-and-sdks \"Direct link to Environments and SDKs\")\n\nWhen you configure your SDK endpoint you will be asked which environment you want to use. Each SDK endpoint will have a unique SDK key. When this endpoint is called from the code, a JSON file containing all the features and rules by which they should be shown is returned. Scoping SDKs to environments allows you to easily separate, for example, your production and development environments.\n\nTo use multiple environments in the same code base, you can use environment variables to set a dynamic key, e.g. `GROWTHBOOK_CLIENT_KEY='sdk-abc123'` and then reference that environment variable in your code base. Depending on the framework you're using, some environment variables are not exposed by default on the front-end unless provided an appropriate prefix, e.g. `NEXT_GROWTHBOOK_CLIENT_KEY='sdk-abc123'` in order to access environment variables in Next.js client code.\n\nnote\n\nIt's possible for a feature to be enabled for an environment and still be considered \"off\". This happens when its value is set to `false`, `null`, `0`, or an empty string.",
    "title": "Environments | GrowthBook Docs",
    "description": "Define multiple environments to control which features are enabled in each.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/app/fact-tables",
    "markdown": "# Fact Tables | GrowthBook Docs\n\nWith Fact Tables, you write SQL once for an event (e.g. `SELECT * FROM orders`) and from that you can quickly and easily create a bunch of related metrics - for example, `Revenue per User`, `Average Order Value`, and `Items per Order`.\n\nThese metrics can be used as Goals and Guardrails in Experiments.\n\n## Fact Table SQL[​](#fact-table-sql \"Direct link to Fact Table SQL\")\n\nFirst, you have to write SQL that transforms your event data into a format that GrowthBook understands. The following column names are required:\n\n*   `timestamp` - The date the event happened\n*   One column per supported identifier type (e.g. `user_id` and `anonymous_id`). The possible identifier types depend on your data source settings.\n\nAny other columns you return can be used to create metrics or used as a filter.\n\nHere's a full example:\n\n```\nSELECT  -- Required columns  purchase_date as timestamp,  user_id,  anonymous_id,  -- Additional columns (depends on your event)  amount,  coupon_code,  device_typeFROM  ordersWHERE  status = 'completed'\n```\n\n### Columns[​](#columns \"Direct link to Columns\")\n\nWhen you create a Fact Table, we query the first few rows and inspect the returned data to determine which columns you've selected and what data types they are.\n\nThis process isn't perfect. For example, if the first few rows happen to have `null` as the value of a column, we can't tell if it's supposed to be a number, string, etc.. When this happens, we will show you a warning and you can manually specify the type.\n\nAny column can be used to create filters, but only numeric columns can be used as a metric value.\n\n#### Number Formats[​](#number-formats \"Direct link to Number Formats\")\n\nFor numeric columns, you can also specify a number format, which controls how the metric is displayed on the front-end. Possible values are `currency` and `time:seconds`.\n\nnote\n\nThe default display currency is USD, but you can change it under **Settings** → **General** → **Metric Settings**\n\n## Filters[​](#filters \"Direct link to Filters\")\n\nFilters are reusable SQL snippets to filter the rows in the Fact Table. These let you easily create metric variants. For example, `Purchase`, `Mobile Purchase`, and `Desktop Purchase`\n\nHere's an example Filter SQL:\n\nIf a metric uses this Filter, GrowthBook will add it to the WHERE clause automatically. If there are multiple Filters, they will be ANDed together.\n\n## Metrics[​](#metrics \"Direct link to Metrics\")\n\nThere are 4 types of supported Fact Table metrics today - **Proportion**, **Mean**, **Ratio**, and **Quantile**.\n\n| Metric Type | Description | Example | User Aggregation | Variation Aggregation |\n| --- | --- | --- | --- | --- |\n| Proportion | Percentage of users | Created Account | 1 or 0 | Proportion of users in variation |\n| Mean | Average of user totals | Revenue per User | `SUM(value)` | Average across users in variation |\n| Ratio | Ratio of two totals | Average Order Value | `SUM(value)` for both numerator and denominator | Sum of user numerators / sum of user denominators |\n| Quantile (event) | Quantile of row values | P95 Latency | None | Quantile across all values |\n| Quantile (per user) | Quantile of user totals | P90 Total User Revenue | `SUM(value)` | Quantile across user totals |\n\n### Proportion Metrics[​](#proportion-metrics \"Direct link to Proportion Metrics\")\n\nProportion Metrics measure the percent of users in an experiment who exist in a Fact Table. The number of rows the user has doesn't matter - we just care whether or not they have at least 1 row.\n\nFor example, if you have an Orders Fact Table, you can create a Proportion Metric to see what percent of users purchased something. Whether a user made 1 purchase or 10 purchases, it will just count as 1 conversion.\n\nYou can optionally add Filters to limit which rows are considered. For example, adding a `Mobile` filter, you can see what percent of users completed a purchase on a mobile device.\n\n### Mean Metrics[​](#mean-metrics \"Direct link to Mean Metrics\")\n\nMean Metrics are useful when there are more than 2 possible states a user can be in. For example, instead of just purchase/not purchase, you might care about the average number of orders a user makes, or the average revenue you earned per user in an experiment.\n\nFor the metric value, there are 2 types of aggregations you can do - `COUNT(*)` and `SUM(column)`. For `SUM`, you will be able to choose any numeric column in your Fact Table.\n\nFor example, an **Orders per User** metric would use `COUNT(*)` since you want to count the total number of rows. A **Revenue per User** metric would use `SUM` and select the column where the order total is stored.\n\nThe denominator for Mean Metrics is always the number of users in an experiment variation. So, even though you may be doing `SUM(revenue)` as the aggregation, it will be divided by number of users and you will actually end up with an average value per user, not an overall sum for the variation.\n\n### Ratio Metrics[​](#ratio-metrics \"Direct link to Ratio Metrics\")\n\nRatio Metrics let you pick a custom denominator and allow for metrics such as **Average Order Value** (denominator is number of orders) or **Session Duration** (denominator is number of sessions).\n\nFor both the numerator and denominator, you can select a Fact Table, an aggregation, and optional filters. GrowthBook allows the numerator and denominator to have different Fact Tables, which can open up some really advanced use cases.\n\nThe types of aggregations supported for ratio metrics are:\n\n*   `COUNT(*)` - Number of rows in the Fact Table\n*   `COUNT(DISTINCT 'User Identifier')` - Sample size of the experiment variation\n*   `SUM(column)` - Total of a numeric column in the Fact Table\n\nUnder the hood, GrowthBook uses the Delta Method to accurately determine the variance.\n\nFor example, to create a **Session Duration** metric, you would do the following:\n\n*   Numerator: `SUM(duration)` from a `Sessions` fact table\n*   Denominator: `COUNT(*)` from a `Sessions` fact table\n\n### Quantile Metrics[​](#quantile-metrics \"Direct link to Quantile Metrics\")\n\nQuantile Metrics are useful when you care about comparing variations at a quantile (e.g. latency at P99) rather than the mean. Learn more about when to use Quantile Metrics [here](https://docs.growthbook.io/statistics/quantile).\n\nOne key consideration is `Group by Experiment User before taking quantile?`. We provide a more complete description [here](https://docs.growthbook.io/app/fact-tables#quantile-metrics). In short, if you often think about your metric at the user level, you should aggregate. If you think about your metric at the event level, do not aggregate.\n\nFor the metric value, the only aggregation available is `SUM(column)`. For `SUM`, you will be able to choose any numeric column in your Fact Table.\n\nYou have the option to `Ignore Zeros`. For event-level analysis, ignoring zeros entails removing all events from the analysis with value equal to 0. Similarly, for a user-level analysis, removing zeros entails removing all rows corresponding to user-level aggregations that have value 0.\n\nWhen picking `Quantile` you have several default options or can select `Custom`. If you select `Custom` you must input a number between 0 and 1. For example, inputting 0.75 will compare the 75th75^{\\\\text{th}} percentiles across variations.\n\n### Metric Windows[​](#metric-windows \"Direct link to Metric Windows\")\n\nWhen used in an experiment, we only consider rows of a Metric where the timestamp is greater than or equal to the first time the user was exposed to the experiment. In other words, if someone purchases something before seeing your experiment, it won't be included in the analysis. This behavior is ideal for the vast majority of metrics, but you can change it with the Metric Delay setting if desired (see below).\n\nThere are three window settings one can use to configure the metric date window. Each of them defines the lower and upper date range of the metric to use for each user:\n\n*   **None** (default)\n    *   Lower bound: user's first exposure plus the metric delay\n    *   Upper bound: experiment end date\n*   **Conversion Window**\n    *   Lower bound: user's first exposure plus the metric delay\n    *   Upper bound: the lower bound + the length of the conversion window\n*   **Lookback Window**\n    *   Lower bound: the experiment end date minus the lookback window OR the user's first exposure plus the metric delay, whichever is later\n    *   Upper bound: experiment end date\n\nHere's a graphical representation of these three window types for a hypothetical User 1: ![Metric Windows](https://docs.growthbook.io/assets/images/metric-windows-024e6a7e756c8cd43f0d35ee221cc089.png)\n\nHere's a second example for a hypothetical User 2, who joins the experiment late. Notice that the conversion window can extend beyond the experiment end date. ![Metric Windows (User 2)](https://docs.growthbook.io/assets/images/metric-windows-user-2-dac5ae6d7345e2211ec13dd5f8869954.png)\n\nWhy might you choose one window over another?\n\n**None** - The simplest. Use all data available. This is useful for using as much data associated with users in your experiment and will combine any behavior that is right after experiment exposure as well as long run behavior within the experiment time frame.\n\n**Conversion window** - Conversion windows allow you to only look at events that are tied to the first exposure to an experiment. This can help if, for example, you are tracking purchases and you only want to measure the effect of an experiment in a checkout flow on purchases made soon after seeing that checkout flow. Using a conversion window can reduce the noise from user behavior not related to an experiment. However, if you set the window too short, you may not capture users that return a few days later and were influenced by the experiment.\n\n**Lookback window** - Lookback windows are good for capturing long run impacts of an experiment on regular behavior like user log ins or page views. They have two main advantages:\n\n(1) You can mitigate the novelty effect of an experiment; if you are testing a new recommendation algorithm, at first users may react a certain way to the experiment, but eventually they may adjust and so may their behavior. In these cases, you may just want to look at the last 14 days of an experiment.\n\n(2) Lookback windows help you focus on the long run effects of an experiment. Much of experimentation is about building a better product; by focusing on impact of an experiment after it has been live for a week or two, you may get a better picture of the long run impact of launching the experiment.\n\nLarger companies who measure long run logged in behavior want to ensure their experiments have lasting effects and often rely on lookback windows to make shipping decisions However, lookback windows may not be right if you are testing a feature on logged-out or anonymous users and are measuring simple purchase conversions or something similar. In these cases, you might end up with many logged-out users who, in the long run, simply have no metric data associated with them.\n\n### Advanced Settings[​](#advanced-settings \"Direct link to Advanced Settings\")\n\n#### What is the Goal?[​](#what-is-the-goal \"Direct link to What is the Goal?\")\n\nFor the vast majority of metrics, the goal is to increase the value. But for some metrics like \"Bounce Rate\" and \"Page Load Time\", lower is actually better.\n\nSetting this to \"decrease\" basically inverts the \"Chance to Beat Control\" value in experiment results so that \"beating\" the control means decreasing the value. This will also reverse the red and green coloring on graphs.\n\n#### Capped Value[​](#capped-value \"Direct link to Capped Value\")\n\nLarge outliers can have an outsized effect on experiment results. For example, if your normal revenue per user $40 and someone happens to make a $5000 order, whatever variation that person is in will be much more likely \"win\" any experiment because that one order is an outlier.\n\nCapping (also known as winsorization) works by ensuring that all aggregate unit (e.g. user) values are no more than some value. So in the above example, if the cap was $100, the $5000 purchase will still be counted, but the aggregated value for that user will be capped at $100 and will have a much smaller effect on the results. It will still give a boost to whatever variation the person is in, but it won't completely dominate all of the other orders and is unlikely to make a winner just on its own. Another way to think about this is that you are slightly biasing your results by truncating large values, but you are reducing variance to prevent the outsized effect of outliers.\n\nThere are two ways to cap metric values in GrowthBook:\n\n**1\\. Absolute capping** - if set above zero, all aggregated user values will be capped at exactly this value. For example, if the cap is $100 on total revenue per user, then after we sum all of a users orders up, any user with an aggregate sum of greater than $100 will be set to $100.\n\n**2\\. Percentile capping** - when this is set to between 0 and 1, it uses that percentile to select a cap based on the data in your experiment so far. This cap is therefore specific to each experiment and specific to each analysis run in that experiment if new data has come in. It works like so: after we calculate the unit-level aggregate values for all units (e.g. users) during an experiment analysis, we find the specified percentile of these unit-level aggregates and then cap these aggregated values at this percentile. Using the above example, if you were to specify percentile capping with a value of `0.95`, then we find the 95th percentile of total revenue per users (say this turns out to be $135). We then cap those user-level aggregates at $135.\n\nYou can additionally choose to ignore zeros, which will compute the percentile without including any user aggregated zero values. This is useful if you have a lot of zero values and you don't want to have to fine tune the percentile to avoid setting the cap too low.\n\nBecause the percentile cap depends on the data in your experiment, it can be different from experiment to experiment, or even analysis to analysis. To find out what value was actually used for capping you can do the following: on the Experiment Results tab, click the three dot menu in the top right and select \"View Queries\". Each percentile capped metric will have a column with the `main_cap_value` that was used to cap that metric and represents the computed percentile of unit-level aggregate values.\n\n#### Metric Delay[​](#metric-delay \"Direct link to Metric Delay\")\n\nConversions within the first X hours of being put into an experiment are ignored (default = `0`). This is useful for metrics like \"day 2 retention\". In that case, if your underlying table reports whether a user is retained on any given day, you could set a metric delay to `24` hours.\n\n##### Negative metric delays[​](#negative-metric-delays \"Direct link to Negative metric delays\")\n\nThe metric delay can also be negative to include some conversions **before** a user is put into an experiment. For example, a value of `-2` would mean conversions up to 2 hours before will be included. You might be wondering when this would ever be useful.\n\nImagine the average person stays on your site for 60 seconds and your experiment can trigger at any time.\n\nIf you just look at the average time spent after the experiment, the numbers will lose a lot of meaning. A value of `20 seconds` might be horrible if it happened to someone after only 5 seconds on your site since they are staying a lot less time than average. But, that same `20 seconds` might be great if it happened to someone after 55 seconds since their visit is a lot longer than usual. Over time, these things will average out and you can eventually see patterns, but you need an enormous amount of data to get to that point.\n\nIf you set the metric delay to something negative, say `-0.5` (30 minutes), you can reduce the amount of data you need to see patterns. For example, you may see your average go from 60 seconds to 65 seconds.\n\nKeep in mind, these two things are answering slightly different questions. `How much longer do people stay after viewing the experiment?` vs `How much longer is an average session that includes the experiment?`. The first question is more direct and often a more strict test of your hypothesis, but it may not be worth the extra running time.\n\n#### Bayesian Priors[​](#bayesian-priors \"Direct link to Bayesian Priors\")\n\nYour organization can set default priors for Bayesian analyses that are used by all metrics.\n\nHowever, you can also set metric specific priors by opening the Edit Metric modal from the Metric page, clicking on Advanced Settings, and turning on the metric override. This will allow you to set a custom prior for that metric.\n\nAdditionally, you can use experiment metric overrides to further customize these priors for each experiment.\n\nYou can read more about Bayesian priors on [our statistical details page](https://docs.growthbook.io/statistics/details).\n\n## Fact Table Query Optimization[​](#fact-table-query-optimization \"Direct link to Fact Table Query Optimization\")\n\nGrowthBook Enterprise customers can enable Fact Table Query Optimization for faster, more efficient queries.\n\nIf multiple metrics from the same Fact Table are added to an experiment, they will be combined into a single SQL query. For data sourcees with usage-based billing, this can result in dramatic cost savings.\n\nThere are some restrictions that limit when this optimization can be performed:\n\n*   Ratio metrics where the numerator and denominator are part of different Fact Tables are always excluded from this optimization\n*   If `Exclude In-Progress Conversions` is set for an experiment, optimization is disabled for all metrics\n*   If you are using MySQL and a metric has percentile capping, it will be excluded from optimization\n\nIn all other cases, this optimization is enabled by default for all Enterprise customers. It can be disabled under **Settings → General → Experiment Settings**. When disabled, a separate SQL query will always be run for every individual metric.\n\n## Migrating Existing Metrics to Fact Tables[​](#migrating-existing-metrics-to-fact-tables \"Direct link to Migrating Existing Metrics to Fact Tables\")\n\nFact Tables are brand new to GrowthBook, first launching in October 2023. Eventually, we see Fact Tables completely replacing the existing way of defining metrics. Right now though, Fact Tables are still in early preview mode and there are some rough edges.\n\nIf you'd like to get an early start migrating your existing metrics, there are a few differences to be aware of:\n\n### Reusable Definitions[​](#reusable-definitions \"Direct link to Reusable Definitions\")\n\nMetric definitions have been split up into a few different reusable pieces. It's a couple more steps to create your first metric, but it should drastically simplify adding subsequent ones and building out your metric library.\n\n*   The SQL and supported user identifiers are defined in the **Fact Table**\n*   The display formatting (e.g. currency vs duration) is attached to a Fact Table **Column**\n*   Any WHERE clauses for metrics are defined as **Filters** (e.g. `device_type = 'mobile'`)\n\nOnce these pieces are in place, defining Metrics is now much easier. The form went from 13+ steps down to just 4 and no longer requires any specialized SQL or database knowledge.\n\n### Metric SQL[​](#metric-sql \"Direct link to Metric SQL\")\n\nBefore, SQL for a metric would select at most 1 numeric column and it had to be named `value`. With Fact Tables, you can have as many numeric columns as you want and there are no naming restrictions. This allows you to have 1 complex SQL definition be re-used across many related metrics.\n\nAlso, Custom aggregations are no longer supported. Fact Tables only support a few pre-defined aggregations - `COUNT` and `SUM` (we may add more in the future). Using these pre-defined aggregations greatly simplifies the queries we run and enables advanced performance and cost optimizations.\n\n### Metric Types[​](#metric-types \"Direct link to Metric Types\")\n\nMetric types have changed.\n\n*   Binomial Metrics have been renamed to **Proportion Metrics**\n*   Count, Duration, and Revenue are all now just **Mean Metrics** (the display formatting is controlled by the Fact Table columns now)\n*   Instead of just adding a denominator to any metric, there is now a dedicated type for **Ratio Metrics**.\n\n### Ratio Metrics[​](#ratio-metrics-1 \"Direct link to Ratio Metrics\")\n\nThere are a lot of changes to how Ratio Metrics are defined and how they behave.\n\nRatio metrics are now self-contained. Previously, the denominator would just be a pointer to an entirely separate metric. This allowed some weird edge cases like the denominator itself being a ratio metric with it's own denominator. With Fact Tables, you define both the numerator and denominator in one flow and these nested denominator edge cases are no longer supported.\n\nDuring analysis, Ratio metrics used to behave like a Funnel - the denominator had to happen first before the numerator. This was unintuitive for many people, so With Fact Tables, we changed them to act like true ratios - we calculate the numerator and denominator independently and then divide them. We plan to add a dedicated Funnel metric type in the future to support this use case.\n\nLastly, Ratio metrics now have a single metric window and capping behavior. Previously, this would be controlled separately for the numerator and denominator. Because of this change, only \"percentile\" capping is allowed for ratio metrics.",
    "title": "Fact Tables | GrowthBook Docs",
    "description": "Learn about defining Fact Tables and using them to create a library of Metrics",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/app/experiment-results",
    "markdown": "# Experiments (Results) | GrowthBook Docs\n\nOnce your experiment is up and running, you will be able to track how it is performing in the Experiment Results tab. This can be found on any Experiment page under the Results tab at the top.\n\nThere, you can update your analysis, configure how you want your analysis to run, and see the impact of your experiment on your metrics.\n\n## Experiment Results Table[​](#experiment-results-table \"Direct link to Experiment Results Table\")\n\nThe heart of the experiment results page is the table of results. What you will see will depend a little bit on whether you are using our Bayesian or our Frequentist engine, as well as whether your experiment has 2 variations or if it has 3+, but in either case the first two data columns will look the same, and each row will represent one comparison between baseline and variation for one metric.\n\n![Results Table](https://docs.growthbook.io/assets/images/results-table-781167fd137533b109a3d111851125bf.png)\n\nIn both engines, the first two data columns are:\n\n**Baseline** - the average value of the metric in the baseline variation; either a percentage of users in that variation (for proportion metrics) or an average value for mean or ratio metrics. **Variation** the average value of the metric in the comparison variation.\n\nFor both columns, the raw data in grey underneath shows the numerator and denominator totals.\n\n### Bayesian Engine[​](#bayesian-engine \"Direct link to Bayesian Engine\")\n\n**Chance to Win** tells you the probability that the variation is better. Anything above 95% (a customizable threshold set at the organization level) is highlighted green indicating a very clear winner. Anything below 5% is highlighted red, indicating a very clear loser. Anything in between is grayed out indicating it's inconclusive. If that's the case, there's either no measurable difference or you haven't gathered enough data yet.\n\nFurthermore, we include tooltips for **Risk**, which captures the average loss in a metric if the variation were actually to be worse than control. We use this tooltip to let you know about \"risky\" cases. For example, in cases like in the screenshot above, the chance to win is above 50% for a few metrics, but the average loss if the baseline was actually better is above the risk threshold, indicating that shipping the variation still has substantial risk. More information about risk is available in a tooltip when you mouseover the result:\n\n![Results Tooltip](https://docs.growthbook.io/images/results-tooltip.png)\n\nThe graph and the **% Change** column show you how much better/worse the variation is compared to the baseline. It is a probability density graph and the thicker the area, the more likely the true percent change will be there. As you collect more data, the tails of the graphs will shorten, indicating more certainty around the estimates.\n\n### Frequentist Engine[​](#frequentist-engine \"Direct link to Frequentist Engine\")\n\nIf you select the \"Frequentist\" engine, when you navigate to the results tab to view and update the results, you will see the following results table:\n\n![Results Table (Frequentist)](https://docs.growthbook.io/assets/images/results-table-frequentist-e1b1ec1e35beb85d08b660b7d6766c3d.png)\n\nThe **P-value** column is the probability that the experiment effect for a varitopm would have been observed if the true effect was zero. When the p-value is less than 0.05 (a customizable threshold set at the organization level) and the experiment effect is in the preferred direction, we highlight the cell green, indicating it is a clear winner. When the p-value is less than 0.05 and the experiment effect is _opposite_ the preferred direction, we highlight the cell red, indicating the variant is a clear loser on this metric.\n\nThe graph now represents a 95% confidence interval (or 100\\*(1 - α\\\\alpha)% confidence interval if you have a custom significance threshold other than 0.05).\n\nThe _% Change_ column is unaffected, although we now also represent the width of the confidence interval in grey.\n\n## Guardrails[​](#guardrails \"Direct link to Guardrails\")\n\nIn the new results view (as of GrowthBook 2.4), guardrail metrics are treated much like regular metrics, but they are placed in a separate part of the results view, have an additional tooltip warning if they are trending in the wrong direction, and are not part of any p-value corrections in the frequentist engine (in other words, even with p-value corrections applied, these results will be more sensitive to negative or positive trends).\n\n## Results Table Settings[​](#results-table-settings \"Direct link to Results Table Settings\")\n\nThere are several settings at the top of the results table that allow you to control your results.\n\n### Variations[​](#variations \"Direct link to Variations\")\n\nThis option allows you to filter which variations are shown in the results table, in the case that you have 3+ variations in your experiment.\n\n### Baseline Variation[​](#baseline-variation \"Direct link to Baseline Variation\")\n\nThis option allows you to change which variation is the baseline variation. This is particularly useful in the case when you have one control and two treatment variations. In this case, our result defaults to showing you the statistics comparing each treatment variation versus the baseline variation, but you may want to additionally analyze how the treatment variations compare to one another.\n\nIn that case, you can switch the baseline to be one of the treatment variations to directly compare treatment 1 to treatment 2.\n\n### Difference Types[​](#difference-types \"Direct link to Difference Types\")\n\nA \"difference type\" is the way we measure the difference in variations. There are three difference types that you can select from\"\n\n*   `Relative` - The default, this is the relative change or \"uplift\" of your variation when compared to the baseline. Specifically, the `Relative` change is 100%∗μt−μcμc100\\\\% \\* \\\\frac{\\\\mu\\_t - \\\\mu\\_c}{\\\\mu\\_c} where mutmu\\_t and μc\\\\mu\\_c are the averages in the treatment and baseline variations respectively. Effects here tell you that the average user value in the variation was X% greater than the average user value in treatment. For example, if your metric is Revenue and your baseline average is 10.00 and your variation average is 10.31, then your `Relative` change is 3.1%.\n*   `Absolute` - This is simply the difference in average values across your variations --- μt−μc\\\\mu\\_t - \\\\mu\\_c. This can help you understand the raw difference in average values, e.g. the treatment leads to an increase in revenue of $0.31 per user in the above example.\n*   `Scaled Impact` - This helps you understand the daily total (as opposed to average) effect that your experiment would have had if 100% of users that would have been exposed to your treatment variation had gotten that treatment variation. It is computed as (μt−μc)∗(Nt/pt)∗(1/d)(\\\\mu\\_t - \\\\mu\\_c) \\* (N\\_t / p\\_t) \\* (1 / d), where NtN\\_t is the number of users that are in your treatment variation, ptp\\_t is the percent of all traffic that is in that variation, and dd is the number of days in the current phase used for the results. So if your experiment ran on 10% of traffic for 20 days, with 5% going to the treatment variation, and there were 5,000 users in your treatment variation, the scaled impact would be 0.31∗5,000/0.05/20\\=1,5500.31 \\* 5,000 / 0.05 / 20 = 1,550 dollars per day. This implies that this experiment would have lead to a 1,5501,550 increase in total revenue per day if every user that could have been exposed the variation had been exposed to the variation.\n\nThese difference types can have slightly different statistics because for Relative effects we need to account for the uncertainty in estimating μc\\\\mu\\_c (which forces us to use a delta method derived variance to properly handle). For more details, see the [Statistical Details](https://docs.growthbook.io/statistics/details).\n\nFurthermore, with CUPED enabled, you may find that the changes are not exactly the same as the difference in raw variation averages, due to CUPED adjusting those averages under the hood to reduce variance.\n\n### Dimensions[​](#dimensions \"Direct link to Dimensions\")\n\nDimensions allow you to slice and dice your data, but require additional queries to compute.\n\n#### User or Experiment[​](#user-or-experiment \"Direct link to User or Experiment\")\n\nIf you have defined dimensions for your data source, you can use the **Dimension** dropdown to drill down into your results. For SQL integrations (e.g. non-MixPanel) GrowthBook enforces one dimension per user to prevent statistical bias and to simplify analyses. For more on how GrowthBook picks a dimension when more than one are present for a user, see the [Dimensions documentation](https://docs.growthbook.io/app/dimensions). This is very useful for debugging (e.g. if Safari is down, but the other browsers are fine, you may have an implementation bug) or for better understanding your experiment effects.\n\nBe careful. The more metrics and dimensions you look at, the more likely you are to see a false positive. If you find something that looks surprising, it's often worth a dedicated follow-up experiment to verify that it's real.\n\n#### Date[​](#date \"Direct link to Date\")\n\nThe date dimension shows a time series of the count of users _first_ exposed to an experiment, as well as effects when comparing users _first_ bucketed on each day.\n\nTake the following results, for example.\n\n![Experiment Date Results](https://docs.growthbook.io/images/experiment-date-results.png)\n\nIn the first graph, we see the number of users who were first exposed to the experiment on that day.\n\nIn the second graph, we see the uplift for the two variations relative to the control _for all users first bucketed on that day_. That means that the values on October 7 show that users first exposed to the experiment on October 7 had X% uplift relative to control, when pooling all of the data in their relevant metric window. It does not mean show the difference in conversions across variations on October 7 for all previously bucketed users.\n\nThat analysis, and other time series analyses, are on GrowthBook's roadmap.\n\n## Experiment Health[​](#experiment-health \"Direct link to Experiment Health\")\n\nBy default, GrowthBook runs several health checks on your experiment to help you diagnose if there are any issues with the configuration.\n\nHealth checks appear in two places in the app:\n\n1.  On the results tab -- we insert Experiment Balance and Multiple Exposures warnings for all experiments that might be untrustworthy right into your results tab\n2.  On the health tab -- if you have health traffic queries enabled, we can run additional queries to further dig into any experiment health issues\n\n### Experiment Balance (SRM)[​](#experiment-balance-srm \"Direct link to Experiment Balance (SRM)\")\n\nEvery experiment automatically checks for a Sample Ratio Mismatch (SRM) and will warn you if found. This happens when you expect a certain traffic split (e.g. 50/50) but you see something significantly different (e.g. 46/54). We only show this warning if the p-value is less than `0.001` (customizable in your Organization Settings), which means it's extremely unlikely to occur by chance.\n\n![SRM Warning](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA74AAACACAMAAAAbOEVzAAABMlBMVEX/883///+FZAX/7roCe///8syHZguJaRCihj/hzp/+8cunikXv37SLaxWaezDn1aj88MnCqnCggzuegDeTdCXr26+VdimymFjq2a2+pmr468P36sHt3LGcfjOqjkvz5ru5oGOkiEKvlVPfzZzNt4C8pGePbx3Ru4fXw5HIsXjj0aKojUj67cXUwIzLtX7778f26L/Gr3aYeSyNbRnbyJbdypmskk+0m1uRcSHKs3vx4bbWwo7o16rSvonPuYLz47nl06Vzpu/25r7Pu4a3nV/ErHPAqGyQtujZxZPezJuTdCNam/TV3NkYf/327tA0ifrK1tskg/zC0d1OlfVCkPf/8caIsuuhwOUMff6Xuudro/CpxOPt6dNkoPHk5NR9rOy1yuDe4db/+un/99//77//7ryt7HuRAAAhPElEQVR42uzXsQ3DMBAEQRrK1N83QFL9t+DcoBz/ATM9bLDjA4SSL8SSL8T6zXfVBTRV60++c9c9gKbu2vMt3/nUABqrZ77ku9ULzdU+57vUC+3VOubre6G/u475XgNo75IvpJIvxJIvxJIvxJIvxJIvxJIvxJIvxJIvxJIvxJIvxJIvxJIvxJIvxJIvxJIvxJIvxJIvxJIvxJIvxJIvxJIvfNk5z+7EcSgM6+gcGzAYjAndpgUzJLQQakgoh5TD5P//oNVVje14mQw7u0mW98NgX9kqV3pUnfmyOuN71llfVmd8zzrry+rb4Jt/ufydV8466wvrdHy3W3SSrpPJ5AM6VdUYxrNTXzldQ1IYLSqkLK5H+RH6mFLJZC/CzwuI+M8pQUpUQv+YnpJJ7/RnVfCHpa0c64hZGT69TsPXuEp2MO4kxwb6bXUxxpGjYDFOlWys8+hvNSOxRLbiSxJFsy/uHIgxFfHKiWqQON/1hRPDeIdApaKrYz1dzLA+JM5UezlslWEnHdwjd11y0cJ4jt7VLcZN9Oc0wBgn3vEoMZOsFTclDX1EafLa6c+q4A/KKeqQ8Z8R5mhDdUFK+/kmayfhW01irvj+z+B7i6We3sNiYNt2Ci6sW2xGDhL3mOiHuCvD3YN45feUJ+l2P4JvE+MWy0sMM8VohupYSleGouqViO7IxUrHePoRfOO2/RK0RTnw4/jeY6ne6Ovg+1M4/znCHGl4hbsB+mw6Bd9+ARO9LuHfgvGn8cU1Kxx+RexsXDYuK+hv8FVVbSw5vuqVjytDomh/AN97zCfqG0ruLW0ej4xWpbEwmCJjLYEvSoKPP4BvjPcX0VIOPAlf3Ox/FXzz4Hbzgvo+2hw2jEi1fj9876DvrSNUn0Pj/FP4vjqOMy2CQ6cfaX3hxpZSAxrgS/Vv4VvDeAl2q4OxOdCQ1p1gbHNa56SEP+hEpip4/iGX54CvxOhT4es9PCTuOuTi5avg28MYZyvGgfimU4k0hw0uuV9+O3yB2jpcWEvRVi6z81xrzKr7h+c9o9Q4mXweIZRqxGtXKzAnPM+70daL5OKg+fHdZmu5ZCMTaJsFCbnHusarol0r3wMMUy8OM02vjFCdxLpDoPq4losXu1YQX9HKWhxf9Yo1KCfjT+0tzQMxZrTuk128Rkh7nNuNLkLBdPNekUSR9DxaoBTJdu15pkl89+158+XaN0+JYfwEFyXML9CQXDmM1oUkf8oMsl22scS3ojMHKD00eq2rvsK3v5nb8eKU9hKeRx6/9bxEICCQX+VAUKaRJAFbked2q9e4/ht812xNH4RoRjyYp24tex4MXsag3LMXd85b5u48r00TIQ/PIiqfPVsdz2sevBssicK3v27Z9nxYRaxOr3m8CUi7zOMXznc17uohijKHDSY2HwffDl/opPZslKjX9/DTwkwvGhtxXrcduE33uzE6z07x/r5kY1DLh+9PXU4hw/gaJIIc/I75Uz1SW55YRoLL+XCYiDGbXQnie6GpAQ0/qFdWNqaaTPmw+ljGoEcrzrEPpjvFXEB/lwe0RrzCq2kMukdKB9Had+SiQU1WvV4fvcX3GjooZqBkg3IKX+RSVyhtMGjpCHy3FzyDFkJ9OR0PBATyqxxIlOXXDNYKW7d4R/CFWtZ9q9+EcFmCZb2Uw1Rm9w1zLkdvD+NcuPIVvpkONXdRsIgK33qBWTt54lWTdY+XUEBO4kHONEREe5JYDUWZwwbTTqHvh+8zUFIK8IwpHllWsRNedcUJ+81x58Qx09UbfHcmIIQpU2F8t9Ajkt+xTKL5Lr4ZUy7JRm8bW4yA9ZMPaGUfvtorZIxmNMPwbXKci5hp6k/Xj+9MFze2BvjKwul5JPUkpqhWjAQM+ypE4TsAspmhzACAHM4LAt8FhVpqx9N1lwzfmzQgAjlsaT58fQH+/PrwbVME4FkYArUaD0oewfeJLUuUtCWrZ/RCQrZoNAFf0EQTEfiGKl/he8vRNPOBIsqowMq1JPmoscSzcAszQJJ2FXFBkVYIRGI1UZQ5bBga6Bviu8Og26fHOrt3oOXtrUSHubAGLhxkyrR9tDOP4PcKwxfn2ocFVOuDxLfaIaSW0L4IVITxHbPu1LjAuJnSSkBYFe0dD+hyHMnifkIibe8zLegzfPhm+GCfw7EHH7471kFvl5SeDAaerqd07OldJqAQXjDdvgPNN+s4I7SNkbjXNzvI9jXDVx/vrgr+hlgjD2lverheNmEE8U3CK8xw3cGv5HGgaybxbfs4op1O/PEeCkrxbZJop9aoTTtFzYFJbc9xbgIB/vwqB7KxsrZFjkswGrGx3SzPxhf4CL42YV7zhUGUN2zqEKcR6YN+ZQ1+jMA3qvIpl4tDG7pWN1BEFZUN3Z6zgrGkYMGaRLfgUSKH1oeNhCAeC4Ggh+1HmN997jviix4xV7xtQF3sdjtxMlNl+CZ4i93wwTrB8L2t8GoeSnxnfICy0nTMUPguM5lMtxVjT41IEn3Enj6onRfJ4pDPv0Yu63YVvsjFsQp9rrXy4XsHgwTk3nFWfPTV2G/BIhHB2i6Urtq66vLCWQVKf4M3rUtKpVROTnyrLmbqPJUEvjVSwk0TeKkyQ4ZNFYwlXhoS34Ov/TjQpGF+UWT4ViBDfDRMqq2rQEAov8qBZZJFKOFWpwS1eGql2N/j+wOHDqQzbOVww1Jydrs8x9yNwDeq8tMc+WoBOn5/SWRU0Bf3ND47maI8uA8mObd019jm8xgxli7V/scqwhwyfFt80TSJueaWsGlVwJfNY0yNT6Ic3v4O0GBotbIF2kLim4UaBMVhvaHwVbqTVq3yk+7OhvGt0Z6DBxx8+BJMN2xA8+ObAFDHO57/DOffEEtzF2M3lK7Ctyz653qplGL4OnyS3ERSFzAfYbrxlpjJTAQOjibCkHmgiU/hsxKJb8K339IV67Mt4MtCp+C+LHhd4hsMCOZXOTBOspgHgadpsdMItIjEt5DNNuLiPKVhMw0YDwv6iH6DuKybHMYXEfhGVX5a5LUNU4VASURUd8IRGbb4WELFXBNbDBehGlTmIaiA1EIkwhwyfF98EaoPWwUMemK7jnETbgS+r2KJXIfdCYXvTnR7tsS3h5U67+BrzpillO0tdYwj8M2Jl6dw78N3r5PUjA5eGn58LdYF6c1NVWxdISIokhw1VLpBfMnLF8GDo/CpRgzGCyHjpxeP0Tn0yodvOoUEvjBVqMLOfl7hW/Id0TzLhjWh+I7xG+UlvsGAQH6VAw0TK7WQpcO/oLuj575DMDRVHwv99Stt+j1K7uPCheJG4xuufLX2lbt67UBJRFQe3IhpxpzORhbkUb3SxBdQTTELCcGMTJMLlWqEOWT4zviCnAWm/ZX1hKmO4+vIKaXAF26UjDf4TrLZF10e1G1oS4jAN1DjQx++kJ88HdD8+KJRY4KpLpxofFW6Cl9ehvRxfM3g2eyoC2vXNaPVzWYXGABX+MJU4Qb6G4XvA7R0X0J71gmKXTylS4lvMIDnN4xvBSvBcY3cIV8fwdd9REF8SzTOCza93to8JBrfqMpPi4VrHqZEgZKIqJ7E6aWmU3zXUF89bEOzW22EVyWMddGsdC3CHDJ8d3yRcQsFpk2hdZ9JjY/i26X+NjGuSXwXhOUboeDW1ROtZY6N3d45iQh8m8TfhliW7/z4Hgi6MKD58QVZ0xfa/OwofFW6QXwXsCl1FN8CROLXABKQW1daGihR+MJUYQhJKHwvZXZF+RJiCdJk0aWE+yyJbzCA5zeML3i6KB6rILQUHU45El97s9nMxBjWvWPK8PHszsGw18CWUN7sYdXz48sdsoKKDVW+wteUK4VDoCQiqqzIXwoYp/7TKyZ+gQ58vYCdCKkX8ShsaNgR5rDhm+Jbee10PLX3XkFNXtjyUXyL8oBQ4AvtMSb73SC+sF9q7llcJrSY2Rt8MxJfxvmOY6WP/PhaHWzCgBbGF7RNkzf6EfiG0s2ItfgG4qIcFIt3kfja3BXoudNZbuUi2xP4Mi/YCl9wXgcm0ApfIKbr2/Uv86YNoDls51spRvtGf0A4v8qBLYyT/jNAEyrNyB3ZeQ6KT9h7Q4znnIAX6gIfvnE+K50CvlGVnxZZL0KD8pdERnUP1Aq+EsxM0v4JR8ALlxcWyRlZTSwIniPMIcN3xZcehxzElwC31HFpjdBxcRRf3LZQHqaP9xLfEp+uGQvXXQTwZVg02K++QmiU5BgNWfX79qFci/3mkA9fPo/cBPEtN5vzPhvhl1oEvqF04d2kIaYDFh+1I/Gdw3GGmAHX9uKvPQYKX80F7yh8D/yzFoXvla/19jF4z0CZCcMXkV97BB5xXfiFe7OCggHB/CoHDnnvsI+7LngFot2jfgNzKjI9d/Cr+KaIv21auWiPxXcUPnwbAMYI7V1IPlz5Ct/XPLLoIZYWKImIqm+SQIcktIQhhEXdgY4Y9bCp+w61jDRravUO23fQXm6L9ZA5aAjha6DPo1PwBfCw2yq6WLVd+/mpc3zta2KzgIGwkcCXDZzN5xeIrBvCtx4DftjDhXI5LdagM7i47UkWNVhEdopNnTj+MogvsBOrBvGFeokPp2X6XWMEvqF0RxjSSeaR1oLTbZZgJRLfspzKu1D65KI3gQgtiS/jNW1IfC3w4uwtvpDQ3h8lnlwQtzB8B/C+N+6JRasNhW0OAgHB/CoHVnLEMr/ySLomcTT/XE7HOsc3znx3HF+RODZHYmNoPm7pfnwfae7jJpizUZWfpoUrmHRNHSiiimoNBa21TDEKT8VHp1esBxQShW3SvJR5l1IOmYOGIL73k+bnAfgUfLWxjrl0aPKlDgaZi6P4HmIYNFkhiS80LK6X4OSZj5xF1shAnsAo7f/qSsWiT1EQX+RCdQbxtWqYK7eKwDecLkzOGZJWDzOZ0+i1r9pIc1wsZNd9n23kIGqJLxT4VeP4qn16JS2Jqcbio8k25mpacLtmoYGAYH6VA9XXS/oMAhKsbpdDji/MlZxfxXeoyFmzeNymD9++zbcBAd+oyodnG2IvPFxECFZWiVpFdAkZzOtSaez767VHiDhkDhhC+MZhEvRZdNrW1bWr0wrP7fgfwsNaf7c5im9qZ2N40vfNs1XuUIhm6B189ybbY6m0JqQdrB2B0bZR0PFE4YsMFos9RWF8hzCghde+m1udDq4WisI3nG5/nDaxnpEb12Yzj6Lx1Tq8oah97mXDQj58ZzA+WRLfB9ocFb5bBqNStQj78UNN4It+UP4u2gZvbzZJaBgICORXORCu6Lcx+pxD2oX9yJ4jlpRDHc/Rr+Jbx+oPxA5poKTe8uGL9kmS2OQH3XkOV77C1xqbpPKe+ihUROXiNbUWxCZVHHIszsJWyKd1gfZcLxb/rHtyHTIHDCF81zH78/w3HKfuPI8e1oOSKo6Vr6IjumJwV0vhJy0nURodHfOdesAQeMVwEpk6+pCs0q7y4XTRSJPZdjQUKbFB3Rc329nm5x4F9fG/7Bvlt/5kV9c7n1MtIxyg8ht2YL+USBlvICz1kdLeQb+pSn70ns93eetXKl9LOVZEEaW2u+uUhn5Fxm69uayIqDOjkDnKoDRCn0dR+P4ZKXz/Z8rQ0eoEsZPSs8464/uvi387f4J29E+YzjrrjO9/oOrypGNDLQebOmed9V/ju3t+fq6i/50Sz8+P6Le1Ik77TGuusz6Hvs1/037WWf8/nfE966wvqzO+Z531ZXXG96yzvqzO+J71F3tn2pVGEoXhe97TNNqAbAoCgiwT3BCDiOKeuMZ9PdFEjfr//8Rwq7otu0uSzkxmojM8H4KVLqrq3rpPepEZerxZevr26PFm6enbo8ebpadvjx5vlp6+PXq8WXr69ujxZunp26PHm6Wnb48eb5aevj16vFl6+vbo8Wb5LfrmMpnArx5tY2EnoI2sdXvVNDJh8s1olv4C0cwa/Ygvn7+RPx4+n+vN7vjpm51+l/5A/x4jmQnyyXI5yn9mKvR6+Dv6DvcJQpnxDfopwoBPk/yP1gAm3SPr3V65voPoJ39sTrWBgfQK/Sxj6KMfcWKckj8+Grt6szs++uaSANbo36OFFPkjFkGIiNKI0+vh7+g7CYfm5F/Rd67w7tfp2x/Zz/0j+i4VCjPkm0ZhjH6WdCH6U/rOpDnlQSA4/RPL+uf0/XJ3o5oa53ef/eu7g3Z9JEf/Hrq+XQuzgIn/mL5mtEP/2gCC/X9B3z+Q/HX6Utaif0TfIaBGvplHhn6WKuZ+St80gvUNsoYKQMv/sv45fb8an1VT48q48K/vFHboX0XXt3th5ui/pi8JYgkUfru+RP8TfWMRfHImK//H9E2hRT74PfrSf1RfaqEZkI6sNlZHyMYaXq3352TXinytVfodk8KVImYrlRV3T8VMdKzenyUmV5kkK7r4SXRt1RfnYrqXWTUycasyKt45PrE2+azbKPcSrFRGnmaqVEiwLlYTrgx1ZquvDsupN4G5Sr9ahCsYT5zRSh/KlcqS0yVQqVhyOXIR0c3G6hC5Y6pUImhUKlmpb26uPimi+1BZJ7JDsTwVF7Hjj4YKFnnC1FOkliX1DQz/sbyujm1OLL/X9L09vzo9Jpvbhy83yuhv51cPj88cPDw/ML6en3+TzePTq/NbYpze98bl+fmhyMbjg31Q9rXOr24OSRGrVNqYqFTEcrLji/W5GWf9o7Sx3NggUu3ceF1EHF1bW+EkePPLu1jba0S19DCyVCc+ZVlfT9JUYTLrrcXlkYBdMetSX7Xpv/3/2fZr9F0CWAYr/fyb9odnuRH84/mJZRhBx6QdCAqunoq9fTAN6tCPwfcp2bV/EB3ae5q+UTSVvrU+TPHW1yPokF93uvEfYWICbXzSzst1TBFRHOmRKjqka0QVCCJqEa5gPHH2QbBIBYhgPkB23RQDjybAhLLPY7IgiYpxJ8RQHF0aaedUkPemHTlSeMLUU6SWJfTdEMud4j1ylhRsePT9cm0YxtE5Ca6OjA6X34g5vjdUS+h7YQiuRPNU9P1CT+wagjsiepQ9vx7bbz285OYBNyU5SFpPITWn7fWPOd+E6LQ3RRDZXIFfkzIfKr9yFyeDwKI7PYotdKiusr7upD0vzOwCmIEleWFfV/pqJeubV6jvB1lRRUTmG/NNLIiLzgimNsfSQUy8rG9/fArteHza3dOhBfRl4kkgLkq9WgqWinWikSby7zJJRIa768v2yn9CxmGWtrcGkc8+HerjSeSQsa76llL5zEQBeEcUjm8BmXhDLcIVjCfOsfgAEvH4B/pDXtZuQ97LpXnns0lUy435CEKxZzEF4vEgyvH4KI+bDhYaO7MIRvm4fY4tYZFczAQxP0MKd5h6itSyWN98cra4mIZc30wC7YXtkIlVl74fj+6+7F4aR4fcfDCuD3bvT4xL4dmFcfbxy9cz4+TW0fem0/Nid/eUm3dnF7tfDgzjhhxOd++Mk93dB6LbI+Py/svBkXEg9f14dvaRm3cqsHi8iXQ8PkK0CiR33uVh7kld583ZdHFJ6ZuOzE+kTaSnIml+DRF58xtHX7s6X2y50qNoAMl4MYUiUt6kqcKkBKrpiXIT7VG3vnrJ+ucV6ruAWXGeiAzJVHDB7WBelA4GLV1fde/r6emQQFFmeVCUOmbF3uVmsSX/6RzMdtWX7S3zSNEgeA9qSRSeum3acxZRpK76osztBsysuvdVi3AF41q9uskMoy2iCAaT8h0jRCHM8njrbSyo4dz3vib/MJPntQUG5d9umOaG/vW57Xf90mB3mFqK9HtflPiN00BO/HWSY1uGGX2u7/U5n2cvjXsiOjwyHrh1ITw7N84euXXGhur3vvKHe+PyhXvfXePimH02jG+y7+WxHH6XFCkIX/tNrInKkBXVZ1+FKX3NT8ReorkigjFr5M1vHJif0dLjsAd5eZQGUt6kqcLcQ3OEN6SJMbe+esn657XpGxvagsjQAMaJWUaCs2mnPJsNfE9fb09G/bxhIixK/YN9nslb9je1trrqWyshHXiu6ChQc7plgwjLa+dod32DMW7NmIi69f1Amr7u1StPZlnYnDk/jw2iJa6RDedrEioIWmo4l74LtmMJUSFpbqxhirxMBAGYfWs50sLUUqTpu27PtSeWNEqybDOusy8xN8K7+47EzO319THR8fExMffcR9f3hJhvBnd168tvtYi5tM0/erQPn+j6bqFMTKCEhtA1RG5958XRqozcCmJSy28ckZieHoe0PUFtFilvXanCjGVn7CHSLn31kvXPa9L3iR1OhXNPti7yl0G1Zcf2A31VT502JsWFpGX3fOec7re76duxd0uOlsAnsl1Sn+goY0IsfYC665twamncpW/E0oJxVq95UsQaV8XmJqaJVrFFNOdMGYhgWA6n6btp5zXCFzGy/kpYJo3cWsJkg+NamJ4U6fq2SRDCIlELeRJMo/Rc3xtiTo0zcbV8rj2QZrUPXtJXeh+4Ng51fRnZ+4voe0G268axpm/SCXoR80LXBinUHVAS03bgc1p+45givQoc8s4E75DS6kp78ryGkEdf3vTX8CGgv6mv2QFIRe1mSAKsEI0OAO3y2vsf6evqqaj1N8pTiQFIfQedooMzQ6Gbvn1AlpgYMOD0XnyatIWksKvxHX3TJEh69B0kXV+1ercncyhzMYyu82ALXEHbKJMkgTExXLdfHK0gIrvN8eVHZIZ0OD+ZNpDRwnSlqPsvjubZgG2nbxtN/RdHh8YRkWUYlwcCw7gSuj3c3x1cGrq+sik4e1HfwOHVR36rre89OZ1PvfrGTAyRoIVB+aiKFKrNG8QMYE7Lr9xFLT0SNcEYUnpdKX3D08X5UhKavnrJ+uf16GvyyyrMsHyFKZG3Ju8bAwDMcvb7+rp7OgzLL1gddOubcqYAkl30ZQrCxiUAznrePU1qtRHma+f1X6KvZ/XKk5q5T7SfJ8pXA5Qys+xw8cmluB99/+B1rGGBulGbh1nzhqmnqLu+C6qvmXtRXz45GtcC47ojaeCz0eHo7C/oe3sg3noi9FV96dJ48OjLIeXITjEsX/pq+eVd1KuAcU2wh5S3rlRhWhnwu6u6vnrJ+ueV6RvIy1uRKNrkYWk1BCTFvW9FVqZHX72nJBfB/OSGRdR26VvAGrnR9d2OBhG3L6JGSJc0gwmaRMl9xCJm0ae+KhjP6pUnVEJ4GDs8XXQdJXtwSR7jfvTNBSMxCnH83cgBeypMPUU/0ncRZXKh6csqPpJi1zi7eTwmuvl5fS+My/Nvx+ri+SsJAkfc2aUvhxQlwTgGyJe+Wn55F/UqYFwT1JHSk6aeqVY3R2raxbNr09/yva9JTAuYlFcko6TRAlY4wcvEfPLoq/d0tq0pnMmaLn23sfVDfQO0CnySBk2/oO8wklTEKik2gA1iin70dQXjXb3SdwJji5jkJDWm0eBsiffLPC350JfHmtswU1p9bJc/kcSKYFyFqVLkV99+zP5Q3wPjgRSXHfeYzz+t761hD3th63tJgkfjyPLoyyGNOdGk/emr5VfsolYFaoRNEmwh5SRN13cADWIymr56yfrntelLJSQCIpvbxGTr9RmqjY1l5eNBLsoydohZeK7vGqr84u4padgJXIZL3zm0R4mp1Pu76ssaRoZk1i1iVuthpS8lEd6P1OgZbVk01uxL+o4Awy59XcF4V1/GvHPZlw41LSKr2bcl9rgG2/pFVOVwavq6pq+MNr1mF4tFijoGbKX3gCF3mF1SJJal65uFPeNQfbqLviyqnO3m6pFPleci2Eu3vl+/o++NcWaPdivuna9tfXkk22NN3wySM/yaS6HuT18tv3IXtSqwKSIvJgg3kfLUlSrMQARz8nm0W19t0wMB8s0r1DcK8Pa3TKzFiEanUBKXMAVLpsLic1GTHdjEc31bwBx5e0qi8lAr4tY3VkJyna0O4nv6Wn3iV4BLbSx0XmYyiGRdd7hBsbWKKSRyRLUtaPpK7TIxl2+uYDyrz6AZtqVsBsvCHLPaFhPHEekPkDVuYs2tbwKl3Ev6WlU0IUZ7F8zQE+9NTIWF3lWW0RVmlxSJZen60g6ak5y7FLa76fvtxLjn3xh9Ns46L3fGBTfuXPe+nUPfuut7LkW1zozPgc5wT4+ujs5OiY6v+Kim79I+0jmi0RAGcv701fIrd1FLDyO15QnC+SBS3rpShTmFvhpRrQC3vt5NH0qlRsg/r05fKiM1Yxd0KRnE4BIXVxCRwkISJl+m5AZgJqYGMfFc31wVGCx6ekoCfUCqsI+dqtKXyeaB2dAgOIfd9aWNffH4aiUCM9HXRLClDonfJaNCz4lG0CyVmtXMS/pSCGgm1CLcwXhXPwlgYFWemyFeV+GMtwBUQxFeu1vfBmDmh3R9qQhpW8xEMEZPzDVhzham2kDfBpEnTD1FalmavoE0L2kACM1005c/WHF9cXAmP0N5fmQcHVwcnew+1/eUP0V5003f2zPDOLkXH588u+ucte9sfT9fGCcHRyyzri8NR4BEHthfJ3/6avmVu+hJj2LPhJkYQHUTKW/SVGG2TARDiWB7R9PXtelxYJv88hr1DZvyLmFsFkCkOErMUCkIRPqixKxzXveXXU+e6UPCRMHbUxLbagLNxUDbrS+tl00AyU/0XX0pGsQOr7AEwCysqG5MAfsBctGfNIFEVH/yLKeMIKIW4Q5GW/3qLLBoX/eLPGzAufmydqoA9ifIo28sUwWimr78A9aI2TKL9IwwzwhUi+y0J0w9RWpZXn156iYvaTFGXfWl0wN++nx3KBuX14Zx8KgeXTE3J9fGVTd96fTiWnxi6+qkM8z9sfPoavf2/rpj9C5p+jIfOCQUhsi/viq/Sl9vehTjXKpTIy2ktKSpwpzMAwiNaI+u3Js+3N4fIt+8Gn1fIDAaXQ+oVnhENaxhdUT1eG/pPSWBkTAf05gZGa6Rb3IrIzHyUEaGvNRW3n9vlBmS6MHoq4+9txs61pJIj04tSy8whGCOBNr8Q9OtUT1MPUX6svQleSLXuT18VFtxfHhLGse3362KW8se59j9LjWuTnZ4yM8+6/n1WQWB9ZWsVldaYWZXcuRB33TLIt+8an3fAsNmcJTeBGUUqUePnr4OVng8/zak2IjuILhOPXr09HXIAej77f+VtR+KQHCaevzJfh3bIAwDUBA1oktFB4yABDUVY3iBxNl/BUQTK1IG8Efv7XDFId/N83r/XEqC1/txKyBf+EvyhVjyhVjyhVjyhVjyhVjyhVjyhVjyhVjyhVjyhVjyhVjyhVjyhVjyhVjyhVjyhVjyhVjyhVjyhVjyhVjH+dapAIOb6mG+Sy3A4Oqyy3fT9AuDq+10nO+86heGVtd5n283N/8L45pq6/X2fPv/noFB/b53ly8QSr4QS74QS77fjYJRMGQBAHcYu0IZxeCKAAAAAElFTkSuQmCC)\n\nLike the warning says, you shouldn't trust the results since they are likely misleading. Instead, find and fix the source of the bug and restart the experiment. You can find more information about potential sources of the problems in our [troubleshooting guide](https://docs.growthbook.io/kb/experiments/troubleshooting-experiments).\n\nUnder the hood, we are conducting a standard chi-squared test for Sample Ratio Mismatch, which compares the distribution of observed units to the expected units and computes a p-value for the probability of observing this traffic split if the traffic split were truly unbiased.\n\n### Multiple Exposures[​](#multiple-exposures \"Direct link to Multiple Exposures\")\n\nThis alert indicates that there a substantial number of users (or other unit) in your experiment that have been exposed to multiple variations. At its core, this means that your Experiment Assignment Query is returning data that has rows that look like the following:\n\n| user\\_id | timestamp | experiment\\_id | variation\\_id |\n| --- | --- | --- | --- |\n| 123 | 2022-08-23-10:53:04 | my-button-test | 0   |\n| 123 | 2022-08-23 10:53:06 | my-button-test | 1   |\n\nThis indicates that for some reason your identifier type (in this case `user_id`) is being tracked with multiple values of `variation_id` and it is impossible to tell which variation to assign to that user. This can happen if:\n\n*   Your SDK is misaligned with GrowthBook's identifier types for some reason. For example, it's possible that the identifier type you're using as the hash attribute in the SDK is different from the one you're firing in the `trackingCallback` to your warehouse. Ensure that the id you're using to hash users is the same one that you see in your data warehouse for a given user.\n*   If you're using something other than GrowthBook for experiment assignment, there are many possible reasons for this issue:\n    *   A bug with the third party solution's hashing algorithm\n    *   A mismatch between the identifier type that you have set up in GrowthBook and the ID that is being used to assign variations in that third-party solution\n    *   A mistaken in your Experiment Assignment Query that is returning the wrong `variation_id` or identifier type for a given experiment.\n\n### Health Tab[​](#health-tab \"Direct link to Health Tab\")\n\ntip\n\nTo get access to the health tab, you need to enable us to run one additional query per experiment analysis. You can do this on a health tab for any experiment if you have the requisite permissions to run queries.\n\nThe health tab provides you with more insights on the traffic to your experiment over time and across dimensions.\n\n![Experiment Health Tab](https://docs.growthbook.io/images/health-tab.png)\n\n**Experiment Traffic** - A plot of experiment units by the first date they were exposed to the experiment. You can look at daily traffic or cumulative traffic. If you have your experiment dimensions configured with pre-defined slices, we will also return traffic splits by dimension in this tab. For example, if you have a `browser` dimension with pre-defined slices, we will show you the traffic splits by browser.\n\n**Experiment Balance Check** - A table with information on the actual number of experiment units, the expected number, and the differences between the percent traffic allocated to each bucket.\n\nWe also provide you with checks by any pre-defined dimension slices you have configured for your experiment dimensions.\n\n#### Adding Dimensions to Health Tab[​](#adding-dimensions-to-health-tab \"Direct link to Adding Dimensions to Health Tab\")\n\nYour health tab shows dimension breakdowns only for Experiment Dimensions which have pre-defined slices.\n\nWhen setting up the health tab, you will be prompted to configure your Experiment Dimensions to have pre-defined slices that can be used in the health tab. This is optional, but we require pre-defined slices for your experiment dimensions to compute dimension traffic and health checks so that we can run only one additional query per analysis and get reliable results.\n\nIf you want to refresh your dimension slices or change your dimension definitions, you should do so via the Data Source page for the related data source. You can read more about that [here](https://docs.growthbook.io/app/dimensions#experiment-dimensions).",
    "title": "Experiments (Results) | GrowthBook Docs",
    "description": "Analyze your experiment results from your data source.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/features/scheduling",
    "markdown": "# Scheduling Features | GrowthBook Docs\n\n![Feature Scheduling](https://docs.growthbook.io/assets/images/feature-scheduling-cf430204529618ffbb61543bdbf6b92c.png)\n\nIf you have a Pro or Enterprise plan, you can schedule features to turn on or off at a specific date and time. This is useful for things like turning features on or off for holidays or special promotions.\n\nScheduling features is currently supported with all override rule types, including force rules, rollout rules, and experiment rules - and just like non-scheduled override rules, they will override the default value when all conditions are met.",
    "title": "Scheduling Features | GrowthBook Docs",
    "description": "Scheduling features flags",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/features/stale-detection",
    "markdown": "# Stale Feature Flag Detection | GrowthBook Docs\n\n## Overview[​](#overview \"Direct link to Overview\")\n\nFeature flags are a crucial part of software development, allowing for controlled rollouts and A/B testing. However, managing these flags, especially in large systems, can be challenging. Over time, some flags may become \"stale\" - no longer actively used or relevant.\n\nStale flags can clutter your system, lead to confusion, and obscure the status of your features. GrowthBook introduces the Stale Feature Flag Detection feature to address this issue, ensuring your feature flag ecosystem remains clean and efficient.\n\n## Why Stale Feature Flag Detection?[​](#why-stale-feature-flag-detection \"Direct link to Why Stale Feature Flag Detection?\")\n\n*   Reduce Clutter: Identifies and flags feature flags that are no longer active, helping to declutter your dashboard.\n    \n*   Improve Clarity: Enhances visibility into which feature flags are currently significant and in use.\n    \n*   Streamline Management: Makes it easier to manage a large number of feature flags, improving operational efficiency.\n    \n\n## Accessing and Using the Feature[​](#accessing-and-using-the-feature \"Direct link to Accessing and Using the Feature\")\n\n### Viewing Stale Flags[​](#viewing-stale-flags \"Direct link to Viewing Stale Flags\")\n\nTo view features that have been marked stale, navigate to the main feature flag table in GrowthBook. Look for the 'Stale' column which indicates whether a flag is considered stale.\n\n![Stale Flag Column](https://docs.growthbook.io/assets/images/stale-ff-01-0989ccff0120dfe772a2c213271f1f31.png)\n\nYou can also navigate to a particular feature and see the stale indicator marked next to the feature name.\n\n![Stale Flag Indicator](https://docs.growthbook.io/assets/images/stale-ff-02-cf6680a12b90f5619de8b3c0f2c0ad7a.png)\n\n### Understanding Stale Status[​](#understanding-stale-status \"Direct link to Understanding Stale Status\")\n\nHover over the Warning icon next to a flagged item.\n\nA tooltip will provide the reason for its staleness, based on the set heuristics.\n\n#### Heuristics Used:[​](#heuristics-used \"Direct link to Heuristics Used:\")\n\nA flag is stale if not updated in two weeks and meets certain criteria (e.g., no active environments, or one-sided rules).\n\n### Toggling Stale Detection:[​](#toggling-stale-detection \"Direct link to Toggling Stale Detection:\")\n\nYou can enable or disable stale detection from the feature details page. From the features table, stale detection can only be disabled.\n\n![Stale Flag Toggle](https://docs.growthbook.io/assets/images/stale-ff-03-57cd68e20eedfe9894f8880f81c8ed5b.gif)\n\nYou can also re-enable stale feature flag detection by navigating to the menu in the top right of the feature details page.\n\n![Stale Flag Toggle](https://docs.growthbook.io/assets/images/stale-ff-04-6d41ad886f26e4bb7286da539fe61430.gif)",
    "title": "Stale Feature Flag Detection | GrowthBook Docs",
    "description": "Overview",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/self-host/proxy",
    "markdown": "# GrowthBook Proxy | GrowthBook Docs\n\nThe GrowthBook Proxy server sits between your application and GrowthBook (both Cloud or Self-hosted instances). It turbocharges your GrowthBook implementation by providing **speed**, **scalability**, **security**, and **real-time** feature rollouts.\n\n## Features[​](#features \"Direct link to Features\")\n\n*   **Caching** - Significantly faster feature lookups!\n    *   In-memory cache plus an optional distributed layer (Redis or MongoDB)\n    *   Automatic cache invalidation when features change in GrowthBook (using WebHooks)\n*   **Streaming** - Updates your application in real-time as features are changed or toggled in GrowthBook (Javascript and React only)\n*   **Remote Evaluation** - Hide your features' business logic in insecure environments\n*   **Security** - Private-key authentication between GrowthBook and GrowthBook Proxy\n*   **Scalability** - Support millions of concurrent users\n\n## Installation[​](#installation \"Direct link to Installation\")\n\n### Using docker-compose[​](#using-docker-compose \"Direct link to Using docker-compose\")\n\nIf you are already using `docker-compose` to run GrowthBook, we have a pre-configured setup that includes a GrowthBook Proxy instance.\n\nJust run\n\n```\ndocker-compose -f docker-compose.proxy.yml up -d\n```\n\nThis will start the proxy server on port 3300. Check `http://localhost:3300/healthcheck` to ensure it's working correctly.\n\n### Standalone[​](#standalone \"Direct link to Standalone\")\n\nYou can also run the GrowthBook Proxy as a standalone Docker container.\n\nFirst, pull the latest image\n\n```\ndocker pull growthbook/proxy:latest\n```\n\nThen, run a GrowthBook Proxy instance on port 3300\n\n```\ndocker run -d -p 3300:3300 \\  -e \"GROWTHBOOK_API_HOST=https://growthbook-api.example.com\" \\  -e \"SECRET_API_KEY=something_secret\" \\  --name gbproxy growthbook/proxy\n```\n\nCheck `http://localhost:3300/healthcheck` to ensure it's running correctly.\n\n### Authentication[​](#authentication \"Direct link to Authentication\")\n\nYou will need to create a \"readonly\" secret API key in GrowthBook by going to **Settings → API Keys** (you can also use a Personal Access Token if preferred). Or you can use a custom `SECRET_API_KEY` of your choosing. Whichever method you choose, this key will be used to authenticate your proxy server with the GrowthBook app.\n\nLastly, for self-hosted customers, add environment variables your main GrowthBook API server to enable the proxy:\n\n```\nPROXY_ENABLED=1PROXY_HOST_PUBLIC=https://growthbook-proxy.example.com# OPTIONAL: You can either create the secret key in the GrowthBook UI or define one here orSECRET_API_KEY=something_secret\n```\n\nNote: Setting `PROXY_HOST_PUBLIC` is not strictly required, but is considered a best practice. Setting it enables faster rollouts by allowing GrowthBook to push updates to your proxy whenever feature definitions change.\n\n### Cloud Customers[​](#cloud-customers \"Direct link to Cloud Customers\")\n\nFor cloud customers who self-host a proxy server, you must configure each SDK Connection to use the proxy server.\n\nYou may optionally enter your proxy server's public host URL. This enables faster rollouts by allowing GrowthBook to push updates to your proxy whenever your feature definitions change. If you do not provide a proxy host URL, your proxy server the proxy will fall back to a pull-based stale-while-revalidate caching strategy.\n\nGo to **SDK Configuration → SDK Connections** in the GrowthBook app to configure the proxy server per each connection.\n\n## Using with the SDKs[​](#using-with-the-sdks \"Direct link to Using with the SDKs\")\n\nThe GrowthBook Proxy has the same public feature endpoints as GrowthBook, so all you need to do is change the API host your SDK clients connect to:\n\n```\n// Beforeconst gb = new GrowthBook({  apiHost: \"https://growthbook-api.example.com\",  clientKey: \"sdk-abc123\"});// After (clientKey remains the same)const gb = new GrowthBook({  apiHost: \"https://growthbook-proxy.example.com\",  clientKey: \"sdk-abc123\"});\n```\n\n## Configuration[​](#configuration \"Direct link to Configuration\")\n\nThe GrowthBook Proxy supports a number of configuration options available via environment variables. Some of the more common options are:\n\n*   `GROWTHBOOK_API_HOST` - Set this to the host and port of your GrowthBook API instance\n*   `SECRET_API_KEY` - Create a secret API key in GrowthBook by going to **Settings → API Keys**\n*   `NODE_ENV` - Set to \"production\" to hide debug and informational log messages\n*   `CACHE_ENGINE` - One of - `memory`, `redis`, or `mongo`\n*   `CACHE_CONNECTION_URL` - The URL of your redis or mongo cluster (if using)\n*   `CACHE_STALE_TTL` - Number of seconds until a cache entry is considered stale\n*   `CACHE_EXPIRES_TTL` - Number of seconds until a cache entry is expired\n\nYou can also configure the GrowthBook Proxy to handle SSL termination. It supports HTTP/2 by default, which is required for high performance streaming.\n\n*   `USE_HTTP2` - Set to \"true\" or \"1\" to enable\n*   `HTTPS_CERT` - The SSL certificate\n*   `HTTPS_KEY` - The SSL key\n\nFor more complete configuration documentation, please see the GrowthBook Proxy GitHub page: [https://github.com/growthbook/growthbook-proxy](https://github.com/growthbook/growthbook-proxy)\n\n## Best Practices[​](#best-practices \"Direct link to Best Practices\")\n\nIn high-traffic production scenarios, there are a few best practices to follow\n\n*   Auto-scale GrowthBook Proxy instances based on number of active connections or memory\n*   Run the instances in the same region as your application servers for the lowest latency\n*   Add a load balancer in-front that supports HTTP/2 and streaming responses (AWS ALB, HAProxy, etc.)\n*   Use Redis (or MongoDB) as the cache engine for more consistent feature releases\n*   Use the `/healthcheck` endpoint to determine if the instances are running correctly",
    "title": "GrowthBook Proxy | GrowthBook Docs",
    "description": "Turbocharge your GrowthBook deployment with the GrowthBook Proxy server",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/features/features/approval-flows",
    "markdown": "# Approval Flows | GrowthBook Docs\n\nnote\n\nApproval Flows is a GrowthBook Enterprise feature.\n\nWith Approval flows, you can require approval before publishing any change to an existing feature flag. Approval flows help reduce errors by making sure changes to features have been viewed and approved by someone else in your organization.\n\n## Settings page[​](#settings-page \"Direct link to Settings page\")\n\nApproval flows can be enabled for your organization on the settings page. You are able to select the environments which require approvals, or leave the field blank to require approvals on all environments. If you would like to force reset the review when a change is made after it is approved, toggle on the `Reset review on changes`.\n\n![approvals-org-settings.png](https://docs.growthbook.io/assets/images/approvals-org-settings-df2393063873a78f353add8422b9cf44.png)\n\n## Approval Flow[​](#approval-flow \"Direct link to Approval Flow\")\n\n### Draft[​](#draft \"Direct link to Draft\")\n\nA Draft is created whenever you make changes to an existing Feature and save it. If you have not turned on approval flows, you can directly publish your changes. When you turn on Approval Flows for Features, you have to request a review before publishing changes.\n\n![approvals-approve-flow-1.png](https://docs.growthbook.io/assets/images/approvals-approve-flow-1-5305e4a237f3b9abe1dd954a914da84d.png)\n\n### Requesting a Review[​](#requesting-a-review \"Direct link to Requesting a Review\")\n\nRequesting a review is changing the status on your draft to tell other people in your organization that your feature is ready to publish and you need someone to review to ensure that you have no errors before publishing. Before requesting a review, make sure that you add a detailed comment describing the changes that you have made so everyone can understand the intent of your request.\n\nWhen a request is made it will show up in the Drafts tab on your Features overview page. The status will be set to `Pending Review` when you have requested a review. You will be able to sort by date updated to see your newly requested change at the top of the list.\n\n![approvals-see-list.png](https://docs.growthbook.io/assets/images/approvals-see-list-dafbc526ea4d50f43dc12286eabf3350.png)\n\n### Reviewing[​](#reviewing \"Direct link to Reviewing\")\n\nAnyone that has the ability to \"Edit\" or \"Add\" a Feature Flag (see [Permissions](https://docs.growthbook.io/account/user-permissions)) can serve as a reviewer, besides the user who created the request.\n\nAfter clicking on the feature, you will be able to open the review modal by clicking `Review and Approve`.\n\n![approvals-approve-flow-4.5-request.png](https://docs.growthbook.io/assets/images/approvals-approve-flow-4.5-request-30d44e20d8012b4a150b587193e490bd.png)\n\nFrom here, you can see the diff between the currently published changes as well as the comments.\n\n![approvals-approve-flow-3-review.png](https://docs.growthbook.io/assets/images/approvals-approve-flow-3-review-09dabf255ad3512807442f44a1db2bcc.png)\n\nAfter clicking next you are able to write your review in the comment box and select the correct status you want. The statuses are:\n\n*   `Comment` - which is mainly used if you are wanting to say something without reviewing the changes\n*   `Request Changes` - use this status if you think that there needs to be changes made\n*   `Approve` - if everything look correct\n\n![approvals-approve-flow-4.png](https://docs.growthbook.io/assets/images/approvals-approve-flow-4-ddabc5c40ac5eb6e26270a437ff88ea6.png)\n\nOnce the changes are `Approved`, the changes will be able to be published.\n\n![approvals-approve-flow-3.5.png](https://docs.growthbook.io/assets/images/approvals-approve-flow-3.5-84410c8bccaad5b5d15ed6d94c6b73d3.png)\n\n### Publishing[​](#publishing \"Direct link to Publishing\")\n\nAny one with permission to Add or Edit Feature flags will be able to publish the changes once they are marked as `Approved`. Admins are able to publish features without requiring a review, by clicking the box at the top of the modal to bypass the review.\n\n![approvals-approve-flow-5.5.png](https://docs.growthbook.io/assets/images/approvals-approve-flow-5.5-816de85fe09f95ea97c7679479bce648.png)\n\nOnce the changes are published you'll see a green bar indicating that the version is live.\n\n![approvals-approve-flow-5-done.png](https://docs.growthbook.io/assets/images/approvals-approve-flow-5-done-7bb3c0e7eb7457da24521f2fda0cde5a.png)",
    "title": "Approval Flows | GrowthBook Docs",
    "description": "Learn about how Approval flows work on feature flags",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/app/url-redirects",
    "markdown": "# URL Redirect Testing | GrowthBook Docs\n\nURL Redirect tests are an alternative to using the Visual Editor and are ideal for testing big changes or complete page redesigns.\n\nURL Redirects require a Pro or Enterprise GrowthBook license.\n\n## How it Works[​](#how-it-works \"Direct link to How it Works\")\n\nYou start by specifying an \"Original URL\". Users who visit this URL will be included in the experiment (assuming they meet all of the other targeting conditions).\n\nYou then specify \"Destination URLs\" for each of your variations. You can also turn off redirects for some of your variations if you want to keep the user on the Original URL.\n\nWhen a user visits the Original URL and is included in the experiment, they will be assigned a variation. Then, an \"Experiment Viewed\" event will be sent to your data warehouse. After a short delay (default `100ms`) to allow for the tracking event to finish, the user will be redirected to the destination URL.\n\n## Implementation[​](#implementation \"Direct link to Implementation\")\n\nURL Redirect tests require you to integrate one of our [SDKs](https://docs.growthbook.io/lib) into your application. Currently, URL Redirect tests are only supported in our [Script Tag](https://docs.growthbook.io/lib/script-tag), [Javascript](https://docs.growthbook.io/lib/js), and [ReactJS](https://docs.growthbook.io/lib/js) SDKs. Support for other SDKs are coming soon.\n\n### HTML Script Tag[​](#html-script-tag \"Direct link to HTML Script Tag\")\n\nThe easiest option is to use our [Script Tag](https://docs.growthbook.io/lib/script-tag) SDK. This involves adding a single `<script>` tag to the HEAD of your website. This option fully works out-of-the-box with no configuration required.\n\n### Client-Side JavaScript and React[​](#client-side-javascript-and-react \"Direct link to Client-Side JavaScript and React\")\n\nA more advanced integration involves using our [Javascript](https://docs.growthbook.io/lib/js) or [ReactJS](https://docs.growthbook.io/lib/js) client-side SDKs.\n\nBesides the standard implementation described in the SDK docs, there are 4 additional settings that control the redirect behavior.\n\n*   `navigate` - a callback function to perform the redirect. Defaults to `(url) => window.location.replace(url)`.\n*   `navigateDelay` - the number of milliseconds to wait before redirecting. Use this to give time for your analytics tracking callback to finish. Defaults to `100`\n*   `antiFlicker` - If `true`, a white screen will be shown while the redirect is happening to avoid the user seeing a \"flicker\". Defaults to `false`.\n*   `antiFlickerTimeout` - the maximum number of milliseconds that the anti-flicker white screen will be shown. Defaults to `3500` (3.5 seconds).\n\n#### Single Page Apps (SPAs)[​](#single-page-apps-spas \"Direct link to Single Page Apps (SPAs)\")\n\nIf you have a Single Page App (SPA), it's recommended to use your own `navigate` function to avoid doing full-page redirects. In this case, you also want to set `navigateDelay` to 0. Here's an example in Next.js\n\n```\nimport router from \"next/router\";const gb = new GrowthBook({    navigate: (url) => router.replace(url),    navigateDelay: 0,    // ... other settings});\n```\n\nIt's also super important to update the URL in the GrowthBook instance on every client-side navigation. For example:\n\n```\nrouter.events.on(\"routeChangeComplete\", (url) => {    gb.setURL(url);})\n```\n\n### Node.js / Edge Workers\n\nbeta\n\n[​](#nodejs--edge-workers-beta \"Direct link to nodejs--edge-workers-beta\")\n\nIt's possible to use our [Javascript](https://docs.growthbook.io/lib/js) SDK to perform redirects on the back-end as well, in either a Node.js application or in an edge worker.\n\nReach out to us on Slack or at [hello@growthbook.io](mailto:hello@growthbook.io) if you're interested in helping us beta test this and we can help you get set up.",
    "title": "URL Redirect Testing | GrowthBook Docs",
    "description": "Easily A/B test multiple versions of a page without writing code",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/app/making-experiment-changes",
    "markdown": "# Making Changes to Experiments | GrowthBook Docs\n\nWe allow you make changes to an experiment's targeting while it is running. This is especially useful if you want to start running on a small percent of traffic and then gradually ramp up exposure. To make a change to a running experiment, click the \"Make Changes\" button on the top of the experiment page.\n\nYou will then be asked what sort of change you want to make, with options ranging from targeting changes to traffic and variation weight changes. You may also make multiple changes at once by choosing \"advanced\".\n\nBased on what you are changing, we will provide a list of possible release plans for that change and provide a recommended plan to use. The UI should guide you to make the correct recommended choice in most cases, but you are able to change this if desired.\n\nWhen changing a **single targeting or traffic setting**, your release plan options may include:\n\n*   New phase, re-randomize traffic\n*   Same phase, apply changes to everyone\n*   Same phase, apply changes to new traffic only (Sticky Bucketing enabled only)\n\nNote that potentially unsafe options per your specific changes may be removed (often \"Same phase\" options are unsafe for certain types of changes).\n\nWhen using **\"advanced\"** to make multiple targeting or traffic changes at once, all above options will be made available (including potentially unsafe ones), as well as an additional option:\n\n*   New Phase, re-randomize traffic, block bucketed users (Sticky Bucketing enabled only)\n\nIf you are not making targeting or traffic changes and simply want to **start a new phase**, the release plan options will be:\n\n*   New phase, re-randomize traffic\n*   New phase, do not re-randomize\n\n## Update the existing phase[​](#update-the-existing-phase \"Direct link to Update the existing phase\")\n\nThis modifies the experiment in-place without resetting results or re-randomizing users. This provides the best user experience for your users and you can re-use data that was already collected, which can reduce the time the experiment needs to run.\n\nHowever, if you're not careful, this can introduce significant bias and data quality issues into your results. A few categories of changes are broadly considered \"safe\" and if you are only making these changes, this is the approach we recommend going with. The \"safe\" changes are:\n\n*   Increasing the percent of people included in the experiment\n*   Removing a condition from an experiment (e.g. going from \"US visitors only\" to \"All visitors\")\n*   Removing an experiment from a namespace\n\nAll of these changes have something in common - they are simply increasing the number of users exposed to the experiment. There is no effect on existing users in the experiment.\n\nIf you have Sticky Bucketing enabled, you may also elect to apply changes to new traffic only, leaving already-bucketed users in their existing (sticky) buckets. An example of this scenario could be decreasing the percent of people included in the experiment for all new incoming users, but leaving existing users in their existing buckets.\n\n## Start a new phase[​](#start-a-new-phase \"Direct link to Start a new phase\")\n\nThis creates a brand new phase of the experiment. All data collected until this point is excluded from the analysis and you start fresh (nothing is deleted from your data warehouse, we just hide old data from the results).\n\nIn most cases, you will also want to re-randomize traffic. This will cause everyone - including existing experiment users - to get assigned a new random variation. This can be a disruptive user experience since many people will switch from Control to Treatment (or vice versa).\n\nWhy would you ever want to do this? Some changes you make completely invalidate past results so this lets you cleanly separate the data analysis from before and after you make the change. Re-randomizing traffic can also eliminate [carryover bias](https://docs.growthbook.io/kb/experiments/carryover-bias) and make your results more reliable and accurate.\n\nWe recommend this approach for any change that is not considered \"safe\" (listed above). This can include (but not limited to):\n\n*   Changing the traffic split (weights) between variations\n*   Adding a new targeting condition\n*   Decreasing the percent of people included\n\nBecause of how disruptive this can be, it's best to plan ahead before starting an experiment. It's better to start with more conservative targeting and scale up than the reverse (starting big and scaling back).\n\nAs before, if you have Sticky Bucketing enabled, you have some additional options about how to treat already-bucketed users. By default when starting a new phase, these bucketed users will be reassigned (their sticky bucket will be cleared). You may instead choose to block these users from the experiment going forward (in which case they will still see the control). This strategy is only available in the \"advanced\" mode.",
    "title": "Making Changes to Experiments | GrowthBook Docs",
    "description": "Make targeting and rollout changes to a running experiment",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/app/sticky-bucketing",
    "markdown": "# Sticky Bucketing | GrowthBook Docs\n\nThis article serves two purposes:\n\n*   High level overview of GrowthBook's Sticky Bucketing feature\n*   Technical details on how to implement Sticky Bucketing in your codebase\n\nSticky bucketing ensures users continue to see the same variation when you make changes to a running experiment. GrowthBook's flavor of sticky bucketing has a few additional features:(1) Bucketing based on either a primary hash attribute (i.e. user id) or a secondary attribute (i.e. anonymous id) and (2) the ability to version-control and purge your users' assigned buckets.\n\n## Motivation[​](#motivation \"Direct link to Motivation\")\n\nSo why would you want to use Sticky Bucketing? Let's look at a few examples:\n\n1.  You are managing an experiment rollout and need to slow down enrollment. You decrease the percentage of traffic exposed to the experiment from 50% to 10% but you do not want to alter the experience for users who were already exposed to the experiment. Sticky bucketing allows you to apply the rollout percentage to new users while keeping the old users in their original buckets.\n    \n2.  You discovered a bug in your experiment the day after launching. You fix the bug and want to re-start the experiment, but don't want to include any \"tainted\" users who saw the buggy version since their negative experience might impact the results.\n    \n3.  Your have a cross-platform app and want to ensure a consistent experience as users log in and move between devices.\n    \n\nnote\n\nSticky Bucketing is a GrowthBook Pro and Enterprise feature.\n\n## Setting up Sticky Bucketing[​](#setting-up-sticky-bucketing \"Direct link to Setting up Sticky Bucketing\")\n\nTo use Sticky Bucketing for your experiments, there are a few steps that you need to complete.\n\n### 1\\. Ensure you are using a compatible SDK version[​](#1-ensure-you-are-using-a-compatible-sdk-version \"Direct link to 1. Ensure you are using a compatible SDK version\")\n\nUpdate your codebase to use a compatible SDK. Sticky Bucketing is currently supported in the following SDK versions:\n\n*   Javascript: `0.32.0`\n*   React: `0.22.0`\n\n### 2\\. Pass a Sticky Bucketing Service into your SDK Implementation[​](#2-pass-a-sticky-bucketing-service-into-your-sdk-implementation \"Direct link to 2. Pass a Sticky Bucketing Service into your SDK Implementation\")\n\nYou may use one of our built-in Sticky Bucketing Services or implement your own. We provide common drivers for browser-generated cookies, backend-generated cookies, browser LocalStorage, and Redis stores.\n\nFor more information about setting up Sticky Bucketing at the SDK level, see the appropriate SDK documentation. For instance, see the [Javascript SDK - Sticky Bucketing documentation](https://docs.growthbook.io/lib/js#sticky-bucketing) for more information about setting up Sticky Bucketing in the Javascript SDK.\n\n### 3\\. Update your SDK Connections in the GrowthBook app[​](#3-update-your-sdk-connections-in-the-growthbook-app \"Direct link to 3. Update your SDK Connections in the GrowthBook app\")\n\nWithin the GrowthBook app, ensure that your SDK Connections are configured correctly. You can do this by going to the **SDK Connections** page, clicking into a connection, and clicking the **Edit** button in the top right.\n\nMake sure the connection (1) only has a single language selected and (2) has the correct SDK version specified.\n\n![Setting the SDK Connection Version](https://docs.growthbook.io/assets/images/sdk-connection-version-sb-34f8a06a7b027e265de5eeb898c2a2e2.png)\n\nIn the above example, React is selected and the version is set to the latest `0.22.0`, which supports sticky bucketing.\n\nIf you are using GrowthBook with multiple languages, create a separate SDK Connection for each language.\n\n### 4\\. Enable Sticky Bucketing for your organization[​](#4-enable-sticky-bucketing-for-your-organization \"Direct link to 4. Enable Sticky Bucketing for your organization\")\n\nIn the GrowthBook app, go to **Settings** → **General** → **Experiment Settings** and enable the Sticky Bucketing toggle. This will add new options specific to Sticky Bucketing whenever you make changes to a running experiment. To read more about these options, see [Experiments (setup)](https://docs.growthbook.io/app/experiment-configuration).\n\nOnce Sticky Bucketing is enabled, there is an additional toggle for enabling a **Fallback Attribute**. See below for more information on this feature.\n\n## Fallback Attribute[​](#fallback-attribute \"Direct link to Fallback Attribute\")\n\nUsers are assigned an experiment variation based on a **Hash Attribute**, for example a logged-in `userId`. With Sticky Bucketing, you also have the option of specifying a **Fallback Attribute** for an experiment, for example an anonymous `cookieId`. This fallback will be used if the primary hash attribute is missing or empty.\n\n### Fallback Attribute Example[​](#fallback-attribute-example \"Direct link to Fallback Attribute Example\")\n\nImagine your users tend to sign in on multiple devices. Let's say you want to test changes to the main navigation header of your app, something that is visible to both logged-in and anonymous visitors.\n\nIf you were to only use `userId` to assign variations, signing in could become a jarring experience - users might flip from seeing the control (since their user id is empty) to seeing the variation (once they log in). On the plus side, if users open your app on multiple devices (when logged in), they will always see a consistent experience.\n\nIf instead, you were to only use the anonymous `cookieId` to assign variations, it solves the issue where the UI flips during sign in (since the anonymous id stays the same before and after), but now switching devices could become a jarring experience - the same user might get assigned different variations on different devices, since each device would have its own separate anonymous id.\n\nFallback attributes, when implemented properly with sticky bucketing, lets you have the best of both worlds (with some caveats). Your primary hashing attribute would be the logged-in `userId` and your fallback attribute would be the anonymous `cookieId`.\n\nThe very first variation a user is assigned to will \"stick\" to them and follow them across devices. So if a visitor lands on your website, gets assigned variation B (from their fallback attribute), and then logs in, they will continue seeing variation B, even though they now have a `userId` attribute. If that same user then logs into your app on a new device, they again will continue seeing variation B.\n\nThere are 2 caveats with fallback attributes:\n\n1.  There are still some scenarios where users will get inconsistent experiences. For example, if they are logged out on two devices, there's no way for us to know they are the same person.\n2.  It opens you up to potential bias in your experiment results (see more below).\n\n### Bias Risk[​](#bias-risk \"Direct link to Bias Risk\")\n\nTo understand the risk of bias, lets focus on a user switching devices. During analysis, we will have to use the anonymous `cookieId` as the experimental unit to make sure we capture everyone in the experiment, even those who never logged in. When a user logs in on two devices, they will be seen as two separate \"users\" in the analysis since each device has its own cookie id. Because of the fallback attribute and sticky bucketing, however, they will both get assigned the same variation. This breaks one of the statistical assumptions of A/B testing - that each user is randomly assigned a variation. Let's see how this might play out to cause bias in your results.\n\nImagine your variation causes people to use multiple devices more often than your control does. 200 people land on your website and get split into control and variation - 100 in each. In the control, 20 of them also log in on their phone, but in the variation 60 of them log in on their phone. In your analysis, you have 280 total anonymous ids and you expect them to be split evenly - 140 each. In reality, the control would have 120 ids while the variation has 160. A difference this extreme is easy to spot in the results (GrowthBook runs Sample Ratio Mismatch tests automatically to catch exactly this type of bug), however there are many similar, but more subtle, issues that may fly under the radar.\n\nBottom line: with Fallback Attributes, you can get a more consistent within-session and cross-device user experience at the expense of statistical rigor. With GrowthBook, we let you decide this trade-off for yourself on a per-experiment basis.\n\n## Example Sticky Bucket Implementations[​](#example-sticky-bucket-implementations \"Direct link to Example Sticky Bucket Implementations\")\n\n### Front-end only[​](#front-end-only \"Direct link to Front-end only\")\n\nSuppose your website integrates GrowthBook on the front end only. You would like to implement Sticky Bucketing to protect against variation hopping should targeting or rollout rules change in the future.\n\nIn our JavaScript and React SDKs, we provide 2 different Sticky Bucket Services that make sense in this scenario: `LocalStorageStickyBucketService` and `BrowserCookieStickyBucketService`. You can instantiate either of these services and plug them into the GrowthBook SDK.\n\n### Front-end and Back-end (Node.js)[​](#front-end-and-back-end-nodejs \"Direct link to Front-end and Back-end (Node.js)\")\n\nLet's expand the \"front-end only\" example above so that our back-end controllers also integrate with GrowthBook and can reference the same experiments. In this scenario, we would like both the front-end and back-end to perform bucketing and persist a sticky bucket that reliably crosses the front-end / back-end divide.\n\nOn the front end, you will want to use the `BrowserCookieStickyBucketService` because cookies are easily transportable to and from the back end. Then, assuming we are using an Express (NodeJS) server, we would use the `ExpressCookieStickyBucketService` on the back end. Importantly, if customizing the cookie name, you must ensure that the same name prefix is chosen for both the front-end and back-end cookies.\n\n### Back-end only[​](#back-end-only \"Direct link to Back-end only\")\n\nSuppose that in a server-side context we are interested in persisting a user's bucket both across multiple requests and across other back-end (micro)services that may not have direct access to the incoming user request nor their cookies.\n\nWe could use a Redis instance inside our network and read/write to that for sticky bucket storage. In a NodeJS context, we could use the `RedisStickyBucketService` and pass in an `ioredis` client.\n\n### Hybrid and custom implementations[​](#hybrid-and-custom-implementations \"Direct link to Hybrid and custom implementations\")\n\nYou may wish to employ multiple strategies at once (front-end, back-end, Redis) or write your own sticky bucket connector for a SQL server or DynamoDB cluster. You could write your own custom sticky bucket connector by implementing the `StickyBucketService` interface. Within your connector, you could do things like:\n\n*   Connect to SQL server for sticky bucket reads/writes\n*   GET/POST/RPC to a custom bucketing microservice\n*   Wrap both the `ExpressCookieStickyBucketService` and `RedisStickyBucketService` within your custom service's getter and setter methods\n*   Trigger side effects on bucket reads/writes",
    "title": "Sticky Bucketing | GrowthBook Docs",
    "description": "Ensure users continue to see the same variation when you make changes to a running experiment",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/features/code-references",
    "markdown": "# Code References | GrowthBook Docs\n\n## Overview[​](#overview \"Direct link to Overview\")\n\nCode References allows teams to quickly see instances of feature flags being leveraged in their codebase. By scanning customers’ code bases via a CLI tool and sending results to our application backend, GrowthBook can help surface valuable information such as flagging stale feature flags more accurately, and directing devs to the exact lines of code that need to be cleaned up.\n\n## Getting Started[​](#getting-started \"Direct link to Getting Started\")\n\nFor GitHub users, we provide a streamlined GitHub Action that is easy-to-set up and geting with code references.\n\n*   [GrowthBook Code References GitHub Action](https://github.com/marketplace/actions/growthbook-code-references)\n\nFor non-GitHub users, we provide all the tools you need to get set up with code references with your platform of choice.\n\n*   [Growthbook gb-find-code-refs CLI utility](https://github.com/growthbook/gb-find-code-refs)\n*   [Dockerized version of gb-find-code-refs](https://hub.docker.com/r/growthbook/gb-find-code-refs)\n\n## Enabling Code References in GrowthBook[​](#enabling-code-references-in-growthbook \"Direct link to Enabling Code References in GrowthBook\")\n\nTo enable code references, navigate to your General Settings page, and scroll to **Configure Code References**. You can enable code references here, and access relevant docs to help get set up.\n\n### Branch filtering[​](#branch-filtering \"Direct link to Branch filtering\")\n\nWe provide the option to explicitly specify branch names (comma-separated) to show code references for. By default, we will display all code references received for any branch.\n\nFor example, if your team only needed to see code references from branches `main` and `qa`, this option would be set to `main, qa`.\n\n### Platform links[​](#platform-links \"Direct link to Platform links\")\n\nWe provide direct links to your codebase hosted on either GitHub or GitLab. Use this option to select which platform you use and code references in the app will automatically provide external links to your codebase.\n\nIf you don't see your platform supported, please let us know in the [Slack community](https://slack.growthbook.io/?ref=coderefs)!\n\n## Viewing Code References[​](#viewing-code-references \"Direct link to Viewing Code References\")\n\nOnce enabled, you can view Code References on a specific feature page, under the Code Refs tab.",
    "title": "Code References | GrowthBook Docs",
    "description": "Overview",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/warehouses/athena",
    "markdown": "# Setting up Athena as a data source\n\nSetting up Athena as your datasource requires you set up the proper permissions within AWS for Growthbook to access and then provide the correct credentials to Growthbook make use of those permissions. There are also optional connection data that will help Growthbook create the correct default sql to analyze your data.\n\n## Setting up Permissions in AWS[​](#setting-up-permissions-in-aws \"Direct link to Setting up Permissions in AWS\")\n\nUnlike other database engines with their own user management system, Athena uses IAM for authentication.\n\n### Growthbook Cloud[​](#growthbook-cloud \"Direct link to Growthbook Cloud\")\n\nWe recommend creating a new IAM user with readonly permissions for GrowthBook.\n\nThe managed [AWSQuicksightAthenaAccess](https://docs.aws.amazon.com/athena/latest/ug/managed-policies.html) is a good starting point. You will also need to give it permission to read from the s3 tables that hold your event data, by taking a modified version of `AmazonS3ReadOnlyAccess` policy whose resources are confined to only those tables that hold your event data. For example with the following policy after replacing the `<BUCKET NAME>`:\n\n```\n{    \"Version\": \"2012-10-17\",    \"Statement\": [        {            \"Effect\": \"Allow\",            \"Action\": [                \"s3:Get*\",                \"s3:List*\",                \"s3-object-lambda:Get*\",                \"s3-object-lambda:List*\"            ],            \"Resource\": [                \"arn:aws:s3:::<BUCKET NAME>*\"            ],        }    ]}\n```\n\nIdeally that bucket should only have event data that growthbook needs to calculated its metrics and no other data. You can futher restrict the resources as your security policy requires.\n\nAfterwards your IAM user's permission page might look like:\n\n![Athena permissions](https://docs.growthbook.io/images/guides/athena-permissions.png)\n\n### Self hosted[​](#self-hosted \"Direct link to Self hosted\")\n\nWe recommend creating a new IAM role with the same permissions as for Growthbook Cloud. This role can then be [attached to the ec2 instance](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html#attach-iam-role) that is running Growthbook.\n\n## Providing Credentials to Growthbook[​](#providing-credentials-to-growthbook \"Direct link to Providing Credentials to Growthbook\")\n\n### Growthbook Cloud[​](#growthbook-cloud-1 \"Direct link to Growthbook Cloud\")\n\nIf you are using Growthbook Cloud you will need to create an IAM user that has the above policies attached - either directly or through a group.\n\nYou must then create an access key by clicking on Security Credentials then \"Create Access Key\". You can then choose \"Third-party service\". It will warn you that this is not best practice, but unfortunately this is the only way to give Growthbook access at the moment. We are working on other ways to connect in the future. You can then confirm and click next. You can add a tag if you like and then press \"Create access key\". You should see then see following screen:\n\n![Athena permissions](https://docs.growthbook.io/images/guides/athena-keys1.png)\n\nIn another browser tab open up Growthbook Data Sources tab and choose your event tracker. Select Athena as your data source type. You can then copy the Access Key and Secret Access Key from the AWS browser tab to their corresponding fields.\n\n### Self hosting[​](#self-hosting \"Direct link to Self hosting\")\n\nIf you are self hosting then in addition to the method above you can also pass the credentials in via environmental variables or part of the instance metadata. You can select which method you want in the `Authentication Method` field.\n\n## Remaining Configuration[​](#remaining-configuration \"Direct link to Remaining Configuration\")\n\n`AWS Region` - This should be the AWS Region your Athena database is in. From the AWS console you would see it on the right side of the search bar on the top of the screen next to the account name.\n\n`Workgroup` - This is the workgroup within Athena.\n\n`Default Catalog` - This is that catalog where the event data lives.\n\n`Default Database` - This is the database where the event data lives.\n\n![Extra Fields in Growthbook for setting up Athena](https://docs.growthbook.io/images/guides/athena-extra-fields.png)\n\n`S3 Results URL` - This is the s3 URL where the results to Athena queries get saved. When setting up Athena for the S3 results url, we recommend naming your bucket with the prefix `aws-athena-query-results-` as the AWSQuicksightAthenaAccess gives permission to write to any bucket with this prefix. If Growthbook warns you that it can not write to an s3 location other than the one you select here it is most likely because you have set the [workgroup to override client side settings](https://docs.aws.amazon.com/athena/latest/ug/workgroups-settings-override.html). If that is the case you would either need to change that setting or add the permissions for growthbook to also write to the s3 results url saved there.",
    "title": "Setting up Athena as a data source | GrowthBook Docs",
    "description": "This document outlines the steps needed to add your Athena database to GrowthBook.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/guide/bigquery",
    "markdown": "# GrowthBook and BigQuery | GrowthBook Docs\n\n## Configuring GrowthBook to work with BigQuery\n\nThis document outlines the steps needed to add your BigQuery database to GrowthBook.\n\n## 1\\. Create a service account for GrowthBook[​](#1-create-a-service-account-for-growthbook \"Direct link to 1. Create a service account for GrowthBook\")\n\nWithin your [Google Cloud console account](https://console.cloud.google.com/iam-admin/serviceaccounts), create a service account for GrowthBook to use\n\n![Create a new service account in BigQuery](https://docs.growthbook.io/images/guides/bigquery-1-addserviceaccount-for-gb-highlited.png) ![Create a new service account in BigQuery](https://docs.growthbook.io/images/guides/bigquery-2-addserviceaccount-for-gb3.png)\n\nCreate a service account name and account ID. On the next page you need to add 3 specific roles:\n\n![Create a new service account in BigQuery](https://docs.growthbook.io/images/guides/bigquery-3-addserviceaccount-for-gb4-roles.png)\n\nOn the Grant page, add the following three permissions roles for read-only access:\n\n*   BigQuery Data Viewer\n*   BigQuery Metadata Viewer\n*   BigQuery Job User\n\n![Create a new service account in BigQuery](https://docs.growthbook.io/images/guides/bigquery-4-addserviceaccount-for-gb5-roles.png)\n\nOn the final page when creating a service account, you can skip the optional fields.\n\nYou should see the new service account listed, without a `Key ID`. We need to add an access key to this account so the credentials can be added to GrowthBook. Click on actions, and select `Manage Keys`.\n\n![Create a new service account in BigQuery](https://docs.growthbook.io/images/guides/bigquery-5-getjson-key.png)\n\nThere are two ways to provide credentials to GrowthBook:\n\n*   Auto-discovery from environment variables or GCP metadata (only available when self-hosting)\n*   Upload a JSON key file for the service account\n\nWe're going to show how to do the JSON key file method. On the keys page, add a new key, and select JSON.\n\n![Get json key for service account](https://docs.growthbook.io/images/guides/bigquery-6-getjson-key2.png) ![Get json key for service account](https://docs.growthbook.io/images/guides/bigquery-6-getjson-key3.png)\n\nThis will cause the JSON key to be downloaded to your computer.\n\n## 2\\. Connect GrowthBook to BigQuery[​](#2-connect-growthbook-to-bigquery \"Direct link to 2. Connect GrowthBook to BigQuery\")\n\nFrom the Metrics and Data → Data Source page, click on add new data source and select the event tracker you're using. If your event tracker is not listed, or you're using something custom, click on the \"Custom\" button at the bottom.\n\nSelecting an event tracker here will pre-populate the experiment exposure query which is need to determine which user saw which experiment variation. Depending on your needs, you may still need to adjust these queries to match your specific schema.\n\n![Add BigQuery to GrowthBook](https://docs.growthbook.io/images/guides/bigquery-7-add-datasource1.png)\n\nSelect BigQuery as the data source type.\n\n![Add BigQuery to GrowthBook](https://docs.growthbook.io/images/guides/bigquery-7-add-datasource2.png)\n\nAdd the names you'd like to use, and select the JSON key file that was downloaded earlier.\n\nGrowthbook will use the `Project Id` and `Dataset` you enter as the default ones when creating queries. You can get the value for these fields from the [Google Cloud explorer](https://console.cloud.google.com/bigquery). You will see the top level project id, and when expanded, find the dataset which has your experiment exposure table (which will be `experiment_viewed` if you use Segment or Rudderstack).\n\n![Get default project id and default dataset](https://docs.growthbook.io/images/guides/bigquery-8-getdefault-names.png)\n\nWhen you click save, GrowthBook will test the connection to make sure the credentials are correct. If the connection is successful, you should see a success message on the next page.\n\n## Enabling Data Pipeline Mode (Enterprise)[​](#enabling-data-pipeline-mode-enterprise \"Direct link to Enabling Data Pipeline Mode (Enterprise)\")\n\nEnterprise customers can enable pipeline mode, which can reduce query costs if you grant the GrowthBook service account write permissions in your data warehouse.\n\n[More details can be found here.](https://docs.growthbook.io/app/data-pipeline)\n\n## Monitoring GrowthBook query cost[​](#monitoring-growthbook-query-cost \"Direct link to Monitoring GrowthBook query cost\")\n\nWhenever we query your BigQuery database we add `{ integration: \"growthbook\" }` as a label to the query job to make it easy for you to monitor cost or filter GrowthBook query jobs by label for other use cases.\n\nRead more about how to [group by label value for a specific key here.](https://cloud.google.com/billing/docs/how-to/bq-examples#group_by_label_value_for_a_specific_key)",
    "title": "GrowthBook and BigQuery | GrowthBook Docs",
    "description": "This document outlines the steps needed to add your BigQuery database to GrowthBook.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/warehouses/clickhouse",
    "markdown": "# Setting up Clickhouse as a data source\n\nConnecting to Clickhouse is very straightforward. You just need to provide the connection string and credentials. If you are using something like Clickhouse Cloud, you can find the connection string in the UI.\n\n![](https://docs.growthbook.io/images/guides/guide-clickhouse-1.png)\n\nIf you are making connection credentials just for GrowthBook, you can give it read-only access to the database.\n\nIf you are using GrowthBook Cloud (app.growthbook.io), make sure to whitelist the ip address 52.70.79.40 if applicable.",
    "title": "Setting up Clickhouse as a data source | GrowthBook Docs",
    "description": "This document outlines the steps needed to add your Clickhouse database to GrowthBook.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/lib/js",
    "markdown": "# Javascript SDK | GrowthBook Docs\n\nSupports both browser and NodeJS environments.\n\n## Installation[​](#installation \"Direct link to Installation\")\n\nInstall with a package manager\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save @growthbook/growthbook\n```\n\n## Quick Usage[​](#quick-usage \"Direct link to Quick Usage\")\n\n### Step 1: Configure your app[​](#step-1-configure-your-app \"Direct link to Step 1: Configure your app\")\n\n```\nimport { GrowthBook } from \"@growthbook/growthbook\";// Create a GrowthBook instanceconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  // Targeting attributes  attributes: {    id: \"123\",    country: \"US\"  },  // Only required for A/B testing  // Called every time a user is put into an experiment  trackingCallback: (experiment, result) => {    console.log(\"Experiment Viewed\", {      experimentId: experiment.key,      variationId: result.key,    });  },});// Download features and experiments from the CDN// Also, start running any Visual Editor or URL Redirect experimentsawait gb.init();\n```\n\n### Step 2: Start Feature Flagging![​](#step-2-start-feature-flagging \"Direct link to Step 2: Start Feature Flagging!\")\n\nThere are 2 main methods for evaluating features: `isOn` and `getFeatureValue`:\n\n```\n// Simple boolean (on/off) feature flagif (gb.isOn(\"my-feature\")) {  console.log(\"Feature enabled!\");}// Get the value of a string/JSON/number feature with a fallbackconst color = gb.getFeatureValue(\"button-color\", \"blue\");\n```\n\n## OpenFeature Provider[​](#openfeature-provider \"Direct link to OpenFeature Provider\")\n\nIf you are using OpenFeature, we have created a [GrowthBook Provider](https://github.com/open-feature/js-sdk-contrib/tree/main/libs/providers/growthbook-client) that you can use client-side. Simply import our package and set `GrowthbookClientProvider` as the provider for your OpenFeature client. Similarly to using our SDK directly, you'll want to pass in GrowthBook `Context` into the new provider instance as well as any `InitOptions`.\n\n```\nimport { GrowthBook, Context, InitOptions } from '@growthbook/growthbook';import { GrowthbookClientProvider } from '@openfeature/growthbook-client-provider';/* * Configure your GrowthBook instance with GrowthBook context * @see https://docs.growthbook.io/lib/js#step-1-configure-your-app */const gbContext: Context = {  apiHost: 'https://cdn.growthbook.io',  clientKey: 'sdk-abc123',  // Only required if you have feature encryption enabled in GrowthBook  decryptionKey: 'key_abc123',};/* * optional init options * @see https://docs.growthbook.io/lib/js#switching-to-init */const initOptions: InitOptions = {  timeout: 2000,  streaming: true,};OpenFeature.setProvider(new GrowthbookClientProvider(gbContext, initOptions));\n```\n\n## Node.js[​](#nodejs \"Direct link to Node.js\")\n\nThe GrowthBook SDK officially supports Node v18 and above.\n\nIn browser environments, you typically want a single global GrowthBook instance.\n\nIn server environments, you instead want a separate GrowthBook instance for every incoming request. Here's an example middleware you can use:\n\n```\n// Example using Expressapp.use(function(req, res, next) {  // Create a GrowthBook instance and store in the request  req.growthbook = new GrowthBook({    apiHost: \"https://cdn.growthbook.io\",    clientKey: \"sdk-abc123\"  });  // Clean up at the end of the request  res.on('close', () => req.growthbook.destroy());  // Wait for features to load (will be cached in-memory for future requests)  req.growthbook.init({timeout: 1000}).then(() => next())});\n```\n\nThen, you can access the GrowthBook instance from any route:\n\n```\napp.get(\"/\", (req, res) => {  const gb = req.growthbook;  // ...})\n```\n\n## Loading Features and Experiments[​](#loading-features-and-experiments \"Direct link to Loading Features and Experiments\")\n\nIn order for the GrowthBook SDK to work, it needs to have feature and experiment definitions from the GrowthBook API. There are a few ways to get this data into the SDK.\n\n### Built-in Fetching and Caching[​](#built-in-fetching-and-caching \"Direct link to Built-in Fetching and Caching\")\n\nIf you pass an `apiHost` and `clientKey` into the GrowthBook constructor, it will handle the network requests, caching, retry logic, etc. for you automatically. If your feature payload is encrypted, you can also pass in a `decryptionKey`.\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  // Only required if you have feature encryption enabled in GrowthBook  decryptionKey: \"key_abc123\",});// Wait for features to be downloaded with a timeout (in ms)await gb.init({  timeout: 2000,});\n```\n\nUntil features are loaded, all features will evaluate to `null`. If you're ok with a potential flicker in your application (features going from `null` to their real value), you can call `init` without awaiting the result.\n\nIf you want to refresh the features at any time (e.g. when a navigation event occurs), you can call `gb.refreshFeatures()`.\n\n#### Error Handling[​](#error-handling \"Direct link to Error Handling\")\n\nIn the case of network issues, the `init` call will not throw an error. Instead, it will stay in the default state where every feature evaluates to `null`.\n\nYou can still get access to the error if needed:\n\n```\nconst res = await gb.init({  timeout: 1000});console.log(res);\n```\n\nThe return value has 3 properties:\n\n*   **status** - `true` if the GrowthBook instance was populated with features/experiments. Otherwise `false`\n*   **source** - Where this result came from. One of the following values: `network`, `cache`, `init`, `error`, or `timeout`\n*   **error** - If status is `false`, this will contain an `Error` object with more details about the error\n\n### Custom Integration[​](#custom-integration \"Direct link to Custom Integration\")\n\nIf you prefer to handle the network and caching logic yourself, you can pass in a full JSON \"payload\" directly into the SDK. For example, you might store features in Postgres and send it down to your front-end as part of your app's initial bootstrap API call.\n\n```\nawait gb.init({  payload: {    features: {      \"feature-1\": {...},      \"feature-2\": {...},      \"another-feature\": {...},    }  }})\n```\n\nThe data structure for \"payload\" is exactly the same as what is returned by the GrowthBook SDK endpoints and webhooks.\n\nYou can update the payload at any time by calling `setPayload(newPayloadJSON)` and there are also `getPayload()` and `getDecryptedPayload()` methods, which are useful in hybrid apps where you want to hydrate the client with data from the server.\n\nNote: you don't need to specify `clientKey` or `apiHost` on your GrowthBook instance unless you want to enable streaming (see below) or call `refreshFeatures()` later.\n\n#### Synchronous Init[​](#synchronous-init \"Direct link to Synchronous Init\")\n\nThere is a alternate synchronous version of init named `initSync`, which can be useful in some environments. There are some restrictions/differences:\n\n*   You MUST pass in `payload`\n*   The `payload` MUST NOT have encrypted features or experiments\n*   If you use sticky bucketing, you MUST pass `stickyBucketAssignmentDocs` into your GrowthBook constructor\n*   The return value is the GrowthBook instance to enable easy method chaining\n\n## Streaming Updates[​](#streaming-updates \"Direct link to Streaming Updates\")\n\nThe GrowthBook SDK supports streaming with Server-Sent Events (SSE). When enabled, changes to features within GrowthBook will be streamed to the SDK in realtime as they are published. This is only supported on GrowthBook Cloud or if running a GrowthBook Proxy Server.\n\n### Streaming in Browser Environments[​](#streaming-in-browser-environments \"Direct link to Streaming in Browser Environments\")\n\nSSE is supported on all major browsers, so enabling streaming is as easy as passing `streaming: true` into your `init` call:\n\n```\ngb.init({  streaming: true,  // Other settings...})\n```\n\nYou may also differentiate your streaming host URL from your API host by setting the `streamingHost` property in the GrowthBook constructor (ex: Remote Evaluation is done on a CDN edge worker while Streaming is done through a GrowthBook Proxy server).\n\n### Streaming in Node.js[​](#streaming-in-nodejs \"Direct link to Streaming in Node.js\")\n\nNode.js does not natively support SSE, but there is a small library you can install:\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save eventsource\n```\n\nInstead of enabling streaming separately for every GrowthBook instance, we recommend opening a single shared stream at app startup instead:\n\n```\nconst { setPolyfills, prefetchPayload } = require(\"@growthbook/growthbook\");// Configure GrowthBook to use the eventsource librarysetPolyfills({  EventSource: require(\"eventsource\"),});// Start a streaming connectionprefetchPayload({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  streaming: true}).then(() => console.log(\"Streaming connection open!\"))\n```\n\nThis will work as long as you use the exact same `apiHost` and `clientKey` when creating GrowthBook instances in your middleware.\n\n## Remote Evaluation[​](#remote-evaluation \"Direct link to Remote Evaluation\")\n\nWhen used in a front-end context, the JS SDK may be run in Remote Evaluation mode. This mode brings the security benefits of a backend SDK to the front end by evaluating feature flags exclusively on a private server. Using Remote Evaluation ensures that any sensitive information within targeting rules or unused feature variations are never seen by the client. Note that Remote Evaluation should not be used in a backend context.\n\nYou must enable Remote Evaluation in your SDK Connection settings. Cloud customers are also required to self-host a GrowthBook Proxy Server or custom remote evaluation backend.\n\nTo use Remote Evaluation, add the `remoteEval: true` property to your SDK instance. A new evaluation API call will be made any time a user attribute or other dependency changes. You may optionally limit these API calls to specific attribute changes by setting the `cacheKeyAttributes` property (an array of attribute names that, when changed, trigger a new evaluation call).\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://gb-proxy.mydomain.io/\",  clientKey: \"sdk-abc123\",  // Enable remote evaluation  remoteEval: true,  // Optional: only trigger a new evaluation call when the `id` and `email` attribute changes  cacheKeyAttributes: [\"id\", \"email\"],});\n```\n\nnote\n\nIf you would like to implement Sticky Bucketing while using Remote Evaluation, you must configure your remote evaluation backend to support Sticky Bucketing. In the case of the GrowthBook Proxy Server, this means implementing a Redis database for sticky bucketing use. You will not need to provide a StickyBucketService instance to the client side SDK.\n\n## Caching[​](#caching \"Direct link to Caching\")\n\nThe JavaScript SDK has 2 caching layers:\n\n1.  In-memory cache (available on all platforms)\n2.  Persistent localStorage cache (only available in browsers by default)\n\nThere are a number of cache settings you can configure within GrowthBook. This must be done BEFORE creating a GrowthBook instance.\n\nBelow are all of the default values. You can call `configureCache` with a subset of these fields and the rest will keep their default values.\n\n```\nimport { configureCache } from \"@growthbook/growthbook\";configureCache({  // The localStorage key the cache will be stored under  cacheKey: \"gbFeaturesCache\",  // Consider features stale after this much time (60 seconds default)  staleTTL: 1000 * 60,  // Cached features older than this will be ignored (24 hours default)  maxAge: 1000 * 60 * 60 * 24,  // For Remote Eval only - limit the number of cache entries (~1 entry per user)  maxEntries: 10,  // When `false`, we add a `visibilitychange` listener to disable SSE when the page is idle  disableIdleStreams: false,  // Consider a page \"idle\" when it is hidden for this long (default 20 seconds)  idleStreamInterval: 20000,  // Set to `true` to completely disable both in-memory and persistent caching  disableCache: false,})\n```\n\n### Polyfilling localStorage[​](#polyfilling-localstorage \"Direct link to Polyfilling localStorage\")\n\nOutside of a browser environment, you can still use persistent caching. You just need to provide an implementation of the localStorage interface.\n\nHere's an example of using Redis in Node.js:\n\n```\nconst { setPolyfills } = require(\"@growthbook/growthbook\");setPolyfills({  localStorage: {    // Example using Redis    getItem: (key) => redisClient.get(key),    setItem: (key, value) => redisClient.set(key, value),  }});\n```\n\nThis must be done BEFORE you call either `prefetchPayload` or create the first GrowthBook instance.\n\n## Re-rendering When Features Change[​](#re-rendering-when-features-change \"Direct link to Re-rendering When Features Change\")\n\nWhen features change (e.g. by calling `gb.refreshFeatures()`), you need to re-render your app so that all of your feature flag checks can be re-evaluated. You can specify your own custom rendering function for this purpose:\n\n```\n// Callback to re-render your app when feature flag values changegb.setRenderer(() => {  // TODO: re-render your app});\n```\n\n## Experimentation (A/B Testing)[​](#experimentation-ab-testing \"Direct link to Experimentation (A/B Testing)\")\n\nIn order to run A/B tests, you need to set up a tracking callback function. This is called every time a user is put into an experiment and can be used to track the exposure event in your analytics system (Segment, Mixpanel, GA, etc.).\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  trackingCallback: (experiment, result) => {    // Example using Segment    analytics.track(\"Experiment Viewed\", {      experimentId: experiment.key,      variationId: result.key,    });  },});\n```\n\nThis same tracking callback is used for both feature flag experiments and Visual Editor experiments.\n\n### Feature Flag Experiments[​](#feature-flag-experiments \"Direct link to Feature Flag Experiments\")\n\nThere is nothing special you have to do for feature flag experiments. Just evaluate the feature flag like you would normally do. If the user is put into an experiment as part of the feature flag, it will call the `trackingCallback` automatically in the background.\n\n```\n// If this has an active experiment and the user is included,// it will call trackingCallback automaticallyconst newLogin = gb.isOn(\"new-signup-form\");\n```\n\nIf the experiment came from a feature rule, `result.featureId` in the trackingCallback will contain the feature id, which may be useful for tracking/logging purposes.\n\n### Visual Editor Experiments[​](#visual-editor-experiments \"Direct link to Visual Editor Experiments\")\n\nExperiments created through the GrowthBook Visual Editor will run automatically as soon as their targeting conditions are met.\n\n**Note**: Visual Editor experiments are only supported in a web browser environment. They will not run in Node.js, Mobile apps, or Desktop apps.\n\nIf you are using this SDK in a Single Page App (SPA), you will need to let the GrowthBook instance know when the URL changes so the active experiments can update accordingly.\n\n```\n// Call this every time a navigation event happens in your SPAfunction onRouteChange() {  gb.setURL(window.location.href);}\n```\n\nVisual Editor experiments are enabled by default, but can be disabled with various GrowthBook constructor settings:\n\n*   **disableVisualExperiments** - If true, all visual editor experiments will be skipped\n*   **disableJsInjection** - If true, any visual editor experiment that injects custom javascript will be skipped.\n\n#### Content Security Policy[​](#content-security-policy \"Direct link to Content Security Policy\")\n\nIf you plan to use the Custom Javascript feature of the Visual Editor and you have a Content Security Policy on your site, there are two options:\n\n1.  Enable `unsafe-inline` script-src\n2.  OR generate a unique nonce value, add it to your script-src directive, and pass it into the GrowthBook constructor as `jsInjectionNonce`\n\n### URL Redirect Experiments[​](#url-redirect-experiments \"Direct link to URL Redirect Experiments\")\n\nSimilarly to Visual Editor experiments, URL redirect tests will run automatically if targetting conditions are met.\n\nIf you are using this SDK in a Single Page App (SPA), you'll want to pass in a custom navigation function into the SDK (as default navigation for URL Redirects uses `window.location.replace(url)`) and set the `navigateDelay` to 0.\n\n```\n// Example in Next.jsimport router from \"next/router\";const gb = new GrowthBook({    navigate: (url) => router.replace(url),    navigateDelay: 0,    // ... other settings});\n```\n\nFor SPA's you will also need to let the GrowthBook instance know when the URL changes so the active experiments can update accordingly.\n\n```\n// Call this every time a navigation event happens in your SPAfunction onRouteChange() {  gb.setURL(window.location.href);}\n```\n\nURL Redirect experiments are enabled by default, but can be disabled with various GrowthBook constructor settings:\n\n*   **disableUrlRedirectExperiments** - If true, all URL Redirect experiments will be skipped\n*   **disableCrossOriginUrlRedirectExperiments** - If true, any URL Redirect with a destination pointing to a different origin will be skipped.\n\n### Deferred Tracking[​](#deferred-tracking \"Direct link to Deferred Tracking\")\n\nSometimes, your analytics tracker is loaded after GrowthBook. In that case, you should not specify a `trackingCallback` in the constructor and instead use `setTrackingCallback` later when ready. When you do this, the GrowthBook instance will queue up tracking calls and then fire them all at once when you set the callback.\n\nThere are some scenarios where you need to queue up tracking calls in one GrowthBook instance and fire them in another. For example, if your analytics tracker is only available on the front-end, but you are running experiments in Node.js.\n\nExport the queue tracking calls with the `getDeferredTrackingCalls()` method. The result is a serializable JSON object:\n\n```\nconst tracks = gb.getDeferredTrackingCalls();\n```\n\nThen, import with `setDeferredTrackingCalls`. This does not fire them automatically. You must call `fireDeferredTrackingCalls` after.\n\n```\ngb2.setDeferredTrackingCalls(tracks);gb2.fireDeferredTrackingCalls();\n```\n\n### Sticky Bucketing[​](#sticky-bucketing \"Direct link to Sticky Bucketing\")\n\nSticky bucketing ensures that users see the same experiment variant, even when user session, user login status, or experiment parameters change. See the [Sticky Bucketing docs](https://docs.growthbook.io/app/sticky-bucketing) for more information. If your organization and experiment supports sticky bucketing, you must implement an instance of the `StickyBucketService` to use Sticky Bucketing. The JS SDK exports several implementations of this service for common use cases, or you may build your own:\n\n*   `LocalStorageStickyBucketService` — For simple bucket persistence using the browser's LocalStorage (can be polyfilled for other environments).\n    \n*   `BrowserCookieStickyBucketService` — For simple bucket persistence using browser cookies, which are transportable to the back end. Assumes `js-cookie` is implemented (can be polyfilled). Cookie attributes can also be configured.\n    \n*   `ExpressCookieStickyBucketService` — For NodeJS/Express controller-level bucket persistence using browser cookies; intended to be interoperable with `BrowserCookieStickyBucketService`. Assumes `cookie-parser` is implemented (can be polyfilled). Cookie attributes can also be configured.\n    \n*   `RedisStickyBucketService` — For NodeJS Redis-based bucket persistence. Requires an `ioredis` Redis client instance to be passed in.\n    \n*   Build your own — Implement the abstract `StickyBucketService` class and connect to your own data store, or custom wrap multiple service implementations (ex: read/write to both cookies and Redis).\n    \n\nImplementing most StickyBucketService implementations is straightforward and works with minimal setup. For instance, to use the `BrowserCookieStickyBucketService`:\n\n```\nimport { BrowserCookieStickyBucketService } from \"@growthbook/growthbook\";import Cookies from 'js-cookie';const gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  stickyBucketService: new BrowserCookieStickyBucketService({    jsCookie: Cookies,  }),  // ...});\n```\n\n## TypeScript[​](#typescript \"Direct link to TypeScript\")\n\nWhen used in a TypeScript project, GrowthBook includes basic type inference out of the box:\n\n```\n// Type will be `string` based on the fallback provided (\"blue\")const color = gb.getFeatureValue(\"button-color\", \"blue\");// You can manually specify types as well// feature.value will be type `number`const feature = gb.evalFeature<number>(\"font-size\");console.log(feature.value);// Experiments will use the variations to infer the return value// result.value will be type \"string\"const result = gb.run({  key: \"my-test\",  variations: [\"blue\", \"green\"],});\n```\n\n### Strict Typing[​](#strict-typing \"Direct link to Strict Typing\")\n\nIf you want to enforce stricter types in your application, you can do that when creating the GrowthBook instance:\n\n```\n// Define all your feature flags and types hereinterface AppFeatures {  \"button-color\": string;  \"font-size\": number;  \"newForm\": boolean;}// Pass into the GrowthBook instanceconst gb = new GrowthBook<AppFeatures>({  ...});\n```\n\nNow, all feature flag methods will be strictly typed.\n\n```\n// feature.value will by type `number`const feature = gb.evalFeature(\"font-size\");console.log(feature.value);// Typos will cause compile-time errorsgb.isOn(\"buton-color\"); // \"buton\" instead of \"button\"\n```\n\nInstead of defining the `AppFeatures` interface manually like above, you can auto-generate it from your GrowthBook account using the [GrowthBook CLI](https://docs.growthbook.io/tools/cli).\n\n## Updating[​](#updating \"Direct link to Updating\")\n\nAs a general philosophy, we aim to keep the SDK 100% backwards compatible at all times. View the [Changelog](https://github.com/growthbook/growthbook/blob/main/packages/sdk-js/CHANGELOG.md) for a complete list of all SDK changes.\n\n### Updating to 1.0.0[​](#updating-to-100 \"Direct link to Updating to 1.0.0\")\n\nUpdating from a **0.X.X** release to **1.0.0** is still backwards compatible for the vast majority of use cases, although there are a few minor changes:\n\n*   The `enableDevMode: true` setting previously also disabled cache as a side-effect. This is no longer the case in 1.0.0, and you must explicitly also set `disableCache: true`\n*   Previously, a network request to fetch features was started immediately upon creating a GrowthBook instance. Starting in 1.0.0, it waits until you call `loadFeatures` (or the new `init` method) before starting the network request. As a replacement, there is now a standalone `prefetchPayload` function that you can use to kick off a network request outside of the context of a GrowthBook instance.\n\n#### Switching to init[​](#switching-to-init \"Direct link to Switching to init\")\n\nGrowthBook 1.0.0 introduced a new `init` (and `initSync`) method.\n\nWe recommend everyone starts using this in their implementation. It solves many pain points including easier error handling and more control over caching and streaming.\n\nFor those currently using `loadFeatures`, `init` is a direct replacement. The only difference is that streaming is now opt-in instead of on-by-default.\n\n```\n// Previousawait gb.loadFeatures({ timeout: 1000 });// Newawait gb.init({ timeout: 1000, streaming: true });\n```\n\nFor those currently NOT using `loadFeatures` and passing features/experiments directly into the GrowthBook constructor, `init` and `initSync` can be used instead. The code below assumes you have a `payload` variable with the contents from the SDK Connection Endpoint.\n\n```\n// Previousconst gb = new GrowthBook({  features: payload.features,  experiments: payload.experiments});// New (async)const gb = new GrowthBook();await gb.init({ payload: payload });// New (non-async)const gb = (new GrowthBook()).initSync({ payload: payload });\n```\n\n## GrowthBook Instance (reference)[​](#growthbook-instance-reference \"Direct link to GrowthBook Instance (reference)\")\n\n### Attributes[​](#attributes \"Direct link to Attributes\")\n\nYou can specify attributes about the current user and request. These are used for two things:\n\n1.  Feature targeting (e.g. paid users get one value, free users get another)\n2.  Assigning persistent variations in A/B tests (e.g. user id \"123\" always gets variation B)\n\nThe following are some commonly used attributes, but use whatever makes sense for your application.\n\n```\nnew GrowthBook({  attributes: {    id: \"123\",    loggedIn: true,    deviceId: \"abc123def456\",    company: \"acme\",    paid: false,    url: \"/pricing\",    browser: \"chrome\",    mobile: false,    country: \"US\",  },});\n```\n\n#### Updating Attributes[​](#updating-attributes \"Direct link to Updating Attributes\")\n\nIf attributes change, you can call `setAttributes()` to update. This will completely overwrite any existing attributes. To do a partial update, use the following pattern:\n\n```\ngb.setAttributes({  // Only update the `url` attribute, keep the rest the same  ...gb.getAttributes(),  url: \"/new-page\"})\n```\n\n#### Secure Attributes[​](#secure-attributes \"Direct link to Secure Attributes\")\n\nWhen _secure attribute hashing_ is enabled, all targeting conditions in the SDK payload referencing attributes with datatype `secureString` or `secureString[]` will be anonymized via SHA-256 hashing. This allows you to safely target users based on sensitive attributes. You must enable this feature in your SDK Connection for it to take effect.\n\nIf your SDK Connection has secure attribute hashing enabled, you will need to manually hash any `secureString` or `secureString[]` attributes that you pass into the GrowthBook SDK.\n\nTo hash an attribute, use a cryptographic library with SHA-256 support, and compute the SHA-256 hashed value of your attribute _plus_ your organization's secure attribute salt.\n\n```\nconst salt = \"f09jq3fij\"; // Your organization's secure attribute salt (see Organization Settings)// hashing a secureString attributeconst userEmail = sha256(salt + user.email);// hashing an secureString[] attributeconst userTags = user.tags.map(tag => sha256(salt + tag));gb.setAttributes({  id: user.id,  loggedIn: true,  email: userEmail,  tags: userTags,});await gb.init();// In this example, we are using Node.js's built-in crypto libraryfunction sha256(str) {  return crypto.createHash(\"sha256\").update(str).digest(\"hex\");}\n```\n\nNote that in a browser context, we will not be able to natively access the Node.js crypto library. In modern browsers `window.crypto.subtle` is available, although calls are asynchronous. You would need to await all attribute hashing to complete before calling `gb.setAttributes()`.\n\n```\nasync function sha256(str) {  const buffer = await crypto.subtle.digest(\"SHA-256\", new TextEncoder().encode(str));  const hashArray = Array.from(new Uint8Array(buffer));  return hashArray.map(byte => byte.toString(16).padStart(2, \"0\")).join(\"\");}\n```\n\nAlternatively, CryptoJS ([https://www.npmjs.com/package/crypto-js](https://www.npmjs.com/package/crypto-js)) provides a synchronous API:\n\n```\nimport sha256 from 'crypto-js/sha256';const userEmail = sha256(salt + user.email);\n```\n\n### Feature Usage Callback[​](#feature-usage-callback \"Direct link to Feature Usage Callback\")\n\nGrowthBook can fire a callback whenever a feature is evaluated for a user. This can be useful to update 3rd party tools like NewRelic or DataDog.\n\n```\nnew GrowthBook({  onFeatureUsage: (featureKey, result) => {    console.log(\"feature\", featureKey, \"has value\", result.value);  },});\n```\n\nThe `result` argument is the same thing returned from `gb.evalFeature`.\n\nNote: If you evaluate the same feature multiple times (and the value doesn't change), the callback will only be fired the first time.\n\n### Dev Mode[​](#dev-mode \"Direct link to Dev Mode\")\n\nThere is a [GrowthBook Chrome DevTools Extension](https://chrome.google.com/webstore/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia) that can help you debug and test your feature flags in development.\n\nIn order for this to work, you must explicitly enable dev mode when creating your GrowthBook instance:\n\n```\nconst gb = new GrowthBook({  enableDevMode: true,});\n```\n\nTo avoid exposing all of your internal feature flags and experiments to users, we recommend setting this to `false` in production in most cases.\n\n### evalFeature[​](#evalfeature \"Direct link to evalFeature\")\n\nIn addition to the `isOn` and `getFeatureValue` helper methods, there is the `evalFeature` method that gives you more detailed information about why the value was assigned to the user.\n\n```\n// Get detailed information about the feature evaluationconst result = gb.evalFeature(\"my-feature\");// The value of the feature (or `null` if not defined)console.log(result.value);// Why the value was assigned to the user// One of: `override`, `unknownFeature`, `defaultValue`, `force`, or `experiment`console.log(result.source);// The string id of the rule (if any) which was usedconsole.log(result.ruleId);// Information about the experiment (if any) which was usedconsole.log(result.experiment);// The result of the experiment (or `undefined`)console.log(result.experimentResult);\n```\n\n### Inline Experiments[​](#inline-experiments \"Direct link to Inline Experiments\")\n\nInstead of declaring all features up-front in the context and referencing them by ids in your code, you can also just run an experiment directly. This is done with the `gb.run` method:\n\n```\n// These are the only required optionsconst { value } = gb.run({  key: \"my-experiment\",  variations: [\"red\", \"blue\", \"green\"],});\n```\n\n#### Customizing the Traffic Split[​](#customizing-the-traffic-split \"Direct link to Customizing the Traffic Split\")\n\nBy default, this will include all traffic and do an even split between all variations. There are 2 ways to customize this behavior:\n\n```\n// Option 1: Using weights and coveragegb.run({  key: \"my-experiment\",  variations: [\"red\", \"blue\", \"green\"],  // Only include 10% of traffic  coverage: 0.1,  // Split the included traffic 50/25/25 instead of the default 33/33/33  weights: [0.5, 0.25, 0.25],});// Option 2: Specifying rangesgb.run({  key: \"my-experiment\",  variations: [\"red\", \"blue\", \"green\"],  // Identical to the above  // 5% of traffic in A, 2.5% each in B and C  ranges: [    [0, 0.05],    [0.5, 0.525],    [0.75, 0.775],  ],});\n```\n\n#### Hashing[​](#hashing \"Direct link to Hashing\")\n\nWe use deterministic hashing to assign a variation to a user. We hash together the user's id and experiment key, which produces a number between `0` and `1`. Each variation is assigned a range of numbers, and whichever one the user's hash value falls into will be assigned.\n\nYou can customize this hashing behavior:\n\n```\ngb.run({  key: \"my-experiment\",  variations: [\"A\", \"B\"],  // Which hashing algorithm to use  // Version 2 is the latest and the one we recommend  hashVersion: 2,  // Use a different seed instead of the experiment key  seed: \"abcdef123456\",  // Use a different user attribute (default is `id`)  hashAttribute: \"device_id\",});\n```\n\n**Note**: For backwards compatibility, if no `hashVersion` is specified, it will fall back to using version `1`, which is deprecated. In the future, version `2` will become the default. We recommend specifying version `2` now for all new experiments to avoid migration issues down the line.\n\n#### Meta Info[​](#meta-info \"Direct link to Meta Info\")\n\nYou can also define meta info for the experiment and/or variations. These do not affect the behavior, but they are passed through to the `trackingCallback`, so they can be used to annotate events.\n\n```\ngb.run({  key: \"results-per-page\",  variations: [10, 20],  // Experiment meta info  name: \"Results per Page\",  phase: \"full-traffic\"  // Variation meta info  meta: [    {      key: \"control\",      name: \"10 Results per Page\",    },    {      key: \"variation\",      name: \"20 Results per Page\",    },  ]})\n```\n\n#### Mutual Exclusion[​](#mutual-exclusion \"Direct link to Mutual Exclusion\")\n\nSometimes you want to run multiple conflicting experiments at the same time. You can use the `filters` setting to run mutually exclusive experiments.\n\nWe do this using deterministic hashing to assign users a value between 0 and 1 for each filter.\n\n```\n// Will include 60% of users - ones with a hash between 0 and 0.6gb.run({  key: \"experiment-1\",  variation: [0, 1],  filters: [    {      seed: \"pricing\",      attribute: \"id\",      ranges: [[0, 0.6]]    }  ]});// Will include the other 40% of users - ones with a hash between 0.6 and 1gb.run({  key: \"experiment-2\",  variation: [0, 1],  filters: [    {      seed: \"pricing\",      attribute: \"id\",      ranges: [[0.6, 1.0]]    }  ]});\n```\n\n**Note** - If a user is excluded from an experiment due to a filter, the rule will be skipped and the next matching rule will be used instead.\n\n#### Holdout Groups[​](#holdout-groups \"Direct link to Holdout Groups\")\n\nTo use global holdout groups, use a nested experiment design:\n\n```\n// The value will be `true` if in the holdout group, otherwise `false`const holdout = gb.run({  key: \"holdout\",  variations: [true, false],  // 10% of users in the holdout group  weights: [0.1, 0.9]});// Only run your main experiment if the user is NOT in the holdoutif (!holdout.value) {  const res = gb.run({    key: \"my-experiment\",    variations: [\"A\", \"B\"]  })}\n```\n\n#### Targeting Conditions[​](#targeting-conditions \"Direct link to Targeting Conditions\")\n\nYou can also define targeting conditions that limit which users are included in the experiment. These conditions are evaluated against the `attributes` passed into the GrowthBook context. The syntax for conditions is based on the MongoDB query syntax and is straightforward to read and write.\n\nFor example, if the attributes are:\n\n```\n{  \"id\": \"123\",  \"browser\": {    \"vendor\": \"firefox\",    \"version\": 94  },  \"country\": \"CA\"}\n```\n\nThe following condition would evaluate to `true` and the user would be included in the experiment:\n\n```\ngb.run({  key: \"my-experiment\",  variation: [0, 1],  condition: {    \"browser.vendor\": \"firefox\",    \"country\": {      \"$in\": [\"US\", \"CA\", \"IN\"]    }  }})\n```\n\n#### Inline Experiment Return Value[​](#inline-experiment-return-value \"Direct link to Inline Experiment Return Value\")\n\nA call to `gb.run(experiment)` returns an object with a few useful properties:\n\n```\nconst {  value,  key,  name,  variationId,  inExperiment,  hashUsed,  hashAttribute,  hashValue,} = gb.run({  key: \"my-experiment\",  variations: [\"A\", \"B\"],});// If user is included in the experimentconsole.log(inExperiment); // true or false// The index of the assigned variationconsole.log(variationId); // 0 or 1// The value of the assigned variationconsole.log(value); // \"A\" or \"B\"// The key and name of the assigned variation (if specified in `meta`)console.log(key); // \"0\" or \"1\"console.log(name); // \"\"// If the variation was randomly assigned by hashingconsole.log(hashUsed);// The user attribute that was hashedconsole.log(hashAttribute); // \"id\"// The value of that attributeconsole.log(hashValue); // e.g. \"123\"\n```\n\nThe `inExperiment` flag will be false if the user was excluded from being part of the experiment for any reason (e.g. failed targeting conditions).\n\nThe `hashUsed` flag will only be true if the user was randomly assigned a variation. If the user was forced into a specific variation instead, this flag will be false.\n\n## Feature Definitions (reference)[​](#feature-definitions-reference \"Direct link to Feature Definitions (reference)\")\n\nThe feature definition JSON file contains information about all of the features in your application.\n\nEach feature consists of a unique key, a list of possible values, and rules for how to assign those values to users.\n\n```\n{  \"feature-1\": {...},  \"feature-2\": {...},  \"another-feature\": {...},}\n```\n\n### Basic Feature[​](#basic-feature \"Direct link to Basic Feature\")\n\nAn empty feature always has the value `null`:\n\n#### Default Values[​](#default-values \"Direct link to Default Values\")\n\nYou can change the default assigned value with the `defaultValue` property:\n\n```\n{  \"my-feature\": {    defaultValue: \"green\"  }}\n```\n\n### Override Rules[​](#override-rules \"Direct link to Override Rules\")\n\nYou can override the default value with **rules**.\n\nRules give you fine-grained control over how feature values are assigned to users. There are 2 types of feature rules: `force` and `experiment`. Force rules give the same value to everyone. Experiment rules assign values to users randomly.\n\n#### Rule Ids[​](#rule-ids \"Direct link to Rule Ids\")\n\nRules can specify a unique identifier with the `id` property. This can help with debugging and QA by letting you see exactly why a specific value was assigned to a user.\n\n#### Rule Conditions[​](#rule-conditions \"Direct link to Rule Conditions\")\n\nRules can optionally define targeting conditions that limit which users the rule applies to. These conditions are evaluated against the `attributes` passed into the GrowthBook context. The syntax for conditions is based on the MongoDB query syntax and is straightforward to read and write.\n\nFor example, if the attributes are:\n\n```\n{  \"id\": \"123\",  \"browser\": {    \"vendor\": \"firefox\",    \"version\": 94  },  \"country\": \"CA\"}\n```\n\nThe following condition would evaluate to `true`:\n\n```\n{  \"browser.vendor\": \"firefox\",  \"country\": {    \"$in\": [\"US\", \"CA\", \"IN\"]  }}\n```\n\nIf a condition evaluates to `false`, the rule will be skipped. This means you can chain rules together with different conditions to support even the most complex use cases.\n\n#### Force Rules[​](#force-rules \"Direct link to Force Rules\")\n\nForce rules do what you'd expect - force a specific value for the feature\n\n```\n// Firefox users in the US or Canada get \"green\"// Everyone else gets the default \"blue\"{  \"button-color\": {    defaultValue: \"blue\",    rules: [      {        id: \"rule-123\",        condition: {          browser: \"firefox\",          country: {            $in: [\"US\", \"CA\"]          }        },        force: \"green\"      }    ],  }}\n```\n\n##### Gradual Rollouts[​](#gradual-rollouts \"Direct link to Gradual Rollouts\")\n\nYou can specify a `range` for your rule, which determines what percent of users will get the rule applied to them. Users who do not get the rule applied will fall through to the next matching rule (or default value). You can also specify a `seed` that will be used for hashing.\n\nIn order to figure out if a user is included or not, we use deterministic hashing. By default, we use the user attribute `id` for this, but you can override this by specifying `hashAttribute` for the rule:\n\nThis is useful for gradually rolling out features to users (start with a small range and slowly increase).\n\n```\n{  \"new-feature\": {    defaultValue: false,    rules: [      {        force: true,        hashAttribute: \"device-id\",        seed: 'new-feature-rollout-abcdef123',        // 20% of users        range: [0, 0.2]        // Increase to 40%:        // range: [0, 0.4]      }    ]  }}\n```\n\n#### Experiment Rules[​](#experiment-rules \"Direct link to Experiment Rules\")\n\nExperiment rules let you adjust the percent of users who get randomly assigned to each variation. This can either be used for hypothesis-driven A/B tests or to simply mitigate risk by gradually rolling out new features to your users.\n\n```\n// Each variation gets assigned to a random 1/3rd of users{  \"image-size\": {    rules: [      {        variations: [\"small\", \"medium\", \"large\"]      }    ]  }}\n```\n\n##### Customizing the Traffic Split[​](#customizing-the-traffic-split-1 \"Direct link to Customizing the Traffic Split\")\n\nBy default, an experiment rule will include all traffic and do an even split between all variations. There are 2 ways to customize this behavior:\n\n```\n// Option 1: Using weights and coverage{  variations: [\"red\", \"blue\", \"green\"],  // Only include 10% of traffic  coverage: 0.1,  // Split the included traffic 50/25/25 instead of the default 33/33/33  weights: [0.5, 0.25, 0.25]}// Option 2: Specifying ranges{  variations: [\"red\", \"blue\", \"green\"],  // Identical to the above  // 5% of traffic in A, 2.5% each in B and C  ranges: [    [0, 0.05],    [0.5, 0.525],    [0.75, 0.775]  ]}\n```\n\nA user is assigned a number from 0 to 1 and whichever variation's range includes their number will be assigned to them.\n\n##### Variation Meta Info[​](#variation-meta-info \"Direct link to Variation Meta Info\")\n\nYou can use the `meta` setting to provide additional info about the variations such as name.\n\n```\n{  \"image-size\": {    rules: [      {        variations: [\"sm\", \"md\", \"lg\"],        ranges: [          [0, 0.5],          [0.5, 0.75],          [0.75, 1.0]        ],        meta: [          {            key: \"control\",            name: \"Small\",          },          {            key: \"v1\",            name: \"Medium\",          },          {            key: \"v2\",            name: \"Large\",          }        ]      }    ]  }}\n```\n\n##### Tracking Key and Name[​](#tracking-key-and-name \"Direct link to Tracking Key and Name\")\n\nWhen a user is assigned a variation, we call the `trackingCallback` function so you can record the exposure with your analytics event tracking system. By default, we use the feature id to identify the experiment, but this can be overridden if needed with the `key` setting. You can also optionally provide a human-readable name.\n\n```\n{  \"feature-1\": {    rules: [      {        // Use \"my-experiment\" as the key instead of \"feature-1\"        key: \"my-experiment\",        name: \"My Experiment\",        variations: [\"A\", \"B\"]      }    ]  },}\n```\n\n##### Hash Attribute[​](#hash-attribute \"Direct link to Hash Attribute\")\n\nWe use deterministic hashing to make sure the same user always gets assigned the same value. By default, we use the attribute `id`, but this can be overridden with the `hashAttribute` setting:\n\n```\nconst gb = new GrowthBook({  attributes: {    id: \"123\",    company: \"acme\",  },  features: {    \"my-feature\": {      rules: [        // All users with the same \"company\" value        // will be assigned the same variation        {          variations: [\"A\", \"B\"],          hashAttribute: \"company\",        },        // If \"company\" is empty for the user (e.g. if they are logged out)        // The experiment will be skipped and fall through to this next rule        {          force: \"A\",        },      ],    },  },});\n```\n\n##### Filters[​](#filters \"Direct link to Filters\")\n\nSometimes you want to run multiple conflicting experiments at the same time. You can use the `filters` setting to run mutually exclusive experiments.\n\nWe do this using deterministic hashing to assign users a value between 0 and 1 for each filter.\n\n```\n{  \"feature1\": {    rules: [      // Will include 60% of users - ones with a hash between 0 and 0.6      {        variations: [false, true],        filters: [          {            seed: \"pricing\",            attribute: \"id\",            ranges: [[0, 0.6]]          }        ]      }    ]  },  \"feature2\": {    rules: [      // Will include the other 40% of users - ones with a hash between 0.6 and 1      {        variations: [false, true],        filters: [          {            seed: \"pricing\",            attribute: \"id\",            ranges: [[0.6, 1.0]]          }        ]      },    ]  }}\n```\n\n**Note** - If a user is excluded from an experiment due to a filter, the rule will be skipped and the next matching rule will be used instead.\n\n## Examples[​](#examples \"Direct link to Examples\")\n\n*   [Typescript example app with strict typing](https://github.com/growthbook/examples/tree/main/vanilla-typescript) .",
    "title": "Javascript SDK | GrowthBook Docs",
    "description": "GrowthBook SDK for Javascript",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/lib/react",
    "markdown": "# React SDK | GrowthBook Docs\n\n## ReactJS\n\nThis is a thin wrapper on top of the [Javascript Library](https://docs.growthbook.io/lib/js), so you might want to view those docs first to familiarize yourself with the basic classes and methods.\n\nThis SDK supports both ReactJS and ReactNative environments.\n\n**Important**: Starting in version 1.0.0, you must always pass a GrowthBook instance into the GrowthBookProvider. In previous versions, you were allowed to pass `null` as well.\n\n## Installation[​](#installation \"Direct link to Installation\")\n\nInstall with a package manager\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save @growthbook/growthbook-react\n```\n\n## Quick Usage[​](#quick-usage \"Direct link to Quick Usage\")\n\n### Step 1: Configure your app[​](#step-1-configure-your-app \"Direct link to Step 1: Configure your app\")\n\n```\nimport { useEffect } from \"react\";import { GrowthBook, GrowthBookProvider } from \"@growthbook/growthbook-react\";// Create a GrowthBook instanceconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  enableDevMode: true,  // Only required for A/B testing  // Called every time a user is put into an experiment  trackingCallback: (experiment, result) => {    console.log(\"Experiment Viewed\", {      experimentId: experiment.key,      variationId: result.key,    });  },});gb.init({  // Optional, enable streaming updates  streaming: true})export default function App() {  useEffect(() => {    // Set user attributes for targeting (from cookie, auth system, etc.)    gb.setAttributes({      id: user.id,      company: user.company,    });  }, [user])  return (    <GrowthBookProvider growthbook={gb}>      <OtherComponent />    </GrowthBookProvider>  );}\n```\n\n### Step 2: Start feature flagging![​](#step-2-start-feature-flagging \"Direct link to Step 2: Start feature flagging!\")\n\nThere are a few ways to use feature flags in GrowthBook:\n\n## OpenFeature Provider[​](#openfeature-provider \"Direct link to OpenFeature Provider\")\n\nIf you are using OpenFeature, we have created a [GrowthBook Provider](https://github.com/open-feature/js-sdk-contrib/tree/main/libs/providers/growthbook-client) that you can use client-side. Simply import our package and set `GrowthbookClientProvider` as the provider for your OpenFeature client. Similarly to using our SDK directly, you'll want to pass in GrowthBook `Context` into the new provider instance as well as any `InitOptions`.\n\n```\nimport { OpenFeature, OpenFeatureProvider, useFlag } from \"@openfeature/react-sdk\";import { GrowthBook, Context, InitOptions } from '@growthbook/growthbook';import { GrowthbookClientProvider } from '@openfeature/growthbook-client-provider';OpenFeature.setProvider(  new GrowthbookClientProvider(context, { streaming: true }));function Page() {  const { value: showNewMessage } = useFlag(\"new-message\", true);  const gbContext: Context = {    apiHost: 'https://cdn.growthbook.io',    clientKey: 'sdk-abc123',    // Only required if you have feature encryption enabled in GrowthBook    decryptionKey: 'key_abc123',  };  return (    <div className='App'>      <header className='App-header'>        <div>OpenFeature Testing React App</div>      </header>      <p>        {showNewMessage ? (          <p>Welcome to this OpenFeature enabled React app!</p>        ) : (          <p>Welcome to this React app.</p>        )}      </p>    </div>  );}\n```\n\n#### Feature Hooks[​](#feature-hooks \"Direct link to Feature Hooks\")\n\n```\nimport { useFeatureValue, useFeatureIsOn } from \"@growthbook/growthbook-react\";export default function OtherComponent() {  // Boolean on/off features  const newLogin = useFeatureIsOn(\"new-login-form\");  // String/Number/JSON features with a fallback value  const buttonColor = useFeatureValue(\"login-button-color\", \"blue\");  if (newLogin) {    return <NewLogin color={buttonColor} />;  } else {    return <Login color={buttonColor} />;  }}\n```\n\n#### Feature Wrapper Components[​](#feature-wrapper-components \"Direct link to Feature Wrapper Components\")\n\n```\nimport { IfFeatureEnabled, FeatureString } from \"@growthbook/growthbook-react\";export default function OtherComponent() {  return (    <div>      <h1>        <FeatureString feature=\"site-h1\" default=\"My Site\"/>      </h1>      <IfFeatureEnabled feature=\"welcome-message\">        <p>Welcome to our site!</p>      </IfFeatureEnabled>    </div>  );}\n```\n\n#### useGrowthBook hook[​](#usegrowthbook-hook \"Direct link to useGrowthBook hook\")\n\nIf you need low-level access to the GrowthBook instance for any reason, you can use the `useGrowthBook` hook.\n\nOne example is updating targeting attributes when a user logs in:\n\n```\nimport { useGrowthBook } from \"@growthbook/growthbook-react\";export default function Auth() {  const growthbook = useGrowthBook();  const user = useUser();  useEffect(() => {    if (!user) return;    growthbook.setAttributes({      loggedIn: true,      id: user.id,      company: user.company,      isPro: user.plan === \"pro\"    })  }, [user, growthbook])  ...}\n```\n\n## Loading Features[​](#loading-features \"Direct link to Loading Features\")\n\nIn order for the GrowthBook SDK to work, it needs to have feature definitions from the GrowthBook API. There are 2 ways to get this data into the SDK.\n\n### Built-in Fetching and Caching[​](#built-in-fetching-and-caching \"Direct link to Built-in Fetching and Caching\")\n\nIf you pass an `apiHost` and `clientKey` into the GrowthBook constructor, it will handle the network requests, caching, retry logic, etc. for you automatically. If your feature payload is encrypted, you can also pass in a `decryptionKey`.\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  // Only required if you have feature encryption enabled in GrowthBook  decryptionKey: \"key_abc123\",});await gb.init({  // If the network request takes longer than this (in milliseconds), continue  // Default: `0` (no timeout)  timeout: 2000,})\n```\n\nUntil features are loaded, all features will evaluate to `null`. If you're ok with a potential flicker in your application (features going from `null` to their real value), you can call `init` without awaiting the result.\n\nIf you want to refresh the features at any time (e.g. when a navigation event occurs), you can call `gb.refreshFeatures()`.\n\n#### Error Handling[​](#error-handling \"Direct link to Error Handling\")\n\nIn the case of network issues, the `init` call will not throw an error. Instead, it will stay in the default state where every feature evaluates to `null`.\n\nYou can still get access to the error if needed:\n\n```\nconst res = await gb.init({  timeout: 1000});console.log(res);\n```\n\nThe return value has 3 properties:\n\n*   **status** - `true` if the GrowthBook instance was populated with features/experiments. Otherwise `false`\n*   **source** - Where this result came from. One of the following values: `network`, `cache`, `init`, `error`, or `timeout`\n*   **error** - If status is `false`, this will contain an `Error` object with more details about the error\n\n### Custom Integration[​](#custom-integration \"Direct link to Custom Integration\")\n\nIf you prefer to handle the network and caching logic yourself, you can pass in a full JSON \"payload\" directly into the SDK. For example, you might store features in Postgres and send it down to your front-end as part of your app's initial bootstrap API call.\n\n```\nawait gb.init({  payload: {    features: {      \"feature-1\": {...},      \"feature-2\": {...},      \"another-feature\": {...},    }  }})\n```\n\nThe data structure for \"payload\" is exactly the same as what is returned by the GrowthBook SDK endpoints and webhooks.\n\nYou can update the payload at any time by calling `setPayload(newPayloadJSON)` and there are also `getPayload()` and `getDecryptedPayload()` methods, which are useful in hybrid apps where you want to hydrate the client with data from the server.\n\nNote: you don't need to specify `clientKey` or `apiHost` on your GrowthBook instance unless you want to enable streaming (see below) or call `refreshFeatures()` later.\n\n#### Synchronous Init[​](#synchronous-init \"Direct link to Synchronous Init\")\n\nThere is a alternate synchronous version of init named `initSync`, which can be especially useful in SSR to prevent hydration mismatches. There are some restrictions/differences:\n\n*   You MUST pass in `payload`\n*   The `payload` MUST NOT have encrypted features or experiments\n*   If you use sticky bucketing, you MUST pass `stickyBucketAssignmentDocs` into your GrowthBook constructor\n*   The return value is the GrowthBook instance to enable easy method chaining\n\n## Waiting for Features to Load[​](#waiting-for-features-to-load \"Direct link to Waiting for Features to Load\")\n\nThere is a helper component `<FeaturesReady>` that lets you render a fallback component until features are done loading. This works for both built-in fetching and custom integrations.\n\n```\n<FeaturesReady timeout={500} fallback={<LoadingSpinner/>}>  <ComponentThatUsesFeatures/></FeaturesReady>\n```\n\n*   `timeout` is the max time you want to wait for features to load (in ms). The default is `0` (no timeout).\n*   `fallback` is the component you want to display before features are loaded. The default is `null`.\n\nIf you want more control, you can use the `useGrowthBook()` hook and the `ready` flag:\n\n```\nconst gb = useGrowthBook();if (gb.ready) {  // Do something}\n```\n\n## Streaming Updates[​](#streaming-updates \"Direct link to Streaming Updates\")\n\nThe GrowthBook SDK supports streaming with Server-Sent Events (SSE). When enabled, changes to features within GrowthBook will be streamed to the SDK in realtime as they are published. This is only supported on GrowthBook Cloud or if running a GrowthBook Proxy Server.\n\n### Streaming in Browser Environments[​](#streaming-in-browser-environments \"Direct link to Streaming in Browser Environments\")\n\nSSE is supported on all major browsers, so enabling streaming is as easy as passing `streaming: true` into your `init` call:\n\n```\ngb.init({  streaming: true,  // Other settings...})\n```\n\nYou may also differentiate your streaming host URL from your API host by setting the `streamingHost` property in the GrowthBook constructor (ex: Remote Evaluation is done on a CDN edge worker while Streaming is done through a GrowthBook Proxy server).\n\n### Streaming on the Server[​](#streaming-on-the-server \"Direct link to Streaming on the Server\")\n\nNode.js does not natively support SSE, but there is a small library you can install:\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save eventsource\n```\n\nInstead of enabling streaming separately for every GrowthBook instance, we recommend opening a single shared stream at app startup instead:\n\n```\nconst { setPolyfills, prefetchPayload } = require(\"@growthbook/growthbook\");// Configure GrowthBook to use the eventsource librarysetPolyfills({  EventSource: require(\"eventsource\"),});// Start a streaming connectionprefetchPayload({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  streaming: true}).then(() => console.log(\"Streaming connection open!\"))\n```\n\nThis will work as long as you use the exact same `apiHost` and `clientKey` when creating GrowthBook instances in your middleware.\n\n### Streaming in ReactNative[​](#streaming-in-reactnative \"Direct link to Streaming in ReactNative\")\n\nSimilar to Node.js, you need to install a polyfill for SSE to use streaming in a ReactNative application:\n\n*   npm\n*   Yarn\n*   pnpm\n\n```\nnpm install --save eventsource\n```\n\nThe, tell GrowthBook to use this polyfill:\n\n```\nconst { setPolyfills } = require(\"@growthbook/growthbook\");// Configure GrowthBook to use the eventsource librarysetPolyfills({  EventSource: require(\"eventsource\"),});\n```\n\nAnd finally, you can simply pass `streaming: true` into your init calls:\n\n```\ngb.init({  streaming: true,  // Other options...})\n```\n\n## Remote Evaluation[​](#remote-evaluation \"Direct link to Remote Evaluation\")\n\nWhen used in a front-end context, the React SDK may be run in Remote Evaluation mode. This mode brings the security benefits of a backend SDK to the front end by evaluating feature flags exclusively on a private server. Using Remote Evaluation ensures that any sensitive information within targeting rules or unused feature variations are never seen by the client. Note that Remote Evaluation should not be used in a backend context (Hybrid SSR/CSR is also not supported).\n\nYou must enable Remote Evaluation in your SDK Connection settings. Cloud customers are also required to self-host a GrowthBook Proxy Server or custom remote evaluation backend.\n\nTo use Remote Evaluation, add the `remoteEval: true` property to your SDK instance. A new evaluation API call will be made any time a user attribute or other dependency changes. You may optionally limit these API calls to specific attribute changes by setting the `cacheKeyAttributes` property (an array of attribute names that, when changed, trigger a new evaluation call).\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://gb-proxy.mydomain.io/\",  clientKey: \"sdk-abc123\",  // Enable remote evaluation  remoteEval: true,  // Optional: only trigger a new evaluation call when the `id` and `email` attribute changes  cacheKeyAttributes: [\"id\", \"email\"],});\n```\n\nnote\n\nIf you would like to implement Sticky Bucketing while using Remote Evaluation, you must configure your remote evaluation backend to support Sticky Bucketing. In the case of the GrowthBook Proxy Server, this means implementing a Redis database for sticky bucketing use. You will not need to provide a StickyBucketService instance to the client side SDK.\n\n## Caching[​](#caching \"Direct link to Caching\")\n\nThe JavaScript SDK has 2 caching layers:\n\n1.  In-memory cache (available on all platforms)\n2.  Persistent localStorage cache (only available in browsers by default)\n\nThere are a number of cache settings you can configure within GrowthBook. This must be done BEFORE creating a GrowthBook instance.\n\nBelow are all of the default values. You can call `configureCache` with a subset of these fields and the rest will keep their default values.\n\n```\nimport { configureCache } from \"@growthbook/growthbook\";configureCache({  // The localStorage key the cache will be stored under  cacheKey: \"gbFeaturesCache\",  // Consider features stale after this much time (60 seconds default)  staleTTL: 1000 * 60,  // Cached features older than this will be ignored (24 hours default)  maxAge: 1000 * 60 * 60 * 24,  // For Remote Eval only - limit the number of cache entries (~1 entry per user)  maxEntries: 10,  // When `false`, we add a `visibilitychange` listener to disable SSE when the page is idle  disableIdleStreams: false,  // Consider a page \"idle\" when it is hidden for this long (default 20 seconds)  idleStreamInterval: 20000,  // Set to `true` to completely disable both in-memory and persistent caching  disableCache: false,})\n```\n\n### Polyfilling localStorage[​](#polyfilling-localstorage \"Direct link to Polyfilling localStorage\")\n\nOutside of a browser environment, you can still use persistent caching. You just need to provide an implementation of the localStorage interface.\n\nHere's an example of using Redis in Node.js:\n\n```\nconst { setPolyfills } = require(\"@growthbook/growthbook\");setPolyfills({  localStorage: {    // Example using Redis    getItem: (key) => redisClient.get(key),    setItem: (key, value) => redisClient.set(key, value),  }});\n```\n\nThis must be done BEFORE you call either `prefetchPayload` or create the first GrowthBook instance.\n\n## Experimentation (A/B Testing)[​](#experimentation-ab-testing \"Direct link to Experimentation (A/B Testing)\")\n\nIn order to run A/B tests, you need to set up a tracking callback function. This is called every time a user is put into an experiment and can be used to track the exposure event in your analytics system (Segment, Mixpanel, GA, etc.).\n\n```\nconst gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  trackingCallback: (experiment, result) => {    // Example using Segment    analytics.track(\"Experiment Viewed\", {      experimentId: experiment.key,      variationId: result.key,    });  },});\n```\n\nThis same tracking callback is used for both feature flag experiments and Visual Editor experiments.\n\n### Feature Flag Experiments[​](#feature-flag-experiments \"Direct link to Feature Flag Experiments\")\n\nThere is nothing special you have to do for feature flag experiments. Just evaluate the feature flag like you would normally do. If the user is put into an experiment as part of the feature flag, it will call the `trackingCallback` automatically in the background.\n\n```\n// If this has an active experiment and the user is included,// it will call trackingCallback automaticallyuseFeatureIsOn(\"new-signup-form\")\n```\n\nIf the experiment came from a feature rule, `result.featureId` in the trackingCallback will contain the feature id, which may be useful for tracking/logging purposes.\n\n### Visual Editor Experiments[​](#visual-editor-experiments \"Direct link to Visual Editor Experiments\")\n\nExperiments created through the GrowthBook Visual Editor will run automatically as soon as their targeting conditions are met.\n\n**Note**: Visual Editor experiments are only supported in a web browser environment. They will not run in React Native or during Server Side Rendering (SSR).\n\nIf you are using this SDK in a Single Page App (SPA), you will need to let the GrowthBook instance know when the URL changes so the active experiments can update accordingly.\n\nFor example, in Next.js, you could do this:\n\n```\nfunction updateGrowthBookURL() {  gb.setURL(window.location.href);}export default function MyApp() {  // Subscribe to route change events and update GrowthBook  const router = useRouter();  useEffect(() => {    router.events.on(\"routeChangeComplete\", updateGrowthBookURL);    return () => router.events.off(\"routeChangeComplete\", updateGrowthBookURL);  }, []);  // ...}\n```\n\n### URL Redirect Experiments[​](#url-redirect-experiments \"Direct link to URL Redirect Experiments\")\n\nSimilarly to Visual Editor experiments, URL redirect tests will run automatically if targetting conditions are met.\n\nIf you are using this SDK in a Single Page App (SPA), you'll want to pass in a custom navigation function into the SDK (as default navigation for URL Redirects uses `window.location.replace(url)`) and set the `navigateDelay` to 0.\n\n```\n// Example in Next.jsimport router from \"next/router\";const gb = new GrowthBook({    navigate: (url) => router.replace(url),    navigateDelay: 0,    // ... other settings});\n```\n\nFor SPA's you will also need to let the GrowthBook instance know when the URL changes so the active experiments can update accordingly.\n\n```\n// Call this every time a navigation event happens in your SPAfunction onRouteChange() {  gb.setURL(window.location.href);}\n```\n\n### Sticky Bucketing[​](#sticky-bucketing \"Direct link to Sticky Bucketing\")\n\nSticky bucketing ensures that users see the same experiment variant, even when user session, user login status, or experiment parameters change. See the [Sticky Bucketing docs](https://docs.growthbook.io/app/sticky-bucketing) for more information. If your organization and experiment supports sticky bucketing, you must implement an instance of the `StickyBucketService` to use Sticky Bucketing. The JS SDK exports several implementations of this service for common use cases, or you may build your own:\n\n*   `LocalStorageStickyBucketService` — For simple bucket persistence using the browser's LocalStorage (can be polyfilled for other environments).\n    \n*   `BrowserCookieStickyBucketService` — For simple bucket persistence using browser cookies, which are transportable to the back end. Assumes `js-cookie` is implemented (can be polyfilled). Cookie attributes can also be configured.\n    \n*   `ExpressCookieStickyBucketService` — For NodeJS/Express controller-level bucket persistence using browser cookies; intended to be interoperable with `BrowserCookieStickyBucketService`. Assumes `cookie-parser` is implemented (can be polyfilled). Cookie attributes can also be configured.\n    \n*   `RedisStickyBucketService` — For NodeJS Redis-based bucket persistence. Requires an `ioredis` Redis client instance to be passed in.\n    \n*   Build your own — Implement the abstract `StickyBucketService` class and connect to your own data store, or custom wrap multiple service implementations (ex: read/write to both cookies and Redis).\n    \n\nImplementing most StickyBucketService implementations is straightforward and works with minimal setup. For instance, to use the `BrowserCookieStickyBucketService`:\n\n```\nimport { BrowserCookieStickyBucketService } from \"@growthbook/growthbook\";import Cookies from 'js-cookie';const gb = new GrowthBook({  apiHost: \"https://cdn.growthbook.io\",  clientKey: \"sdk-abc123\",  stickyBucketService: new BrowserCookieStickyBucketService({    jsCookie: Cookies,  }),  // ...});\n```\n\n## Next.js[​](#nextjs \"Direct link to Next.js\")\n\nIf you are using Next.js, checkout our example apps for [Next with App Router](https://github.com/growthbook/examples/tree/main/next-js) and [Next with Pages Router](https://github.com/growthbook/examples/tree/main/next-js-pages).\n\nThe examples above show how to use GrowthBook with a number of different rendering strategies and app setups and the App Router example has been updated to support the latest features in Next 14.\n\n## Server Side Rendering (SSR)[​](#server-side-rendering-ssr \"Direct link to Server Side Rendering (SSR)\")\n\nThis SDK fully supports server side rendering with React.\n\n### React Server Components[​](#react-server-components \"Direct link to React Server Components\")\n\nIf your framework supports the new React Server Components (RSC), welcome to the future! GrowthBook works great with modern React.\n\nFirst, if you are running experiments with GrowthBook, you will need to fire analytics tracking calls to record which variation a user is assigned. Analytics tools are often only supported client-side, so you can create a small Client Component first:\n\n```\n\"use client\";import { TrackingData } from \"@growthbook/growthbook-react\";// Helper component to track experiment views from server componentsexport default function GrowthBookTracking({ data }: { data: TrackingData[] }) {  useEffect(() => {    data.forEach(({ experiment, result }) => {      console.log(\"Viewed Experiment\", {        experimentId: experiment.key,        variationId: result.key      });    });  }, [data])  return null;}\n```\n\nThe React SDK relies on client-side Context, so for Server Components, you need to import our Javascript SDK `@growthbook/growthbook` instead.\n\n```\nimport { GrowthBook } from \"@growthbook/growthbook\";import GrowthBookTracking from \"./GrowthBookTracking\";export default async function MyServerPage() { // Create and initialize a GrowthBook instance  const gb = new GrowthBook({    apiHost: process.env.NEXT_PUBLIC_GROWTHBOOK_API_HOST,    clientKey: process.env.NEXT_PUBLIC_GROWTHBOOK_CLIENT_KEY,    decryptionKey: process.env.NEXT_PUBLIC_GROWTHBOOK_DECRYPTION_KEY,  });  await gb.init({ timeout: 1000 });  // Set targeting attributes for the user/page  await gb.setAttributes({    // TODO: get this from cookies, headers, etc.    id: cookies().get(\"my_uuid\")?.value || \"\",  });  // Evaluate any feature flags  const showBanner = gb.isOn(\"showBanner\");  const title = gb.getFeatureValue(\"title\", \"My Site\");  // If the above features ran any experiments, get the tracking call data  // This is passed into the <GrowthBookTracking> client component below  const trackingData = gb.getDeferredTrackingCalls();  // Cleanup  gb.destroy();  return (    <div>      <h1>{title}</h1>      {showBanner && (        <div className=\"sale\">There's a Sale!</div>      )}      <GrowthBookTracking data={trackingData} />    </div>  );}\n```\n\n#### Hydrating Client Components From the Server[​](#hydrating-client-components-from-the-server \"Direct link to Hydrating Client Components From the Server\")\n\nThe best part about React Server Components, is that you can easily share feature definitions with your Client Components. By doing this, you avoid any network requests from the browser and any flickering that goes along with that.\n\nLet's first create a GrowthBookWrapper wrapper that takes a `payload` prop and uses it to initialize a GrowthBook instance:\n\n```\n\"use client\";import {  GrowthBook,  GrowthBookProvider,  GrowthBookPayload} from \"@growthbook/growthbook-react\";import { PropsWithChildren, useMemo } from \"react\";import Cookies from \"js-cookie\";export default function GrowthBookWrapper({  payload,  children,}: PropsWithChildren<{ payload: GrowthBookPayload }>) {  // Create a singleton GrowthBook instance for this page  const gb = useMemo(    () =>      new GrowthBook({        apiHost: process.env.NEXT_PUBLIC_GROWTHBOOK_API_HOST,        clientKey: process.env.NEXT_PUBLIC_GROWTHBOOK_CLIENT_KEY,        decryptionKey: process.env.NEXT_PUBLIC_GROWTHBOOK_DECRYPTION_KEY,        trackingCallback: (experiment, result) => {          console.log(\"Viewed Experiment\", {            experimentId: experiment.key,            variationId: result.key          });        },        // Targeting attributes        attributes: {          id: Cookies.get(\"my_uuid\"),        },      }).initSync({        payload,        // Optional, enable streaming updates        streaming: true,      }),    [payload]  );  return <GrowthBookProvider growthbook={gb}>{children}</GrowthBookProvider>;}\n```\n\nNow we'll make a really simple client component using the GrowthBook React SDK:\n\n```\n\"use client\";import { useFeatureIsOn } from \"@growthbook/growthbook-react\";export default function OtherComponent() {  const clientFeature = useFeatureIsOn(\"client-feature\");  return (    <p>Client feature: {clientFeature ? \"ON\" : \"OFF\"}</p>  )}\n```\n\nNow, we can render these from our server component:\n\n```\nimport { GrowthBook } from \"@growthbook/growthbook\";import GrowthBookWrapper from \"./GrowthBookWrapper\";import OtherComponent from \"./OtherComponent\";import GrowthBookTracking from \"./GrowthBookTracking\";export default async function MyServerPage() {  // Create and initialize a GrowthBook instance  const gb = new GrowthBook({    apiHost: process.env.NEXT_PUBLIC_GROWTHBOOK_API_HOST,    clientKey: process.env.NEXT_PUBLIC_GROWTHBOOK_CLIENT_KEY,    decryptionKey: process.env.NEXT_PUBLIC_GROWTHBOOK_DECRYPTION_KEY,  });  await gb.init({ timeout: 1000 });  // Set targeting attributes for the user  gb.setAttributes({    id: cookies().get(\"my_uuid\")?.value || \"\",  });  // Evaluate any feature flags  const serverFeature = gb.isOn(\"server-feature\");  // If the above features ran any experiments, get the tracking call data  // This is passed into the <GrowthBookTracking> client component below  const trackingData = gb.getDeferredTrackingCalls();  // Get the payload to hydrate the client-side GrowthBook instance  // We need the decrypted payload so the initial client-render can be synchronous  const payload = gb.getDecryptedPayload();  // Cleanup your GrowthBook instance  gb.destroy();  return (    <div>      <p>Server feature: {serverFeature ? \"ON\" : \"OFF\"}</p>      <GrowthBookWrapper payload={payload}>        <OtherComponent>      </GrowthBookWrapper>      <GrowthBookTracking data={trackingData} />    </div>  );}\n```\n\n### Traditional SSR[​](#traditional-ssr \"Direct link to Traditional SSR\")\n\nBefore React Server Components, each framework implemented their own way to do data fetching and SSR. This example uses Next.js `getServerSideProps` method, but other frameworks should be similar.\n\nWith this approach, feature flags are evaluated once when the page is rendered. If a feature flag changes, the user would need to refresh the page to see it.\n\n```\nexport const getServerSideProps = async (context) => {  // Create and initialize a GrowthBook instance  const gb = new GrowthBook({    apiHost: process.env.GROWTHBOOK_API_HOST,    clientKey: process.env.GROWTHBOOK_CLIENT_KEY,    decryptionKey: process.env.GROWTHBOOK_DECRYPTION_KEY,  });  await gb.init({ timeout: 1000 });  // Set targeting attributes for the user  await gb.setAttributes({    id: context?.cookies?.my_uuid || \"\",  });  // Evaluate any feature flags  const showBanner = gb.isOn(\"show-banner\");  const title = gb.getFeatureValue(\"title\", \"My Site\");  // If the above features ran any experiments, get the tracking call data  // This is passed into the <GrowthBookTracking> client component below  const trackingData = gb.getDeferredTrackingCalls();  // Cleanup  gb.destroy();  // Pass the result into your component  return {    props: {      showBanner,      title,      trackingData    }  }}export default function MyPage({ title, showBanner, trackingData }) {  useEffect(() => {    trackingData?.forEach(({experiment, result}) => {      // TODO: Track in your analytics tool      console.log(\"Viewed Experiment\", {        experimentId: experiment.key,        variationId: result.key      });    });  }, [trackingData])  return (    <div>      <h1>{title}</h1>      {showBanner && (        <div className=\"sale\">There's a Sale!</div>      )}    </div>  )}\n```\n\n#### Hybrid (SSR + Client-side)[​](#hybrid-ssr--client-side \"Direct link to Hybrid (SSR + Client-side)\")\n\nInstead of passing the result of individual feature flags to your component, you can also pass the entire payload. By doing this, you get the benefits of client-side rendering (interactivity, realtime feature flag updates) plus the benefits of SSR (no flickering, improved SEO).\n\n```\nexport const getServerSideProps = async (context) => {  // Create and initialize a GrowthBook instance  const gb = new GrowthBook({    apiHost: process.env.NEXT_PUBLIC_GROWTHBOOK_API_HOST,    clientKey: process.env.NEXT_PUBLIC_GROWTHBOOK_CLIENT_KEY,    decryptionKey: process.env.NEXT_PUBLIC_GROWTHBOOK_DECRYPTION_KEY,  });  await gb.init({ timeout: 1000 });  // Get the payload to hydrate the client-side GrowthBook instance  // We need the decrypted payload so the initial client-render can be synchronous  const payload = gb.getDecryptedPayload();  // Cleanup  gb.destroy();  // Pass the result into your component  return {    props: {      payload    }  }}export default function MyPage({ payload }) {  // Create a singleton GrowthBook instance for this page  const gb = useMemo(    () =>      new GrowthBook({        apiHost: process.env.NEXT_PUBLIC_GROWTHBOOK_API_HOST,        clientKey: process.env.NEXT_PUBLIC_GROWTHBOOK_CLIENT_KEY,        decryptionKey: process.env.NEXT_PUBLIC_GROWTHBOOK_DECRYPTION_KEY,        trackingCallback: (experiment, result) => {          console.log(\"Viewed Experiment\", {            experimentId: experiment.key,            variationId: result.key          });        },        attributes: {          id: Cookies.get(\"my_uuid\"),        },      }).initSync({        payload,        // Optional, enable streaming updates        streaming: true,      }),    [payload]  );  return <GrowthBookProvider growthbook={gb}><MyComponent></GrowthBookProvider>;}\n```\n\nThen, within `MyComponent`, you can use any of the normal client-side hooks or helper components - `useFeatureIsOn`, `useFeatureValue`, etc.\n\n## API Reference[​](#api-reference \"Direct link to API Reference\")\n\nThere are a number of configuration options and settings that control how GrowthBook behaves.\n\n### Attributes[​](#attributes \"Direct link to Attributes\")\n\nYou can specify attributes about the current user and request. These are used for two things:\n\n1.  Feature targeting (e.g. paid users get one value, free users get another)\n2.  Assigning persistent variations in A/B tests (e.g. user id \"123\" always gets variation B)\n\nThe following are some commonly used attributes, but use whatever makes sense for your application.\n\n```\nnew GrowthBook({  attributes: {    id: \"123\",    loggedIn: true,    deviceId: \"abc123def456\",    company: \"acme\",    paid: false,    url: \"/pricing\",    browser: \"chrome\",    mobile: false,    country: \"US\",  },});\n```\n\n#### Updating Attributes[​](#updating-attributes \"Direct link to Updating Attributes\")\n\nIf attributes change, you can call `setAttributes()` to update. This will completely overwrite any existing attributes. To do a partial update, use the following pattern:\n\n```\ngb.setAttributes({  // Only update the `url` attribute, keep the rest the same  ...gb.getAttributes(),  url: \"/new-page\"})\n```\n\n#### Secure Attributes[​](#secure-attributes \"Direct link to Secure Attributes\")\n\nWhen _secure attribute hashing_ is enabled, all targeting conditions in the SDK payload referencing attributes with datatype `secureString` or `secureString[]` will be anonymized via SHA-256 hashing. This allows you to safely target users based on sensitive attributes. You must enable this feature in your SDK Connection for it to take effect.\n\nIf your SDK Connection has secure attribute hashing enabled, you will need to manually hash any `secureString` or `secureString[]` attributes that you pass into the GrowthBook SDK.\n\nTo hash an attribute, use a cryptographic library with SHA-256 support, and compute the SHA-256 hashed value of your attribute _plus_ your organization's secure attribute salt.\n\n```\nconst salt = \"f09jq3fij\"; // Your organization's secure attribute salt (see Organization Settings)// hashing a secureString attributeconst userEmail = sha256(salt + user.email);// hashing an secureString[] attributeconst userTags = user.tags.map(tag => sha256(salt + tag));gb.setAttributes({  id: user.id,  loggedIn: true,  email: userEmail,  tags: userTags,});await gb.init();// In this example, we are using Node.js's built-in crypto libraryfunction sha256(str) {  return crypto.createHash(\"sha256\").update(str).digest(\"hex\");}\n```\n\nNote that in a browser context, we will not be able to natively access the Node.js crypto library. In modern browsers `window.crypto.subtle` is available, although calls are asynchronous. You would need to await all attribute hashing to complete before calling `gb.setAttributes()`.\n\n```\nasync function sha256(str) {  const buffer = await crypto.subtle.digest(\"SHA-256\", new TextEncoder().encode(str));  const hashArray = Array.from(new Uint8Array(buffer));  return hashArray.map(byte => byte.toString(16).padStart(2, \"0\")).join(\"\");}\n```\n\nAlternatively, CryptoJS ([https://www.npmjs.com/package/crypto-js](https://www.npmjs.com/package/crypto-js)) provides a synchronous API:\n\n```\nimport sha256 from 'crypto-js/sha256';const userEmail = sha256(salt + user.email);\n```\n\n### Feature Usage Callback[​](#feature-usage-callback \"Direct link to Feature Usage Callback\")\n\nGrowthBook can fire a callback whenever a feature is evaluated for a user. This can be useful to update 3rd party tools like NewRelic or DataDog.\n\n```\nnew GrowthBook({  onFeatureUsage: (featureKey, result) => {    console.log(\"feature\", featureKey, \"has value\", result.value);  },});\n```\n\nNote: If you evaluate the same feature multiple times (and the value doesn't change), the callback will only be fired the first time.\n\n### Dev Mode[​](#dev-mode \"Direct link to Dev Mode\")\n\nThere is a [GrowthBook Chrome DevTools Extension](https://chrome.google.com/webstore/detail/growthbook-devtools/opemhndcehfgipokneipaafbglcecjia) that can help you debug and test your feature flags in development.\n\nIn order for this to work, you must explicitly enable dev mode when creating your GrowthBook instance:\n\n```\nconst gb = new GrowthBook({  enableDevMode: true,});\n```\n\nTo avoid exposing all of your internal feature flags and experiments to users, we recommend setting this to `false` in production in most cases.\n\n### Inline Experiments[​](#inline-experiments \"Direct link to Inline Experiments\")\n\nDepending on how you configure feature flags, they may run A/B tests behind the scenes to determine which value gets assigned to the user.\n\nSometimes though, you want to run an inline experiment without going through a feature flag first. For this, you can use either the `useExperiment` hook or the Higher Order Component `withRunExperiment`:\n\nView the [Javascript SDK Docs](https://docs.growthbook.io/lib/js) for all of the options available for inline experiments\n\n#### useExperiment hook[​](#useexperiment-hook \"Direct link to useExperiment hook\")\n\n```\nimport { useExperiment } from \"@growthbook/growthbook-react\";export default function OtherComponent() {  const { value } = useExperiment({    key: \"new-headline\",    variations: [\"Hello\", \"Hi\", \"Good Day\"]  });  return <h1>{value}</h1>;}\n```\n\n#### withRunExperiment (class components)[​](#withrunexperiment-class-components \"Direct link to withRunExperiment (class components)\")\n\n**Note:** This library uses hooks internally, so still requires React 16.8 or above.\n\n```\nimport { withRunExperiment } from \"@growthbook/growthbook-react\";class OtherComponent extends React.Component {  render() {    // The `runExperiment` prop is identical to the `useExperiment` hook    const { value } = this.props.runExperiment({      key: \"headline-test\",      variations: [\"Hello World\", \"Hola Mundo\"]    });    return <h1>{value}</h1>;  }}// Wrap your component in `withRunExperiment`export default withRunExperiment(OtherComponent);\n```\n\n## TypeScript support[​](#typescript-support \"Direct link to TypeScript support\")\n\nSome hooks are available in type-safe versions. These require you to pass in your generated types as the generic argument.\n\nSee the [GrowthBook CLI](https://docs.growthbook.io/tools/cli) documentation for more information on generating type definitions and [JavaScript → TypeScript → Scrict Typing](https://docs.growthbook.io/lib/js#strict-typing) for how to use them.\n\n### useGrowthBook<T>()[​](#usegrowthbookt \"Direct link to useGrowthBook<T>()\")\n\nA type-safe version of the `useGrowthBook()` hook is available. Everywhere you use `useGrowthBook()`, pass the generated features as the generic argument:\n\n```\nconst growthbook = useGrowthBook<AppFeatures>()\n```\n\nIn that case, the hook will return `GrowthBook<AppFeatures> | undefined`.\n\nYou can reduce this boilerplate by creating your own hook, e.g.:\n\n```\n// ./src/utils/growthbook.tsimport { useGrowthBook as _useGrowthBook } from \"@growthbook/growthbook-react\";export const useGrowthBook = (): GrowthBook<AppFeatures> | undefined =>  _useGrowthBook<AppFeatures>();\n```\n\nYou can now reference the hook you created instead of the one from the official package:\n\n```\nimport { useGrowthBook } from \"@/src/utils/growthbook\"const growthbook = useGrowthBook();growthbook.getFeatureValue(knownKey, defaultValueOfValidType)\n```\n\n### useFeatureIsOn<T>()[​](#usefeatureisont \"Direct link to useFeatureIsOn<T>()\")\n\nThe React SDK also provides access to a type-safe `useFeatureIsOn<AppFeatures>()` hook.\n\n```\nconst isDarkModeOn = useFeatureIsOn<AppFeatures>(\"dark_mode\");\n```\n\nThis will only allow you to pass known keys to the hook.\n\nYou can reduce the boilerplate for this hook by creating your own and using that instead:\n\n```\n// ./src/utils/growthbook.tsimport { useFeatureIsOn as _useFeatureIsOn } from \"@growthbook/growthbook-react\";export const useFeatureIsOn = (id: keyof AppFeatures & string): boolean =>  _useFeatureIsOn<AppFeatures>(id);\n```\n\nAnd then reference the hook you created instead of the one from the official package:\n\n```\nimport { useFeatureIsOn } from \"@/src/utils/growthbook\"const isDarkModeOn = useFeatureIsOn(\"dark_mode\");\n```\n\n## Examples[​](#examples \"Direct link to Examples\")\n\n*   [Next.js](https://github.com/growthbook/examples/tree/main/next-js)\n*   [React Native](https://github.com/growthbook/examples/tree/main/react-native-cli)\n*   [Typescript example app with strict typing](https://github.com/growthbook/examples/tree/main/vanilla-typescript) .",
    "title": "React SDK | GrowthBook Docs",
    "description": "GrowthBook SDK for React",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/warehouses/databricks",
    "markdown": "# Setting up Databricks as a data source\n\nTo connect to Databricks, you need to provide GrowthBook with the connection details and access token to the SQL Warehouse you use within Databricks.\n\n## 1\\. Find the connection details for your SQL Warehouse[​](#1-find-the-connection-details-for-your-sql-warehouse \"Direct link to 1. Find the connection details for your SQL Warehouse\")\n\nIn your Databricks instance, navigate to the SQL Warehouses, select your SQL Warehouse that stores the data you want GrowthBook to access, and the click Connection Details. You should see the following page, which contains most of the fields needed to connect GrowthBook to your Databricks SQL Warehouse.\n\n![Finding SQL Warehouse Connection Details in Databricks](https://docs.growthbook.io/images/guides/databricks-connection.png)\n\n## 2\\. Create an access token for GrowthBook[​](#2-create-an-access-token-for-growthbook \"Direct link to 2. Create an access token for GrowthBook\")\n\nThere are two kinds of access tokens that will work to connect GrowthBook to Databricks:\n\n*   A personal access token for a user account\n*   A personal access token for a service principal\n\nWhichever path you choose, ensure the service principal or the user has permission to execute SQL queries against your SQL Warehouse.\n\nFollow these instructions to create a service principal and create an access token for the service principal: [https://docs.databricks.com/en/dev-tools/service-principals.html](https://docs.databricks.com/en/dev-tools/service-principals.html)\n\nAlternatively, you can create a personal access token for a Databricks workspace user following these instructions: [https://docs.databricks.com/en/dev-tools/auth.html#pat](https://docs.databricks.com/en/dev-tools/auth.html#pat)\n\n## 3\\. Add credentials to GrowthBook[​](#3-add-credentials-to-growthbook \"Direct link to 3. Add credentials to GrowthBook\")\n\nNow that you have the connection details and an access token, you can enter the Connection Details and Access Token to GrowthBook when when creating a Data Source!\n\nClick \"Add a Datasource\" from the Data Sources page under Metrics and Data and either select your event tracker or click \"custom data source\". Then you can select Databricks as your data warehouse and enter the above credentials.\n\nNote: We only use the event tracker (e.g. Snowplow, Segment) to help us build queries for you. This information **does not** impact how or whether we are able to connect to Databricks.",
    "title": "Setting up Databricks as a data source | GrowthBook Docs",
    "description": "This document outlines the steps needed to add your Databricks database to GrowthBook.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/warehouses/mixpanel",
    "markdown": "# Setting up Mixpanel as a data source\n\ntip\n\nYou can find a more detailed walk through for setting up Mixpanel [here](https://docs.growthbook.io/guide/mixpanel)\n\nYou must first create a Service Account in Mixpanel under your [Project Settings](https://mixpanel.com/settings/project#serviceaccounts).\n\nTo add the datasource in GrowthBook, you will need:\n\n1.  The service account username\n2.  The service account secret\n3.  Your project id (found on the Project Settings Overview page)",
    "title": "Setting up Mixpanel as a data source | GrowthBook Docs",
    "description": "This document outlines the steps needed to add your Mixpanel database to GrowthBook.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/warehouses/ms-sql-or-sql-server",
    "markdown": "# Setting up MS SQL or SQL Server as a data source\n\nWhen setting up MS SQL or SQL Server to work with Growthbook, remember it's important to create read-only users with minimal permissions, ideally granting only read access to the relevant data tables that need to be aggregated.\n\nIf you are using GrowthBook Cloud (app.growthbook.io), make sure to whitelist the ip address `52.70.79.40` if applicable.\n\nUnfortunately there isn't a specific guide for setting up MS SQL or SQL Server for Growthbook yet. However, if you encounter any difficulties while setting up your data source, you can seek assistance from our active developer community on [Slack](https://slack.growthbook.io/?ref=docs-datasource-ms-sql-or-sql-server). They can help you troubleshoot and ensure your implementation is successful. Once you've successfully set up MS SQL or SQL Server according to best practices, we encourage you to contributing to the community by [creating improved documentation for MS SQL or SQL Server](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs). Your contribution will benefit other users in the future.",
    "title": "Setting up MS SQL or SQL Server as a data source | GrowthBook Docs",
    "description": "This document outlines the steps needed to add your MS SQL or SQL Server database to GrowthBook.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/warehouses/mysql-or-mariadb",
    "markdown": "# Setting up MySQL or MariaDB as a data source\n\nWhen setting up MySQL or MariaDB to work with Growthbook, remember it's important to create read-only users with minimal permissions, ideally granting only read access to the relevant data tables that need to be aggregated.\n\nIf you are using GrowthBook Cloud (app.growthbook.io), make sure to whitelist the ip address `52.70.79.40` if applicable.\n\nUnfortunately there isn't a specific guide for setting up MySQL or MariaDB for Growthbook yet. However, if you encounter any difficulties while setting up your data source, you can seek assistance from our active developer community on [Slack](https://slack.growthbook.io/?ref=docs-datasource-mysql-or-mariadb). They can help you troubleshoot and ensure your implementation is successful. Once you've successfully set up MySQL or MariaDB according to best practices, we encourage you to contributing to the community by [creating improved documentation for MySQL or MariaDB](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs). Your contribution will benefit other users in the future.",
    "title": "Setting up MySQL or MariaDB as a data source | GrowthBook Docs",
    "description": "This document outlines the steps needed to add your MySQL or MariaDB database to GrowthBook.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/warehouses/postgres",
    "markdown": "# Setting up Postgres as a data source\n\nWhen setting up Postgres to work with Growthbook, remember it's important to create read-only users with minimal permissions, ideally granting only read access to the relevant data tables that need to be aggregated.\n\nIf you are using GrowthBook Cloud (app.growthbook.io), make sure to whitelist the ip address `52.70.79.40` if applicable.\n\nUnfortunately there isn't a specific guide for setting up Postgres for Growthbook yet. However, if you encounter any difficulties while setting up your data source, you can seek assistance from our active developer community on [Slack](https://slack.growthbook.io/?ref=docs-datasource-postgres). They can help you troubleshoot and ensure your implementation is successful. Once you've successfully set up Postgres according to best practices, we encourage you to contributing to the community by [creating improved documentation for Postgres](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs). Your contribution will benefit other users in the future.",
    "title": "Setting up Postgres as a data source | GrowthBook Docs",
    "description": "This document outlines the steps needed to add your Postgres database to GrowthBook.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/warehouses/prestodb-or-trino",
    "markdown": "# Setting up Prestodb or Trino as a data source\n\nWhen setting up Prestodb or Trino to work with Growthbook, remember it's important to create read-only users with minimal permissions, ideally granting only read access to the relevant data tables that need to be aggregated.\n\nIf you are using GrowthBook Cloud (app.growthbook.io), make sure to whitelist the ip address `52.70.79.40` if applicable.\n\nUnfortunately there isn't a specific guide for setting up Prestodb or Trino for Growthbook yet. However, if you encounter any difficulties while setting up your data source, you can seek assistance from our active developer community on [Slack](https://slack.growthbook.io/?ref=docs-datasource-prestodb-or-trino). They can help you troubleshoot and ensure your implementation is successful. Once you've successfully set up Prestodb or Trino according to best practices, we encourage you to contributing to the community by [creating improved documentation for Prestodb or Trino](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs). Your contribution will benefit other users in the future.",
    "title": "Setting up Prestodb or Trino as a data source | GrowthBook Docs",
    "description": "This document outlines the steps needed to add your Prestodb or Trino database to GrowthBook.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/warehouses/redshift",
    "markdown": "# Setting up Redshift as a data source\n\nWhen setting up Redshift to work with Growthbook, remember it's important to create read-only users with minimal permissions, ideally granting only read access to the relevant data tables that need to be aggregated.\n\nIf you are using GrowthBook Cloud (app.growthbook.io), make sure to whitelist the ip address `52.70.79.40` if applicable.\n\nUnfortunately there isn't a specific guide for setting up Redshift for Growthbook yet. However, if you encounter any difficulties while setting up your data source, you can seek assistance from our active developer community on [Slack](https://slack.growthbook.io/?ref=docs-datasource-redshift). They can help you troubleshoot and ensure your implementation is successful. Once you've successfully set up Redshift according to best practices, we encourage you to contributing to the community by [creating improved documentation for Redshift](https://github.com/growthbook/growthbook/blob/main/CONTRIBUTING.md#working-on-docs). Your contribution will benefit other users in the future.",
    "title": "Setting up Redshift as a data source | GrowthBook Docs",
    "description": "This document outlines the steps needed to add your Redshift database to GrowthBook.",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/app/data-pipeline",
    "markdown": "# Data Pipeline | GrowthBook Docs\n\nnote\n\nPipeline mode is only available for Enterprise customers and is currently only available for BigQuery, Snowflake, and Databricks Data Sources.\n\nFor experimenters who have multiple metrics per experiment and have large experiment assignment sources, GrowthBook can greatly improve the performance of your queries if you enable **Pipeline Mode**, writing some intermediate tables back to your warehouse with short retention and re-using those across metric analyses in an experiment. This depends a bit on your datasource cost structure, but if you are billed by rows scanned, pipeline mode will almost certainly provide substantial savings.\n\nWith **Pipeline Mode** enabled, whenever an experiment analysis is run, GrowthBook dedupes your experiment assignment source, joins any relevant activation or dimension data, and then stores that deduped experiment assignment table to be re-used by the individual metric analyses.\n\nThe only change from enabling pipeline mode is that we materialize one intermediate table per experiment analysis that will have the number of rows equal to the number of experiment units in that experiment. Enabling pipeline mode has no impact on any of your analysis settings or experiment results and we do not access any more data than if pipeline mode is disabled.\n\nTo enable Pipeline Mode, follow the steps for your data warehouse:\n\n### BigQuery[​](#bigquery \"Direct link to BigQuery\")\n\n1.  (strongly recommended, but optional) Create a dedicated dataset to which GrowthBook will write temporary tables. This will keep your data warehouse clean and ensure that we are only writing to a dedicated space.\n2.  Grant permissions to create tables to the role connecting GrowthBook to your warehouse. You can do this by granting your GrowthBook Service Account the `BigQuery Data Editor` role on the new datahouse. You can also give only BigQuery table reading and writing permissions on that dataset if you want to be more restrictive.\n3.  Navigate to your BigQuery Data Source in GrowthBook and scroll down to \"Data Pipeline Settings\"\n4.  Click \"Edit\" and enable pipeline mode, set the destination dataset to your new dedicated GrowthBook dataset from step 1, and set the number of hours you will retain our temporary tables. We recommend at least 6 hours and the default is 24.\n\n### Snowflake[​](#snowflake \"Direct link to Snowflake\")\n\n1.  (strongly recommended, but optional) Create a dedicated schema to which GrowthBook will write temporary tables. This will keep your data warehouse clean and ensure that we are only writing to a dedicated space.\n2.  Grant permissions to create tables to the role connecting GrowthBook to your warehouse. The Snowflake role attached to GrowthBook will need `CREATE TABLE`, `SELECT - FUTURE TABLE`, and `USAGE` on the schema created in step 1.\n3.  Navigate to your Snowflake Data Source in GrowthBook and scroll down to \"Data Pipeline Settings\"\n4.  Click \"Edit\" and enable pipeline mode, set the destination schema to your new dedicated GrowthBook schema from step 1, and set the number of hours you will retain our temporary tables. For Snowflake, we recommend leaving the value at 24 as Snowflake's retention is set in days and we will round up to the nearest day.\n\n### Databricks[​](#databricks \"Direct link to Databricks\")\n\nDatabricks works slightly differently. Instead of creating a temporary table, we create a regular table for the deduped units assignment and then `DROP` that table when analysis is completed.\n\nnote\n\nUsing pipeline mode in Databricks requires either granting DROP permissions to the Databricks account that GrowthBook uses, or leaving many tables in your schema you have to manually delete later! For this reason we strongly recommend a standalone schema for GrowthBook to use to write tables to.\n\n1.  (strongly recommended, but optional) Create a dedicated schema to which GrowthBook will write temporary tables. This will keep your data warehouse clean and ensure that we are only writing to and dropping from a dedicated space.\n2.  Grant permissions to your user account or service principal that already has read permission in your warehouse. That user/service principle will need to be able to `USE SCHEMA`, `CREATE TABLE`, `DROP TABLE`, and to `SELECT` and `EXECUTE` in the schema.\n3.  Navigate to your Databricks Data Source in GrowthBook and scroll down to \"Data Pipeline Settings\"\n4.  Click \"Edit\" and enable pipeline mode, set the destination schema to your new dedicated GrowthBook schema from step 1, and whether you want the table to be deleted (we recommend you leave this setting on as we will not re-use these tables at a later date). If this setting is off, you'll need to manually delete the tables that GrowthBook creates.",
    "title": "Data Pipeline | GrowthBook Docs",
    "description": "Learn about enabling Pipeline Mode and improving query efficiency",
    "languageCode": "en"
  },
  {
    "url": "https://docs.growthbook.io/warehouses/snowflake",
    "markdown": "# Setting up Snowflake as a data source\n\nWe support multiple [account identifier](https://docs.snowflake.com/en/user-guide/admin-account-identifier.html) formats when connecting to Snowflake. An example account identifier is `xy12345.us-east-2.aws`.\n\nIf you are self-hosting GrowthBook, you can send queries to Snowflake through an Authenticated Proxy.\n\nTo enable this, set a `SNOWFLAKE_PROXY` environment variable in your GrowthBook container. Here is an example:\n\n```\nSNOWFLAKE_PROXY=http://username:password@proxyserver.company.com:80\n```\n\nEnterprise customers can enable pipeline mode, which can reduce query costs if you grant the GrowthBook service account write permissions in your data warehouse.",
    "title": "Setting up Snowflake as a data source | GrowthBook Docs",
    "description": "This document outlines the steps needed to add your Snowflake database to GrowthBook.",
    "languageCode": "en"
  }
]